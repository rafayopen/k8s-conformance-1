I1114 21:47:35.246792      13 test_context.go:406] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-216763962
I1114 21:47:35.247790      13 e2e.go:243] Starting e2e run "da23674e-9498-42c0-b428-9abdf9bb8dec" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1573768052 - Will randomize all specs
Will run 215 of 4413 specs

Nov 14 21:47:35.544: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
Nov 14 21:47:35.548: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Nov 14 21:47:35.808: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Nov 14 21:47:37.565: INFO: 10 / 10 pods in namespace 'kube-system' are running and ready (1 seconds elapsed)
Nov 14 21:47:37.565: INFO: expected 5 pod replicas in namespace 'kube-system', 5 are Running and Ready.
Nov 14 21:47:37.565: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Nov 14 21:47:38.010: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Nov 14 21:47:38.010: INFO: 1 / 1 pods ready in namespace 'kube-system' in daemonset 'k8s-keystone-auth' (0 seconds elapsed)
Nov 14 21:47:38.010: INFO: 1 / 1 pods ready in namespace 'kube-system' in daemonset 'openstack-cloud-controller-manager' (0 seconds elapsed)
Nov 14 21:47:38.010: INFO: e2e test version: v1.15.5
Nov 14 21:47:38.014: INFO: kube-apiserver version: v1.15.5
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 21:47:38.015: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename container-probe
Nov 14 21:47:40.402: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Nov 14 21:47:41.507: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-3118
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Nov 14 21:48:30.792: INFO: Container started at 2019-11-14 21:48:06 +0000 UTC, pod became ready at 2019-11-14 21:48:30 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 21:48:30.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3118" for this suite.
Nov 14 21:49:10.119: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 21:49:10.635: INFO: namespace container-probe-3118 deletion completed in 39.564042922s

• [SLOW TEST:92.620 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 21:49:10.637: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-4539
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Nov 14 21:49:12.661: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-4539,SelfLink:/api/v1/namespaces/watch-4539/configmaps/e2e-watch-test-resource-version,UID:4076cb23-94fe-4e8e-8e39-45e52b779ba5,ResourceVersion:6593,Generation:0,CreationTimestamp:2019-11-14 21:49:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov 14 21:49:12.662: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-4539,SelfLink:/api/v1/namespaces/watch-4539/configmaps/e2e-watch-test-resource-version,UID:4076cb23-94fe-4e8e-8e39-45e52b779ba5,ResourceVersion:6596,Generation:0,CreationTimestamp:2019-11-14 21:49:10 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 21:49:12.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-4539" for this suite.
Nov 14 21:49:27.821: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 21:49:28.048: INFO: namespace watch-4539 deletion completed in 15.06407603s

• [SLOW TEST:17.411 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 21:49:28.053: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-5518
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod liveness-60146088-fa82-41ea-8462-d4b58940cdd4 in namespace container-probe-5518
Nov 14 21:50:04.233: INFO: Started pod liveness-60146088-fa82-41ea-8462-d4b58940cdd4 in namespace container-probe-5518
STEP: checking the pod's current state and verifying that restartCount is present
Nov 14 21:50:04.249: INFO: Initial restart count of pod liveness-60146088-fa82-41ea-8462-d4b58940cdd4 is 0
Nov 14 21:50:18.309: INFO: Restart count of pod container-probe-5518/liveness-60146088-fa82-41ea-8462-d4b58940cdd4 is now 1 (14.059383352s elapsed)
Nov 14 21:50:38.404: INFO: Restart count of pod container-probe-5518/liveness-60146088-fa82-41ea-8462-d4b58940cdd4 is now 2 (34.153836743s elapsed)
Nov 14 21:50:58.759: INFO: Restart count of pod container-probe-5518/liveness-60146088-fa82-41ea-8462-d4b58940cdd4 is now 3 (54.508995142s elapsed)
Nov 14 21:51:18.825: INFO: Restart count of pod container-probe-5518/liveness-60146088-fa82-41ea-8462-d4b58940cdd4 is now 4 (1m14.575296237s elapsed)
Nov 14 21:52:27.578: INFO: Restart count of pod container-probe-5518/liveness-60146088-fa82-41ea-8462-d4b58940cdd4 is now 5 (2m23.328362948s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 21:52:27.649: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5518" for this suite.
Nov 14 21:52:34.127: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 21:52:34.302: INFO: namespace container-probe-5518 deletion completed in 6.43573604s

• [SLOW TEST:186.250 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 21:52:34.312: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1392
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a replication controller
Nov 14 21:52:34.667: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 create -f - --namespace=kubectl-1392'
Nov 14 21:52:38.467: INFO: stderr: ""
Nov 14 21:52:38.467: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov 14 21:52:38.506: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1392'
Nov 14 21:52:38.649: INFO: stderr: ""
Nov 14 21:52:38.649: INFO: stdout: ""
STEP: Replicas for name=update-demo: expected=2 actual=0
Nov 14 21:52:43.649: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1392'
Nov 14 21:52:43.870: INFO: stderr: ""
Nov 14 21:52:43.870: INFO: stdout: "update-demo-nautilus-4ljlf update-demo-nautilus-v6ndl "
Nov 14 21:52:43.870: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 get pods update-demo-nautilus-4ljlf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1392'
Nov 14 21:52:44.235: INFO: stderr: ""
Nov 14 21:52:44.235: INFO: stdout: ""
Nov 14 21:52:44.235: INFO: update-demo-nautilus-4ljlf is created but not running
Nov 14 21:52:49.235: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1392'
Nov 14 21:52:49.355: INFO: stderr: ""
Nov 14 21:52:49.355: INFO: stdout: "update-demo-nautilus-4ljlf update-demo-nautilus-v6ndl "
Nov 14 21:52:49.355: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 get pods update-demo-nautilus-4ljlf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1392'
Nov 14 21:52:49.508: INFO: stderr: ""
Nov 14 21:52:49.509: INFO: stdout: ""
Nov 14 21:52:49.509: INFO: update-demo-nautilus-4ljlf is created but not running
Nov 14 21:52:54.510: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1392'
Nov 14 21:52:54.658: INFO: stderr: ""
Nov 14 21:52:54.658: INFO: stdout: "update-demo-nautilus-4ljlf update-demo-nautilus-v6ndl "
Nov 14 21:52:54.658: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 get pods update-demo-nautilus-4ljlf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1392'
Nov 14 21:52:54.767: INFO: stderr: ""
Nov 14 21:52:54.767: INFO: stdout: ""
Nov 14 21:52:54.767: INFO: update-demo-nautilus-4ljlf is created but not running
Nov 14 21:52:59.767: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1392'
Nov 14 21:53:00.001: INFO: stderr: ""
Nov 14 21:53:00.001: INFO: stdout: "update-demo-nautilus-4ljlf update-demo-nautilus-v6ndl "
Nov 14 21:53:00.001: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 get pods update-demo-nautilus-4ljlf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1392'
Nov 14 21:53:00.226: INFO: stderr: ""
Nov 14 21:53:00.226: INFO: stdout: "true"
Nov 14 21:53:00.227: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 get pods update-demo-nautilus-4ljlf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1392'
Nov 14 21:53:00.384: INFO: stderr: ""
Nov 14 21:53:00.384: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov 14 21:53:00.384: INFO: validating pod update-demo-nautilus-4ljlf
Nov 14 21:53:00.460: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 14 21:53:00.460: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 14 21:53:00.460: INFO: update-demo-nautilus-4ljlf is verified up and running
Nov 14 21:53:00.460: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 get pods update-demo-nautilus-v6ndl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1392'
Nov 14 21:53:00.577: INFO: stderr: ""
Nov 14 21:53:00.578: INFO: stdout: "true"
Nov 14 21:53:00.578: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 get pods update-demo-nautilus-v6ndl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1392'
Nov 14 21:53:00.676: INFO: stderr: ""
Nov 14 21:53:00.677: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov 14 21:53:00.677: INFO: validating pod update-demo-nautilus-v6ndl
Nov 14 21:53:00.683: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 14 21:53:00.683: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 14 21:53:00.683: INFO: update-demo-nautilus-v6ndl is verified up and running
STEP: scaling down the replication controller
Nov 14 21:53:00.686: INFO: scanned /root for discovery docs: <nil>
Nov 14 21:53:00.686: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-1392'
Nov 14 21:53:01.989: INFO: stderr: ""
Nov 14 21:53:01.989: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov 14 21:53:01.989: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1392'
Nov 14 21:53:02.400: INFO: stderr: ""
Nov 14 21:53:02.400: INFO: stdout: "update-demo-nautilus-4ljlf update-demo-nautilus-v6ndl "
STEP: Replicas for name=update-demo: expected=1 actual=2
Nov 14 21:53:07.400: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1392'
Nov 14 21:53:07.533: INFO: stderr: ""
Nov 14 21:53:07.533: INFO: stdout: "update-demo-nautilus-4ljlf "
Nov 14 21:53:07.533: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 get pods update-demo-nautilus-4ljlf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1392'
Nov 14 21:53:07.663: INFO: stderr: ""
Nov 14 21:53:07.663: INFO: stdout: "true"
Nov 14 21:53:07.663: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 get pods update-demo-nautilus-4ljlf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1392'
Nov 14 21:53:07.815: INFO: stderr: ""
Nov 14 21:53:07.815: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov 14 21:53:07.815: INFO: validating pod update-demo-nautilus-4ljlf
Nov 14 21:53:07.822: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 14 21:53:07.822: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 14 21:53:07.822: INFO: update-demo-nautilus-4ljlf is verified up and running
STEP: scaling up the replication controller
Nov 14 21:53:07.828: INFO: scanned /root for discovery docs: <nil>
Nov 14 21:53:07.828: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-1392'
Nov 14 21:53:09.133: INFO: stderr: ""
Nov 14 21:53:09.133: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov 14 21:53:09.133: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1392'
Nov 14 21:53:09.290: INFO: stderr: ""
Nov 14 21:53:09.290: INFO: stdout: "update-demo-nautilus-2444j update-demo-nautilus-4ljlf "
Nov 14 21:53:09.290: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 get pods update-demo-nautilus-2444j -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1392'
Nov 14 21:53:09.415: INFO: stderr: ""
Nov 14 21:53:09.415: INFO: stdout: ""
Nov 14 21:53:09.415: INFO: update-demo-nautilus-2444j is created but not running
Nov 14 21:53:14.415: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1392'
Nov 14 21:53:14.536: INFO: stderr: ""
Nov 14 21:53:14.536: INFO: stdout: "update-demo-nautilus-2444j update-demo-nautilus-4ljlf "
Nov 14 21:53:14.536: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 get pods update-demo-nautilus-2444j -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1392'
Nov 14 21:53:14.716: INFO: stderr: ""
Nov 14 21:53:14.716: INFO: stdout: "true"
Nov 14 21:53:14.716: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 get pods update-demo-nautilus-2444j -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1392'
Nov 14 21:53:14.921: INFO: stderr: ""
Nov 14 21:53:14.921: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov 14 21:53:14.921: INFO: validating pod update-demo-nautilus-2444j
Nov 14 21:53:14.959: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 14 21:53:14.959: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 14 21:53:14.959: INFO: update-demo-nautilus-2444j is verified up and running
Nov 14 21:53:14.959: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 get pods update-demo-nautilus-4ljlf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1392'
Nov 14 21:53:15.113: INFO: stderr: ""
Nov 14 21:53:15.113: INFO: stdout: "true"
Nov 14 21:53:15.113: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 get pods update-demo-nautilus-4ljlf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1392'
Nov 14 21:53:15.226: INFO: stderr: ""
Nov 14 21:53:15.226: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov 14 21:53:15.226: INFO: validating pod update-demo-nautilus-4ljlf
Nov 14 21:53:15.232: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 14 21:53:15.232: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 14 21:53:15.232: INFO: update-demo-nautilus-4ljlf is verified up and running
STEP: using delete to clean up resources
Nov 14 21:53:15.232: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 delete --grace-period=0 --force -f - --namespace=kubectl-1392'
Nov 14 21:53:15.384: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 14 21:53:15.384: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Nov 14 21:53:15.384: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-1392'
Nov 14 21:53:15.783: INFO: stderr: "No resources found.\n"
Nov 14 21:53:15.783: INFO: stdout: ""
Nov 14 21:53:15.783: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 get pods -l name=update-demo --namespace=kubectl-1392 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov 14 21:53:15.942: INFO: stderr: ""
Nov 14 21:53:15.942: INFO: stdout: "update-demo-nautilus-2444j\nupdate-demo-nautilus-4ljlf\n"
Nov 14 21:53:16.443: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-1392'
Nov 14 21:53:17.266: INFO: stderr: "No resources found.\n"
Nov 14 21:53:17.266: INFO: stdout: ""
Nov 14 21:53:17.266: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 get pods -l name=update-demo --namespace=kubectl-1392 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov 14 21:53:17.839: INFO: stderr: ""
Nov 14 21:53:17.839: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 21:53:17.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1392" for this suite.
Nov 14 21:53:44.473: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 21:53:44.622: INFO: namespace kubectl-1392 deletion completed in 26.502721253s

• [SLOW TEST:70.311 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 21:53:44.632: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-3471
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Nov 14 21:53:58.634: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 21:53:58.949: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-3471" for this suite.
Nov 14 21:54:05.290: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 21:54:05.413: INFO: namespace container-runtime-3471 deletion completed in 6.459054464s

• [SLOW TEST:20.781 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 21:54:05.416: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-2360
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Nov 14 21:54:06.034: INFO: Pod name pod-release: Found 0 pods out of 1
Nov 14 21:54:11.114: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 21:54:12.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-2360" for this suite.
Nov 14 21:54:26.461: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 21:54:26.927: INFO: namespace replication-controller-2360 deletion completed in 14.63108051s

• [SLOW TEST:21.512 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 21:54:26.936: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-4606
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Nov 14 21:54:27.450: INFO: Creating ReplicaSet my-hostname-basic-23d75c04-6763-47e1-b931-dd231ddcd68f
Nov 14 21:54:27.692: INFO: Pod name my-hostname-basic-23d75c04-6763-47e1-b931-dd231ddcd68f: Found 0 pods out of 1
Nov 14 21:54:32.697: INFO: Pod name my-hostname-basic-23d75c04-6763-47e1-b931-dd231ddcd68f: Found 1 pods out of 1
Nov 14 21:54:32.697: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-23d75c04-6763-47e1-b931-dd231ddcd68f" is running
Nov 14 21:54:42.705: INFO: Pod "my-hostname-basic-23d75c04-6763-47e1-b931-dd231ddcd68f-66f4l" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-11-14 21:54:28 +0000 UTC Reason: Message:} {Type:Ready Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-11-14 21:54:28 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-23d75c04-6763-47e1-b931-dd231ddcd68f]} {Type:ContainersReady Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-11-14 21:54:28 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-23d75c04-6763-47e1-b931-dd231ddcd68f]} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-11-14 21:54:27 +0000 UTC Reason: Message:}])
Nov 14 21:54:42.705: INFO: Trying to dial the pod
Nov 14 21:54:47.715: INFO: Controller my-hostname-basic-23d75c04-6763-47e1-b931-dd231ddcd68f: Got expected result from replica 1 [my-hostname-basic-23d75c04-6763-47e1-b931-dd231ddcd68f-66f4l]: "my-hostname-basic-23d75c04-6763-47e1-b931-dd231ddcd68f-66f4l", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 21:54:47.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-4606" for this suite.
Nov 14 21:54:55.756: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 21:54:55.905: INFO: namespace replicaset-4606 deletion completed in 8.184823308s

• [SLOW TEST:28.970 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 21:54:55.917: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2274
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir volume type on tmpfs
Nov 14 21:54:56.626: INFO: Waiting up to 5m0s for pod "pod-814248ca-6f9b-4df9-80b7-79fe57e650d7" in namespace "emptydir-2274" to be "success or failure"
Nov 14 21:54:56.717: INFO: Pod "pod-814248ca-6f9b-4df9-80b7-79fe57e650d7": Phase="Pending", Reason="", readiness=false. Elapsed: 90.135203ms
Nov 14 21:54:59.282: INFO: Pod "pod-814248ca-6f9b-4df9-80b7-79fe57e650d7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.654437626s
Nov 14 21:55:01.285: INFO: Pod "pod-814248ca-6f9b-4df9-80b7-79fe57e650d7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.658220383s
Nov 14 21:55:03.290: INFO: Pod "pod-814248ca-6f9b-4df9-80b7-79fe57e650d7": Phase="Pending", Reason="", readiness=false. Elapsed: 6.662391964s
Nov 14 21:55:05.293: INFO: Pod "pod-814248ca-6f9b-4df9-80b7-79fe57e650d7": Phase="Pending", Reason="", readiness=false. Elapsed: 8.666050562s
Nov 14 21:55:07.296: INFO: Pod "pod-814248ca-6f9b-4df9-80b7-79fe57e650d7": Phase="Pending", Reason="", readiness=false. Elapsed: 10.669100818s
Nov 14 21:55:09.329: INFO: Pod "pod-814248ca-6f9b-4df9-80b7-79fe57e650d7": Phase="Pending", Reason="", readiness=false. Elapsed: 12.702295888s
Nov 14 21:55:11.335: INFO: Pod "pod-814248ca-6f9b-4df9-80b7-79fe57e650d7": Phase="Pending", Reason="", readiness=false. Elapsed: 14.70751433s
Nov 14 21:55:13.608: INFO: Pod "pod-814248ca-6f9b-4df9-80b7-79fe57e650d7": Phase="Pending", Reason="", readiness=false. Elapsed: 16.981238303s
Nov 14 21:55:15.989: INFO: Pod "pod-814248ca-6f9b-4df9-80b7-79fe57e650d7": Phase="Pending", Reason="", readiness=false. Elapsed: 19.362248162s
Nov 14 21:55:17.993: INFO: Pod "pod-814248ca-6f9b-4df9-80b7-79fe57e650d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 21.365900999s
STEP: Saw pod success
Nov 14 21:55:17.993: INFO: Pod "pod-814248ca-6f9b-4df9-80b7-79fe57e650d7" satisfied condition "success or failure"
Nov 14 21:55:17.997: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-1 pod pod-814248ca-6f9b-4df9-80b7-79fe57e650d7 container test-container: <nil>
STEP: delete the pod
Nov 14 21:55:20.045: INFO: Waiting for pod pod-814248ca-6f9b-4df9-80b7-79fe57e650d7 to disappear
Nov 14 21:55:23.069: INFO: Pod pod-814248ca-6f9b-4df9-80b7-79fe57e650d7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 21:55:23.069: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2274" for this suite.
Nov 14 21:55:40.449: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 21:55:40.660: INFO: namespace emptydir-2274 deletion completed in 17.306879891s

• [SLOW TEST:44.743 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 21:55:40.673: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-502
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Nov 14 21:55:41.112: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 version'
Nov 14 21:55:41.399: INFO: stderr: ""
Nov 14 21:55:41.399: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.5\", GitCommit:\"20c265fef0741dd71a66480e35bd69f18351daea\", GitTreeState:\"clean\", BuildDate:\"2019-10-15T19:16:51Z\", GoVersion:\"go1.12.10\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.5\", GitCommit:\"20c265fef0741dd71a66480e35bd69f18351daea\", GitTreeState:\"clean\", BuildDate:\"2019-10-15T19:07:57Z\", GoVersion:\"go1.12.10\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 21:55:41.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-502" for this suite.
Nov 14 21:55:47.804: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 21:55:51.280: INFO: namespace kubectl-502 deletion completed in 9.852449106s

• [SLOW TEST:10.609 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl version
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 21:55:51.287: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-7450
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Nov 14 21:55:53.346: INFO: Create a RollingUpdate DaemonSet
Nov 14 21:55:53.417: INFO: Check that daemon pods launch on every node of the cluster
Nov 14 21:55:53.650: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 21:55:53.655: INFO: Number of nodes with available pods: 0
Nov 14 21:55:53.655: INFO: Node k8s-1-tdyr52fdsot3-minion-0 is running more than one daemon pod
Nov 14 21:55:55.199: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 21:55:56.762: INFO: Number of nodes with available pods: 0
Nov 14 21:55:56.762: INFO: Node k8s-1-tdyr52fdsot3-minion-0 is running more than one daemon pod
Nov 14 21:55:57.802: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 21:55:58.209: INFO: Number of nodes with available pods: 0
Nov 14 21:55:58.210: INFO: Node k8s-1-tdyr52fdsot3-minion-0 is running more than one daemon pod
Nov 14 21:55:58.659: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 21:55:58.663: INFO: Number of nodes with available pods: 0
Nov 14 21:55:58.663: INFO: Node k8s-1-tdyr52fdsot3-minion-0 is running more than one daemon pod
Nov 14 21:56:01.450: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 21:56:02.085: INFO: Number of nodes with available pods: 0
Nov 14 21:56:02.085: INFO: Node k8s-1-tdyr52fdsot3-minion-0 is running more than one daemon pod
Nov 14 21:56:05.312: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 21:56:06.891: INFO: Number of nodes with available pods: 1
Nov 14 21:56:06.891: INFO: Node k8s-1-tdyr52fdsot3-minion-0 is running more than one daemon pod
Nov 14 21:56:07.660: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 21:56:07.663: INFO: Number of nodes with available pods: 2
Nov 14 21:56:07.663: INFO: Number of running nodes: 2, number of available pods: 2
Nov 14 21:56:07.663: INFO: Update the DaemonSet to trigger a rollout
Nov 14 21:56:07.675: INFO: Updating DaemonSet daemon-set
Nov 14 21:56:22.918: INFO: Roll back the DaemonSet before rollout is complete
Nov 14 21:56:22.925: INFO: Updating DaemonSet daemon-set
Nov 14 21:56:22.925: INFO: Make sure DaemonSet rollback is complete
Nov 14 21:56:23.065: INFO: Wrong image for pod: daemon-set-nrgc9. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Nov 14 21:56:23.066: INFO: Pod daemon-set-nrgc9 is not available
Nov 14 21:56:23.081: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 21:56:24.086: INFO: Wrong image for pod: daemon-set-nrgc9. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Nov 14 21:56:24.086: INFO: Pod daemon-set-nrgc9 is not available
Nov 14 21:56:24.111: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 21:56:25.089: INFO: Wrong image for pod: daemon-set-nrgc9. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Nov 14 21:56:25.089: INFO: Pod daemon-set-nrgc9 is not available
Nov 14 21:56:25.093: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 21:56:26.091: INFO: Wrong image for pod: daemon-set-nrgc9. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Nov 14 21:56:26.091: INFO: Pod daemon-set-nrgc9 is not available
Nov 14 21:56:26.094: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 21:56:27.088: INFO: Wrong image for pod: daemon-set-nrgc9. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Nov 14 21:56:27.088: INFO: Pod daemon-set-nrgc9 is not available
Nov 14 21:56:27.092: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 21:56:28.089: INFO: Pod daemon-set-vrdzf is not available
Nov 14 21:56:28.095: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7450, will wait for the garbage collector to delete the pods
Nov 14 21:56:28.288: INFO: Deleting DaemonSet.extensions daemon-set took: 11.343575ms
Nov 14 21:56:28.989: INFO: Terminating DaemonSet.extensions daemon-set pods took: 701.08569ms
Nov 14 21:56:44.067: INFO: Number of nodes with available pods: 0
Nov 14 21:56:44.067: INFO: Number of running nodes: 0, number of available pods: 0
Nov 14 21:56:44.076: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7450/daemonsets","resourceVersion":"7806"},"items":null}

Nov 14 21:56:44.079: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7450/pods","resourceVersion":"7806"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 21:56:44.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7450" for this suite.
Nov 14 21:56:52.138: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 21:56:52.320: INFO: namespace daemonsets-7450 deletion completed in 8.224661484s

• [SLOW TEST:61.034 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 21:56:52.323: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-2418
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Nov 14 21:56:53.400: INFO: (0) /api/v1/nodes/k8s-1-tdyr52fdsot3-minion-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 136.346091ms)
Nov 14 21:56:53.542: INFO: (1) /api/v1/nodes/k8s-1-tdyr52fdsot3-minion-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 141.725651ms)
Nov 14 21:56:53.552: INFO: (2) /api/v1/nodes/k8s-1-tdyr52fdsot3-minion-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 8.581922ms)
Nov 14 21:56:53.559: INFO: (3) /api/v1/nodes/k8s-1-tdyr52fdsot3-minion-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 6.664464ms)
Nov 14 21:56:53.566: INFO: (4) /api/v1/nodes/k8s-1-tdyr52fdsot3-minion-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 6.261736ms)
Nov 14 21:56:53.575: INFO: (5) /api/v1/nodes/k8s-1-tdyr52fdsot3-minion-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 7.922296ms)
Nov 14 21:56:53.581: INFO: (6) /api/v1/nodes/k8s-1-tdyr52fdsot3-minion-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 5.568753ms)
Nov 14 21:56:53.588: INFO: (7) /api/v1/nodes/k8s-1-tdyr52fdsot3-minion-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 6.153676ms)
Nov 14 21:56:53.593: INFO: (8) /api/v1/nodes/k8s-1-tdyr52fdsot3-minion-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 5.310529ms)
Nov 14 21:56:53.600: INFO: (9) /api/v1/nodes/k8s-1-tdyr52fdsot3-minion-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 5.734777ms)
Nov 14 21:56:53.614: INFO: (10) /api/v1/nodes/k8s-1-tdyr52fdsot3-minion-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 14.40558ms)
Nov 14 21:56:53.620: INFO: (11) /api/v1/nodes/k8s-1-tdyr52fdsot3-minion-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 5.430566ms)
Nov 14 21:56:53.626: INFO: (12) /api/v1/nodes/k8s-1-tdyr52fdsot3-minion-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 5.115455ms)
Nov 14 21:56:53.632: INFO: (13) /api/v1/nodes/k8s-1-tdyr52fdsot3-minion-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 6.009231ms)
Nov 14 21:56:53.642: INFO: (14) /api/v1/nodes/k8s-1-tdyr52fdsot3-minion-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 8.794038ms)
Nov 14 21:56:53.646: INFO: (15) /api/v1/nodes/k8s-1-tdyr52fdsot3-minion-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 4.090535ms)
Nov 14 21:56:53.652: INFO: (16) /api/v1/nodes/k8s-1-tdyr52fdsot3-minion-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 5.083302ms)
Nov 14 21:56:53.657: INFO: (17) /api/v1/nodes/k8s-1-tdyr52fdsot3-minion-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 5.068698ms)
Nov 14 21:56:53.663: INFO: (18) /api/v1/nodes/k8s-1-tdyr52fdsot3-minion-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 5.601441ms)
Nov 14 21:56:53.670: INFO: (19) /api/v1/nodes/k8s-1-tdyr52fdsot3-minion-0/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 5.817485ms)
[AfterEach] version v1
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 21:56:53.671: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-2418" for this suite.
Nov 14 21:56:59.723: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 21:56:59.922: INFO: namespace proxy-2418 deletion completed in 6.245733889s

• [SLOW TEST:7.599 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 21:56:59.926: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5186
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-projected-all-test-volume-33ea3346-b8f2-47a3-a4e9-6ceaa6392bb5
STEP: Creating secret with name secret-projected-all-test-volume-ebff59df-9af7-4d38-9d26-21d13162c1ea
STEP: Creating a pod to test Check all projections for projected volume plugin
Nov 14 21:57:00.820: INFO: Waiting up to 5m0s for pod "projected-volume-c05ca2b4-c03a-4d2d-b606-727391b1ab08" in namespace "projected-5186" to be "success or failure"
Nov 14 21:57:00.828: INFO: Pod "projected-volume-c05ca2b4-c03a-4d2d-b606-727391b1ab08": Phase="Pending", Reason="", readiness=false. Elapsed: 8.033368ms
Nov 14 21:57:02.897: INFO: Pod "projected-volume-c05ca2b4-c03a-4d2d-b606-727391b1ab08": Phase="Pending", Reason="", readiness=false. Elapsed: 2.07664608s
Nov 14 21:57:05.071: INFO: Pod "projected-volume-c05ca2b4-c03a-4d2d-b606-727391b1ab08": Phase="Pending", Reason="", readiness=false. Elapsed: 4.250266459s
Nov 14 21:57:07.074: INFO: Pod "projected-volume-c05ca2b4-c03a-4d2d-b606-727391b1ab08": Phase="Pending", Reason="", readiness=false. Elapsed: 6.253426018s
Nov 14 21:57:09.079: INFO: Pod "projected-volume-c05ca2b4-c03a-4d2d-b606-727391b1ab08": Phase="Pending", Reason="", readiness=false. Elapsed: 8.25848886s
Nov 14 21:57:11.084: INFO: Pod "projected-volume-c05ca2b4-c03a-4d2d-b606-727391b1ab08": Phase="Pending", Reason="", readiness=false. Elapsed: 10.263539798s
Nov 14 21:57:13.090: INFO: Pod "projected-volume-c05ca2b4-c03a-4d2d-b606-727391b1ab08": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.270014553s
STEP: Saw pod success
Nov 14 21:57:13.093: INFO: Pod "projected-volume-c05ca2b4-c03a-4d2d-b606-727391b1ab08" satisfied condition "success or failure"
Nov 14 21:57:13.100: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-0 pod projected-volume-c05ca2b4-c03a-4d2d-b606-727391b1ab08 container projected-all-volume-test: <nil>
STEP: delete the pod
Nov 14 21:57:14.038: INFO: Waiting for pod projected-volume-c05ca2b4-c03a-4d2d-b606-727391b1ab08 to disappear
Nov 14 21:57:14.071: INFO: Pod projected-volume-c05ca2b4-c03a-4d2d-b606-727391b1ab08 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 21:57:14.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5186" for this suite.
Nov 14 21:57:20.125: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 21:57:20.309: INFO: namespace projected-5186 deletion completed in 6.232275845s

• [SLOW TEST:20.384 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 21:57:20.323: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8819
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Nov 14 21:57:20.923: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a7f4e5b0-ba29-4601-831d-bbd014c8dabe" in namespace "projected-8819" to be "success or failure"
Nov 14 21:57:20.987: INFO: Pod "downwardapi-volume-a7f4e5b0-ba29-4601-831d-bbd014c8dabe": Phase="Pending", Reason="", readiness=false. Elapsed: 63.263206ms
Nov 14 21:57:22.990: INFO: Pod "downwardapi-volume-a7f4e5b0-ba29-4601-831d-bbd014c8dabe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.066740789s
Nov 14 21:57:25.214: INFO: Pod "downwardapi-volume-a7f4e5b0-ba29-4601-831d-bbd014c8dabe": Phase="Pending", Reason="", readiness=false. Elapsed: 4.290611187s
Nov 14 21:57:27.219: INFO: Pod "downwardapi-volume-a7f4e5b0-ba29-4601-831d-bbd014c8dabe": Phase="Pending", Reason="", readiness=false. Elapsed: 6.296063417s
Nov 14 21:57:29.223: INFO: Pod "downwardapi-volume-a7f4e5b0-ba29-4601-831d-bbd014c8dabe": Phase="Pending", Reason="", readiness=false. Elapsed: 8.299896243s
Nov 14 21:57:31.232: INFO: Pod "downwardapi-volume-a7f4e5b0-ba29-4601-831d-bbd014c8dabe": Phase="Pending", Reason="", readiness=false. Elapsed: 10.308344363s
Nov 14 21:57:33.236: INFO: Pod "downwardapi-volume-a7f4e5b0-ba29-4601-831d-bbd014c8dabe": Phase="Pending", Reason="", readiness=false. Elapsed: 12.312793424s
Nov 14 21:57:35.418: INFO: Pod "downwardapi-volume-a7f4e5b0-ba29-4601-831d-bbd014c8dabe": Phase="Pending", Reason="", readiness=false. Elapsed: 14.494078503s
Nov 14 21:57:37.421: INFO: Pod "downwardapi-volume-a7f4e5b0-ba29-4601-831d-bbd014c8dabe": Phase="Pending", Reason="", readiness=false. Elapsed: 16.497642514s
Nov 14 21:57:39.430: INFO: Pod "downwardapi-volume-a7f4e5b0-ba29-4601-831d-bbd014c8dabe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 18.506933654s
STEP: Saw pod success
Nov 14 21:57:39.431: INFO: Pod "downwardapi-volume-a7f4e5b0-ba29-4601-831d-bbd014c8dabe" satisfied condition "success or failure"
Nov 14 21:57:39.434: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-0 pod downwardapi-volume-a7f4e5b0-ba29-4601-831d-bbd014c8dabe container client-container: <nil>
STEP: delete the pod
Nov 14 21:57:39.528: INFO: Waiting for pod downwardapi-volume-a7f4e5b0-ba29-4601-831d-bbd014c8dabe to disappear
Nov 14 21:57:39.615: INFO: Pod downwardapi-volume-a7f4e5b0-ba29-4601-831d-bbd014c8dabe no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 21:57:39.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8819" for this suite.
Nov 14 21:57:47.653: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 21:57:48.142: INFO: namespace projected-8819 deletion completed in 8.522545709s

• [SLOW TEST:27.819 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 21:57:48.149: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-3262
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-3448
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-3550
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 21:58:27.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-3262" for this suite.
Nov 14 21:58:35.802: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 21:58:36.158: INFO: namespace namespaces-3262 deletion completed in 8.404679742s
STEP: Destroying namespace "nsdeletetest-3448" for this suite.
Nov 14 21:58:36.162: INFO: Namespace nsdeletetest-3448 was already deleted
STEP: Destroying namespace "nsdeletetest-3550" for this suite.
Nov 14 21:58:44.400: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 21:58:46.153: INFO: namespace nsdeletetest-3550 deletion completed in 9.989735726s

• [SLOW TEST:58.005 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 21:58:46.159: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3440
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-87b49911-66b3-4c69-849c-5d8a0fd4f2d5
STEP: Creating a pod to test consume configMaps
Nov 14 21:58:49.927: INFO: Waiting up to 5m0s for pod "pod-configmaps-cc03b758-8d21-4d26-9181-362c261b6d1c" in namespace "configmap-3440" to be "success or failure"
Nov 14 21:58:50.010: INFO: Pod "pod-configmaps-cc03b758-8d21-4d26-9181-362c261b6d1c": Phase="Pending", Reason="", readiness=false. Elapsed: 82.669117ms
Nov 14 21:58:52.078: INFO: Pod "pod-configmaps-cc03b758-8d21-4d26-9181-362c261b6d1c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.150035199s
Nov 14 21:58:54.140: INFO: Pod "pod-configmaps-cc03b758-8d21-4d26-9181-362c261b6d1c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.212449969s
Nov 14 21:58:56.151: INFO: Pod "pod-configmaps-cc03b758-8d21-4d26-9181-362c261b6d1c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.223413896s
STEP: Saw pod success
Nov 14 21:58:56.151: INFO: Pod "pod-configmaps-cc03b758-8d21-4d26-9181-362c261b6d1c" satisfied condition "success or failure"
Nov 14 21:58:56.154: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-1 pod pod-configmaps-cc03b758-8d21-4d26-9181-362c261b6d1c container configmap-volume-test: <nil>
STEP: delete the pod
Nov 14 21:58:56.375: INFO: Waiting for pod pod-configmaps-cc03b758-8d21-4d26-9181-362c261b6d1c to disappear
Nov 14 21:58:56.431: INFO: Pod pod-configmaps-cc03b758-8d21-4d26-9181-362c261b6d1c no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 21:58:56.431: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3440" for this suite.
Nov 14 21:59:04.621: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 21:59:04.787: INFO: namespace configmap-3440 deletion completed in 8.350950429s

• [SLOW TEST:18.629 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 21:59:04.798: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7928
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap configmap-7928/configmap-test-78d772a7-c540-428d-8df5-1b7bb6790d66
STEP: Creating a pod to test consume configMaps
Nov 14 21:59:05.450: INFO: Waiting up to 5m0s for pod "pod-configmaps-09ac2ccb-3476-4706-8497-fc9b881f0a7c" in namespace "configmap-7928" to be "success or failure"
Nov 14 21:59:05.528: INFO: Pod "pod-configmaps-09ac2ccb-3476-4706-8497-fc9b881f0a7c": Phase="Pending", Reason="", readiness=false. Elapsed: 76.987576ms
Nov 14 21:59:07.726: INFO: Pod "pod-configmaps-09ac2ccb-3476-4706-8497-fc9b881f0a7c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.275851393s
Nov 14 21:59:09.989: INFO: Pod "pod-configmaps-09ac2ccb-3476-4706-8497-fc9b881f0a7c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.538810852s
Nov 14 21:59:11.996: INFO: Pod "pod-configmaps-09ac2ccb-3476-4706-8497-fc9b881f0a7c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.545131137s
STEP: Saw pod success
Nov 14 21:59:11.996: INFO: Pod "pod-configmaps-09ac2ccb-3476-4706-8497-fc9b881f0a7c" satisfied condition "success or failure"
Nov 14 21:59:12.000: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-0 pod pod-configmaps-09ac2ccb-3476-4706-8497-fc9b881f0a7c container env-test: <nil>
STEP: delete the pod
Nov 14 21:59:12.135: INFO: Waiting for pod pod-configmaps-09ac2ccb-3476-4706-8497-fc9b881f0a7c to disappear
Nov 14 21:59:12.197: INFO: Pod pod-configmaps-09ac2ccb-3476-4706-8497-fc9b881f0a7c no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 21:59:12.197: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7928" for this suite.
Nov 14 21:59:18.325: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 21:59:18.479: INFO: namespace configmap-7928 deletion completed in 6.275245187s

• [SLOW TEST:13.682 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 21:59:18.487: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9396
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir volume type on node default medium
Nov 14 21:59:19.096: INFO: Waiting up to 5m0s for pod "pod-1cd890bf-a30a-4b7a-8e00-7eb87a319425" in namespace "emptydir-9396" to be "success or failure"
Nov 14 21:59:19.177: INFO: Pod "pod-1cd890bf-a30a-4b7a-8e00-7eb87a319425": Phase="Pending", Reason="", readiness=false. Elapsed: 80.489056ms
Nov 14 21:59:21.209: INFO: Pod "pod-1cd890bf-a30a-4b7a-8e00-7eb87a319425": Phase="Pending", Reason="", readiness=false. Elapsed: 2.112618932s
Nov 14 21:59:23.214: INFO: Pod "pod-1cd890bf-a30a-4b7a-8e00-7eb87a319425": Phase="Pending", Reason="", readiness=false. Elapsed: 4.118260908s
Nov 14 21:59:25.256: INFO: Pod "pod-1cd890bf-a30a-4b7a-8e00-7eb87a319425": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.159436348s
STEP: Saw pod success
Nov 14 21:59:25.256: INFO: Pod "pod-1cd890bf-a30a-4b7a-8e00-7eb87a319425" satisfied condition "success or failure"
Nov 14 21:59:25.450: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-1 pod pod-1cd890bf-a30a-4b7a-8e00-7eb87a319425 container test-container: <nil>
STEP: delete the pod
Nov 14 21:59:25.513: INFO: Waiting for pod pod-1cd890bf-a30a-4b7a-8e00-7eb87a319425 to disappear
Nov 14 21:59:25.540: INFO: Pod pod-1cd890bf-a30a-4b7a-8e00-7eb87a319425 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 21:59:25.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9396" for this suite.
Nov 14 21:59:31.703: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 21:59:31.877: INFO: namespace emptydir-9396 deletion completed in 6.331331187s

• [SLOW TEST:13.390 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 21:59:31.883: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5006
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Nov 14 21:59:32.559: INFO: Waiting up to 5m0s for pod "downward-api-f453ad40-9068-4cec-8a08-d2635535a8ec" in namespace "downward-api-5006" to be "success or failure"
Nov 14 21:59:32.583: INFO: Pod "downward-api-f453ad40-9068-4cec-8a08-d2635535a8ec": Phase="Pending", Reason="", readiness=false. Elapsed: 24.282466ms
Nov 14 21:59:34.622: INFO: Pod "downward-api-f453ad40-9068-4cec-8a08-d2635535a8ec": Phase="Pending", Reason="", readiness=false. Elapsed: 2.063472829s
Nov 14 21:59:37.667: INFO: Pod "downward-api-f453ad40-9068-4cec-8a08-d2635535a8ec": Phase="Succeeded", Reason="", readiness=false. Elapsed: 5.107871279s
STEP: Saw pod success
Nov 14 21:59:37.667: INFO: Pod "downward-api-f453ad40-9068-4cec-8a08-d2635535a8ec" satisfied condition "success or failure"
Nov 14 21:59:38.030: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-1 pod downward-api-f453ad40-9068-4cec-8a08-d2635535a8ec container dapi-container: <nil>
STEP: delete the pod
Nov 14 21:59:38.294: INFO: Waiting for pod downward-api-f453ad40-9068-4cec-8a08-d2635535a8ec to disappear
Nov 14 21:59:39.203: INFO: Pod downward-api-f453ad40-9068-4cec-8a08-d2635535a8ec no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 21:59:39.205: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5006" for this suite.
Nov 14 21:59:46.815: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 21:59:46.963: INFO: namespace downward-api-5006 deletion completed in 7.436831348s

• [SLOW TEST:15.081 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 21:59:46.971: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9016
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Nov 14 21:59:48.460: INFO: Waiting up to 5m0s for pod "downwardapi-volume-06576c90-4251-4a79-97b3-741094f7f9a3" in namespace "projected-9016" to be "success or failure"
Nov 14 21:59:48.800: INFO: Pod "downwardapi-volume-06576c90-4251-4a79-97b3-741094f7f9a3": Phase="Pending", Reason="", readiness=false. Elapsed: 340.093486ms
Nov 14 21:59:51.486: INFO: Pod "downwardapi-volume-06576c90-4251-4a79-97b3-741094f7f9a3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.025368334s
Nov 14 21:59:53.841: INFO: Pod "downwardapi-volume-06576c90-4251-4a79-97b3-741094f7f9a3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.38097131s
Nov 14 21:59:55.848: INFO: Pod "downwardapi-volume-06576c90-4251-4a79-97b3-741094f7f9a3": Phase="Pending", Reason="", readiness=false. Elapsed: 7.387935397s
Nov 14 21:59:57.938: INFO: Pod "downwardapi-volume-06576c90-4251-4a79-97b3-741094f7f9a3": Phase="Pending", Reason="", readiness=false. Elapsed: 9.477558447s
Nov 14 21:59:59.944: INFO: Pod "downwardapi-volume-06576c90-4251-4a79-97b3-741094f7f9a3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 11.483802595s
STEP: Saw pod success
Nov 14 21:59:59.944: INFO: Pod "downwardapi-volume-06576c90-4251-4a79-97b3-741094f7f9a3" satisfied condition "success or failure"
Nov 14 21:59:59.951: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-1 pod downwardapi-volume-06576c90-4251-4a79-97b3-741094f7f9a3 container client-container: <nil>
STEP: delete the pod
Nov 14 22:00:00.150: INFO: Waiting for pod downwardapi-volume-06576c90-4251-4a79-97b3-741094f7f9a3 to disappear
Nov 14 22:00:00.281: INFO: Pod downwardapi-volume-06576c90-4251-4a79-97b3-741094f7f9a3 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:00:00.282: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9016" for this suite.
Nov 14 22:00:08.333: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:00:08.475: INFO: namespace projected-9016 deletion completed in 8.18607593s

• [SLOW TEST:21.505 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:00:08.479: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7923
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Nov 14 22:00:08.989: INFO: Waiting up to 5m0s for pod "downwardapi-volume-08653b8d-02e2-4b08-bb04-ffe183a142c0" in namespace "projected-7923" to be "success or failure"
Nov 14 22:00:09.011: INFO: Pod "downwardapi-volume-08653b8d-02e2-4b08-bb04-ffe183a142c0": Phase="Pending", Reason="", readiness=false. Elapsed: 21.986465ms
Nov 14 22:00:11.016: INFO: Pod "downwardapi-volume-08653b8d-02e2-4b08-bb04-ffe183a142c0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026997483s
Nov 14 22:00:13.088: INFO: Pod "downwardapi-volume-08653b8d-02e2-4b08-bb04-ffe183a142c0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.098113207s
Nov 14 22:00:15.097: INFO: Pod "downwardapi-volume-08653b8d-02e2-4b08-bb04-ffe183a142c0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.107314015s
STEP: Saw pod success
Nov 14 22:00:15.097: INFO: Pod "downwardapi-volume-08653b8d-02e2-4b08-bb04-ffe183a142c0" satisfied condition "success or failure"
Nov 14 22:00:15.230: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-1 pod downwardapi-volume-08653b8d-02e2-4b08-bb04-ffe183a142c0 container client-container: <nil>
STEP: delete the pod
Nov 14 22:00:15.299: INFO: Waiting for pod downwardapi-volume-08653b8d-02e2-4b08-bb04-ffe183a142c0 to disappear
Nov 14 22:00:15.323: INFO: Pod downwardapi-volume-08653b8d-02e2-4b08-bb04-ffe183a142c0 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:00:15.323: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7923" for this suite.
Nov 14 22:00:21.499: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:00:23.136: INFO: namespace projected-7923 deletion completed in 7.80805918s

• [SLOW TEST:14.658 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:00:23.139: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-4636
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:00:36.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-4636" for this suite.
Nov 14 22:00:45.232: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:00:45.824: INFO: namespace watch-4636 deletion completed in 8.969931549s

• [SLOW TEST:22.686 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:00:45.825: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-1594
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Nov 14 22:00:53.829: INFO: Successfully updated pod "pod-update-9093152e-cf07-41dc-b082-aaf501d26f64"
STEP: verifying the updated pod is in kubernetes
Nov 14 22:00:54.060: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:00:54.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1594" for this suite.
Nov 14 22:01:18.217: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:01:18.488: INFO: namespace pods-1594 deletion completed in 24.423143726s

• [SLOW TEST:32.664 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:01:18.495: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-7355
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-vcj7z in namespace proxy-7355
I1114 22:01:19.416029      13 runners.go:180] Created replication controller with name: proxy-service-vcj7z, namespace: proxy-7355, replica count: 1
I1114 22:01:20.467039      13 runners.go:180] proxy-service-vcj7z Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1114 22:01:21.467844      13 runners.go:180] proxy-service-vcj7z Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1114 22:01:22.468423      13 runners.go:180] proxy-service-vcj7z Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1114 22:01:23.469200      13 runners.go:180] proxy-service-vcj7z Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1114 22:01:24.469794      13 runners.go:180] proxy-service-vcj7z Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1114 22:01:25.470849      13 runners.go:180] proxy-service-vcj7z Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1114 22:01:26.471945      13 runners.go:180] proxy-service-vcj7z Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1114 22:01:27.472809      13 runners.go:180] proxy-service-vcj7z Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1114 22:01:28.473713      13 runners.go:180] proxy-service-vcj7z Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1114 22:01:29.474800      13 runners.go:180] proxy-service-vcj7z Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1114 22:01:30.475882      13 runners.go:180] proxy-service-vcj7z Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1114 22:01:31.476377      13 runners.go:180] proxy-service-vcj7z Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1114 22:01:32.478029      13 runners.go:180] proxy-service-vcj7z Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1114 22:01:33.508422      13 runners.go:180] proxy-service-vcj7z Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1114 22:01:34.509140      13 runners.go:180] proxy-service-vcj7z Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1114 22:01:35.509437      13 runners.go:180] proxy-service-vcj7z Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1114 22:01:36.509798      13 runners.go:180] proxy-service-vcj7z Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1114 22:01:37.510174      13 runners.go:180] proxy-service-vcj7z Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1114 22:01:38.510442      13 runners.go:180] proxy-service-vcj7z Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1114 22:01:39.510735      13 runners.go:180] proxy-service-vcj7z Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1114 22:01:40.511082      13 runners.go:180] proxy-service-vcj7z Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1114 22:01:41.511406      13 runners.go:180] proxy-service-vcj7z Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1114 22:01:42.511710      13 runners.go:180] proxy-service-vcj7z Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1114 22:01:43.512071      13 runners.go:180] proxy-service-vcj7z Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1114 22:01:44.512352      13 runners.go:180] proxy-service-vcj7z Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov 14 22:01:44.569: INFO: setup took 25.607441586s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Nov 14 22:01:44.626: INFO: (0) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4/proxy/rewriteme">test</a> (200; 56.342679ms)
Nov 14 22:01:44.626: INFO: (0) /api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:160/proxy/: foo (200; 52.01539ms)
Nov 14 22:01:44.626: INFO: (0) /api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:162/proxy/: bar (200; 51.533389ms)
Nov 14 22:01:44.630: INFO: (0) /api/v1/namespaces/proxy-7355/services/http:proxy-service-vcj7z:portname2/proxy/: bar (200; 60.356439ms)
Nov 14 22:01:44.649: INFO: (0) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:160/proxy/: foo (200; 64.404909ms)
Nov 14 22:01:44.650: INFO: (0) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:162/proxy/: bar (200; 65.032913ms)
Nov 14 22:01:44.650: INFO: (0) /api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:1080/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:1080/proxy/rewriteme">... (200; 75.939018ms)
Nov 14 22:01:44.650: INFO: (0) /api/v1/namespaces/proxy-7355/services/proxy-service-vcj7z:portname2/proxy/: bar (200; 65.164927ms)
Nov 14 22:01:44.650: INFO: (0) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:1080/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:1080/proxy/rewriteme">test<... (200; 75.580925ms)
Nov 14 22:01:44.658: INFO: (0) /api/v1/namespaces/proxy-7355/services/proxy-service-vcj7z:portname1/proxy/: foo (200; 73.125338ms)
Nov 14 22:01:44.663: INFO: (0) /api/v1/namespaces/proxy-7355/services/http:proxy-service-vcj7z:portname1/proxy/: foo (200; 88.913709ms)
Nov 14 22:01:44.665: INFO: (0) /api/v1/namespaces/proxy-7355/services/https:proxy-service-vcj7z:tlsportname2/proxy/: tls qux (200; 90.031505ms)
Nov 14 22:01:44.665: INFO: (0) /api/v1/namespaces/proxy-7355/services/https:proxy-service-vcj7z:tlsportname1/proxy/: tls baz (200; 92.307938ms)
Nov 14 22:01:44.665: INFO: (0) /api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:443/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:443/proxy/tlsrewritem... (200; 95.578905ms)
Nov 14 22:01:44.665: INFO: (0) /api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:462/proxy/: tls qux (200; 91.065192ms)
Nov 14 22:01:44.665: INFO: (0) /api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:460/proxy/: tls baz (200; 95.780168ms)
Nov 14 22:01:44.735: INFO: (1) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:1080/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:1080/proxy/rewriteme">test<... (200; 68.052039ms)
Nov 14 22:01:44.735: INFO: (1) /api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:162/proxy/: bar (200; 70.038237ms)
Nov 14 22:01:44.736: INFO: (1) /api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:443/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:443/proxy/tlsrewritem... (200; 69.15665ms)
Nov 14 22:01:44.737: INFO: (1) /api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:462/proxy/: tls qux (200; 70.066841ms)
Nov 14 22:01:44.737: INFO: (1) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4/proxy/rewriteme">test</a> (200; 71.282797ms)
Nov 14 22:01:44.737: INFO: (1) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:160/proxy/: foo (200; 71.447127ms)
Nov 14 22:01:44.738: INFO: (1) /api/v1/namespaces/proxy-7355/services/proxy-service-vcj7z:portname1/proxy/: foo (200; 72.066761ms)
Nov 14 22:01:44.738: INFO: (1) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:162/proxy/: bar (200; 72.243209ms)
Nov 14 22:01:44.739: INFO: (1) /api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:460/proxy/: tls baz (200; 71.919679ms)
Nov 14 22:01:44.739: INFO: (1) /api/v1/namespaces/proxy-7355/services/https:proxy-service-vcj7z:tlsportname2/proxy/: tls qux (200; 72.165007ms)
Nov 14 22:01:44.740: INFO: (1) /api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:160/proxy/: foo (200; 73.091531ms)
Nov 14 22:01:44.740: INFO: (1) /api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:1080/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:1080/proxy/rewriteme">... (200; 72.41363ms)
Nov 14 22:01:44.741: INFO: (1) /api/v1/namespaces/proxy-7355/services/http:proxy-service-vcj7z:portname2/proxy/: bar (200; 74.349624ms)
Nov 14 22:01:44.741: INFO: (1) /api/v1/namespaces/proxy-7355/services/http:proxy-service-vcj7z:portname1/proxy/: foo (200; 74.281116ms)
Nov 14 22:01:44.741: INFO: (1) /api/v1/namespaces/proxy-7355/services/proxy-service-vcj7z:portname2/proxy/: bar (200; 75.542771ms)
Nov 14 22:01:44.742: INFO: (1) /api/v1/namespaces/proxy-7355/services/https:proxy-service-vcj7z:tlsportname1/proxy/: tls baz (200; 75.492965ms)
Nov 14 22:01:44.753: INFO: (2) /api/v1/namespaces/proxy-7355/services/proxy-service-vcj7z:portname1/proxy/: foo (200; 10.28498ms)
Nov 14 22:01:44.753: INFO: (2) /api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:160/proxy/: foo (200; 10.298693ms)
Nov 14 22:01:44.754: INFO: (2) /api/v1/namespaces/proxy-7355/services/https:proxy-service-vcj7z:tlsportname1/proxy/: tls baz (200; 11.152953ms)
Nov 14 22:01:44.754: INFO: (2) /api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:462/proxy/: tls qux (200; 10.443678ms)
Nov 14 22:01:44.755: INFO: (2) /api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:460/proxy/: tls baz (200; 11.345011ms)
Nov 14 22:01:44.755: INFO: (2) /api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:443/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:443/proxy/tlsrewritem... (200; 12.105767ms)
Nov 14 22:01:44.757: INFO: (2) /api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:1080/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:1080/proxy/rewriteme">... (200; 12.250516ms)
Nov 14 22:01:44.758: INFO: (2) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4/proxy/rewriteme">test</a> (200; 12.551712ms)
Nov 14 22:01:44.759: INFO: (2) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:160/proxy/: foo (200; 13.508093ms)
Nov 14 22:01:44.759: INFO: (2) /api/v1/namespaces/proxy-7355/services/http:proxy-service-vcj7z:portname2/proxy/: bar (200; 15.95673ms)
Nov 14 22:01:44.760: INFO: (2) /api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:162/proxy/: bar (200; 14.864544ms)
Nov 14 22:01:44.760: INFO: (2) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:1080/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:1080/proxy/rewriteme">test<... (200; 15.472984ms)
Nov 14 22:01:44.760: INFO: (2) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:162/proxy/: bar (200; 14.696628ms)
Nov 14 22:01:44.760: INFO: (2) /api/v1/namespaces/proxy-7355/services/https:proxy-service-vcj7z:tlsportname2/proxy/: tls qux (200; 16.23352ms)
Nov 14 22:01:44.760: INFO: (2) /api/v1/namespaces/proxy-7355/services/http:proxy-service-vcj7z:portname1/proxy/: foo (200; 15.197066ms)
Nov 14 22:01:44.760: INFO: (2) /api/v1/namespaces/proxy-7355/services/proxy-service-vcj7z:portname2/proxy/: bar (200; 15.183059ms)
Nov 14 22:01:44.770: INFO: (3) /api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:443/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:443/proxy/tlsrewritem... (200; 6.172164ms)
Nov 14 22:01:44.771: INFO: (3) /api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:1080/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:1080/proxy/rewriteme">... (200; 8.383997ms)
Nov 14 22:01:44.772: INFO: (3) /api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:460/proxy/: tls baz (200; 7.709607ms)
Nov 14 22:01:44.772: INFO: (3) /api/v1/namespaces/proxy-7355/services/http:proxy-service-vcj7z:portname2/proxy/: bar (200; 10.390609ms)
Nov 14 22:01:44.772: INFO: (3) /api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:462/proxy/: tls qux (200; 10.208897ms)
Nov 14 22:01:44.772: INFO: (3) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:1080/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:1080/proxy/rewriteme">test<... (200; 9.968009ms)
Nov 14 22:01:44.772: INFO: (3) /api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:160/proxy/: foo (200; 8.715719ms)
Nov 14 22:01:44.772: INFO: (3) /api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:162/proxy/: bar (200; 9.907828ms)
Nov 14 22:01:44.773: INFO: (3) /api/v1/namespaces/proxy-7355/services/proxy-service-vcj7z:portname1/proxy/: foo (200; 9.689495ms)
Nov 14 22:01:44.773: INFO: (3) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:162/proxy/: bar (200; 9.881302ms)
Nov 14 22:01:44.773: INFO: (3) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4/proxy/rewriteme">test</a> (200; 10.174361ms)
Nov 14 22:01:44.773: INFO: (3) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:160/proxy/: foo (200; 10.100234ms)
Nov 14 22:01:44.775: INFO: (3) /api/v1/namespaces/proxy-7355/services/https:proxy-service-vcj7z:tlsportname2/proxy/: tls qux (200; 13.49388ms)
Nov 14 22:01:44.776: INFO: (3) /api/v1/namespaces/proxy-7355/services/proxy-service-vcj7z:portname2/proxy/: bar (200; 13.204193ms)
Nov 14 22:01:44.776: INFO: (3) /api/v1/namespaces/proxy-7355/services/http:proxy-service-vcj7z:portname1/proxy/: foo (200; 13.539477ms)
Nov 14 22:01:44.776: INFO: (3) /api/v1/namespaces/proxy-7355/services/https:proxy-service-vcj7z:tlsportname1/proxy/: tls baz (200; 12.818888ms)
Nov 14 22:01:44.784: INFO: (4) /api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:443/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:443/proxy/tlsrewritem... (200; 6.776589ms)
Nov 14 22:01:44.785: INFO: (4) /api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:462/proxy/: tls qux (200; 7.906992ms)
Nov 14 22:01:44.790: INFO: (4) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:162/proxy/: bar (200; 12.60834ms)
Nov 14 22:01:44.791: INFO: (4) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4/proxy/rewriteme">test</a> (200; 13.046791ms)
Nov 14 22:01:44.792: INFO: (4) /api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:160/proxy/: foo (200; 12.489893ms)
Nov 14 22:01:44.792: INFO: (4) /api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:162/proxy/: bar (200; 14.632168ms)
Nov 14 22:01:44.792: INFO: (4) /api/v1/namespaces/proxy-7355/services/proxy-service-vcj7z:portname1/proxy/: foo (200; 14.030551ms)
Nov 14 22:01:44.792: INFO: (4) /api/v1/namespaces/proxy-7355/services/http:proxy-service-vcj7z:portname2/proxy/: bar (200; 13.554366ms)
Nov 14 22:01:44.793: INFO: (4) /api/v1/namespaces/proxy-7355/services/http:proxy-service-vcj7z:portname1/proxy/: foo (200; 15.237614ms)
Nov 14 22:01:44.793: INFO: (4) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:160/proxy/: foo (200; 14.145298ms)
Nov 14 22:01:44.793: INFO: (4) /api/v1/namespaces/proxy-7355/services/https:proxy-service-vcj7z:tlsportname2/proxy/: tls qux (200; 15.158964ms)
Nov 14 22:01:44.793: INFO: (4) /api/v1/namespaces/proxy-7355/services/https:proxy-service-vcj7z:tlsportname1/proxy/: tls baz (200; 13.732426ms)
Nov 14 22:01:44.793: INFO: (4) /api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:1080/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:1080/proxy/rewriteme">... (200; 14.982894ms)
Nov 14 22:01:44.793: INFO: (4) /api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:460/proxy/: tls baz (200; 14.128644ms)
Nov 14 22:01:44.793: INFO: (4) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:1080/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:1080/proxy/rewriteme">test<... (200; 15.139631ms)
Nov 14 22:01:44.793: INFO: (4) /api/v1/namespaces/proxy-7355/services/proxy-service-vcj7z:portname2/proxy/: bar (200; 14.637694ms)
Nov 14 22:01:44.798: INFO: (5) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:162/proxy/: bar (200; 3.647148ms)
Nov 14 22:01:44.801: INFO: (5) /api/v1/namespaces/proxy-7355/services/http:proxy-service-vcj7z:portname2/proxy/: bar (200; 6.014696ms)
Nov 14 22:01:44.802: INFO: (5) /api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:462/proxy/: tls qux (200; 6.12381ms)
Nov 14 22:01:44.802: INFO: (5) /api/v1/namespaces/proxy-7355/services/https:proxy-service-vcj7z:tlsportname2/proxy/: tls qux (200; 6.133417ms)
Nov 14 22:01:44.803: INFO: (5) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4/proxy/rewriteme">test</a> (200; 7.170131ms)
Nov 14 22:01:44.805: INFO: (5) /api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:1080/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:1080/proxy/rewriteme">... (200; 8.848938ms)
Nov 14 22:01:44.805: INFO: (5) /api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:162/proxy/: bar (200; 8.789178ms)
Nov 14 22:01:44.805: INFO: (5) /api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:160/proxy/: foo (200; 10.373436ms)
Nov 14 22:01:44.806: INFO: (5) /api/v1/namespaces/proxy-7355/services/proxy-service-vcj7z:portname2/proxy/: bar (200; 10.26414ms)
Nov 14 22:01:44.807: INFO: (5) /api/v1/namespaces/proxy-7355/services/http:proxy-service-vcj7z:portname1/proxy/: foo (200; 11.609212ms)
Nov 14 22:01:44.808: INFO: (5) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:1080/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:1080/proxy/rewriteme">test<... (200; 12.487178ms)
Nov 14 22:01:44.808: INFO: (5) /api/v1/namespaces/proxy-7355/services/https:proxy-service-vcj7z:tlsportname1/proxy/: tls baz (200; 13.408686ms)
Nov 14 22:01:44.808: INFO: (5) /api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:443/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:443/proxy/tlsrewritem... (200; 13.263108ms)
Nov 14 22:01:44.809: INFO: (5) /api/v1/namespaces/proxy-7355/services/proxy-service-vcj7z:portname1/proxy/: foo (200; 12.890769ms)
Nov 14 22:01:44.809: INFO: (5) /api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:460/proxy/: tls baz (200; 13.921045ms)
Nov 14 22:01:44.809: INFO: (5) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:160/proxy/: foo (200; 13.03261ms)
Nov 14 22:01:44.816: INFO: (6) /api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:462/proxy/: tls qux (200; 6.089472ms)
Nov 14 22:01:44.818: INFO: (6) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:1080/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:1080/proxy/rewriteme">test<... (200; 8.176239ms)
Nov 14 22:01:44.820: INFO: (6) /api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:162/proxy/: bar (200; 9.051557ms)
Nov 14 22:01:44.820: INFO: (6) /api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:160/proxy/: foo (200; 7.536152ms)
Nov 14 22:01:44.820: INFO: (6) /api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:443/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:443/proxy/tlsrewritem... (200; 7.471381ms)
Nov 14 22:01:44.822: INFO: (6) /api/v1/namespaces/proxy-7355/services/http:proxy-service-vcj7z:portname1/proxy/: foo (200; 12.214656ms)
Nov 14 22:01:44.823: INFO: (6) /api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:1080/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:1080/proxy/rewriteme">... (200; 12.314767ms)
Nov 14 22:01:44.823: INFO: (6) /api/v1/namespaces/proxy-7355/services/https:proxy-service-vcj7z:tlsportname2/proxy/: tls qux (200; 12.763674ms)
Nov 14 22:01:44.823: INFO: (6) /api/v1/namespaces/proxy-7355/services/https:proxy-service-vcj7z:tlsportname1/proxy/: tls baz (200; 10.780712ms)
Nov 14 22:01:44.823: INFO: (6) /api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:460/proxy/: tls baz (200; 10.345916ms)
Nov 14 22:01:44.824: INFO: (6) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4/proxy/rewriteme">test</a> (200; 12.422959ms)
Nov 14 22:01:44.824: INFO: (6) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:160/proxy/: foo (200; 12.687217ms)
Nov 14 22:01:44.825: INFO: (6) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:162/proxy/: bar (200; 13.203425ms)
Nov 14 22:01:44.825: INFO: (6) /api/v1/namespaces/proxy-7355/services/proxy-service-vcj7z:portname1/proxy/: foo (200; 14.400092ms)
Nov 14 22:01:44.826: INFO: (6) /api/v1/namespaces/proxy-7355/services/proxy-service-vcj7z:portname2/proxy/: bar (200; 15.184772ms)
Nov 14 22:01:44.826: INFO: (6) /api/v1/namespaces/proxy-7355/services/http:proxy-service-vcj7z:portname2/proxy/: bar (200; 14.567157ms)
Nov 14 22:01:44.834: INFO: (7) /api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:160/proxy/: foo (200; 5.13533ms)
Nov 14 22:01:44.834: INFO: (7) /api/v1/namespaces/proxy-7355/services/proxy-service-vcj7z:portname1/proxy/: foo (200; 7.247894ms)
Nov 14 22:01:44.835: INFO: (7) /api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:162/proxy/: bar (200; 8.113621ms)
Nov 14 22:01:44.836: INFO: (7) /api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:1080/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:1080/proxy/rewriteme">... (200; 6.099956ms)
Nov 14 22:01:44.836: INFO: (7) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:162/proxy/: bar (200; 8.037142ms)
Nov 14 22:01:44.841: INFO: (7) /api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:460/proxy/: tls baz (200; 12.472915ms)
Nov 14 22:01:44.841: INFO: (7) /api/v1/namespaces/proxy-7355/services/http:proxy-service-vcj7z:portname2/proxy/: bar (200; 13.317244ms)
Nov 14 22:01:44.841: INFO: (7) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:1080/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:1080/proxy/rewriteme">test<... (200; 11.867125ms)
Nov 14 22:01:44.841: INFO: (7) /api/v1/namespaces/proxy-7355/services/https:proxy-service-vcj7z:tlsportname1/proxy/: tls baz (200; 13.268162ms)
Nov 14 22:01:44.841: INFO: (7) /api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:462/proxy/: tls qux (200; 12.440798ms)
Nov 14 22:01:44.841: INFO: (7) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:160/proxy/: foo (200; 13.855858ms)
Nov 14 22:01:44.841: INFO: (7) /api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:443/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:443/proxy/tlsrewritem... (200; 12.896691ms)
Nov 14 22:01:44.841: INFO: (7) /api/v1/namespaces/proxy-7355/services/proxy-service-vcj7z:portname2/proxy/: bar (200; 14.313585ms)
Nov 14 22:01:44.841: INFO: (7) /api/v1/namespaces/proxy-7355/services/http:proxy-service-vcj7z:portname1/proxy/: foo (200; 12.415438ms)
Nov 14 22:01:44.841: INFO: (7) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4/proxy/rewriteme">test</a> (200; 14.123402ms)
Nov 14 22:01:44.842: INFO: (7) /api/v1/namespaces/proxy-7355/services/https:proxy-service-vcj7z:tlsportname2/proxy/: tls qux (200; 12.956424ms)
Nov 14 22:01:44.851: INFO: (8) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4/proxy/rewriteme">test</a> (200; 7.758254ms)
Nov 14 22:01:44.852: INFO: (8) /api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:462/proxy/: tls qux (200; 9.490977ms)
Nov 14 22:01:44.852: INFO: (8) /api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:162/proxy/: bar (200; 9.651566ms)
Nov 14 22:01:44.853: INFO: (8) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:162/proxy/: bar (200; 9.445124ms)
Nov 14 22:01:44.853: INFO: (8) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:1080/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:1080/proxy/rewriteme">test<... (200; 9.881208ms)
Nov 14 22:01:44.853: INFO: (8) /api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:1080/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:1080/proxy/rewriteme">... (200; 10.532148ms)
Nov 14 22:01:44.853: INFO: (8) /api/v1/namespaces/proxy-7355/services/http:proxy-service-vcj7z:portname2/proxy/: bar (200; 9.798ms)
Nov 14 22:01:44.854: INFO: (8) /api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:443/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:443/proxy/tlsrewritem... (200; 10.406299ms)
Nov 14 22:01:44.854: INFO: (8) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:160/proxy/: foo (200; 11.214046ms)
Nov 14 22:01:44.854: INFO: (8) /api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:160/proxy/: foo (200; 10.019154ms)
Nov 14 22:01:44.855: INFO: (8) /api/v1/namespaces/proxy-7355/services/proxy-service-vcj7z:portname1/proxy/: foo (200; 11.608232ms)
Nov 14 22:01:44.855: INFO: (8) /api/v1/namespaces/proxy-7355/services/https:proxy-service-vcj7z:tlsportname2/proxy/: tls qux (200; 12.431656ms)
Nov 14 22:01:44.855: INFO: (8) /api/v1/namespaces/proxy-7355/services/http:proxy-service-vcj7z:portname1/proxy/: foo (200; 12.910251ms)
Nov 14 22:01:44.856: INFO: (8) /api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:460/proxy/: tls baz (200; 12.054099ms)
Nov 14 22:01:44.856: INFO: (8) /api/v1/namespaces/proxy-7355/services/https:proxy-service-vcj7z:tlsportname1/proxy/: tls baz (200; 11.616935ms)
Nov 14 22:01:44.856: INFO: (8) /api/v1/namespaces/proxy-7355/services/proxy-service-vcj7z:portname2/proxy/: bar (200; 12.835506ms)
Nov 14 22:01:44.861: INFO: (9) /api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:162/proxy/: bar (200; 4.894503ms)
Nov 14 22:01:44.867: INFO: (9) /api/v1/namespaces/proxy-7355/services/proxy-service-vcj7z:portname1/proxy/: foo (200; 10.086912ms)
Nov 14 22:01:44.867: INFO: (9) /api/v1/namespaces/proxy-7355/services/proxy-service-vcj7z:portname2/proxy/: bar (200; 10.883002ms)
Nov 14 22:01:44.868: INFO: (9) /api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:1080/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:1080/proxy/rewriteme">... (200; 9.307836ms)
Nov 14 22:01:44.869: INFO: (9) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:160/proxy/: foo (200; 11.874797ms)
Nov 14 22:01:44.869: INFO: (9) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:1080/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:1080/proxy/rewriteme">test<... (200; 10.185047ms)
Nov 14 22:01:44.870: INFO: (9) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4/proxy/rewriteme">test</a> (200; 13.23461ms)
Nov 14 22:01:44.870: INFO: (9) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:162/proxy/: bar (200; 13.396256ms)
Nov 14 22:01:44.871: INFO: (9) /api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:160/proxy/: foo (200; 13.834929ms)
Nov 14 22:01:44.872: INFO: (9) /api/v1/namespaces/proxy-7355/services/https:proxy-service-vcj7z:tlsportname2/proxy/: tls qux (200; 13.293371ms)
Nov 14 22:01:44.872: INFO: (9) /api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:443/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:443/proxy/tlsrewritem... (200; 14.472053ms)
Nov 14 22:01:44.872: INFO: (9) /api/v1/namespaces/proxy-7355/services/http:proxy-service-vcj7z:portname2/proxy/: bar (200; 15.348719ms)
Nov 14 22:01:44.873: INFO: (9) /api/v1/namespaces/proxy-7355/services/https:proxy-service-vcj7z:tlsportname1/proxy/: tls baz (200; 15.803837ms)
Nov 14 22:01:44.873: INFO: (9) /api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:462/proxy/: tls qux (200; 15.387442ms)
Nov 14 22:01:44.874: INFO: (9) /api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:460/proxy/: tls baz (200; 16.02932ms)
Nov 14 22:01:44.874: INFO: (9) /api/v1/namespaces/proxy-7355/services/http:proxy-service-vcj7z:portname1/proxy/: foo (200; 15.986407ms)
Nov 14 22:01:45.040: INFO: (10) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4/proxy/rewriteme">test</a> (200; 165.312678ms)
Nov 14 22:01:45.040: INFO: (10) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:1080/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:1080/proxy/rewriteme">test<... (200; 164.371402ms)
Nov 14 22:01:45.040: INFO: (10) /api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:162/proxy/: bar (200; 164.499094ms)
Nov 14 22:01:45.040: INFO: (10) /api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:1080/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:1080/proxy/rewriteme">... (200; 164.605868ms)
Nov 14 22:01:45.040: INFO: (10) /api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:460/proxy/: tls baz (200; 165.068866ms)
Nov 14 22:01:45.040: INFO: (10) /api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:443/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:443/proxy/tlsrewritem... (200; 165.30424ms)
Nov 14 22:01:45.040: INFO: (10) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:160/proxy/: foo (200; 164.532336ms)
Nov 14 22:01:45.040: INFO: (10) /api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:160/proxy/: foo (200; 164.924233ms)
Nov 14 22:01:45.040: INFO: (10) /api/v1/namespaces/proxy-7355/services/https:proxy-service-vcj7z:tlsportname2/proxy/: tls qux (200; 164.751731ms)
Nov 14 22:01:45.041: INFO: (10) /api/v1/namespaces/proxy-7355/services/proxy-service-vcj7z:portname1/proxy/: foo (200; 165.519445ms)
Nov 14 22:01:45.041: INFO: (10) /api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:462/proxy/: tls qux (200; 165.993265ms)
Nov 14 22:01:45.041: INFO: (10) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:162/proxy/: bar (200; 165.891549ms)
Nov 14 22:01:45.042: INFO: (10) /api/v1/namespaces/proxy-7355/services/http:proxy-service-vcj7z:portname1/proxy/: foo (200; 166.178874ms)
Nov 14 22:01:45.044: INFO: (10) /api/v1/namespaces/proxy-7355/services/http:proxy-service-vcj7z:portname2/proxy/: bar (200; 168.707739ms)
Nov 14 22:01:45.044: INFO: (10) /api/v1/namespaces/proxy-7355/services/https:proxy-service-vcj7z:tlsportname1/proxy/: tls baz (200; 169.202857ms)
Nov 14 22:01:45.045: INFO: (10) /api/v1/namespaces/proxy-7355/services/proxy-service-vcj7z:portname2/proxy/: bar (200; 169.413284ms)
Nov 14 22:01:45.051: INFO: (11) /api/v1/namespaces/proxy-7355/services/https:proxy-service-vcj7z:tlsportname2/proxy/: tls qux (200; 5.500326ms)
Nov 14 22:01:45.051: INFO: (11) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:162/proxy/: bar (200; 5.47614ms)
Nov 14 22:01:45.052: INFO: (11) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4/proxy/rewriteme">test</a> (200; 6.347476ms)
Nov 14 22:01:45.052: INFO: (11) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:160/proxy/: foo (200; 6.341628ms)
Nov 14 22:01:45.053: INFO: (11) /api/v1/namespaces/proxy-7355/services/proxy-service-vcj7z:portname2/proxy/: bar (200; 6.629147ms)
Nov 14 22:01:45.053: INFO: (11) /api/v1/namespaces/proxy-7355/services/proxy-service-vcj7z:portname1/proxy/: foo (200; 7.127791ms)
Nov 14 22:01:45.057: INFO: (11) /api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:443/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:443/proxy/tlsrewritem... (200; 10.93858ms)
Nov 14 22:01:45.058: INFO: (11) /api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:160/proxy/: foo (200; 11.520549ms)
Nov 14 22:01:45.059: INFO: (11) /api/v1/namespaces/proxy-7355/services/http:proxy-service-vcj7z:portname2/proxy/: bar (200; 12.308423ms)
Nov 14 22:01:45.059: INFO: (11) /api/v1/namespaces/proxy-7355/services/https:proxy-service-vcj7z:tlsportname1/proxy/: tls baz (200; 12.460513ms)
Nov 14 22:01:45.060: INFO: (11) /api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:460/proxy/: tls baz (200; 12.982283ms)
Nov 14 22:01:45.063: INFO: (11) /api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:1080/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:1080/proxy/rewriteme">... (200; 15.64802ms)
Nov 14 22:01:45.063: INFO: (11) /api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:162/proxy/: bar (200; 15.881613ms)
Nov 14 22:01:45.064: INFO: (11) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:1080/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:1080/proxy/rewriteme">test<... (200; 16.24679ms)
Nov 14 22:01:45.064: INFO: (11) /api/v1/namespaces/proxy-7355/services/http:proxy-service-vcj7z:portname1/proxy/: foo (200; 16.395484ms)
Nov 14 22:01:45.066: INFO: (11) /api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:462/proxy/: tls qux (200; 18.989993ms)
Nov 14 22:01:45.071: INFO: (12) /api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:160/proxy/: foo (200; 4.965442ms)
Nov 14 22:01:45.072: INFO: (12) /api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:162/proxy/: bar (200; 4.888481ms)
Nov 14 22:01:45.072: INFO: (12) /api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:1080/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:1080/proxy/rewriteme">... (200; 5.051296ms)
Nov 14 22:01:45.074: INFO: (12) /api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:462/proxy/: tls qux (200; 7.308986ms)
Nov 14 22:01:45.075: INFO: (12) /api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:443/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:443/proxy/tlsrewritem... (200; 6.716473ms)
Nov 14 22:01:45.076: INFO: (12) /api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:460/proxy/: tls baz (200; 7.474429ms)
Nov 14 22:01:45.076: INFO: (12) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4/proxy/rewriteme">test</a> (200; 7.892449ms)
Nov 14 22:01:45.076: INFO: (12) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:160/proxy/: foo (200; 8.520528ms)
Nov 14 22:01:45.076: INFO: (12) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:1080/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:1080/proxy/rewriteme">test<... (200; 8.87811ms)
Nov 14 22:01:45.076: INFO: (12) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:162/proxy/: bar (200; 8.857323ms)
Nov 14 22:01:45.078: INFO: (12) /api/v1/namespaces/proxy-7355/services/proxy-service-vcj7z:portname2/proxy/: bar (200; 10.247581ms)
Nov 14 22:01:45.080: INFO: (12) /api/v1/namespaces/proxy-7355/services/https:proxy-service-vcj7z:tlsportname1/proxy/: tls baz (200; 11.283122ms)
Nov 14 22:01:45.080: INFO: (12) /api/v1/namespaces/proxy-7355/services/http:proxy-service-vcj7z:portname1/proxy/: foo (200; 12.728036ms)
Nov 14 22:01:45.080: INFO: (12) /api/v1/namespaces/proxy-7355/services/http:proxy-service-vcj7z:portname2/proxy/: bar (200; 12.183967ms)
Nov 14 22:01:45.081: INFO: (12) /api/v1/namespaces/proxy-7355/services/proxy-service-vcj7z:portname1/proxy/: foo (200; 13.079472ms)
Nov 14 22:01:45.081: INFO: (12) /api/v1/namespaces/proxy-7355/services/https:proxy-service-vcj7z:tlsportname2/proxy/: tls qux (200; 13.583226ms)
Nov 14 22:01:45.089: INFO: (13) /api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:462/proxy/: tls qux (200; 7.312616ms)
Nov 14 22:01:45.092: INFO: (13) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:1080/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:1080/proxy/rewriteme">test<... (200; 10.473766ms)
Nov 14 22:01:45.095: INFO: (13) /api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:443/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:443/proxy/tlsrewritem... (200; 11.493896ms)
Nov 14 22:01:45.095: INFO: (13) /api/v1/namespaces/proxy-7355/services/proxy-service-vcj7z:portname1/proxy/: foo (200; 12.435346ms)
Nov 14 22:01:45.095: INFO: (13) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:162/proxy/: bar (200; 12.019302ms)
Nov 14 22:01:45.095: INFO: (13) /api/v1/namespaces/proxy-7355/services/http:proxy-service-vcj7z:portname2/proxy/: bar (200; 11.95037ms)
Nov 14 22:01:45.095: INFO: (13) /api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:162/proxy/: bar (200; 12.589901ms)
Nov 14 22:01:45.095: INFO: (13) /api/v1/namespaces/proxy-7355/services/proxy-service-vcj7z:portname2/proxy/: bar (200; 12.416704ms)
Nov 14 22:01:45.095: INFO: (13) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4/proxy/rewriteme">test</a> (200; 12.334974ms)
Nov 14 22:01:45.095: INFO: (13) /api/v1/namespaces/proxy-7355/services/https:proxy-service-vcj7z:tlsportname2/proxy/: tls qux (200; 12.976881ms)
Nov 14 22:01:45.095: INFO: (13) /api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:1080/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:1080/proxy/rewriteme">... (200; 12.777434ms)
Nov 14 22:01:45.095: INFO: (13) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:160/proxy/: foo (200; 12.332017ms)
Nov 14 22:01:45.095: INFO: (13) /api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:460/proxy/: tls baz (200; 12.190126ms)
Nov 14 22:01:45.095: INFO: (13) /api/v1/namespaces/proxy-7355/services/http:proxy-service-vcj7z:portname1/proxy/: foo (200; 13.715405ms)
Nov 14 22:01:45.095: INFO: (13) /api/v1/namespaces/proxy-7355/services/https:proxy-service-vcj7z:tlsportname1/proxy/: tls baz (200; 12.609176ms)
Nov 14 22:01:45.095: INFO: (13) /api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:160/proxy/: foo (200; 12.483791ms)
Nov 14 22:01:45.100: INFO: (14) /api/v1/namespaces/proxy-7355/services/http:proxy-service-vcj7z:portname1/proxy/: foo (200; 4.732341ms)
Nov 14 22:01:45.102: INFO: (14) /api/v1/namespaces/proxy-7355/services/proxy-service-vcj7z:portname2/proxy/: bar (200; 6.553026ms)
Nov 14 22:01:45.103: INFO: (14) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:160/proxy/: foo (200; 6.936215ms)
Nov 14 22:01:45.104: INFO: (14) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:162/proxy/: bar (200; 7.735347ms)
Nov 14 22:01:45.104: INFO: (14) /api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:160/proxy/: foo (200; 7.823475ms)
Nov 14 22:01:45.104: INFO: (14) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4/proxy/rewriteme">test</a> (200; 8.46723ms)
Nov 14 22:01:45.104: INFO: (14) /api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:443/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:443/proxy/tlsrewritem... (200; 8.215568ms)
Nov 14 22:01:45.108: INFO: (14) /api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:460/proxy/: tls baz (200; 11.686448ms)
Nov 14 22:01:45.108: INFO: (14) /api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:1080/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:1080/proxy/rewriteme">... (200; 11.704844ms)
Nov 14 22:01:45.109: INFO: (14) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:1080/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:1080/proxy/rewriteme">test<... (200; 11.982219ms)
Nov 14 22:01:45.109: INFO: (14) /api/v1/namespaces/proxy-7355/services/https:proxy-service-vcj7z:tlsportname1/proxy/: tls baz (200; 12.773347ms)
Nov 14 22:01:45.109: INFO: (14) /api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:462/proxy/: tls qux (200; 12.451019ms)
Nov 14 22:01:45.109: INFO: (14) /api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:162/proxy/: bar (200; 11.973634ms)
Nov 14 22:01:45.109: INFO: (14) /api/v1/namespaces/proxy-7355/services/https:proxy-service-vcj7z:tlsportname2/proxy/: tls qux (200; 12.435199ms)
Nov 14 22:01:45.109: INFO: (14) /api/v1/namespaces/proxy-7355/services/http:proxy-service-vcj7z:portname2/proxy/: bar (200; 12.588556ms)
Nov 14 22:01:45.109: INFO: (14) /api/v1/namespaces/proxy-7355/services/proxy-service-vcj7z:portname1/proxy/: foo (200; 12.944346ms)
Nov 14 22:01:45.114: INFO: (15) /api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:462/proxy/: tls qux (200; 3.925032ms)
Nov 14 22:01:45.115: INFO: (15) /api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:460/proxy/: tls baz (200; 5.093564ms)
Nov 14 22:01:45.118: INFO: (15) /api/v1/namespaces/proxy-7355/services/http:proxy-service-vcj7z:portname1/proxy/: foo (200; 7.036849ms)
Nov 14 22:01:45.119: INFO: (15) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:1080/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:1080/proxy/rewriteme">test<... (200; 8.369429ms)
Nov 14 22:01:45.120: INFO: (15) /api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:162/proxy/: bar (200; 8.612672ms)
Nov 14 22:01:45.120: INFO: (15) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:160/proxy/: foo (200; 8.6138ms)
Nov 14 22:01:45.121: INFO: (15) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4/proxy/rewriteme">test</a> (200; 9.255201ms)
Nov 14 22:01:45.121: INFO: (15) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:162/proxy/: bar (200; 9.107914ms)
Nov 14 22:01:45.121: INFO: (15) /api/v1/namespaces/proxy-7355/services/https:proxy-service-vcj7z:tlsportname2/proxy/: tls qux (200; 10.466232ms)
Nov 14 22:01:45.122: INFO: (15) /api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:1080/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:1080/proxy/rewriteme">... (200; 11.101442ms)
Nov 14 22:01:45.123: INFO: (15) /api/v1/namespaces/proxy-7355/services/proxy-service-vcj7z:portname2/proxy/: bar (200; 11.152415ms)
Nov 14 22:01:45.123: INFO: (15) /api/v1/namespaces/proxy-7355/services/http:proxy-service-vcj7z:portname2/proxy/: bar (200; 11.389342ms)
Nov 14 22:01:45.124: INFO: (15) /api/v1/namespaces/proxy-7355/services/proxy-service-vcj7z:portname1/proxy/: foo (200; 12.299152ms)
Nov 14 22:01:45.124: INFO: (15) /api/v1/namespaces/proxy-7355/services/https:proxy-service-vcj7z:tlsportname1/proxy/: tls baz (200; 12.141045ms)
Nov 14 22:01:45.124: INFO: (15) /api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:160/proxy/: foo (200; 12.120387ms)
Nov 14 22:01:45.126: INFO: (15) /api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:443/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:443/proxy/tlsrewritem... (200; 13.416855ms)
Nov 14 22:01:45.226: INFO: (16) /api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:443/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:443/proxy/tlsrewritem... (200; 98.654319ms)
Nov 14 22:01:45.227: INFO: (16) /api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:460/proxy/: tls baz (200; 99.495097ms)
Nov 14 22:01:45.228: INFO: (16) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:1080/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:1080/proxy/rewriteme">test<... (200; 99.989892ms)
Nov 14 22:01:45.228: INFO: (16) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:160/proxy/: foo (200; 101.8247ms)
Nov 14 22:01:45.229: INFO: (16) /api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:162/proxy/: bar (200; 102.648997ms)
Nov 14 22:01:45.232: INFO: (16) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4/proxy/rewriteme">test</a> (200; 105.952715ms)
Nov 14 22:01:45.233: INFO: (16) /api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:462/proxy/: tls qux (200; 105.562466ms)
Nov 14 22:01:45.233: INFO: (16) /api/v1/namespaces/proxy-7355/services/https:proxy-service-vcj7z:tlsportname2/proxy/: tls qux (200; 105.633728ms)
Nov 14 22:01:45.233: INFO: (16) /api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:160/proxy/: foo (200; 106.573719ms)
Nov 14 22:01:45.234: INFO: (16) /api/v1/namespaces/proxy-7355/services/proxy-service-vcj7z:portname1/proxy/: foo (200; 107.633237ms)
Nov 14 22:01:45.234: INFO: (16) /api/v1/namespaces/proxy-7355/services/http:proxy-service-vcj7z:portname1/proxy/: foo (200; 106.68832ms)
Nov 14 22:01:45.234: INFO: (16) /api/v1/namespaces/proxy-7355/services/proxy-service-vcj7z:portname2/proxy/: bar (200; 108.053527ms)
Nov 14 22:01:45.235: INFO: (16) /api/v1/namespaces/proxy-7355/services/https:proxy-service-vcj7z:tlsportname1/proxy/: tls baz (200; 107.838498ms)
Nov 14 22:01:45.235: INFO: (16) /api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:1080/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:1080/proxy/rewriteme">... (200; 107.323049ms)
Nov 14 22:01:45.235: INFO: (16) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:162/proxy/: bar (200; 108.456554ms)
Nov 14 22:01:45.235: INFO: (16) /api/v1/namespaces/proxy-7355/services/http:proxy-service-vcj7z:portname2/proxy/: bar (200; 108.380567ms)
Nov 14 22:01:45.243: INFO: (17) /api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:462/proxy/: tls qux (200; 7.66677ms)
Nov 14 22:01:45.244: INFO: (17) /api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:160/proxy/: foo (200; 7.499363ms)
Nov 14 22:01:45.246: INFO: (17) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:162/proxy/: bar (200; 10.044438ms)
Nov 14 22:01:45.247: INFO: (17) /api/v1/namespaces/proxy-7355/services/proxy-service-vcj7z:portname1/proxy/: foo (200; 10.687749ms)
Nov 14 22:01:45.247: INFO: (17) /api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:162/proxy/: bar (200; 11.252321ms)
Nov 14 22:01:45.248: INFO: (17) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4/proxy/rewriteme">test</a> (200; 11.606874ms)
Nov 14 22:01:45.249: INFO: (17) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:1080/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:1080/proxy/rewriteme">test<... (200; 12.696803ms)
Nov 14 22:01:45.249: INFO: (17) /api/v1/namespaces/proxy-7355/services/https:proxy-service-vcj7z:tlsportname2/proxy/: tls qux (200; 12.96811ms)
Nov 14 22:01:45.249: INFO: (17) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:160/proxy/: foo (200; 12.554423ms)
Nov 14 22:01:45.249: INFO: (17) /api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:443/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:443/proxy/tlsrewritem... (200; 12.4077ms)
Nov 14 22:01:45.249: INFO: (17) /api/v1/namespaces/proxy-7355/services/https:proxy-service-vcj7z:tlsportname1/proxy/: tls baz (200; 12.593276ms)
Nov 14 22:01:45.249: INFO: (17) /api/v1/namespaces/proxy-7355/services/http:proxy-service-vcj7z:portname2/proxy/: bar (200; 12.762959ms)
Nov 14 22:01:45.249: INFO: (17) /api/v1/namespaces/proxy-7355/services/http:proxy-service-vcj7z:portname1/proxy/: foo (200; 13.653706ms)
Nov 14 22:01:45.249: INFO: (17) /api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:460/proxy/: tls baz (200; 12.866443ms)
Nov 14 22:01:45.249: INFO: (17) /api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:1080/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:1080/proxy/rewriteme">... (200; 13.276695ms)
Nov 14 22:01:45.249: INFO: (17) /api/v1/namespaces/proxy-7355/services/proxy-service-vcj7z:portname2/proxy/: bar (200; 13.160975ms)
Nov 14 22:01:45.259: INFO: (18) /api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:460/proxy/: tls baz (200; 6.745973ms)
Nov 14 22:01:45.260: INFO: (18) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:162/proxy/: bar (200; 9.221874ms)
Nov 14 22:01:45.261: INFO: (18) /api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:160/proxy/: foo (200; 8.9793ms)
Nov 14 22:01:45.261: INFO: (18) /api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:443/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:443/proxy/tlsrewritem... (200; 8.874222ms)
Nov 14 22:01:45.262: INFO: (18) /api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:462/proxy/: tls qux (200; 9.254068ms)
Nov 14 22:01:45.263: INFO: (18) /api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:162/proxy/: bar (200; 9.367991ms)
Nov 14 22:01:45.264: INFO: (18) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:1080/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:1080/proxy/rewriteme">test<... (200; 10.488014ms)
Nov 14 22:01:45.264: INFO: (18) /api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:1080/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:1080/proxy/rewriteme">... (200; 11.144003ms)
Nov 14 22:01:45.265: INFO: (18) /api/v1/namespaces/proxy-7355/services/http:proxy-service-vcj7z:portname2/proxy/: bar (200; 13.32786ms)
Nov 14 22:01:45.265: INFO: (18) /api/v1/namespaces/proxy-7355/services/https:proxy-service-vcj7z:tlsportname2/proxy/: tls qux (200; 11.917556ms)
Nov 14 22:01:45.265: INFO: (18) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4/proxy/rewriteme">test</a> (200; 10.908109ms)
Nov 14 22:01:45.266: INFO: (18) /api/v1/namespaces/proxy-7355/services/http:proxy-service-vcj7z:portname1/proxy/: foo (200; 13.05855ms)
Nov 14 22:01:45.267: INFO: (18) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:160/proxy/: foo (200; 12.660156ms)
Nov 14 22:01:45.267: INFO: (18) /api/v1/namespaces/proxy-7355/services/https:proxy-service-vcj7z:tlsportname1/proxy/: tls baz (200; 15.417663ms)
Nov 14 22:01:45.268: INFO: (18) /api/v1/namespaces/proxy-7355/services/proxy-service-vcj7z:portname1/proxy/: foo (200; 14.18868ms)
Nov 14 22:01:45.268: INFO: (18) /api/v1/namespaces/proxy-7355/services/proxy-service-vcj7z:portname2/proxy/: bar (200; 14.211593ms)
Nov 14 22:01:45.273: INFO: (19) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:162/proxy/: bar (200; 4.798403ms)
Nov 14 22:01:45.275: INFO: (19) /api/v1/namespaces/proxy-7355/services/http:proxy-service-vcj7z:portname2/proxy/: bar (200; 6.226673ms)
Nov 14 22:01:45.275: INFO: (19) /api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:443/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:443/proxy/tlsrewritem... (200; 5.959012ms)
Nov 14 22:01:45.275: INFO: (19) /api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:460/proxy/: tls baz (200; 5.891258ms)
Nov 14 22:01:45.275: INFO: (19) /api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:160/proxy/: foo (200; 6.255079ms)
Nov 14 22:01:45.278: INFO: (19) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4/proxy/rewriteme">test</a> (200; 7.919192ms)
Nov 14 22:01:45.279: INFO: (19) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:160/proxy/: foo (200; 8.343484ms)
Nov 14 22:01:45.279: INFO: (19) /api/v1/namespaces/proxy-7355/services/https:proxy-service-vcj7z:tlsportname1/proxy/: tls baz (200; 10.594909ms)
Nov 14 22:01:45.279: INFO: (19) /api/v1/namespaces/proxy-7355/pods/https:proxy-service-vcj7z-cdmf4:462/proxy/: tls qux (200; 10.072958ms)
Nov 14 22:01:45.280: INFO: (19) /api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:1080/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:1080/proxy/rewriteme">... (200; 9.841439ms)
Nov 14 22:01:45.280: INFO: (19) /api/v1/namespaces/proxy-7355/pods/http:proxy-service-vcj7z-cdmf4:162/proxy/: bar (200; 9.844773ms)
Nov 14 22:01:45.280: INFO: (19) /api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:1080/proxy/: <a href="/api/v1/namespaces/proxy-7355/pods/proxy-service-vcj7z-cdmf4:1080/proxy/rewriteme">test<... (200; 10.296185ms)
Nov 14 22:01:45.283: INFO: (19) /api/v1/namespaces/proxy-7355/services/proxy-service-vcj7z:portname1/proxy/: foo (200; 12.743958ms)
Nov 14 22:01:45.283: INFO: (19) /api/v1/namespaces/proxy-7355/services/http:proxy-service-vcj7z:portname1/proxy/: foo (200; 13.961203ms)
Nov 14 22:01:45.283: INFO: (19) /api/v1/namespaces/proxy-7355/services/proxy-service-vcj7z:portname2/proxy/: bar (200; 13.107027ms)
Nov 14 22:01:45.284: INFO: (19) /api/v1/namespaces/proxy-7355/services/https:proxy-service-vcj7z:tlsportname2/proxy/: tls qux (200; 13.866753ms)
STEP: deleting ReplicationController proxy-service-vcj7z in namespace proxy-7355, will wait for the garbage collector to delete the pods
Nov 14 22:01:45.346: INFO: Deleting ReplicationController proxy-service-vcj7z took: 8.529029ms
Nov 14 22:01:46.047: INFO: Terminating ReplicationController proxy-service-vcj7z pods took: 700.531395ms
[AfterEach] version v1
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:01:53.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-7355" for this suite.
Nov 14 22:02:01.811: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:02:02.088: INFO: namespace proxy-7355 deletion completed in 8.52243837s

• [SLOW TEST:43.593 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:02:02.091: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-962
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:02:43.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-962" for this suite.
Nov 14 22:02:51.483: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:02:52.056: INFO: namespace container-runtime-962 deletion completed in 8.662152893s

• [SLOW TEST:49.965 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    when starting a container that exits
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:02:52.069: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3849
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Nov 14 22:02:52.656: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c0e3c00c-d1fe-41ab-b713-25a4c2c5e7ea" in namespace "projected-3849" to be "success or failure"
Nov 14 22:02:52.679: INFO: Pod "downwardapi-volume-c0e3c00c-d1fe-41ab-b713-25a4c2c5e7ea": Phase="Pending", Reason="", readiness=false. Elapsed: 22.884589ms
Nov 14 22:02:54.684: INFO: Pod "downwardapi-volume-c0e3c00c-d1fe-41ab-b713-25a4c2c5e7ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027848949s
Nov 14 22:02:56.757: INFO: Pod "downwardapi-volume-c0e3c00c-d1fe-41ab-b713-25a4c2c5e7ea": Phase="Pending", Reason="", readiness=false. Elapsed: 4.100701746s
Nov 14 22:02:58.762: INFO: Pod "downwardapi-volume-c0e3c00c-d1fe-41ab-b713-25a4c2c5e7ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.105697191s
STEP: Saw pod success
Nov 14 22:02:58.762: INFO: Pod "downwardapi-volume-c0e3c00c-d1fe-41ab-b713-25a4c2c5e7ea" satisfied condition "success or failure"
Nov 14 22:02:58.766: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-0 pod downwardapi-volume-c0e3c00c-d1fe-41ab-b713-25a4c2c5e7ea container client-container: <nil>
STEP: delete the pod
Nov 14 22:02:58.963: INFO: Waiting for pod downwardapi-volume-c0e3c00c-d1fe-41ab-b713-25a4c2c5e7ea to disappear
Nov 14 22:02:58.992: INFO: Pod downwardapi-volume-c0e3c00c-d1fe-41ab-b713-25a4c2c5e7ea no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:02:58.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3849" for this suite.
Nov 14 22:03:05.166: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:03:05.321: INFO: namespace projected-3849 deletion completed in 6.324020385s

• [SLOW TEST:13.253 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:03:05.327: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-4886
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-4886
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Nov 14 22:03:05.646: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Nov 14 22:04:02.415: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.2.18 8081 | grep -v '^\s*$'] Namespace:pod-network-test-4886 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 14 22:04:02.416: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
Nov 14 22:04:04.164: INFO: Found all expected endpoints: [netserver-0]
Nov 14 22:04:04.317: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.1.22 8081 | grep -v '^\s*$'] Namespace:pod-network-test-4886 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 14 22:04:04.318: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
Nov 14 22:04:05.472: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:04:05.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-4886" for this suite.
Nov 14 22:04:37.598: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:04:37.747: INFO: namespace pod-network-test-4886 deletion completed in 32.26736755s

• [SLOW TEST:92.421 seconds]
[sig-network] Networking
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:04:37.761: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7371
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Nov 14 22:04:38.312: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a2bdeb3d-415c-4e84-a439-640ce3e4815e" in namespace "downward-api-7371" to be "success or failure"
Nov 14 22:04:38.688: INFO: Pod "downwardapi-volume-a2bdeb3d-415c-4e84-a439-640ce3e4815e": Phase="Pending", Reason="", readiness=false. Elapsed: 376.149726ms
Nov 14 22:04:40.797: INFO: Pod "downwardapi-volume-a2bdeb3d-415c-4e84-a439-640ce3e4815e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.485058893s
Nov 14 22:04:42.804: INFO: Pod "downwardapi-volume-a2bdeb3d-415c-4e84-a439-640ce3e4815e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.49159195s
STEP: Saw pod success
Nov 14 22:04:42.805: INFO: Pod "downwardapi-volume-a2bdeb3d-415c-4e84-a439-640ce3e4815e" satisfied condition "success or failure"
Nov 14 22:04:43.021: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-0 pod downwardapi-volume-a2bdeb3d-415c-4e84-a439-640ce3e4815e container client-container: <nil>
STEP: delete the pod
Nov 14 22:04:43.380: INFO: Waiting for pod downwardapi-volume-a2bdeb3d-415c-4e84-a439-640ce3e4815e to disappear
Nov 14 22:04:43.715: INFO: Pod downwardapi-volume-a2bdeb3d-415c-4e84-a439-640ce3e4815e no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:04:43.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7371" for this suite.
Nov 14 22:04:52.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:04:52.302: INFO: namespace downward-api-7371 deletion completed in 8.188312362s

• [SLOW TEST:14.541 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:04:52.305: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7744
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-7f8e450a-cadc-4f02-a5c6-cf00684b194f
STEP: Creating a pod to test consume configMaps
Nov 14 22:04:52.967: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4713c9a4-fdba-4bc5-9617-fbee3cc18fd5" in namespace "projected-7744" to be "success or failure"
Nov 14 22:04:52.990: INFO: Pod "pod-projected-configmaps-4713c9a4-fdba-4bc5-9617-fbee3cc18fd5": Phase="Pending", Reason="", readiness=false. Elapsed: 21.910381ms
Nov 14 22:04:55.046: INFO: Pod "pod-projected-configmaps-4713c9a4-fdba-4bc5-9617-fbee3cc18fd5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.07752838s
Nov 14 22:04:57.050: INFO: Pod "pod-projected-configmaps-4713c9a4-fdba-4bc5-9617-fbee3cc18fd5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.082206056s
STEP: Saw pod success
Nov 14 22:04:57.051: INFO: Pod "pod-projected-configmaps-4713c9a4-fdba-4bc5-9617-fbee3cc18fd5" satisfied condition "success or failure"
Nov 14 22:04:57.055: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-0 pod pod-projected-configmaps-4713c9a4-fdba-4bc5-9617-fbee3cc18fd5 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov 14 22:04:57.221: INFO: Waiting for pod pod-projected-configmaps-4713c9a4-fdba-4bc5-9617-fbee3cc18fd5 to disappear
Nov 14 22:04:57.992: INFO: Pod pod-projected-configmaps-4713c9a4-fdba-4bc5-9617-fbee3cc18fd5 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:04:57.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7744" for this suite.
Nov 14 22:05:04.586: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:05:05.428: INFO: namespace projected-7744 deletion completed in 7.432255717s

• [SLOW TEST:13.123 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:05:05.432: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3636
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-map-4514ee75-c505-46d8-8ce2-98798323d269
STEP: Creating a pod to test consume secrets
Nov 14 22:05:06.396: INFO: Waiting up to 5m0s for pod "pod-secrets-b2f96d01-6cdb-4ca5-9230-6d7e44a08ccb" in namespace "secrets-3636" to be "success or failure"
Nov 14 22:05:06.610: INFO: Pod "pod-secrets-b2f96d01-6cdb-4ca5-9230-6d7e44a08ccb": Phase="Pending", Reason="", readiness=false. Elapsed: 212.092155ms
Nov 14 22:05:08.614: INFO: Pod "pod-secrets-b2f96d01-6cdb-4ca5-9230-6d7e44a08ccb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.216105768s
Nov 14 22:05:10.881: INFO: Pod "pod-secrets-b2f96d01-6cdb-4ca5-9230-6d7e44a08ccb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.483622728s
Nov 14 22:05:16.009: INFO: Pod "pod-secrets-b2f96d01-6cdb-4ca5-9230-6d7e44a08ccb": Phase="Pending", Reason="", readiness=false. Elapsed: 9.611421076s
Nov 14 22:05:18.025: INFO: Pod "pod-secrets-b2f96d01-6cdb-4ca5-9230-6d7e44a08ccb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 11.627354643s
STEP: Saw pod success
Nov 14 22:05:18.027: INFO: Pod "pod-secrets-b2f96d01-6cdb-4ca5-9230-6d7e44a08ccb" satisfied condition "success or failure"
Nov 14 22:05:18.032: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-1 pod pod-secrets-b2f96d01-6cdb-4ca5-9230-6d7e44a08ccb container secret-volume-test: <nil>
STEP: delete the pod
Nov 14 22:05:19.412: INFO: Waiting for pod pod-secrets-b2f96d01-6cdb-4ca5-9230-6d7e44a08ccb to disappear
Nov 14 22:05:19.507: INFO: Pod pod-secrets-b2f96d01-6cdb-4ca5-9230-6d7e44a08ccb no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:05:19.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3636" for this suite.
Nov 14 22:05:26.158: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:05:26.806: INFO: namespace secrets-3636 deletion completed in 7.063730717s

• [SLOW TEST:21.374 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:05:26.813: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6158
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on node default medium
Nov 14 22:05:27.930: INFO: Waiting up to 5m0s for pod "pod-3b556859-a889-402b-a3de-de27d85fb2a4" in namespace "emptydir-6158" to be "success or failure"
Nov 14 22:05:27.975: INFO: Pod "pod-3b556859-a889-402b-a3de-de27d85fb2a4": Phase="Pending", Reason="", readiness=false. Elapsed: 45.218956ms
Nov 14 22:05:29.979: INFO: Pod "pod-3b556859-a889-402b-a3de-de27d85fb2a4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.04863609s
Nov 14 22:05:31.981: INFO: Pod "pod-3b556859-a889-402b-a3de-de27d85fb2a4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.051432483s
Nov 14 22:05:33.986: INFO: Pod "pod-3b556859-a889-402b-a3de-de27d85fb2a4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.056432657s
Nov 14 22:05:35.991: INFO: Pod "pod-3b556859-a889-402b-a3de-de27d85fb2a4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.061453999s
Nov 14 22:05:37.995: INFO: Pod "pod-3b556859-a889-402b-a3de-de27d85fb2a4": Phase="Pending", Reason="", readiness=false. Elapsed: 10.064931892s
Nov 14 22:05:40.119: INFO: Pod "pod-3b556859-a889-402b-a3de-de27d85fb2a4": Phase="Pending", Reason="", readiness=false. Elapsed: 12.188732369s
Nov 14 22:05:42.123: INFO: Pod "pod-3b556859-a889-402b-a3de-de27d85fb2a4": Phase="Pending", Reason="", readiness=false. Elapsed: 14.192651127s
Nov 14 22:05:44.127: INFO: Pod "pod-3b556859-a889-402b-a3de-de27d85fb2a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 16.197305103s
STEP: Saw pod success
Nov 14 22:05:44.127: INFO: Pod "pod-3b556859-a889-402b-a3de-de27d85fb2a4" satisfied condition "success or failure"
Nov 14 22:05:44.130: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-0 pod pod-3b556859-a889-402b-a3de-de27d85fb2a4 container test-container: <nil>
STEP: delete the pod
Nov 14 22:05:44.595: INFO: Waiting for pod pod-3b556859-a889-402b-a3de-de27d85fb2a4 to disappear
Nov 14 22:05:44.849: INFO: Pod pod-3b556859-a889-402b-a3de-de27d85fb2a4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:05:44.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6158" for this suite.
Nov 14 22:05:53.067: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:05:53.437: INFO: namespace emptydir-6158 deletion completed in 8.582989907s

• [SLOW TEST:26.625 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:05:53.443: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3821
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: validating api versions
Nov 14 22:05:54.669: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 api-versions'
Nov 14 22:05:55.322: INFO: stderr: ""
Nov 14 22:05:55.322: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauditregistration.k8s.io/v1alpha1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\nbatch/v2alpha1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\ncrd.projectcalico.org/v1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1alpha1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1alpha1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1alpha1\nscheduling.k8s.io/v1beta1\nsettings.k8s.io/v1alpha1\nstorage.k8s.io/v1\nstorage.k8s.io/v1alpha1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:05:55.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3821" for this suite.
Nov 14 22:06:03.992: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:06:04.497: INFO: namespace kubectl-3821 deletion completed in 8.920207374s

• [SLOW TEST:11.056 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:06:04.513: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-8325
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-8325
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-8325
STEP: Creating statefulset with conflicting port in namespace statefulset-8325
STEP: Waiting until pod test-pod will start running in namespace statefulset-8325
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-8325
Nov 14 22:06:13.994: INFO: Observed stateful pod in namespace: statefulset-8325, name: ss-0, uid: f979fda6-0bca-4600-b0ae-8d299f0925f3, status phase: Pending. Waiting for statefulset controller to delete.
Nov 14 22:06:22.370: INFO: Observed stateful pod in namespace: statefulset-8325, name: ss-0, uid: f979fda6-0bca-4600-b0ae-8d299f0925f3, status phase: Failed. Waiting for statefulset controller to delete.
Nov 14 22:06:22.678: INFO: Observed stateful pod in namespace: statefulset-8325, name: ss-0, uid: f979fda6-0bca-4600-b0ae-8d299f0925f3, status phase: Failed. Waiting for statefulset controller to delete.
Nov 14 22:06:22.925: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-8325
STEP: Removing pod with conflicting port in namespace statefulset-8325
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-8325 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Nov 14 22:06:43.979: INFO: Deleting all statefulset in ns statefulset-8325
Nov 14 22:06:44.012: INFO: Scaling statefulset ss to 0
Nov 14 22:06:54.100: INFO: Waiting for statefulset status.replicas updated to 0
Nov 14 22:06:54.102: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:06:54.523: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8325" for this suite.
Nov 14 22:07:02.727: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:07:02.908: INFO: namespace statefulset-8325 deletion completed in 8.379458474s

• [SLOW TEST:58.396 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:07:02.912: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-9923
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating pod
Nov 14 22:07:15.511: INFO: Pod pod-hostip-f2e10a00-26f4-4360-be99-5a928e4069f0 has hostIP: 10.0.0.152
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:07:15.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9923" for this suite.
Nov 14 22:07:39.658: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:07:40.080: INFO: namespace pods-9923 deletion completed in 24.562649762s

• [SLOW TEST:37.168 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:07:40.085: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-6832
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: getting the auto-created API token
STEP: reading a file in the container
Nov 14 22:07:47.306: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6832 pod-service-account-e41cb17e-7baf-4dff-b155-87e2efac1bf5 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Nov 14 22:07:50.238: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6832 pod-service-account-e41cb17e-7baf-4dff-b155-87e2efac1bf5 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Nov 14 22:07:50.547: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6832 pod-service-account-e41cb17e-7baf-4dff-b155-87e2efac1bf5 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:07:50.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-6832" for this suite.
Nov 14 22:07:58.890: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:07:59.041: INFO: namespace svcaccounts-6832 deletion completed in 8.188584576s

• [SLOW TEST:18.957 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:07:59.047: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7354
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Nov 14 22:08:07.513: INFO: Successfully updated pod "annotationupdatef9f26e9d-5802-4fa1-883d-d4c7b408f077"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:08:11.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7354" for this suite.
Nov 14 22:08:35.857: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:08:35.998: INFO: namespace projected-7354 deletion completed in 24.354867579s

• [SLOW TEST:36.952 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:08:36.006: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-1693
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: expected 0 pods, got 2 pods
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W1114 22:08:40.725824      13 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Nov 14 22:08:40.726: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:08:40.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1693" for this suite.
Nov 14 22:08:49.130: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:08:49.391: INFO: namespace gc-1693 deletion completed in 8.66149406s

• [SLOW TEST:13.387 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:08:49.400: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6116
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Nov 14 22:08:49.735: INFO: Waiting up to 5m0s for pod "downwardapi-volume-eed78f49-f4bb-4142-9262-4619e4adfec0" in namespace "projected-6116" to be "success or failure"
Nov 14 22:08:49.771: INFO: Pod "downwardapi-volume-eed78f49-f4bb-4142-9262-4619e4adfec0": Phase="Pending", Reason="", readiness=false. Elapsed: 33.887413ms
Nov 14 22:08:52.057: INFO: Pod "downwardapi-volume-eed78f49-f4bb-4142-9262-4619e4adfec0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.319376324s
Nov 14 22:08:54.246: INFO: Pod "downwardapi-volume-eed78f49-f4bb-4142-9262-4619e4adfec0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.508786444s
STEP: Saw pod success
Nov 14 22:08:54.246: INFO: Pod "downwardapi-volume-eed78f49-f4bb-4142-9262-4619e4adfec0" satisfied condition "success or failure"
Nov 14 22:08:54.251: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-0 pod downwardapi-volume-eed78f49-f4bb-4142-9262-4619e4adfec0 container client-container: <nil>
STEP: delete the pod
Nov 14 22:08:54.330: INFO: Waiting for pod downwardapi-volume-eed78f49-f4bb-4142-9262-4619e4adfec0 to disappear
Nov 14 22:08:54.506: INFO: Pod downwardapi-volume-eed78f49-f4bb-4142-9262-4619e4adfec0 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:08:54.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6116" for this suite.
Nov 14 22:09:01.192: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:09:01.473: INFO: namespace projected-6116 deletion completed in 6.962517362s

• [SLOW TEST:12.074 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:09:01.476: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-2429
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-842f0776-9102-44ae-b505-41b49fac0022
STEP: Creating a pod to test consume secrets
Nov 14 22:09:02.119: INFO: Waiting up to 5m0s for pod "pod-secrets-c82a4d36-b6a0-4251-8833-0050a7e93b54" in namespace "secrets-2429" to be "success or failure"
Nov 14 22:09:02.157: INFO: Pod "pod-secrets-c82a4d36-b6a0-4251-8833-0050a7e93b54": Phase="Pending", Reason="", readiness=false. Elapsed: 36.865704ms
Nov 14 22:09:04.186: INFO: Pod "pod-secrets-c82a4d36-b6a0-4251-8833-0050a7e93b54": Phase="Pending", Reason="", readiness=false. Elapsed: 2.066567141s
Nov 14 22:09:06.282: INFO: Pod "pod-secrets-c82a4d36-b6a0-4251-8833-0050a7e93b54": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.162362418s
STEP: Saw pod success
Nov 14 22:09:06.283: INFO: Pod "pod-secrets-c82a4d36-b6a0-4251-8833-0050a7e93b54" satisfied condition "success or failure"
Nov 14 22:09:06.289: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-1 pod pod-secrets-c82a4d36-b6a0-4251-8833-0050a7e93b54 container secret-volume-test: <nil>
STEP: delete the pod
Nov 14 22:09:06.611: INFO: Waiting for pod pod-secrets-c82a4d36-b6a0-4251-8833-0050a7e93b54 to disappear
Nov 14 22:09:06.976: INFO: Pod pod-secrets-c82a4d36-b6a0-4251-8833-0050a7e93b54 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:09:06.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2429" for this suite.
Nov 14 22:09:13.272: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:09:13.563: INFO: namespace secrets-2429 deletion completed in 6.580837369s

• [SLOW TEST:12.087 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:09:13.563: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-9780
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: getting the auto-created API token
Nov 14 22:09:14.640: INFO: created pod pod-service-account-defaultsa
Nov 14 22:09:14.640: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Nov 14 22:09:14.667: INFO: created pod pod-service-account-mountsa
Nov 14 22:09:14.667: INFO: pod pod-service-account-mountsa service account token volume mount: true
Nov 14 22:09:14.903: INFO: created pod pod-service-account-nomountsa
Nov 14 22:09:14.903: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Nov 14 22:09:14.963: INFO: created pod pod-service-account-defaultsa-mountspec
Nov 14 22:09:14.963: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Nov 14 22:09:15.147: INFO: created pod pod-service-account-mountsa-mountspec
Nov 14 22:09:15.148: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Nov 14 22:09:15.205: INFO: created pod pod-service-account-nomountsa-mountspec
Nov 14 22:09:15.208: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Nov 14 22:09:15.493: INFO: created pod pod-service-account-defaultsa-nomountspec
Nov 14 22:09:15.493: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Nov 14 22:09:15.922: INFO: created pod pod-service-account-mountsa-nomountspec
Nov 14 22:09:15.923: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Nov 14 22:09:15.934: INFO: created pod pod-service-account-nomountsa-nomountspec
Nov 14 22:09:15.935: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:09:15.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-9780" for this suite.
Nov 14 22:10:07.168: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:10:07.415: INFO: namespace svcaccounts-9780 deletion completed in 50.857781616s

• [SLOW TEST:53.852 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:10:07.421: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-5389
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:10:14.255: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-5389" for this suite.
Nov 14 22:11:06.303: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:11:06.486: INFO: namespace kubelet-test-5389 deletion completed in 52.225733661s

• [SLOW TEST:59.066 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:11:06.493: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-2194
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Nov 14 22:11:07.185: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:11:13.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2194" for this suite.
Nov 14 22:12:05.810: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:12:06.055: INFO: namespace pods-2194 deletion completed in 52.279617681s

• [SLOW TEST:59.563 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:12:06.060: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-8728
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Nov 14 22:12:06.576: INFO: (0) /api/v1/nodes/k8s-1-tdyr52fdsot3-minion-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 16.72752ms)
Nov 14 22:12:06.584: INFO: (1) /api/v1/nodes/k8s-1-tdyr52fdsot3-minion-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 7.558392ms)
Nov 14 22:12:06.591: INFO: (2) /api/v1/nodes/k8s-1-tdyr52fdsot3-minion-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 6.278841ms)
Nov 14 22:12:06.596: INFO: (3) /api/v1/nodes/k8s-1-tdyr52fdsot3-minion-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 5.220658ms)
Nov 14 22:12:06.601: INFO: (4) /api/v1/nodes/k8s-1-tdyr52fdsot3-minion-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 4.154861ms)
Nov 14 22:12:06.607: INFO: (5) /api/v1/nodes/k8s-1-tdyr52fdsot3-minion-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 5.046832ms)
Nov 14 22:12:06.612: INFO: (6) /api/v1/nodes/k8s-1-tdyr52fdsot3-minion-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 4.70344ms)
Nov 14 22:12:06.618: INFO: (7) /api/v1/nodes/k8s-1-tdyr52fdsot3-minion-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 4.929715ms)
Nov 14 22:12:06.624: INFO: (8) /api/v1/nodes/k8s-1-tdyr52fdsot3-minion-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 5.649928ms)
Nov 14 22:12:06.630: INFO: (9) /api/v1/nodes/k8s-1-tdyr52fdsot3-minion-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 5.228654ms)
Nov 14 22:12:06.636: INFO: (10) /api/v1/nodes/k8s-1-tdyr52fdsot3-minion-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 5.31219ms)
Nov 14 22:12:06.642: INFO: (11) /api/v1/nodes/k8s-1-tdyr52fdsot3-minion-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 5.643008ms)
Nov 14 22:12:06.649: INFO: (12) /api/v1/nodes/k8s-1-tdyr52fdsot3-minion-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 6.480929ms)
Nov 14 22:12:06.658: INFO: (13) /api/v1/nodes/k8s-1-tdyr52fdsot3-minion-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 7.869167ms)
Nov 14 22:12:06.665: INFO: (14) /api/v1/nodes/k8s-1-tdyr52fdsot3-minion-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 6.417072ms)
Nov 14 22:12:06.669: INFO: (15) /api/v1/nodes/k8s-1-tdyr52fdsot3-minion-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 3.882512ms)
Nov 14 22:12:06.674: INFO: (16) /api/v1/nodes/k8s-1-tdyr52fdsot3-minion-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 4.433617ms)
Nov 14 22:12:06.679: INFO: (17) /api/v1/nodes/k8s-1-tdyr52fdsot3-minion-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 4.745559ms)
Nov 14 22:12:06.684: INFO: (18) /api/v1/nodes/k8s-1-tdyr52fdsot3-minion-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 4.784635ms)
Nov 14 22:12:06.690: INFO: (19) /api/v1/nodes/k8s-1-tdyr52fdsot3-minion-0:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="btmp">btmp</a>
<a hr... (200; 5.528544ms)
[AfterEach] version v1
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:12:06.692: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-8728" for this suite.
Nov 14 22:12:14.748: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:12:14.856: INFO: namespace proxy-8728 deletion completed in 8.159402239s

• [SLOW TEST:8.797 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:12:14.867: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3993
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secret-namespace-5768
STEP: Creating secret with name secret-test-2158531f-d932-4523-8f98-9952868b07f0
STEP: Creating a pod to test consume secrets
Nov 14 22:12:16.312: INFO: Waiting up to 5m0s for pod "pod-secrets-c5a566d6-448f-4c3e-baf8-444e750f8fb9" in namespace "secrets-3993" to be "success or failure"
Nov 14 22:12:16.357: INFO: Pod "pod-secrets-c5a566d6-448f-4c3e-baf8-444e750f8fb9": Phase="Pending", Reason="", readiness=false. Elapsed: 43.71731ms
Nov 14 22:12:18.391: INFO: Pod "pod-secrets-c5a566d6-448f-4c3e-baf8-444e750f8fb9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.077598996s
Nov 14 22:12:20.406: INFO: Pod "pod-secrets-c5a566d6-448f-4c3e-baf8-444e750f8fb9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.093124847s
Nov 14 22:12:22.412: INFO: Pod "pod-secrets-c5a566d6-448f-4c3e-baf8-444e750f8fb9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.098878677s
STEP: Saw pod success
Nov 14 22:12:22.413: INFO: Pod "pod-secrets-c5a566d6-448f-4c3e-baf8-444e750f8fb9" satisfied condition "success or failure"
Nov 14 22:12:22.416: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-1 pod pod-secrets-c5a566d6-448f-4c3e-baf8-444e750f8fb9 container secret-volume-test: <nil>
STEP: delete the pod
Nov 14 22:12:22.957: INFO: Waiting for pod pod-secrets-c5a566d6-448f-4c3e-baf8-444e750f8fb9 to disappear
Nov 14 22:12:23.203: INFO: Pod pod-secrets-c5a566d6-448f-4c3e-baf8-444e750f8fb9 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:12:23.203: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3993" for this suite.
Nov 14 22:12:29.504: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:12:29.621: INFO: namespace secrets-3993 deletion completed in 6.354412431s
STEP: Destroying namespace "secret-namespace-5768" for this suite.
Nov 14 22:12:35.776: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:12:36.193: INFO: namespace secret-namespace-5768 deletion completed in 6.571145272s

• [SLOW TEST:21.326 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:12:36.195: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-2481
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Nov 14 22:12:36.973: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:12:49.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2481" for this suite.
Nov 14 22:13:52.194: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:13:52.958: INFO: namespace pods-2481 deletion completed in 1m3.392704111s

• [SLOW TEST:76.763 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:13:52.965: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-4934
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating replication controller my-hostname-basic-81c72769-a5df-4708-a864-3f6d5b915275
Nov 14 22:13:53.743: INFO: Pod name my-hostname-basic-81c72769-a5df-4708-a864-3f6d5b915275: Found 0 pods out of 1
Nov 14 22:13:58.746: INFO: Pod name my-hostname-basic-81c72769-a5df-4708-a864-3f6d5b915275: Found 1 pods out of 1
Nov 14 22:13:58.746: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-81c72769-a5df-4708-a864-3f6d5b915275" are running
Nov 14 22:14:14.753: INFO: Pod "my-hostname-basic-81c72769-a5df-4708-a864-3f6d5b915275-9q6gw" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-11-14 22:13:53 +0000 UTC Reason: Message:} {Type:Ready Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-11-14 22:13:53 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-81c72769-a5df-4708-a864-3f6d5b915275]} {Type:ContainersReady Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-11-14 22:13:53 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-81c72769-a5df-4708-a864-3f6d5b915275]} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-11-14 22:13:53 +0000 UTC Reason: Message:}])
Nov 14 22:14:14.753: INFO: Trying to dial the pod
Nov 14 22:14:19.770: INFO: Controller my-hostname-basic-81c72769-a5df-4708-a864-3f6d5b915275: Got expected result from replica 1 [my-hostname-basic-81c72769-a5df-4708-a864-3f6d5b915275-9q6gw]: "my-hostname-basic-81c72769-a5df-4708-a864-3f6d5b915275-9q6gw", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:14:19.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-4934" for this suite.
Nov 14 22:14:27.822: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:14:27.961: INFO: namespace replication-controller-4934 deletion completed in 8.181225241s

• [SLOW TEST:34.997 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:14:27.961: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5962
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1516
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Nov 14 22:14:28.483: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-5962'
Nov 14 22:14:28.848: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Nov 14 22:14:28.848: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Nov 14 22:14:29.117: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Nov 14 22:14:29.171: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Nov 14 22:14:29.581: INFO: scanned /root for discovery docs: <nil>
Nov 14 22:14:29.582: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-5962'
Nov 14 22:14:53.285: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Nov 14 22:14:53.285: INFO: stdout: "Created e2e-test-nginx-rc-7dcb990308eb2ac5cb2fbdeb44f6d97c\nScaling up e2e-test-nginx-rc-7dcb990308eb2ac5cb2fbdeb44f6d97c from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-7dcb990308eb2ac5cb2fbdeb44f6d97c up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-7dcb990308eb2ac5cb2fbdeb44f6d97c to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Nov 14 22:14:53.286: INFO: stdout: "Created e2e-test-nginx-rc-7dcb990308eb2ac5cb2fbdeb44f6d97c\nScaling up e2e-test-nginx-rc-7dcb990308eb2ac5cb2fbdeb44f6d97c from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-7dcb990308eb2ac5cb2fbdeb44f6d97c up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-7dcb990308eb2ac5cb2fbdeb44f6d97c to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Nov 14 22:14:53.287: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-5962'
Nov 14 22:14:53.444: INFO: stderr: ""
Nov 14 22:14:53.444: INFO: stdout: "e2e-test-nginx-rc-7dcb990308eb2ac5cb2fbdeb44f6d97c-gp5t4 "
Nov 14 22:14:53.444: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 get pods e2e-test-nginx-rc-7dcb990308eb2ac5cb2fbdeb44f6d97c-gp5t4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5962'
Nov 14 22:14:53.557: INFO: stderr: ""
Nov 14 22:14:53.557: INFO: stdout: "true"
Nov 14 22:14:53.557: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 get pods e2e-test-nginx-rc-7dcb990308eb2ac5cb2fbdeb44f6d97c-gp5t4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5962'
Nov 14 22:14:53.686: INFO: stderr: ""
Nov 14 22:14:53.686: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Nov 14 22:14:53.686: INFO: e2e-test-nginx-rc-7dcb990308eb2ac5cb2fbdeb44f6d97c-gp5t4 is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1522
Nov 14 22:14:53.686: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 delete rc e2e-test-nginx-rc --namespace=kubectl-5962'
Nov 14 22:14:53.917: INFO: stderr: ""
Nov 14 22:14:53.917: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:14:53.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5962" for this suite.
Nov 14 22:15:02.369: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:15:02.507: INFO: namespace kubectl-5962 deletion completed in 8.391870143s

• [SLOW TEST:34.546 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:15:02.515: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-7856
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Nov 14 22:15:03.622: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Nov 14 22:15:03.845: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 22:15:03.853: INFO: Number of nodes with available pods: 0
Nov 14 22:15:03.853: INFO: Node k8s-1-tdyr52fdsot3-minion-0 is running more than one daemon pod
Nov 14 22:15:05.144: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 22:15:05.479: INFO: Number of nodes with available pods: 0
Nov 14 22:15:05.479: INFO: Node k8s-1-tdyr52fdsot3-minion-0 is running more than one daemon pod
Nov 14 22:15:05.889: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 22:15:06.295: INFO: Number of nodes with available pods: 0
Nov 14 22:15:06.295: INFO: Node k8s-1-tdyr52fdsot3-minion-0 is running more than one daemon pod
Nov 14 22:15:06.857: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 22:15:06.860: INFO: Number of nodes with available pods: 0
Nov 14 22:15:06.860: INFO: Node k8s-1-tdyr52fdsot3-minion-0 is running more than one daemon pod
Nov 14 22:15:07.856: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 22:15:07.858: INFO: Number of nodes with available pods: 0
Nov 14 22:15:07.858: INFO: Node k8s-1-tdyr52fdsot3-minion-0 is running more than one daemon pod
Nov 14 22:15:08.856: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 22:15:08.859: INFO: Number of nodes with available pods: 0
Nov 14 22:15:08.859: INFO: Node k8s-1-tdyr52fdsot3-minion-0 is running more than one daemon pod
Nov 14 22:15:09.968: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 22:15:09.974: INFO: Number of nodes with available pods: 0
Nov 14 22:15:09.974: INFO: Node k8s-1-tdyr52fdsot3-minion-0 is running more than one daemon pod
Nov 14 22:15:10.890: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 22:15:10.893: INFO: Number of nodes with available pods: 0
Nov 14 22:15:10.893: INFO: Node k8s-1-tdyr52fdsot3-minion-0 is running more than one daemon pod
Nov 14 22:15:11.920: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 22:15:11.923: INFO: Number of nodes with available pods: 1
Nov 14 22:15:11.923: INFO: Node k8s-1-tdyr52fdsot3-minion-0 is running more than one daemon pod
Nov 14 22:15:12.856: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 22:15:12.859: INFO: Number of nodes with available pods: 1
Nov 14 22:15:12.859: INFO: Node k8s-1-tdyr52fdsot3-minion-0 is running more than one daemon pod
Nov 14 22:15:13.950: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 22:15:13.958: INFO: Number of nodes with available pods: 2
Nov 14 22:15:13.958: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Nov 14 22:15:14.130: INFO: Wrong image for pod: daemon-set-fb9pc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov 14 22:15:14.131: INFO: Wrong image for pod: daemon-set-fddr2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov 14 22:15:14.157: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 22:15:15.239: INFO: Wrong image for pod: daemon-set-fb9pc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov 14 22:15:15.240: INFO: Wrong image for pod: daemon-set-fddr2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov 14 22:15:15.280: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 22:15:16.225: INFO: Wrong image for pod: daemon-set-fb9pc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov 14 22:15:16.225: INFO: Wrong image for pod: daemon-set-fddr2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov 14 22:15:16.234: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 22:15:17.164: INFO: Wrong image for pod: daemon-set-fb9pc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov 14 22:15:17.165: INFO: Wrong image for pod: daemon-set-fddr2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov 14 22:15:17.169: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 22:15:18.335: INFO: Wrong image for pod: daemon-set-fb9pc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov 14 22:15:18.335: INFO: Pod daemon-set-fb9pc is not available
Nov 14 22:15:18.335: INFO: Wrong image for pod: daemon-set-fddr2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov 14 22:15:18.338: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 22:15:19.165: INFO: Pod daemon-set-dmt5t is not available
Nov 14 22:15:19.165: INFO: Wrong image for pod: daemon-set-fddr2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov 14 22:15:19.171: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 22:15:20.251: INFO: Pod daemon-set-dmt5t is not available
Nov 14 22:15:20.251: INFO: Wrong image for pod: daemon-set-fddr2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov 14 22:15:20.256: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 22:15:21.162: INFO: Pod daemon-set-dmt5t is not available
Nov 14 22:15:21.164: INFO: Wrong image for pod: daemon-set-fddr2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov 14 22:15:21.180: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 22:15:22.163: INFO: Pod daemon-set-dmt5t is not available
Nov 14 22:15:22.163: INFO: Wrong image for pod: daemon-set-fddr2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov 14 22:15:22.169: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 22:15:23.163: INFO: Pod daemon-set-dmt5t is not available
Nov 14 22:15:23.164: INFO: Wrong image for pod: daemon-set-fddr2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov 14 22:15:23.168: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 22:15:24.163: INFO: Pod daemon-set-dmt5t is not available
Nov 14 22:15:24.163: INFO: Wrong image for pod: daemon-set-fddr2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov 14 22:15:24.169: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 22:15:25.164: INFO: Pod daemon-set-dmt5t is not available
Nov 14 22:15:25.164: INFO: Wrong image for pod: daemon-set-fddr2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov 14 22:15:25.169: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 22:15:26.187: INFO: Pod daemon-set-dmt5t is not available
Nov 14 22:15:26.187: INFO: Wrong image for pod: daemon-set-fddr2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov 14 22:15:26.191: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 22:15:27.166: INFO: Pod daemon-set-dmt5t is not available
Nov 14 22:15:27.166: INFO: Wrong image for pod: daemon-set-fddr2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov 14 22:15:27.172: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 22:15:28.161: INFO: Pod daemon-set-dmt5t is not available
Nov 14 22:15:28.162: INFO: Wrong image for pod: daemon-set-fddr2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov 14 22:15:28.165: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 22:15:29.255: INFO: Pod daemon-set-dmt5t is not available
Nov 14 22:15:29.256: INFO: Wrong image for pod: daemon-set-fddr2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov 14 22:15:29.261: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 22:15:30.161: INFO: Pod daemon-set-dmt5t is not available
Nov 14 22:15:30.161: INFO: Wrong image for pod: daemon-set-fddr2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov 14 22:15:30.164: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 22:15:31.161: INFO: Wrong image for pod: daemon-set-fddr2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov 14 22:15:31.165: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 22:15:32.183: INFO: Wrong image for pod: daemon-set-fddr2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov 14 22:15:32.188: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 22:15:33.164: INFO: Wrong image for pod: daemon-set-fddr2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov 14 22:15:33.164: INFO: Pod daemon-set-fddr2 is not available
Nov 14 22:15:33.170: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 22:15:34.201: INFO: Wrong image for pod: daemon-set-fddr2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov 14 22:15:34.202: INFO: Pod daemon-set-fddr2 is not available
Nov 14 22:15:34.207: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 22:15:35.165: INFO: Wrong image for pod: daemon-set-fddr2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov 14 22:15:35.166: INFO: Pod daemon-set-fddr2 is not available
Nov 14 22:15:35.171: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 22:15:36.213: INFO: Wrong image for pod: daemon-set-fddr2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov 14 22:15:36.214: INFO: Pod daemon-set-fddr2 is not available
Nov 14 22:15:36.243: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 22:15:37.178: INFO: Wrong image for pod: daemon-set-fddr2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov 14 22:15:37.178: INFO: Pod daemon-set-fddr2 is not available
Nov 14 22:15:37.183: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 22:15:38.163: INFO: Wrong image for pod: daemon-set-fddr2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov 14 22:15:38.163: INFO: Pod daemon-set-fddr2 is not available
Nov 14 22:15:38.169: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 22:15:39.161: INFO: Wrong image for pod: daemon-set-fddr2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov 14 22:15:39.162: INFO: Pod daemon-set-fddr2 is not available
Nov 14 22:15:39.165: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 22:15:40.161: INFO: Wrong image for pod: daemon-set-fddr2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov 14 22:15:40.161: INFO: Pod daemon-set-fddr2 is not available
Nov 14 22:15:40.163: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 22:15:41.188: INFO: Wrong image for pod: daemon-set-fddr2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov 14 22:15:41.188: INFO: Pod daemon-set-fddr2 is not available
Nov 14 22:15:41.193: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 22:15:42.179: INFO: Wrong image for pod: daemon-set-fddr2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov 14 22:15:42.179: INFO: Pod daemon-set-fddr2 is not available
Nov 14 22:15:42.184: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 22:15:43.232: INFO: Wrong image for pod: daemon-set-fddr2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Nov 14 22:15:43.233: INFO: Pod daemon-set-fddr2 is not available
Nov 14 22:15:43.239: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 22:15:44.402: INFO: Pod daemon-set-rb7wj is not available
Nov 14 22:15:44.551: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Nov 14 22:15:44.554: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 22:15:44.634: INFO: Number of nodes with available pods: 1
Nov 14 22:15:44.634: INFO: Node k8s-1-tdyr52fdsot3-minion-1 is running more than one daemon pod
Nov 14 22:15:45.637: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 22:15:45.639: INFO: Number of nodes with available pods: 1
Nov 14 22:15:45.639: INFO: Node k8s-1-tdyr52fdsot3-minion-1 is running more than one daemon pod
Nov 14 22:15:46.850: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 22:15:46.854: INFO: Number of nodes with available pods: 1
Nov 14 22:15:46.854: INFO: Node k8s-1-tdyr52fdsot3-minion-1 is running more than one daemon pod
Nov 14 22:15:47.637: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 22:15:47.639: INFO: Number of nodes with available pods: 1
Nov 14 22:15:47.639: INFO: Node k8s-1-tdyr52fdsot3-minion-1 is running more than one daemon pod
Nov 14 22:15:48.954: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 22:15:48.957: INFO: Number of nodes with available pods: 1
Nov 14 22:15:48.957: INFO: Node k8s-1-tdyr52fdsot3-minion-1 is running more than one daemon pod
Nov 14 22:15:49.637: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 22:15:49.641: INFO: Number of nodes with available pods: 1
Nov 14 22:15:49.641: INFO: Node k8s-1-tdyr52fdsot3-minion-1 is running more than one daemon pod
Nov 14 22:15:50.642: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 22:15:50.706: INFO: Number of nodes with available pods: 1
Nov 14 22:15:50.706: INFO: Node k8s-1-tdyr52fdsot3-minion-1 is running more than one daemon pod
Nov 14 22:15:51.637: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 22:15:51.639: INFO: Number of nodes with available pods: 1
Nov 14 22:15:51.640: INFO: Node k8s-1-tdyr52fdsot3-minion-1 is running more than one daemon pod
Nov 14 22:15:52.672: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 22:15:52.675: INFO: Number of nodes with available pods: 1
Nov 14 22:15:52.675: INFO: Node k8s-1-tdyr52fdsot3-minion-1 is running more than one daemon pod
Nov 14 22:15:53.639: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 22:15:53.642: INFO: Number of nodes with available pods: 1
Nov 14 22:15:53.643: INFO: Node k8s-1-tdyr52fdsot3-minion-1 is running more than one daemon pod
Nov 14 22:15:54.733: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 22:15:54.738: INFO: Number of nodes with available pods: 1
Nov 14 22:15:54.738: INFO: Node k8s-1-tdyr52fdsot3-minion-1 is running more than one daemon pod
Nov 14 22:15:55.640: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 22:15:55.644: INFO: Number of nodes with available pods: 1
Nov 14 22:15:55.645: INFO: Node k8s-1-tdyr52fdsot3-minion-1 is running more than one daemon pod
Nov 14 22:15:56.716: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 22:15:56.719: INFO: Number of nodes with available pods: 1
Nov 14 22:15:56.719: INFO: Node k8s-1-tdyr52fdsot3-minion-1 is running more than one daemon pod
Nov 14 22:15:57.642: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 22:15:57.645: INFO: Number of nodes with available pods: 1
Nov 14 22:15:57.646: INFO: Node k8s-1-tdyr52fdsot3-minion-1 is running more than one daemon pod
Nov 14 22:15:59.074: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 22:15:59.077: INFO: Number of nodes with available pods: 1
Nov 14 22:15:59.077: INFO: Node k8s-1-tdyr52fdsot3-minion-1 is running more than one daemon pod
Nov 14 22:15:59.639: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 22:15:59.660: INFO: Number of nodes with available pods: 1
Nov 14 22:15:59.660: INFO: Node k8s-1-tdyr52fdsot3-minion-1 is running more than one daemon pod
Nov 14 22:16:00.669: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 22:16:00.870: INFO: Number of nodes with available pods: 2
Nov 14 22:16:00.870: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7856, will wait for the garbage collector to delete the pods
Nov 14 22:16:00.953: INFO: Deleting DaemonSet.extensions daemon-set took: 8.163147ms
Nov 14 22:16:01.853: INFO: Terminating DaemonSet.extensions daemon-set pods took: 900.312407ms
Nov 14 22:16:12.557: INFO: Number of nodes with available pods: 0
Nov 14 22:16:12.557: INFO: Number of running nodes: 0, number of available pods: 0
Nov 14 22:16:12.559: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7856/daemonsets","resourceVersion":"11539"},"items":null}

Nov 14 22:16:12.561: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7856/pods","resourceVersion":"11539"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:16:12.636: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7856" for this suite.
Nov 14 22:16:20.722: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:16:20.872: INFO: namespace daemonsets-7856 deletion completed in 8.190676589s

• [SLOW TEST:78.357 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:16:20.882: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-5489
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating service endpoint-test2 in namespace services-5489
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5489 to expose endpoints map[]
Nov 14 22:16:21.787: INFO: successfully validated that service endpoint-test2 in namespace services-5489 exposes endpoints map[] (113.774938ms elapsed)
STEP: Creating pod pod1 in namespace services-5489
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5489 to expose endpoints map[pod1:[80]]
Nov 14 22:16:25.393: INFO: successfully validated that service endpoint-test2 in namespace services-5489 exposes endpoints map[pod1:[80]] (3.561150653s elapsed)
STEP: Creating pod pod2 in namespace services-5489
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5489 to expose endpoints map[pod1:[80] pod2:[80]]
Nov 14 22:16:29.729: INFO: Unexpected endpoints: found map[a1a41a2f-7cf8-4523-bbd9-9588664cffb4:[80]], expected map[pod1:[80] pod2:[80]] (4.327539944s elapsed, will retry)
Nov 14 22:16:30.742: INFO: successfully validated that service endpoint-test2 in namespace services-5489 exposes endpoints map[pod1:[80] pod2:[80]] (5.340572997s elapsed)
STEP: Deleting pod pod1 in namespace services-5489
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5489 to expose endpoints map[pod2:[80]]
Nov 14 22:16:31.838: INFO: successfully validated that service endpoint-test2 in namespace services-5489 exposes endpoints map[pod2:[80]] (1.091192153s elapsed)
STEP: Deleting pod pod2 in namespace services-5489
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5489 to expose endpoints map[]
Nov 14 22:16:32.251: INFO: successfully validated that service endpoint-test2 in namespace services-5489 exposes endpoints map[] (406.069413ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:16:33.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5489" for this suite.
Nov 14 22:16:42.339: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:16:42.740: INFO: namespace services-5489 deletion completed in 9.218022852s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:21.859 seconds]
[sig-network] Services
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:16:42.741: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-1949
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Nov 14 22:17:11.813: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 14 22:17:11.959: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 14 22:17:13.959: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 14 22:17:13.964: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 14 22:17:15.959: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 14 22:17:15.963: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 14 22:17:17.959: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 14 22:17:18.230: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 14 22:17:19.959: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 14 22:17:19.963: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 14 22:17:21.959: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 14 22:17:21.962: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 14 22:17:23.959: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 14 22:17:23.966: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 14 22:17:25.959: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 14 22:17:25.962: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 14 22:17:27.959: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 14 22:17:28.158: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 14 22:17:29.959: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 14 22:17:30.304: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 14 22:17:31.959: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 14 22:17:31.962: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 14 22:17:33.959: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 14 22:17:34.527: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:17:34.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-1949" for this suite.
Nov 14 22:17:58.637: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:17:58.886: INFO: namespace container-lifecycle-hook-1949 deletion completed in 24.349705279s

• [SLOW TEST:76.145 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:17:58.892: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-1531
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override all
Nov 14 22:17:59.279: INFO: Waiting up to 5m0s for pod "client-containers-351495b2-4782-4869-929f-105b382e52a9" in namespace "containers-1531" to be "success or failure"
Nov 14 22:17:59.302: INFO: Pod "client-containers-351495b2-4782-4869-929f-105b382e52a9": Phase="Pending", Reason="", readiness=false. Elapsed: 22.994921ms
Nov 14 22:18:01.478: INFO: Pod "client-containers-351495b2-4782-4869-929f-105b382e52a9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.198984275s
Nov 14 22:18:03.484: INFO: Pod "client-containers-351495b2-4782-4869-929f-105b382e52a9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.205017972s
Nov 14 22:18:05.488: INFO: Pod "client-containers-351495b2-4782-4869-929f-105b382e52a9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.208578139s
Nov 14 22:18:07.516: INFO: Pod "client-containers-351495b2-4782-4869-929f-105b382e52a9": Phase="Pending", Reason="", readiness=false. Elapsed: 8.236915328s
Nov 14 22:18:09.521: INFO: Pod "client-containers-351495b2-4782-4869-929f-105b382e52a9": Phase="Pending", Reason="", readiness=false. Elapsed: 10.241879888s
Nov 14 22:18:11.526: INFO: Pod "client-containers-351495b2-4782-4869-929f-105b382e52a9": Phase="Pending", Reason="", readiness=false. Elapsed: 12.247164121s
Nov 14 22:18:13.532: INFO: Pod "client-containers-351495b2-4782-4869-929f-105b382e52a9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 14.253279103s
STEP: Saw pod success
Nov 14 22:18:13.534: INFO: Pod "client-containers-351495b2-4782-4869-929f-105b382e52a9" satisfied condition "success or failure"
Nov 14 22:18:13.538: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-0 pod client-containers-351495b2-4782-4869-929f-105b382e52a9 container test-container: <nil>
STEP: delete the pod
Nov 14 22:18:13.662: INFO: Waiting for pod client-containers-351495b2-4782-4869-929f-105b382e52a9 to disappear
Nov 14 22:18:13.689: INFO: Pod client-containers-351495b2-4782-4869-929f-105b382e52a9 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:18:13.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-1531" for this suite.
Nov 14 22:18:19.811: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:18:20.158: INFO: namespace containers-1531 deletion completed in 6.459521232s

• [SLOW TEST:21.267 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:18:20.160: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2673
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1685
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Nov 14 22:18:20.878: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-2673'
Nov 14 22:18:24.641: INFO: stderr: ""
Nov 14 22:18:24.642: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1690
Nov 14 22:18:24.662: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 delete pods e2e-test-nginx-pod --namespace=kubectl-2673'
Nov 14 22:18:29.062: INFO: stderr: ""
Nov 14 22:18:29.062: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:18:29.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2673" for this suite.
Nov 14 22:18:35.123: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:18:35.414: INFO: namespace kubectl-2673 deletion completed in 6.344216621s

• [SLOW TEST:15.255 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:18:35.419: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9985
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting the proxy server
Nov 14 22:18:36.115: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-216763962 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:18:37.103: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9985" for this suite.
Nov 14 22:18:43.586: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:18:43.822: INFO: namespace kubectl-9985 deletion completed in 6.500327419s

• [SLOW TEST:8.403 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:18:43.831: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-3543
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test substitution in container's command
Nov 14 22:18:44.459: INFO: Waiting up to 5m0s for pod "var-expansion-e665ead6-5530-44f2-b956-c4e54a796c26" in namespace "var-expansion-3543" to be "success or failure"
Nov 14 22:18:44.521: INFO: Pod "var-expansion-e665ead6-5530-44f2-b956-c4e54a796c26": Phase="Pending", Reason="", readiness=false. Elapsed: 60.880598ms
Nov 14 22:18:46.525: INFO: Pod "var-expansion-e665ead6-5530-44f2-b956-c4e54a796c26": Phase="Pending", Reason="", readiness=false. Elapsed: 2.065604611s
Nov 14 22:18:49.493: INFO: Pod "var-expansion-e665ead6-5530-44f2-b956-c4e54a796c26": Phase="Pending", Reason="", readiness=false. Elapsed: 5.033272192s
Nov 14 22:18:51.498: INFO: Pod "var-expansion-e665ead6-5530-44f2-b956-c4e54a796c26": Phase="Pending", Reason="", readiness=false. Elapsed: 7.038238398s
Nov 14 22:18:53.502: INFO: Pod "var-expansion-e665ead6-5530-44f2-b956-c4e54a796c26": Phase="Pending", Reason="", readiness=false. Elapsed: 9.042068824s
Nov 14 22:18:55.528: INFO: Pod "var-expansion-e665ead6-5530-44f2-b956-c4e54a796c26": Phase="Pending", Reason="", readiness=false. Elapsed: 11.068138692s
Nov 14 22:18:58.223: INFO: Pod "var-expansion-e665ead6-5530-44f2-b956-c4e54a796c26": Phase="Succeeded", Reason="", readiness=false. Elapsed: 13.763685044s
STEP: Saw pod success
Nov 14 22:18:58.224: INFO: Pod "var-expansion-e665ead6-5530-44f2-b956-c4e54a796c26" satisfied condition "success or failure"
Nov 14 22:18:58.766: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-0 pod var-expansion-e665ead6-5530-44f2-b956-c4e54a796c26 container dapi-container: <nil>
STEP: delete the pod
Nov 14 22:18:59.378: INFO: Waiting for pod var-expansion-e665ead6-5530-44f2-b956-c4e54a796c26 to disappear
Nov 14 22:18:59.592: INFO: Pod var-expansion-e665ead6-5530-44f2-b956-c4e54a796c26 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:18:59.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-3543" for this suite.
Nov 14 22:19:05.671: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:19:05.865: INFO: namespace var-expansion-3543 deletion completed in 6.264865226s

• [SLOW TEST:22.034 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:19:05.869: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8467
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on tmpfs
Nov 14 22:19:06.419: INFO: Waiting up to 5m0s for pod "pod-2efe1e90-e3b3-417b-8b36-2f534b8e8948" in namespace "emptydir-8467" to be "success or failure"
Nov 14 22:19:06.479: INFO: Pod "pod-2efe1e90-e3b3-417b-8b36-2f534b8e8948": Phase="Pending", Reason="", readiness=false. Elapsed: 59.911734ms
Nov 14 22:19:08.485: INFO: Pod "pod-2efe1e90-e3b3-417b-8b36-2f534b8e8948": Phase="Pending", Reason="", readiness=false. Elapsed: 2.065967078s
Nov 14 22:19:10.660: INFO: Pod "pod-2efe1e90-e3b3-417b-8b36-2f534b8e8948": Phase="Pending", Reason="", readiness=false. Elapsed: 4.24088693s
Nov 14 22:19:12.810: INFO: Pod "pod-2efe1e90-e3b3-417b-8b36-2f534b8e8948": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.390867046s
STEP: Saw pod success
Nov 14 22:19:12.811: INFO: Pod "pod-2efe1e90-e3b3-417b-8b36-2f534b8e8948" satisfied condition "success or failure"
Nov 14 22:19:12.813: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-0 pod pod-2efe1e90-e3b3-417b-8b36-2f534b8e8948 container test-container: <nil>
STEP: delete the pod
Nov 14 22:19:12.874: INFO: Waiting for pod pod-2efe1e90-e3b3-417b-8b36-2f534b8e8948 to disappear
Nov 14 22:19:12.894: INFO: Pod pod-2efe1e90-e3b3-417b-8b36-2f534b8e8948 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:19:12.895: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8467" for this suite.
Nov 14 22:19:18.999: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:19:19.110: INFO: namespace emptydir-8467 deletion completed in 6.21046017s

• [SLOW TEST:13.243 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:19:19.119: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-1555
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Nov 14 22:19:23.934: INFO: Waiting up to 5m0s for pod "client-envvars-94c002ac-0813-4766-b3f1-f0fdb9dfeaf3" in namespace "pods-1555" to be "success or failure"
Nov 14 22:19:23.976: INFO: Pod "client-envvars-94c002ac-0813-4766-b3f1-f0fdb9dfeaf3": Phase="Pending", Reason="", readiness=false. Elapsed: 42.108843ms
Nov 14 22:19:25.980: INFO: Pod "client-envvars-94c002ac-0813-4766-b3f1-f0fdb9dfeaf3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.046232119s
Nov 14 22:19:29.525: INFO: Pod "client-envvars-94c002ac-0813-4766-b3f1-f0fdb9dfeaf3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.591407525s
Nov 14 22:19:31.529: INFO: Pod "client-envvars-94c002ac-0813-4766-b3f1-f0fdb9dfeaf3": Phase="Pending", Reason="", readiness=false. Elapsed: 7.594801929s
Nov 14 22:19:33.899: INFO: Pod "client-envvars-94c002ac-0813-4766-b3f1-f0fdb9dfeaf3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 9.964715405s
STEP: Saw pod success
Nov 14 22:19:33.899: INFO: Pod "client-envvars-94c002ac-0813-4766-b3f1-f0fdb9dfeaf3" satisfied condition "success or failure"
Nov 14 22:19:33.961: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-1 pod client-envvars-94c002ac-0813-4766-b3f1-f0fdb9dfeaf3 container env3cont: <nil>
STEP: delete the pod
Nov 14 22:19:34.239: INFO: Waiting for pod client-envvars-94c002ac-0813-4766-b3f1-f0fdb9dfeaf3 to disappear
Nov 14 22:19:34.288: INFO: Pod client-envvars-94c002ac-0813-4766-b3f1-f0fdb9dfeaf3 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:19:34.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1555" for this suite.
Nov 14 22:20:16.732: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:20:16.897: INFO: namespace pods-1555 deletion completed in 42.602047802s

• [SLOW TEST:57.778 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:20:16.903: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2343
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-69da13ad-ad4c-44ef-93c5-44d970558b31
STEP: Creating a pod to test consume secrets
Nov 14 22:20:17.508: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-49fdf34d-2095-42af-9b2c-6fbcca3b5e73" in namespace "projected-2343" to be "success or failure"
Nov 14 22:20:17.549: INFO: Pod "pod-projected-secrets-49fdf34d-2095-42af-9b2c-6fbcca3b5e73": Phase="Pending", Reason="", readiness=false. Elapsed: 40.389952ms
Nov 14 22:20:19.576: INFO: Pod "pod-projected-secrets-49fdf34d-2095-42af-9b2c-6fbcca3b5e73": Phase="Pending", Reason="", readiness=false. Elapsed: 2.068240853s
Nov 14 22:20:21.582: INFO: Pod "pod-projected-secrets-49fdf34d-2095-42af-9b2c-6fbcca3b5e73": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.074294282s
STEP: Saw pod success
Nov 14 22:20:21.583: INFO: Pod "pod-projected-secrets-49fdf34d-2095-42af-9b2c-6fbcca3b5e73" satisfied condition "success or failure"
Nov 14 22:20:21.784: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-1 pod pod-projected-secrets-49fdf34d-2095-42af-9b2c-6fbcca3b5e73 container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov 14 22:20:22.144: INFO: Waiting for pod pod-projected-secrets-49fdf34d-2095-42af-9b2c-6fbcca3b5e73 to disappear
Nov 14 22:20:22.233: INFO: Pod pod-projected-secrets-49fdf34d-2095-42af-9b2c-6fbcca3b5e73 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:20:22.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2343" for this suite.
Nov 14 22:20:30.893: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:20:31.034: INFO: namespace projected-2343 deletion completed in 8.607012694s

• [SLOW TEST:14.132 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:20:31.038: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-8113
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Nov 14 22:20:31.557: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov 14 22:20:31.701: INFO: Waiting for terminating namespaces to be deleted...
Nov 14 22:20:31.713: INFO: 
Logging pods the kubelet thinks is on node k8s-1-tdyr52fdsot3-minion-0 before test
Nov 14 22:20:31.756: INFO: calico-node-pd87t from kube-system started at 2019-11-14 21:02:40 +0000 UTC (2 container statuses recorded)
Nov 14 22:20:31.757: INFO: 	Container calico-node ready: true, restart count 0
Nov 14 22:20:31.757: INFO: 	Container install-cni ready: true, restart count 0
Nov 14 22:20:31.758: INFO: coredns-ffc7449c-87zqg from kube-system started at 2019-11-14 21:03:34 +0000 UTC (1 container statuses recorded)
Nov 14 22:20:31.758: INFO: 	Container coredns ready: true, restart count 0
Nov 14 22:20:31.759: INFO: kube-dns-autoscaler-6d5d44bf86-j5ft5 from kube-system started at 2019-11-14 21:03:34 +0000 UTC (1 container statuses recorded)
Nov 14 22:20:31.759: INFO: 	Container autoscaler ready: true, restart count 0
Nov 14 22:20:31.760: INFO: coredns-ffc7449c-gjzvx from kube-system started at 2019-11-14 21:03:36 +0000 UTC (1 container statuses recorded)
Nov 14 22:20:31.760: INFO: 	Container coredns ready: true, restart count 0
Nov 14 22:20:31.760: INFO: heapster-868bbf8578-n64qw from kube-system started at 2019-11-14 21:03:34 +0000 UTC (1 container statuses recorded)
Nov 14 22:20:31.760: INFO: 	Container heapster ready: true, restart count 0
Nov 14 22:20:31.760: INFO: kubernetes-dashboard-6bcf74b4cd-6xg4w from kube-system started at 2019-11-14 21:03:35 +0000 UTC (1 container statuses recorded)
Nov 14 22:20:31.760: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Nov 14 22:20:31.761: INFO: sonobuoy-systemd-logs-daemon-set-72adb34422cf47dd-jsls8 from sonobuoy started at 2019-11-14 21:44:03 +0000 UTC (2 container statuses recorded)
Nov 14 22:20:31.761: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 14 22:20:31.761: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 14 22:20:31.761: INFO: 
Logging pods the kubelet thinks is on node k8s-1-tdyr52fdsot3-minion-1 before test
Nov 14 22:20:31.905: INFO: sonobuoy from sonobuoy started at 2019-11-14 21:43:40 +0000 UTC (1 container statuses recorded)
Nov 14 22:20:31.905: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov 14 22:20:31.906: INFO: sonobuoy-e2e-job-bf04e2a15c5e4b97 from sonobuoy started at 2019-11-14 21:44:02 +0000 UTC (2 container statuses recorded)
Nov 14 22:20:31.906: INFO: 	Container e2e ready: true, restart count 0
Nov 14 22:20:31.906: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 14 22:20:31.907: INFO: sonobuoy-systemd-logs-daemon-set-72adb34422cf47dd-v5lkx from sonobuoy started at 2019-11-14 21:44:04 +0000 UTC (2 container statuses recorded)
Nov 14 22:20:31.907: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 14 22:20:31.907: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 14 22:20:31.907: INFO: calico-node-xt7x6 from kube-system started at 2019-11-14 21:40:55 +0000 UTC (2 container statuses recorded)
Nov 14 22:20:31.907: INFO: 	Container calico-node ready: true, restart count 0
Nov 14 22:20:31.907: INFO: 	Container install-cni ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15d727815f702af9], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:20:33.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-8113" for this suite.
Nov 14 22:20:39.682: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:20:40.369: INFO: namespace sched-pred-8113 deletion completed in 7.197591886s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:9.332 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:20:40.371: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-1815
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-0d2682d1-36ef-4519-b622-a433f0a121e1
STEP: Creating a pod to test consume secrets
Nov 14 22:20:42.123: INFO: Waiting up to 5m0s for pod "pod-secrets-d3c1cf37-0f35-4724-8b84-da6fb2d42f9f" in namespace "secrets-1815" to be "success or failure"
Nov 14 22:20:42.151: INFO: Pod "pod-secrets-d3c1cf37-0f35-4724-8b84-da6fb2d42f9f": Phase="Pending", Reason="", readiness=false. Elapsed: 27.73868ms
Nov 14 22:20:44.164: INFO: Pod "pod-secrets-d3c1cf37-0f35-4724-8b84-da6fb2d42f9f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041465318s
Nov 14 22:20:46.229: INFO: Pod "pod-secrets-d3c1cf37-0f35-4724-8b84-da6fb2d42f9f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.106092279s
Nov 14 22:20:48.234: INFO: Pod "pod-secrets-d3c1cf37-0f35-4724-8b84-da6fb2d42f9f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.110840067s
Nov 14 22:20:50.457: INFO: Pod "pod-secrets-d3c1cf37-0f35-4724-8b84-da6fb2d42f9f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.333914401s
STEP: Saw pod success
Nov 14 22:20:50.458: INFO: Pod "pod-secrets-d3c1cf37-0f35-4724-8b84-da6fb2d42f9f" satisfied condition "success or failure"
Nov 14 22:20:50.460: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-1 pod pod-secrets-d3c1cf37-0f35-4724-8b84-da6fb2d42f9f container secret-volume-test: <nil>
STEP: delete the pod
Nov 14 22:20:50.539: INFO: Waiting for pod pod-secrets-d3c1cf37-0f35-4724-8b84-da6fb2d42f9f to disappear
Nov 14 22:20:50.757: INFO: Pod pod-secrets-d3c1cf37-0f35-4724-8b84-da6fb2d42f9f no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:20:50.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1815" for this suite.
Nov 14 22:20:58.841: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:20:59.875: INFO: namespace secrets-1815 deletion completed in 9.113125055s

• [SLOW TEST:19.505 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:20:59.883: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7231
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name cm-test-opt-del-94e9eb22-adff-475a-afa8-a0b0fcf487b4
STEP: Creating configMap with name cm-test-opt-upd-ff8a860a-fe88-45b9-a938-424835a510a2
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-94e9eb22-adff-475a-afa8-a0b0fcf487b4
STEP: Updating configmap cm-test-opt-upd-ff8a860a-fe88-45b9-a938-424835a510a2
STEP: Creating configMap with name cm-test-opt-create-b8df55c7-cafe-41d5-987c-0a4f190359ac
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:21:22.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7231" for this suite.
Nov 14 22:21:52.298: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:21:52.447: INFO: namespace configmap-7231 deletion completed in 30.260161539s

• [SLOW TEST:52.564 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:21:52.452: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3030
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-c1294a72-2e7a-43f6-bf6c-069a108e8abe
STEP: Creating a pod to test consume secrets
Nov 14 22:21:53.058: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-78c220c6-85d1-4d1c-a0ac-616ba64f3999" in namespace "projected-3030" to be "success or failure"
Nov 14 22:21:53.083: INFO: Pod "pod-projected-secrets-78c220c6-85d1-4d1c-a0ac-616ba64f3999": Phase="Pending", Reason="", readiness=false. Elapsed: 24.646676ms
Nov 14 22:21:55.370: INFO: Pod "pod-projected-secrets-78c220c6-85d1-4d1c-a0ac-616ba64f3999": Phase="Pending", Reason="", readiness=false. Elapsed: 2.311632405s
Nov 14 22:21:57.376: INFO: Pod "pod-projected-secrets-78c220c6-85d1-4d1c-a0ac-616ba64f3999": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.317498604s
STEP: Saw pod success
Nov 14 22:21:57.376: INFO: Pod "pod-projected-secrets-78c220c6-85d1-4d1c-a0ac-616ba64f3999" satisfied condition "success or failure"
Nov 14 22:21:57.687: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-1 pod pod-projected-secrets-78c220c6-85d1-4d1c-a0ac-616ba64f3999 container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov 14 22:21:58.394: INFO: Waiting for pod pod-projected-secrets-78c220c6-85d1-4d1c-a0ac-616ba64f3999 to disappear
Nov 14 22:21:58.426: INFO: Pod pod-projected-secrets-78c220c6-85d1-4d1c-a0ac-616ba64f3999 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:21:58.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3030" for this suite.
Nov 14 22:22:04.482: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:22:04.625: INFO: namespace projected-3030 deletion completed in 6.193605278s

• [SLOW TEST:12.173 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:22:04.629: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8761
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name projected-secret-test-67e499f1-05cb-45d8-ad65-0268bb636b0f
STEP: Creating a pod to test consume secrets
Nov 14 22:22:05.275: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-becca08c-a8b6-47a2-b977-0e221328c025" in namespace "projected-8761" to be "success or failure"
Nov 14 22:22:05.302: INFO: Pod "pod-projected-secrets-becca08c-a8b6-47a2-b977-0e221328c025": Phase="Pending", Reason="", readiness=false. Elapsed: 26.410366ms
Nov 14 22:22:07.306: INFO: Pod "pod-projected-secrets-becca08c-a8b6-47a2-b977-0e221328c025": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030815651s
Nov 14 22:22:09.325: INFO: Pod "pod-projected-secrets-becca08c-a8b6-47a2-b977-0e221328c025": Phase="Pending", Reason="", readiness=false. Elapsed: 4.049791475s
Nov 14 22:22:11.332: INFO: Pod "pod-projected-secrets-becca08c-a8b6-47a2-b977-0e221328c025": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.057209972s
STEP: Saw pod success
Nov 14 22:22:11.333: INFO: Pod "pod-projected-secrets-becca08c-a8b6-47a2-b977-0e221328c025" satisfied condition "success or failure"
Nov 14 22:22:11.336: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-0 pod pod-projected-secrets-becca08c-a8b6-47a2-b977-0e221328c025 container secret-volume-test: <nil>
STEP: delete the pod
Nov 14 22:22:11.635: INFO: Waiting for pod pod-projected-secrets-becca08c-a8b6-47a2-b977-0e221328c025 to disappear
Nov 14 22:22:11.833: INFO: Pod pod-projected-secrets-becca08c-a8b6-47a2-b977-0e221328c025 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:22:11.834: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8761" for this suite.
Nov 14 22:22:17.932: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:22:18.147: INFO: namespace projected-8761 deletion completed in 6.305283889s

• [SLOW TEST:13.519 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:22:18.153: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6564
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Nov 14 22:22:18.611: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 create -f - --namespace=kubectl-6564'
Nov 14 22:22:20.633: INFO: stderr: ""
Nov 14 22:22:20.633: INFO: stdout: "replicationcontroller/redis-master created\n"
Nov 14 22:22:20.633: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 create -f - --namespace=kubectl-6564'
Nov 14 22:22:21.391: INFO: stderr: ""
Nov 14 22:22:21.391: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Nov 14 22:22:22.559: INFO: Selector matched 1 pods for map[app:redis]
Nov 14 22:22:22.559: INFO: Found 0 / 1
Nov 14 22:22:23.398: INFO: Selector matched 1 pods for map[app:redis]
Nov 14 22:22:23.398: INFO: Found 0 / 1
Nov 14 22:22:24.633: INFO: Selector matched 1 pods for map[app:redis]
Nov 14 22:22:24.634: INFO: Found 0 / 1
Nov 14 22:22:25.486: INFO: Selector matched 1 pods for map[app:redis]
Nov 14 22:22:25.486: INFO: Found 0 / 1
Nov 14 22:22:26.412: INFO: Selector matched 1 pods for map[app:redis]
Nov 14 22:22:26.412: INFO: Found 1 / 1
Nov 14 22:22:26.413: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Nov 14 22:22:26.417: INFO: Selector matched 1 pods for map[app:redis]
Nov 14 22:22:26.417: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Nov 14 22:22:26.417: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 describe pod redis-master-d4ql6 --namespace=kubectl-6564'
Nov 14 22:22:26.597: INFO: stderr: ""
Nov 14 22:22:26.597: INFO: stdout: "Name:           redis-master-d4ql6\nNamespace:      kubectl-6564\nNode:           k8s-1-tdyr52fdsot3-minion-1/10.0.0.152\nStart Time:     Thu, 14 Nov 2019 22:22:20 +0000\nLabels:         app=redis\n                role=master\nAnnotations:    cni.projectcalico.org/podIP: 192.168.2.42/32\nStatus:         Running\nIP:             192.168.2.42\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://6ab54b93302b4b512f11790614412b6fd55224c5209bb421d1c7c6b8d2356714\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Thu, 14 Nov 2019 22:22:25 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-rx5lt (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-rx5lt:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-rx5lt\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                  Message\n  ----    ------     ----  ----                                  -------\n  Normal  Scheduled  6s    default-scheduler                     Successfully assigned kubectl-6564/redis-master-d4ql6 to k8s-1-tdyr52fdsot3-minion-1\n  Normal  Pulled     3s    kubelet, k8s-1-tdyr52fdsot3-minion-1  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    2s    kubelet, k8s-1-tdyr52fdsot3-minion-1  Created container redis-master\n  Normal  Started    1s    kubelet, k8s-1-tdyr52fdsot3-minion-1  Started container redis-master\n"
Nov 14 22:22:26.597: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 describe rc redis-master --namespace=kubectl-6564'
Nov 14 22:22:26.735: INFO: stderr: ""
Nov 14 22:22:26.735: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-6564\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  7s    replication-controller  Created pod: redis-master-d4ql6\n"
Nov 14 22:22:26.735: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 describe service redis-master --namespace=kubectl-6564'
Nov 14 22:22:26.883: INFO: stderr: ""
Nov 14 22:22:26.883: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-6564\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.254.6.193\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         192.168.2.42:6379\nSession Affinity:  None\nEvents:            <none>\n"
Nov 14 22:22:26.888: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 describe node k8s-1-tdyr52fdsot3-master-0'
Nov 14 22:22:27.050: INFO: stderr: ""
Nov 14 22:22:27.051: INFO: stdout: "Name:               k8s-1-tdyr52fdsot3-master-0\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=d3\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=RegionOne\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=k8s-1-tdyr52fdsot3-master-0\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/master=\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 10.0.0.251/24\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Thu, 14 Nov 2019 20:53:15 +0000\nTaints:             CriticalAddonsOnly=True:NoSchedule\n                    dedicated=master:NoSchedule\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Thu, 14 Nov 2019 22:21:56 +0000   Thu, 14 Nov 2019 20:53:15 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Thu, 14 Nov 2019 22:21:56 +0000   Thu, 14 Nov 2019 20:53:15 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Thu, 14 Nov 2019 22:21:56 +0000   Thu, 14 Nov 2019 20:53:15 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Thu, 14 Nov 2019 22:21:56 +0000   Thu, 14 Nov 2019 20:56:18 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  10.0.0.251\n  ExternalIP:  172.24.4.86\nCapacity:\n cpu:                2\n ephemeral-storage:  9202Mi\n hugepages-2Mi:      0\n memory:             2038204Ki\n pods:               110\nAllocatable:\n cpu:                2\n ephemeral-storage:  8684096703\n hugepages-2Mi:      0\n memory:             1935804Ki\n pods:               110\nSystem Info:\n Machine ID:                 311936e2303b034fe7ef70182235b8cb\n System UUID:                e945dcfa-81d7-4efa-a1fb-90bfd7641bdf\n Boot ID:                    dfb52453-b1be-45b9-9b03-277383d8500d\n Kernel Version:             5.2.7-100.fc29.x86_64\n OS Image:                   Fedora 29.20190820.0 (Atomic Host)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://1.13.1\n Kubelet Version:            v1.15.5\n Kube-Proxy Version:         v1.15.5\nPodCIDR:                     192.168.0.0/24\nProviderID:                  openstack:///e945dcfa-81d7-4efa-a1fb-90bfd7641bdf\nNon-terminated Pods:         (4 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                calico-node-w5ng4                                          250m (12%)    0 (0%)      0 (0%)           0 (0%)         88m\n  kube-system                k8s-keystone-auth-h2swj                                    200m (10%)    0 (0%)      0 (0%)           0 (0%)         87m\n  kube-system                openstack-cloud-controller-manager-d6lbk                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         86m\n  sonobuoy                   sonobuoy-systemd-logs-daemon-set-72adb34422cf47dd-c2bk7    0 (0%)        0 (0%)      0 (0%)           0 (0%)         38m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                450m (22%)  0 (0%)\n  memory             0 (0%)      0 (0%)\n  ephemeral-storage  0 (0%)      0 (0%)\nEvents:              <none>\n"
Nov 14 22:22:27.077: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 describe namespace kubectl-6564'
Nov 14 22:22:27.192: INFO: stderr: ""
Nov 14 22:22:27.192: INFO: stdout: "Name:         kubectl-6564\nLabels:       e2e-framework=kubectl\n              e2e-run=da23674e-9498-42c0-b428-9abdf9bb8dec\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:22:27.192: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6564" for this suite.
Nov 14 22:22:49.503: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:22:49.762: INFO: namespace kubectl-6564 deletion completed in 22.566586146s

• [SLOW TEST:31.610 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl describe
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:22:49.778: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-4570
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test env composition
Nov 14 22:22:50.194: INFO: Waiting up to 5m0s for pod "var-expansion-73d8b2a5-0622-47aa-884e-62ee0b967303" in namespace "var-expansion-4570" to be "success or failure"
Nov 14 22:22:50.240: INFO: Pod "var-expansion-73d8b2a5-0622-47aa-884e-62ee0b967303": Phase="Pending", Reason="", readiness=false. Elapsed: 45.385929ms
Nov 14 22:22:52.244: INFO: Pod "var-expansion-73d8b2a5-0622-47aa-884e-62ee0b967303": Phase="Pending", Reason="", readiness=false. Elapsed: 2.049764798s
Nov 14 22:22:54.248: INFO: Pod "var-expansion-73d8b2a5-0622-47aa-884e-62ee0b967303": Phase="Pending", Reason="", readiness=false. Elapsed: 4.053984212s
Nov 14 22:22:56.267: INFO: Pod "var-expansion-73d8b2a5-0622-47aa-884e-62ee0b967303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.072839675s
STEP: Saw pod success
Nov 14 22:22:56.268: INFO: Pod "var-expansion-73d8b2a5-0622-47aa-884e-62ee0b967303" satisfied condition "success or failure"
Nov 14 22:22:56.301: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-0 pod var-expansion-73d8b2a5-0622-47aa-884e-62ee0b967303 container dapi-container: <nil>
STEP: delete the pod
Nov 14 22:22:56.482: INFO: Waiting for pod var-expansion-73d8b2a5-0622-47aa-884e-62ee0b967303 to disappear
Nov 14 22:22:56.603: INFO: Pod var-expansion-73d8b2a5-0622-47aa-884e-62ee0b967303 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:22:56.604: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4570" for this suite.
Nov 14 22:23:02.711: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:23:02.953: INFO: namespace var-expansion-4570 deletion completed in 6.29324741s

• [SLOW TEST:13.176 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:23:02.999: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3377
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: executing a command with run --rm and attach with stdin
Nov 14 22:23:03.299: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 --namespace=kubectl-3377 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Nov 14 22:23:09.549: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Nov 14 22:23:09.549: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:23:11.557: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3377" for this suite.
Nov 14 22:23:19.830: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:23:20.110: INFO: namespace kubectl-3377 deletion completed in 8.537655857s

• [SLOW TEST:17.111 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:23:20.116: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9147
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Nov 14 22:23:27.337: INFO: Successfully updated pod "labelsupdateb1790d28-0dac-47fc-bbe0-438183b107b3"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:23:29.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9147" for this suite.
Nov 14 22:23:47.983: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:23:48.569: INFO: namespace downward-api-9147 deletion completed in 18.823466849s

• [SLOW TEST:28.454 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:23:48.576: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6019
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on tmpfs
Nov 14 22:23:49.719: INFO: Waiting up to 5m0s for pod "pod-6da13c89-cd14-4fa4-9170-ec119ea072f8" in namespace "emptydir-6019" to be "success or failure"
Nov 14 22:23:49.776: INFO: Pod "pod-6da13c89-cd14-4fa4-9170-ec119ea072f8": Phase="Pending", Reason="", readiness=false. Elapsed: 56.207943ms
Nov 14 22:23:52.426: INFO: Pod "pod-6da13c89-cd14-4fa4-9170-ec119ea072f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.706262843s
Nov 14 22:23:54.473: INFO: Pod "pod-6da13c89-cd14-4fa4-9170-ec119ea072f8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.753524564s
Nov 14 22:23:56.477: INFO: Pod "pod-6da13c89-cd14-4fa4-9170-ec119ea072f8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.756683029s
Nov 14 22:23:58.506: INFO: Pod "pod-6da13c89-cd14-4fa4-9170-ec119ea072f8": Phase="Pending", Reason="", readiness=false. Elapsed: 8.786001941s
Nov 14 22:24:00.509: INFO: Pod "pod-6da13c89-cd14-4fa4-9170-ec119ea072f8": Phase="Pending", Reason="", readiness=false. Elapsed: 10.78961234s
Nov 14 22:24:02.513: INFO: Pod "pod-6da13c89-cd14-4fa4-9170-ec119ea072f8": Phase="Pending", Reason="", readiness=false. Elapsed: 12.792821607s
Nov 14 22:24:04.516: INFO: Pod "pod-6da13c89-cd14-4fa4-9170-ec119ea072f8": Phase="Pending", Reason="", readiness=false. Elapsed: 14.796152895s
Nov 14 22:24:06.520: INFO: Pod "pod-6da13c89-cd14-4fa4-9170-ec119ea072f8": Phase="Pending", Reason="", readiness=false. Elapsed: 16.799771032s
Nov 14 22:24:08.526: INFO: Pod "pod-6da13c89-cd14-4fa4-9170-ec119ea072f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 18.806071604s
STEP: Saw pod success
Nov 14 22:24:08.526: INFO: Pod "pod-6da13c89-cd14-4fa4-9170-ec119ea072f8" satisfied condition "success or failure"
Nov 14 22:24:08.531: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-1 pod pod-6da13c89-cd14-4fa4-9170-ec119ea072f8 container test-container: <nil>
STEP: delete the pod
Nov 14 22:24:08.716: INFO: Waiting for pod pod-6da13c89-cd14-4fa4-9170-ec119ea072f8 to disappear
Nov 14 22:24:08.741: INFO: Pod pod-6da13c89-cd14-4fa4-9170-ec119ea072f8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:24:08.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6019" for this suite.
Nov 14 22:24:14.887: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:24:15.618: INFO: namespace emptydir-6019 deletion completed in 6.870125304s

• [SLOW TEST:27.043 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:24:15.626: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svc-latency-609
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating replication controller svc-latency-rc in namespace svc-latency-609
I1114 22:24:16.332182      13 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: svc-latency-609, replica count: 1
I1114 22:24:17.384281      13 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1114 22:24:18.384823      13 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1114 22:24:19.385308      13 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1114 22:24:20.385779      13 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1114 22:24:21.386329      13 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov 14 22:24:21.813: INFO: Created: latency-svc-dc7fp
Nov 14 22:24:22.055: INFO: Got endpoints: latency-svc-dc7fp [453.925854ms]
Nov 14 22:24:22.230: INFO: Created: latency-svc-5xpt6
Nov 14 22:24:22.288: INFO: Got endpoints: latency-svc-5xpt6 [227.575928ms]
Nov 14 22:24:22.292: INFO: Created: latency-svc-kwvzn
Nov 14 22:24:22.432: INFO: Got endpoints: latency-svc-kwvzn [371.087657ms]
Nov 14 22:24:22.444: INFO: Created: latency-svc-7tzdn
Nov 14 22:24:22.465: INFO: Got endpoints: latency-svc-7tzdn [403.534455ms]
Nov 14 22:24:22.512: INFO: Created: latency-svc-5lpw2
Nov 14 22:24:22.684: INFO: Got endpoints: latency-svc-5lpw2 [629.187362ms]
Nov 14 22:24:22.690: INFO: Created: latency-svc-l96bv
Nov 14 22:24:22.714: INFO: Got endpoints: latency-svc-l96bv [652.360873ms]
Nov 14 22:24:22.919: INFO: Created: latency-svc-2r79g
Nov 14 22:24:22.940: INFO: Got endpoints: latency-svc-2r79g [877.903308ms]
Nov 14 22:24:23.113: INFO: Created: latency-svc-8mhck
Nov 14 22:24:23.173: INFO: Created: latency-svc-4vrqv
Nov 14 22:24:23.174: INFO: Got endpoints: latency-svc-8mhck [1.111919182s]
Nov 14 22:24:23.211: INFO: Got endpoints: latency-svc-4vrqv [1.14835654s]
Nov 14 22:24:23.352: INFO: Created: latency-svc-wn9c7
Nov 14 22:24:23.408: INFO: Got endpoints: latency-svc-wn9c7 [1.34520836s]
Nov 14 22:24:23.413: INFO: Created: latency-svc-sdjnq
Nov 14 22:24:23.441: INFO: Got endpoints: latency-svc-sdjnq [1.378603271s]
Nov 14 22:24:23.515: INFO: Created: latency-svc-7whhs
Nov 14 22:24:23.550: INFO: Got endpoints: latency-svc-7whhs [1.486923659s]
Nov 14 22:24:23.716: INFO: Created: latency-svc-l9h4c
Nov 14 22:24:23.786: INFO: Got endpoints: latency-svc-l9h4c [1.722555504s]
Nov 14 22:24:23.786: INFO: Created: latency-svc-hx4vr
Nov 14 22:24:23.967: INFO: Got endpoints: latency-svc-hx4vr [1.90364206s]
Nov 14 22:24:23.981: INFO: Created: latency-svc-ht5dj
Nov 14 22:24:24.004: INFO: Got endpoints: latency-svc-ht5dj [1.940914524s]
Nov 14 22:24:24.212: INFO: Created: latency-svc-gw7m7
Nov 14 22:24:24.422: INFO: Created: latency-svc-f6qtc
Nov 14 22:24:24.423: INFO: Got endpoints: latency-svc-gw7m7 [2.35873168s]
Nov 14 22:24:24.493: INFO: Created: latency-svc-h9j8d
Nov 14 22:24:24.499: INFO: Got endpoints: latency-svc-f6qtc [2.210074876s]
Nov 14 22:24:24.618: INFO: Got endpoints: latency-svc-h9j8d [2.185731084s]
Nov 14 22:24:24.650: INFO: Created: latency-svc-89n2h
Nov 14 22:24:24.685: INFO: Got endpoints: latency-svc-89n2h [2.219869133s]
Nov 14 22:24:24.988: INFO: Created: latency-svc-k2d2x
Nov 14 22:24:25.088: INFO: Got endpoints: latency-svc-k2d2x [2.404080523s]
Nov 14 22:24:25.090: INFO: Created: latency-svc-vf2mz
Nov 14 22:24:25.210: INFO: Got endpoints: latency-svc-vf2mz [2.496292314s]
Nov 14 22:24:25.254: INFO: Created: latency-svc-lgmks
Nov 14 22:24:25.285: INFO: Got endpoints: latency-svc-lgmks [2.344476054s]
Nov 14 22:24:25.442: INFO: Created: latency-svc-rqj2c
Nov 14 22:24:25.471: INFO: Got endpoints: latency-svc-rqj2c [2.296526616s]
Nov 14 22:24:25.668: INFO: Created: latency-svc-gshlv
Nov 14 22:24:25.694: INFO: Got endpoints: latency-svc-gshlv [2.483284216s]
Nov 14 22:24:25.921: INFO: Created: latency-svc-t6zlc
Nov 14 22:24:26.014: INFO: Got endpoints: latency-svc-t6zlc [2.60644524s]
Nov 14 22:24:26.024: INFO: Created: latency-svc-p45ds
Nov 14 22:24:26.204: INFO: Got endpoints: latency-svc-p45ds [2.762530533s]
Nov 14 22:24:26.216: INFO: Created: latency-svc-qgr5d
Nov 14 22:24:26.239: INFO: Got endpoints: latency-svc-qgr5d [2.689168011s]
Nov 14 22:24:26.440: INFO: Created: latency-svc-fdddc
Nov 14 22:24:26.456: INFO: Got endpoints: latency-svc-fdddc [2.670596021s]
Nov 14 22:24:26.663: INFO: Created: latency-svc-q78bl
Nov 14 22:24:26.705: INFO: Created: latency-svc-j6pf4
Nov 14 22:24:26.709: INFO: Got endpoints: latency-svc-q78bl [2.742482897s]
Nov 14 22:24:26.876: INFO: Got endpoints: latency-svc-j6pf4 [2.871395347s]
Nov 14 22:24:26.889: INFO: Created: latency-svc-ckpp2
Nov 14 22:24:26.914: INFO: Got endpoints: latency-svc-ckpp2 [2.490794686s]
Nov 14 22:24:26.976: INFO: Created: latency-svc-7lnc2
Nov 14 22:24:27.102: INFO: Got endpoints: latency-svc-7lnc2 [2.603280199s]
Nov 14 22:24:27.106: INFO: Created: latency-svc-vntxl
Nov 14 22:24:27.157: INFO: Got endpoints: latency-svc-vntxl [2.538442632s]
Nov 14 22:24:27.342: INFO: Created: latency-svc-5bxl8
Nov 14 22:24:27.406: INFO: Got endpoints: latency-svc-5bxl8 [2.721141556s]
Nov 14 22:24:27.410: INFO: Created: latency-svc-hjkq5
Nov 14 22:24:27.448: INFO: Got endpoints: latency-svc-hjkq5 [2.359678745s]
Nov 14 22:24:27.559: INFO: Created: latency-svc-np6tk
Nov 14 22:24:27.640: INFO: Got endpoints: latency-svc-np6tk [2.429350071s]
Nov 14 22:24:27.645: INFO: Created: latency-svc-4ns6s
Nov 14 22:24:27.851: INFO: Got endpoints: latency-svc-4ns6s [2.566557736s]
Nov 14 22:24:27.858: INFO: Created: latency-svc-pvs6l
Nov 14 22:24:27.891: INFO: Got endpoints: latency-svc-pvs6l [2.419514034s]
Nov 14 22:24:28.118: INFO: Created: latency-svc-4x6cr
Nov 14 22:24:28.155: INFO: Got endpoints: latency-svc-4x6cr [303.994036ms]
Nov 14 22:24:28.374: INFO: Created: latency-svc-4ljd9
Nov 14 22:24:28.384: INFO: Got endpoints: latency-svc-4ljd9 [2.689984295s]
Nov 14 22:24:28.593: INFO: Created: latency-svc-4xpm5
Nov 14 22:24:28.669: INFO: Got endpoints: latency-svc-4xpm5 [2.654557189s]
Nov 14 22:24:28.669: INFO: Created: latency-svc-cn2vl
Nov 14 22:24:28.819: INFO: Got endpoints: latency-svc-cn2vl [2.614664613s]
Nov 14 22:24:28.860: INFO: Created: latency-svc-c8xxx
Nov 14 22:24:28.892: INFO: Got endpoints: latency-svc-c8xxx [2.65238s]
Nov 14 22:24:29.056: INFO: Created: latency-svc-z5bk2
Nov 14 22:24:29.127: INFO: Created: latency-svc-57hjr
Nov 14 22:24:29.132: INFO: Got endpoints: latency-svc-z5bk2 [2.675876924s]
Nov 14 22:24:29.298: INFO: Got endpoints: latency-svc-57hjr [2.588402858s]
Nov 14 22:24:29.311: INFO: Created: latency-svc-tnblz
Nov 14 22:24:29.341: INFO: Got endpoints: latency-svc-tnblz [2.46470505s]
Nov 14 22:24:29.546: INFO: Created: latency-svc-2qkkp
Nov 14 22:24:29.778: INFO: Got endpoints: latency-svc-2qkkp [2.864588667s]
Nov 14 22:24:29.782: INFO: Created: latency-svc-9rxdr
Nov 14 22:24:29.860: INFO: Created: latency-svc-lrnbf
Nov 14 22:24:29.866: INFO: Got endpoints: latency-svc-9rxdr [2.763863423s]
Nov 14 22:24:29.986: INFO: Got endpoints: latency-svc-lrnbf [2.828508784s]
Nov 14 22:24:30.022: INFO: Created: latency-svc-q7vjq
Nov 14 22:24:30.052: INFO: Got endpoints: latency-svc-q7vjq [2.645169954s]
Nov 14 22:24:30.362: INFO: Created: latency-svc-pbf7t
Nov 14 22:24:30.784: INFO: Got endpoints: latency-svc-pbf7t [3.334773259s]
Nov 14 22:24:30.785: INFO: Created: latency-svc-hcvbn
Nov 14 22:24:31.039: INFO: Created: latency-svc-t5bcw
Nov 14 22:24:31.045: INFO: Got endpoints: latency-svc-hcvbn [3.404851218s]
Nov 14 22:24:31.086: INFO: Got endpoints: latency-svc-t5bcw [3.195753362s]
Nov 14 22:24:31.307: INFO: Created: latency-svc-hl7ft
Nov 14 22:24:31.577: INFO: Got endpoints: latency-svc-hl7ft [3.421570311s]
Nov 14 22:24:31.582: INFO: Created: latency-svc-wxv4s
Nov 14 22:24:31.622: INFO: Got endpoints: latency-svc-wxv4s [3.236947935s]
Nov 14 22:24:31.825: INFO: Created: latency-svc-8rfqf
Nov 14 22:24:31.899: INFO: Created: latency-svc-h9gfr
Nov 14 22:24:31.904: INFO: Got endpoints: latency-svc-8rfqf [3.235180731s]
Nov 14 22:24:32.106: INFO: Created: latency-svc-8f7gx
Nov 14 22:24:32.107: INFO: Got endpoints: latency-svc-h9gfr [3.288340722s]
Nov 14 22:24:32.134: INFO: Got endpoints: latency-svc-8f7gx [3.242418822s]
Nov 14 22:24:32.192: INFO: Created: latency-svc-sqg98
Nov 14 22:24:32.340: INFO: Got endpoints: latency-svc-sqg98 [3.207746528s]
Nov 14 22:24:32.345: INFO: Created: latency-svc-p59fm
Nov 14 22:24:32.413: INFO: Got endpoints: latency-svc-p59fm [3.115287814s]
Nov 14 22:24:32.627: INFO: Created: latency-svc-wb4cf
Nov 14 22:24:32.747: INFO: Created: latency-svc-hvql8
Nov 14 22:24:32.747: INFO: Got endpoints: latency-svc-hvql8 [2.968628184s]
Nov 14 22:24:32.748: INFO: Got endpoints: latency-svc-wb4cf [3.406432733s]
Nov 14 22:24:32.905: INFO: Created: latency-svc-h6txd
Nov 14 22:24:32.962: INFO: Got endpoints: latency-svc-h6txd [3.095570524s]
Nov 14 22:24:32.965: INFO: Created: latency-svc-2sl9f
Nov 14 22:24:33.160: INFO: Got endpoints: latency-svc-2sl9f [3.174812537s]
Nov 14 22:24:33.172: INFO: Created: latency-svc-6bltz
Nov 14 22:24:33.202: INFO: Got endpoints: latency-svc-6bltz [3.149894791s]
Nov 14 22:24:33.468: INFO: Created: latency-svc-z5hml
Nov 14 22:24:33.544: INFO: Got endpoints: latency-svc-z5hml [2.759771389s]
Nov 14 22:24:33.551: INFO: Created: latency-svc-8fnx9
Nov 14 22:24:33.717: INFO: Got endpoints: latency-svc-8fnx9 [2.671718824s]
Nov 14 22:24:33.970: INFO: Created: latency-svc-r5dq5
Nov 14 22:24:34.052: INFO: Got endpoints: latency-svc-r5dq5 [2.965633587s]
Nov 14 22:24:34.059: INFO: Created: latency-svc-fb2jg
Nov 14 22:24:34.219: INFO: Got endpoints: latency-svc-fb2jg [2.642129769s]
Nov 14 22:24:34.226: INFO: Created: latency-svc-fx54j
Nov 14 22:24:34.270: INFO: Got endpoints: latency-svc-fx54j [2.648147502s]
Nov 14 22:24:34.496: INFO: Created: latency-svc-zjj7b
Nov 14 22:24:34.570: INFO: Created: latency-svc-bp7kv
Nov 14 22:24:34.570: INFO: Got endpoints: latency-svc-zjj7b [2.665895087s]
Nov 14 22:24:34.781: INFO: Got endpoints: latency-svc-bp7kv [2.67347881s]
Nov 14 22:24:34.785: INFO: Created: latency-svc-855d9
Nov 14 22:24:34.812: INFO: Got endpoints: latency-svc-855d9 [2.677869655s]
Nov 14 22:24:34.870: INFO: Created: latency-svc-bm5l7
Nov 14 22:24:35.090: INFO: Got endpoints: latency-svc-bm5l7 [2.749362665s]
Nov 14 22:24:35.102: INFO: Created: latency-svc-mt694
Nov 14 22:24:35.129: INFO: Got endpoints: latency-svc-mt694 [2.715848055s]
Nov 14 22:24:35.497: INFO: Created: latency-svc-jg5pb
Nov 14 22:24:35.531: INFO: Got endpoints: latency-svc-jg5pb [2.783832993s]
Nov 14 22:24:35.700: INFO: Created: latency-svc-tvphr
Nov 14 22:24:35.782: INFO: Created: latency-svc-ks4zd
Nov 14 22:24:35.782: INFO: Got endpoints: latency-svc-tvphr [3.034872966s]
Nov 14 22:24:36.006: INFO: Got endpoints: latency-svc-ks4zd [3.044091383s]
Nov 14 22:24:36.096: INFO: Created: latency-svc-tbn7n
Nov 14 22:24:36.290: INFO: Got endpoints: latency-svc-tbn7n [3.129531869s]
Nov 14 22:24:36.305: INFO: Created: latency-svc-vwjfl
Nov 14 22:24:36.332: INFO: Got endpoints: latency-svc-vwjfl [3.130498145s]
Nov 14 22:24:36.732: INFO: Created: latency-svc-psrwv
Nov 14 22:24:37.343: INFO: Got endpoints: latency-svc-psrwv [3.799029523s]
Nov 14 22:24:37.353: INFO: Created: latency-svc-4tqv2
Nov 14 22:24:37.643: INFO: Got endpoints: latency-svc-4tqv2 [3.926356225s]
Nov 14 22:24:37.648: INFO: Created: latency-svc-6dkj9
Nov 14 22:24:37.695: INFO: Got endpoints: latency-svc-6dkj9 [3.64289125s]
Nov 14 22:24:38.182: INFO: Created: latency-svc-27xz7
Nov 14 22:24:38.450: INFO: Got endpoints: latency-svc-27xz7 [4.230381778s]
Nov 14 22:24:38.462: INFO: Created: latency-svc-qqh7f
Nov 14 22:24:38.755: INFO: Got endpoints: latency-svc-qqh7f [4.485226067s]
Nov 14 22:24:38.771: INFO: Created: latency-svc-th9qb
Nov 14 22:24:38.828: INFO: Got endpoints: latency-svc-th9qb [4.257859752s]
Nov 14 22:24:39.168: INFO: Created: latency-svc-6jhnl
Nov 14 22:24:39.421: INFO: Got endpoints: latency-svc-6jhnl [4.639814843s]
Nov 14 22:24:39.432: INFO: Created: latency-svc-f8dj5
Nov 14 22:24:39.509: INFO: Got endpoints: latency-svc-f8dj5 [4.696794465s]
Nov 14 22:24:39.509: INFO: Created: latency-svc-mqxs8
Nov 14 22:24:39.724: INFO: Got endpoints: latency-svc-mqxs8 [4.63406878s]
Nov 14 22:24:39.754: INFO: Created: latency-svc-rj5c7
Nov 14 22:24:39.789: INFO: Got endpoints: latency-svc-rj5c7 [4.659593985s]
Nov 14 22:24:40.001: INFO: Created: latency-svc-hg488
Nov 14 22:24:40.015: INFO: Got endpoints: latency-svc-hg488 [4.482988013s]
Nov 14 22:24:40.075: INFO: Created: latency-svc-mrgx4
Nov 14 22:24:40.282: INFO: Got endpoints: latency-svc-mrgx4 [4.499969186s]
Nov 14 22:24:40.291: INFO: Created: latency-svc-kh2r7
Nov 14 22:24:40.322: INFO: Got endpoints: latency-svc-kh2r7 [4.316046815s]
Nov 14 22:24:40.692: INFO: Created: latency-svc-7fwdt
Nov 14 22:24:40.758: INFO: Got endpoints: latency-svc-7fwdt [4.466995094s]
Nov 14 22:24:40.764: INFO: Created: latency-svc-bhpkm
Nov 14 22:24:40.918: INFO: Got endpoints: latency-svc-bhpkm [4.585346171s]
Nov 14 22:24:40.919: INFO: Created: latency-svc-8mkcj
Nov 14 22:24:40.947: INFO: Got endpoints: latency-svc-8mkcj [3.603422554s]
Nov 14 22:24:41.199: INFO: Created: latency-svc-b7477
Nov 14 22:24:41.576: INFO: Got endpoints: latency-svc-b7477 [3.932475227s]
Nov 14 22:24:41.577: INFO: Created: latency-svc-dntw2
Nov 14 22:24:41.983: INFO: Created: latency-svc-bsfrg
Nov 14 22:24:41.988: INFO: Got endpoints: latency-svc-dntw2 [4.292804981s]
Nov 14 22:24:42.651: INFO: Created: latency-svc-5qdgr
Nov 14 22:24:42.657: INFO: Got endpoints: latency-svc-bsfrg [4.207019381s]
Nov 14 22:24:42.725: INFO: Got endpoints: latency-svc-5qdgr [3.969644618s]
Nov 14 22:24:42.932: INFO: Created: latency-svc-p2c4f
Nov 14 22:24:43.301: INFO: Created: latency-svc-cln7c
Nov 14 22:24:43.306: INFO: Got endpoints: latency-svc-p2c4f [4.477763069s]
Nov 14 22:24:43.777: INFO: Created: latency-svc-l2rvc
Nov 14 22:24:43.777: INFO: Got endpoints: latency-svc-cln7c [4.356224041s]
Nov 14 22:24:44.285: INFO: Created: latency-svc-vt2s6
Nov 14 22:24:44.290: INFO: Got endpoints: latency-svc-l2rvc [4.780932096s]
Nov 14 22:24:44.610: INFO: Created: latency-svc-ggsnd
Nov 14 22:24:44.612: INFO: Got endpoints: latency-svc-vt2s6 [4.887652673s]
Nov 14 22:24:44.937: INFO: Got endpoints: latency-svc-ggsnd [5.14771987s]
Nov 14 22:24:44.952: INFO: Created: latency-svc-rtlnh
Nov 14 22:24:45.225: INFO: Got endpoints: latency-svc-rtlnh [5.210550722s]
Nov 14 22:24:45.671: INFO: Created: latency-svc-9d24s
Nov 14 22:24:46.025: INFO: Got endpoints: latency-svc-9d24s [5.742660983s]
Nov 14 22:24:46.404: INFO: Created: latency-svc-lk8f6
Nov 14 22:24:46.411: INFO: Created: latency-svc-snchl
Nov 14 22:24:46.963: INFO: Created: latency-svc-njj6m
Nov 14 22:24:46.964: INFO: Got endpoints: latency-svc-snchl [6.205691888s]
Nov 14 22:24:46.964: INFO: Got endpoints: latency-svc-lk8f6 [6.641939027s]
Nov 14 22:24:47.234: INFO: Got endpoints: latency-svc-njj6m [6.316533961s]
Nov 14 22:24:47.238: INFO: Created: latency-svc-hktfh
Nov 14 22:24:47.274: INFO: Got endpoints: latency-svc-hktfh [6.327402318s]
Nov 14 22:24:47.487: INFO: Created: latency-svc-f9zrv
Nov 14 22:24:47.550: INFO: Created: latency-svc-d5lhd
Nov 14 22:24:47.554: INFO: Got endpoints: latency-svc-f9zrv [5.978213951s]
Nov 14 22:24:47.583: INFO: Got endpoints: latency-svc-d5lhd [5.59436807s]
Nov 14 22:24:47.924: INFO: Created: latency-svc-jfjgd
Nov 14 22:24:48.012: INFO: Got endpoints: latency-svc-jfjgd [5.354525932s]
Nov 14 22:24:48.012: INFO: Created: latency-svc-rtft6
Nov 14 22:24:48.400: INFO: Got endpoints: latency-svc-rtft6 [5.675090944s]
Nov 14 22:24:48.811: INFO: Created: latency-svc-nlxfb
Nov 14 22:24:48.811: INFO: Created: latency-svc-plf8l
Nov 14 22:24:49.216: INFO: Got endpoints: latency-svc-plf8l [5.439095414s]
Nov 14 22:24:49.218: INFO: Got endpoints: latency-svc-nlxfb [5.91172773s]
Nov 14 22:24:49.227: INFO: Created: latency-svc-6r77t
Nov 14 22:24:49.285: INFO: Got endpoints: latency-svc-6r77t [4.995078195s]
Nov 14 22:24:49.293: INFO: Created: latency-svc-bcggw
Nov 14 22:24:49.581: INFO: Created: latency-svc-6v88m
Nov 14 22:24:49.581: INFO: Got endpoints: latency-svc-bcggw [4.969450669s]
Nov 14 22:24:49.612: INFO: Got endpoints: latency-svc-6v88m [4.674686244s]
Nov 14 22:24:49.784: INFO: Created: latency-svc-cwk2g
Nov 14 22:24:49.851: INFO: Got endpoints: latency-svc-cwk2g [4.626020858s]
Nov 14 22:24:49.859: INFO: Created: latency-svc-jmxdz
Nov 14 22:24:50.086: INFO: Got endpoints: latency-svc-jmxdz [4.061060221s]
Nov 14 22:24:50.087: INFO: Created: latency-svc-s2d86
Nov 14 22:24:50.119: INFO: Got endpoints: latency-svc-s2d86 [3.155202946s]
Nov 14 22:24:50.321: INFO: Created: latency-svc-vmdth
Nov 14 22:24:50.613: INFO: Created: latency-svc-lrtkq
Nov 14 22:24:50.620: INFO: Got endpoints: latency-svc-vmdth [3.656017822s]
Nov 14 22:24:50.693: INFO: Created: latency-svc-n8n8p
Nov 14 22:24:50.698: INFO: Got endpoints: latency-svc-lrtkq [3.463649982s]
Nov 14 22:24:50.911: INFO: Got endpoints: latency-svc-n8n8p [3.636761924s]
Nov 14 22:24:50.915: INFO: Created: latency-svc-d8r4q
Nov 14 22:24:50.949: INFO: Got endpoints: latency-svc-d8r4q [3.394304646s]
Nov 14 22:24:51.008: INFO: Created: latency-svc-r77vc
Nov 14 22:24:51.145: INFO: Got endpoints: latency-svc-r77vc [3.562329053s]
Nov 14 22:24:51.154: INFO: Created: latency-svc-gr5tb
Nov 14 22:24:51.186: INFO: Got endpoints: latency-svc-gr5tb [3.174379538s]
Nov 14 22:24:51.446: INFO: Created: latency-svc-8ktp6
Nov 14 22:24:51.864: INFO: Created: latency-svc-qq4tn
Nov 14 22:24:51.868: INFO: Got endpoints: latency-svc-8ktp6 [3.467731562s]
Nov 14 22:24:52.148: INFO: Created: latency-svc-4dv7g
Nov 14 22:24:52.154: INFO: Got endpoints: latency-svc-qq4tn [2.93724602s]
Nov 14 22:24:52.218: INFO: Got endpoints: latency-svc-4dv7g [2.999479104s]
Nov 14 22:24:52.219: INFO: Created: latency-svc-q56vs
Nov 14 22:24:52.400: INFO: Got endpoints: latency-svc-q56vs [3.114354474s]
Nov 14 22:24:52.482: INFO: Created: latency-svc-r6mp6
Nov 14 22:24:52.608: INFO: Got endpoints: latency-svc-r6mp6 [3.026471815s]
Nov 14 22:24:52.614: INFO: Created: latency-svc-xlmb8
Nov 14 22:24:52.737: INFO: Got endpoints: latency-svc-xlmb8 [3.124611898s]
Nov 14 22:24:52.923: INFO: Created: latency-svc-p74jf
Nov 14 22:24:53.000: INFO: Got endpoints: latency-svc-p74jf [3.148545062s]
Nov 14 22:24:53.001: INFO: Created: latency-svc-fk9lm
Nov 14 22:24:53.172: INFO: Created: latency-svc-sj9bl
Nov 14 22:24:53.173: INFO: Got endpoints: latency-svc-fk9lm [3.086112819s]
Nov 14 22:24:53.192: INFO: Got endpoints: latency-svc-sj9bl [3.073123307s]
Nov 14 22:24:53.247: INFO: Created: latency-svc-xq8wp
Nov 14 22:24:53.476: INFO: Got endpoints: latency-svc-xq8wp [2.855150196s]
Nov 14 22:24:53.492: INFO: Created: latency-svc-vd6jj
Nov 14 22:24:53.508: INFO: Got endpoints: latency-svc-vd6jj [2.809477112s]
Nov 14 22:24:53.740: INFO: Created: latency-svc-tdsq4
Nov 14 22:24:53.800: INFO: Got endpoints: latency-svc-tdsq4 [2.888782577s]
Nov 14 22:24:53.808: INFO: Created: latency-svc-v6sfm
Nov 14 22:24:53.826: INFO: Got endpoints: latency-svc-v6sfm [2.877141504s]
Nov 14 22:24:53.967: INFO: Created: latency-svc-7gzqd
Nov 14 22:24:54.040: INFO: Got endpoints: latency-svc-7gzqd [2.894944074s]
Nov 14 22:24:54.045: INFO: Created: latency-svc-8hxts
Nov 14 22:24:54.211: INFO: Got endpoints: latency-svc-8hxts [3.025230041s]
Nov 14 22:24:54.220: INFO: Created: latency-svc-5hrhj
Nov 14 22:24:54.310: INFO: Created: latency-svc-c4b8p
Nov 14 22:24:54.310: INFO: Got endpoints: latency-svc-5hrhj [2.442287865s]
Nov 14 22:24:54.510: INFO: Got endpoints: latency-svc-c4b8p [2.355682551s]
Nov 14 22:24:54.514: INFO: Created: latency-svc-pv2w9
Nov 14 22:24:54.543: INFO: Got endpoints: latency-svc-pv2w9 [2.324426508s]
Nov 14 22:24:54.750: INFO: Created: latency-svc-597wt
Nov 14 22:24:54.810: INFO: Got endpoints: latency-svc-597wt [2.410551145s]
Nov 14 22:24:54.812: INFO: Created: latency-svc-dqxbq
Nov 14 22:24:54.835: INFO: Got endpoints: latency-svc-dqxbq [2.22659158s]
Nov 14 22:24:55.143: INFO: Created: latency-svc-sfb8l
Nov 14 22:24:55.452: INFO: Got endpoints: latency-svc-sfb8l [2.71499601s]
Nov 14 22:24:55.452: INFO: Created: latency-svc-d66jc
Nov 14 22:24:55.504: INFO: Got endpoints: latency-svc-d66jc [2.503454752s]
Nov 14 22:24:55.510: INFO: Created: latency-svc-sbpb2
Nov 14 22:24:55.535: INFO: Got endpoints: latency-svc-sbpb2 [2.361929884s]
Nov 14 22:24:55.745: INFO: Created: latency-svc-c6cw2
Nov 14 22:24:55.745: INFO: Created: latency-svc-7rgff
Nov 14 22:24:56.030: INFO: Got endpoints: latency-svc-c6cw2 [2.837934508s]
Nov 14 22:24:56.032: INFO: Got endpoints: latency-svc-7rgff [2.555779451s]
Nov 14 22:24:56.044: INFO: Created: latency-svc-pkhwn
Nov 14 22:24:56.072: INFO: Got endpoints: latency-svc-pkhwn [2.564543035s]
Nov 14 22:24:56.247: INFO: Created: latency-svc-fsglr
Nov 14 22:24:56.321: INFO: Created: latency-svc-84d96
Nov 14 22:24:56.324: INFO: Got endpoints: latency-svc-fsglr [2.523782968s]
Nov 14 22:24:56.669: INFO: Got endpoints: latency-svc-84d96 [2.842639635s]
Nov 14 22:24:56.676: INFO: Created: latency-svc-fjqsp
Nov 14 22:24:56.713: INFO: Got endpoints: latency-svc-fjqsp [2.672270998s]
Nov 14 22:24:56.969: INFO: Created: latency-svc-tbh55
Nov 14 22:24:57.200: INFO: Got endpoints: latency-svc-tbh55 [2.988271883s]
Nov 14 22:24:57.210: INFO: Created: latency-svc-2d5hj
Nov 14 22:24:57.478: INFO: Got endpoints: latency-svc-2d5hj [3.166980876s]
Nov 14 22:24:57.486: INFO: Created: latency-svc-m7hwm
Nov 14 22:24:57.549: INFO: Got endpoints: latency-svc-m7hwm [3.039508113s]
Nov 14 22:24:57.557: INFO: Created: latency-svc-jcc56
Nov 14 22:24:57.779: INFO: Got endpoints: latency-svc-jcc56 [3.23670108s]
Nov 14 22:24:57.784: INFO: Created: latency-svc-brkdt
Nov 14 22:24:57.856: INFO: Got endpoints: latency-svc-brkdt [3.045000746s]
Nov 14 22:24:58.039: INFO: Created: latency-svc-kdjxq
Nov 14 22:24:58.082: INFO: Got endpoints: latency-svc-kdjxq [3.247577241s]
Nov 14 22:24:58.260: INFO: Created: latency-svc-gfstr
Nov 14 22:24:58.325: INFO: Got endpoints: latency-svc-gfstr [2.872650997s]
Nov 14 22:24:58.331: INFO: Created: latency-svc-whd9x
Nov 14 22:24:58.587: INFO: Got endpoints: latency-svc-whd9x [3.083022766s]
Nov 14 22:24:58.597: INFO: Created: latency-svc-nb85d
Nov 14 22:24:58.623: INFO: Got endpoints: latency-svc-nb85d [3.087795822s]
Nov 14 22:24:58.878: INFO: Created: latency-svc-xrqgp
Nov 14 22:24:58.951: INFO: Created: latency-svc-hg8rz
Nov 14 22:24:58.958: INFO: Got endpoints: latency-svc-xrqgp [2.927434117s]
Nov 14 22:24:59.097: INFO: Got endpoints: latency-svc-hg8rz [3.064613156s]
Nov 14 22:24:59.105: INFO: Created: latency-svc-w72s9
Nov 14 22:24:59.134: INFO: Got endpoints: latency-svc-w72s9 [3.061763932s]
Nov 14 22:24:59.388: INFO: Created: latency-svc-xlbzf
Nov 14 22:24:59.633: INFO: Created: latency-svc-9np2l
Nov 14 22:24:59.634: INFO: Got endpoints: latency-svc-xlbzf [3.309150353s]
Nov 14 22:24:59.695: INFO: Created: latency-svc-2hgdg
Nov 14 22:24:59.696: INFO: Got endpoints: latency-svc-9np2l [3.026441966s]
Nov 14 22:24:59.723: INFO: Got endpoints: latency-svc-2hgdg [3.00970521s]
Nov 14 22:24:59.908: INFO: Created: latency-svc-pr6qg
Nov 14 22:24:59.960: INFO: Created: latency-svc-h6xrj
Nov 14 22:24:59.985: INFO: Got endpoints: latency-svc-pr6qg [2.784676048s]
Nov 14 22:25:00.154: INFO: Created: latency-svc-vcb5t
Nov 14 22:25:00.160: INFO: Got endpoints: latency-svc-h6xrj [2.681486943s]
Nov 14 22:25:00.245: INFO: Got endpoints: latency-svc-vcb5t [2.694771839s]
Nov 14 22:25:00.247: INFO: Created: latency-svc-nv458
Nov 14 22:25:00.540: INFO: Got endpoints: latency-svc-nv458 [2.760590972s]
Nov 14 22:25:00.541: INFO: Created: latency-svc-6nhg5
Nov 14 22:25:00.612: INFO: Got endpoints: latency-svc-6nhg5 [2.755881682s]
Nov 14 22:25:00.837: INFO: Created: latency-svc-g5l6t
Nov 14 22:25:00.889: INFO: Got endpoints: latency-svc-g5l6t [2.806096313s]
Nov 14 22:25:00.896: INFO: Created: latency-svc-t6jfb
Nov 14 22:25:00.912: INFO: Got endpoints: latency-svc-t6jfb [2.58736112s]
Nov 14 22:25:01.209: INFO: Created: latency-svc-42r9k
Nov 14 22:25:01.288: INFO: Got endpoints: latency-svc-42r9k [2.70145755s]
Nov 14 22:25:01.292: INFO: Created: latency-svc-xxwsr
Nov 14 22:25:01.496: INFO: Got endpoints: latency-svc-xxwsr [2.872675057s]
Nov 14 22:25:01.500: INFO: Created: latency-svc-v6q5g
Nov 14 22:25:01.524: INFO: Got endpoints: latency-svc-v6q5g [2.565713522s]
Nov 14 22:25:01.587: INFO: Created: latency-svc-zg5jf
Nov 14 22:25:01.765: INFO: Got endpoints: latency-svc-zg5jf [2.66809021s]
Nov 14 22:25:01.770: INFO: Created: latency-svc-d7kng
Nov 14 22:25:01.833: INFO: Got endpoints: latency-svc-d7kng [2.698597774s]
Nov 14 22:25:01.976: INFO: Created: latency-svc-gf25v
Nov 14 22:25:02.011: INFO: Got endpoints: latency-svc-gf25v [2.377380666s]
Nov 14 22:25:02.190: INFO: Created: latency-svc-srpvb
Nov 14 22:25:02.548: INFO: Got endpoints: latency-svc-srpvb [2.852515038s]
Nov 14 22:25:02.549: INFO: Created: latency-svc-z9st5
Nov 14 22:25:02.553: INFO: Got endpoints: latency-svc-z9st5 [2.830436426s]
Nov 14 22:25:02.753: INFO: Created: latency-svc-x2p4q
Nov 14 22:25:02.824: INFO: Got endpoints: latency-svc-x2p4q [2.839525081s]
Nov 14 22:25:02.831: INFO: Created: latency-svc-h8l2x
Nov 14 22:25:03.011: INFO: Got endpoints: latency-svc-h8l2x [2.850758622s]
Nov 14 22:25:03.069: INFO: Created: latency-svc-qdrm7
Nov 14 22:25:03.219: INFO: Created: latency-svc-pkwlh
Nov 14 22:25:03.225: INFO: Got endpoints: latency-svc-qdrm7 [2.980532665s]
Nov 14 22:25:03.296: INFO: Got endpoints: latency-svc-pkwlh [2.755586031s]
Nov 14 22:25:03.296: INFO: Created: latency-svc-rfwlx
Nov 14 22:25:03.604: INFO: Got endpoints: latency-svc-rfwlx [2.992325229s]
Nov 14 22:25:03.615: INFO: Created: latency-svc-cd9m7
Nov 14 22:25:03.636: INFO: Got endpoints: latency-svc-cd9m7 [2.746890392s]
Nov 14 22:25:03.933: INFO: Created: latency-svc-xmwtt
Nov 14 22:25:04.009: INFO: Got endpoints: latency-svc-xmwtt [3.096403162s]
Nov 14 22:25:04.013: INFO: Created: latency-svc-q7l85
Nov 14 22:25:04.164: INFO: Got endpoints: latency-svc-q7l85 [2.875575261s]
Nov 14 22:25:04.234: INFO: Created: latency-svc-qk2bg
Nov 14 22:25:04.426: INFO: Got endpoints: latency-svc-qk2bg [2.928094262s]
Nov 14 22:25:04.430: INFO: Created: latency-svc-hbdnx
Nov 14 22:25:04.511: INFO: Got endpoints: latency-svc-hbdnx [2.987858593s]
Nov 14 22:25:04.718: INFO: Created: latency-svc-2jkgq
Nov 14 22:25:04.776: INFO: Got endpoints: latency-svc-2jkgq [3.011583745s]
Nov 14 22:25:04.780: INFO: Created: latency-svc-2697v
Nov 14 22:25:04.810: INFO: Got endpoints: latency-svc-2697v [2.977440964s]
Nov 14 22:25:04.968: INFO: Created: latency-svc-nrbgc
Nov 14 22:25:05.010: INFO: Got endpoints: latency-svc-nrbgc [2.998394811s]
Nov 14 22:25:05.010: INFO: Latencies: [227.575928ms 303.994036ms 371.087657ms 403.534455ms 629.187362ms 652.360873ms 877.903308ms 1.111919182s 1.14835654s 1.34520836s 1.378603271s 1.486923659s 1.722555504s 1.90364206s 1.940914524s 2.185731084s 2.210074876s 2.219869133s 2.22659158s 2.296526616s 2.324426508s 2.344476054s 2.355682551s 2.35873168s 2.359678745s 2.361929884s 2.377380666s 2.404080523s 2.410551145s 2.419514034s 2.429350071s 2.442287865s 2.46470505s 2.483284216s 2.490794686s 2.496292314s 2.503454752s 2.523782968s 2.538442632s 2.555779451s 2.564543035s 2.565713522s 2.566557736s 2.58736112s 2.588402858s 2.603280199s 2.60644524s 2.614664613s 2.642129769s 2.645169954s 2.648147502s 2.65238s 2.654557189s 2.665895087s 2.66809021s 2.670596021s 2.671718824s 2.672270998s 2.67347881s 2.675876924s 2.677869655s 2.681486943s 2.689168011s 2.689984295s 2.694771839s 2.698597774s 2.70145755s 2.71499601s 2.715848055s 2.721141556s 2.742482897s 2.746890392s 2.749362665s 2.755586031s 2.755881682s 2.759771389s 2.760590972s 2.762530533s 2.763863423s 2.783832993s 2.784676048s 2.806096313s 2.809477112s 2.828508784s 2.830436426s 2.837934508s 2.839525081s 2.842639635s 2.850758622s 2.852515038s 2.855150196s 2.864588667s 2.871395347s 2.872650997s 2.872675057s 2.875575261s 2.877141504s 2.888782577s 2.894944074s 2.927434117s 2.928094262s 2.93724602s 2.965633587s 2.968628184s 2.977440964s 2.980532665s 2.987858593s 2.988271883s 2.992325229s 2.998394811s 2.999479104s 3.00970521s 3.011583745s 3.025230041s 3.026441966s 3.026471815s 3.034872966s 3.039508113s 3.044091383s 3.045000746s 3.061763932s 3.064613156s 3.073123307s 3.083022766s 3.086112819s 3.087795822s 3.095570524s 3.096403162s 3.114354474s 3.115287814s 3.124611898s 3.129531869s 3.130498145s 3.148545062s 3.149894791s 3.155202946s 3.166980876s 3.174379538s 3.174812537s 3.195753362s 3.207746528s 3.235180731s 3.23670108s 3.236947935s 3.242418822s 3.247577241s 3.288340722s 3.309150353s 3.334773259s 3.394304646s 3.404851218s 3.406432733s 3.421570311s 3.463649982s 3.467731562s 3.562329053s 3.603422554s 3.636761924s 3.64289125s 3.656017822s 3.799029523s 3.926356225s 3.932475227s 3.969644618s 4.061060221s 4.207019381s 4.230381778s 4.257859752s 4.292804981s 4.316046815s 4.356224041s 4.466995094s 4.477763069s 4.482988013s 4.485226067s 4.499969186s 4.585346171s 4.626020858s 4.63406878s 4.639814843s 4.659593985s 4.674686244s 4.696794465s 4.780932096s 4.887652673s 4.969450669s 4.995078195s 5.14771987s 5.210550722s 5.354525932s 5.439095414s 5.59436807s 5.675090944s 5.742660983s 5.91172773s 5.978213951s 6.205691888s 6.316533961s 6.327402318s 6.641939027s]
Nov 14 22:25:05.010: INFO: 50 %ile: 2.928094262s
Nov 14 22:25:05.010: INFO: 90 %ile: 4.659593985s
Nov 14 22:25:05.010: INFO: 99 %ile: 6.327402318s
Nov 14 22:25:05.010: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:25:05.010: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-609" for this suite.
Nov 14 22:26:47.280: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:26:47.590: INFO: namespace svc-latency-609 deletion completed in 1m42.545320098s

• [SLOW TEST:151.965 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:26:47.595: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-9677
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-a7586aac-54f6-4b87-a540-35d8a9bc9b9d
STEP: Creating a pod to test consume secrets
Nov 14 22:26:48.193: INFO: Waiting up to 5m0s for pod "pod-secrets-e5b09a62-86db-4f44-8ab6-fe824d28da31" in namespace "secrets-9677" to be "success or failure"
Nov 14 22:26:48.230: INFO: Pod "pod-secrets-e5b09a62-86db-4f44-8ab6-fe824d28da31": Phase="Pending", Reason="", readiness=false. Elapsed: 36.891359ms
Nov 14 22:26:50.655: INFO: Pod "pod-secrets-e5b09a62-86db-4f44-8ab6-fe824d28da31": Phase="Pending", Reason="", readiness=false. Elapsed: 2.461505181s
Nov 14 22:26:52.713: INFO: Pod "pod-secrets-e5b09a62-86db-4f44-8ab6-fe824d28da31": Phase="Running", Reason="", readiness=true. Elapsed: 4.519296512s
Nov 14 22:26:54.718: INFO: Pod "pod-secrets-e5b09a62-86db-4f44-8ab6-fe824d28da31": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.524930861s
STEP: Saw pod success
Nov 14 22:26:54.720: INFO: Pod "pod-secrets-e5b09a62-86db-4f44-8ab6-fe824d28da31" satisfied condition "success or failure"
Nov 14 22:26:54.728: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-1 pod pod-secrets-e5b09a62-86db-4f44-8ab6-fe824d28da31 container secret-volume-test: <nil>
STEP: delete the pod
Nov 14 22:26:54.915: INFO: Waiting for pod pod-secrets-e5b09a62-86db-4f44-8ab6-fe824d28da31 to disappear
Nov 14 22:26:54.948: INFO: Pod pod-secrets-e5b09a62-86db-4f44-8ab6-fe824d28da31 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:26:54.949: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9677" for this suite.
Nov 14 22:27:03.829: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:27:04.096: INFO: namespace secrets-9677 deletion completed in 9.088882586s

• [SLOW TEST:16.501 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:27:04.105: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2533
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a replication controller
Nov 14 22:27:04.590: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 create -f - --namespace=kubectl-2533'
Nov 14 22:27:05.578: INFO: stderr: ""
Nov 14 22:27:05.578: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov 14 22:27:05.578: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2533'
Nov 14 22:27:05.915: INFO: stderr: ""
Nov 14 22:27:05.915: INFO: stdout: "update-demo-nautilus-59n42 update-demo-nautilus-7g7fp "
Nov 14 22:27:05.915: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 get pods update-demo-nautilus-59n42 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2533'
Nov 14 22:27:06.123: INFO: stderr: ""
Nov 14 22:27:06.123: INFO: stdout: ""
Nov 14 22:27:06.123: INFO: update-demo-nautilus-59n42 is created but not running
Nov 14 22:27:11.123: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2533'
Nov 14 22:27:11.662: INFO: stderr: ""
Nov 14 22:27:11.662: INFO: stdout: "update-demo-nautilus-59n42 update-demo-nautilus-7g7fp "
Nov 14 22:27:11.662: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 get pods update-demo-nautilus-59n42 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2533'
Nov 14 22:27:12.222: INFO: stderr: ""
Nov 14 22:27:12.222: INFO: stdout: ""
Nov 14 22:27:12.222: INFO: update-demo-nautilus-59n42 is created but not running
Nov 14 22:27:17.222: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2533'
Nov 14 22:27:17.370: INFO: stderr: ""
Nov 14 22:27:17.370: INFO: stdout: "update-demo-nautilus-59n42 update-demo-nautilus-7g7fp "
Nov 14 22:27:17.370: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 get pods update-demo-nautilus-59n42 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2533'
Nov 14 22:27:17.482: INFO: stderr: ""
Nov 14 22:27:17.482: INFO: stdout: "true"
Nov 14 22:27:17.482: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 get pods update-demo-nautilus-59n42 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2533'
Nov 14 22:27:17.594: INFO: stderr: ""
Nov 14 22:27:17.594: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov 14 22:27:17.594: INFO: validating pod update-demo-nautilus-59n42
Nov 14 22:27:17.636: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 14 22:27:17.636: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 14 22:27:17.636: INFO: update-demo-nautilus-59n42 is verified up and running
Nov 14 22:27:17.636: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 get pods update-demo-nautilus-7g7fp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2533'
Nov 14 22:27:17.750: INFO: stderr: ""
Nov 14 22:27:17.750: INFO: stdout: "true"
Nov 14 22:27:17.750: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 get pods update-demo-nautilus-7g7fp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2533'
Nov 14 22:27:18.002: INFO: stderr: ""
Nov 14 22:27:18.002: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov 14 22:27:18.002: INFO: validating pod update-demo-nautilus-7g7fp
Nov 14 22:27:18.011: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 14 22:27:18.011: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 14 22:27:18.011: INFO: update-demo-nautilus-7g7fp is verified up and running
STEP: using delete to clean up resources
Nov 14 22:27:18.011: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 delete --grace-period=0 --force -f - --namespace=kubectl-2533'
Nov 14 22:27:18.331: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 14 22:27:18.331: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Nov 14 22:27:18.331: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-2533'
Nov 14 22:27:18.584: INFO: stderr: "No resources found.\n"
Nov 14 22:27:18.584: INFO: stdout: ""
Nov 14 22:27:18.585: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 get pods -l name=update-demo --namespace=kubectl-2533 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov 14 22:27:18.738: INFO: stderr: ""
Nov 14 22:27:18.738: INFO: stdout: "update-demo-nautilus-59n42\nupdate-demo-nautilus-7g7fp\n"
Nov 14 22:27:19.239: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-2533'
Nov 14 22:27:19.596: INFO: stderr: "No resources found.\n"
Nov 14 22:27:19.596: INFO: stdout: ""
Nov 14 22:27:19.596: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 get pods -l name=update-demo --namespace=kubectl-2533 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov 14 22:27:19.716: INFO: stderr: ""
Nov 14 22:27:19.716: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:27:19.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2533" for this suite.
Nov 14 22:27:44.107: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:27:44.259: INFO: namespace kubectl-2533 deletion completed in 24.539302033s

• [SLOW TEST:40.155 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:27:44.266: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-403
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-403.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-403.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov 14 22:28:44.303: INFO: Unable to read wheezy_udp@PodARecord from pod dns-403/dns-test-73aa2afe-57fc-432a-8b83-a49b587b99c9: the server could not find the requested resource (get pods dns-test-73aa2afe-57fc-432a-8b83-a49b587b99c9)
Nov 14 22:28:44.656: INFO: Unable to read wheezy_tcp@PodARecord from pod dns-403/dns-test-73aa2afe-57fc-432a-8b83-a49b587b99c9: the server could not find the requested resource (get pods dns-test-73aa2afe-57fc-432a-8b83-a49b587b99c9)
Nov 14 22:28:44.665: INFO: Unable to read jessie_udp@PodARecord from pod dns-403/dns-test-73aa2afe-57fc-432a-8b83-a49b587b99c9: the server could not find the requested resource (get pods dns-test-73aa2afe-57fc-432a-8b83-a49b587b99c9)
Nov 14 22:28:44.669: INFO: Unable to read jessie_tcp@PodARecord from pod dns-403/dns-test-73aa2afe-57fc-432a-8b83-a49b587b99c9: the server could not find the requested resource (get pods dns-test-73aa2afe-57fc-432a-8b83-a49b587b99c9)
Nov 14 22:28:44.669: INFO: Lookups using dns-403/dns-test-73aa2afe-57fc-432a-8b83-a49b587b99c9 failed for: [wheezy_udp@PodARecord wheezy_tcp@PodARecord jessie_udp@PodARecord jessie_tcp@PodARecord]

Nov 14 22:28:49.718: INFO: DNS probes using dns-403/dns-test-73aa2afe-57fc-432a-8b83-a49b587b99c9 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:28:50.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-403" for this suite.
Nov 14 22:29:00.054: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:29:01.619: INFO: namespace dns-403 deletion completed in 9.860803191s

• [SLOW TEST:77.354 seconds]
[sig-network] DNS
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:29:01.656: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-715
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Nov 14 22:29:02.391: INFO: Waiting up to 5m0s for pod "downwardapi-volume-63d3c68b-84e1-4910-a899-19758eea7348" in namespace "downward-api-715" to be "success or failure"
Nov 14 22:29:02.665: INFO: Pod "downwardapi-volume-63d3c68b-84e1-4910-a899-19758eea7348": Phase="Pending", Reason="", readiness=false. Elapsed: 248.673272ms
Nov 14 22:29:04.669: INFO: Pod "downwardapi-volume-63d3c68b-84e1-4910-a899-19758eea7348": Phase="Pending", Reason="", readiness=false. Elapsed: 2.252355046s
Nov 14 22:29:06.673: INFO: Pod "downwardapi-volume-63d3c68b-84e1-4910-a899-19758eea7348": Phase="Pending", Reason="", readiness=false. Elapsed: 4.256746617s
Nov 14 22:29:08.680: INFO: Pod "downwardapi-volume-63d3c68b-84e1-4910-a899-19758eea7348": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.263292614s
STEP: Saw pod success
Nov 14 22:29:08.680: INFO: Pod "downwardapi-volume-63d3c68b-84e1-4910-a899-19758eea7348" satisfied condition "success or failure"
Nov 14 22:29:08.684: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-1 pod downwardapi-volume-63d3c68b-84e1-4910-a899-19758eea7348 container client-container: <nil>
STEP: delete the pod
Nov 14 22:29:09.573: INFO: Waiting for pod downwardapi-volume-63d3c68b-84e1-4910-a899-19758eea7348 to disappear
Nov 14 22:29:09.580: INFO: Pod downwardapi-volume-63d3c68b-84e1-4910-a899-19758eea7348 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:29:09.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-715" for this suite.
Nov 14 22:29:15.829: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:29:16.121: INFO: namespace downward-api-715 deletion completed in 6.53378629s

• [SLOW TEST:14.466 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:29:16.142: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-791
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Nov 14 22:29:31.306: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:29:31.306: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-791" for this suite.
W1114 22:29:31.306027      13 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Nov 14 22:29:55.856: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:29:56.231: INFO: namespace gc-791 deletion completed in 24.92136264s

• [SLOW TEST:40.089 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:29:56.252: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1416
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-355c9b1b-83e4-4a2e-a119-7f26dbf40c20
STEP: Creating a pod to test consume configMaps
Nov 14 22:29:57.566: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4de52ed3-7f9a-4b30-8a73-90e9d6bdd680" in namespace "projected-1416" to be "success or failure"
Nov 14 22:29:57.890: INFO: Pod "pod-projected-configmaps-4de52ed3-7f9a-4b30-8a73-90e9d6bdd680": Phase="Pending", Reason="", readiness=false. Elapsed: 322.993771ms
Nov 14 22:30:00.129: INFO: Pod "pod-projected-configmaps-4de52ed3-7f9a-4b30-8a73-90e9d6bdd680": Phase="Pending", Reason="", readiness=false. Elapsed: 2.562323664s
Nov 14 22:30:02.308: INFO: Pod "pod-projected-configmaps-4de52ed3-7f9a-4b30-8a73-90e9d6bdd680": Phase="Pending", Reason="", readiness=false. Elapsed: 4.740602134s
Nov 14 22:30:04.550: INFO: Pod "pod-projected-configmaps-4de52ed3-7f9a-4b30-8a73-90e9d6bdd680": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.983047854s
STEP: Saw pod success
Nov 14 22:30:04.550: INFO: Pod "pod-projected-configmaps-4de52ed3-7f9a-4b30-8a73-90e9d6bdd680" satisfied condition "success or failure"
Nov 14 22:30:04.553: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-0 pod pod-projected-configmaps-4de52ed3-7f9a-4b30-8a73-90e9d6bdd680 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov 14 22:30:04.788: INFO: Waiting for pod pod-projected-configmaps-4de52ed3-7f9a-4b30-8a73-90e9d6bdd680 to disappear
Nov 14 22:30:04.817: INFO: Pod pod-projected-configmaps-4de52ed3-7f9a-4b30-8a73-90e9d6bdd680 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:30:04.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1416" for this suite.
Nov 14 22:30:10.880: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:30:11.054: INFO: namespace projected-1416 deletion completed in 6.230227189s

• [SLOW TEST:14.803 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:30:11.058: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-8401
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test use defaults
Nov 14 22:30:11.621: INFO: Waiting up to 5m0s for pod "client-containers-879606d0-024a-4785-a29f-b61f1e30585d" in namespace "containers-8401" to be "success or failure"
Nov 14 22:30:11.648: INFO: Pod "client-containers-879606d0-024a-4785-a29f-b61f1e30585d": Phase="Pending", Reason="", readiness=false. Elapsed: 27.078157ms
Nov 14 22:30:13.651: INFO: Pod "client-containers-879606d0-024a-4785-a29f-b61f1e30585d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030093016s
Nov 14 22:30:15.860: INFO: Pod "client-containers-879606d0-024a-4785-a29f-b61f1e30585d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.238862556s
Nov 14 22:30:17.987: INFO: Pod "client-containers-879606d0-024a-4785-a29f-b61f1e30585d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.365454747s
Nov 14 22:30:20.013: INFO: Pod "client-containers-879606d0-024a-4785-a29f-b61f1e30585d": Phase="Pending", Reason="", readiness=false. Elapsed: 8.391870436s
Nov 14 22:30:22.028: INFO: Pod "client-containers-879606d0-024a-4785-a29f-b61f1e30585d": Phase="Pending", Reason="", readiness=false. Elapsed: 10.40718278s
Nov 14 22:30:24.133: INFO: Pod "client-containers-879606d0-024a-4785-a29f-b61f1e30585d": Phase="Pending", Reason="", readiness=false. Elapsed: 12.511417391s
Nov 14 22:30:26.200: INFO: Pod "client-containers-879606d0-024a-4785-a29f-b61f1e30585d": Phase="Pending", Reason="", readiness=false. Elapsed: 14.578912364s
Nov 14 22:30:28.382: INFO: Pod "client-containers-879606d0-024a-4785-a29f-b61f1e30585d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 16.760452796s
STEP: Saw pod success
Nov 14 22:30:28.382: INFO: Pod "client-containers-879606d0-024a-4785-a29f-b61f1e30585d" satisfied condition "success or failure"
Nov 14 22:30:28.694: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-1 pod client-containers-879606d0-024a-4785-a29f-b61f1e30585d container test-container: <nil>
STEP: delete the pod
Nov 14 22:30:28.786: INFO: Waiting for pod client-containers-879606d0-024a-4785-a29f-b61f1e30585d to disappear
Nov 14 22:30:28.934: INFO: Pod client-containers-879606d0-024a-4785-a29f-b61f1e30585d no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:30:28.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8401" for this suite.
Nov 14 22:30:37.000: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:30:37.371: INFO: namespace containers-8401 deletion completed in 8.432870778s

• [SLOW TEST:26.313 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:30:37.371: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9899
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Nov 14 22:30:38.675: INFO: Waiting up to 5m0s for pod "downwardapi-volume-af580e6c-94a7-4a3b-ac8e-f4c27d2d0c29" in namespace "projected-9899" to be "success or failure"
Nov 14 22:30:38.981: INFO: Pod "downwardapi-volume-af580e6c-94a7-4a3b-ac8e-f4c27d2d0c29": Phase="Pending", Reason="", readiness=false. Elapsed: 305.851894ms
Nov 14 22:30:41.677: INFO: Pod "downwardapi-volume-af580e6c-94a7-4a3b-ac8e-f4c27d2d0c29": Phase="Pending", Reason="", readiness=false. Elapsed: 3.001156706s
Nov 14 22:30:43.681: INFO: Pod "downwardapi-volume-af580e6c-94a7-4a3b-ac8e-f4c27d2d0c29": Phase="Pending", Reason="", readiness=false. Elapsed: 5.005936354s
Nov 14 22:30:45.882: INFO: Pod "downwardapi-volume-af580e6c-94a7-4a3b-ac8e-f4c27d2d0c29": Phase="Pending", Reason="", readiness=false. Elapsed: 7.206770417s
Nov 14 22:30:47.894: INFO: Pod "downwardapi-volume-af580e6c-94a7-4a3b-ac8e-f4c27d2d0c29": Phase="Succeeded", Reason="", readiness=false. Elapsed: 9.218870471s
STEP: Saw pod success
Nov 14 22:30:47.894: INFO: Pod "downwardapi-volume-af580e6c-94a7-4a3b-ac8e-f4c27d2d0c29" satisfied condition "success or failure"
Nov 14 22:30:47.932: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-0 pod downwardapi-volume-af580e6c-94a7-4a3b-ac8e-f4c27d2d0c29 container client-container: <nil>
STEP: delete the pod
Nov 14 22:30:48.096: INFO: Waiting for pod downwardapi-volume-af580e6c-94a7-4a3b-ac8e-f4c27d2d0c29 to disappear
Nov 14 22:30:48.194: INFO: Pod downwardapi-volume-af580e6c-94a7-4a3b-ac8e-f4c27d2d0c29 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:30:48.194: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9899" for this suite.
Nov 14 22:30:56.581: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:30:57.136: INFO: namespace projected-9899 deletion completed in 8.899937435s

• [SLOW TEST:19.766 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:30:57.140: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-1484
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W1114 22:31:28.542478      13 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Nov 14 22:31:28.542: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:31:28.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1484" for this suite.
Nov 14 22:31:40.700: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:31:41.397: INFO: namespace gc-1484 deletion completed in 12.850612463s

• [SLOW TEST:44.258 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:31:41.406: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-1443
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Nov 14 22:31:42.595: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:31:52.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1443" for this suite.
Nov 14 22:32:00.231: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:32:00.769: INFO: namespace init-container-1443 deletion completed in 8.72384816s

• [SLOW TEST:19.364 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:32:00.772: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename aggregator
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in aggregator-2462
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:76
Nov 14 22:32:01.462: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Registering the sample API server.
Nov 14 22:32:06.092: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Nov 14 22:32:10.334: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367523, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 14 22:32:12.338: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367523, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 14 22:32:14.338: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367523, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 14 22:32:16.392: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367523, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 14 22:32:18.596: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367523, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 14 22:32:20.337: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367523, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 14 22:32:22.339: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367523, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 14 22:32:24.999: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367523, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 14 22:32:26.356: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367523, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 14 22:32:28.506: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367523, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 14 22:32:30.354: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367523, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 14 22:32:32.338: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367523, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 14 22:32:34.373: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367523, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 14 22:32:36.582: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367523, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 14 22:32:38.474: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367523, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 14 22:32:40.877: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367523, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 14 22:32:42.633: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367523, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 14 22:32:44.967: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367523, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 14 22:32:46.670: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367523, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 14 22:32:48.607: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367523, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 14 22:32:50.431: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367523, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 14 22:32:52.749: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367523, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 14 22:32:54.524: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367523, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 14 22:32:56.337: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367523, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 14 22:32:58.428: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367524, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709367523, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 14 22:33:10.772: INFO: Waited 7.554910408s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:67
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:33:15.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-2462" for this suite.
Nov 14 22:33:24.226: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:33:24.391: INFO: namespace aggregator-2462 deletion completed in 8.645328909s

• [SLOW TEST:83.620 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:33:24.408: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9876
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name cm-test-opt-del-aba5d44a-5e55-4742-9bd1-ce840ed300c2
STEP: Creating configMap with name cm-test-opt-upd-88b61afc-517f-48e4-b711-a04016fe140d
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-aba5d44a-5e55-4742-9bd1-ce840ed300c2
STEP: Updating configmap cm-test-opt-upd-88b61afc-517f-48e4-b711-a04016fe140d
STEP: Creating configMap with name cm-test-opt-create-3ca65cc2-dc78-4edd-b658-02bbef6009c1
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:34:46.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9876" for this suite.
Nov 14 22:35:15.306: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:35:16.075: INFO: namespace projected-9876 deletion completed in 29.276289371s

• [SLOW TEST:111.667 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:35:16.086: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-49
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:35:21.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-49" for this suite.
Nov 14 22:36:05.325: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:36:05.681: INFO: namespace kubelet-test-49 deletion completed in 44.617754582s

• [SLOW TEST:49.596 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a read only busybox container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:36:05.709: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-1452
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:36:10.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1452" for this suite.
Nov 14 22:36:16.778: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:36:17.320: INFO: namespace kubelet-test-1452 deletion completed in 6.98434327s

• [SLOW TEST:11.613 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:36:17.352: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-5734
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-5734
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a new StatefulSet
Nov 14 22:36:18.412: INFO: Found 0 stateful pods, waiting for 3
Nov 14 22:36:28.483: INFO: Found 2 stateful pods, waiting for 3
Nov 14 22:36:38.417: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 14 22:36:38.417: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov 14 22:36:38.417: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Nov 14 22:36:48.419: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 14 22:36:48.419: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov 14 22:36:48.420: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Nov 14 22:36:48.454: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 exec --namespace=statefulset-5734 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov 14 22:36:53.972: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Nov 14 22:36:53.972: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov 14 22:36:53.972: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Nov 14 22:36:54.262: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Nov 14 22:37:04.533: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 exec --namespace=statefulset-5734 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 14 22:37:04.898: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Nov 14 22:37:04.898: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov 14 22:37:04.898: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Nov 14 22:37:15.148: INFO: Waiting for StatefulSet statefulset-5734/ss2 to complete update
Nov 14 22:37:15.148: INFO: Waiting for Pod statefulset-5734/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Nov 14 22:37:15.161: INFO: Waiting for Pod statefulset-5734/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Nov 14 22:37:25.252: INFO: Waiting for StatefulSet statefulset-5734/ss2 to complete update
Nov 14 22:37:25.252: INFO: Waiting for Pod statefulset-5734/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Nov 14 22:37:25.253: INFO: Waiting for Pod statefulset-5734/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Nov 14 22:37:35.522: INFO: Waiting for StatefulSet statefulset-5734/ss2 to complete update
Nov 14 22:37:35.522: INFO: Waiting for Pod statefulset-5734/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Nov 14 22:37:45.167: INFO: Waiting for StatefulSet statefulset-5734/ss2 to complete update
Nov 14 22:37:45.167: INFO: Waiting for Pod statefulset-5734/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Nov 14 22:37:55.210: INFO: Waiting for StatefulSet statefulset-5734/ss2 to complete update
Nov 14 22:37:55.210: INFO: Waiting for Pod statefulset-5734/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Nov 14 22:38:05.186: INFO: Waiting for StatefulSet statefulset-5734/ss2 to complete update
STEP: Rolling back to a previous revision
Nov 14 22:38:15.172: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 exec --namespace=statefulset-5734 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov 14 22:38:15.554: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Nov 14 22:38:15.554: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov 14 22:38:15.554: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov 14 22:38:25.596: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Nov 14 22:38:35.868: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 exec --namespace=statefulset-5734 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 14 22:38:36.147: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Nov 14 22:38:36.147: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov 14 22:38:36.147: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Nov 14 22:38:46.169: INFO: Waiting for StatefulSet statefulset-5734/ss2 to complete update
Nov 14 22:38:46.169: INFO: Waiting for Pod statefulset-5734/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Nov 14 22:38:46.170: INFO: Waiting for Pod statefulset-5734/ss2-1 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Nov 14 22:38:56.186: INFO: Waiting for StatefulSet statefulset-5734/ss2 to complete update
Nov 14 22:38:56.187: INFO: Waiting for Pod statefulset-5734/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Nov 14 22:38:56.187: INFO: Waiting for Pod statefulset-5734/ss2-1 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Nov 14 22:39:06.390: INFO: Waiting for StatefulSet statefulset-5734/ss2 to complete update
Nov 14 22:39:06.391: INFO: Waiting for Pod statefulset-5734/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Nov 14 22:39:16.182: INFO: Waiting for StatefulSet statefulset-5734/ss2 to complete update
Nov 14 22:39:16.183: INFO: Waiting for Pod statefulset-5734/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Nov 14 22:39:26.182: INFO: Waiting for StatefulSet statefulset-5734/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Nov 14 22:39:36.194: INFO: Deleting all statefulset in ns statefulset-5734
Nov 14 22:39:36.208: INFO: Scaling statefulset ss2 to 0
Nov 14 22:40:16.244: INFO: Waiting for statefulset status.replicas updated to 0
Nov 14 22:40:16.560: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:40:17.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5734" for this suite.
Nov 14 22:40:29.282: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:40:29.422: INFO: namespace statefulset-5734 deletion completed in 12.375835324s

• [SLOW TEST:252.071 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:40:29.427: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-1934
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:40:30.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1934" for this suite.
Nov 14 22:40:37.112: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:40:37.234: INFO: namespace kubelet-test-1934 deletion completed in 6.394185313s

• [SLOW TEST:7.808 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:40:37.242: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8948
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-8c9ae98b-f441-4d99-babb-6fd130e8647e
STEP: Creating a pod to test consume configMaps
Nov 14 22:40:37.678: INFO: Waiting up to 5m0s for pod "pod-configmaps-d1e463b1-d590-443c-99c6-308fd23e0612" in namespace "configmap-8948" to be "success or failure"
Nov 14 22:40:37.713: INFO: Pod "pod-configmaps-d1e463b1-d590-443c-99c6-308fd23e0612": Phase="Pending", Reason="", readiness=false. Elapsed: 34.348904ms
Nov 14 22:40:39.718: INFO: Pod "pod-configmaps-d1e463b1-d590-443c-99c6-308fd23e0612": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040006404s
Nov 14 22:40:41.734: INFO: Pod "pod-configmaps-d1e463b1-d590-443c-99c6-308fd23e0612": Phase="Pending", Reason="", readiness=false. Elapsed: 4.055547727s
Nov 14 22:40:43.738: INFO: Pod "pod-configmaps-d1e463b1-d590-443c-99c6-308fd23e0612": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.059814137s
STEP: Saw pod success
Nov 14 22:40:43.738: INFO: Pod "pod-configmaps-d1e463b1-d590-443c-99c6-308fd23e0612" satisfied condition "success or failure"
Nov 14 22:40:43.741: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-0 pod pod-configmaps-d1e463b1-d590-443c-99c6-308fd23e0612 container configmap-volume-test: <nil>
STEP: delete the pod
Nov 14 22:40:43.795: INFO: Waiting for pod pod-configmaps-d1e463b1-d590-443c-99c6-308fd23e0612 to disappear
Nov 14 22:40:43.819: INFO: Pod pod-configmaps-d1e463b1-d590-443c-99c6-308fd23e0612 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:40:43.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8948" for this suite.
Nov 14 22:40:49.940: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:40:50.732: INFO: namespace configmap-8948 deletion completed in 6.906208655s

• [SLOW TEST:13.490 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:40:50.733: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-469
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-configmap-h5dj
STEP: Creating a pod to test atomic-volume-subpath
Nov 14 22:40:51.525: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-h5dj" in namespace "subpath-469" to be "success or failure"
Nov 14 22:40:51.745: INFO: Pod "pod-subpath-test-configmap-h5dj": Phase="Pending", Reason="", readiness=false. Elapsed: 220.138429ms
Nov 14 22:40:54.035: INFO: Pod "pod-subpath-test-configmap-h5dj": Phase="Pending", Reason="", readiness=false. Elapsed: 2.509254812s
Nov 14 22:40:56.625: INFO: Pod "pod-subpath-test-configmap-h5dj": Phase="Pending", Reason="", readiness=false. Elapsed: 5.09966655s
Nov 14 22:40:58.628: INFO: Pod "pod-subpath-test-configmap-h5dj": Phase="Pending", Reason="", readiness=false. Elapsed: 7.102771842s
Nov 14 22:41:01.932: INFO: Pod "pod-subpath-test-configmap-h5dj": Phase="Running", Reason="", readiness=true. Elapsed: 10.406601412s
Nov 14 22:41:04.221: INFO: Pod "pod-subpath-test-configmap-h5dj": Phase="Running", Reason="", readiness=true. Elapsed: 12.695960397s
Nov 14 22:41:06.225: INFO: Pod "pod-subpath-test-configmap-h5dj": Phase="Running", Reason="", readiness=true. Elapsed: 14.699855046s
Nov 14 22:41:08.645: INFO: Pod "pod-subpath-test-configmap-h5dj": Phase="Running", Reason="", readiness=true. Elapsed: 17.119358879s
Nov 14 22:41:10.974: INFO: Pod "pod-subpath-test-configmap-h5dj": Phase="Running", Reason="", readiness=true. Elapsed: 19.448909964s
Nov 14 22:41:12.998: INFO: Pod "pod-subpath-test-configmap-h5dj": Phase="Running", Reason="", readiness=true. Elapsed: 21.47237541s
Nov 14 22:41:15.063: INFO: Pod "pod-subpath-test-configmap-h5dj": Phase="Running", Reason="", readiness=true. Elapsed: 23.537768108s
Nov 14 22:41:17.067: INFO: Pod "pod-subpath-test-configmap-h5dj": Phase="Running", Reason="", readiness=true. Elapsed: 25.541455314s
Nov 14 22:41:19.072: INFO: Pod "pod-subpath-test-configmap-h5dj": Phase="Running", Reason="", readiness=true. Elapsed: 27.546846902s
Nov 14 22:41:21.338: INFO: Pod "pod-subpath-test-configmap-h5dj": Phase="Succeeded", Reason="", readiness=false. Elapsed: 29.812284346s
STEP: Saw pod success
Nov 14 22:41:21.338: INFO: Pod "pod-subpath-test-configmap-h5dj" satisfied condition "success or failure"
Nov 14 22:41:21.341: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-1 pod pod-subpath-test-configmap-h5dj container test-container-subpath-configmap-h5dj: <nil>
STEP: delete the pod
Nov 14 22:41:21.951: INFO: Waiting for pod pod-subpath-test-configmap-h5dj to disappear
Nov 14 22:41:22.040: INFO: Pod pod-subpath-test-configmap-h5dj no longer exists
STEP: Deleting pod pod-subpath-test-configmap-h5dj
Nov 14 22:41:22.040: INFO: Deleting pod "pod-subpath-test-configmap-h5dj" in namespace "subpath-469"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:41:22.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-469" for this suite.
Nov 14 22:41:39.235: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:41:39.585: INFO: namespace subpath-469 deletion completed in 16.893237634s

• [SLOW TEST:48.853 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:41:39.594: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-9383
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
Nov 14 22:41:47.233: INFO: 8 pods remaining
Nov 14 22:41:47.233: INFO: 1 pods has nil DeletionTimestamp
Nov 14 22:41:47.234: INFO: 
Nov 14 22:41:48.218: INFO: 0 pods remaining
Nov 14 22:41:48.218: INFO: 0 pods has nil DeletionTimestamp
Nov 14 22:41:48.218: INFO: 
STEP: Gathering metrics
Nov 14 22:41:49.012: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:41:49.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W1114 22:41:49.012311      13 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-9383" for this suite.
Nov 14 22:42:06.188: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:42:07.341: INFO: namespace gc-9383 deletion completed in 17.438339252s

• [SLOW TEST:27.748 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:42:07.349: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7792
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-03e32e29-6a63-44d5-82ec-18a5a305372c
STEP: Creating a pod to test consume configMaps
Nov 14 22:42:09.668: INFO: Waiting up to 5m0s for pod "pod-configmaps-c6b6a648-0356-4da0-a6bb-872ae2f9001e" in namespace "configmap-7792" to be "success or failure"
Nov 14 22:42:09.942: INFO: Pod "pod-configmaps-c6b6a648-0356-4da0-a6bb-872ae2f9001e": Phase="Pending", Reason="", readiness=false. Elapsed: 273.267508ms
Nov 14 22:42:11.947: INFO: Pod "pod-configmaps-c6b6a648-0356-4da0-a6bb-872ae2f9001e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.278124925s
Nov 14 22:42:13.950: INFO: Pod "pod-configmaps-c6b6a648-0356-4da0-a6bb-872ae2f9001e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.281694226s
Nov 14 22:42:15.955: INFO: Pod "pod-configmaps-c6b6a648-0356-4da0-a6bb-872ae2f9001e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.286055905s
Nov 14 22:42:17.969: INFO: Pod "pod-configmaps-c6b6a648-0356-4da0-a6bb-872ae2f9001e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.299960196s
STEP: Saw pod success
Nov 14 22:42:17.969: INFO: Pod "pod-configmaps-c6b6a648-0356-4da0-a6bb-872ae2f9001e" satisfied condition "success or failure"
Nov 14 22:42:17.971: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-0 pod pod-configmaps-c6b6a648-0356-4da0-a6bb-872ae2f9001e container configmap-volume-test: <nil>
STEP: delete the pod
Nov 14 22:42:18.069: INFO: Waiting for pod pod-configmaps-c6b6a648-0356-4da0-a6bb-872ae2f9001e to disappear
Nov 14 22:42:18.192: INFO: Pod pod-configmaps-c6b6a648-0356-4da0-a6bb-872ae2f9001e no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:42:18.193: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7792" for this suite.
Nov 14 22:42:26.339: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:42:26.528: INFO: namespace configmap-7792 deletion completed in 8.330244087s

• [SLOW TEST:19.180 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:42:26.534: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6513
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on node default medium
Nov 14 22:42:26.934: INFO: Waiting up to 5m0s for pod "pod-81e02719-cb25-4a49-8593-95d1aa709186" in namespace "emptydir-6513" to be "success or failure"
Nov 14 22:42:26.967: INFO: Pod "pod-81e02719-cb25-4a49-8593-95d1aa709186": Phase="Pending", Reason="", readiness=false. Elapsed: 33.252141ms
Nov 14 22:42:28.973: INFO: Pod "pod-81e02719-cb25-4a49-8593-95d1aa709186": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039093836s
Nov 14 22:42:30.979: INFO: Pod "pod-81e02719-cb25-4a49-8593-95d1aa709186": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.044913611s
STEP: Saw pod success
Nov 14 22:42:30.979: INFO: Pod "pod-81e02719-cb25-4a49-8593-95d1aa709186" satisfied condition "success or failure"
Nov 14 22:42:30.985: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-1 pod pod-81e02719-cb25-4a49-8593-95d1aa709186 container test-container: <nil>
STEP: delete the pod
Nov 14 22:42:31.197: INFO: Waiting for pod pod-81e02719-cb25-4a49-8593-95d1aa709186 to disappear
Nov 14 22:42:31.248: INFO: Pod pod-81e02719-cb25-4a49-8593-95d1aa709186 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:42:31.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6513" for this suite.
Nov 14 22:42:37.361: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:42:37.614: INFO: namespace emptydir-6513 deletion completed in 6.362005779s

• [SLOW TEST:11.081 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:42:37.619: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-4526
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-4526
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-4526
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-4526
Nov 14 22:42:38.968: INFO: Found 0 stateful pods, waiting for 1
Nov 14 22:42:48.974: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Nov 14 22:42:48.980: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 exec --namespace=statefulset-4526 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov 14 22:42:49.397: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Nov 14 22:42:49.397: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov 14 22:42:49.397: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov 14 22:42:49.400: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Nov 14 22:42:59.404: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov 14 22:42:59.404: INFO: Waiting for statefulset status.replicas updated to 0
Nov 14 22:42:59.534: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999493s
Nov 14 22:43:00.539: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.882128896s
Nov 14 22:43:01.548: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.877502928s
Nov 14 22:43:02.553: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.868328654s
Nov 14 22:43:03.561: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.863266889s
Nov 14 22:43:04.570: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.85502774s
Nov 14 22:43:05.637: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.846423546s
Nov 14 22:43:06.646: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.778811169s
Nov 14 22:43:07.682: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.769966324s
Nov 14 22:43:08.808: INFO: Verifying statefulset ss doesn't scale past 1 for another 733.825011ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-4526
Nov 14 22:43:09.883: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 exec --namespace=statefulset-4526 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 14 22:43:10.173: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Nov 14 22:43:10.174: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov 14 22:43:10.174: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Nov 14 22:43:10.194: INFO: Found 1 stateful pods, waiting for 3
Nov 14 22:43:20.307: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 14 22:43:20.308: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Nov 14 22:43:20.308: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Pending - Ready=false
Nov 14 22:43:30.217: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 14 22:43:30.217: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Nov 14 22:43:30.218: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Nov 14 22:43:30.228: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 exec --namespace=statefulset-4526 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov 14 22:43:30.599: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Nov 14 22:43:30.599: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov 14 22:43:30.599: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov 14 22:43:30.599: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 exec --namespace=statefulset-4526 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov 14 22:43:31.239: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Nov 14 22:43:31.239: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov 14 22:43:31.239: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov 14 22:43:31.239: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 exec --namespace=statefulset-4526 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov 14 22:43:31.879: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Nov 14 22:43:31.879: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov 14 22:43:31.879: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov 14 22:43:31.879: INFO: Waiting for statefulset status.replicas updated to 0
Nov 14 22:43:31.918: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Nov 14 22:43:41.936: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov 14 22:43:41.936: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Nov 14 22:43:41.937: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Nov 14 22:43:42.014: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999505s
Nov 14 22:43:43.039: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.96460556s
Nov 14 22:43:44.108: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.938933148s
Nov 14 22:43:45.114: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.870438571s
Nov 14 22:43:46.121: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.864062273s
Nov 14 22:43:47.128: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.856550938s
Nov 14 22:43:48.135: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.849818174s
Nov 14 22:43:49.142: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.842976606s
Nov 14 22:43:50.249: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.835997833s
Nov 14 22:43:51.289: INFO: Verifying statefulset ss doesn't scale past 3 for another 729.804717ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-4526
Nov 14 22:43:52.474: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 exec --namespace=statefulset-4526 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 14 22:43:53.031: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Nov 14 22:43:53.031: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov 14 22:43:53.031: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Nov 14 22:43:53.032: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 exec --namespace=statefulset-4526 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 14 22:43:53.336: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Nov 14 22:43:53.336: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov 14 22:43:53.336: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Nov 14 22:43:53.336: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 exec --namespace=statefulset-4526 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 14 22:43:53.688: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Nov 14 22:43:53.688: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov 14 22:43:53.688: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Nov 14 22:43:53.688: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Nov 14 22:44:13.708: INFO: Deleting all statefulset in ns statefulset-4526
Nov 14 22:44:13.713: INFO: Scaling statefulset ss to 0
Nov 14 22:44:13.725: INFO: Waiting for statefulset status.replicas updated to 0
Nov 14 22:44:13.728: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:44:13.868: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4526" for this suite.
Nov 14 22:44:22.002: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:44:22.277: INFO: namespace statefulset-4526 deletion completed in 8.404555033s

• [SLOW TEST:104.659 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:44:22.282: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-176
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override arguments
Nov 14 22:44:22.907: INFO: Waiting up to 5m0s for pod "client-containers-68ed6eda-f45a-4a4c-ab78-2d9e7de9bf1a" in namespace "containers-176" to be "success or failure"
Nov 14 22:44:22.936: INFO: Pod "client-containers-68ed6eda-f45a-4a4c-ab78-2d9e7de9bf1a": Phase="Pending", Reason="", readiness=false. Elapsed: 29.353524ms
Nov 14 22:44:24.973: INFO: Pod "client-containers-68ed6eda-f45a-4a4c-ab78-2d9e7de9bf1a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.065831173s
Nov 14 22:44:26.979: INFO: Pod "client-containers-68ed6eda-f45a-4a4c-ab78-2d9e7de9bf1a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.071601633s
STEP: Saw pod success
Nov 14 22:44:26.979: INFO: Pod "client-containers-68ed6eda-f45a-4a4c-ab78-2d9e7de9bf1a" satisfied condition "success or failure"
Nov 14 22:44:26.984: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-1 pod client-containers-68ed6eda-f45a-4a4c-ab78-2d9e7de9bf1a container test-container: <nil>
STEP: delete the pod
Nov 14 22:44:27.151: INFO: Waiting for pod client-containers-68ed6eda-f45a-4a4c-ab78-2d9e7de9bf1a to disappear
Nov 14 22:44:27.224: INFO: Pod client-containers-68ed6eda-f45a-4a4c-ab78-2d9e7de9bf1a no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:44:27.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-176" for this suite.
Nov 14 22:44:35.469: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:44:35.604: INFO: namespace containers-176 deletion completed in 8.187395346s

• [SLOW TEST:13.323 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:44:35.613: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5381
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on tmpfs
Nov 14 22:44:36.111: INFO: Waiting up to 5m0s for pod "pod-74d79090-db69-4fda-a81f-41d286c318f6" in namespace "emptydir-5381" to be "success or failure"
Nov 14 22:44:36.145: INFO: Pod "pod-74d79090-db69-4fda-a81f-41d286c318f6": Phase="Pending", Reason="", readiness=false. Elapsed: 32.872116ms
Nov 14 22:44:38.150: INFO: Pod "pod-74d79090-db69-4fda-a81f-41d286c318f6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038018525s
Nov 14 22:44:40.176: INFO: Pod "pod-74d79090-db69-4fda-a81f-41d286c318f6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.063489756s
Nov 14 22:44:42.230: INFO: Pod "pod-74d79090-db69-4fda-a81f-41d286c318f6": Phase="Pending", Reason="", readiness=false. Elapsed: 6.117946816s
Nov 14 22:44:44.251: INFO: Pod "pod-74d79090-db69-4fda-a81f-41d286c318f6": Phase="Pending", Reason="", readiness=false. Elapsed: 8.138996255s
Nov 14 22:44:47.121: INFO: Pod "pod-74d79090-db69-4fda-a81f-41d286c318f6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 11.008911005s
STEP: Saw pod success
Nov 14 22:44:47.121: INFO: Pod "pod-74d79090-db69-4fda-a81f-41d286c318f6" satisfied condition "success or failure"
Nov 14 22:44:47.123: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-0 pod pod-74d79090-db69-4fda-a81f-41d286c318f6 container test-container: <nil>
STEP: delete the pod
Nov 14 22:44:47.626: INFO: Waiting for pod pod-74d79090-db69-4fda-a81f-41d286c318f6 to disappear
Nov 14 22:44:48.036: INFO: Pod pod-74d79090-db69-4fda-a81f-41d286c318f6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:44:48.036: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5381" for this suite.
Nov 14 22:45:03.498: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:45:04.202: INFO: namespace emptydir-5381 deletion completed in 15.711889679s

• [SLOW TEST:28.589 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:45:04.213: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-684
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Nov 14 22:45:04.861: INFO: Waiting up to 5m0s for pod "downwardapi-volume-72686e56-c0f5-4425-a23a-62e0115cfa6e" in namespace "downward-api-684" to be "success or failure"
Nov 14 22:45:04.892: INFO: Pod "downwardapi-volume-72686e56-c0f5-4425-a23a-62e0115cfa6e": Phase="Pending", Reason="", readiness=false. Elapsed: 29.652417ms
Nov 14 22:45:07.132: INFO: Pod "downwardapi-volume-72686e56-c0f5-4425-a23a-62e0115cfa6e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.269847848s
Nov 14 22:45:09.137: INFO: Pod "downwardapi-volume-72686e56-c0f5-4425-a23a-62e0115cfa6e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.275167109s
Nov 14 22:45:11.144: INFO: Pod "downwardapi-volume-72686e56-c0f5-4425-a23a-62e0115cfa6e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.282059615s
STEP: Saw pod success
Nov 14 22:45:11.145: INFO: Pod "downwardapi-volume-72686e56-c0f5-4425-a23a-62e0115cfa6e" satisfied condition "success or failure"
Nov 14 22:45:11.151: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-1 pod downwardapi-volume-72686e56-c0f5-4425-a23a-62e0115cfa6e container client-container: <nil>
STEP: delete the pod
Nov 14 22:45:11.323: INFO: Waiting for pod downwardapi-volume-72686e56-c0f5-4425-a23a-62e0115cfa6e to disappear
Nov 14 22:45:11.350: INFO: Pod downwardapi-volume-72686e56-c0f5-4425-a23a-62e0115cfa6e no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:45:11.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-684" for this suite.
Nov 14 22:45:19.421: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:45:19.588: INFO: namespace downward-api-684 deletion completed in 8.230962715s

• [SLOW TEST:15.376 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:45:19.591: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-3387
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Nov 14 22:45:31.739: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:45:32.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-3387" for this suite.
Nov 14 22:45:39.202: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:45:39.375: INFO: namespace container-runtime-3387 deletion completed in 6.427467277s

• [SLOW TEST:19.785 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:45:39.388: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-7101
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:45:44.186: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7101" for this suite.
Nov 14 22:46:24.336: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:46:24.723: INFO: namespace kubelet-test-7101 deletion completed in 40.448162899s

• [SLOW TEST:45.335 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command in a pod
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:46:24.741: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-7421
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Nov 14 22:46:25.155: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov 14 22:46:25.358: INFO: Waiting for terminating namespaces to be deleted...
Nov 14 22:46:25.364: INFO: 
Logging pods the kubelet thinks is on node k8s-1-tdyr52fdsot3-minion-0 before test
Nov 14 22:46:25.663: INFO: heapster-868bbf8578-n64qw from kube-system started at 2019-11-14 21:03:34 +0000 UTC (1 container statuses recorded)
Nov 14 22:46:25.664: INFO: 	Container heapster ready: true, restart count 0
Nov 14 22:46:25.664: INFO: kubernetes-dashboard-6bcf74b4cd-6xg4w from kube-system started at 2019-11-14 21:03:35 +0000 UTC (1 container statuses recorded)
Nov 14 22:46:25.664: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Nov 14 22:46:25.664: INFO: sonobuoy-systemd-logs-daemon-set-72adb34422cf47dd-jsls8 from sonobuoy started at 2019-11-14 21:44:03 +0000 UTC (2 container statuses recorded)
Nov 14 22:46:25.664: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Nov 14 22:46:25.664: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 14 22:46:25.664: INFO: coredns-ffc7449c-gjzvx from kube-system started at 2019-11-14 21:03:36 +0000 UTC (1 container statuses recorded)
Nov 14 22:46:25.665: INFO: 	Container coredns ready: true, restart count 0
Nov 14 22:46:25.665: INFO: calico-node-pd87t from kube-system started at 2019-11-14 21:02:40 +0000 UTC (2 container statuses recorded)
Nov 14 22:46:25.665: INFO: 	Container calico-node ready: true, restart count 0
Nov 14 22:46:25.666: INFO: 	Container install-cni ready: true, restart count 0
Nov 14 22:46:25.666: INFO: coredns-ffc7449c-87zqg from kube-system started at 2019-11-14 21:03:34 +0000 UTC (1 container statuses recorded)
Nov 14 22:46:25.666: INFO: 	Container coredns ready: true, restart count 0
Nov 14 22:46:25.667: INFO: kube-dns-autoscaler-6d5d44bf86-j5ft5 from kube-system started at 2019-11-14 21:03:34 +0000 UTC (1 container statuses recorded)
Nov 14 22:46:25.667: INFO: 	Container autoscaler ready: true, restart count 0
Nov 14 22:46:25.667: INFO: 
Logging pods the kubelet thinks is on node k8s-1-tdyr52fdsot3-minion-1 before test
Nov 14 22:46:25.981: INFO: calico-node-xt7x6 from kube-system started at 2019-11-14 21:40:55 +0000 UTC (2 container statuses recorded)
Nov 14 22:46:25.982: INFO: 	Container calico-node ready: true, restart count 0
Nov 14 22:46:25.982: INFO: 	Container install-cni ready: true, restart count 0
Nov 14 22:46:25.982: INFO: sonobuoy from sonobuoy started at 2019-11-14 21:43:40 +0000 UTC (1 container statuses recorded)
Nov 14 22:46:25.982: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov 14 22:46:25.983: INFO: sonobuoy-e2e-job-bf04e2a15c5e4b97 from sonobuoy started at 2019-11-14 21:44:02 +0000 UTC (2 container statuses recorded)
Nov 14 22:46:25.983: INFO: 	Container e2e ready: true, restart count 0
Nov 14 22:46:25.983: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 14 22:46:25.983: INFO: sonobuoy-systemd-logs-daemon-set-72adb34422cf47dd-v5lkx from sonobuoy started at 2019-11-14 21:44:04 +0000 UTC (2 container statuses recorded)
Nov 14 22:46:25.983: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Nov 14 22:46:25.983: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: verifying the node has the label node k8s-1-tdyr52fdsot3-minion-0
STEP: verifying the node has the label node k8s-1-tdyr52fdsot3-minion-1
Nov 14 22:46:26.494: INFO: Pod calico-node-pd87t requesting resource cpu=250m on Node k8s-1-tdyr52fdsot3-minion-0
Nov 14 22:46:26.494: INFO: Pod calico-node-xt7x6 requesting resource cpu=250m on Node k8s-1-tdyr52fdsot3-minion-1
Nov 14 22:46:26.495: INFO: Pod coredns-ffc7449c-87zqg requesting resource cpu=100m on Node k8s-1-tdyr52fdsot3-minion-0
Nov 14 22:46:26.495: INFO: Pod coredns-ffc7449c-gjzvx requesting resource cpu=100m on Node k8s-1-tdyr52fdsot3-minion-0
Nov 14 22:46:26.495: INFO: Pod heapster-868bbf8578-n64qw requesting resource cpu=0m on Node k8s-1-tdyr52fdsot3-minion-0
Nov 14 22:46:26.495: INFO: Pod kube-dns-autoscaler-6d5d44bf86-j5ft5 requesting resource cpu=20m on Node k8s-1-tdyr52fdsot3-minion-0
Nov 14 22:46:26.495: INFO: Pod kubernetes-dashboard-6bcf74b4cd-6xg4w requesting resource cpu=0m on Node k8s-1-tdyr52fdsot3-minion-0
Nov 14 22:46:26.495: INFO: Pod sonobuoy requesting resource cpu=0m on Node k8s-1-tdyr52fdsot3-minion-1
Nov 14 22:46:26.495: INFO: Pod sonobuoy-e2e-job-bf04e2a15c5e4b97 requesting resource cpu=0m on Node k8s-1-tdyr52fdsot3-minion-1
Nov 14 22:46:26.495: INFO: Pod sonobuoy-systemd-logs-daemon-set-72adb34422cf47dd-jsls8 requesting resource cpu=0m on Node k8s-1-tdyr52fdsot3-minion-0
Nov 14 22:46:26.496: INFO: Pod sonobuoy-systemd-logs-daemon-set-72adb34422cf47dd-v5lkx requesting resource cpu=0m on Node k8s-1-tdyr52fdsot3-minion-1
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d4e5b082-9783-4957-9fa1-84dc84bd0c03.15d728eb5b7b25b8], Reason = [Scheduled], Message = [Successfully assigned sched-pred-7421/filler-pod-d4e5b082-9783-4957-9fa1-84dc84bd0c03 to k8s-1-tdyr52fdsot3-minion-1]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d4e5b082-9783-4957-9fa1-84dc84bd0c03.15d728ec5ff7eee3], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d4e5b082-9783-4957-9fa1-84dc84bd0c03.15d728ec8c9ccdec], Reason = [Created], Message = [Created container filler-pod-d4e5b082-9783-4957-9fa1-84dc84bd0c03]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d4e5b082-9783-4957-9fa1-84dc84bd0c03.15d728eca4cd9b55], Reason = [Started], Message = [Started container filler-pod-d4e5b082-9783-4957-9fa1-84dc84bd0c03]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-fad71dc8-2426-4a4c-bf59-8b8e50d1c37e.15d728eb501048a4], Reason = [Scheduled], Message = [Successfully assigned sched-pred-7421/filler-pod-fad71dc8-2426-4a4c-bf59-8b8e50d1c37e to k8s-1-tdyr52fdsot3-minion-0]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-fad71dc8-2426-4a4c-bf59-8b8e50d1c37e.15d728eca7c0f17b], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-fad71dc8-2426-4a4c-bf59-8b8e50d1c37e.15d728ed19aa9be9], Reason = [Created], Message = [Created container filler-pod-fad71dc8-2426-4a4c-bf59-8b8e50d1c37e]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-fad71dc8-2426-4a4c-bf59-8b8e50d1c37e.15d728ed29845215], Reason = [Started], Message = [Started container filler-pod-fad71dc8-2426-4a4c-bf59-8b8e50d1c37e]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15d728ed632637fa], Reason = [FailedScheduling], Message = [0/3 nodes are available: 1 node(s) had taints that the pod didn't tolerate, 2 Insufficient cpu.]
STEP: removing the label node off the node k8s-1-tdyr52fdsot3-minion-1
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node k8s-1-tdyr52fdsot3-minion-0
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:46:36.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-7421" for this suite.
Nov 14 22:46:48.965: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:46:49.102: INFO: namespace sched-pred-7421 deletion completed in 12.176694456s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:24.362 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:46:49.106: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9322
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1456
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Nov 14 22:46:50.442: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-9322'
Nov 14 22:46:50.881: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Nov 14 22:46:50.881: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Nov 14 22:46:51.130: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-dpggc]
Nov 14 22:46:51.130: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-dpggc" in namespace "kubectl-9322" to be "running and ready"
Nov 14 22:46:52.442: INFO: Pod "e2e-test-nginx-rc-dpggc": Phase="Pending", Reason="", readiness=false. Elapsed: 1.311739319s
Nov 14 22:46:54.609: INFO: Pod "e2e-test-nginx-rc-dpggc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.47861998s
Nov 14 22:46:56.949: INFO: Pod "e2e-test-nginx-rc-dpggc": Phase="Pending", Reason="", readiness=false. Elapsed: 5.819295559s
Nov 14 22:46:59.085: INFO: Pod "e2e-test-nginx-rc-dpggc": Phase="Pending", Reason="", readiness=false. Elapsed: 7.955070289s
Nov 14 22:47:01.113: INFO: Pod "e2e-test-nginx-rc-dpggc": Phase="Running", Reason="", readiness=true. Elapsed: 9.982396423s
Nov 14 22:47:01.113: INFO: Pod "e2e-test-nginx-rc-dpggc" satisfied condition "running and ready"
Nov 14 22:47:01.113: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-dpggc]
Nov 14 22:47:01.113: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 logs rc/e2e-test-nginx-rc --namespace=kubectl-9322'
Nov 14 22:47:05.147: INFO: stderr: ""
Nov 14 22:47:05.147: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1461
Nov 14 22:47:05.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 delete rc e2e-test-nginx-rc --namespace=kubectl-9322'
Nov 14 22:47:05.317: INFO: stderr: ""
Nov 14 22:47:05.318: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:47:05.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9322" for this suite.
Nov 14 22:47:13.453: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:47:13.718: INFO: namespace kubectl-9322 deletion completed in 8.394074438s

• [SLOW TEST:24.613 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:47:13.722: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9768
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: validating cluster-info
Nov 14 22:47:14.545: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 cluster-info'
Nov 14 22:47:14.665: INFO: stderr: ""
Nov 14 22:47:14.665: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.254.0.1:443\x1b[0m\n\x1b[0;32mHeapster\x1b[0m is running at \x1b[0;33mhttps://10.254.0.1:443/api/v1/namespaces/kube-system/services/heapster/proxy\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://10.254.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:47:14.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9768" for this suite.
Nov 14 22:47:20.981: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:47:21.122: INFO: namespace kubectl-9768 deletion completed in 6.453769487s

• [SLOW TEST:7.400 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:47:21.125: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-3343
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Nov 14 22:47:40.846: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 14 22:47:40.901: INFO: Pod pod-with-prestop-exec-hook still exists
Nov 14 22:47:42.901: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 14 22:47:42.904: INFO: Pod pod-with-prestop-exec-hook still exists
Nov 14 22:47:44.901: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 14 22:47:44.908: INFO: Pod pod-with-prestop-exec-hook still exists
Nov 14 22:47:46.901: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 14 22:47:46.905: INFO: Pod pod-with-prestop-exec-hook still exists
Nov 14 22:47:48.901: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 14 22:47:48.906: INFO: Pod pod-with-prestop-exec-hook still exists
Nov 14 22:47:50.901: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 14 22:47:51.032: INFO: Pod pod-with-prestop-exec-hook still exists
Nov 14 22:47:52.901: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 14 22:47:52.905: INFO: Pod pod-with-prestop-exec-hook still exists
Nov 14 22:47:54.901: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 14 22:47:54.930: INFO: Pod pod-with-prestop-exec-hook still exists
Nov 14 22:47:56.901: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 14 22:47:56.919: INFO: Pod pod-with-prestop-exec-hook still exists
Nov 14 22:47:58.901: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 14 22:47:58.904: INFO: Pod pod-with-prestop-exec-hook still exists
Nov 14 22:48:00.901: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 14 22:48:00.926: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:48:01.027: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-3343" for this suite.
Nov 14 22:48:25.572: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:48:25.994: INFO: namespace container-lifecycle-hook-3343 deletion completed in 24.83255612s

• [SLOW TEST:64.870 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:48:25.998: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-9239
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Nov 14 22:48:26.728: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"4d988436-7537-406d-8de8-81cc99847521", Controller:(*bool)(0xc003a16456), BlockOwnerDeletion:(*bool)(0xc003a16457)}}
Nov 14 22:48:26.916: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"8c731fbf-a05a-4ddf-97de-ab65a22532f0", Controller:(*bool)(0xc003a1660a), BlockOwnerDeletion:(*bool)(0xc003a1660b)}}
Nov 14 22:48:26.952: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"c356dfbb-653d-4f5b-8150-3e15d119e92a", Controller:(*bool)(0xc003a16816), BlockOwnerDeletion:(*bool)(0xc003a16817)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:48:32.285: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9239" for this suite.
Nov 14 22:48:38.591: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:48:38.732: INFO: namespace gc-9239 deletion completed in 6.439188292s

• [SLOW TEST:12.734 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:48:38.738: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3344
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name secret-emptykey-test-582b09fa-cadb-424e-996b-11ecfa7ce303
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:48:39.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3344" for this suite.
Nov 14 22:48:45.522: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:48:45.715: INFO: namespace secrets-3344 deletion completed in 6.239038741s

• [SLOW TEST:6.978 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:48:45.716: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-8325
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-downwardapi-ptjv
STEP: Creating a pod to test atomic-volume-subpath
Nov 14 22:48:46.758: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-ptjv" in namespace "subpath-8325" to be "success or failure"
Nov 14 22:48:47.046: INFO: Pod "pod-subpath-test-downwardapi-ptjv": Phase="Pending", Reason="", readiness=false. Elapsed: 288.085608ms
Nov 14 22:48:49.216: INFO: Pod "pod-subpath-test-downwardapi-ptjv": Phase="Pending", Reason="", readiness=false. Elapsed: 2.457974081s
Nov 14 22:48:51.336: INFO: Pod "pod-subpath-test-downwardapi-ptjv": Phase="Pending", Reason="", readiness=false. Elapsed: 4.578054567s
Nov 14 22:48:53.345: INFO: Pod "pod-subpath-test-downwardapi-ptjv": Phase="Pending", Reason="", readiness=false. Elapsed: 6.586839581s
Nov 14 22:48:55.350: INFO: Pod "pod-subpath-test-downwardapi-ptjv": Phase="Pending", Reason="", readiness=false. Elapsed: 8.592155012s
Nov 14 22:48:57.354: INFO: Pod "pod-subpath-test-downwardapi-ptjv": Phase="Running", Reason="", readiness=true. Elapsed: 10.596149954s
Nov 14 22:48:59.360: INFO: Pod "pod-subpath-test-downwardapi-ptjv": Phase="Running", Reason="", readiness=true. Elapsed: 12.60201768s
Nov 14 22:49:01.365: INFO: Pod "pod-subpath-test-downwardapi-ptjv": Phase="Running", Reason="", readiness=true. Elapsed: 14.606686627s
Nov 14 22:49:03.371: INFO: Pod "pod-subpath-test-downwardapi-ptjv": Phase="Running", Reason="", readiness=true. Elapsed: 16.613081772s
Nov 14 22:49:05.376: INFO: Pod "pod-subpath-test-downwardapi-ptjv": Phase="Running", Reason="", readiness=true. Elapsed: 18.617393262s
Nov 14 22:49:07.383: INFO: Pod "pod-subpath-test-downwardapi-ptjv": Phase="Running", Reason="", readiness=true. Elapsed: 20.624352549s
Nov 14 22:49:09.388: INFO: Pod "pod-subpath-test-downwardapi-ptjv": Phase="Running", Reason="", readiness=true. Elapsed: 22.62998143s
Nov 14 22:49:11.393: INFO: Pod "pod-subpath-test-downwardapi-ptjv": Phase="Running", Reason="", readiness=true. Elapsed: 24.634335619s
Nov 14 22:49:13.398: INFO: Pod "pod-subpath-test-downwardapi-ptjv": Phase="Running", Reason="", readiness=true. Elapsed: 26.639604298s
Nov 14 22:49:15.542: INFO: Pod "pod-subpath-test-downwardapi-ptjv": Phase="Running", Reason="", readiness=true. Elapsed: 28.783430884s
Nov 14 22:49:17.549: INFO: Pod "pod-subpath-test-downwardapi-ptjv": Phase="Succeeded", Reason="", readiness=false. Elapsed: 30.791033739s
STEP: Saw pod success
Nov 14 22:49:17.549: INFO: Pod "pod-subpath-test-downwardapi-ptjv" satisfied condition "success or failure"
Nov 14 22:49:17.552: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-0 pod pod-subpath-test-downwardapi-ptjv container test-container-subpath-downwardapi-ptjv: <nil>
STEP: delete the pod
Nov 14 22:49:17.633: INFO: Waiting for pod pod-subpath-test-downwardapi-ptjv to disappear
Nov 14 22:49:17.726: INFO: Pod pod-subpath-test-downwardapi-ptjv no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-ptjv
Nov 14 22:49:17.726: INFO: Deleting pod "pod-subpath-test-downwardapi-ptjv" in namespace "subpath-8325"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:49:17.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8325" for this suite.
Nov 14 22:49:26.087: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:49:26.342: INFO: namespace subpath-8325 deletion completed in 8.347739823s

• [SLOW TEST:40.627 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:49:26.347: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-4855
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:49:26.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4855" for this suite.
Nov 14 22:49:32.862: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:49:32.998: INFO: namespace services-4855 deletion completed in 6.219100098s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:6.652 seconds]
[sig-network] Services
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide secure master service  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:49:33.005: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-9780
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-projected-dhqx
STEP: Creating a pod to test atomic-volume-subpath
Nov 14 22:49:33.681: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-dhqx" in namespace "subpath-9780" to be "success or failure"
Nov 14 22:49:33.715: INFO: Pod "pod-subpath-test-projected-dhqx": Phase="Pending", Reason="", readiness=false. Elapsed: 33.642512ms
Nov 14 22:49:35.722: INFO: Pod "pod-subpath-test-projected-dhqx": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039974608s
Nov 14 22:49:37.726: INFO: Pod "pod-subpath-test-projected-dhqx": Phase="Running", Reason="", readiness=true. Elapsed: 4.044007709s
Nov 14 22:49:39.729: INFO: Pod "pod-subpath-test-projected-dhqx": Phase="Running", Reason="", readiness=true. Elapsed: 6.047886365s
Nov 14 22:49:41.736: INFO: Pod "pod-subpath-test-projected-dhqx": Phase="Running", Reason="", readiness=true. Elapsed: 8.0545275s
Nov 14 22:49:43.740: INFO: Pod "pod-subpath-test-projected-dhqx": Phase="Running", Reason="", readiness=true. Elapsed: 10.058140481s
Nov 14 22:49:45.747: INFO: Pod "pod-subpath-test-projected-dhqx": Phase="Running", Reason="", readiness=true. Elapsed: 12.065096248s
Nov 14 22:49:47.754: INFO: Pod "pod-subpath-test-projected-dhqx": Phase="Running", Reason="", readiness=true. Elapsed: 14.072527246s
Nov 14 22:49:49.847: INFO: Pod "pod-subpath-test-projected-dhqx": Phase="Running", Reason="", readiness=true. Elapsed: 16.165286651s
Nov 14 22:49:51.908: INFO: Pod "pod-subpath-test-projected-dhqx": Phase="Running", Reason="", readiness=true. Elapsed: 18.226644068s
Nov 14 22:49:53.926: INFO: Pod "pod-subpath-test-projected-dhqx": Phase="Running", Reason="", readiness=true. Elapsed: 20.244103675s
Nov 14 22:49:55.964: INFO: Pod "pod-subpath-test-projected-dhqx": Phase="Running", Reason="", readiness=true. Elapsed: 22.28208097s
Nov 14 22:49:58.154: INFO: Pod "pod-subpath-test-projected-dhqx": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.472560625s
STEP: Saw pod success
Nov 14 22:49:58.154: INFO: Pod "pod-subpath-test-projected-dhqx" satisfied condition "success or failure"
Nov 14 22:49:58.159: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-1 pod pod-subpath-test-projected-dhqx container test-container-subpath-projected-dhqx: <nil>
STEP: delete the pod
Nov 14 22:49:58.464: INFO: Waiting for pod pod-subpath-test-projected-dhqx to disappear
Nov 14 22:49:58.736: INFO: Pod pod-subpath-test-projected-dhqx no longer exists
STEP: Deleting pod pod-subpath-test-projected-dhqx
Nov 14 22:49:58.737: INFO: Deleting pod "pod-subpath-test-projected-dhqx" in namespace "subpath-9780"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:49:58.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9780" for this suite.
Nov 14 22:50:07.271: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:50:07.589: INFO: namespace subpath-9780 deletion completed in 8.843439728s

• [SLOW TEST:34.585 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:50:07.597: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-5049
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-5049
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Nov 14 22:50:09.247: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Nov 14 22:50:59.692: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.1.73:8080/dial?request=hostName&protocol=http&host=192.168.2.69&port=8080&tries=1'] Namespace:pod-network-test-5049 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 14 22:50:59.693: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
Nov 14 22:51:00.334: INFO: Waiting for endpoints: map[]
Nov 14 22:51:00.375: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.1.73:8080/dial?request=hostName&protocol=http&host=192.168.1.72&port=8080&tries=1'] Namespace:pod-network-test-5049 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 14 22:51:00.375: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
Nov 14 22:51:00.586: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:51:00.586: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5049" for this suite.
Nov 14 22:51:30.693: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:51:31.048: INFO: namespace pod-network-test-5049 deletion completed in 30.42127217s

• [SLOW TEST:83.452 seconds]
[sig-network] Networking
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:51:31.050: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-79
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-c6cb5dcc-3ae6-4750-bd56-2ee838728154
STEP: Creating a pod to test consume configMaps
Nov 14 22:51:31.804: INFO: Waiting up to 5m0s for pod "pod-configmaps-70a3d456-dba3-416a-9919-e54e9fd2560f" in namespace "configmap-79" to be "success or failure"
Nov 14 22:51:32.054: INFO: Pod "pod-configmaps-70a3d456-dba3-416a-9919-e54e9fd2560f": Phase="Pending", Reason="", readiness=false. Elapsed: 250.608316ms
Nov 14 22:51:34.120: INFO: Pod "pod-configmaps-70a3d456-dba3-416a-9919-e54e9fd2560f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.315813446s
Nov 14 22:51:36.123: INFO: Pod "pod-configmaps-70a3d456-dba3-416a-9919-e54e9fd2560f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.319167141s
Nov 14 22:51:38.129: INFO: Pod "pod-configmaps-70a3d456-dba3-416a-9919-e54e9fd2560f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.325669488s
STEP: Saw pod success
Nov 14 22:51:38.131: INFO: Pod "pod-configmaps-70a3d456-dba3-416a-9919-e54e9fd2560f" satisfied condition "success or failure"
Nov 14 22:51:38.135: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-0 pod pod-configmaps-70a3d456-dba3-416a-9919-e54e9fd2560f container configmap-volume-test: <nil>
STEP: delete the pod
Nov 14 22:51:38.367: INFO: Waiting for pod pod-configmaps-70a3d456-dba3-416a-9919-e54e9fd2560f to disappear
Nov 14 22:51:38.392: INFO: Pod pod-configmaps-70a3d456-dba3-416a-9919-e54e9fd2560f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:51:38.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-79" for this suite.
Nov 14 22:51:46.623: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:51:46.776: INFO: namespace configmap-79 deletion completed in 8.377618985s

• [SLOW TEST:15.727 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:51:46.785: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-381
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-85979e8e-eb16-4521-acf4-7f7418ccd1b4
STEP: Creating a pod to test consume secrets
Nov 14 22:51:47.561: INFO: Waiting up to 5m0s for pod "pod-secrets-e7999b60-e7bd-4040-b601-6f3ac7c6ef50" in namespace "secrets-381" to be "success or failure"
Nov 14 22:51:47.597: INFO: Pod "pod-secrets-e7999b60-e7bd-4040-b601-6f3ac7c6ef50": Phase="Pending", Reason="", readiness=false. Elapsed: 35.681797ms
Nov 14 22:51:49.600: INFO: Pod "pod-secrets-e7999b60-e7bd-4040-b601-6f3ac7c6ef50": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038821291s
Nov 14 22:51:51.621: INFO: Pod "pod-secrets-e7999b60-e7bd-4040-b601-6f3ac7c6ef50": Phase="Pending", Reason="", readiness=false. Elapsed: 4.059874297s
Nov 14 22:51:53.627: INFO: Pod "pod-secrets-e7999b60-e7bd-4040-b601-6f3ac7c6ef50": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.065704548s
STEP: Saw pod success
Nov 14 22:51:53.628: INFO: Pod "pod-secrets-e7999b60-e7bd-4040-b601-6f3ac7c6ef50" satisfied condition "success or failure"
Nov 14 22:51:53.634: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-0 pod pod-secrets-e7999b60-e7bd-4040-b601-6f3ac7c6ef50 container secret-volume-test: <nil>
STEP: delete the pod
Nov 14 22:51:53.788: INFO: Waiting for pod pod-secrets-e7999b60-e7bd-4040-b601-6f3ac7c6ef50 to disappear
Nov 14 22:51:53.822: INFO: Pod pod-secrets-e7999b60-e7bd-4040-b601-6f3ac7c6ef50 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:51:53.822: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-381" for this suite.
Nov 14 22:51:59.974: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:52:00.270: INFO: namespace secrets-381 deletion completed in 6.443415476s

• [SLOW TEST:13.486 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:52:00.277: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-2643
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Nov 14 22:52:01.219: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov 14 22:52:01.308: INFO: Waiting for terminating namespaces to be deleted...
Nov 14 22:52:01.313: INFO: 
Logging pods the kubelet thinks is on node k8s-1-tdyr52fdsot3-minion-0 before test
Nov 14 22:52:01.341: INFO: calico-node-pd87t from kube-system started at 2019-11-14 21:02:40 +0000 UTC (2 container statuses recorded)
Nov 14 22:52:01.341: INFO: 	Container calico-node ready: true, restart count 0
Nov 14 22:52:01.341: INFO: 	Container install-cni ready: true, restart count 0
Nov 14 22:52:01.341: INFO: coredns-ffc7449c-87zqg from kube-system started at 2019-11-14 21:03:34 +0000 UTC (1 container statuses recorded)
Nov 14 22:52:01.342: INFO: 	Container coredns ready: true, restart count 0
Nov 14 22:52:01.342: INFO: kube-dns-autoscaler-6d5d44bf86-j5ft5 from kube-system started at 2019-11-14 21:03:34 +0000 UTC (1 container statuses recorded)
Nov 14 22:52:01.342: INFO: 	Container autoscaler ready: true, restart count 0
Nov 14 22:52:01.342: INFO: coredns-ffc7449c-gjzvx from kube-system started at 2019-11-14 21:03:36 +0000 UTC (1 container statuses recorded)
Nov 14 22:52:01.343: INFO: 	Container coredns ready: true, restart count 0
Nov 14 22:52:01.343: INFO: heapster-868bbf8578-n64qw from kube-system started at 2019-11-14 21:03:34 +0000 UTC (1 container statuses recorded)
Nov 14 22:52:01.343: INFO: 	Container heapster ready: true, restart count 0
Nov 14 22:52:01.343: INFO: kubernetes-dashboard-6bcf74b4cd-6xg4w from kube-system started at 2019-11-14 21:03:35 +0000 UTC (1 container statuses recorded)
Nov 14 22:52:01.344: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Nov 14 22:52:01.344: INFO: sonobuoy-systemd-logs-daemon-set-72adb34422cf47dd-jsls8 from sonobuoy started at 2019-11-14 21:44:03 +0000 UTC (2 container statuses recorded)
Nov 14 22:52:01.344: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Nov 14 22:52:01.344: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 14 22:52:01.345: INFO: 
Logging pods the kubelet thinks is on node k8s-1-tdyr52fdsot3-minion-1 before test
Nov 14 22:52:01.362: INFO: calico-node-xt7x6 from kube-system started at 2019-11-14 21:40:55 +0000 UTC (2 container statuses recorded)
Nov 14 22:52:01.363: INFO: 	Container calico-node ready: true, restart count 0
Nov 14 22:52:01.364: INFO: 	Container install-cni ready: true, restart count 0
Nov 14 22:52:01.364: INFO: sonobuoy from sonobuoy started at 2019-11-14 21:43:40 +0000 UTC (1 container statuses recorded)
Nov 14 22:52:01.364: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov 14 22:52:01.365: INFO: sonobuoy-e2e-job-bf04e2a15c5e4b97 from sonobuoy started at 2019-11-14 21:44:02 +0000 UTC (2 container statuses recorded)
Nov 14 22:52:01.365: INFO: 	Container e2e ready: true, restart count 0
Nov 14 22:52:01.365: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 14 22:52:01.365: INFO: sonobuoy-systemd-logs-daemon-set-72adb34422cf47dd-v5lkx from sonobuoy started at 2019-11-14 21:44:04 +0000 UTC (2 container statuses recorded)
Nov 14 22:52:01.365: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Nov 14 22:52:01.365: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-b1f22f94-e06e-44ad-b381-83d642bade1c 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-b1f22f94-e06e-44ad-b381-83d642bade1c off the node k8s-1-tdyr52fdsot3-minion-1
STEP: verifying the node doesn't have the label kubernetes.io/e2e-b1f22f94-e06e-44ad-b381-83d642bade1c
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:52:10.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2643" for this suite.
Nov 14 22:52:22.661: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:52:22.801: INFO: namespace sched-pred-2643 deletion completed in 12.183259265s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:22.525 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:52:22.805: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2524
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-c8379965-f859-46fe-8fc3-e5bcd726a76d
STEP: Creating a pod to test consume configMaps
Nov 14 22:52:23.780: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-9e6996c6-05eb-4338-bdca-eb24d50e52c3" in namespace "projected-2524" to be "success or failure"
Nov 14 22:52:24.057: INFO: Pod "pod-projected-configmaps-9e6996c6-05eb-4338-bdca-eb24d50e52c3": Phase="Pending", Reason="", readiness=false. Elapsed: 277.564463ms
Nov 14 22:52:27.081: INFO: Pod "pod-projected-configmaps-9e6996c6-05eb-4338-bdca-eb24d50e52c3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.30092794s
Nov 14 22:52:29.176: INFO: Pod "pod-projected-configmaps-9e6996c6-05eb-4338-bdca-eb24d50e52c3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.396036046s
Nov 14 22:52:31.251: INFO: Pod "pod-projected-configmaps-9e6996c6-05eb-4338-bdca-eb24d50e52c3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 7.470897698s
STEP: Saw pod success
Nov 14 22:52:31.252: INFO: Pod "pod-projected-configmaps-9e6996c6-05eb-4338-bdca-eb24d50e52c3" satisfied condition "success or failure"
Nov 14 22:52:31.332: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-1 pod pod-projected-configmaps-9e6996c6-05eb-4338-bdca-eb24d50e52c3 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov 14 22:52:31.626: INFO: Waiting for pod pod-projected-configmaps-9e6996c6-05eb-4338-bdca-eb24d50e52c3 to disappear
Nov 14 22:52:31.718: INFO: Pod pod-projected-configmaps-9e6996c6-05eb-4338-bdca-eb24d50e52c3 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:52:31.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2524" for this suite.
Nov 14 22:52:37.857: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:52:38.016: INFO: namespace projected-2524 deletion completed in 6.206247371s

• [SLOW TEST:15.212 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:52:38.021: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7076
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Nov 14 22:52:38.821: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c847c509-39dc-4d7c-bdab-6257cfde454f" in namespace "downward-api-7076" to be "success or failure"
Nov 14 22:52:38.884: INFO: Pod "downwardapi-volume-c847c509-39dc-4d7c-bdab-6257cfde454f": Phase="Pending", Reason="", readiness=false. Elapsed: 62.420166ms
Nov 14 22:52:40.888: INFO: Pod "downwardapi-volume-c847c509-39dc-4d7c-bdab-6257cfde454f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.066249414s
Nov 14 22:52:42.895: INFO: Pod "downwardapi-volume-c847c509-39dc-4d7c-bdab-6257cfde454f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.073215328s
Nov 14 22:52:44.898: INFO: Pod "downwardapi-volume-c847c509-39dc-4d7c-bdab-6257cfde454f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.076454741s
STEP: Saw pod success
Nov 14 22:52:44.899: INFO: Pod "downwardapi-volume-c847c509-39dc-4d7c-bdab-6257cfde454f" satisfied condition "success or failure"
Nov 14 22:52:44.901: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-0 pod downwardapi-volume-c847c509-39dc-4d7c-bdab-6257cfde454f container client-container: <nil>
STEP: delete the pod
Nov 14 22:52:45.087: INFO: Waiting for pod downwardapi-volume-c847c509-39dc-4d7c-bdab-6257cfde454f to disappear
Nov 14 22:52:45.143: INFO: Pod downwardapi-volume-c847c509-39dc-4d7c-bdab-6257cfde454f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:52:45.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7076" for this suite.
Nov 14 22:52:51.331: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:52:51.459: INFO: namespace downward-api-7076 deletion completed in 6.269557932s

• [SLOW TEST:13.439 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:52:51.462: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6240
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1210
STEP: creating the pod
Nov 14 22:52:52.077: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 create -f - --namespace=kubectl-6240'
Nov 14 22:52:52.768: INFO: stderr: ""
Nov 14 22:52:52.768: INFO: stdout: "pod/pause created\n"
Nov 14 22:52:52.768: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Nov 14 22:52:52.768: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-6240" to be "running and ready"
Nov 14 22:52:53.054: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 285.732993ms
Nov 14 22:52:55.126: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.357883053s
Nov 14 22:52:57.134: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.366344568s
Nov 14 22:52:57.134: INFO: Pod "pause" satisfied condition "running and ready"
Nov 14 22:52:57.134: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: adding the label testing-label with value testing-label-value to a pod
Nov 14 22:52:57.134: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 label pods pause testing-label=testing-label-value --namespace=kubectl-6240'
Nov 14 22:52:57.291: INFO: stderr: ""
Nov 14 22:52:57.291: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Nov 14 22:52:57.291: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 get pod pause -L testing-label --namespace=kubectl-6240'
Nov 14 22:52:57.517: INFO: stderr: ""
Nov 14 22:52:57.517: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Nov 14 22:52:57.517: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 label pods pause testing-label- --namespace=kubectl-6240'
Nov 14 22:52:57.656: INFO: stderr: ""
Nov 14 22:52:57.656: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Nov 14 22:52:57.656: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 get pod pause -L testing-label --namespace=kubectl-6240'
Nov 14 22:52:57.802: INFO: stderr: ""
Nov 14 22:52:57.802: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1217
STEP: using delete to clean up resources
Nov 14 22:52:57.803: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 delete --grace-period=0 --force -f - --namespace=kubectl-6240'
Nov 14 22:52:58.245: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 14 22:52:58.245: INFO: stdout: "pod \"pause\" force deleted\n"
Nov 14 22:52:58.245: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 get rc,svc -l name=pause --no-headers --namespace=kubectl-6240'
Nov 14 22:52:58.554: INFO: stderr: "No resources found.\n"
Nov 14 22:52:58.554: INFO: stdout: ""
Nov 14 22:52:58.554: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 get pods -l name=pause --namespace=kubectl-6240 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov 14 22:52:58.710: INFO: stderr: ""
Nov 14 22:52:58.710: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:52:58.710: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6240" for this suite.
Nov 14 22:53:06.759: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:53:07.006: INFO: namespace kubectl-6240 deletion completed in 8.290184709s

• [SLOW TEST:15.545 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl label
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:53:07.013: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8750
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Nov 14 22:53:07.510: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5414e016-2b30-4ded-8cbb-c01547132d8a" in namespace "projected-8750" to be "success or failure"
Nov 14 22:53:07.547: INFO: Pod "downwardapi-volume-5414e016-2b30-4ded-8cbb-c01547132d8a": Phase="Pending", Reason="", readiness=false. Elapsed: 36.990397ms
Nov 14 22:53:09.555: INFO: Pod "downwardapi-volume-5414e016-2b30-4ded-8cbb-c01547132d8a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.044485266s
Nov 14 22:53:11.561: INFO: Pod "downwardapi-volume-5414e016-2b30-4ded-8cbb-c01547132d8a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.050221347s
Nov 14 22:53:13.565: INFO: Pod "downwardapi-volume-5414e016-2b30-4ded-8cbb-c01547132d8a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.054929928s
STEP: Saw pod success
Nov 14 22:53:13.565: INFO: Pod "downwardapi-volume-5414e016-2b30-4ded-8cbb-c01547132d8a" satisfied condition "success or failure"
Nov 14 22:53:13.568: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-0 pod downwardapi-volume-5414e016-2b30-4ded-8cbb-c01547132d8a container client-container: <nil>
STEP: delete the pod
Nov 14 22:53:13.874: INFO: Waiting for pod downwardapi-volume-5414e016-2b30-4ded-8cbb-c01547132d8a to disappear
Nov 14 22:53:13.959: INFO: Pod downwardapi-volume-5414e016-2b30-4ded-8cbb-c01547132d8a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:53:13.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8750" for this suite.
Nov 14 22:53:20.198: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:53:20.501: INFO: namespace projected-8750 deletion completed in 6.535803594s

• [SLOW TEST:13.489 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:53:20.506: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2772
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-34369671-2694-412f-9aef-9225bb0a7392
STEP: Creating a pod to test consume secrets
Nov 14 22:53:20.863: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-4ced2d6b-9eff-4314-a953-c08cf88240c3" in namespace "projected-2772" to be "success or failure"
Nov 14 22:53:20.897: INFO: Pod "pod-projected-secrets-4ced2d6b-9eff-4314-a953-c08cf88240c3": Phase="Pending", Reason="", readiness=false. Elapsed: 33.256856ms
Nov 14 22:53:22.903: INFO: Pod "pod-projected-secrets-4ced2d6b-9eff-4314-a953-c08cf88240c3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039327354s
Nov 14 22:53:24.980: INFO: Pod "pod-projected-secrets-4ced2d6b-9eff-4314-a953-c08cf88240c3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.11574877s
Nov 14 22:53:26.986: INFO: Pod "pod-projected-secrets-4ced2d6b-9eff-4314-a953-c08cf88240c3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.121521585s
STEP: Saw pod success
Nov 14 22:53:26.986: INFO: Pod "pod-projected-secrets-4ced2d6b-9eff-4314-a953-c08cf88240c3" satisfied condition "success or failure"
Nov 14 22:53:26.989: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-1 pod pod-projected-secrets-4ced2d6b-9eff-4314-a953-c08cf88240c3 container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov 14 22:53:27.139: INFO: Waiting for pod pod-projected-secrets-4ced2d6b-9eff-4314-a953-c08cf88240c3 to disappear
Nov 14 22:53:27.171: INFO: Pod pod-projected-secrets-4ced2d6b-9eff-4314-a953-c08cf88240c3 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:53:27.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2772" for this suite.
Nov 14 22:53:33.243: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:53:33.469: INFO: namespace projected-2772 deletion completed in 6.264498609s

• [SLOW TEST:12.964 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:53:33.480: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8270
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the initial replication controller
Nov 14 22:53:33.850: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 create -f - --namespace=kubectl-8270'
Nov 14 22:53:34.547: INFO: stderr: ""
Nov 14 22:53:34.547: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov 14 22:53:34.547: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8270'
Nov 14 22:53:34.762: INFO: stderr: ""
Nov 14 22:53:34.762: INFO: stdout: "update-demo-nautilus-2l8tk update-demo-nautilus-ldzt4 "
Nov 14 22:53:34.762: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 get pods update-demo-nautilus-2l8tk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8270'
Nov 14 22:53:34.946: INFO: stderr: ""
Nov 14 22:53:34.946: INFO: stdout: ""
Nov 14 22:53:34.946: INFO: update-demo-nautilus-2l8tk is created but not running
Nov 14 22:53:39.947: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8270'
Nov 14 22:53:40.060: INFO: stderr: ""
Nov 14 22:53:40.061: INFO: stdout: "update-demo-nautilus-2l8tk update-demo-nautilus-ldzt4 "
Nov 14 22:53:40.061: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 get pods update-demo-nautilus-2l8tk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8270'
Nov 14 22:53:40.175: INFO: stderr: ""
Nov 14 22:53:40.175: INFO: stdout: ""
Nov 14 22:53:40.175: INFO: update-demo-nautilus-2l8tk is created but not running
Nov 14 22:53:45.175: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8270'
Nov 14 22:53:45.430: INFO: stderr: ""
Nov 14 22:53:45.430: INFO: stdout: "update-demo-nautilus-2l8tk update-demo-nautilus-ldzt4 "
Nov 14 22:53:45.430: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 get pods update-demo-nautilus-2l8tk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8270'
Nov 14 22:53:45.746: INFO: stderr: ""
Nov 14 22:53:45.746: INFO: stdout: ""
Nov 14 22:53:45.746: INFO: update-demo-nautilus-2l8tk is created but not running
Nov 14 22:53:50.747: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8270'
Nov 14 22:53:50.954: INFO: stderr: ""
Nov 14 22:53:50.954: INFO: stdout: "update-demo-nautilus-2l8tk update-demo-nautilus-ldzt4 "
Nov 14 22:53:50.954: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 get pods update-demo-nautilus-2l8tk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8270'
Nov 14 22:53:51.072: INFO: stderr: ""
Nov 14 22:53:51.072: INFO: stdout: "true"
Nov 14 22:53:51.072: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 get pods update-demo-nautilus-2l8tk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8270'
Nov 14 22:53:51.180: INFO: stderr: ""
Nov 14 22:53:51.180: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov 14 22:53:51.180: INFO: validating pod update-demo-nautilus-2l8tk
Nov 14 22:53:51.256: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 14 22:53:51.391: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 14 22:53:51.392: INFO: update-demo-nautilus-2l8tk is verified up and running
Nov 14 22:53:51.392: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 get pods update-demo-nautilus-ldzt4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8270'
Nov 14 22:53:51.622: INFO: stderr: ""
Nov 14 22:53:51.622: INFO: stdout: "true"
Nov 14 22:53:51.622: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 get pods update-demo-nautilus-ldzt4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8270'
Nov 14 22:53:51.743: INFO: stderr: ""
Nov 14 22:53:51.743: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov 14 22:53:51.743: INFO: validating pod update-demo-nautilus-ldzt4
Nov 14 22:53:51.802: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 14 22:53:51.802: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 14 22:53:51.802: INFO: update-demo-nautilus-ldzt4 is verified up and running
STEP: rolling-update to new replication controller
Nov 14 22:53:51.812: INFO: scanned /root for discovery docs: <nil>
Nov 14 22:53:51.812: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-8270'
Nov 14 22:54:36.360: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Nov 14 22:54:36.396: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov 14 22:54:36.396: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8270'
Nov 14 22:54:36.578: INFO: stderr: ""
Nov 14 22:54:36.578: INFO: stdout: "update-demo-kitten-95f6v update-demo-kitten-ftdf9 "
Nov 14 22:54:36.578: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 get pods update-demo-kitten-95f6v -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8270'
Nov 14 22:54:36.745: INFO: stderr: ""
Nov 14 22:54:36.745: INFO: stdout: "true"
Nov 14 22:54:36.745: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 get pods update-demo-kitten-95f6v -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8270'
Nov 14 22:54:36.916: INFO: stderr: ""
Nov 14 22:54:36.916: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Nov 14 22:54:36.916: INFO: validating pod update-demo-kitten-95f6v
Nov 14 22:54:36.923: INFO: got data: {
  "image": "kitten.jpg"
}

Nov 14 22:54:36.923: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Nov 14 22:54:36.923: INFO: update-demo-kitten-95f6v is verified up and running
Nov 14 22:54:36.923: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 get pods update-demo-kitten-ftdf9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8270'
Nov 14 22:54:37.039: INFO: stderr: ""
Nov 14 22:54:37.039: INFO: stdout: "true"
Nov 14 22:54:37.039: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 get pods update-demo-kitten-ftdf9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8270'
Nov 14 22:54:37.150: INFO: stderr: ""
Nov 14 22:54:37.150: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Nov 14 22:54:37.150: INFO: validating pod update-demo-kitten-ftdf9
Nov 14 22:54:37.158: INFO: got data: {
  "image": "kitten.jpg"
}

Nov 14 22:54:37.158: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Nov 14 22:54:37.158: INFO: update-demo-kitten-ftdf9 is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:54:37.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8270" for this suite.
Nov 14 22:55:03.300: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:55:03.870: INFO: namespace kubectl-8270 deletion completed in 26.70665714s

• [SLOW TEST:90.391 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:55:03.874: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8814
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Nov 14 22:55:08.996: INFO: Successfully updated pod "annotationupdate6cb4c6ff-4fa6-4c72-941a-e1afa0bfce56"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:55:11.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8814" for this suite.
Nov 14 22:55:35.199: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:55:35.353: INFO: namespace downward-api-8814 deletion completed in 24.28526484s

• [SLOW TEST:31.479 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:55:35.356: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-1438
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Nov 14 22:55:35.882: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:55:46.070: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1438" for this suite.
Nov 14 22:55:52.299: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:55:52.587: INFO: namespace init-container-1438 deletion completed in 6.467035134s

• [SLOW TEST:17.231 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:55:52.588: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2109
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Nov 14 22:55:53.203: INFO: Waiting up to 5m0s for pod "downwardapi-volume-24d8e913-0a34-40f1-95f4-12cd21e5fd99" in namespace "downward-api-2109" to be "success or failure"
Nov 14 22:55:53.277: INFO: Pod "downwardapi-volume-24d8e913-0a34-40f1-95f4-12cd21e5fd99": Phase="Pending", Reason="", readiness=false. Elapsed: 73.971294ms
Nov 14 22:55:55.667: INFO: Pod "downwardapi-volume-24d8e913-0a34-40f1-95f4-12cd21e5fd99": Phase="Pending", Reason="", readiness=false. Elapsed: 2.464309086s
Nov 14 22:55:57.673: INFO: Pod "downwardapi-volume-24d8e913-0a34-40f1-95f4-12cd21e5fd99": Phase="Pending", Reason="", readiness=false. Elapsed: 4.470626069s
Nov 14 22:55:59.678: INFO: Pod "downwardapi-volume-24d8e913-0a34-40f1-95f4-12cd21e5fd99": Phase="Pending", Reason="", readiness=false. Elapsed: 6.474845625s
Nov 14 22:56:01.683: INFO: Pod "downwardapi-volume-24d8e913-0a34-40f1-95f4-12cd21e5fd99": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.480107292s
STEP: Saw pod success
Nov 14 22:56:01.683: INFO: Pod "downwardapi-volume-24d8e913-0a34-40f1-95f4-12cd21e5fd99" satisfied condition "success or failure"
Nov 14 22:56:01.687: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-0 pod downwardapi-volume-24d8e913-0a34-40f1-95f4-12cd21e5fd99 container client-container: <nil>
STEP: delete the pod
Nov 14 22:56:02.059: INFO: Waiting for pod downwardapi-volume-24d8e913-0a34-40f1-95f4-12cd21e5fd99 to disappear
Nov 14 22:56:02.395: INFO: Pod downwardapi-volume-24d8e913-0a34-40f1-95f4-12cd21e5fd99 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:56:02.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2109" for this suite.
Nov 14 22:56:09.253: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:56:09.416: INFO: namespace downward-api-2109 deletion completed in 7.014362469s

• [SLOW TEST:16.829 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:56:09.426: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7620
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-af0c359f-e2b2-417e-b51d-22b81a5cca67
STEP: Creating a pod to test consume configMaps
Nov 14 22:56:09.821: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-6895b157-c890-4d94-9f16-b2c0e3c69ac7" in namespace "projected-7620" to be "success or failure"
Nov 14 22:56:09.842: INFO: Pod "pod-projected-configmaps-6895b157-c890-4d94-9f16-b2c0e3c69ac7": Phase="Pending", Reason="", readiness=false. Elapsed: 20.146663ms
Nov 14 22:56:11.923: INFO: Pod "pod-projected-configmaps-6895b157-c890-4d94-9f16-b2c0e3c69ac7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.101945318s
Nov 14 22:56:13.943: INFO: Pod "pod-projected-configmaps-6895b157-c890-4d94-9f16-b2c0e3c69ac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.121135861s
STEP: Saw pod success
Nov 14 22:56:13.943: INFO: Pod "pod-projected-configmaps-6895b157-c890-4d94-9f16-b2c0e3c69ac7" satisfied condition "success or failure"
Nov 14 22:56:14.022: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-1 pod pod-projected-configmaps-6895b157-c890-4d94-9f16-b2c0e3c69ac7 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov 14 22:56:14.459: INFO: Waiting for pod pod-projected-configmaps-6895b157-c890-4d94-9f16-b2c0e3c69ac7 to disappear
Nov 14 22:56:14.541: INFO: Pod pod-projected-configmaps-6895b157-c890-4d94-9f16-b2c0e3c69ac7 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:56:14.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7620" for this suite.
Nov 14 22:56:21.067: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:56:21.182: INFO: namespace projected-7620 deletion completed in 6.403651081s

• [SLOW TEST:11.757 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:56:21.189: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5877
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap configmap-5877/configmap-test-27a55d50-5386-43aa-9621-638447bf5fa2
STEP: Creating a pod to test consume configMaps
Nov 14 22:56:21.616: INFO: Waiting up to 5m0s for pod "pod-configmaps-a4f1f82f-134e-4f36-a0f9-29921c362ec3" in namespace "configmap-5877" to be "success or failure"
Nov 14 22:56:21.653: INFO: Pod "pod-configmaps-a4f1f82f-134e-4f36-a0f9-29921c362ec3": Phase="Pending", Reason="", readiness=false. Elapsed: 36.115224ms
Nov 14 22:56:23.658: INFO: Pod "pod-configmaps-a4f1f82f-134e-4f36-a0f9-29921c362ec3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.04094766s
Nov 14 22:56:25.663: INFO: Pod "pod-configmaps-a4f1f82f-134e-4f36-a0f9-29921c362ec3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.04620536s
Nov 14 22:56:27.667: INFO: Pod "pod-configmaps-a4f1f82f-134e-4f36-a0f9-29921c362ec3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.050002831s
STEP: Saw pod success
Nov 14 22:56:27.667: INFO: Pod "pod-configmaps-a4f1f82f-134e-4f36-a0f9-29921c362ec3" satisfied condition "success or failure"
Nov 14 22:56:27.669: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-0 pod pod-configmaps-a4f1f82f-134e-4f36-a0f9-29921c362ec3 container env-test: <nil>
STEP: delete the pod
Nov 14 22:56:27.789: INFO: Waiting for pod pod-configmaps-a4f1f82f-134e-4f36-a0f9-29921c362ec3 to disappear
Nov 14 22:56:27.822: INFO: Pod pod-configmaps-a4f1f82f-134e-4f36-a0f9-29921c362ec3 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:56:27.822: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5877" for this suite.
Nov 14 22:56:33.875: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:56:34.160: INFO: namespace configmap-5877 deletion completed in 6.331482118s

• [SLOW TEST:12.972 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:56:34.173: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-9896
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Nov 14 22:56:34.651: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Nov 14 22:56:43.890: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:56:43.894: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9896" for this suite.
Nov 14 22:56:51.945: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:56:52.251: INFO: namespace pods-9896 deletion completed in 8.349550503s

• [SLOW TEST:18.078 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:56:52.251: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8583
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Nov 14 22:56:52.613: INFO: Waiting up to 5m0s for pod "downward-api-c7714cd8-b0ad-4d2b-8639-e7fd44171e36" in namespace "downward-api-8583" to be "success or failure"
Nov 14 22:56:52.684: INFO: Pod "downward-api-c7714cd8-b0ad-4d2b-8639-e7fd44171e36": Phase="Pending", Reason="", readiness=false. Elapsed: 70.898498ms
Nov 14 22:56:54.689: INFO: Pod "downward-api-c7714cd8-b0ad-4d2b-8639-e7fd44171e36": Phase="Pending", Reason="", readiness=false. Elapsed: 2.076022047s
Nov 14 22:56:56.696: INFO: Pod "downward-api-c7714cd8-b0ad-4d2b-8639-e7fd44171e36": Phase="Pending", Reason="", readiness=false. Elapsed: 4.082201529s
Nov 14 22:56:58.824: INFO: Pod "downward-api-c7714cd8-b0ad-4d2b-8639-e7fd44171e36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.210231149s
STEP: Saw pod success
Nov 14 22:56:58.824: INFO: Pod "downward-api-c7714cd8-b0ad-4d2b-8639-e7fd44171e36" satisfied condition "success or failure"
Nov 14 22:56:58.830: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-0 pod downward-api-c7714cd8-b0ad-4d2b-8639-e7fd44171e36 container dapi-container: <nil>
STEP: delete the pod
Nov 14 22:56:59.101: INFO: Waiting for pod downward-api-c7714cd8-b0ad-4d2b-8639-e7fd44171e36 to disappear
Nov 14 22:56:59.182: INFO: Pod downward-api-c7714cd8-b0ad-4d2b-8639-e7fd44171e36 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:56:59.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8583" for this suite.
Nov 14 22:57:07.362: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:57:07.664: INFO: namespace downward-api-8583 deletion completed in 8.387370443s

• [SLOW TEST:15.413 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:57:07.670: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-9864
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-3933
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-2518
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 22:57:17.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-9864" for this suite.
Nov 14 22:57:23.769: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:57:23.951: INFO: namespace namespaces-9864 deletion completed in 6.222972609s
STEP: Destroying namespace "nsdeletetest-3933" for this suite.
Nov 14 22:57:23.957: INFO: Namespace nsdeletetest-3933 was already deleted
STEP: Destroying namespace "nsdeletetest-2518" for this suite.
Nov 14 22:57:30.108: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 22:57:30.649: INFO: namespace nsdeletetest-2518 deletion completed in 6.691607895s

• [SLOW TEST:22.980 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 22:57:30.656: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-1470
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod test-webserver-80fb0019-8c41-4165-8301-882fc8046211 in namespace container-probe-1470
Nov 14 22:57:35.532: INFO: Started pod test-webserver-80fb0019-8c41-4165-8301-882fc8046211 in namespace container-probe-1470
STEP: checking the pod's current state and verifying that restartCount is present
Nov 14 22:57:35.547: INFO: Initial restart count of pod test-webserver-80fb0019-8c41-4165-8301-882fc8046211 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:01:37.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1470" for this suite.
Nov 14 23:01:44.214: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:01:44.555: INFO: namespace container-probe-1470 deletion completed in 6.419791431s

• [SLOW TEST:253.901 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:01:44.564: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4756
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on node default medium
Nov 14 23:01:45.236: INFO: Waiting up to 5m0s for pod "pod-31caca85-4992-4fc9-a59a-9cff27ffa181" in namespace "emptydir-4756" to be "success or failure"
Nov 14 23:01:45.297: INFO: Pod "pod-31caca85-4992-4fc9-a59a-9cff27ffa181": Phase="Pending", Reason="", readiness=false. Elapsed: 61.245768ms
Nov 14 23:01:47.302: INFO: Pod "pod-31caca85-4992-4fc9-a59a-9cff27ffa181": Phase="Pending", Reason="", readiness=false. Elapsed: 2.066145282s
Nov 14 23:01:49.312: INFO: Pod "pod-31caca85-4992-4fc9-a59a-9cff27ffa181": Phase="Pending", Reason="", readiness=false. Elapsed: 4.075777024s
Nov 14 23:01:51.475: INFO: Pod "pod-31caca85-4992-4fc9-a59a-9cff27ffa181": Phase="Pending", Reason="", readiness=false. Elapsed: 6.239315073s
Nov 14 23:01:53.481: INFO: Pod "pod-31caca85-4992-4fc9-a59a-9cff27ffa181": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.244682299s
STEP: Saw pod success
Nov 14 23:01:53.481: INFO: Pod "pod-31caca85-4992-4fc9-a59a-9cff27ffa181" satisfied condition "success or failure"
Nov 14 23:01:53.485: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-0 pod pod-31caca85-4992-4fc9-a59a-9cff27ffa181 container test-container: <nil>
STEP: delete the pod
Nov 14 23:01:53.622: INFO: Waiting for pod pod-31caca85-4992-4fc9-a59a-9cff27ffa181 to disappear
Nov 14 23:01:53.652: INFO: Pod pod-31caca85-4992-4fc9-a59a-9cff27ffa181 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:01:53.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4756" for this suite.
Nov 14 23:02:03.700: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:02:04.024: INFO: namespace emptydir-4756 deletion completed in 10.367861239s

• [SLOW TEST:19.461 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:02:04.029: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-2982
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating secret secrets-2982/secret-test-87cd2aa5-1370-40c7-a8d1-2f575181f51f
STEP: Creating a pod to test consume secrets
Nov 14 23:02:04.548: INFO: Waiting up to 5m0s for pod "pod-configmaps-7d4d6b2a-0964-41e8-8bb6-df692fe645b1" in namespace "secrets-2982" to be "success or failure"
Nov 14 23:02:04.580: INFO: Pod "pod-configmaps-7d4d6b2a-0964-41e8-8bb6-df692fe645b1": Phase="Pending", Reason="", readiness=false. Elapsed: 31.739389ms
Nov 14 23:02:06.585: INFO: Pod "pod-configmaps-7d4d6b2a-0964-41e8-8bb6-df692fe645b1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036653096s
Nov 14 23:02:08.591: INFO: Pod "pod-configmaps-7d4d6b2a-0964-41e8-8bb6-df692fe645b1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.042833029s
Nov 14 23:02:10.596: INFO: Pod "pod-configmaps-7d4d6b2a-0964-41e8-8bb6-df692fe645b1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.047802112s
STEP: Saw pod success
Nov 14 23:02:10.597: INFO: Pod "pod-configmaps-7d4d6b2a-0964-41e8-8bb6-df692fe645b1" satisfied condition "success or failure"
Nov 14 23:02:10.601: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-0 pod pod-configmaps-7d4d6b2a-0964-41e8-8bb6-df692fe645b1 container env-test: <nil>
STEP: delete the pod
Nov 14 23:02:10.672: INFO: Waiting for pod pod-configmaps-7d4d6b2a-0964-41e8-8bb6-df692fe645b1 to disappear
Nov 14 23:02:10.785: INFO: Pod pod-configmaps-7d4d6b2a-0964-41e8-8bb6-df692fe645b1 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:02:10.785: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2982" for this suite.
Nov 14 23:02:16.991: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:02:17.128: INFO: namespace secrets-2982 deletion completed in 6.337667493s

• [SLOW TEST:13.099 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:02:17.140: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-9627
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Nov 14 23:02:22.033: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:02:22.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-9627" for this suite.
Nov 14 23:02:30.510: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:02:30.826: INFO: namespace container-runtime-9627 deletion completed in 7.899175845s

• [SLOW TEST:13.687 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:02:30.841: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-837
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Nov 14 23:02:36.080: INFO: Successfully updated pod "labelsupdate9952fa84-228b-4de1-b1a1-0acd331e67a9"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:02:40.160: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-837" for this suite.
Nov 14 23:03:04.348: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:03:04.566: INFO: namespace projected-837 deletion completed in 24.403499094s

• [SLOW TEST:33.726 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:03:04.578: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-9558
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-9558
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating stateful set ss in namespace statefulset-9558
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-9558
Nov 14 23:03:05.660: INFO: Found 0 stateful pods, waiting for 1
Nov 14 23:03:15.668: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Nov 14 23:03:15.673: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 exec --namespace=statefulset-9558 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov 14 23:03:23.081: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Nov 14 23:03:23.081: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov 14 23:03:23.081: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov 14 23:03:23.089: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Nov 14 23:03:33.095: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov 14 23:03:33.096: INFO: Waiting for statefulset status.replicas updated to 0
Nov 14 23:03:33.261: INFO: POD   NODE                         PHASE    GRACE  CONDITIONS
Nov 14 23:03:33.262: INFO: ss-0  k8s-1-tdyr52fdsot3-minion-0  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:24 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:05 +0000 UTC  }]
Nov 14 23:03:33.263: INFO: 
Nov 14 23:03:33.263: INFO: StatefulSet ss has not reached scale 3, at 1
Nov 14 23:03:34.269: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.844462972s
Nov 14 23:03:35.330: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.838673505s
Nov 14 23:03:36.373: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.777888852s
Nov 14 23:03:37.376: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.734504481s
Nov 14 23:03:38.518: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.730956834s
Nov 14 23:03:39.769: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.587002044s
Nov 14 23:03:40.812: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.338716159s
Nov 14 23:03:41.832: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.295252488s
Nov 14 23:03:42.897: INFO: Verifying statefulset ss doesn't scale past 3 for another 275.466727ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-9558
Nov 14 23:03:43.905: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 exec --namespace=statefulset-9558 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 14 23:03:44.215: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Nov 14 23:03:44.215: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov 14 23:03:44.215: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Nov 14 23:03:44.215: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 exec --namespace=statefulset-9558 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 14 23:03:44.587: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Nov 14 23:03:44.587: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov 14 23:03:44.587: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Nov 14 23:03:44.587: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 exec --namespace=statefulset-9558 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 14 23:03:44.914: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Nov 14 23:03:44.914: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov 14 23:03:44.914: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Nov 14 23:03:44.917: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 14 23:03:44.917: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Nov 14 23:03:44.917: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Nov 14 23:03:44.920: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 exec --namespace=statefulset-9558 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov 14 23:03:45.249: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Nov 14 23:03:45.249: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov 14 23:03:45.249: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov 14 23:03:45.249: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 exec --namespace=statefulset-9558 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov 14 23:03:45.539: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Nov 14 23:03:45.539: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov 14 23:03:45.539: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov 14 23:03:45.539: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 exec --namespace=statefulset-9558 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov 14 23:03:45.849: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Nov 14 23:03:45.849: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov 14 23:03:45.849: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov 14 23:03:45.849: INFO: Waiting for statefulset status.replicas updated to 0
Nov 14 23:03:45.885: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Nov 14 23:03:55.894: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov 14 23:03:55.894: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Nov 14 23:03:55.894: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Nov 14 23:03:56.025: INFO: POD   NODE                         PHASE    GRACE  CONDITIONS
Nov 14 23:03:56.025: INFO: ss-0  k8s-1-tdyr52fdsot3-minion-0  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:05 +0000 UTC  }]
Nov 14 23:03:56.025: INFO: ss-1  k8s-1-tdyr52fdsot3-minion-1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:32 +0000 UTC  }]
Nov 14 23:03:56.025: INFO: ss-2  k8s-1-tdyr52fdsot3-minion-1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:32 +0000 UTC  }]
Nov 14 23:03:56.026: INFO: 
Nov 14 23:03:56.026: INFO: StatefulSet ss has not reached scale 0, at 3
Nov 14 23:03:57.184: INFO: POD   NODE                         PHASE    GRACE  CONDITIONS
Nov 14 23:03:57.184: INFO: ss-0  k8s-1-tdyr52fdsot3-minion-0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:05 +0000 UTC  }]
Nov 14 23:03:57.185: INFO: ss-1  k8s-1-tdyr52fdsot3-minion-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:32 +0000 UTC  }]
Nov 14 23:03:57.185: INFO: ss-2  k8s-1-tdyr52fdsot3-minion-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:32 +0000 UTC  }]
Nov 14 23:03:57.186: INFO: 
Nov 14 23:03:57.186: INFO: StatefulSet ss has not reached scale 0, at 3
Nov 14 23:03:58.370: INFO: POD   NODE                         PHASE    GRACE  CONDITIONS
Nov 14 23:03:58.371: INFO: ss-0  k8s-1-tdyr52fdsot3-minion-0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:05 +0000 UTC  }]
Nov 14 23:03:58.371: INFO: ss-1  k8s-1-tdyr52fdsot3-minion-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:32 +0000 UTC  }]
Nov 14 23:03:58.371: INFO: ss-2  k8s-1-tdyr52fdsot3-minion-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:32 +0000 UTC  }]
Nov 14 23:03:58.371: INFO: 
Nov 14 23:03:58.371: INFO: StatefulSet ss has not reached scale 0, at 3
Nov 14 23:03:59.377: INFO: POD   NODE                         PHASE    GRACE  CONDITIONS
Nov 14 23:03:59.378: INFO: ss-0  k8s-1-tdyr52fdsot3-minion-0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:05 +0000 UTC  }]
Nov 14 23:03:59.379: INFO: ss-1  k8s-1-tdyr52fdsot3-minion-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:32 +0000 UTC  }]
Nov 14 23:03:59.379: INFO: ss-2  k8s-1-tdyr52fdsot3-minion-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:32 +0000 UTC  }]
Nov 14 23:03:59.379: INFO: 
Nov 14 23:03:59.380: INFO: StatefulSet ss has not reached scale 0, at 3
Nov 14 23:04:00.580: INFO: POD   NODE                         PHASE    GRACE  CONDITIONS
Nov 14 23:04:00.580: INFO: ss-0  k8s-1-tdyr52fdsot3-minion-0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:05 +0000 UTC  }]
Nov 14 23:04:00.580: INFO: ss-1  k8s-1-tdyr52fdsot3-minion-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:32 +0000 UTC  }]
Nov 14 23:04:00.580: INFO: ss-2  k8s-1-tdyr52fdsot3-minion-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:32 +0000 UTC  }]
Nov 14 23:04:00.580: INFO: 
Nov 14 23:04:00.580: INFO: StatefulSet ss has not reached scale 0, at 3
Nov 14 23:04:02.163: INFO: POD   NODE                         PHASE    GRACE  CONDITIONS
Nov 14 23:04:02.163: INFO: ss-0  k8s-1-tdyr52fdsot3-minion-0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:05 +0000 UTC  }]
Nov 14 23:04:02.163: INFO: ss-1  k8s-1-tdyr52fdsot3-minion-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:32 +0000 UTC  }]
Nov 14 23:04:02.164: INFO: ss-2  k8s-1-tdyr52fdsot3-minion-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:32 +0000 UTC  }]
Nov 14 23:04:02.164: INFO: 
Nov 14 23:04:02.165: INFO: StatefulSet ss has not reached scale 0, at 3
Nov 14 23:04:03.237: INFO: POD   NODE                         PHASE    GRACE  CONDITIONS
Nov 14 23:04:03.237: INFO: ss-0  k8s-1-tdyr52fdsot3-minion-0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:05 +0000 UTC  }]
Nov 14 23:04:03.237: INFO: ss-1  k8s-1-tdyr52fdsot3-minion-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:32 +0000 UTC  }]
Nov 14 23:04:03.237: INFO: ss-2  k8s-1-tdyr52fdsot3-minion-1  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:32 +0000 UTC  }]
Nov 14 23:04:03.237: INFO: 
Nov 14 23:04:03.237: INFO: StatefulSet ss has not reached scale 0, at 3
Nov 14 23:04:04.244: INFO: POD   NODE                         PHASE    GRACE  CONDITIONS
Nov 14 23:04:04.244: INFO: ss-0  k8s-1-tdyr52fdsot3-minion-0  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:46 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:03:05 +0000 UTC  }]
Nov 14 23:04:04.245: INFO: 
Nov 14 23:04:04.245: INFO: StatefulSet ss has not reached scale 0, at 1
Nov 14 23:04:05.249: INFO: Verifying statefulset ss doesn't scale past 0 for another 657.796814ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-9558
Nov 14 23:04:06.254: INFO: Scaling statefulset ss to 0
Nov 14 23:04:06.266: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Nov 14 23:04:06.270: INFO: Deleting all statefulset in ns statefulset-9558
Nov 14 23:04:06.274: INFO: Scaling statefulset ss to 0
Nov 14 23:04:06.282: INFO: Waiting for statefulset status.replicas updated to 0
Nov 14 23:04:06.284: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:04:06.338: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9558" for this suite.
Nov 14 23:04:14.502: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:04:14.632: INFO: namespace statefulset-9558 deletion completed in 8.219713305s

• [SLOW TEST:70.055 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:04:14.643: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1438
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-map-27cedc91-8fe8-4efe-8811-cbc1e62b977f
STEP: Creating a pod to test consume secrets
Nov 14 23:04:15.255: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-4eb0b62e-0fe0-4958-a231-fa78f8b1325f" in namespace "projected-1438" to be "success or failure"
Nov 14 23:04:15.285: INFO: Pod "pod-projected-secrets-4eb0b62e-0fe0-4958-a231-fa78f8b1325f": Phase="Pending", Reason="", readiness=false. Elapsed: 29.651936ms
Nov 14 23:04:17.414: INFO: Pod "pod-projected-secrets-4eb0b62e-0fe0-4958-a231-fa78f8b1325f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.158205317s
Nov 14 23:04:19.448: INFO: Pod "pod-projected-secrets-4eb0b62e-0fe0-4958-a231-fa78f8b1325f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.192347193s
STEP: Saw pod success
Nov 14 23:04:19.449: INFO: Pod "pod-projected-secrets-4eb0b62e-0fe0-4958-a231-fa78f8b1325f" satisfied condition "success or failure"
Nov 14 23:04:19.517: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-1 pod pod-projected-secrets-4eb0b62e-0fe0-4958-a231-fa78f8b1325f container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov 14 23:04:19.724: INFO: Waiting for pod pod-projected-secrets-4eb0b62e-0fe0-4958-a231-fa78f8b1325f to disappear
Nov 14 23:04:19.805: INFO: Pod pod-projected-secrets-4eb0b62e-0fe0-4958-a231-fa78f8b1325f no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:04:19.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1438" for this suite.
Nov 14 23:04:27.855: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:04:28.080: INFO: namespace projected-1438 deletion completed in 8.271592276s

• [SLOW TEST:13.438 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:04:28.088: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9262
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-64d1a8d9-a174-4b04-854d-29ad722aa071
STEP: Creating a pod to test consume configMaps
Nov 14 23:04:28.532: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-305a69e4-b46a-418f-be13-b619255b601b" in namespace "projected-9262" to be "success or failure"
Nov 14 23:04:28.569: INFO: Pod "pod-projected-configmaps-305a69e4-b46a-418f-be13-b619255b601b": Phase="Pending", Reason="", readiness=false. Elapsed: 36.882573ms
Nov 14 23:04:30.574: INFO: Pod "pod-projected-configmaps-305a69e4-b46a-418f-be13-b619255b601b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041827771s
Nov 14 23:04:32.578: INFO: Pod "pod-projected-configmaps-305a69e4-b46a-418f-be13-b619255b601b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.045672332s
Nov 14 23:04:34.583: INFO: Pod "pod-projected-configmaps-305a69e4-b46a-418f-be13-b619255b601b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.050858962s
STEP: Saw pod success
Nov 14 23:04:34.583: INFO: Pod "pod-projected-configmaps-305a69e4-b46a-418f-be13-b619255b601b" satisfied condition "success or failure"
Nov 14 23:04:34.586: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-0 pod pod-projected-configmaps-305a69e4-b46a-418f-be13-b619255b601b container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov 14 23:04:34.848: INFO: Waiting for pod pod-projected-configmaps-305a69e4-b46a-418f-be13-b619255b601b to disappear
Nov 14 23:04:34.916: INFO: Pod pod-projected-configmaps-305a69e4-b46a-418f-be13-b619255b601b no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:04:34.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9262" for this suite.
Nov 14 23:04:41.207: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:04:41.470: INFO: namespace projected-9262 deletion completed in 6.546207424s

• [SLOW TEST:13.383 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:04:41.475: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-6829
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W1114 23:05:22.482423      13 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Nov 14 23:05:22.482: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:05:22.483: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6829" for this suite.
Nov 14 23:05:52.603: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:05:52.778: INFO: namespace gc-6829 deletion completed in 30.290782281s

• [SLOW TEST:71.304 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:05:52.784: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-2610
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:06:00.810: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-2610" for this suite.
Nov 14 23:06:24.896: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:06:25.203: INFO: namespace replication-controller-2610 deletion completed in 24.383105206s

• [SLOW TEST:32.421 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:06:25.209: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-4376
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod liveness-9f032afb-126e-4a36-bd96-885e0d02f77c in namespace container-probe-4376
Nov 14 23:06:39.631: INFO: Started pod liveness-9f032afb-126e-4a36-bd96-885e0d02f77c in namespace container-probe-4376
STEP: checking the pod's current state and verifying that restartCount is present
Nov 14 23:06:39.637: INFO: Initial restart count of pod liveness-9f032afb-126e-4a36-bd96-885e0d02f77c is 0
Nov 14 23:07:05.741: INFO: Restart count of pod container-probe-4376/liveness-9f032afb-126e-4a36-bd96-885e0d02f77c is now 1 (26.103630353s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:07:05.778: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4376" for this suite.
Nov 14 23:07:12.242: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:07:12.590: INFO: namespace container-probe-4376 deletion completed in 6.624532241s

• [SLOW TEST:47.382 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:07:12.591: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-350
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-350
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Nov 14 23:07:12.924: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Nov 14 23:07:49.405: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.1.96:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-350 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 14 23:07:49.406: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
Nov 14 23:07:49.673: INFO: Found all expected endpoints: [netserver-0]
Nov 14 23:07:49.676: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.2.90:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-350 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 14 23:07:49.676: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
Nov 14 23:07:49.907: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:07:49.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-350" for this suite.
Nov 14 23:08:17.992: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:08:18.144: INFO: namespace pod-network-test-350 deletion completed in 28.186045066s

• [SLOW TEST:65.553 seconds]
[sig-network] Networking
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:08:18.154: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6674
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Nov 14 23:08:18.783: INFO: Waiting up to 5m0s for pod "downwardapi-volume-95d60c44-6413-4337-a056-1b952cef32e7" in namespace "downward-api-6674" to be "success or failure"
Nov 14 23:08:18.825: INFO: Pod "downwardapi-volume-95d60c44-6413-4337-a056-1b952cef32e7": Phase="Pending", Reason="", readiness=false. Elapsed: 41.253628ms
Nov 14 23:08:20.831: INFO: Pod "downwardapi-volume-95d60c44-6413-4337-a056-1b952cef32e7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.047483183s
Nov 14 23:08:22.912: INFO: Pod "downwardapi-volume-95d60c44-6413-4337-a056-1b952cef32e7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.128124141s
Nov 14 23:08:25.204: INFO: Pod "downwardapi-volume-95d60c44-6413-4337-a056-1b952cef32e7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.420377684s
STEP: Saw pod success
Nov 14 23:08:25.205: INFO: Pod "downwardapi-volume-95d60c44-6413-4337-a056-1b952cef32e7" satisfied condition "success or failure"
Nov 14 23:08:25.214: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-1 pod downwardapi-volume-95d60c44-6413-4337-a056-1b952cef32e7 container client-container: <nil>
STEP: delete the pod
Nov 14 23:08:25.922: INFO: Waiting for pod downwardapi-volume-95d60c44-6413-4337-a056-1b952cef32e7 to disappear
Nov 14 23:08:26.066: INFO: Pod downwardapi-volume-95d60c44-6413-4337-a056-1b952cef32e7 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:08:26.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6674" for this suite.
Nov 14 23:08:34.187: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:08:34.308: INFO: namespace downward-api-6674 deletion completed in 8.23407458s

• [SLOW TEST:16.155 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:08:34.314: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7020
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Nov 14 23:08:34.890: INFO: Waiting up to 5m0s for pod "downwardapi-volume-92369fed-af1b-4281-bec4-6d8ef34fce5c" in namespace "projected-7020" to be "success or failure"
Nov 14 23:08:35.174: INFO: Pod "downwardapi-volume-92369fed-af1b-4281-bec4-6d8ef34fce5c": Phase="Pending", Reason="", readiness=false. Elapsed: 283.818963ms
Nov 14 23:08:37.179: INFO: Pod "downwardapi-volume-92369fed-af1b-4281-bec4-6d8ef34fce5c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.289120865s
Nov 14 23:08:39.198: INFO: Pod "downwardapi-volume-92369fed-af1b-4281-bec4-6d8ef34fce5c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.308406439s
Nov 14 23:08:41.202: INFO: Pod "downwardapi-volume-92369fed-af1b-4281-bec4-6d8ef34fce5c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.311986055s
STEP: Saw pod success
Nov 14 23:08:41.203: INFO: Pod "downwardapi-volume-92369fed-af1b-4281-bec4-6d8ef34fce5c" satisfied condition "success or failure"
Nov 14 23:08:41.205: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-0 pod downwardapi-volume-92369fed-af1b-4281-bec4-6d8ef34fce5c container client-container: <nil>
STEP: delete the pod
Nov 14 23:08:41.377: INFO: Waiting for pod downwardapi-volume-92369fed-af1b-4281-bec4-6d8ef34fce5c to disappear
Nov 14 23:08:41.400: INFO: Pod downwardapi-volume-92369fed-af1b-4281-bec4-6d8ef34fce5c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:08:41.401: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7020" for this suite.
Nov 14 23:08:47.587: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:08:47.697: INFO: namespace projected-7020 deletion completed in 6.292155556s

• [SLOW TEST:13.384 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:08:47.702: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-1151
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Nov 14 23:08:48.372: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-1151,SelfLink:/api/v1/namespaces/watch-1151/configmaps/e2e-watch-test-configmap-a,UID:93ccc120-4b73-4648-8188-e79fa46d5624,ResourceVersion:22668,Generation:0,CreationTimestamp:2019-11-14 23:08:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov 14 23:08:48.604: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-1151,SelfLink:/api/v1/namespaces/watch-1151/configmaps/e2e-watch-test-configmap-a,UID:93ccc120-4b73-4648-8188-e79fa46d5624,ResourceVersion:22668,Generation:0,CreationTimestamp:2019-11-14 23:08:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Nov 14 23:08:58.621: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-1151,SelfLink:/api/v1/namespaces/watch-1151/configmaps/e2e-watch-test-configmap-a,UID:93ccc120-4b73-4648-8188-e79fa46d5624,ResourceVersion:22688,Generation:0,CreationTimestamp:2019-11-14 23:08:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Nov 14 23:08:58.621: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-1151,SelfLink:/api/v1/namespaces/watch-1151/configmaps/e2e-watch-test-configmap-a,UID:93ccc120-4b73-4648-8188-e79fa46d5624,ResourceVersion:22688,Generation:0,CreationTimestamp:2019-11-14 23:08:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Nov 14 23:09:08.633: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-1151,SelfLink:/api/v1/namespaces/watch-1151/configmaps/e2e-watch-test-configmap-a,UID:93ccc120-4b73-4648-8188-e79fa46d5624,ResourceVersion:22709,Generation:0,CreationTimestamp:2019-11-14 23:08:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov 14 23:09:08.634: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-1151,SelfLink:/api/v1/namespaces/watch-1151/configmaps/e2e-watch-test-configmap-a,UID:93ccc120-4b73-4648-8188-e79fa46d5624,ResourceVersion:22709,Generation:0,CreationTimestamp:2019-11-14 23:08:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Nov 14 23:09:18.644: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-1151,SelfLink:/api/v1/namespaces/watch-1151/configmaps/e2e-watch-test-configmap-a,UID:93ccc120-4b73-4648-8188-e79fa46d5624,ResourceVersion:22729,Generation:0,CreationTimestamp:2019-11-14 23:08:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov 14 23:09:18.644: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-1151,SelfLink:/api/v1/namespaces/watch-1151/configmaps/e2e-watch-test-configmap-a,UID:93ccc120-4b73-4648-8188-e79fa46d5624,ResourceVersion:22729,Generation:0,CreationTimestamp:2019-11-14 23:08:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Nov 14 23:09:28.655: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-1151,SelfLink:/api/v1/namespaces/watch-1151/configmaps/e2e-watch-test-configmap-b,UID:f4c0a61a-593b-47b6-b43e-a164901ec1d3,ResourceVersion:22749,Generation:0,CreationTimestamp:2019-11-14 23:09:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov 14 23:09:28.655: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-1151,SelfLink:/api/v1/namespaces/watch-1151/configmaps/e2e-watch-test-configmap-b,UID:f4c0a61a-593b-47b6-b43e-a164901ec1d3,ResourceVersion:22749,Generation:0,CreationTimestamp:2019-11-14 23:09:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Nov 14 23:09:38.664: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-1151,SelfLink:/api/v1/namespaces/watch-1151/configmaps/e2e-watch-test-configmap-b,UID:f4c0a61a-593b-47b6-b43e-a164901ec1d3,ResourceVersion:22770,Generation:0,CreationTimestamp:2019-11-14 23:09:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov 14 23:09:38.665: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-1151,SelfLink:/api/v1/namespaces/watch-1151/configmaps/e2e-watch-test-configmap-b,UID:f4c0a61a-593b-47b6-b43e-a164901ec1d3,ResourceVersion:22770,Generation:0,CreationTimestamp:2019-11-14 23:09:27 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:09:48.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1151" for this suite.
Nov 14 23:09:54.729: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:09:55.212: INFO: namespace watch-1151 deletion completed in 6.528721719s

• [SLOW TEST:67.511 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:09:55.218: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2938
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap that has name configmap-test-emptyKey-79cf25f8-b6e3-4c8c-9df9-2872d15a2aac
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:09:55.684: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2938" for this suite.
Nov 14 23:10:01.797: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:10:01.947: INFO: namespace configmap-2938 deletion completed in 6.191834502s

• [SLOW TEST:6.730 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:10:01.952: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6661
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with configMap that has name projected-configmap-test-upd-5f998187-15b7-4f31-9889-fe2d486b7f69
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-5f998187-15b7-4f31-9889-fe2d486b7f69
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:11:11.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6661" for this suite.
Nov 14 23:11:36.040: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:11:36.186: INFO: namespace projected-6661 deletion completed in 24.209176539s

• [SLOW TEST:94.235 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:11:36.189: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in events-6709
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Nov 14 23:11:42.661: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-e66dc176-50ce-480f-bc4f-5e29150c3cd6,GenerateName:,Namespace:events-6709,SelfLink:/api/v1/namespaces/events-6709/pods/send-events-e66dc176-50ce-480f-bc4f-5e29150c3cd6,UID:7d4c24a5-2d53-430e-8bc2-27ef28ace3b1,ResourceVersion:23069,Generation:0,CreationTimestamp:2019-11-14 23:11:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 592847370,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.98/32,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-2d76n {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2d76n,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-2d76n true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-tdyr52fdsot3-minion-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001ebe000} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001ebe050}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:11:37 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:11:42 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:11:42 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:11:35 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.126,PodIP:192.168.1.98,StartTime:2019-11-14 23:11:37 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-11-14 23:11:40 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://30ee2f5e24dd190a99b0490aab5fa42654ea747890eb4b75b9839203487e373a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Nov 14 23:11:44.689: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Nov 14 23:11:46.697: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:11:46.708: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-6709" for this suite.
Nov 14 23:12:25.174: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:12:25.517: INFO: namespace events-6709 deletion completed in 38.559824211s

• [SLOW TEST:49.329 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:12:25.528: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-8438
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod busybox-72fc976e-fd89-4733-a892-34243a9ad785 in namespace container-probe-8438
Nov 14 23:12:30.139: INFO: Started pod busybox-72fc976e-fd89-4733-a892-34243a9ad785 in namespace container-probe-8438
STEP: checking the pod's current state and verifying that restartCount is present
Nov 14 23:12:30.141: INFO: Initial restart count of pod busybox-72fc976e-fd89-4733-a892-34243a9ad785 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:16:30.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8438" for this suite.
Nov 14 23:16:38.717: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:16:38.867: INFO: namespace container-probe-8438 deletion completed in 8.246251132s

• [SLOW TEST:253.339 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:16:38.871: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1433
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-5d2e3a87-9165-482d-bdf7-15dde5a70c9c
STEP: Creating a pod to test consume configMaps
Nov 14 23:16:40.162: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-8a425364-ab69-4ea0-ac1b-0d51806456d8" in namespace "projected-1433" to be "success or failure"
Nov 14 23:16:40.279: INFO: Pod "pod-projected-configmaps-8a425364-ab69-4ea0-ac1b-0d51806456d8": Phase="Pending", Reason="", readiness=false. Elapsed: 117.364379ms
Nov 14 23:16:42.469: INFO: Pod "pod-projected-configmaps-8a425364-ab69-4ea0-ac1b-0d51806456d8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.3070034s
Nov 14 23:16:44.627: INFO: Pod "pod-projected-configmaps-8a425364-ab69-4ea0-ac1b-0d51806456d8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.464514299s
Nov 14 23:16:46.838: INFO: Pod "pod-projected-configmaps-8a425364-ab69-4ea0-ac1b-0d51806456d8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.6756123s
STEP: Saw pod success
Nov 14 23:16:46.838: INFO: Pod "pod-projected-configmaps-8a425364-ab69-4ea0-ac1b-0d51806456d8" satisfied condition "success or failure"
Nov 14 23:16:46.840: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-0 pod pod-projected-configmaps-8a425364-ab69-4ea0-ac1b-0d51806456d8 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov 14 23:16:47.733: INFO: Waiting for pod pod-projected-configmaps-8a425364-ab69-4ea0-ac1b-0d51806456d8 to disappear
Nov 14 23:16:48.361: INFO: Pod pod-projected-configmaps-8a425364-ab69-4ea0-ac1b-0d51806456d8 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:16:48.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1433" for this suite.
Nov 14 23:16:55.658: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:16:55.959: INFO: namespace projected-1433 deletion completed in 7.579220467s

• [SLOW TEST:17.088 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:16:55.961: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2599
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on tmpfs
Nov 14 23:16:56.516: INFO: Waiting up to 5m0s for pod "pod-adb61825-45cb-4cb5-b38d-cc1390ee839b" in namespace "emptydir-2599" to be "success or failure"
Nov 14 23:16:56.550: INFO: Pod "pod-adb61825-45cb-4cb5-b38d-cc1390ee839b": Phase="Pending", Reason="", readiness=false. Elapsed: 34.029916ms
Nov 14 23:16:58.679: INFO: Pod "pod-adb61825-45cb-4cb5-b38d-cc1390ee839b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.163067362s
Nov 14 23:17:00.690: INFO: Pod "pod-adb61825-45cb-4cb5-b38d-cc1390ee839b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.174004914s
STEP: Saw pod success
Nov 14 23:17:00.692: INFO: Pod "pod-adb61825-45cb-4cb5-b38d-cc1390ee839b" satisfied condition "success or failure"
Nov 14 23:17:00.724: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-1 pod pod-adb61825-45cb-4cb5-b38d-cc1390ee839b container test-container: <nil>
STEP: delete the pod
Nov 14 23:17:00.882: INFO: Waiting for pod pod-adb61825-45cb-4cb5-b38d-cc1390ee839b to disappear
Nov 14 23:17:01.111: INFO: Pod pod-adb61825-45cb-4cb5-b38d-cc1390ee839b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:17:01.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2599" for this suite.
Nov 14 23:17:07.166: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:17:07.293: INFO: namespace emptydir-2599 deletion completed in 6.17436512s

• [SLOW TEST:11.333 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:17:07.298: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2972
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Nov 14 23:17:07.865: INFO: Waiting up to 5m0s for pod "downwardapi-volume-13b1f251-9f22-47bc-8c6e-2fdd656a23e3" in namespace "downward-api-2972" to be "success or failure"
Nov 14 23:17:07.998: INFO: Pod "downwardapi-volume-13b1f251-9f22-47bc-8c6e-2fdd656a23e3": Phase="Pending", Reason="", readiness=false. Elapsed: 132.905031ms
Nov 14 23:17:10.002: INFO: Pod "downwardapi-volume-13b1f251-9f22-47bc-8c6e-2fdd656a23e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.137338397s
Nov 14 23:17:12.179: INFO: Pod "downwardapi-volume-13b1f251-9f22-47bc-8c6e-2fdd656a23e3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.314118621s
Nov 14 23:17:14.183: INFO: Pod "downwardapi-volume-13b1f251-9f22-47bc-8c6e-2fdd656a23e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.317387538s
STEP: Saw pod success
Nov 14 23:17:14.183: INFO: Pod "downwardapi-volume-13b1f251-9f22-47bc-8c6e-2fdd656a23e3" satisfied condition "success or failure"
Nov 14 23:17:14.185: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-0 pod downwardapi-volume-13b1f251-9f22-47bc-8c6e-2fdd656a23e3 container client-container: <nil>
STEP: delete the pod
Nov 14 23:17:14.304: INFO: Waiting for pod downwardapi-volume-13b1f251-9f22-47bc-8c6e-2fdd656a23e3 to disappear
Nov 14 23:17:14.337: INFO: Pod downwardapi-volume-13b1f251-9f22-47bc-8c6e-2fdd656a23e3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:17:14.338: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2972" for this suite.
Nov 14 23:17:22.382: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:17:22.787: INFO: namespace downward-api-2972 deletion completed in 8.444410287s

• [SLOW TEST:15.490 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:17:22.790: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1374
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Nov 14 23:17:24.228: INFO: Waiting up to 5m0s for pod "downward-api-53088a1c-2773-46a9-b40e-920b6af725b1" in namespace "downward-api-1374" to be "success or failure"
Nov 14 23:17:24.264: INFO: Pod "downward-api-53088a1c-2773-46a9-b40e-920b6af725b1": Phase="Pending", Reason="", readiness=false. Elapsed: 34.846215ms
Nov 14 23:17:26.267: INFO: Pod "downward-api-53088a1c-2773-46a9-b40e-920b6af725b1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038746188s
Nov 14 23:17:28.741: INFO: Pod "downward-api-53088a1c-2773-46a9-b40e-920b6af725b1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.512588308s
Nov 14 23:17:30.764: INFO: Pod "downward-api-53088a1c-2773-46a9-b40e-920b6af725b1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.535681843s
STEP: Saw pod success
Nov 14 23:17:30.764: INFO: Pod "downward-api-53088a1c-2773-46a9-b40e-920b6af725b1" satisfied condition "success or failure"
Nov 14 23:17:30.767: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-1 pod downward-api-53088a1c-2773-46a9-b40e-920b6af725b1 container dapi-container: <nil>
STEP: delete the pod
Nov 14 23:17:30.935: INFO: Waiting for pod downward-api-53088a1c-2773-46a9-b40e-920b6af725b1 to disappear
Nov 14 23:17:30.966: INFO: Pod downward-api-53088a1c-2773-46a9-b40e-920b6af725b1 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:17:30.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1374" for this suite.
Nov 14 23:17:39.001: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:17:39.129: INFO: namespace downward-api-1374 deletion completed in 8.159160775s

• [SLOW TEST:16.340 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:17:39.135: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-5357
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Nov 14 23:17:39.738: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-5357,SelfLink:/api/v1/namespaces/watch-5357/configmaps/e2e-watch-test-watch-closed,UID:a2d43bc1-1813-48ab-b683-f8af31865a8b,ResourceVersion:23910,Generation:0,CreationTimestamp:2019-11-14 23:17:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov 14 23:17:39.739: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-5357,SelfLink:/api/v1/namespaces/watch-5357/configmaps/e2e-watch-test-watch-closed,UID:a2d43bc1-1813-48ab-b683-f8af31865a8b,ResourceVersion:23912,Generation:0,CreationTimestamp:2019-11-14 23:17:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Nov 14 23:17:39.954: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-5357,SelfLink:/api/v1/namespaces/watch-5357/configmaps/e2e-watch-test-watch-closed,UID:a2d43bc1-1813-48ab-b683-f8af31865a8b,ResourceVersion:23914,Generation:0,CreationTimestamp:2019-11-14 23:17:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov 14 23:17:39.954: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-5357,SelfLink:/api/v1/namespaces/watch-5357/configmaps/e2e-watch-test-watch-closed,UID:a2d43bc1-1813-48ab-b683-f8af31865a8b,ResourceVersion:23915,Generation:0,CreationTimestamp:2019-11-14 23:17:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:17:39.954: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-5357" for this suite.
Nov 14 23:17:46.033: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:17:46.147: INFO: namespace watch-5357 deletion completed in 6.161268635s

• [SLOW TEST:7.012 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:17:46.179: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-5369
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating service multi-endpoint-test in namespace services-5369
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5369 to expose endpoints map[]
Nov 14 23:17:46.851: INFO: successfully validated that service multi-endpoint-test in namespace services-5369 exposes endpoints map[] (179.576751ms elapsed)
STEP: Creating pod pod1 in namespace services-5369
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5369 to expose endpoints map[pod1:[100]]
Nov 14 23:17:51.370: INFO: Unexpected endpoints: found map[], expected map[pod1:[100]] (4.50435576s elapsed, will retry)
Nov 14 23:17:54.671: INFO: successfully validated that service multi-endpoint-test in namespace services-5369 exposes endpoints map[pod1:[100]] (7.805496326s elapsed)
STEP: Creating pod pod2 in namespace services-5369
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5369 to expose endpoints map[pod1:[100] pod2:[101]]
Nov 14 23:17:58.887: INFO: successfully validated that service multi-endpoint-test in namespace services-5369 exposes endpoints map[pod1:[100] pod2:[101]] (4.16746938s elapsed)
STEP: Deleting pod pod1 in namespace services-5369
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5369 to expose endpoints map[pod2:[101]]
Nov 14 23:17:59.108: INFO: successfully validated that service multi-endpoint-test in namespace services-5369 exposes endpoints map[pod2:[101]] (212.00735ms elapsed)
STEP: Deleting pod pod2 in namespace services-5369
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5369 to expose endpoints map[]
Nov 14 23:17:59.363: INFO: successfully validated that service multi-endpoint-test in namespace services-5369 exposes endpoints map[] (31.451406ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:18:00.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5369" for this suite.
Nov 14 23:18:25.919: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:18:26.086: INFO: namespace services-5369 deletion completed in 25.093263081s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:39.908 seconds]
[sig-network] Services
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:18:26.097: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-8145
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Nov 14 23:18:26.612: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-8145,SelfLink:/api/v1/namespaces/watch-8145/configmaps/e2e-watch-test-label-changed,UID:fb28ca59-3d26-4fa0-a0d9-77039a89c031,ResourceVersion:24073,Generation:0,CreationTimestamp:2019-11-14 23:18:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov 14 23:18:26.613: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-8145,SelfLink:/api/v1/namespaces/watch-8145/configmaps/e2e-watch-test-label-changed,UID:fb28ca59-3d26-4fa0-a0d9-77039a89c031,ResourceVersion:24074,Generation:0,CreationTimestamp:2019-11-14 23:18:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Nov 14 23:18:26.614: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-8145,SelfLink:/api/v1/namespaces/watch-8145/configmaps/e2e-watch-test-label-changed,UID:fb28ca59-3d26-4fa0-a0d9-77039a89c031,ResourceVersion:24075,Generation:0,CreationTimestamp:2019-11-14 23:18:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Nov 14 23:18:36.964: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-8145,SelfLink:/api/v1/namespaces/watch-8145/configmaps/e2e-watch-test-label-changed,UID:fb28ca59-3d26-4fa0-a0d9-77039a89c031,ResourceVersion:24096,Generation:0,CreationTimestamp:2019-11-14 23:18:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov 14 23:18:36.965: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-8145,SelfLink:/api/v1/namespaces/watch-8145/configmaps/e2e-watch-test-label-changed,UID:fb28ca59-3d26-4fa0-a0d9-77039a89c031,ResourceVersion:24098,Generation:0,CreationTimestamp:2019-11-14 23:18:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Nov 14 23:18:36.965: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-8145,SelfLink:/api/v1/namespaces/watch-8145/configmaps/e2e-watch-test-label-changed,UID:fb28ca59-3d26-4fa0-a0d9-77039a89c031,ResourceVersion:24099,Generation:0,CreationTimestamp:2019-11-14 23:18:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:18:36.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8145" for this suite.
Nov 14 23:18:43.211: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:18:43.629: INFO: namespace watch-8145 deletion completed in 6.63220053s

• [SLOW TEST:17.533 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:18:43.639: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-3330
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Nov 14 23:18:48.425: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:18:48.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-3330" for this suite.
Nov 14 23:18:56.794: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:18:56.974: INFO: namespace container-runtime-3330 deletion completed in 8.312640741s

• [SLOW TEST:13.335 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:18:56.974: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-5797
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Nov 14 23:19:06.055: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov 14 23:19:06.089: INFO: Pod pod-with-poststart-http-hook still exists
Nov 14 23:19:08.089: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov 14 23:19:08.168: INFO: Pod pod-with-poststart-http-hook still exists
Nov 14 23:19:10.089: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov 14 23:19:10.150: INFO: Pod pod-with-poststart-http-hook still exists
Nov 14 23:19:12.089: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov 14 23:19:12.092: INFO: Pod pod-with-poststart-http-hook still exists
Nov 14 23:19:14.089: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov 14 23:19:14.179: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:19:14.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-5797" for this suite.
Nov 14 23:19:38.279: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:19:38.600: INFO: namespace container-lifecycle-hook-5797 deletion completed in 24.413415275s

• [SLOW TEST:41.626 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:19:38.617: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9782
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on node default medium
Nov 14 23:19:39.174: INFO: Waiting up to 5m0s for pod "pod-735e9a59-e8a7-4605-b6fa-bc0e9af26a24" in namespace "emptydir-9782" to be "success or failure"
Nov 14 23:19:39.237: INFO: Pod "pod-735e9a59-e8a7-4605-b6fa-bc0e9af26a24": Phase="Pending", Reason="", readiness=false. Elapsed: 62.254972ms
Nov 14 23:19:41.281: INFO: Pod "pod-735e9a59-e8a7-4605-b6fa-bc0e9af26a24": Phase="Pending", Reason="", readiness=false. Elapsed: 2.106824943s
Nov 14 23:19:43.286: INFO: Pod "pod-735e9a59-e8a7-4605-b6fa-bc0e9af26a24": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.11164851s
STEP: Saw pod success
Nov 14 23:19:43.286: INFO: Pod "pod-735e9a59-e8a7-4605-b6fa-bc0e9af26a24" satisfied condition "success or failure"
Nov 14 23:19:43.290: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-1 pod pod-735e9a59-e8a7-4605-b6fa-bc0e9af26a24 container test-container: <nil>
STEP: delete the pod
Nov 14 23:19:43.349: INFO: Waiting for pod pod-735e9a59-e8a7-4605-b6fa-bc0e9af26a24 to disappear
Nov 14 23:19:43.485: INFO: Pod pod-735e9a59-e8a7-4605-b6fa-bc0e9af26a24 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:19:43.485: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9782" for this suite.
Nov 14 23:19:49.774: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:19:50.005: INFO: namespace emptydir-9782 deletion completed in 6.514886776s

• [SLOW TEST:11.388 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:19:50.012: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5317
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-0c76927c-30d4-48f0-8ce1-299a34bb3280
STEP: Creating a pod to test consume secrets
Nov 14 23:19:50.735: INFO: Waiting up to 5m0s for pod "pod-secrets-a40d5a49-18d5-413d-98f4-b7ff57d64534" in namespace "secrets-5317" to be "success or failure"
Nov 14 23:19:50.998: INFO: Pod "pod-secrets-a40d5a49-18d5-413d-98f4-b7ff57d64534": Phase="Pending", Reason="", readiness=false. Elapsed: 262.325847ms
Nov 14 23:19:53.243: INFO: Pod "pod-secrets-a40d5a49-18d5-413d-98f4-b7ff57d64534": Phase="Pending", Reason="", readiness=false. Elapsed: 2.507742454s
Nov 14 23:19:55.846: INFO: Pod "pod-secrets-a40d5a49-18d5-413d-98f4-b7ff57d64534": Phase="Pending", Reason="", readiness=false. Elapsed: 5.110943875s
Nov 14 23:19:57.850: INFO: Pod "pod-secrets-a40d5a49-18d5-413d-98f4-b7ff57d64534": Phase="Succeeded", Reason="", readiness=false. Elapsed: 7.115148824s
STEP: Saw pod success
Nov 14 23:19:57.851: INFO: Pod "pod-secrets-a40d5a49-18d5-413d-98f4-b7ff57d64534" satisfied condition "success or failure"
Nov 14 23:19:57.854: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-0 pod pod-secrets-a40d5a49-18d5-413d-98f4-b7ff57d64534 container secret-env-test: <nil>
STEP: delete the pod
Nov 14 23:19:58.092: INFO: Waiting for pod pod-secrets-a40d5a49-18d5-413d-98f4-b7ff57d64534 to disappear
Nov 14 23:19:58.191: INFO: Pod pod-secrets-a40d5a49-18d5-413d-98f4-b7ff57d64534 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:19:58.192: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5317" for this suite.
Nov 14 23:20:04.719: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:20:04.833: INFO: namespace secrets-5317 deletion completed in 6.518299117s

• [SLOW TEST:14.822 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:20:04.838: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-7417
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-7417
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Nov 14 23:20:05.302: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Nov 14 23:20:36.055: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.2.101:8080/dial?request=hostName&protocol=udp&host=192.168.1.105&port=8081&tries=1'] Namespace:pod-network-test-7417 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 14 23:20:36.055: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
Nov 14 23:20:36.391: INFO: Waiting for endpoints: map[]
Nov 14 23:20:36.394: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.2.101:8080/dial?request=hostName&protocol=udp&host=192.168.2.100&port=8081&tries=1'] Namespace:pod-network-test-7417 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 14 23:20:36.394: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
Nov 14 23:20:36.565: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:20:36.565: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7417" for this suite.
Nov 14 23:21:04.708: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:21:04.851: INFO: namespace pod-network-test-7417 deletion completed in 28.260967821s

• [SLOW TEST:60.013 seconds]
[sig-network] Networking
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:21:04.855: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-5159
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test substitution in container's args
Nov 14 23:21:05.389: INFO: Waiting up to 5m0s for pod "var-expansion-f96083c8-55dc-4f63-b89f-967e63b3bbf5" in namespace "var-expansion-5159" to be "success or failure"
Nov 14 23:21:05.421: INFO: Pod "var-expansion-f96083c8-55dc-4f63-b89f-967e63b3bbf5": Phase="Pending", Reason="", readiness=false. Elapsed: 32.260403ms
Nov 14 23:21:07.425: INFO: Pod "var-expansion-f96083c8-55dc-4f63-b89f-967e63b3bbf5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036515421s
Nov 14 23:21:09.431: INFO: Pod "var-expansion-f96083c8-55dc-4f63-b89f-967e63b3bbf5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.042394181s
STEP: Saw pod success
Nov 14 23:21:09.432: INFO: Pod "var-expansion-f96083c8-55dc-4f63-b89f-967e63b3bbf5" satisfied condition "success or failure"
Nov 14 23:21:09.436: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-1 pod var-expansion-f96083c8-55dc-4f63-b89f-967e63b3bbf5 container dapi-container: <nil>
STEP: delete the pod
Nov 14 23:21:10.120: INFO: Waiting for pod var-expansion-f96083c8-55dc-4f63-b89f-967e63b3bbf5 to disappear
Nov 14 23:21:10.124: INFO: Pod var-expansion-f96083c8-55dc-4f63-b89f-967e63b3bbf5 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:21:10.124: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-5159" for this suite.
Nov 14 23:21:16.402: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:21:16.588: INFO: namespace var-expansion-5159 deletion completed in 6.459638172s

• [SLOW TEST:11.734 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:21:16.594: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-2748
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:22:17.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2748" for this suite.
Nov 14 23:22:41.233: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:22:41.390: INFO: namespace container-probe-2748 deletion completed in 24.277320171s

• [SLOW TEST:84.798 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:22:41.397: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1662
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1612
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Nov 14 23:22:41.896: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-1662'
Nov 14 23:22:44.722: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Nov 14 23:22:44.722: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1617
Nov 14 23:22:44.818: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 delete jobs e2e-test-nginx-job --namespace=kubectl-1662'
Nov 14 23:22:45.168: INFO: stderr: ""
Nov 14 23:22:45.168: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:22:45.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1662" for this suite.
Nov 14 23:23:07.424: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:23:07.559: INFO: namespace kubectl-1662 deletion completed in 22.302711558s

• [SLOW TEST:26.163 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run job
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:23:07.567: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5509
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1721
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Nov 14 23:23:08.053: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=kubectl-5509'
Nov 14 23:23:08.182: INFO: stderr: ""
Nov 14 23:23:08.182: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Nov 14 23:23:13.271: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 get pod e2e-test-nginx-pod --namespace=kubectl-5509 -o json'
Nov 14 23:23:13.392: INFO: stderr: ""
Nov 14 23:23:13.392: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"192.168.1.107/32\"\n        },\n        \"creationTimestamp\": \"2019-11-14T23:23:07Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"kubectl-5509\",\n        \"resourceVersion\": \"24935\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-5509/pods/e2e-test-nginx-pod\",\n        \"uid\": \"854127d1-863f-4211-91c2-7b144a5bff11\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-2p762\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"k8s-1-tdyr52fdsot3-minion-0\",\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-2p762\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-2p762\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-11-14T23:23:08Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-11-14T23:23:12Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-11-14T23:23:12Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-11-14T23:23:07Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://af64ea726f40f71ba57634c4c29f993b4b63b47281ed20029fb2e6177444fa0f\",\n                \"image\": \"docker.io/nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://docker.io/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-11-14T23:23:12Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.0.0.126\",\n        \"phase\": \"Running\",\n        \"podIP\": \"192.168.1.107\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-11-14T23:23:08Z\"\n    }\n}\n"
STEP: replace the image in the pod
Nov 14 23:23:13.392: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 replace -f - --namespace=kubectl-5509'
Nov 14 23:23:13.799: INFO: stderr: ""
Nov 14 23:23:13.799: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1726
Nov 14 23:23:13.887: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 delete pods e2e-test-nginx-pod --namespace=kubectl-5509'
Nov 14 23:23:18.642: INFO: stderr: ""
Nov 14 23:23:18.642: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:23:18.642: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5509" for this suite.
Nov 14 23:23:26.711: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:23:26.839: INFO: namespace kubectl-5509 deletion completed in 8.173088156s

• [SLOW TEST:19.273 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl replace
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:23:26.846: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5928
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on node default medium
Nov 14 23:23:27.445: INFO: Waiting up to 5m0s for pod "pod-51f2695c-abdb-4abb-9672-b675c86a015b" in namespace "emptydir-5928" to be "success or failure"
Nov 14 23:23:27.514: INFO: Pod "pod-51f2695c-abdb-4abb-9672-b675c86a015b": Phase="Pending", Reason="", readiness=false. Elapsed: 68.509534ms
Nov 14 23:23:29.519: INFO: Pod "pod-51f2695c-abdb-4abb-9672-b675c86a015b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.073628151s
Nov 14 23:23:31.525: INFO: Pod "pod-51f2695c-abdb-4abb-9672-b675c86a015b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.079945602s
Nov 14 23:23:33.532: INFO: Pod "pod-51f2695c-abdb-4abb-9672-b675c86a015b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.0864677s
STEP: Saw pod success
Nov 14 23:23:33.532: INFO: Pod "pod-51f2695c-abdb-4abb-9672-b675c86a015b" satisfied condition "success or failure"
Nov 14 23:23:33.536: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-1 pod pod-51f2695c-abdb-4abb-9672-b675c86a015b container test-container: <nil>
STEP: delete the pod
Nov 14 23:23:33.683: INFO: Waiting for pod pod-51f2695c-abdb-4abb-9672-b675c86a015b to disappear
Nov 14 23:23:33.703: INFO: Pod pod-51f2695c-abdb-4abb-9672-b675c86a015b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:23:33.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5928" for this suite.
Nov 14 23:23:39.781: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:23:39.901: INFO: namespace emptydir-5928 deletion completed in 6.19240783s

• [SLOW TEST:13.056 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:23:39.908: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-7150
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-secret-5vk9
STEP: Creating a pod to test atomic-volume-subpath
Nov 14 23:23:40.841: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-5vk9" in namespace "subpath-7150" to be "success or failure"
Nov 14 23:23:40.975: INFO: Pod "pod-subpath-test-secret-5vk9": Phase="Pending", Reason="", readiness=false. Elapsed: 134.603358ms
Nov 14 23:23:43.035: INFO: Pod "pod-subpath-test-secret-5vk9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.194475466s
Nov 14 23:23:45.112: INFO: Pod "pod-subpath-test-secret-5vk9": Phase="Running", Reason="", readiness=true. Elapsed: 4.271506542s
Nov 14 23:23:47.119: INFO: Pod "pod-subpath-test-secret-5vk9": Phase="Running", Reason="", readiness=true. Elapsed: 6.277854703s
Nov 14 23:23:49.125: INFO: Pod "pod-subpath-test-secret-5vk9": Phase="Running", Reason="", readiness=true. Elapsed: 8.284485394s
Nov 14 23:23:51.131: INFO: Pod "pod-subpath-test-secret-5vk9": Phase="Running", Reason="", readiness=true. Elapsed: 10.29031203s
Nov 14 23:23:53.136: INFO: Pod "pod-subpath-test-secret-5vk9": Phase="Running", Reason="", readiness=true. Elapsed: 12.295194654s
Nov 14 23:23:55.243: INFO: Pod "pod-subpath-test-secret-5vk9": Phase="Running", Reason="", readiness=true. Elapsed: 14.401791546s
Nov 14 23:23:57.246: INFO: Pod "pod-subpath-test-secret-5vk9": Phase="Running", Reason="", readiness=true. Elapsed: 16.404997397s
Nov 14 23:23:59.251: INFO: Pod "pod-subpath-test-secret-5vk9": Phase="Running", Reason="", readiness=true. Elapsed: 18.4105893s
Nov 14 23:24:01.255: INFO: Pod "pod-subpath-test-secret-5vk9": Phase="Running", Reason="", readiness=true. Elapsed: 20.414361281s
Nov 14 23:24:03.260: INFO: Pod "pod-subpath-test-secret-5vk9": Phase="Running", Reason="", readiness=true. Elapsed: 22.419366837s
Nov 14 23:24:05.264: INFO: Pod "pod-subpath-test-secret-5vk9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.422868932s
STEP: Saw pod success
Nov 14 23:24:05.264: INFO: Pod "pod-subpath-test-secret-5vk9" satisfied condition "success or failure"
Nov 14 23:24:05.267: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-1 pod pod-subpath-test-secret-5vk9 container test-container-subpath-secret-5vk9: <nil>
STEP: delete the pod
Nov 14 23:24:05.322: INFO: Waiting for pod pod-subpath-test-secret-5vk9 to disappear
Nov 14 23:24:05.354: INFO: Pod pod-subpath-test-secret-5vk9 no longer exists
STEP: Deleting pod pod-subpath-test-secret-5vk9
Nov 14 23:24:05.354: INFO: Deleting pod "pod-subpath-test-secret-5vk9" in namespace "subpath-7150"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:24:05.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7150" for this suite.
Nov 14 23:24:11.462: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:24:11.624: INFO: namespace subpath-7150 deletion completed in 6.262671417s

• [SLOW TEST:31.717 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:24:11.629: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-8180
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Nov 14 23:24:11.981: INFO: Creating deployment "test-recreate-deployment"
Nov 14 23:24:12.036: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Nov 14 23:24:12.482: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Nov 14 23:24:14.492: INFO: Waiting deployment "test-recreate-deployment" to complete
Nov 14 23:24:14.562: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709370651, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709370651, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709370652, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709370651, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-6df85df6b9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 14 23:24:16.693: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709370651, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709370651, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709370652, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709370651, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-6df85df6b9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 14 23:24:18.598: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Nov 14 23:24:18.611: INFO: Updating deployment test-recreate-deployment
Nov 14 23:24:18.612: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Nov 14 23:24:20.514: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-8180,SelfLink:/apis/apps/v1/namespaces/deployment-8180/deployments/test-recreate-deployment,UID:488bdfaf-bc8e-4a34-bf0b-d86813912c25,ResourceVersion:25189,Generation:2,CreationTimestamp:2019-11-14 23:24:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-11-14 23:24:18 +0000 UTC 2019-11-14 23:24:18 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-11-14 23:24:19 +0000 UTC 2019-11-14 23:24:11 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-5c8c9cc69d" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Nov 14 23:24:20.645: INFO: New ReplicaSet "test-recreate-deployment-5c8c9cc69d" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5c8c9cc69d,GenerateName:,Namespace:deployment-8180,SelfLink:/apis/apps/v1/namespaces/deployment-8180/replicasets/test-recreate-deployment-5c8c9cc69d,UID:e14bdc45-946b-4544-8f85-3e09cd58ff0c,ResourceVersion:25188,Generation:1,CreationTimestamp:2019-11-14 23:24:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 488bdfaf-bc8e-4a34-bf0b-d86813912c25 0xc003a0f767 0xc003a0f768}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Nov 14 23:24:20.646: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Nov 14 23:24:20.717: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-6df85df6b9,GenerateName:,Namespace:deployment-8180,SelfLink:/apis/apps/v1/namespaces/deployment-8180/replicasets/test-recreate-deployment-6df85df6b9,UID:b2117f27-64ea-442a-9db0-ac0f02067a7b,ResourceVersion:25175,Generation:2,CreationTimestamp:2019-11-14 23:24:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 488bdfaf-bc8e-4a34-bf0b-d86813912c25 0xc003a0f837 0xc003a0f838}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Nov 14 23:24:20.993: INFO: Pod "test-recreate-deployment-5c8c9cc69d-qchqj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5c8c9cc69d-qchqj,GenerateName:test-recreate-deployment-5c8c9cc69d-,Namespace:deployment-8180,SelfLink:/api/v1/namespaces/deployment-8180/pods/test-recreate-deployment-5c8c9cc69d-qchqj,UID:eed78ef7-34e8-4f56-8a54-ebdaa862c9b4,ResourceVersion:25191,Generation:0,CreationTimestamp:2019-11-14 23:24:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-5c8c9cc69d e14bdc45-946b-4544-8f85-3e09cd58ff0c 0xc002d2e117 0xc002d2e118}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pbs8g {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pbs8g,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-pbs8g true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-tdyr52fdsot3-minion-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002d2e180} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002d2e1a0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:24:20 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:24:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:24:20 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:24:18 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.126,PodIP:,StartTime:2019-11-14 23:24:20 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:24:20.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8180" for this suite.
Nov 14 23:24:33.287: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:24:33.683: INFO: namespace deployment-8180 deletion completed in 12.685566892s

• [SLOW TEST:22.054 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:24:33.686: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-5195
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Nov 14 23:24:34.137: INFO: PodSpec: initContainers in spec.initContainers
Nov 14 23:25:30.306: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-6e60a2f5-358f-47e4-a485-d4506ee246ef", GenerateName:"", Namespace:"init-container-5195", SelfLink:"/api/v1/namespaces/init-container-5195/pods/pod-init-6e60a2f5-358f-47e4-a485-d4506ee246ef", UID:"002450e0-82ab-4c20-b44a-c2b3fc7b66cc", ResourceVersion:"25385", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63709370673, loc:(*time.Location)(0x7ed0a20)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"137068075"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"192.168.1.110/32"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-cbl5g", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc002cfc740), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-cbl5g", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-cbl5g", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-cbl5g", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc003a164d8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"k8s-1-tdyr52fdsot3-minion-0", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc00261df20), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc003a16550)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc003a16570)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(nil), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc003a16578), PreemptionPolicy:(*v1.PreemptionPolicy)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709370674, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709370674, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709370674, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709370673, loc:(*time.Location)(0x7ed0a20)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.0.0.126", PodIP:"192.168.1.110", StartTime:(*v1.Time)(0xc0033193a0), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002bfb110)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002bfb180)}, Ready:false, RestartCount:3, Image:"docker.io/busybox:1.29", ImageID:"docker-pullable://docker.io/busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://4d966c2acff45d45f1205dfdc50d7c2ff6f831ccbedaf739d19ed4e8cc34c61a"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0033193e0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0033193c0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:25:30.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-5195" for this suite.
Nov 14 23:25:54.607: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:25:54.882: INFO: namespace init-container-5195 deletion completed in 24.556109833s

• [SLOW TEST:81.197 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:25:54.892: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-3074
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Nov 14 23:26:05.708: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov 14 23:26:05.773: INFO: Pod pod-with-prestop-http-hook still exists
Nov 14 23:26:07.773: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov 14 23:26:07.833: INFO: Pod pod-with-prestop-http-hook still exists
Nov 14 23:26:09.773: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov 14 23:26:09.777: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:26:09.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-3074" for this suite.
Nov 14 23:26:34.001: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:26:34.134: INFO: namespace container-lifecycle-hook-3074 deletion completed in 24.328048303s

• [SLOW TEST:39.242 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:26:34.137: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2617
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Starting the proxy
Nov 14 23:26:34.671: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-216763962 proxy --unix-socket=/tmp/kubectl-proxy-unix110835733/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:26:34.783: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2617" for this suite.
Nov 14 23:26:40.835: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:26:40.959: INFO: namespace kubectl-2617 deletion completed in 6.171251685s

• [SLOW TEST:6.822 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:26:40.963: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-2756
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name s-test-opt-del-187923a1-f528-4b60-bbd9-8e76daff02c9
STEP: Creating secret with name s-test-opt-upd-56f36c20-459a-4186-9161-3891c3c83bd0
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-187923a1-f528-4b60-bbd9-8e76daff02c9
STEP: Updating secret s-test-opt-upd-56f36c20-459a-4186-9161-3891c3c83bd0
STEP: Creating secret with name s-test-opt-create-8cf713fd-4490-4ede-b5a1-204e33041223
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:28:13.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2756" for this suite.
Nov 14 23:28:37.453: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:28:37.616: INFO: namespace secrets-2756 deletion completed in 24.247884551s

• [SLOW TEST:116.653 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:28:37.631: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7339
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Nov 14 23:28:38.239: INFO: Waiting up to 5m0s for pod "downwardapi-volume-20a471d6-13b7-4d89-a47a-746fe855160f" in namespace "projected-7339" to be "success or failure"
Nov 14 23:28:38.272: INFO: Pod "downwardapi-volume-20a471d6-13b7-4d89-a47a-746fe855160f": Phase="Pending", Reason="", readiness=false. Elapsed: 32.578932ms
Nov 14 23:28:40.275: INFO: Pod "downwardapi-volume-20a471d6-13b7-4d89-a47a-746fe855160f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036421011s
Nov 14 23:28:42.299: INFO: Pod "downwardapi-volume-20a471d6-13b7-4d89-a47a-746fe855160f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.059643026s
STEP: Saw pod success
Nov 14 23:28:42.299: INFO: Pod "downwardapi-volume-20a471d6-13b7-4d89-a47a-746fe855160f" satisfied condition "success or failure"
Nov 14 23:28:42.302: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-1 pod downwardapi-volume-20a471d6-13b7-4d89-a47a-746fe855160f container client-container: <nil>
STEP: delete the pod
Nov 14 23:28:42.521: INFO: Waiting for pod downwardapi-volume-20a471d6-13b7-4d89-a47a-746fe855160f to disappear
Nov 14 23:28:42.875: INFO: Pod downwardapi-volume-20a471d6-13b7-4d89-a47a-746fe855160f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:28:42.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7339" for this suite.
Nov 14 23:28:51.188: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:28:51.299: INFO: namespace projected-7339 deletion completed in 8.417360492s

• [SLOW TEST:13.669 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:28:51.304: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-1401
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-configmap-vwrp
STEP: Creating a pod to test atomic-volume-subpath
Nov 14 23:28:52.128: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-vwrp" in namespace "subpath-1401" to be "success or failure"
Nov 14 23:28:52.245: INFO: Pod "pod-subpath-test-configmap-vwrp": Phase="Pending", Reason="", readiness=false. Elapsed: 116.954853ms
Nov 14 23:28:54.250: INFO: Pod "pod-subpath-test-configmap-vwrp": Phase="Pending", Reason="", readiness=false. Elapsed: 2.121301647s
Nov 14 23:28:56.453: INFO: Pod "pod-subpath-test-configmap-vwrp": Phase="Pending", Reason="", readiness=false. Elapsed: 4.324543738s
Nov 14 23:28:58.460: INFO: Pod "pod-subpath-test-configmap-vwrp": Phase="Running", Reason="", readiness=true. Elapsed: 6.332104289s
Nov 14 23:29:00.463: INFO: Pod "pod-subpath-test-configmap-vwrp": Phase="Running", Reason="", readiness=true. Elapsed: 8.334543946s
Nov 14 23:29:02.468: INFO: Pod "pod-subpath-test-configmap-vwrp": Phase="Running", Reason="", readiness=true. Elapsed: 10.339984823s
Nov 14 23:29:04.473: INFO: Pod "pod-subpath-test-configmap-vwrp": Phase="Running", Reason="", readiness=true. Elapsed: 12.344593399s
Nov 14 23:29:06.479: INFO: Pod "pod-subpath-test-configmap-vwrp": Phase="Running", Reason="", readiness=true. Elapsed: 14.350428362s
Nov 14 23:29:08.583: INFO: Pod "pod-subpath-test-configmap-vwrp": Phase="Running", Reason="", readiness=true. Elapsed: 16.455027408s
Nov 14 23:29:10.626: INFO: Pod "pod-subpath-test-configmap-vwrp": Phase="Running", Reason="", readiness=true. Elapsed: 18.498087177s
Nov 14 23:29:12.702: INFO: Pod "pod-subpath-test-configmap-vwrp": Phase="Running", Reason="", readiness=true. Elapsed: 20.573733183s
Nov 14 23:29:14.779: INFO: Pod "pod-subpath-test-configmap-vwrp": Phase="Running", Reason="", readiness=true. Elapsed: 22.650173195s
Nov 14 23:29:16.823: INFO: Pod "pod-subpath-test-configmap-vwrp": Phase="Running", Reason="", readiness=true. Elapsed: 24.694409708s
Nov 14 23:29:18.829: INFO: Pod "pod-subpath-test-configmap-vwrp": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.700125645s
STEP: Saw pod success
Nov 14 23:29:18.830: INFO: Pod "pod-subpath-test-configmap-vwrp" satisfied condition "success or failure"
Nov 14 23:29:18.836: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-0 pod pod-subpath-test-configmap-vwrp container test-container-subpath-configmap-vwrp: <nil>
STEP: delete the pod
Nov 14 23:29:19.003: INFO: Waiting for pod pod-subpath-test-configmap-vwrp to disappear
Nov 14 23:29:19.032: INFO: Pod pod-subpath-test-configmap-vwrp no longer exists
STEP: Deleting pod pod-subpath-test-configmap-vwrp
Nov 14 23:29:19.032: INFO: Deleting pod "pod-subpath-test-configmap-vwrp" in namespace "subpath-1401"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:29:19.036: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1401" for this suite.
Nov 14 23:29:25.095: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:29:25.441: INFO: namespace subpath-1401 deletion completed in 6.398974851s

• [SLOW TEST:34.138 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:29:25.449: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-1786
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Nov 14 23:29:31.111: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:29:31.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-1786" for this suite.
Nov 14 23:29:55.616: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:29:55.834: INFO: namespace replicaset-1786 deletion completed in 24.54738477s

• [SLOW TEST:30.386 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:29:55.840: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4213
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-bda3a848-a2a1-470b-9ced-5666ac403fc0
STEP: Creating a pod to test consume configMaps
Nov 14 23:29:56.512: INFO: Waiting up to 5m0s for pod "pod-configmaps-ac3fbf52-fe92-492c-a378-2c592a02bd6e" in namespace "configmap-4213" to be "success or failure"
Nov 14 23:29:56.576: INFO: Pod "pod-configmaps-ac3fbf52-fe92-492c-a378-2c592a02bd6e": Phase="Pending", Reason="", readiness=false. Elapsed: 63.252044ms
Nov 14 23:29:58.823: INFO: Pod "pod-configmaps-ac3fbf52-fe92-492c-a378-2c592a02bd6e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.310489717s
Nov 14 23:30:00.829: INFO: Pod "pod-configmaps-ac3fbf52-fe92-492c-a378-2c592a02bd6e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.316659209s
STEP: Saw pod success
Nov 14 23:30:00.830: INFO: Pod "pod-configmaps-ac3fbf52-fe92-492c-a378-2c592a02bd6e" satisfied condition "success or failure"
Nov 14 23:30:00.833: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-1 pod pod-configmaps-ac3fbf52-fe92-492c-a378-2c592a02bd6e container configmap-volume-test: <nil>
STEP: delete the pod
Nov 14 23:30:01.197: INFO: Waiting for pod pod-configmaps-ac3fbf52-fe92-492c-a378-2c592a02bd6e to disappear
Nov 14 23:30:01.224: INFO: Pod pod-configmaps-ac3fbf52-fe92-492c-a378-2c592a02bd6e no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:30:01.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4213" for this suite.
Nov 14 23:30:07.268: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:30:07.413: INFO: namespace configmap-4213 deletion completed in 6.1838861s

• [SLOW TEST:11.574 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:30:07.420: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7042
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-upd-b55e852a-6b90-4539-85bc-6504a0ddabe0
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-b55e852a-6b90-4539-85bc-6504a0ddabe0
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:30:16.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7042" for this suite.
Nov 14 23:30:40.211: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:30:40.520: INFO: namespace configmap-7042 deletion completed in 24.418442146s

• [SLOW TEST:33.102 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:30:40.534: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7590
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on tmpfs
Nov 14 23:30:41.068: INFO: Waiting up to 5m0s for pod "pod-9bca1ef2-95d0-44bb-b639-8c67d2b351d0" in namespace "emptydir-7590" to be "success or failure"
Nov 14 23:30:41.399: INFO: Pod "pod-9bca1ef2-95d0-44bb-b639-8c67d2b351d0": Phase="Pending", Reason="", readiness=false. Elapsed: 331.075452ms
Nov 14 23:30:43.405: INFO: Pod "pod-9bca1ef2-95d0-44bb-b639-8c67d2b351d0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.336745782s
Nov 14 23:30:45.412: INFO: Pod "pod-9bca1ef2-95d0-44bb-b639-8c67d2b351d0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.343594324s
STEP: Saw pod success
Nov 14 23:30:45.413: INFO: Pod "pod-9bca1ef2-95d0-44bb-b639-8c67d2b351d0" satisfied condition "success or failure"
Nov 14 23:30:45.418: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-1 pod pod-9bca1ef2-95d0-44bb-b639-8c67d2b351d0 container test-container: <nil>
STEP: delete the pod
Nov 14 23:30:45.684: INFO: Waiting for pod pod-9bca1ef2-95d0-44bb-b639-8c67d2b351d0 to disappear
Nov 14 23:30:45.708: INFO: Pod pod-9bca1ef2-95d0-44bb-b639-8c67d2b351d0 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:30:45.708: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7590" for this suite.
Nov 14 23:30:51.879: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:30:52.144: INFO: namespace emptydir-7590 deletion completed in 6.429584845s

• [SLOW TEST:11.611 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:30:52.155: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-6754
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6754.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-6754.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6754.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-6754.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6754.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-6754.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6754.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-6754.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6754.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-6754.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6754.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-6754.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6754.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 160.93.254.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.254.93.160_udp@PTR;check="$$(dig +tcp +noall +answer +search 160.93.254.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.254.93.160_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-6754.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-6754.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-6754.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-6754.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-6754.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-6754.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-6754.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-6754.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-6754.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-6754.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-6754.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-6754.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6754.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 160.93.254.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.254.93.160_udp@PTR;check="$$(dig +tcp +noall +answer +search 160.93.254.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.254.93.160_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov 14 23:31:01.707: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-6754.svc.cluster.local from pod dns-6754/dns-test-ede02710-5f97-4cf0-ac6a-8620407e5819: the server could not find the requested resource (get pods dns-test-ede02710-5f97-4cf0-ac6a-8620407e5819)
Nov 14 23:31:01.713: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-6754.svc.cluster.local from pod dns-6754/dns-test-ede02710-5f97-4cf0-ac6a-8620407e5819: the server could not find the requested resource (get pods dns-test-ede02710-5f97-4cf0-ac6a-8620407e5819)
Nov 14 23:31:01.733: INFO: Unable to read wheezy_udp@PodARecord from pod dns-6754/dns-test-ede02710-5f97-4cf0-ac6a-8620407e5819: the server could not find the requested resource (get pods dns-test-ede02710-5f97-4cf0-ac6a-8620407e5819)
Nov 14 23:31:01.739: INFO: Unable to read wheezy_tcp@PodARecord from pod dns-6754/dns-test-ede02710-5f97-4cf0-ac6a-8620407e5819: the server could not find the requested resource (get pods dns-test-ede02710-5f97-4cf0-ac6a-8620407e5819)
Nov 14 23:31:01.765: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-6754.svc.cluster.local from pod dns-6754/dns-test-ede02710-5f97-4cf0-ac6a-8620407e5819: the server could not find the requested resource (get pods dns-test-ede02710-5f97-4cf0-ac6a-8620407e5819)
Nov 14 23:31:01.772: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-6754.svc.cluster.local from pod dns-6754/dns-test-ede02710-5f97-4cf0-ac6a-8620407e5819: the server could not find the requested resource (get pods dns-test-ede02710-5f97-4cf0-ac6a-8620407e5819)
Nov 14 23:31:01.782: INFO: Unable to read jessie_udp@PodARecord from pod dns-6754/dns-test-ede02710-5f97-4cf0-ac6a-8620407e5819: the server could not find the requested resource (get pods dns-test-ede02710-5f97-4cf0-ac6a-8620407e5819)
Nov 14 23:31:01.784: INFO: Unable to read jessie_tcp@PodARecord from pod dns-6754/dns-test-ede02710-5f97-4cf0-ac6a-8620407e5819: the server could not find the requested resource (get pods dns-test-ede02710-5f97-4cf0-ac6a-8620407e5819)
Nov 14 23:31:01.789: INFO: Lookups using dns-6754/dns-test-ede02710-5f97-4cf0-ac6a-8620407e5819 failed for: [wheezy_udp@_http._tcp.dns-test-service.dns-6754.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-6754.svc.cluster.local wheezy_udp@PodARecord wheezy_tcp@PodARecord jessie_udp@_http._tcp.dns-test-service.dns-6754.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-6754.svc.cluster.local jessie_udp@PodARecord jessie_tcp@PodARecord]

Nov 14 23:31:06.969: INFO: DNS probes using dns-6754/dns-test-ede02710-5f97-4cf0-ac6a-8620407e5819 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:31:08.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6754" for this suite.
Nov 14 23:31:16.902: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:31:17.074: INFO: namespace dns-6754 deletion completed in 8.336317631s

• [SLOW TEST:24.920 seconds]
[sig-network] DNS
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:31:17.081: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-8799
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Nov 14 23:31:17.612: INFO: Creating deployment "nginx-deployment"
Nov 14 23:31:17.697: INFO: Waiting for observed generation 1
Nov 14 23:31:19.938: INFO: Waiting for all required pods to come up
Nov 14 23:31:20.029: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Nov 14 23:31:44.321: INFO: Waiting for deployment "nginx-deployment" to complete
Nov 14 23:31:44.366: INFO: Updating deployment "nginx-deployment" with a non-existent image
Nov 14 23:31:44.378: INFO: Updating deployment nginx-deployment
Nov 14 23:31:44.378: INFO: Waiting for observed generation 2
Nov 14 23:31:46.655: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Nov 14 23:31:46.964: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Nov 14 23:31:47.415: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Nov 14 23:31:48.821: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Nov 14 23:31:48.821: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Nov 14 23:31:49.180: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Nov 14 23:31:49.185: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Nov 14 23:31:49.186: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Nov 14 23:31:49.195: INFO: Updating deployment nginx-deployment
Nov 14 23:31:49.195: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Nov 14 23:31:49.843: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Nov 14 23:31:52.350: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Nov 14 23:31:54.667: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-8799,SelfLink:/apis/apps/v1/namespaces/deployment-8799/deployments/nginx-deployment,UID:cd6ad3a7-99cf-4cc2-84b3-3b883531fe62,ResourceVersion:26731,Generation:3,CreationTimestamp:2019-11-14 23:31:16 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:25,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Progressing True 2019-11-14 23:31:47 +0000 UTC 2019-11-14 23:31:17 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-55fb7cb77f" is progressing.} {Available False 2019-11-14 23:31:49 +0000 UTC 2019-11-14 23:31:49 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}],ReadyReplicas:8,CollisionCount:nil,},}

Nov 14 23:31:55.239: INFO: New ReplicaSet "nginx-deployment-55fb7cb77f" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f,GenerateName:,Namespace:deployment-8799,SelfLink:/apis/apps/v1/namespaces/deployment-8799/replicasets/nginx-deployment-55fb7cb77f,UID:931abcd9-bfb2-4127-bedd-359d9dfa963d,ResourceVersion:26733,Generation:3,CreationTimestamp:2019-11-14 23:31:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment cd6ad3a7-99cf-4cc2-84b3-3b883531fe62 0xc002207047 0xc002207048}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Nov 14 23:31:55.240: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Nov 14 23:31:55.240: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498,GenerateName:,Namespace:deployment-8799,SelfLink:/apis/apps/v1/namespaces/deployment-8799/replicasets/nginx-deployment-7b8c6f4498,UID:15f3dcaa-2f2f-47ab-824a-3d8001a6d5fc,ResourceVersion:26727,Generation:3,CreationTimestamp:2019-11-14 23:31:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment cd6ad3a7-99cf-4cc2-84b3-3b883531fe62 0xc002207117 0xc002207118}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Nov 14 23:31:55.566: INFO: Pod "nginx-deployment-55fb7cb77f-7rw8n" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-7rw8n,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-8799,SelfLink:/api/v1/namespaces/deployment-8799/pods/nginx-deployment-55fb7cb77f-7rw8n,UID:bbfcd155-7d83-4e44-8a27-e2abe455cfc9,ResourceVersion:26744,Generation:0,CreationTimestamp:2019-11-14 23:31:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 931abcd9-bfb2-4127-bedd-359d9dfa963d 0xc002207aa7 0xc002207aa8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nmsh2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nmsh2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-nmsh2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-tdyr52fdsot3-minion-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002207b10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002207b30}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:53 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:50 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.152,PodIP:,StartTime:2019-11-14 23:31:53 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 14 23:31:55.568: INFO: Pod "nginx-deployment-55fb7cb77f-8ncs7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-8ncs7,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-8799,SelfLink:/api/v1/namespaces/deployment-8799/pods/nginx-deployment-55fb7cb77f-8ncs7,UID:0ac02208-c6d4-4fbc-9eeb-5151f097c70b,ResourceVersion:26715,Generation:0,CreationTimestamp:2019-11-14 23:31:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 931abcd9-bfb2-4127-bedd-359d9dfa963d 0xc002207bf0 0xc002207bf1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nmsh2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nmsh2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-nmsh2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-tdyr52fdsot3-minion-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002207c60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002207c80}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:50 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 14 23:31:55.569: INFO: Pod "nginx-deployment-55fb7cb77f-9nb4k" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-9nb4k,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-8799,SelfLink:/api/v1/namespaces/deployment-8799/pods/nginx-deployment-55fb7cb77f-9nb4k,UID:98def89c-00f5-42a4-ac9b-2429a7e8016a,ResourceVersion:26713,Generation:0,CreationTimestamp:2019-11-14 23:31:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 931abcd9-bfb2-4127-bedd-359d9dfa963d 0xc002207cf0 0xc002207cf1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nmsh2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nmsh2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-nmsh2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-tdyr52fdsot3-minion-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002207d60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002207d80}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:50 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.126,PodIP:,StartTime:2019-11-14 23:31:51 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 14 23:31:55.569: INFO: Pod "nginx-deployment-55fb7cb77f-9zkjp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-9zkjp,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-8799,SelfLink:/api/v1/namespaces/deployment-8799/pods/nginx-deployment-55fb7cb77f-9zkjp,UID:733a4c87-b617-41fb-a2ad-c99c1e4ce335,ResourceVersion:26638,Generation:0,CreationTimestamp:2019-11-14 23:31:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 931abcd9-bfb2-4127-bedd-359d9dfa963d 0xc002207e40 0xc002207e41}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nmsh2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nmsh2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-nmsh2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-tdyr52fdsot3-minion-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002207eb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002207ed0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:44 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.152,PodIP:,StartTime:2019-11-14 23:31:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 14 23:31:55.570: INFO: Pod "nginx-deployment-55fb7cb77f-bmlnd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-bmlnd,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-8799,SelfLink:/api/v1/namespaces/deployment-8799/pods/nginx-deployment-55fb7cb77f-bmlnd,UID:74d2289a-0497-4590-8d58-a5a2a5e75210,ResourceVersion:26699,Generation:0,CreationTimestamp:2019-11-14 23:31:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 931abcd9-bfb2-4127-bedd-359d9dfa963d 0xc002207f90 0xc002207f91}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nmsh2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nmsh2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-nmsh2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-tdyr52fdsot3-minion-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001b08000} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001b08020}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:50 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 14 23:31:55.570: INFO: Pod "nginx-deployment-55fb7cb77f-d4ndz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-d4ndz,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-8799,SelfLink:/api/v1/namespaces/deployment-8799/pods/nginx-deployment-55fb7cb77f-d4ndz,UID:aee314de-71f1-42c2-accb-13d946f65055,ResourceVersion:26712,Generation:0,CreationTimestamp:2019-11-14 23:31:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 931abcd9-bfb2-4127-bedd-359d9dfa963d 0xc001b08090 0xc001b08091}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nmsh2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nmsh2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-nmsh2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-tdyr52fdsot3-minion-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001b08100} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001b08120}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:45 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.152,PodIP:,StartTime:2019-11-14 23:31:51 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 14 23:31:55.571: INFO: Pod "nginx-deployment-55fb7cb77f-dwfl8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-dwfl8,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-8799,SelfLink:/api/v1/namespaces/deployment-8799/pods/nginx-deployment-55fb7cb77f-dwfl8,UID:2781fab8-4f7d-40ed-bf52-52f674d1ec65,ResourceVersion:26742,Generation:0,CreationTimestamp:2019-11-14 23:31:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 931abcd9-bfb2-4127-bedd-359d9dfa963d 0xc001b081e0 0xc001b081e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nmsh2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nmsh2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-nmsh2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-tdyr52fdsot3-minion-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001b08250} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001b08270}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:52 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:50 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.126,PodIP:,StartTime:2019-11-14 23:31:52 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 14 23:31:55.571: INFO: Pod "nginx-deployment-55fb7cb77f-ffx2h" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-ffx2h,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-8799,SelfLink:/api/v1/namespaces/deployment-8799/pods/nginx-deployment-55fb7cb77f-ffx2h,UID:2b8a0870-a503-4356-b410-9b47a9312128,ResourceVersion:26729,Generation:0,CreationTimestamp:2019-11-14 23:31:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 931abcd9-bfb2-4127-bedd-359d9dfa963d 0xc001b08330 0xc001b08331}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nmsh2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nmsh2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-nmsh2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-tdyr52fdsot3-minion-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001b083a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001b083c0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:50 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.126,PodIP:,StartTime:2019-11-14 23:31:51 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 14 23:31:55.571: INFO: Pod "nginx-deployment-55fb7cb77f-hc9gm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-hc9gm,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-8799,SelfLink:/api/v1/namespaces/deployment-8799/pods/nginx-deployment-55fb7cb77f-hc9gm,UID:8aa6afbd-199e-4c56-b656-3750560065b8,ResourceVersion:26660,Generation:0,CreationTimestamp:2019-11-14 23:31:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 931abcd9-bfb2-4127-bedd-359d9dfa963d 0xc001b08480 0xc001b08481}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nmsh2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nmsh2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-nmsh2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-tdyr52fdsot3-minion-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001b084f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001b08510}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:48 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:45 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.126,PodIP:,StartTime:2019-11-14 23:31:48 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 14 23:31:55.572: INFO: Pod "nginx-deployment-55fb7cb77f-q285x" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-q285x,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-8799,SelfLink:/api/v1/namespaces/deployment-8799/pods/nginx-deployment-55fb7cb77f-q285x,UID:c96d2b76-ef09-4509-96bb-08d6b9532c05,ResourceVersion:26626,Generation:0,CreationTimestamp:2019-11-14 23:31:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 931abcd9-bfb2-4127-bedd-359d9dfa963d 0xc001b085d0 0xc001b085d1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nmsh2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nmsh2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-nmsh2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-tdyr52fdsot3-minion-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001b08640} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001b08660}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:44 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.152,PodIP:,StartTime:2019-11-14 23:31:44 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 14 23:31:55.572: INFO: Pod "nginx-deployment-55fb7cb77f-s9x6g" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-s9x6g,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-8799,SelfLink:/api/v1/namespaces/deployment-8799/pods/nginx-deployment-55fb7cb77f-s9x6g,UID:03558b23-a835-4270-9581-1cb9304d2f3c,ResourceVersion:26700,Generation:0,CreationTimestamp:2019-11-14 23:31:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 931abcd9-bfb2-4127-bedd-359d9dfa963d 0xc001b08720 0xc001b08721}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nmsh2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nmsh2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-nmsh2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-tdyr52fdsot3-minion-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001b08790} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001b087b0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:50 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 14 23:31:55.572: INFO: Pod "nginx-deployment-55fb7cb77f-sssml" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-sssml,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-8799,SelfLink:/api/v1/namespaces/deployment-8799/pods/nginx-deployment-55fb7cb77f-sssml,UID:69166418-7dfd-4681-b758-10650a7dc3bd,ResourceVersion:26629,Generation:0,CreationTimestamp:2019-11-14 23:31:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 931abcd9-bfb2-4127-bedd-359d9dfa963d 0xc001b08820 0xc001b08821}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nmsh2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nmsh2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-nmsh2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-tdyr52fdsot3-minion-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001b08890} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001b088b0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:44 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.126,PodIP:,StartTime:2019-11-14 23:31:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 14 23:31:55.573: INFO: Pod "nginx-deployment-55fb7cb77f-t4rzs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-t4rzs,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-8799,SelfLink:/api/v1/namespaces/deployment-8799/pods/nginx-deployment-55fb7cb77f-t4rzs,UID:aecd9621-7af3-4521-92a5-f660f39eb589,ResourceVersion:26698,Generation:0,CreationTimestamp:2019-11-14 23:31:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 931abcd9-bfb2-4127-bedd-359d9dfa963d 0xc001b08970 0xc001b08971}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nmsh2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nmsh2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-nmsh2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-tdyr52fdsot3-minion-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001b089e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001b08a00}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:50 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 14 23:31:55.573: INFO: Pod "nginx-deployment-7b8c6f4498-2pp56" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-2pp56,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-8799,SelfLink:/api/v1/namespaces/deployment-8799/pods/nginx-deployment-7b8c6f4498-2pp56,UID:dba6ef77-caef-499f-9d9d-9d52e1490694,ResourceVersion:26711,Generation:0,CreationTimestamp:2019-11-14 23:31:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 15f3dcaa-2f2f-47ab-824a-3d8001a6d5fc 0xc001b08a70 0xc001b08a71}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nmsh2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nmsh2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nmsh2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-tdyr52fdsot3-minion-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001b08ad0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001b08af0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:50 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 14 23:31:55.573: INFO: Pod "nginx-deployment-7b8c6f4498-5ssll" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-5ssll,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-8799,SelfLink:/api/v1/namespaces/deployment-8799/pods/nginx-deployment-7b8c6f4498-5ssll,UID:0ac09879-69f3-4fdd-9561-978fce34bd44,ResourceVersion:26578,Generation:0,CreationTimestamp:2019-11-14 23:31:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.2.113/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 15f3dcaa-2f2f-47ab-824a-3d8001a6d5fc 0xc001b08b70 0xc001b08b71}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nmsh2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nmsh2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nmsh2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-tdyr52fdsot3-minion-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001b08bd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001b08bf0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:20 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:40 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:40 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:17 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.152,PodIP:192.168.2.113,StartTime:2019-11-14 23:31:20 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-11-14 23:31:39 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/nginx:1.14-alpine docker-pullable://docker.io/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://9a03602c95902e37bd3ef4221ad86c1f9fbcc50b9ea3281ac186a46cb243f73e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 14 23:31:55.574: INFO: Pod "nginx-deployment-7b8c6f4498-7k7sp" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-7k7sp,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-8799,SelfLink:/api/v1/namespaces/deployment-8799/pods/nginx-deployment-7b8c6f4498-7k7sp,UID:23b316f9-d72c-40d5-a02e-dafe789b585b,ResourceVersion:26586,Generation:0,CreationTimestamp:2019-11-14 23:31:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.2.111/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 15f3dcaa-2f2f-47ab-824a-3d8001a6d5fc 0xc001b08cc0 0xc001b08cc1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nmsh2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nmsh2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nmsh2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-tdyr52fdsot3-minion-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001b08d20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001b08d40}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:17 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:40 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:40 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:17 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.152,PodIP:192.168.2.111,StartTime:2019-11-14 23:31:17 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-11-14 23:31:36 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/nginx:1.14-alpine docker-pullable://docker.io/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://b4e9f889eb0c0501cb584a37b7cf2608aab0b5a2732a0839a3a00d3bc55b9d6a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 14 23:31:55.574: INFO: Pod "nginx-deployment-7b8c6f4498-9t584" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-9t584,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-8799,SelfLink:/api/v1/namespaces/deployment-8799/pods/nginx-deployment-7b8c6f4498-9t584,UID:d6f08b77-cbb2-463a-b959-46bd14b6519f,ResourceVersion:26724,Generation:0,CreationTimestamp:2019-11-14 23:31:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 15f3dcaa-2f2f-47ab-824a-3d8001a6d5fc 0xc001b08e00 0xc001b08e01}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nmsh2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nmsh2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nmsh2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-tdyr52fdsot3-minion-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001b08e60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001b08e80}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:51 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 14 23:31:55.574: INFO: Pod "nginx-deployment-7b8c6f4498-bhhf7" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-bhhf7,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-8799,SelfLink:/api/v1/namespaces/deployment-8799/pods/nginx-deployment-7b8c6f4498-bhhf7,UID:cd0953d8-0174-48cd-9c04-bf0d4f3a6d2f,ResourceVersion:26554,Generation:0,CreationTimestamp:2019-11-14 23:31:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.118/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 15f3dcaa-2f2f-47ab-824a-3d8001a6d5fc 0xc001b08f00 0xc001b08f01}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nmsh2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nmsh2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nmsh2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-tdyr52fdsot3-minion-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001b08f60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001b08f80}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:18 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:37 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:37 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:17 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.126,PodIP:192.168.1.118,StartTime:2019-11-14 23:31:18 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-11-14 23:31:35 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/nginx:1.14-alpine docker-pullable://docker.io/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://946b5624bc3b6178a9bb42ee1cdb495467a8ad38e9f5c86c5b0400667db84521}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 14 23:31:55.575: INFO: Pod "nginx-deployment-7b8c6f4498-drfpl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-drfpl,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-8799,SelfLink:/api/v1/namespaces/deployment-8799/pods/nginx-deployment-7b8c6f4498-drfpl,UID:41c79b10-48b9-4b3f-920d-55c26ada9be8,ResourceVersion:26710,Generation:0,CreationTimestamp:2019-11-14 23:31:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 15f3dcaa-2f2f-47ab-824a-3d8001a6d5fc 0xc001b09040 0xc001b09041}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nmsh2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nmsh2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nmsh2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-tdyr52fdsot3-minion-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001b090a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001b090c0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:50 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 14 23:31:55.575: INFO: Pod "nginx-deployment-7b8c6f4498-ffmpt" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-ffmpt,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-8799,SelfLink:/api/v1/namespaces/deployment-8799/pods/nginx-deployment-7b8c6f4498-ffmpt,UID:2ddf9254-992b-43bb-b73d-2144eb802717,ResourceVersion:26582,Generation:0,CreationTimestamp:2019-11-14 23:31:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.2.112/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 15f3dcaa-2f2f-47ab-824a-3d8001a6d5fc 0xc001b09140 0xc001b09141}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nmsh2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nmsh2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nmsh2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-tdyr52fdsot3-minion-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001b091a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001b091c0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:18 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:40 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:40 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:17 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.152,PodIP:192.168.2.112,StartTime:2019-11-14 23:31:18 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-11-14 23:31:39 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/nginx:1.14-alpine docker-pullable://docker.io/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://1d2d3ddc7c5edb360de258c16a15770ac32cf3aeadcd276448415e5e72413541}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 14 23:31:55.575: INFO: Pod "nginx-deployment-7b8c6f4498-fnlk7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-fnlk7,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-8799,SelfLink:/api/v1/namespaces/deployment-8799/pods/nginx-deployment-7b8c6f4498-fnlk7,UID:ba6a435a-f425-48b4-a326-8b12b7859773,ResourceVersion:26709,Generation:0,CreationTimestamp:2019-11-14 23:31:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 15f3dcaa-2f2f-47ab-824a-3d8001a6d5fc 0xc001b09280 0xc001b09281}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nmsh2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nmsh2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nmsh2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-tdyr52fdsot3-minion-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001b092e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001b09300}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:50 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 14 23:31:55.576: INFO: Pod "nginx-deployment-7b8c6f4498-gtpfc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-gtpfc,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-8799,SelfLink:/api/v1/namespaces/deployment-8799/pods/nginx-deployment-7b8c6f4498-gtpfc,UID:6fe7590f-5df6-4911-bd46-5a13b13ff90f,ResourceVersion:26714,Generation:0,CreationTimestamp:2019-11-14 23:31:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 15f3dcaa-2f2f-47ab-824a-3d8001a6d5fc 0xc001b09370 0xc001b09371}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nmsh2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nmsh2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nmsh2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-tdyr52fdsot3-minion-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001b093d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001b093f0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:50 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 14 23:31:55.576: INFO: Pod "nginx-deployment-7b8c6f4498-hw58x" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-hw58x,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-8799,SelfLink:/api/v1/namespaces/deployment-8799/pods/nginx-deployment-7b8c6f4498-hw58x,UID:7d682d7e-408e-475e-84f5-fdefe7e945a2,ResourceVersion:26722,Generation:0,CreationTimestamp:2019-11-14 23:31:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 15f3dcaa-2f2f-47ab-824a-3d8001a6d5fc 0xc001b09460 0xc001b09461}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nmsh2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nmsh2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nmsh2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-tdyr52fdsot3-minion-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001b094c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001b094e0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:51 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 14 23:31:55.576: INFO: Pod "nginx-deployment-7b8c6f4498-kjzrf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-kjzrf,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-8799,SelfLink:/api/v1/namespaces/deployment-8799/pods/nginx-deployment-7b8c6f4498-kjzrf,UID:14c379e5-910a-4b42-8e9f-a7a525bf5f80,ResourceVersion:26725,Generation:0,CreationTimestamp:2019-11-14 23:31:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 15f3dcaa-2f2f-47ab-824a-3d8001a6d5fc 0xc001b09550 0xc001b09551}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nmsh2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nmsh2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nmsh2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-tdyr52fdsot3-minion-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001b095b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001b095d0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:51 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 14 23:31:56.364: INFO: Pod "nginx-deployment-7b8c6f4498-l8jkn" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-l8jkn,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-8799,SelfLink:/api/v1/namespaces/deployment-8799/pods/nginx-deployment-7b8c6f4498-l8jkn,UID:dfc66482-cebf-43f0-ab3b-1662b4582257,ResourceVersion:26563,Generation:0,CreationTimestamp:2019-11-14 23:31:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.121/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 15f3dcaa-2f2f-47ab-824a-3d8001a6d5fc 0xc001b09650 0xc001b09651}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nmsh2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nmsh2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nmsh2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-tdyr52fdsot3-minion-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001b096b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001b097a0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:21 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:38 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:38 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:17 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.126,PodIP:192.168.1.121,StartTime:2019-11-14 23:31:21 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-11-14 23:31:37 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/nginx:1.14-alpine docker-pullable://docker.io/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://b018f42ca07c344adcd943ca7eb3e72a47b53114fe26706ade50ac636beb5f7c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 14 23:31:56.365: INFO: Pod "nginx-deployment-7b8c6f4498-n95cf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-n95cf,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-8799,SelfLink:/api/v1/namespaces/deployment-8799/pods/nginx-deployment-7b8c6f4498-n95cf,UID:075a7249-89bc-4737-9fa5-d82a3f177ba8,ResourceVersion:26696,Generation:0,CreationTimestamp:2019-11-14 23:31:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 15f3dcaa-2f2f-47ab-824a-3d8001a6d5fc 0xc001b09a00 0xc001b09a01}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nmsh2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nmsh2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nmsh2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-tdyr52fdsot3-minion-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001b09d90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001b09db0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:50 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 14 23:31:56.366: INFO: Pod "nginx-deployment-7b8c6f4498-ngd2f" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-ngd2f,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-8799,SelfLink:/api/v1/namespaces/deployment-8799/pods/nginx-deployment-7b8c6f4498-ngd2f,UID:1498d42d-501f-4f9a-8033-eaa7659689cc,ResourceVersion:26694,Generation:0,CreationTimestamp:2019-11-14 23:31:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 15f3dcaa-2f2f-47ab-824a-3d8001a6d5fc 0xc001b09f20 0xc001b09f21}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nmsh2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nmsh2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nmsh2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-tdyr52fdsot3-minion-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001b09ff0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022a8010}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:50 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 14 23:31:56.367: INFO: Pod "nginx-deployment-7b8c6f4498-p2vlm" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-p2vlm,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-8799,SelfLink:/api/v1/namespaces/deployment-8799/pods/nginx-deployment-7b8c6f4498-p2vlm,UID:6e1f1293-864a-47c5-9fa0-1107be78a2be,ResourceVersion:26560,Generation:0,CreationTimestamp:2019-11-14 23:31:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.120/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 15f3dcaa-2f2f-47ab-824a-3d8001a6d5fc 0xc0022a8090 0xc0022a8091}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nmsh2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nmsh2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nmsh2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-tdyr52fdsot3-minion-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022a80f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022a8110}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:20 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:38 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:38 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:17 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.126,PodIP:192.168.1.120,StartTime:2019-11-14 23:31:20 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-11-14 23:31:37 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/nginx:1.14-alpine docker-pullable://docker.io/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://732039cb8c7c366f04ff334c015b405ecd8be11506ade82557d4eca1a4df0308}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 14 23:31:56.368: INFO: Pod "nginx-deployment-7b8c6f4498-pvj9p" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-pvj9p,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-8799,SelfLink:/api/v1/namespaces/deployment-8799/pods/nginx-deployment-7b8c6f4498-pvj9p,UID:043f24c9-439f-44c9-a3d3-901224469e2d,ResourceVersion:26723,Generation:0,CreationTimestamp:2019-11-14 23:31:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 15f3dcaa-2f2f-47ab-824a-3d8001a6d5fc 0xc0022a81d0 0xc0022a81d1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nmsh2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nmsh2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nmsh2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-tdyr52fdsot3-minion-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022a8230} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022a8250}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:51 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 14 23:31:56.369: INFO: Pod "nginx-deployment-7b8c6f4498-qcp9f" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-qcp9f,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-8799,SelfLink:/api/v1/namespaces/deployment-8799/pods/nginx-deployment-7b8c6f4498-qcp9f,UID:94b65a80-1b38-49f0-a086-4f134a8f28d6,ResourceVersion:26545,Generation:0,CreationTimestamp:2019-11-14 23:31:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.119/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 15f3dcaa-2f2f-47ab-824a-3d8001a6d5fc 0xc0022a82d0 0xc0022a82d1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nmsh2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nmsh2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nmsh2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-tdyr52fdsot3-minion-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022a8330} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022a8350}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:21 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:37 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:37 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:17 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.126,PodIP:192.168.1.119,StartTime:2019-11-14 23:31:21 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-11-14 23:31:36 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/nginx:1.14-alpine docker-pullable://docker.io/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://2f252e00f3765a3e9ab6c5f3ed186a140e418e63440c021aac6821c7b27ea146}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 14 23:31:56.370: INFO: Pod "nginx-deployment-7b8c6f4498-qhwg9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-qhwg9,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-8799,SelfLink:/api/v1/namespaces/deployment-8799/pods/nginx-deployment-7b8c6f4498-qhwg9,UID:2e816c6f-de2f-4a85-9cec-d52db8d1c43e,ResourceVersion:26726,Generation:0,CreationTimestamp:2019-11-14 23:31:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 15f3dcaa-2f2f-47ab-824a-3d8001a6d5fc 0xc0022a8410 0xc0022a8411}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nmsh2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nmsh2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nmsh2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-tdyr52fdsot3-minion-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022a8470} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022a8490}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:51 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 14 23:31:56.370: INFO: Pod "nginx-deployment-7b8c6f4498-stvgg" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-stvgg,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-8799,SelfLink:/api/v1/namespaces/deployment-8799/pods/nginx-deployment-7b8c6f4498-stvgg,UID:8e689e17-2387-4b00-94b0-5113de667c44,ResourceVersion:26550,Generation:0,CreationTimestamp:2019-11-14 23:31:17 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.117/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 15f3dcaa-2f2f-47ab-824a-3d8001a6d5fc 0xc0022a8510 0xc0022a8511}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nmsh2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nmsh2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nmsh2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-tdyr52fdsot3-minion-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022a8570} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022a8590}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:18 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:37 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:37 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:17 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.126,PodIP:192.168.1.117,StartTime:2019-11-14 23:31:18 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-11-14 23:31:32 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/nginx:1.14-alpine docker-pullable://docker.io/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://10e6e111480ac056ba17eb491982b3748017765fd6760c460c794a64dd98b724}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 14 23:31:56.371: INFO: Pod "nginx-deployment-7b8c6f4498-zgxz8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-zgxz8,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-8799,SelfLink:/api/v1/namespaces/deployment-8799/pods/nginx-deployment-7b8c6f4498-zgxz8,UID:d1953a64-b2d0-43d1-8f61-21bb225749bc,ResourceVersion:26730,Generation:0,CreationTimestamp:2019-11-14 23:31:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 15f3dcaa-2f2f-47ab-824a-3d8001a6d5fc 0xc0022a8650 0xc0022a8651}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nmsh2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nmsh2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-nmsh2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-tdyr52fdsot3-minion-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022a86b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022a86d0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:51 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:31:50 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.152,PodIP:,StartTime:2019-11-14 23:31:51 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:31:56.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8799" for this suite.
Nov 14 23:32:41.245: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:32:41.417: INFO: namespace deployment-8799 deletion completed in 44.869018778s

• [SLOW TEST:84.337 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:32:41.425: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3706
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Nov 14 23:32:42.980: INFO: Waiting up to 5m0s for pod "downward-api-83630e75-9ac7-4662-b856-e2d1f655599f" in namespace "downward-api-3706" to be "success or failure"
Nov 14 23:32:43.068: INFO: Pod "downward-api-83630e75-9ac7-4662-b856-e2d1f655599f": Phase="Pending", Reason="", readiness=false. Elapsed: 88.137089ms
Nov 14 23:32:45.354: INFO: Pod "downward-api-83630e75-9ac7-4662-b856-e2d1f655599f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.37415559s
Nov 14 23:32:47.360: INFO: Pod "downward-api-83630e75-9ac7-4662-b856-e2d1f655599f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.38081153s
Nov 14 23:32:49.363: INFO: Pod "downward-api-83630e75-9ac7-4662-b856-e2d1f655599f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.383479449s
Nov 14 23:32:51.403: INFO: Pod "downward-api-83630e75-9ac7-4662-b856-e2d1f655599f": Phase="Pending", Reason="", readiness=false. Elapsed: 8.423715428s
Nov 14 23:32:53.421: INFO: Pod "downward-api-83630e75-9ac7-4662-b856-e2d1f655599f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.441402395s
Nov 14 23:32:55.691: INFO: Pod "downward-api-83630e75-9ac7-4662-b856-e2d1f655599f": Phase="Pending", Reason="", readiness=false. Elapsed: 12.711529784s
Nov 14 23:32:57.907: INFO: Pod "downward-api-83630e75-9ac7-4662-b856-e2d1f655599f": Phase="Pending", Reason="", readiness=false. Elapsed: 14.926883087s
Nov 14 23:32:59.919: INFO: Pod "downward-api-83630e75-9ac7-4662-b856-e2d1f655599f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 16.939084985s
STEP: Saw pod success
Nov 14 23:32:59.919: INFO: Pod "downward-api-83630e75-9ac7-4662-b856-e2d1f655599f" satisfied condition "success or failure"
Nov 14 23:33:00.302: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-0 pod downward-api-83630e75-9ac7-4662-b856-e2d1f655599f container dapi-container: <nil>
STEP: delete the pod
Nov 14 23:33:01.697: INFO: Waiting for pod downward-api-83630e75-9ac7-4662-b856-e2d1f655599f to disappear
Nov 14 23:33:01.702: INFO: Pod downward-api-83630e75-9ac7-4662-b856-e2d1f655599f no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:33:01.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3706" for this suite.
Nov 14 23:33:09.959: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:33:10.842: INFO: namespace downward-api-3706 deletion completed in 9.134952277s

• [SLOW TEST:29.417 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:33:11.087: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-487
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-491bfe09-2e2f-4102-beb4-810bff56035d
STEP: Creating a pod to test consume configMaps
Nov 14 23:33:13.058: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b49a22b4-c34f-41a4-8cfb-257c821b7d82" in namespace "projected-487" to be "success or failure"
Nov 14 23:33:13.328: INFO: Pod "pod-projected-configmaps-b49a22b4-c34f-41a4-8cfb-257c821b7d82": Phase="Pending", Reason="", readiness=false. Elapsed: 269.432081ms
Nov 14 23:33:15.333: INFO: Pod "pod-projected-configmaps-b49a22b4-c34f-41a4-8cfb-257c821b7d82": Phase="Pending", Reason="", readiness=false. Elapsed: 2.274978822s
Nov 14 23:33:17.337: INFO: Pod "pod-projected-configmaps-b49a22b4-c34f-41a4-8cfb-257c821b7d82": Phase="Pending", Reason="", readiness=false. Elapsed: 4.278778761s
Nov 14 23:33:19.381: INFO: Pod "pod-projected-configmaps-b49a22b4-c34f-41a4-8cfb-257c821b7d82": Phase="Pending", Reason="", readiness=false. Elapsed: 6.322750654s
Nov 14 23:33:21.386: INFO: Pod "pod-projected-configmaps-b49a22b4-c34f-41a4-8cfb-257c821b7d82": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.327966585s
STEP: Saw pod success
Nov 14 23:33:21.388: INFO: Pod "pod-projected-configmaps-b49a22b4-c34f-41a4-8cfb-257c821b7d82" satisfied condition "success or failure"
Nov 14 23:33:21.392: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-1 pod pod-projected-configmaps-b49a22b4-c34f-41a4-8cfb-257c821b7d82 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov 14 23:33:21.576: INFO: Waiting for pod pod-projected-configmaps-b49a22b4-c34f-41a4-8cfb-257c821b7d82 to disappear
Nov 14 23:33:21.621: INFO: Pod pod-projected-configmaps-b49a22b4-c34f-41a4-8cfb-257c821b7d82 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:33:21.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-487" for this suite.
Nov 14 23:33:27.669: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:33:27.852: INFO: namespace projected-487 deletion completed in 6.22678847s

• [SLOW TEST:16.766 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:33:27.858: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-8303
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod busybox-c765d5c5-9680-4138-9d0a-32d0e0a5cd3d in namespace container-probe-8303
Nov 14 23:33:33.055: INFO: Started pod busybox-c765d5c5-9680-4138-9d0a-32d0e0a5cd3d in namespace container-probe-8303
STEP: checking the pod's current state and verifying that restartCount is present
Nov 14 23:33:33.140: INFO: Initial restart count of pod busybox-c765d5c5-9680-4138-9d0a-32d0e0a5cd3d is 0
Nov 14 23:34:21.623: INFO: Restart count of pod container-probe-8303/busybox-c765d5c5-9680-4138-9d0a-32d0e0a5cd3d is now 1 (48.482231259s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:34:21.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8303" for this suite.
Nov 14 23:34:27.880: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:34:28.145: INFO: namespace container-probe-8303 deletion completed in 6.370777665s

• [SLOW TEST:60.287 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:34:28.155: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-6051
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override command
Nov 14 23:34:28.572: INFO: Waiting up to 5m0s for pod "client-containers-4873dc6f-055c-41a3-8e84-bd1f8e5cd312" in namespace "containers-6051" to be "success or failure"
Nov 14 23:34:28.768: INFO: Pod "client-containers-4873dc6f-055c-41a3-8e84-bd1f8e5cd312": Phase="Pending", Reason="", readiness=false. Elapsed: 195.619165ms
Nov 14 23:34:30.775: INFO: Pod "client-containers-4873dc6f-055c-41a3-8e84-bd1f8e5cd312": Phase="Pending", Reason="", readiness=false. Elapsed: 2.201882645s
Nov 14 23:34:32.781: INFO: Pod "client-containers-4873dc6f-055c-41a3-8e84-bd1f8e5cd312": Phase="Pending", Reason="", readiness=false. Elapsed: 4.208842058s
Nov 14 23:34:34.786: INFO: Pod "client-containers-4873dc6f-055c-41a3-8e84-bd1f8e5cd312": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.213745919s
STEP: Saw pod success
Nov 14 23:34:34.787: INFO: Pod "client-containers-4873dc6f-055c-41a3-8e84-bd1f8e5cd312" satisfied condition "success or failure"
Nov 14 23:34:34.789: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-1 pod client-containers-4873dc6f-055c-41a3-8e84-bd1f8e5cd312 container test-container: <nil>
STEP: delete the pod
Nov 14 23:34:34.848: INFO: Waiting for pod client-containers-4873dc6f-055c-41a3-8e84-bd1f8e5cd312 to disappear
Nov 14 23:34:34.871: INFO: Pod client-containers-4873dc6f-055c-41a3-8e84-bd1f8e5cd312 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:34:34.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-6051" for this suite.
Nov 14 23:34:40.966: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:34:41.079: INFO: namespace containers-6051 deletion completed in 6.150303286s

• [SLOW TEST:12.924 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:34:41.081: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5479
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name s-test-opt-del-d0d12ffb-3197-4141-9abd-3dd3a1af7ecd
STEP: Creating secret with name s-test-opt-upd-d235d7eb-0487-4b19-9abe-c1bb37b2edcf
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-d0d12ffb-3197-4141-9abd-3dd3a1af7ecd
STEP: Updating secret s-test-opt-upd-d235d7eb-0487-4b19-9abe-c1bb37b2edcf
STEP: Creating secret with name s-test-opt-create-fe0f3aa6-2820-4804-9660-b1a24327aab6
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:34:50.326: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5479" for this suite.
Nov 14 23:35:14.360: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:35:14.529: INFO: namespace projected-5479 deletion completed in 24.199925985s

• [SLOW TEST:33.448 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:35:14.534: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-8771
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Nov 14 23:35:15.029: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Nov 14 23:35:15.348: INFO: Pod name sample-pod: Found 0 pods out of 1
Nov 14 23:35:20.353: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Nov 14 23:35:20.355: INFO: Creating deployment "test-rolling-update-deployment"
Nov 14 23:35:20.360: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Nov 14 23:35:20.416: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Nov 14 23:35:22.557: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Nov 14 23:35:22.561: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709371319, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709371319, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709371320, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709371319, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-79f6b9d75c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 14 23:35:24.681: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709371319, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709371319, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709371320, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709371319, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-79f6b9d75c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 14 23:35:26.568: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Nov 14 23:35:26.582: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-8771,SelfLink:/apis/apps/v1/namespaces/deployment-8771/deployments/test-rolling-update-deployment,UID:d4b77860-8126-4aa8-9b7c-1fa89257ff0d,ResourceVersion:27539,Generation:1,CreationTimestamp:2019-11-14 23:35:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-11-14 23:35:19 +0000 UTC 2019-11-14 23:35:19 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-11-14 23:35:24 +0000 UTC 2019-11-14 23:35:19 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-79f6b9d75c" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Nov 14 23:35:26.585: INFO: New ReplicaSet "test-rolling-update-deployment-79f6b9d75c" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79f6b9d75c,GenerateName:,Namespace:deployment-8771,SelfLink:/apis/apps/v1/namespaces/deployment-8771/replicasets/test-rolling-update-deployment-79f6b9d75c,UID:88832b61-8772-421f-804d-84d2f0e16fe2,ResourceVersion:27528,Generation:1,CreationTimestamp:2019-11-14 23:35:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment d4b77860-8126-4aa8-9b7c-1fa89257ff0d 0xc0032a5737 0xc0032a5738}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Nov 14 23:35:26.586: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Nov 14 23:35:26.586: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-8771,SelfLink:/apis/apps/v1/namespaces/deployment-8771/replicasets/test-rolling-update-controller,UID:3945241c-5f0c-4a69-81b4-30abea889d8f,ResourceVersion:27538,Generation:2,CreationTimestamp:2019-11-14 23:35:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment d4b77860-8126-4aa8-9b7c-1fa89257ff0d 0xc0032a5557 0xc0032a5558}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Nov 14 23:35:26.590: INFO: Pod "test-rolling-update-deployment-79f6b9d75c-jvcxw" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79f6b9d75c-jvcxw,GenerateName:test-rolling-update-deployment-79f6b9d75c-,Namespace:deployment-8771,SelfLink:/api/v1/namespaces/deployment-8771/pods/test-rolling-update-deployment-79f6b9d75c-jvcxw,UID:d7eabdb1-fec5-4220-aa13-b8c7bce66803,ResourceVersion:27527,Generation:0,CreationTimestamp:2019-11-14 23:35:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.127/32,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-79f6b9d75c 88832b61-8772-421f-804d-84d2f0e16fe2 0xc003312567 0xc003312568}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pwq5r {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pwq5r,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-pwq5r true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-tdyr52fdsot3-minion-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0033125d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0033125f0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:35:20 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:35:24 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:35:24 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:35:19 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.126,PodIP:192.168.1.127,StartTime:2019-11-14 23:35:20 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-11-14 23:35:23 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://ed742b77bf53c93a1205f473e8401c4810ed7e5bb17da753a72f6566435f6b28}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:35:26.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8771" for this suite.
Nov 14 23:35:36.736: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:35:36.868: INFO: namespace deployment-8771 deletion completed in 10.272261495s

• [SLOW TEST:22.335 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:35:36.870: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8498
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Nov 14 23:35:37.496: INFO: Waiting up to 5m0s for pod "downward-api-63057246-8214-4c70-ae51-e0a4e9a70011" in namespace "downward-api-8498" to be "success or failure"
Nov 14 23:35:37.533: INFO: Pod "downward-api-63057246-8214-4c70-ae51-e0a4e9a70011": Phase="Pending", Reason="", readiness=false. Elapsed: 36.952053ms
Nov 14 23:35:39.540: INFO: Pod "downward-api-63057246-8214-4c70-ae51-e0a4e9a70011": Phase="Pending", Reason="", readiness=false. Elapsed: 2.043670341s
Nov 14 23:35:41.649: INFO: Pod "downward-api-63057246-8214-4c70-ae51-e0a4e9a70011": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.152931195s
STEP: Saw pod success
Nov 14 23:35:41.649: INFO: Pod "downward-api-63057246-8214-4c70-ae51-e0a4e9a70011" satisfied condition "success or failure"
Nov 14 23:35:41.652: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-1 pod downward-api-63057246-8214-4c70-ae51-e0a4e9a70011 container dapi-container: <nil>
STEP: delete the pod
Nov 14 23:35:41.924: INFO: Waiting for pod downward-api-63057246-8214-4c70-ae51-e0a4e9a70011 to disappear
Nov 14 23:35:41.928: INFO: Pod downward-api-63057246-8214-4c70-ae51-e0a4e9a70011 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:35:41.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8498" for this suite.
Nov 14 23:35:48.221: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:35:48.722: INFO: namespace downward-api-8498 deletion completed in 6.790630668s

• [SLOW TEST:11.853 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:35:48.733: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-kubelet-etc-hosts-9320
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Nov 14 23:36:02.192: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9320 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 14 23:36:02.192: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
Nov 14 23:36:02.412: INFO: Exec stderr: ""
Nov 14 23:36:02.412: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9320 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 14 23:36:02.412: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
Nov 14 23:36:02.570: INFO: Exec stderr: ""
Nov 14 23:36:02.570: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9320 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 14 23:36:02.570: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
Nov 14 23:36:02.771: INFO: Exec stderr: ""
Nov 14 23:36:02.771: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9320 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 14 23:36:02.771: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
Nov 14 23:36:02.923: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Nov 14 23:36:02.923: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9320 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 14 23:36:02.923: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
Nov 14 23:36:03.060: INFO: Exec stderr: ""
Nov 14 23:36:03.060: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9320 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 14 23:36:03.060: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
Nov 14 23:36:03.194: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Nov 14 23:36:03.194: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9320 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 14 23:36:03.195: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
Nov 14 23:36:03.338: INFO: Exec stderr: ""
Nov 14 23:36:03.338: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9320 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 14 23:36:03.338: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
Nov 14 23:36:03.520: INFO: Exec stderr: ""
Nov 14 23:36:03.520: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-9320 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 14 23:36:03.520: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
Nov 14 23:36:03.656: INFO: Exec stderr: ""
Nov 14 23:36:03.656: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-9320 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 14 23:36:03.656: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
Nov 14 23:36:03.978: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:36:03.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-9320" for this suite.
Nov 14 23:36:56.155: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:36:56.314: INFO: namespace e2e-kubelet-etc-hosts-9320 deletion completed in 52.257809072s

• [SLOW TEST:67.582 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:36:56.324: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-1382
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Nov 14 23:36:56.891: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Nov 14 23:37:01.896: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Nov 14 23:37:01.896: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Nov 14 23:37:02.053: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-1382,SelfLink:/apis/apps/v1/namespaces/deployment-1382/deployments/test-cleanup-deployment,UID:74c8dca1-5e22-4ee0-ab8f-a2b23bbbb1ce,ResourceVersion:27864,Generation:1,CreationTimestamp:2019-11-14 23:37:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Nov 14 23:37:02.227: INFO: New ReplicaSet "test-cleanup-deployment-55bbcbc84c" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55bbcbc84c,GenerateName:,Namespace:deployment-1382,SelfLink:/apis/apps/v1/namespaces/deployment-1382/replicasets/test-cleanup-deployment-55bbcbc84c,UID:17e102c8-f92d-412b-b213-948b1d1cf62f,ResourceVersion:27866,Generation:1,CreationTimestamp:2019-11-14 23:37:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 74c8dca1-5e22-4ee0-ab8f-a2b23bbbb1ce 0xc003a0f237 0xc003a0f238}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Nov 14 23:37:02.227: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Nov 14 23:37:02.228: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:deployment-1382,SelfLink:/apis/apps/v1/namespaces/deployment-1382/replicasets/test-cleanup-controller,UID:24366dd2-a050-419d-8264-bd4a5e570dfc,ResourceVersion:27865,Generation:1,CreationTimestamp:2019-11-14 23:36:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 74c8dca1-5e22-4ee0-ab8f-a2b23bbbb1ce 0xc003a0f167 0xc003a0f168}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Nov 14 23:37:02.457: INFO: Pod "test-cleanup-controller-cl52m" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-cl52m,GenerateName:test-cleanup-controller-,Namespace:deployment-1382,SelfLink:/api/v1/namespaces/deployment-1382/pods/test-cleanup-controller-cl52m,UID:b3027be3-e130-467f-8be0-5369ba3aacdc,ResourceVersion:27857,Generation:0,CreationTimestamp:2019-11-14 23:36:56 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.128/32,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller 24366dd2-a050-419d-8264-bd4a5e570dfc 0xc003a0fc07 0xc003a0fc08}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-st8p2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-st8p2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-st8p2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-tdyr52fdsot3-minion-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003a0fc70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003a0fc90}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:36:57 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:36:59 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:36:59 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:36:56 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.126,PodIP:192.168.1.128,StartTime:2019-11-14 23:36:57 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-11-14 23:36:59 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/nginx:1.14-alpine docker-pullable://docker.io/nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://b10d836e81c722662591800321b4912cdc2902ceb3edf5324d2b1c1be4dc3c44}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 14 23:37:02.457: INFO: Pod "test-cleanup-deployment-55bbcbc84c-h5w4t" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55bbcbc84c-h5w4t,GenerateName:test-cleanup-deployment-55bbcbc84c-,Namespace:deployment-1382,SelfLink:/api/v1/namespaces/deployment-1382/pods/test-cleanup-deployment-55bbcbc84c-h5w4t,UID:751b2b80-b009-484f-a952-d5408653a911,ResourceVersion:27870,Generation:0,CreationTimestamp:2019-11-14 23:37:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-55bbcbc84c 17e102c8-f92d-412b-b213-948b1d1cf62f 0xc003a0fd57 0xc003a0fd58}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-st8p2 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-st8p2,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-st8p2 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-tdyr52fdsot3-minion-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003a0fdc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003a0fde0}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:37:01 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:37:02.457: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1382" for this suite.
Nov 14 23:37:10.797: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:37:10.923: INFO: namespace deployment-1382 deletion completed in 8.403163773s

• [SLOW TEST:14.600 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:37:10.930: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-894
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-2b4b01d7-3607-4159-8b77-5d4be01b43be
STEP: Creating a pod to test consume configMaps
Nov 14 23:37:11.696: INFO: Waiting up to 5m0s for pod "pod-configmaps-5b0bd272-7195-4f2a-9910-494008ab9ac1" in namespace "configmap-894" to be "success or failure"
Nov 14 23:37:11.723: INFO: Pod "pod-configmaps-5b0bd272-7195-4f2a-9910-494008ab9ac1": Phase="Pending", Reason="", readiness=false. Elapsed: 26.66652ms
Nov 14 23:37:13.852: INFO: Pod "pod-configmaps-5b0bd272-7195-4f2a-9910-494008ab9ac1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.15538806s
Nov 14 23:37:15.998: INFO: Pod "pod-configmaps-5b0bd272-7195-4f2a-9910-494008ab9ac1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.301728757s
STEP: Saw pod success
Nov 14 23:37:15.998: INFO: Pod "pod-configmaps-5b0bd272-7195-4f2a-9910-494008ab9ac1" satisfied condition "success or failure"
Nov 14 23:37:16.049: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-1 pod pod-configmaps-5b0bd272-7195-4f2a-9910-494008ab9ac1 container configmap-volume-test: <nil>
STEP: delete the pod
Nov 14 23:37:16.204: INFO: Waiting for pod pod-configmaps-5b0bd272-7195-4f2a-9910-494008ab9ac1 to disappear
Nov 14 23:37:16.256: INFO: Pod pod-configmaps-5b0bd272-7195-4f2a-9910-494008ab9ac1 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:37:16.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-894" for this suite.
Nov 14 23:37:22.369: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:37:22.510: INFO: namespace configmap-894 deletion completed in 6.248568606s

• [SLOW TEST:11.580 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:37:22.515: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-603
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating Redis RC
Nov 14 23:37:23.071: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 create -f - --namespace=kubectl-603'
Nov 14 23:37:27.497: INFO: stderr: ""
Nov 14 23:37:27.497: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Nov 14 23:37:28.785: INFO: Selector matched 1 pods for map[app:redis]
Nov 14 23:37:28.785: INFO: Found 0 / 1
Nov 14 23:37:29.895: INFO: Selector matched 1 pods for map[app:redis]
Nov 14 23:37:29.895: INFO: Found 0 / 1
Nov 14 23:37:30.704: INFO: Selector matched 1 pods for map[app:redis]
Nov 14 23:37:30.704: INFO: Found 0 / 1
Nov 14 23:37:31.782: INFO: Selector matched 1 pods for map[app:redis]
Nov 14 23:37:31.782: INFO: Found 1 / 1
Nov 14 23:37:31.782: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Nov 14 23:37:32.121: INFO: Selector matched 1 pods for map[app:redis]
Nov 14 23:37:32.122: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Nov 14 23:37:32.122: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 patch pod redis-master-xg48l --namespace=kubectl-603 -p {"metadata":{"annotations":{"x":"y"}}}'
Nov 14 23:37:32.350: INFO: stderr: ""
Nov 14 23:37:32.350: INFO: stdout: "pod/redis-master-xg48l patched\n"
STEP: checking annotations
Nov 14 23:37:32.393: INFO: Selector matched 1 pods for map[app:redis]
Nov 14 23:37:32.393: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:37:32.393: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-603" for this suite.
Nov 14 23:37:56.506: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:37:56.655: INFO: namespace kubectl-603 deletion completed in 24.25601308s

• [SLOW TEST:34.141 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl patch
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:37:56.659: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6683
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-map-354bde4c-fec2-4571-80ac-9a1dc00fd984
STEP: Creating a pod to test consume secrets
Nov 14 23:37:57.075: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ab133521-d2e1-4075-bc13-260ced4e0459" in namespace "projected-6683" to be "success or failure"
Nov 14 23:37:57.098: INFO: Pod "pod-projected-secrets-ab133521-d2e1-4075-bc13-260ced4e0459": Phase="Pending", Reason="", readiness=false. Elapsed: 23.006576ms
Nov 14 23:37:59.103: INFO: Pod "pod-projected-secrets-ab133521-d2e1-4075-bc13-260ced4e0459": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027647677s
Nov 14 23:38:01.108: INFO: Pod "pod-projected-secrets-ab133521-d2e1-4075-bc13-260ced4e0459": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032814006s
STEP: Saw pod success
Nov 14 23:38:01.108: INFO: Pod "pod-projected-secrets-ab133521-d2e1-4075-bc13-260ced4e0459" satisfied condition "success or failure"
Nov 14 23:38:01.112: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-0 pod pod-projected-secrets-ab133521-d2e1-4075-bc13-260ced4e0459 container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov 14 23:38:01.182: INFO: Waiting for pod pod-projected-secrets-ab133521-d2e1-4075-bc13-260ced4e0459 to disappear
Nov 14 23:38:01.212: INFO: Pod pod-projected-secrets-ab133521-d2e1-4075-bc13-260ced4e0459 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:38:01.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6683" for this suite.
Nov 14 23:38:07.507: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:38:07.752: INFO: namespace projected-6683 deletion completed in 6.457688982s

• [SLOW TEST:11.094 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:38:07.759: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5061
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1292
STEP: creating an rc
Nov 14 23:38:08.276: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 create -f - --namespace=kubectl-5061'
Nov 14 23:38:08.662: INFO: stderr: ""
Nov 14 23:38:08.662: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Waiting for Redis master to start.
Nov 14 23:38:09.835: INFO: Selector matched 1 pods for map[app:redis]
Nov 14 23:38:09.835: INFO: Found 0 / 1
Nov 14 23:38:10.827: INFO: Selector matched 1 pods for map[app:redis]
Nov 14 23:38:10.827: INFO: Found 0 / 1
Nov 14 23:38:11.668: INFO: Selector matched 1 pods for map[app:redis]
Nov 14 23:38:11.668: INFO: Found 0 / 1
Nov 14 23:38:12.680: INFO: Selector matched 1 pods for map[app:redis]
Nov 14 23:38:12.680: INFO: Found 0 / 1
Nov 14 23:38:13.806: INFO: Selector matched 1 pods for map[app:redis]
Nov 14 23:38:13.806: INFO: Found 0 / 1
Nov 14 23:38:14.668: INFO: Selector matched 1 pods for map[app:redis]
Nov 14 23:38:14.668: INFO: Found 1 / 1
Nov 14 23:38:14.668: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Nov 14 23:38:14.671: INFO: Selector matched 1 pods for map[app:redis]
Nov 14 23:38:14.672: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Nov 14 23:38:14.672: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 logs redis-master-24whj redis-master --namespace=kubectl-5061'
Nov 14 23:38:14.801: INFO: stderr: ""
Nov 14 23:38:14.801: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 14 Nov 23:38:13.027 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 14 Nov 23:38:13.027 # Server started, Redis version 3.2.12\n1:M 14 Nov 23:38:13.028 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 14 Nov 23:38:13.028 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Nov 14 23:38:14.802: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 logs redis-master-24whj redis-master --namespace=kubectl-5061 --tail=1'
Nov 14 23:38:14.973: INFO: stderr: ""
Nov 14 23:38:14.973: INFO: stdout: "1:M 14 Nov 23:38:13.028 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Nov 14 23:38:14.973: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 logs redis-master-24whj redis-master --namespace=kubectl-5061 --limit-bytes=1'
Nov 14 23:38:15.173: INFO: stderr: ""
Nov 14 23:38:15.173: INFO: stdout: " "
STEP: exposing timestamps
Nov 14 23:38:15.174: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 logs redis-master-24whj redis-master --namespace=kubectl-5061 --tail=1 --timestamps'
Nov 14 23:38:15.303: INFO: stderr: ""
Nov 14 23:38:15.304: INFO: stdout: "2019-11-14T23:38:13.028600187Z 1:M 14 Nov 23:38:13.028 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Nov 14 23:38:17.804: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 logs redis-master-24whj redis-master --namespace=kubectl-5061 --since=1s'
Nov 14 23:38:17.928: INFO: stderr: ""
Nov 14 23:38:17.928: INFO: stdout: ""
Nov 14 23:38:17.928: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 logs redis-master-24whj redis-master --namespace=kubectl-5061 --since=24h'
Nov 14 23:38:18.211: INFO: stderr: ""
Nov 14 23:38:18.212: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 14 Nov 23:38:13.027 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 14 Nov 23:38:13.027 # Server started, Redis version 3.2.12\n1:M 14 Nov 23:38:13.028 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 14 Nov 23:38:13.028 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
STEP: using delete to clean up resources
Nov 14 23:38:18.212: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 delete --grace-period=0 --force -f - --namespace=kubectl-5061'
Nov 14 23:38:18.470: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 14 23:38:18.470: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Nov 14 23:38:18.470: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 get rc,svc -l name=nginx --no-headers --namespace=kubectl-5061'
Nov 14 23:38:18.596: INFO: stderr: "No resources found.\n"
Nov 14 23:38:18.596: INFO: stdout: ""
Nov 14 23:38:18.596: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 get pods -l name=nginx --namespace=kubectl-5061 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov 14 23:38:18.712: INFO: stderr: ""
Nov 14 23:38:18.712: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:38:18.712: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5061" for this suite.
Nov 14 23:38:24.891: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:38:25.216: INFO: namespace kubectl-5061 deletion completed in 6.499091287s

• [SLOW TEST:17.458 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl logs
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:38:25.225: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-9670
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:38:30.834: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-9670" for this suite.
Nov 14 23:38:37.097: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:38:37.251: INFO: namespace emptydir-wrapper-9670 deletion completed in 6.39780547s

• [SLOW TEST:12.027 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:38:37.258: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-2216
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Nov 14 23:38:38.120: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Nov 14 23:38:38.318: INFO: Number of nodes with available pods: 0
Nov 14 23:38:38.319: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Nov 14 23:38:38.400: INFO: Number of nodes with available pods: 0
Nov 14 23:38:38.400: INFO: Node k8s-1-tdyr52fdsot3-minion-0 is running more than one daemon pod
Nov 14 23:38:39.425: INFO: Number of nodes with available pods: 0
Nov 14 23:38:39.425: INFO: Node k8s-1-tdyr52fdsot3-minion-0 is running more than one daemon pod
Nov 14 23:38:40.428: INFO: Number of nodes with available pods: 0
Nov 14 23:38:40.428: INFO: Node k8s-1-tdyr52fdsot3-minion-0 is running more than one daemon pod
Nov 14 23:38:41.425: INFO: Number of nodes with available pods: 0
Nov 14 23:38:41.425: INFO: Node k8s-1-tdyr52fdsot3-minion-0 is running more than one daemon pod
Nov 14 23:38:42.480: INFO: Number of nodes with available pods: 1
Nov 14 23:38:42.480: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Nov 14 23:38:42.677: INFO: Number of nodes with available pods: 1
Nov 14 23:38:42.677: INFO: Number of running nodes: 0, number of available pods: 1
Nov 14 23:38:43.685: INFO: Number of nodes with available pods: 0
Nov 14 23:38:43.686: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Nov 14 23:38:44.094: INFO: Number of nodes with available pods: 0
Nov 14 23:38:44.095: INFO: Node k8s-1-tdyr52fdsot3-minion-0 is running more than one daemon pod
Nov 14 23:38:45.248: INFO: Number of nodes with available pods: 0
Nov 14 23:38:45.249: INFO: Node k8s-1-tdyr52fdsot3-minion-0 is running more than one daemon pod
Nov 14 23:38:46.101: INFO: Number of nodes with available pods: 0
Nov 14 23:38:46.101: INFO: Node k8s-1-tdyr52fdsot3-minion-0 is running more than one daemon pod
Nov 14 23:38:47.100: INFO: Number of nodes with available pods: 0
Nov 14 23:38:47.100: INFO: Node k8s-1-tdyr52fdsot3-minion-0 is running more than one daemon pod
Nov 14 23:38:48.100: INFO: Number of nodes with available pods: 0
Nov 14 23:38:48.101: INFO: Node k8s-1-tdyr52fdsot3-minion-0 is running more than one daemon pod
Nov 14 23:38:49.203: INFO: Number of nodes with available pods: 0
Nov 14 23:38:49.204: INFO: Node k8s-1-tdyr52fdsot3-minion-0 is running more than one daemon pod
Nov 14 23:38:50.101: INFO: Number of nodes with available pods: 0
Nov 14 23:38:50.101: INFO: Node k8s-1-tdyr52fdsot3-minion-0 is running more than one daemon pod
Nov 14 23:38:51.169: INFO: Number of nodes with available pods: 1
Nov 14 23:38:51.169: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2216, will wait for the garbage collector to delete the pods
Nov 14 23:38:51.333: INFO: Deleting DaemonSet.extensions daemon-set took: 79.349511ms
Nov 14 23:38:52.033: INFO: Terminating DaemonSet.extensions daemon-set pods took: 700.47883ms
Nov 14 23:38:54.738: INFO: Number of nodes with available pods: 0
Nov 14 23:38:54.738: INFO: Number of running nodes: 0, number of available pods: 0
Nov 14 23:38:54.740: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-2216/daemonsets","resourceVersion":"28338"},"items":null}

Nov 14 23:38:54.741: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-2216/pods","resourceVersion":"28338"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:38:54.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2216" for this suite.
Nov 14 23:39:02.945: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:39:03.056: INFO: namespace daemonsets-2216 deletion completed in 8.155561837s

• [SLOW TEST:25.799 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:39:03.061: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9023
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Nov 14 23:39:03.660: INFO: Waiting up to 5m0s for pod "downwardapi-volume-19d0b90f-27d2-4117-900f-e68790157d92" in namespace "downward-api-9023" to be "success or failure"
Nov 14 23:39:03.698: INFO: Pod "downwardapi-volume-19d0b90f-27d2-4117-900f-e68790157d92": Phase="Pending", Reason="", readiness=false. Elapsed: 37.096364ms
Nov 14 23:39:05.701: INFO: Pod "downwardapi-volume-19d0b90f-27d2-4117-900f-e68790157d92": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040111736s
Nov 14 23:39:07.705: INFO: Pod "downwardapi-volume-19d0b90f-27d2-4117-900f-e68790157d92": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.044459358s
STEP: Saw pod success
Nov 14 23:39:07.706: INFO: Pod "downwardapi-volume-19d0b90f-27d2-4117-900f-e68790157d92" satisfied condition "success or failure"
Nov 14 23:39:07.708: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-1 pod downwardapi-volume-19d0b90f-27d2-4117-900f-e68790157d92 container client-container: <nil>
STEP: delete the pod
Nov 14 23:39:07.886: INFO: Waiting for pod downwardapi-volume-19d0b90f-27d2-4117-900f-e68790157d92 to disappear
Nov 14 23:39:07.951: INFO: Pod downwardapi-volume-19d0b90f-27d2-4117-900f-e68790157d92 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:39:07.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9023" for this suite.
Nov 14 23:39:14.755: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:39:15.832: INFO: namespace downward-api-9023 deletion completed in 7.857294544s

• [SLOW TEST:12.772 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:39:15.838: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2450
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1420
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Nov 14 23:39:16.182: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-2450'
Nov 14 23:39:16.336: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Nov 14 23:39:16.336: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1426
Nov 14 23:39:18.455: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 delete deployment e2e-test-nginx-deployment --namespace=kubectl-2450'
Nov 14 23:39:18.816: INFO: stderr: ""
Nov 14 23:39:18.816: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:39:18.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2450" for this suite.
Nov 14 23:41:22.915: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:41:23.054: INFO: namespace kubectl-2450 deletion completed in 2m4.20209246s

• [SLOW TEST:127.217 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run default
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:41:23.055: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4203
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1557
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Nov 14 23:41:23.656: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/apps.v1 --namespace=kubectl-4203'
Nov 14 23:41:23.803: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Nov 14 23:41:23.803: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1562
Nov 14 23:41:25.948: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 delete deployment e2e-test-nginx-deployment --namespace=kubectl-4203'
Nov 14 23:41:26.221: INFO: stderr: ""
Nov 14 23:41:26.222: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:41:26.222: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4203" for this suite.
Nov 14 23:43:30.374: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:43:30.852: INFO: namespace kubectl-4203 deletion completed in 2m4.625628133s

• [SLOW TEST:127.798 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:43:30.853: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-368
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Nov 14 23:43:31.793: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 23:43:31.853: INFO: Number of nodes with available pods: 0
Nov 14 23:43:31.854: INFO: Node k8s-1-tdyr52fdsot3-minion-0 is running more than one daemon pod
Nov 14 23:43:32.882: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 23:43:33.070: INFO: Number of nodes with available pods: 0
Nov 14 23:43:33.071: INFO: Node k8s-1-tdyr52fdsot3-minion-0 is running more than one daemon pod
Nov 14 23:43:33.859: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 23:43:33.863: INFO: Number of nodes with available pods: 0
Nov 14 23:43:33.863: INFO: Node k8s-1-tdyr52fdsot3-minion-0 is running more than one daemon pod
Nov 14 23:43:34.881: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 23:43:34.924: INFO: Number of nodes with available pods: 0
Nov 14 23:43:34.924: INFO: Node k8s-1-tdyr52fdsot3-minion-0 is running more than one daemon pod
Nov 14 23:43:35.861: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 23:43:35.865: INFO: Number of nodes with available pods: 0
Nov 14 23:43:35.866: INFO: Node k8s-1-tdyr52fdsot3-minion-0 is running more than one daemon pod
Nov 14 23:43:36.870: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 23:43:37.192: INFO: Number of nodes with available pods: 0
Nov 14 23:43:37.192: INFO: Node k8s-1-tdyr52fdsot3-minion-0 is running more than one daemon pod
Nov 14 23:43:38.000: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 23:43:38.005: INFO: Number of nodes with available pods: 1
Nov 14 23:43:38.005: INFO: Node k8s-1-tdyr52fdsot3-minion-1 is running more than one daemon pod
Nov 14 23:43:38.861: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 23:43:38.866: INFO: Number of nodes with available pods: 2
Nov 14 23:43:38.866: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Nov 14 23:43:39.050: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 23:43:39.117: INFO: Number of nodes with available pods: 1
Nov 14 23:43:39.118: INFO: Node k8s-1-tdyr52fdsot3-minion-1 is running more than one daemon pod
Nov 14 23:43:40.236: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 23:43:40.239: INFO: Number of nodes with available pods: 1
Nov 14 23:43:40.239: INFO: Node k8s-1-tdyr52fdsot3-minion-1 is running more than one daemon pod
Nov 14 23:43:41.296: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 23:43:41.602: INFO: Number of nodes with available pods: 1
Nov 14 23:43:41.602: INFO: Node k8s-1-tdyr52fdsot3-minion-1 is running more than one daemon pod
Nov 14 23:43:42.122: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 23:43:42.127: INFO: Number of nodes with available pods: 1
Nov 14 23:43:42.127: INFO: Node k8s-1-tdyr52fdsot3-minion-1 is running more than one daemon pod
Nov 14 23:43:43.216: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 23:43:43.246: INFO: Number of nodes with available pods: 1
Nov 14 23:43:43.246: INFO: Node k8s-1-tdyr52fdsot3-minion-1 is running more than one daemon pod
Nov 14 23:43:44.243: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 23:43:44.259: INFO: Number of nodes with available pods: 2
Nov 14 23:43:44.259: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-368, will wait for the garbage collector to delete the pods
Nov 14 23:43:44.334: INFO: Deleting DaemonSet.extensions daemon-set took: 11.701564ms
Nov 14 23:43:45.134: INFO: Terminating DaemonSet.extensions daemon-set pods took: 800.297821ms
Nov 14 23:43:50.340: INFO: Number of nodes with available pods: 0
Nov 14 23:43:50.340: INFO: Number of running nodes: 0, number of available pods: 0
Nov 14 23:43:50.343: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-368/daemonsets","resourceVersion":"29093"},"items":null}

Nov 14 23:43:50.346: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-368/pods","resourceVersion":"29093"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:43:50.359: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-368" for this suite.
Nov 14 23:43:58.463: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:43:58.616: INFO: namespace daemonsets-368 deletion completed in 8.2531241s

• [SLOW TEST:27.763 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:43:58.625: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-427
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-427
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a new StatefulSet
Nov 14 23:43:59.400: INFO: Found 0 stateful pods, waiting for 3
Nov 14 23:44:09.404: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 14 23:44:09.405: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov 14 23:44:09.405: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Nov 14 23:44:19.408: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 14 23:44:19.408: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov 14 23:44:19.408: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Nov 14 23:44:19.440: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Nov 14 23:44:29.747: INFO: Updating stateful set ss2
Nov 14 23:44:29.884: INFO: Waiting for Pod statefulset-427/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Restoring Pods to the correct revision when they are deleted
Nov 14 23:44:42.033: INFO: Found 2 stateful pods, waiting for 3
Nov 14 23:44:52.328: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 14 23:44:52.328: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov 14 23:44:52.328: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Nov 14 23:45:02.134: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 14 23:45:02.134: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov 14 23:45:02.134: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Nov 14 23:45:02.184: INFO: Updating stateful set ss2
Nov 14 23:45:02.410: INFO: Waiting for Pod statefulset-427/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Nov 14 23:45:12.694: INFO: Updating stateful set ss2
Nov 14 23:45:12.934: INFO: Waiting for StatefulSet statefulset-427/ss2 to complete update
Nov 14 23:45:12.934: INFO: Waiting for Pod statefulset-427/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Nov 14 23:45:22.941: INFO: Waiting for StatefulSet statefulset-427/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Nov 14 23:45:32.949: INFO: Deleting all statefulset in ns statefulset-427
Nov 14 23:45:32.953: INFO: Scaling statefulset ss2 to 0
Nov 14 23:45:53.064: INFO: Waiting for statefulset status.replicas updated to 0
Nov 14 23:45:53.068: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:45:53.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-427" for this suite.
Nov 14 23:46:03.211: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:46:03.374: INFO: namespace statefulset-427 deletion completed in 10.257817453s

• [SLOW TEST:124.749 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:46:03.383: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-9920
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Nov 14 23:46:04.062: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 23:46:04.161: INFO: Number of nodes with available pods: 0
Nov 14 23:46:04.162: INFO: Node k8s-1-tdyr52fdsot3-minion-0 is running more than one daemon pod
Nov 14 23:46:05.375: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 23:46:05.380: INFO: Number of nodes with available pods: 0
Nov 14 23:46:05.381: INFO: Node k8s-1-tdyr52fdsot3-minion-0 is running more than one daemon pod
Nov 14 23:46:06.306: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 23:46:06.683: INFO: Number of nodes with available pods: 0
Nov 14 23:46:06.683: INFO: Node k8s-1-tdyr52fdsot3-minion-0 is running more than one daemon pod
Nov 14 23:46:07.167: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 23:46:07.172: INFO: Number of nodes with available pods: 0
Nov 14 23:46:07.172: INFO: Node k8s-1-tdyr52fdsot3-minion-0 is running more than one daemon pod
Nov 14 23:46:08.167: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 23:46:08.171: INFO: Number of nodes with available pods: 0
Nov 14 23:46:08.172: INFO: Node k8s-1-tdyr52fdsot3-minion-0 is running more than one daemon pod
Nov 14 23:46:09.245: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 23:46:09.489: INFO: Number of nodes with available pods: 0
Nov 14 23:46:09.489: INFO: Node k8s-1-tdyr52fdsot3-minion-0 is running more than one daemon pod
Nov 14 23:46:10.466: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 23:46:10.558: INFO: Number of nodes with available pods: 0
Nov 14 23:46:10.558: INFO: Node k8s-1-tdyr52fdsot3-minion-0 is running more than one daemon pod
Nov 14 23:46:11.168: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 23:46:11.172: INFO: Number of nodes with available pods: 0
Nov 14 23:46:11.172: INFO: Node k8s-1-tdyr52fdsot3-minion-0 is running more than one daemon pod
Nov 14 23:46:12.374: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 23:46:12.377: INFO: Number of nodes with available pods: 0
Nov 14 23:46:12.378: INFO: Node k8s-1-tdyr52fdsot3-minion-0 is running more than one daemon pod
Nov 14 23:46:13.511: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 23:46:13.819: INFO: Number of nodes with available pods: 0
Nov 14 23:46:13.819: INFO: Node k8s-1-tdyr52fdsot3-minion-0 is running more than one daemon pod
Nov 14 23:46:14.459: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 23:46:14.563: INFO: Number of nodes with available pods: 1
Nov 14 23:46:14.563: INFO: Node k8s-1-tdyr52fdsot3-minion-0 is running more than one daemon pod
Nov 14 23:46:15.305: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 23:46:15.311: INFO: Number of nodes with available pods: 1
Nov 14 23:46:15.312: INFO: Node k8s-1-tdyr52fdsot3-minion-0 is running more than one daemon pod
Nov 14 23:46:16.166: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 23:46:16.169: INFO: Number of nodes with available pods: 1
Nov 14 23:46:16.169: INFO: Node k8s-1-tdyr52fdsot3-minion-0 is running more than one daemon pod
Nov 14 23:46:17.506: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 23:46:18.309: INFO: Number of nodes with available pods: 1
Nov 14 23:46:18.309: INFO: Node k8s-1-tdyr52fdsot3-minion-0 is running more than one daemon pod
Nov 14 23:46:19.232: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 23:46:19.294: INFO: Number of nodes with available pods: 1
Nov 14 23:46:19.294: INFO: Node k8s-1-tdyr52fdsot3-minion-0 is running more than one daemon pod
Nov 14 23:46:20.415: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 23:46:20.473: INFO: Number of nodes with available pods: 1
Nov 14 23:46:20.473: INFO: Node k8s-1-tdyr52fdsot3-minion-0 is running more than one daemon pod
Nov 14 23:46:21.167: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 23:46:21.171: INFO: Number of nodes with available pods: 1
Nov 14 23:46:21.171: INFO: Node k8s-1-tdyr52fdsot3-minion-0 is running more than one daemon pod
Nov 14 23:46:22.168: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 23:46:22.173: INFO: Number of nodes with available pods: 1
Nov 14 23:46:22.174: INFO: Node k8s-1-tdyr52fdsot3-minion-0 is running more than one daemon pod
Nov 14 23:46:23.238: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 23:46:23.243: INFO: Number of nodes with available pods: 1
Nov 14 23:46:23.243: INFO: Node k8s-1-tdyr52fdsot3-minion-0 is running more than one daemon pod
Nov 14 23:46:24.167: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 23:46:24.174: INFO: Number of nodes with available pods: 2
Nov 14 23:46:24.175: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Nov 14 23:46:24.308: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 23:46:24.314: INFO: Number of nodes with available pods: 1
Nov 14 23:46:24.314: INFO: Node k8s-1-tdyr52fdsot3-minion-0 is running more than one daemon pod
Nov 14 23:46:25.358: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 23:46:25.362: INFO: Number of nodes with available pods: 1
Nov 14 23:46:25.362: INFO: Node k8s-1-tdyr52fdsot3-minion-0 is running more than one daemon pod
Nov 14 23:46:26.321: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 23:46:26.327: INFO: Number of nodes with available pods: 1
Nov 14 23:46:26.327: INFO: Node k8s-1-tdyr52fdsot3-minion-0 is running more than one daemon pod
Nov 14 23:46:27.320: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 23:46:27.327: INFO: Number of nodes with available pods: 1
Nov 14 23:46:27.327: INFO: Node k8s-1-tdyr52fdsot3-minion-0 is running more than one daemon pod
Nov 14 23:46:28.320: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 23:46:28.326: INFO: Number of nodes with available pods: 1
Nov 14 23:46:28.327: INFO: Node k8s-1-tdyr52fdsot3-minion-0 is running more than one daemon pod
Nov 14 23:46:29.319: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 23:46:29.322: INFO: Number of nodes with available pods: 1
Nov 14 23:46:29.323: INFO: Node k8s-1-tdyr52fdsot3-minion-0 is running more than one daemon pod
Nov 14 23:46:30.319: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 23:46:30.322: INFO: Number of nodes with available pods: 1
Nov 14 23:46:30.323: INFO: Node k8s-1-tdyr52fdsot3-minion-0 is running more than one daemon pod
Nov 14 23:46:31.321: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 23:46:31.323: INFO: Number of nodes with available pods: 1
Nov 14 23:46:31.324: INFO: Node k8s-1-tdyr52fdsot3-minion-0 is running more than one daemon pod
Nov 14 23:46:32.321: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 23:46:32.325: INFO: Number of nodes with available pods: 1
Nov 14 23:46:32.326: INFO: Node k8s-1-tdyr52fdsot3-minion-0 is running more than one daemon pod
Nov 14 23:46:33.318: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 23:46:33.322: INFO: Number of nodes with available pods: 1
Nov 14 23:46:33.322: INFO: Node k8s-1-tdyr52fdsot3-minion-0 is running more than one daemon pod
Nov 14 23:46:34.319: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 23:46:34.323: INFO: Number of nodes with available pods: 1
Nov 14 23:46:34.323: INFO: Node k8s-1-tdyr52fdsot3-minion-0 is running more than one daemon pod
Nov 14 23:46:35.449: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 23:46:35.542: INFO: Number of nodes with available pods: 1
Nov 14 23:46:35.542: INFO: Node k8s-1-tdyr52fdsot3-minion-0 is running more than one daemon pod
Nov 14 23:46:36.361: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 23:46:36.368: INFO: Number of nodes with available pods: 1
Nov 14 23:46:36.368: INFO: Node k8s-1-tdyr52fdsot3-minion-0 is running more than one daemon pod
Nov 14 23:46:37.319: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 23:46:37.322: INFO: Number of nodes with available pods: 1
Nov 14 23:46:37.322: INFO: Node k8s-1-tdyr52fdsot3-minion-0 is running more than one daemon pod
Nov 14 23:46:38.322: INFO: DaemonSet pods can't tolerate node k8s-1-tdyr52fdsot3-master-0 with taints [{Key:CriticalAddonsOnly Value:True Effect:NoSchedule TimeAdded:<nil>} {Key:dedicated Value:master Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Nov 14 23:46:38.326: INFO: Number of nodes with available pods: 2
Nov 14 23:46:38.326: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9920, will wait for the garbage collector to delete the pods
Nov 14 23:46:38.393: INFO: Deleting DaemonSet.extensions daemon-set took: 8.809696ms
Nov 14 23:46:39.094: INFO: Terminating DaemonSet.extensions daemon-set pods took: 700.34709ms
Nov 14 23:46:54.105: INFO: Number of nodes with available pods: 0
Nov 14 23:46:54.105: INFO: Number of running nodes: 0, number of available pods: 0
Nov 14 23:46:54.107: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9920/daemonsets","resourceVersion":"29823"},"items":null}

Nov 14 23:46:54.109: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9920/pods","resourceVersion":"29823"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:46:54.119: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9920" for this suite.
Nov 14 23:47:02.160: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:47:02.327: INFO: namespace daemonsets-9920 deletion completed in 8.204826992s

• [SLOW TEST:58.944 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:47:02.329: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-5084
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-5084.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-5084.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5084.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-5084.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-5084.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5084.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov 14 23:48:03.109: INFO: DNS probes using dns-5084/dns-test-8a11bdad-ae9d-4bfb-9f37-23784848d7db succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:48:03.190: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5084" for this suite.
Nov 14 23:48:10.106: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:48:10.560: INFO: namespace dns-5084 deletion completed in 7.168677841s

• [SLOW TEST:68.231 seconds]
[sig-network] DNS
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:48:10.567: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2792
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on tmpfs
Nov 14 23:48:11.079: INFO: Waiting up to 5m0s for pod "pod-60b4931f-37b5-41b9-85b2-87f7e8cc5f39" in namespace "emptydir-2792" to be "success or failure"
Nov 14 23:48:11.147: INFO: Pod "pod-60b4931f-37b5-41b9-85b2-87f7e8cc5f39": Phase="Pending", Reason="", readiness=false. Elapsed: 68.643871ms
Nov 14 23:48:13.369: INFO: Pod "pod-60b4931f-37b5-41b9-85b2-87f7e8cc5f39": Phase="Pending", Reason="", readiness=false. Elapsed: 2.289854288s
Nov 14 23:48:15.662: INFO: Pod "pod-60b4931f-37b5-41b9-85b2-87f7e8cc5f39": Phase="Pending", Reason="", readiness=false. Elapsed: 4.582784873s
Nov 14 23:48:17.836: INFO: Pod "pod-60b4931f-37b5-41b9-85b2-87f7e8cc5f39": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.756986991s
STEP: Saw pod success
Nov 14 23:48:17.836: INFO: Pod "pod-60b4931f-37b5-41b9-85b2-87f7e8cc5f39" satisfied condition "success or failure"
Nov 14 23:48:17.894: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-1 pod pod-60b4931f-37b5-41b9-85b2-87f7e8cc5f39 container test-container: <nil>
STEP: delete the pod
Nov 14 23:48:18.221: INFO: Waiting for pod pod-60b4931f-37b5-41b9-85b2-87f7e8cc5f39 to disappear
Nov 14 23:48:18.529: INFO: Pod pod-60b4931f-37b5-41b9-85b2-87f7e8cc5f39 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:48:18.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2792" for this suite.
Nov 14 23:48:24.826: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:48:25.236: INFO: namespace emptydir-2792 deletion completed in 6.698350293s

• [SLOW TEST:14.670 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:48:25.242: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-8953
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Nov 14 23:48:25.800: INFO: Pod name rollover-pod: Found 0 pods out of 1
Nov 14 23:48:30.817: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Nov 14 23:48:32.842: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Nov 14 23:48:34.867: INFO: Creating deployment "test-rollover-deployment"
Nov 14 23:48:34.922: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Nov 14 23:48:36.974: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Nov 14 23:48:36.982: INFO: Ensure that both replica sets have 1 created replica
Nov 14 23:48:36.986: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Nov 14 23:48:36.993: INFO: Updating deployment test-rollover-deployment
Nov 14 23:48:36.994: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Nov 14 23:48:39.067: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Nov 14 23:48:39.239: INFO: Make sure deployment "test-rollover-deployment" is complete
Nov 14 23:48:39.245: INFO: all replica sets need to contain the pod-template-hash label
Nov 14 23:48:39.245: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709372114, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709372114, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709372118, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709372114, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 14 23:48:41.276: INFO: all replica sets need to contain the pod-template-hash label
Nov 14 23:48:41.277: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709372114, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709372114, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709372118, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709372114, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 14 23:48:43.257: INFO: all replica sets need to contain the pod-template-hash label
Nov 14 23:48:43.258: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709372114, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709372114, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709372122, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709372114, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 14 23:48:45.349: INFO: all replica sets need to contain the pod-template-hash label
Nov 14 23:48:45.349: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709372114, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709372114, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709372122, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709372114, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 14 23:48:47.257: INFO: all replica sets need to contain the pod-template-hash label
Nov 14 23:48:47.257: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709372114, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709372114, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709372122, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709372114, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 14 23:48:49.314: INFO: all replica sets need to contain the pod-template-hash label
Nov 14 23:48:49.315: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709372114, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709372114, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709372122, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709372114, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 14 23:48:51.322: INFO: all replica sets need to contain the pod-template-hash label
Nov 14 23:48:51.322: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709372114, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709372114, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709372122, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709372114, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 14 23:48:53.791: INFO: 
Nov 14 23:48:53.791: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:2, UnavailableReplicas:0, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709372114, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709372114, loc:(*time.Location)(0x7ed0a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709372132, loc:(*time.Location)(0x7ed0a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709372114, loc:(*time.Location)(0x7ed0a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 14 23:48:55.264: INFO: 
Nov 14 23:48:55.264: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Nov 14 23:48:55.285: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-8953,SelfLink:/apis/apps/v1/namespaces/deployment-8953/deployments/test-rollover-deployment,UID:955b759a-8335-44d9-b573-96f9d4e25fd1,ResourceVersion:30223,Generation:2,CreationTimestamp:2019-11-14 23:48:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-11-14 23:48:34 +0000 UTC 2019-11-14 23:48:34 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-11-14 23:48:53 +0000 UTC 2019-11-14 23:48:34 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-854595fc44" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Nov 14 23:48:55.290: INFO: New ReplicaSet "test-rollover-deployment-854595fc44" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-854595fc44,GenerateName:,Namespace:deployment-8953,SelfLink:/apis/apps/v1/namespaces/deployment-8953/replicasets/test-rollover-deployment-854595fc44,UID:25370253-45e6-485c-add0-fe569f034959,ResourceVersion:30211,Generation:2,CreationTimestamp:2019-11-14 23:48:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 955b759a-8335-44d9-b573-96f9d4e25fd1 0xc002c54837 0xc002c54838}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Nov 14 23:48:55.290: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Nov 14 23:48:55.291: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-8953,SelfLink:/apis/apps/v1/namespaces/deployment-8953/replicasets/test-rollover-controller,UID:587be6ea-25bb-415f-8152-3438cb79d067,ResourceVersion:30222,Generation:2,CreationTimestamp:2019-11-14 23:48:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 955b759a-8335-44d9-b573-96f9d4e25fd1 0xc002c54767 0xc002c54768}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Nov 14 23:48:55.291: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-9b8b997cf,GenerateName:,Namespace:deployment-8953,SelfLink:/apis/apps/v1/namespaces/deployment-8953/replicasets/test-rollover-deployment-9b8b997cf,UID:804b37b6-c7a9-444a-9a48-6974b84d4e41,ResourceVersion:30175,Generation:2,CreationTimestamp:2019-11-14 23:48:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 955b759a-8335-44d9-b573-96f9d4e25fd1 0xc002c54900 0xc002c54901}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Nov 14 23:48:55.296: INFO: Pod "test-rollover-deployment-854595fc44-rdc7t" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-854595fc44-rdc7t,GenerateName:test-rollover-deployment-854595fc44-,Namespace:deployment-8953,SelfLink:/api/v1/namespaces/deployment-8953/pods/test-rollover-deployment-854595fc44-rdc7t,UID:646e0785-c0f8-4306-85ed-a34d979c0bb2,ResourceVersion:30189,Generation:0,CreationTimestamp:2019-11-14 23:48:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.1.143/32,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-854595fc44 25370253-45e6-485c-add0-fe569f034959 0xc002c55507 0xc002c55508}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-52dl6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-52dl6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-52dl6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-1-tdyr52fdsot3-minion-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c55570} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c55590}],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:48:38 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:48:42 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:48:42 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-14 23:48:37 +0000 UTC  }],Message:,Reason:,HostIP:10.0.0.126,PodIP:192.168.1.143,StartTime:2019-11-14 23:48:38 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-11-14 23:48:42 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://71c0b9ddabd5366ade3aebb8059e9b2bea4be44e42e9d5146176b2f057f3bc68}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:48:55.297: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8953" for this suite.
Nov 14 23:49:05.428: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:49:05.745: INFO: namespace deployment-8953 deletion completed in 10.440947323s

• [SLOW TEST:40.504 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:49:05.754: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in hostpath-9268
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test hostPath mode
Nov 14 23:49:06.348: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-9268" to be "success or failure"
Nov 14 23:49:06.429: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 81.537936ms
Nov 14 23:49:08.827: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.478878747s
Nov 14 23:49:10.994: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 4.646420379s
Nov 14 23:49:13.073: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.725234258s
STEP: Saw pod success
Nov 14 23:49:13.073: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Nov 14 23:49:13.078: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-1 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Nov 14 23:49:13.145: INFO: Waiting for pod pod-host-path-test to disappear
Nov 14 23:49:13.383: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:49:13.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-9268" for this suite.
Nov 14 23:49:19.659: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:49:20.113: INFO: namespace hostpath-9268 deletion completed in 6.718656742s

• [SLOW TEST:14.360 seconds]
[sig-storage] HostPath
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:49:20.122: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4935
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating Redis RC
Nov 14 23:49:21.307: INFO: namespace kubectl-4935
Nov 14 23:49:21.307: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 create -f - --namespace=kubectl-4935'
Nov 14 23:49:24.328: INFO: stderr: ""
Nov 14 23:49:24.328: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Nov 14 23:49:25.468: INFO: Selector matched 1 pods for map[app:redis]
Nov 14 23:49:25.468: INFO: Found 0 / 1
Nov 14 23:49:26.557: INFO: Selector matched 1 pods for map[app:redis]
Nov 14 23:49:26.557: INFO: Found 0 / 1
Nov 14 23:49:27.362: INFO: Selector matched 1 pods for map[app:redis]
Nov 14 23:49:27.363: INFO: Found 1 / 1
Nov 14 23:49:27.363: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Nov 14 23:49:27.406: INFO: Selector matched 1 pods for map[app:redis]
Nov 14 23:49:27.406: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Nov 14 23:49:27.406: INFO: wait on redis-master startup in kubectl-4935 
Nov 14 23:49:27.406: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 logs redis-master-5j5x9 redis-master --namespace=kubectl-4935'
Nov 14 23:49:27.886: INFO: stderr: ""
Nov 14 23:49:27.886: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 14 Nov 23:49:27.299 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 14 Nov 23:49:27.299 # Server started, Redis version 3.2.12\n1:M 14 Nov 23:49:27.299 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 14 Nov 23:49:27.299 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Nov 14 23:49:27.927: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-4935'
Nov 14 23:49:28.277: INFO: stderr: ""
Nov 14 23:49:28.277: INFO: stdout: "service/rm2 exposed\n"
Nov 14 23:49:28.297: INFO: Service rm2 in namespace kubectl-4935 found.
STEP: exposing service
Nov 14 23:49:30.308: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-4935'
Nov 14 23:49:30.758: INFO: stderr: ""
Nov 14 23:49:30.758: INFO: stdout: "service/rm3 exposed\n"
Nov 14 23:49:30.788: INFO: Service rm3 in namespace kubectl-4935 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:49:32.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4935" for this suite.
Nov 14 23:49:58.884: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:49:59.033: INFO: namespace kubectl-4935 deletion completed in 26.229607133s

• [SLOW TEST:38.911 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl expose
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create services for rc  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:49:59.054: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5640
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Nov 14 23:50:07.837: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 exec pod-sharedvolume-5dbfe844-5414-40e0-a73a-be2c4f9dd88c -c busybox-main-container --namespace=emptydir-5640 -- cat /usr/share/volumeshare/shareddata.txt'
Nov 14 23:50:08.143: INFO: stderr: ""
Nov 14 23:50:08.143: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:50:08.144: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5640" for this suite.
Nov 14 23:50:16.360: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:50:16.486: INFO: namespace emptydir-5640 deletion completed in 8.337410622s

• [SLOW TEST:17.433 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:50:16.492: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8888
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Nov 14 23:50:17.248: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bd42f556-c7fe-4fe0-8177-8479ff7bab18" in namespace "downward-api-8888" to be "success or failure"
Nov 14 23:50:17.314: INFO: Pod "downwardapi-volume-bd42f556-c7fe-4fe0-8177-8479ff7bab18": Phase="Pending", Reason="", readiness=false. Elapsed: 65.809537ms
Nov 14 23:50:19.323: INFO: Pod "downwardapi-volume-bd42f556-c7fe-4fe0-8177-8479ff7bab18": Phase="Pending", Reason="", readiness=false. Elapsed: 2.074357441s
Nov 14 23:50:21.521: INFO: Pod "downwardapi-volume-bd42f556-c7fe-4fe0-8177-8479ff7bab18": Phase="Pending", Reason="", readiness=false. Elapsed: 4.272155405s
Nov 14 23:50:23.525: INFO: Pod "downwardapi-volume-bd42f556-c7fe-4fe0-8177-8479ff7bab18": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.276301061s
STEP: Saw pod success
Nov 14 23:50:23.525: INFO: Pod "downwardapi-volume-bd42f556-c7fe-4fe0-8177-8479ff7bab18" satisfied condition "success or failure"
Nov 14 23:50:23.528: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-0 pod downwardapi-volume-bd42f556-c7fe-4fe0-8177-8479ff7bab18 container client-container: <nil>
STEP: delete the pod
Nov 14 23:50:23.813: INFO: Waiting for pod downwardapi-volume-bd42f556-c7fe-4fe0-8177-8479ff7bab18 to disappear
Nov 14 23:50:23.887: INFO: Pod downwardapi-volume-bd42f556-c7fe-4fe0-8177-8479ff7bab18 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:50:23.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8888" for this suite.
Nov 14 23:50:30.074: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:50:30.567: INFO: namespace downward-api-8888 deletion completed in 6.674372954s

• [SLOW TEST:14.076 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:50:30.579: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-4757
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Nov 14 23:50:35.445: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-216763962 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Nov 14 23:50:40.970: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:50:40.973: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4757" for this suite.
Nov 14 23:50:47.051: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:50:47.155: INFO: namespace pods-4757 deletion completed in 6.177453346s

• [SLOW TEST:16.577 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be submitted and removed [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:50:47.162: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-4891
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Nov 14 23:50:55.736: INFO: Pod name wrapped-volume-race-5d3c74d6-e0db-448d-ab4e-b4307dbfaec2: Found 0 pods out of 5
Nov 14 23:51:01.041: INFO: Pod name wrapped-volume-race-5d3c74d6-e0db-448d-ab4e-b4307dbfaec2: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-5d3c74d6-e0db-448d-ab4e-b4307dbfaec2 in namespace emptydir-wrapper-4891, will wait for the garbage collector to delete the pods
Nov 14 23:51:33.168: INFO: Deleting ReplicationController wrapped-volume-race-5d3c74d6-e0db-448d-ab4e-b4307dbfaec2 took: 433.252747ms
Nov 14 23:51:34.869: INFO: Terminating ReplicationController wrapped-volume-race-5d3c74d6-e0db-448d-ab4e-b4307dbfaec2 pods took: 1.70055931s
STEP: Creating RC which spawns configmap-volume pods
Nov 14 23:52:22.711: INFO: Pod name wrapped-volume-race-88545d36-f1fb-49ca-84af-8e8cb23758ee: Found 0 pods out of 5
Nov 14 23:52:27.820: INFO: Pod name wrapped-volume-race-88545d36-f1fb-49ca-84af-8e8cb23758ee: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-88545d36-f1fb-49ca-84af-8e8cb23758ee in namespace emptydir-wrapper-4891, will wait for the garbage collector to delete the pods
Nov 14 23:52:53.988: INFO: Deleting ReplicationController wrapped-volume-race-88545d36-f1fb-49ca-84af-8e8cb23758ee took: 9.203675ms
Nov 14 23:52:54.989: INFO: Terminating ReplicationController wrapped-volume-race-88545d36-f1fb-49ca-84af-8e8cb23758ee pods took: 1.000926007s
STEP: Creating RC which spawns configmap-volume pods
Nov 14 23:53:43.357: INFO: Pod name wrapped-volume-race-ea171c44-b7a3-43bd-b445-f25d82ce2af6: Found 0 pods out of 5
Nov 14 23:53:48.377: INFO: Pod name wrapped-volume-race-ea171c44-b7a3-43bd-b445-f25d82ce2af6: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-ea171c44-b7a3-43bd-b445-f25d82ce2af6 in namespace emptydir-wrapper-4891, will wait for the garbage collector to delete the pods
Nov 14 23:54:16.925: INFO: Deleting ReplicationController wrapped-volume-race-ea171c44-b7a3-43bd-b445-f25d82ce2af6 took: 9.788988ms
Nov 14 23:54:18.226: INFO: Terminating ReplicationController wrapped-volume-race-ea171c44-b7a3-43bd-b445-f25d82ce2af6 pods took: 1.300700653s
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:55:06.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-4891" for this suite.
Nov 14 23:55:30.764: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:55:30.924: INFO: namespace emptydir-wrapper-4891 deletion completed in 24.272182601s

• [SLOW TEST:283.763 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:55:30.929: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-7298
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Nov 14 23:55:31.470: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:55:41.009: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-7298" for this suite.
Nov 14 23:56:05.179: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:56:05.390: INFO: namespace init-container-7298 deletion completed in 24.253293247s

• [SLOW TEST:34.462 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:56:05.399: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-7175
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-7175, will wait for the garbage collector to delete the pods
Nov 14 23:56:14.202: INFO: Deleting Job.batch foo took: 7.829014ms
Nov 14 23:56:15.002: INFO: Terminating Job.batch foo pods took: 800.231316ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:56:53.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-7175" for this suite.
Nov 14 23:57:02.011: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:57:02.155: INFO: namespace job-7175 deletion completed in 8.243004659s

• [SLOW TEST:56.756 seconds]
[sig-apps] Job
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:57:02.159: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4999
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on node default medium
Nov 14 23:57:02.507: INFO: Waiting up to 5m0s for pod "pod-d8e6baa2-36e5-45b9-8b5a-b103728eeef4" in namespace "emptydir-4999" to be "success or failure"
Nov 14 23:57:02.536: INFO: Pod "pod-d8e6baa2-36e5-45b9-8b5a-b103728eeef4": Phase="Pending", Reason="", readiness=false. Elapsed: 28.276639ms
Nov 14 23:57:04.540: INFO: Pod "pod-d8e6baa2-36e5-45b9-8b5a-b103728eeef4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03282327s
Nov 14 23:57:06.709: INFO: Pod "pod-d8e6baa2-36e5-45b9-8b5a-b103728eeef4": Phase="Running", Reason="", readiness=true. Elapsed: 4.200980645s
Nov 14 23:57:08.714: INFO: Pod "pod-d8e6baa2-36e5-45b9-8b5a-b103728eeef4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.206803786s
STEP: Saw pod success
Nov 14 23:57:08.714: INFO: Pod "pod-d8e6baa2-36e5-45b9-8b5a-b103728eeef4" satisfied condition "success or failure"
Nov 14 23:57:08.717: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-1 pod pod-d8e6baa2-36e5-45b9-8b5a-b103728eeef4 container test-container: <nil>
STEP: delete the pod
Nov 14 23:57:08.871: INFO: Waiting for pod pod-d8e6baa2-36e5-45b9-8b5a-b103728eeef4 to disappear
Nov 14 23:57:08.935: INFO: Pod pod-d8e6baa2-36e5-45b9-8b5a-b103728eeef4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 14 23:57:08.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4999" for this suite.
Nov 14 23:57:15.056: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 14 23:57:15.401: INFO: namespace emptydir-4999 deletion completed in 6.459696565s

• [SLOW TEST:13.243 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 14 23:57:15.410: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-67
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating all guestbook components
Nov 14 23:57:16.195: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Nov 14 23:57:16.196: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 create -f - --namespace=kubectl-67'
Nov 14 23:57:16.666: INFO: stderr: ""
Nov 14 23:57:16.666: INFO: stdout: "service/redis-slave created\n"
Nov 14 23:57:16.666: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Nov 14 23:57:16.666: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 create -f - --namespace=kubectl-67'
Nov 14 23:57:17.337: INFO: stderr: ""
Nov 14 23:57:17.337: INFO: stdout: "service/redis-master created\n"
Nov 14 23:57:17.337: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Nov 14 23:57:17.337: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 create -f - --namespace=kubectl-67'
Nov 14 23:57:18.013: INFO: stderr: ""
Nov 14 23:57:18.013: INFO: stdout: "service/frontend created\n"
Nov 14 23:57:18.014: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Nov 14 23:57:18.014: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 create -f - --namespace=kubectl-67'
Nov 14 23:57:18.516: INFO: stderr: ""
Nov 14 23:57:18.516: INFO: stdout: "deployment.apps/frontend created\n"
Nov 14 23:57:18.516: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Nov 14 23:57:18.516: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 create -f - --namespace=kubectl-67'
Nov 14 23:57:18.996: INFO: stderr: ""
Nov 14 23:57:18.996: INFO: stdout: "deployment.apps/redis-master created\n"
Nov 14 23:57:18.996: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Nov 14 23:57:18.996: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 create -f - --namespace=kubectl-67'
Nov 14 23:57:19.693: INFO: stderr: ""
Nov 14 23:57:19.693: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Nov 14 23:57:19.694: INFO: Waiting for all frontend pods to be Running.
Nov 14 23:59:51.477: INFO: Waiting for frontend to serve content.
Nov 15 00:00:02.824: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection timed out [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection time...', 110)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stre in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Nov 15 00:00:08.515: INFO: Trying to add a new entry to the guestbook.
Nov 15 00:00:08.627: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Nov 15 00:00:08.765: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 delete --grace-period=0 --force -f - --namespace=kubectl-67'
Nov 15 00:00:20.136: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 15 00:00:20.136: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Nov 15 00:00:20.136: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 delete --grace-period=0 --force -f - --namespace=kubectl-67'
Nov 15 00:00:20.645: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 15 00:00:20.645: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Nov 15 00:00:20.645: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 delete --grace-period=0 --force -f - --namespace=kubectl-67'
Nov 15 00:00:21.114: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 15 00:00:21.114: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Nov 15 00:00:21.142: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 delete --grace-period=0 --force -f - --namespace=kubectl-67'
Nov 15 00:00:21.305: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 15 00:00:21.305: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Nov 15 00:00:21.337: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 delete --grace-period=0 --force -f - --namespace=kubectl-67'
Nov 15 00:00:21.635: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 15 00:00:21.635: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Nov 15 00:00:21.636: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-216763962 delete --grace-period=0 --force -f - --namespace=kubectl-67'
Nov 15 00:00:21.822: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 15 00:00:21.822: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 15 00:00:21.860: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-67" for this suite.
Nov 15 00:01:05.348: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 15 00:01:06.029: INFO: namespace kubectl-67 deletion completed in 43.853514784s

• [SLOW TEST:230.619 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Guestbook application
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 15 00:01:06.048: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4745
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-map-0a42d866-6cf8-4ae9-8ee5-9d29bb0c3069
STEP: Creating a pod to test consume secrets
Nov 15 00:01:07.718: INFO: Waiting up to 5m0s for pod "pod-secrets-79341442-386a-4234-8937-f68c957233fa" in namespace "secrets-4745" to be "success or failure"
Nov 15 00:01:08.082: INFO: Pod "pod-secrets-79341442-386a-4234-8937-f68c957233fa": Phase="Pending", Reason="", readiness=false. Elapsed: 363.179994ms
Nov 15 00:01:10.460: INFO: Pod "pod-secrets-79341442-386a-4234-8937-f68c957233fa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.742090229s
Nov 15 00:01:12.578: INFO: Pod "pod-secrets-79341442-386a-4234-8937-f68c957233fa": Phase="Pending", Reason="", readiness=false. Elapsed: 4.859640297s
Nov 15 00:01:14.608: INFO: Pod "pod-secrets-79341442-386a-4234-8937-f68c957233fa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.889879379s
STEP: Saw pod success
Nov 15 00:01:14.609: INFO: Pod "pod-secrets-79341442-386a-4234-8937-f68c957233fa" satisfied condition "success or failure"
Nov 15 00:01:14.758: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-0 pod pod-secrets-79341442-386a-4234-8937-f68c957233fa container secret-volume-test: <nil>
STEP: delete the pod
Nov 15 00:01:15.242: INFO: Waiting for pod pod-secrets-79341442-386a-4234-8937-f68c957233fa to disappear
Nov 15 00:01:15.482: INFO: Pod pod-secrets-79341442-386a-4234-8937-f68c957233fa no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 15 00:01:15.483: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4745" for this suite.
Nov 15 00:01:21.757: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 15 00:01:21.921: INFO: namespace secrets-4745 deletion completed in 6.432976783s

• [SLOW TEST:15.874 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 15 00:01:21.934: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-7998
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Nov 15 00:01:29.128: INFO: Successfully updated pod "pod-update-activedeadlineseconds-35bf6479-099a-4b00-833e-3b3dcf5bc1ac"
Nov 15 00:01:29.128: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-35bf6479-099a-4b00-833e-3b3dcf5bc1ac" in namespace "pods-7998" to be "terminated due to deadline exceeded"
Nov 15 00:01:29.446: INFO: Pod "pod-update-activedeadlineseconds-35bf6479-099a-4b00-833e-3b3dcf5bc1ac": Phase="Running", Reason="", readiness=true. Elapsed: 317.628097ms
Nov 15 00:01:31.453: INFO: Pod "pod-update-activedeadlineseconds-35bf6479-099a-4b00-833e-3b3dcf5bc1ac": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.325245529s
Nov 15 00:01:31.454: INFO: Pod "pod-update-activedeadlineseconds-35bf6479-099a-4b00-833e-3b3dcf5bc1ac" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 15 00:01:31.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7998" for this suite.
Nov 15 00:01:37.765: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 15 00:01:38.112: INFO: namespace pods-7998 deletion completed in 6.583818729s

• [SLOW TEST:16.178 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 15 00:01:38.133: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6558
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-1a6dc3e0-d7cf-446b-bf7b-67bf480045fe
STEP: Creating a pod to test consume configMaps
Nov 15 00:01:39.076: INFO: Waiting up to 5m0s for pod "pod-configmaps-b1cab14d-246c-4b47-aef0-156c188bd485" in namespace "configmap-6558" to be "success or failure"
Nov 15 00:01:39.254: INFO: Pod "pod-configmaps-b1cab14d-246c-4b47-aef0-156c188bd485": Phase="Pending", Reason="", readiness=false. Elapsed: 177.818551ms
Nov 15 00:01:41.259: INFO: Pod "pod-configmaps-b1cab14d-246c-4b47-aef0-156c188bd485": Phase="Pending", Reason="", readiness=false. Elapsed: 2.182830848s
Nov 15 00:01:43.452: INFO: Pod "pod-configmaps-b1cab14d-246c-4b47-aef0-156c188bd485": Phase="Pending", Reason="", readiness=false. Elapsed: 4.375663866s
Nov 15 00:01:45.488: INFO: Pod "pod-configmaps-b1cab14d-246c-4b47-aef0-156c188bd485": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.41177454s
STEP: Saw pod success
Nov 15 00:01:45.488: INFO: Pod "pod-configmaps-b1cab14d-246c-4b47-aef0-156c188bd485" satisfied condition "success or failure"
Nov 15 00:01:45.493: INFO: Trying to get logs from node k8s-1-tdyr52fdsot3-minion-0 pod pod-configmaps-b1cab14d-246c-4b47-aef0-156c188bd485 container configmap-volume-test: <nil>
STEP: delete the pod
Nov 15 00:01:45.560: INFO: Waiting for pod pod-configmaps-b1cab14d-246c-4b47-aef0-156c188bd485 to disappear
Nov 15 00:01:45.927: INFO: Pod pod-configmaps-b1cab14d-246c-4b47-aef0-156c188bd485 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 15 00:01:45.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6558" for this suite.
Nov 15 00:01:52.204: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 15 00:01:52.350: INFO: namespace configmap-6558 deletion completed in 6.351930682s

• [SLOW TEST:14.217 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 15 00:01:52.357: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-7134
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7134.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-7134.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7134.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-7134.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov 15 00:02:01.232: INFO: File jessie_udp@dns-test-service-3.dns-7134.svc.cluster.local from pod  dns-7134/dns-test-48a1dc97-f5eb-4551-a2a4-6a02e6dbc873 contains '' instead of 'foo.example.com.'
Nov 15 00:02:01.232: INFO: Lookups using dns-7134/dns-test-48a1dc97-f5eb-4551-a2a4-6a02e6dbc873 failed for: [jessie_udp@dns-test-service-3.dns-7134.svc.cluster.local]

Nov 15 00:02:06.240: INFO: DNS probes using dns-test-48a1dc97-f5eb-4551-a2a4-6a02e6dbc873 succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7134.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-7134.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7134.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-7134.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov 15 00:02:15.535: INFO: DNS probes using dns-test-e077dd35-8396-4181-a8c6-6649a171b48a succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7134.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-7134.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7134.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-7134.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov 15 00:02:29.069: INFO: DNS probes using dns-test-5923265b-54fc-4071-bc83-9e17dea934e1 succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 15 00:02:29.281: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7134" for this suite.
Nov 15 00:02:40.444: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 15 00:02:40.844: INFO: namespace dns-7134 deletion completed in 10.973867475s

• [SLOW TEST:48.488 seconds]
[sig-network] DNS
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 15 00:02:40.849: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6487
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-upd-c4eb98d2-5c8d-4066-8d8c-de385777ec12
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 15 00:02:49.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6487" for this suite.
Nov 15 00:03:15.798: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 15 00:03:15.932: INFO: namespace configmap-6487 deletion completed in 26.176901837s

• [SLOW TEST:35.084 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 15 00:03:15.939: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in prestop-592
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating server pod server in namespace prestop-592
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-592
STEP: Deleting pre-stop pod
Nov 15 00:03:44.360: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 15 00:03:44.416: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-592" for this suite.
Nov 15 00:04:24.838: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 15 00:04:25.306: INFO: namespace prestop-592 deletion completed in 40.720547257s

• [SLOW TEST:69.368 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 15 00:04:25.314: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-3734
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 15 00:04:25.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3734" for this suite.
Nov 15 00:04:50.215: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 15 00:04:50.339: INFO: namespace pods-3734 deletion completed in 24.200441579s

• [SLOW TEST:25.026 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 15 00:04:50.343: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-4342
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Nov 15 00:04:51.123: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Nov 15 00:04:53.733: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 15 00:04:53.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-4342" for this suite.
Nov 15 00:05:04.130: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 15 00:05:04.290: INFO: namespace replication-controller-4342 deletion completed in 10.366241266s

• [SLOW TEST:13.948 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 15 00:05:04.297: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-2997
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Nov 15 00:05:05.017: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 15 00:05:08.000: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-2997" for this suite.
Nov 15 00:05:14.326: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 15 00:05:14.573: INFO: namespace custom-resource-definition-2997 deletion completed in 6.552997996s

• [SLOW TEST:10.277 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 15 00:05:14.578: INFO: >>> kubeConfig: /tmp/kubeconfig-216763962
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-8778
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Nov 15 00:05:25.605: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 15 00:05:25.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8778" for this suite.
W1115 00:05:25.598466      13 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Nov 15 00:05:31.893: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 15 00:05:32.151: INFO: namespace gc-8778 deletion completed in 6.536723008s

• [SLOW TEST:17.573 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.5-beta.0.35+20c265fef0741d/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSNov 15 00:05:32.156: INFO: Running AfterSuite actions on all nodes
Nov 15 00:05:32.175: INFO: Running AfterSuite actions on node 1
Nov 15 00:05:32.176: INFO: Skipping dumping logs from cluster

Ran 215 of 4413 Specs in 8276.642 seconds
SUCCESS! -- 215 Passed | 0 Failed | 0 Pending | 4198 Skipped
PASS

Ginkgo ran 1 suite in 2h17m59.665178803s
Test Suite Passed
