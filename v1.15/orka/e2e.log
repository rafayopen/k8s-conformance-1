I0927 21:16:24.615816      18 test_context.go:406] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-741451867
I0927 21:16:24.615923      18 e2e.go:241] Starting e2e run "24d25b09-58b8-4d09-9136-b13c1aef9d6c" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1569618983 - Will randomize all specs
Will run 215 of 4413 specs

Sep 27 21:16:24.687: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
Sep 27 21:16:24.689: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Sep 27 21:16:24.701: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Sep 27 21:16:24.727: INFO: 18 / 18 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Sep 27 21:16:24.727: INFO: expected 3 pod replicas in namespace 'kube-system', 3 are Running and Ready.
Sep 27 21:16:24.727: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Sep 27 21:16:24.736: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Sep 27 21:16:24.736: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Sep 27 21:16:24.736: INFO: e2e test version: v1.15.2
Sep 27 21:16:24.737: INFO: kube-apiserver version: v1.15.2
SSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:16:24.737: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename configmap
Sep 27 21:16:24.776: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Sep 27 21:16:24.788: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5669
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap configmap-5669/configmap-test-f911adda-3527-4e68-84c1-c907785b7eae
STEP: Creating a pod to test consume configMaps
Sep 27 21:16:24.925: INFO: Waiting up to 5m0s for pod "pod-configmaps-34db3971-ebea-466a-9419-d93ffddaeadd" in namespace "configmap-5669" to be "success or failure"
Sep 27 21:16:24.932: INFO: Pod "pod-configmaps-34db3971-ebea-466a-9419-d93ffddaeadd": Phase="Pending", Reason="", readiness=false. Elapsed: 6.928259ms
Sep 27 21:16:26.935: INFO: Pod "pod-configmaps-34db3971-ebea-466a-9419-d93ffddaeadd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009424088s
STEP: Saw pod success
Sep 27 21:16:26.935: INFO: Pod "pod-configmaps-34db3971-ebea-466a-9419-d93ffddaeadd" satisfied condition "success or failure"
Sep 27 21:16:26.937: INFO: Trying to get logs from node macpro-1 pod pod-configmaps-34db3971-ebea-466a-9419-d93ffddaeadd container env-test: <nil>
STEP: delete the pod
Sep 27 21:16:26.962: INFO: Waiting for pod pod-configmaps-34db3971-ebea-466a-9419-d93ffddaeadd to disappear
Sep 27 21:16:26.964: INFO: Pod pod-configmaps-34db3971-ebea-466a-9419-d93ffddaeadd no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:16:26.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5669" for this suite.
Sep 27 21:16:32.977: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:16:33.052: INFO: namespace configmap-5669 deletion completed in 6.086125571s

• [SLOW TEST:8.315 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:16:33.053: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-1884
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 27 21:16:33.216: INFO: Create a RollingUpdate DaemonSet
Sep 27 21:16:33.226: INFO: Check that daemon pods launch on every node of the cluster
Sep 27 21:16:33.240: INFO: Number of nodes with available pods: 0
Sep 27 21:16:33.240: INFO: Node macpro-1 is running more than one daemon pod
Sep 27 21:16:34.246: INFO: Number of nodes with available pods: 0
Sep 27 21:16:34.246: INFO: Node macpro-1 is running more than one daemon pod
Sep 27 21:16:35.246: INFO: Number of nodes with available pods: 0
Sep 27 21:16:35.246: INFO: Node macpro-1 is running more than one daemon pod
Sep 27 21:16:36.246: INFO: Number of nodes with available pods: 3
Sep 27 21:16:36.246: INFO: Number of running nodes: 3, number of available pods: 3
Sep 27 21:16:36.246: INFO: Update the DaemonSet to trigger a rollout
Sep 27 21:16:36.254: INFO: Updating DaemonSet daemon-set
Sep 27 21:16:40.268: INFO: Roll back the DaemonSet before rollout is complete
Sep 27 21:16:40.277: INFO: Updating DaemonSet daemon-set
Sep 27 21:16:40.277: INFO: Make sure DaemonSet rollback is complete
Sep 27 21:16:40.282: INFO: Wrong image for pod: daemon-set-82zff. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Sep 27 21:16:40.282: INFO: Pod daemon-set-82zff is not available
Sep 27 21:16:41.287: INFO: Wrong image for pod: daemon-set-82zff. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Sep 27 21:16:41.288: INFO: Pod daemon-set-82zff is not available
Sep 27 21:16:42.287: INFO: Pod daemon-set-j55vq is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1884, will wait for the garbage collector to delete the pods
Sep 27 21:16:42.361: INFO: Deleting DaemonSet.extensions daemon-set took: 14.668049ms
Sep 27 21:16:42.662: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.231461ms
Sep 27 21:16:51.464: INFO: Number of nodes with available pods: 0
Sep 27 21:16:51.464: INFO: Number of running nodes: 0, number of available pods: 0
Sep 27 21:16:51.467: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1884/daemonsets","resourceVersion":"7616378"},"items":null}

Sep 27 21:16:51.470: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1884/pods","resourceVersion":"7616378"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:16:51.478: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1884" for this suite.
Sep 27 21:16:57.495: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:16:57.565: INFO: namespace daemonsets-1884 deletion completed in 6.084115717s

• [SLOW TEST:24.512 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:16:57.565: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-8891
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8891.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-8891.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8891.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-8891.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 27 21:17:19.745: INFO: DNS probes using dns-test-ed1a7ab5-8ccf-4459-8719-a615d10db66d succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8891.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-8891.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8891.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-8891.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 27 21:17:31.822: INFO: File wheezy_udp@dns-test-service-3.dns-8891.svc.cluster.local from pod  dns-8891/dns-test-4782eff2-8da8-498f-9ce9-29aecf66ddd2 contains 'foo.example.com.
' instead of 'bar.example.com.'
Sep 27 21:17:31.824: INFO: File jessie_udp@dns-test-service-3.dns-8891.svc.cluster.local from pod  dns-8891/dns-test-4782eff2-8da8-498f-9ce9-29aecf66ddd2 contains 'foo.example.com.
' instead of 'bar.example.com.'
Sep 27 21:17:31.824: INFO: Lookups using dns-8891/dns-test-4782eff2-8da8-498f-9ce9-29aecf66ddd2 failed for: [wheezy_udp@dns-test-service-3.dns-8891.svc.cluster.local jessie_udp@dns-test-service-3.dns-8891.svc.cluster.local]

Sep 27 21:17:36.828: INFO: File wheezy_udp@dns-test-service-3.dns-8891.svc.cluster.local from pod  dns-8891/dns-test-4782eff2-8da8-498f-9ce9-29aecf66ddd2 contains 'foo.example.com.
' instead of 'bar.example.com.'
Sep 27 21:17:36.830: INFO: File jessie_udp@dns-test-service-3.dns-8891.svc.cluster.local from pod  dns-8891/dns-test-4782eff2-8da8-498f-9ce9-29aecf66ddd2 contains 'foo.example.com.
' instead of 'bar.example.com.'
Sep 27 21:17:36.830: INFO: Lookups using dns-8891/dns-test-4782eff2-8da8-498f-9ce9-29aecf66ddd2 failed for: [wheezy_udp@dns-test-service-3.dns-8891.svc.cluster.local jessie_udp@dns-test-service-3.dns-8891.svc.cluster.local]

Sep 27 21:17:41.828: INFO: File wheezy_udp@dns-test-service-3.dns-8891.svc.cluster.local from pod  dns-8891/dns-test-4782eff2-8da8-498f-9ce9-29aecf66ddd2 contains 'foo.example.com.
' instead of 'bar.example.com.'
Sep 27 21:17:41.830: INFO: Lookups using dns-8891/dns-test-4782eff2-8da8-498f-9ce9-29aecf66ddd2 failed for: [wheezy_udp@dns-test-service-3.dns-8891.svc.cluster.local]

Sep 27 21:17:46.830: INFO: DNS probes using dns-test-4782eff2-8da8-498f-9ce9-29aecf66ddd2 succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8891.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-8891.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8891.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-8891.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 27 21:18:00.941: INFO: DNS probes using dns-test-5de75550-abe7-4b83-a93d-2d205d9392eb succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:18:01.003: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8891" for this suite.
Sep 27 21:18:07.018: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:18:07.095: INFO: namespace dns-8891 deletion completed in 6.089412892s

• [SLOW TEST:69.530 seconds]
[sig-network] DNS
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:18:07.095: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3875
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-map-46382d8d-5c36-40aa-bdb8-12309f6d4785
STEP: Creating a pod to test consume secrets
Sep 27 21:18:07.262: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-bd33ba49-e352-40aa-8937-bdc737a79402" in namespace "projected-3875" to be "success or failure"
Sep 27 21:18:07.264: INFO: Pod "pod-projected-secrets-bd33ba49-e352-40aa-8937-bdc737a79402": Phase="Pending", Reason="", readiness=false. Elapsed: 1.940909ms
Sep 27 21:18:09.276: INFO: Pod "pod-projected-secrets-bd33ba49-e352-40aa-8937-bdc737a79402": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014690102s
STEP: Saw pod success
Sep 27 21:18:09.277: INFO: Pod "pod-projected-secrets-bd33ba49-e352-40aa-8937-bdc737a79402" satisfied condition "success or failure"
Sep 27 21:18:09.279: INFO: Trying to get logs from node macpro-3 pod pod-projected-secrets-bd33ba49-e352-40aa-8937-bdc737a79402 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep 27 21:18:09.319: INFO: Waiting for pod pod-projected-secrets-bd33ba49-e352-40aa-8937-bdc737a79402 to disappear
Sep 27 21:18:09.322: INFO: Pod pod-projected-secrets-bd33ba49-e352-40aa-8937-bdc737a79402 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:18:09.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3875" for this suite.
Sep 27 21:18:15.340: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:18:15.410: INFO: namespace projected-3875 deletion completed in 6.08568222s

• [SLOW TEST:8.315 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:18:15.410: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-6557
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:18:15.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6557" for this suite.
Sep 27 21:18:37.596: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:18:37.667: INFO: namespace pods-6557 deletion completed in 22.092600584s

• [SLOW TEST:22.257 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:18:37.667: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6727
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-71651fc8-c554-43bb-8192-937ae324728d
STEP: Creating a pod to test consume configMaps
Sep 27 21:18:37.837: INFO: Waiting up to 5m0s for pod "pod-configmaps-c720e5b0-11d0-4bde-8306-e1a7b73d0acc" in namespace "configmap-6727" to be "success or failure"
Sep 27 21:18:37.843: INFO: Pod "pod-configmaps-c720e5b0-11d0-4bde-8306-e1a7b73d0acc": Phase="Pending", Reason="", readiness=false. Elapsed: 6.224473ms
Sep 27 21:18:39.846: INFO: Pod "pod-configmaps-c720e5b0-11d0-4bde-8306-e1a7b73d0acc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008739631s
Sep 27 21:18:41.849: INFO: Pod "pod-configmaps-c720e5b0-11d0-4bde-8306-e1a7b73d0acc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011660465s
STEP: Saw pod success
Sep 27 21:18:41.849: INFO: Pod "pod-configmaps-c720e5b0-11d0-4bde-8306-e1a7b73d0acc" satisfied condition "success or failure"
Sep 27 21:18:41.851: INFO: Trying to get logs from node macpro-1 pod pod-configmaps-c720e5b0-11d0-4bde-8306-e1a7b73d0acc container configmap-volume-test: <nil>
STEP: delete the pod
Sep 27 21:18:41.874: INFO: Waiting for pod pod-configmaps-c720e5b0-11d0-4bde-8306-e1a7b73d0acc to disappear
Sep 27 21:18:41.876: INFO: Pod pod-configmaps-c720e5b0-11d0-4bde-8306-e1a7b73d0acc no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:18:41.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6727" for this suite.
Sep 27 21:18:47.897: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:18:47.978: INFO: namespace configmap-6727 deletion completed in 6.099252221s

• [SLOW TEST:10.310 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:18:47.978: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-9513
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod test-webserver-bd583f23-9cef-4e02-881e-eb860f3d646f in namespace container-probe-9513
Sep 27 21:18:50.139: INFO: Started pod test-webserver-bd583f23-9cef-4e02-881e-eb860f3d646f in namespace container-probe-9513
STEP: checking the pod's current state and verifying that restartCount is present
Sep 27 21:18:50.141: INFO: Initial restart count of pod test-webserver-bd583f23-9cef-4e02-881e-eb860f3d646f is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:22:50.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9513" for this suite.
Sep 27 21:22:56.517: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:22:56.591: INFO: namespace container-probe-9513 deletion completed in 6.088250112s

• [SLOW TEST:248.613 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:22:56.591: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5969
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secret-namespace-4406
STEP: Creating secret with name secret-test-de2d663f-cbba-42f4-aae6-fd717669b2f5
STEP: Creating a pod to test consume secrets
Sep 27 21:22:56.905: INFO: Waiting up to 5m0s for pod "pod-secrets-48597ff8-ae4e-4c6d-8c7f-bf0baf1fa7f4" in namespace "secrets-5969" to be "success or failure"
Sep 27 21:22:56.907: INFO: Pod "pod-secrets-48597ff8-ae4e-4c6d-8c7f-bf0baf1fa7f4": Phase="Pending", Reason="", readiness=false. Elapsed: 1.890822ms
Sep 27 21:22:58.910: INFO: Pod "pod-secrets-48597ff8-ae4e-4c6d-8c7f-bf0baf1fa7f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004923881s
STEP: Saw pod success
Sep 27 21:22:58.910: INFO: Pod "pod-secrets-48597ff8-ae4e-4c6d-8c7f-bf0baf1fa7f4" satisfied condition "success or failure"
Sep 27 21:22:58.912: INFO: Trying to get logs from node macpro-3 pod pod-secrets-48597ff8-ae4e-4c6d-8c7f-bf0baf1fa7f4 container secret-volume-test: <nil>
STEP: delete the pod
Sep 27 21:22:58.936: INFO: Waiting for pod pod-secrets-48597ff8-ae4e-4c6d-8c7f-bf0baf1fa7f4 to disappear
Sep 27 21:22:58.938: INFO: Pod pod-secrets-48597ff8-ae4e-4c6d-8c7f-bf0baf1fa7f4 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:22:58.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5969" for this suite.
Sep 27 21:23:04.951: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:23:05.030: INFO: namespace secrets-5969 deletion completed in 6.089662794s
STEP: Destroying namespace "secret-namespace-4406" for this suite.
Sep 27 21:23:11.041: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:23:11.110: INFO: namespace secret-namespace-4406 deletion completed in 6.08042855s

• [SLOW TEST:14.519 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:23:11.110: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-9016
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Sep 27 21:23:13.284: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:23:13.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-9016" for this suite.
Sep 27 21:23:19.326: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:23:19.397: INFO: namespace container-runtime-9016 deletion completed in 6.088804442s

• [SLOW TEST:8.286 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:23:19.397: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4164
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Sep 27 21:23:19.553: INFO: Waiting up to 5m0s for pod "downward-api-1dd0789d-e2e0-405d-9c98-fa444ddab166" in namespace "downward-api-4164" to be "success or failure"
Sep 27 21:23:19.555: INFO: Pod "downward-api-1dd0789d-e2e0-405d-9c98-fa444ddab166": Phase="Pending", Reason="", readiness=false. Elapsed: 1.910092ms
Sep 27 21:23:21.558: INFO: Pod "downward-api-1dd0789d-e2e0-405d-9c98-fa444ddab166": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004866776s
Sep 27 21:23:23.560: INFO: Pod "downward-api-1dd0789d-e2e0-405d-9c98-fa444ddab166": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007735052s
STEP: Saw pod success
Sep 27 21:23:23.560: INFO: Pod "downward-api-1dd0789d-e2e0-405d-9c98-fa444ddab166" satisfied condition "success or failure"
Sep 27 21:23:23.562: INFO: Trying to get logs from node macpro-2 pod downward-api-1dd0789d-e2e0-405d-9c98-fa444ddab166 container dapi-container: <nil>
STEP: delete the pod
Sep 27 21:23:23.593: INFO: Waiting for pod downward-api-1dd0789d-e2e0-405d-9c98-fa444ddab166 to disappear
Sep 27 21:23:23.595: INFO: Pod downward-api-1dd0789d-e2e0-405d-9c98-fa444ddab166 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:23:23.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4164" for this suite.
Sep 27 21:23:29.609: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:23:29.679: INFO: namespace downward-api-4164 deletion completed in 6.081347409s

• [SLOW TEST:10.281 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:23:29.679: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-7219
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 27 21:23:29.828: INFO: Creating deployment "nginx-deployment"
Sep 27 21:23:29.843: INFO: Waiting for observed generation 1
Sep 27 21:23:31.864: INFO: Waiting for all required pods to come up
Sep 27 21:23:31.867: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Sep 27 21:23:33.872: INFO: Waiting for deployment "nginx-deployment" to complete
Sep 27 21:23:33.877: INFO: Updating deployment "nginx-deployment" with a non-existent image
Sep 27 21:23:33.891: INFO: Updating deployment nginx-deployment
Sep 27 21:23:33.891: INFO: Waiting for observed generation 2
Sep 27 21:23:35.896: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Sep 27 21:23:35.898: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Sep 27 21:23:35.899: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Sep 27 21:23:35.906: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Sep 27 21:23:35.906: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Sep 27 21:23:35.908: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Sep 27 21:23:35.912: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Sep 27 21:23:35.912: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Sep 27 21:23:35.920: INFO: Updating deployment nginx-deployment
Sep 27 21:23:35.920: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Sep 27 21:23:35.926: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Sep 27 21:23:35.942: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Sep 27 21:23:35.992: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-7219,SelfLink:/apis/apps/v1/namespaces/deployment-7219/deployments/nginx-deployment,UID:e00e3aa4-01b1-44b5-bb99-619e7e91eca2,ResourceVersion:7617813,Generation:3,CreationTimestamp:2019-09-27 21:23:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Progressing True 2019-09-27 21:23:34 +0000 UTC 2019-09-27 21:23:29 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-55fb7cb77f" is progressing.} {Available False 2019-09-27 21:23:35 +0000 UTC 2019-09-27 21:23:35 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}],ReadyReplicas:8,CollisionCount:nil,},}

Sep 27 21:23:36.064: INFO: New ReplicaSet "nginx-deployment-55fb7cb77f" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f,GenerateName:,Namespace:deployment-7219,SelfLink:/apis/apps/v1/namespaces/deployment-7219/replicasets/nginx-deployment-55fb7cb77f,UID:464dcacc-c7ef-4d6a-a092-97666fe85bc8,ResourceVersion:7617855,Generation:3,CreationTimestamp:2019-09-27 21:23:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment e00e3aa4-01b1-44b5-bb99-619e7e91eca2 0xc002742957 0xc002742958}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep 27 21:23:36.064: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Sep 27 21:23:36.064: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498,GenerateName:,Namespace:deployment-7219,SelfLink:/apis/apps/v1/namespaces/deployment-7219/replicasets/nginx-deployment-7b8c6f4498,UID:fdda612b-e0af-4ed7-a50c-0aa10e2c1972,ResourceVersion:7617856,Generation:3,CreationTimestamp:2019-09-27 21:23:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment e00e3aa4-01b1-44b5-bb99-619e7e91eca2 0xc002742a27 0xc002742a28}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Sep 27 21:23:36.099: INFO: Pod "nginx-deployment-55fb7cb77f-2hx8r" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-2hx8r,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-7219,SelfLink:/api/v1/namespaces/deployment-7219/pods/nginx-deployment-55fb7cb77f-2hx8r,UID:a37ff280-cba8-4853-b27b-a03dfdb7ccdc,ResourceVersion:7617836,Generation:0,CreationTimestamp:2019-09-27 21:23:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 464dcacc-c7ef-4d6a-a092-97666fe85bc8 0xc002743397 0xc002743398}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-p4whc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-p4whc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-p4whc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:macpro-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002743410} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002743430}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:35 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 27 21:23:36.099: INFO: Pod "nginx-deployment-55fb7cb77f-5mhhb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-5mhhb,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-7219,SelfLink:/api/v1/namespaces/deployment-7219/pods/nginx-deployment-55fb7cb77f-5mhhb,UID:bc2ec8ce-02e5-41d3-9049-58c95fd1cf0d,ResourceVersion:7617860,Generation:0,CreationTimestamp:2019-09-27 21:23:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 464dcacc-c7ef-4d6a-a092-97666fe85bc8 0xc0027434b7 0xc0027434b8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-p4whc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-p4whc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-p4whc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:macpro-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002743530} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002743550}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:36 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 27 21:23:36.099: INFO: Pod "nginx-deployment-55fb7cb77f-8l2cq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-8l2cq,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-7219,SelfLink:/api/v1/namespaces/deployment-7219/pods/nginx-deployment-55fb7cb77f-8l2cq,UID:c9f8cb74-7a43-42d9-8965-84cefd598a0d,ResourceVersion:7617845,Generation:0,CreationTimestamp:2019-09-27 21:23:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 464dcacc-c7ef-4d6a-a092-97666fe85bc8 0xc0027435d7 0xc0027435d8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-p4whc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-p4whc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-p4whc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:macpro-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002743650} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002743670}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:36 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 27 21:23:36.099: INFO: Pod "nginx-deployment-55fb7cb77f-b8hdd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-b8hdd,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-7219,SelfLink:/api/v1/namespaces/deployment-7219/pods/nginx-deployment-55fb7cb77f-b8hdd,UID:44e00ecb-50c5-4da1-9941-6ff3cdc1b4b5,ResourceVersion:7617847,Generation:0,CreationTimestamp:2019-09-27 21:23:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 464dcacc-c7ef-4d6a-a092-97666fe85bc8 0xc0027436f7 0xc0027436f8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-p4whc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-p4whc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-p4whc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:macpro-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002743770} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002743790}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:36 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 27 21:23:36.100: INFO: Pod "nginx-deployment-55fb7cb77f-bhgrf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-bhgrf,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-7219,SelfLink:/api/v1/namespaces/deployment-7219/pods/nginx-deployment-55fb7cb77f-bhgrf,UID:64f79bd4-e018-4528-834a-5ce69da63765,ResourceVersion:7617794,Generation:0,CreationTimestamp:2019-09-27 21:23:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.151.213/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 464dcacc-c7ef-4d6a-a092-97666fe85bc8 0xc002743817 0xc002743818}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-p4whc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-p4whc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-p4whc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:macpro-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002743890} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0027438b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:33 +0000 UTC  }],Message:,Reason:,HostIP:10.10.10.4,PodIP:192.168.151.213,StartTime:2019-09-27 21:23:33 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 27 21:23:36.100: INFO: Pod "nginx-deployment-55fb7cb77f-d8mvq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-d8mvq,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-7219,SelfLink:/api/v1/namespaces/deployment-7219/pods/nginx-deployment-55fb7cb77f-d8mvq,UID:c89f5dd3-a82d-43f5-989b-3a5e27a2924e,ResourceVersion:7617810,Generation:0,CreationTimestamp:2019-09-27 21:23:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.153.29/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 464dcacc-c7ef-4d6a-a092-97666fe85bc8 0xc0027439a0 0xc0027439a1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-p4whc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-p4whc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-p4whc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:macpro-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002743a20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002743a40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:33 +0000 UTC  }],Message:,Reason:,HostIP:10.10.10.6,PodIP:192.168.153.29,StartTime:2019-09-27 21:23:33 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 27 21:23:36.100: INFO: Pod "nginx-deployment-55fb7cb77f-gcxrv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-gcxrv,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-7219,SelfLink:/api/v1/namespaces/deployment-7219/pods/nginx-deployment-55fb7cb77f-gcxrv,UID:4a5df04c-50e8-460e-99d9-b74aaec3e7af,ResourceVersion:7617797,Generation:0,CreationTimestamp:2019-09-27 21:23:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.151.212/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 464dcacc-c7ef-4d6a-a092-97666fe85bc8 0xc002743b30 0xc002743b31}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-p4whc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-p4whc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-p4whc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:macpro-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002743bb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002743bd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:34 +0000 UTC  }],Message:,Reason:,HostIP:10.10.10.4,PodIP:192.168.151.212,StartTime:2019-09-27 21:23:34 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 27 21:23:36.100: INFO: Pod "nginx-deployment-55fb7cb77f-hmbmc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-hmbmc,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-7219,SelfLink:/api/v1/namespaces/deployment-7219/pods/nginx-deployment-55fb7cb77f-hmbmc,UID:3a4e79b0-99a1-4dad-a2ea-1781d3813c6f,ResourceVersion:7617851,Generation:0,CreationTimestamp:2019-09-27 21:23:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 464dcacc-c7ef-4d6a-a092-97666fe85bc8 0xc002743cc0 0xc002743cc1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-p4whc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-p4whc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-p4whc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:macpro-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002743d40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002743d60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:36 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 27 21:23:36.100: INFO: Pod "nginx-deployment-55fb7cb77f-hv2zp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-hv2zp,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-7219,SelfLink:/api/v1/namespaces/deployment-7219/pods/nginx-deployment-55fb7cb77f-hv2zp,UID:feed4507-a4cb-4766-bcad-a8f922ab0678,ResourceVersion:7617791,Generation:0,CreationTimestamp:2019-09-27 21:23:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.150.156/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 464dcacc-c7ef-4d6a-a092-97666fe85bc8 0xc002743de7 0xc002743de8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-p4whc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-p4whc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-p4whc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:macpro-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002743e60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002743e80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:33 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:33 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:33 +0000 UTC  }],Message:,Reason:,HostIP:10.10.10.5,PodIP:192.168.150.156,StartTime:2019-09-27 21:23:33 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 27 21:23:36.100: INFO: Pod "nginx-deployment-55fb7cb77f-n7ssh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-n7ssh,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-7219,SelfLink:/api/v1/namespaces/deployment-7219/pods/nginx-deployment-55fb7cb77f-n7ssh,UID:9b54f2f3-02c7-462b-9d4f-77837cf36cee,ResourceVersion:7617788,Generation:0,CreationTimestamp:2019-09-27 21:23:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.150.157/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 464dcacc-c7ef-4d6a-a092-97666fe85bc8 0xc002743f70 0xc002743f71}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-p4whc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-p4whc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-p4whc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:macpro-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002743ff0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003102010}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:34 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:34 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:34 +0000 UTC  }],Message:,Reason:,HostIP:10.10.10.5,PodIP:192.168.150.157,StartTime:2019-09-27 21:23:34 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 27 21:23:36.100: INFO: Pod "nginx-deployment-55fb7cb77f-qd67q" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-qd67q,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-7219,SelfLink:/api/v1/namespaces/deployment-7219/pods/nginx-deployment-55fb7cb77f-qd67q,UID:77bf8937-8da7-4449-97a1-c2502ddee552,ResourceVersion:7617846,Generation:0,CreationTimestamp:2019-09-27 21:23:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 464dcacc-c7ef-4d6a-a092-97666fe85bc8 0xc003102100 0xc003102101}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-p4whc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-p4whc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-p4whc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:macpro-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003102180} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0031021a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:36 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 27 21:23:36.100: INFO: Pod "nginx-deployment-55fb7cb77f-s5t7s" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-s5t7s,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-7219,SelfLink:/api/v1/namespaces/deployment-7219/pods/nginx-deployment-55fb7cb77f-s5t7s,UID:d362338f-efaa-4410-908b-d18f4e59773a,ResourceVersion:7617835,Generation:0,CreationTimestamp:2019-09-27 21:23:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 464dcacc-c7ef-4d6a-a092-97666fe85bc8 0xc003102227 0xc003102228}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-p4whc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-p4whc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-p4whc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:macpro-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0031022a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0031022c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:35 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 27 21:23:36.101: INFO: Pod "nginx-deployment-55fb7cb77f-zhnsh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-zhnsh,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-7219,SelfLink:/api/v1/namespaces/deployment-7219/pods/nginx-deployment-55fb7cb77f-zhnsh,UID:292251fd-5b0a-4328-b88c-090450a981f2,ResourceVersion:7617857,Generation:0,CreationTimestamp:2019-09-27 21:23:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 464dcacc-c7ef-4d6a-a092-97666fe85bc8 0xc003102347 0xc003102348}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-p4whc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-p4whc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-p4whc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:macpro-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0031023c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0031023e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:35 +0000 UTC  }],Message:,Reason:,HostIP:10.10.10.6,PodIP:,StartTime:2019-09-27 21:23:36 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 27 21:23:36.101: INFO: Pod "nginx-deployment-7b8c6f4498-4567b" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-4567b,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-7219,SelfLink:/api/v1/namespaces/deployment-7219/pods/nginx-deployment-7b8c6f4498-4567b,UID:dd5b0d4a-1236-48d3-bb10-0ddd1a691202,ResourceVersion:7617661,Generation:0,CreationTimestamp:2019-09-27 21:23:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.151.197/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 fdda612b-e0af-4ed7-a50c-0aa10e2c1972 0xc0031024b0 0xc0031024b1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-p4whc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-p4whc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-p4whc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:macpro-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003102520} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003102540}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:29 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:31 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:31 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:29 +0000 UTC  }],Message:,Reason:,HostIP:10.10.10.4,PodIP:192.168.151.197,StartTime:2019-09-27 21:23:29 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-27 21:23:31 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://2dd5110e63153ddbab2d9546b090cedf7da9ed914a20686b2012e8d57b52bdda}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 27 21:23:36.101: INFO: Pod "nginx-deployment-7b8c6f4498-4w8s9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-4w8s9,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-7219,SelfLink:/api/v1/namespaces/deployment-7219/pods/nginx-deployment-7b8c6f4498-4w8s9,UID:6081f2e7-1338-4a8f-b51d-fe011054413f,ResourceVersion:7617863,Generation:0,CreationTimestamp:2019-09-27 21:23:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 fdda612b-e0af-4ed7-a50c-0aa10e2c1972 0xc003102617 0xc003102618}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-p4whc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-p4whc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-p4whc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:macpro-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003102690} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0031026b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:35 +0000 UTC  }],Message:,Reason:,HostIP:10.10.10.4,PodIP:,StartTime:2019-09-27 21:23:36 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 27 21:23:36.101: INFO: Pod "nginx-deployment-7b8c6f4498-69445" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-69445,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-7219,SelfLink:/api/v1/namespaces/deployment-7219/pods/nginx-deployment-7b8c6f4498-69445,UID:c98a368e-4603-483f-850a-c7497e827c67,ResourceVersion:7617839,Generation:0,CreationTimestamp:2019-09-27 21:23:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 fdda612b-e0af-4ed7-a50c-0aa10e2c1972 0xc003102777 0xc003102778}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-p4whc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-p4whc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-p4whc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:macpro-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0031027f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003102810}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:35 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 27 21:23:36.101: INFO: Pod "nginx-deployment-7b8c6f4498-69t54" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-69t54,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-7219,SelfLink:/api/v1/namespaces/deployment-7219/pods/nginx-deployment-7b8c6f4498-69t54,UID:dc3106c9-e302-4a1a-81ad-8edf1105015b,ResourceVersion:7617667,Generation:0,CreationTimestamp:2019-09-27 21:23:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.151.210/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 fdda612b-e0af-4ed7-a50c-0aa10e2c1972 0xc003102897 0xc003102898}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-p4whc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-p4whc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-p4whc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:macpro-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003102910} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003102930}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:29 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:31 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:31 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:29 +0000 UTC  }],Message:,Reason:,HostIP:10.10.10.4,PodIP:192.168.151.210,StartTime:2019-09-27 21:23:29 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-27 21:23:31 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://950f990cff65f9f4ace9e9966467abd38dfe43b08d23453d00a10a5a92a8aeac}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 27 21:23:36.101: INFO: Pod "nginx-deployment-7b8c6f4498-6wrxc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-6wrxc,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-7219,SelfLink:/api/v1/namespaces/deployment-7219/pods/nginx-deployment-7b8c6f4498-6wrxc,UID:4d02e465-25c0-4818-91d9-4e4dfb0e5a9e,ResourceVersion:7617837,Generation:0,CreationTimestamp:2019-09-27 21:23:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 fdda612b-e0af-4ed7-a50c-0aa10e2c1972 0xc003102a07 0xc003102a08}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-p4whc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-p4whc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-p4whc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:macpro-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003102a80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003102aa0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:35 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 27 21:23:36.101: INFO: Pod "nginx-deployment-7b8c6f4498-72cpt" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-72cpt,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-7219,SelfLink:/api/v1/namespaces/deployment-7219/pods/nginx-deployment-7b8c6f4498-72cpt,UID:6fa602fb-84b6-41dd-b1a0-80c3dc6a94d9,ResourceVersion:7617688,Generation:0,CreationTimestamp:2019-09-27 21:23:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.153.27/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 fdda612b-e0af-4ed7-a50c-0aa10e2c1972 0xc003102b27 0xc003102b28}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-p4whc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-p4whc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-p4whc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:macpro-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003102ba0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003102bc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:29 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:31 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:31 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:29 +0000 UTC  }],Message:,Reason:,HostIP:10.10.10.6,PodIP:192.168.153.27,StartTime:2019-09-27 21:23:29 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-27 21:23:31 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://2b5e5114385732c2f5742c6a6f1a15fd004d32ccf67b224679807c3f13e9296c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 27 21:23:36.101: INFO: Pod "nginx-deployment-7b8c6f4498-bmn5z" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-bmn5z,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-7219,SelfLink:/api/v1/namespaces/deployment-7219/pods/nginx-deployment-7b8c6f4498-bmn5z,UID:981fbc62-6984-47a8-8cec-4e60dc7440cf,ResourceVersion:7617840,Generation:0,CreationTimestamp:2019-09-27 21:23:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 fdda612b-e0af-4ed7-a50c-0aa10e2c1972 0xc003102c97 0xc003102c98}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-p4whc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-p4whc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-p4whc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:macpro-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003102d10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003102d30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:35 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 27 21:23:36.101: INFO: Pod "nginx-deployment-7b8c6f4498-cc44k" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-cc44k,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-7219,SelfLink:/api/v1/namespaces/deployment-7219/pods/nginx-deployment-7b8c6f4498-cc44k,UID:64ccceae-1156-4964-8566-ff410f0045b8,ResourceVersion:7617858,Generation:0,CreationTimestamp:2019-09-27 21:23:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 fdda612b-e0af-4ed7-a50c-0aa10e2c1972 0xc003102db7 0xc003102db8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-p4whc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-p4whc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-p4whc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:macpro-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003102e30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003102e50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:35 +0000 UTC  }],Message:,Reason:,HostIP:10.10.10.5,PodIP:,StartTime:2019-09-27 21:23:36 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 27 21:23:36.102: INFO: Pod "nginx-deployment-7b8c6f4498-cql2w" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-cql2w,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-7219,SelfLink:/api/v1/namespaces/deployment-7219/pods/nginx-deployment-7b8c6f4498-cql2w,UID:35466bf1-6518-412b-bb1e-e1e79ca6faad,ResourceVersion:7617848,Generation:0,CreationTimestamp:2019-09-27 21:23:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 fdda612b-e0af-4ed7-a50c-0aa10e2c1972 0xc003102f17 0xc003102f18}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-p4whc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-p4whc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-p4whc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:macpro-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003102f90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003102fb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:36 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 27 21:23:36.102: INFO: Pod "nginx-deployment-7b8c6f4498-grkcr" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-grkcr,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-7219,SelfLink:/api/v1/namespaces/deployment-7219/pods/nginx-deployment-7b8c6f4498-grkcr,UID:590fafa5-52e6-41ed-97a1-1d829dfe241b,ResourceVersion:7617675,Generation:0,CreationTimestamp:2019-09-27 21:23:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.150.154/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 fdda612b-e0af-4ed7-a50c-0aa10e2c1972 0xc003103037 0xc003103038}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-p4whc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-p4whc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-p4whc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:macpro-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0031030b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0031030d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:29 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:31 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:31 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:29 +0000 UTC  }],Message:,Reason:,HostIP:10.10.10.5,PodIP:192.168.150.154,StartTime:2019-09-27 21:23:29 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-27 21:23:31 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://e2d7c1cf52d2ee115617814a2b92f5be686f440a8a207565ddbbd413ee42d59e}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 27 21:23:36.102: INFO: Pod "nginx-deployment-7b8c6f4498-j4pqs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-j4pqs,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-7219,SelfLink:/api/v1/namespaces/deployment-7219/pods/nginx-deployment-7b8c6f4498-j4pqs,UID:93143cb3-3a77-4122-b7a9-57464deae697,ResourceVersion:7617841,Generation:0,CreationTimestamp:2019-09-27 21:23:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 fdda612b-e0af-4ed7-a50c-0aa10e2c1972 0xc0031031a7 0xc0031031a8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-p4whc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-p4whc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-p4whc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:macpro-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003103220} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003103240}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:35 +0000 UTC  }],Message:,Reason:,HostIP:10.10.10.4,PodIP:,StartTime:2019-09-27 21:23:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 27 21:23:36.102: INFO: Pod "nginx-deployment-7b8c6f4498-jsfrd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-jsfrd,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-7219,SelfLink:/api/v1/namespaces/deployment-7219/pods/nginx-deployment-7b8c6f4498-jsfrd,UID:97ab3993-fe0c-4a4f-87a6-7e8b6889bfd8,ResourceVersion:7617852,Generation:0,CreationTimestamp:2019-09-27 21:23:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 fdda612b-e0af-4ed7-a50c-0aa10e2c1972 0xc003103307 0xc003103308}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-p4whc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-p4whc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-p4whc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:macpro-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003103380} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0031033a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:36 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 27 21:23:36.102: INFO: Pod "nginx-deployment-7b8c6f4498-k6xs9" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-k6xs9,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-7219,SelfLink:/api/v1/namespaces/deployment-7219/pods/nginx-deployment-7b8c6f4498-k6xs9,UID:346e8c73-e211-488e-aeef-034a0724c5d8,ResourceVersion:7617682,Generation:0,CreationTimestamp:2019-09-27 21:23:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.153.25/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 fdda612b-e0af-4ed7-a50c-0aa10e2c1972 0xc003103427 0xc003103428}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-p4whc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-p4whc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-p4whc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:macpro-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0031034a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0031034c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:29 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:31 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:31 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:29 +0000 UTC  }],Message:,Reason:,HostIP:10.10.10.6,PodIP:192.168.153.25,StartTime:2019-09-27 21:23:29 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-27 21:23:31 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://cb49e0652c4832c0ee17fee3808657fb666b565cf8d57356a85eab6ab03f9e0c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 27 21:23:36.102: INFO: Pod "nginx-deployment-7b8c6f4498-kn6k8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-kn6k8,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-7219,SelfLink:/api/v1/namespaces/deployment-7219/pods/nginx-deployment-7b8c6f4498-kn6k8,UID:c69ada1d-65dd-40b9-98ad-5d8bdbb54184,ResourceVersion:7617850,Generation:0,CreationTimestamp:2019-09-27 21:23:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 fdda612b-e0af-4ed7-a50c-0aa10e2c1972 0xc003103597 0xc003103598}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-p4whc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-p4whc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-p4whc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:macpro-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003103610} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003103630}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:36 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 27 21:23:36.102: INFO: Pod "nginx-deployment-7b8c6f4498-mgmgt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-mgmgt,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-7219,SelfLink:/api/v1/namespaces/deployment-7219/pods/nginx-deployment-7b8c6f4498-mgmgt,UID:5ee19243-2ce0-471a-8b55-16f4428f775d,ResourceVersion:7617853,Generation:0,CreationTimestamp:2019-09-27 21:23:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 fdda612b-e0af-4ed7-a50c-0aa10e2c1972 0xc0031036b7 0xc0031036b8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-p4whc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-p4whc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-p4whc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:macpro-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003103730} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003103750}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:36 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 27 21:23:36.102: INFO: Pod "nginx-deployment-7b8c6f4498-mkt9l" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-mkt9l,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-7219,SelfLink:/api/v1/namespaces/deployment-7219/pods/nginx-deployment-7b8c6f4498-mkt9l,UID:3b6e256c-e63b-48f7-a9a1-606e6bc0d149,ResourceVersion:7617670,Generation:0,CreationTimestamp:2019-09-27 21:23:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.150.153/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 fdda612b-e0af-4ed7-a50c-0aa10e2c1972 0xc0031037d7 0xc0031037d8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-p4whc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-p4whc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-p4whc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:macpro-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003103850} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003103870}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:29 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:31 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:31 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:29 +0000 UTC  }],Message:,Reason:,HostIP:10.10.10.5,PodIP:192.168.150.153,StartTime:2019-09-27 21:23:29 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-27 21:23:31 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://f56a7ec00e1700c8cd83e31568ee9d82289a392e4638bb9abcd01b50df737903}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 27 21:23:36.102: INFO: Pod "nginx-deployment-7b8c6f4498-tmw4n" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-tmw4n,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-7219,SelfLink:/api/v1/namespaces/deployment-7219/pods/nginx-deployment-7b8c6f4498-tmw4n,UID:5621aa9e-bed8-40de-8cba-62a0b07c8bff,ResourceVersion:7617838,Generation:0,CreationTimestamp:2019-09-27 21:23:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 fdda612b-e0af-4ed7-a50c-0aa10e2c1972 0xc003103947 0xc003103948}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-p4whc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-p4whc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-p4whc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:macpro-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0031039c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0031039e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:35 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 27 21:23:36.102: INFO: Pod "nginx-deployment-7b8c6f4498-vnhj6" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-vnhj6,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-7219,SelfLink:/api/v1/namespaces/deployment-7219/pods/nginx-deployment-7b8c6f4498-vnhj6,UID:efda2272-4598-407d-979a-8f7c37a637e7,ResourceVersion:7617679,Generation:0,CreationTimestamp:2019-09-27 21:23:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.153.26/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 fdda612b-e0af-4ed7-a50c-0aa10e2c1972 0xc003103a67 0xc003103a68}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-p4whc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-p4whc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-p4whc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:macpro-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003103ae0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003103b00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:29 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:31 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:31 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:29 +0000 UTC  }],Message:,Reason:,HostIP:10.10.10.6,PodIP:192.168.153.26,StartTime:2019-09-27 21:23:29 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-27 21:23:31 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://db0f9e58e6b6b8aafda87902f75463ecae9735ad4ab546c6526f9fd713fbe020}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 27 21:23:36.103: INFO: Pod "nginx-deployment-7b8c6f4498-z4zcx" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-z4zcx,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-7219,SelfLink:/api/v1/namespaces/deployment-7219/pods/nginx-deployment-7b8c6f4498-z4zcx,UID:f112d1f3-b2c0-4054-a80a-2570c32b08b7,ResourceVersion:7617685,Generation:0,CreationTimestamp:2019-09-27 21:23:29 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.153.28/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 fdda612b-e0af-4ed7-a50c-0aa10e2c1972 0xc003103bd7 0xc003103bd8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-p4whc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-p4whc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-p4whc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:macpro-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003103c50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003103c70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:29 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:31 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:31 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:29 +0000 UTC  }],Message:,Reason:,HostIP:10.10.10.6,PodIP:192.168.153.28,StartTime:2019-09-27 21:23:29 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-27 21:23:31 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://d839074a2a21dd435e02b766f3230910ed9b3b329992ecbe2ef6c5700af26694}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 27 21:23:36.103: INFO: Pod "nginx-deployment-7b8c6f4498-zcjgc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-zcjgc,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-7219,SelfLink:/api/v1/namespaces/deployment-7219/pods/nginx-deployment-7b8c6f4498-zcjgc,UID:323ee260-c54f-434f-bb74-ff01c8aaba22,ResourceVersion:7617849,Generation:0,CreationTimestamp:2019-09-27 21:23:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 fdda612b-e0af-4ed7-a50c-0aa10e2c1972 0xc003103d47 0xc003103d48}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-p4whc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-p4whc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-p4whc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:macpro-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003103dc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003103de0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:23:36 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:23:36.103: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7219" for this suite.
Sep 27 21:23:44.146: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:23:44.215: INFO: namespace deployment-7219 deletion completed in 8.105959047s

• [SLOW TEST:14.536 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:23:44.215: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3934
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep 27 21:23:44.374: INFO: Waiting up to 5m0s for pod "downwardapi-volume-86be10b6-0413-4ab1-a7f6-3f504879269c" in namespace "downward-api-3934" to be "success or failure"
Sep 27 21:23:44.376: INFO: Pod "downwardapi-volume-86be10b6-0413-4ab1-a7f6-3f504879269c": Phase="Pending", Reason="", readiness=false. Elapsed: 1.885559ms
Sep 27 21:23:46.379: INFO: Pod "downwardapi-volume-86be10b6-0413-4ab1-a7f6-3f504879269c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00519062s
STEP: Saw pod success
Sep 27 21:23:46.379: INFO: Pod "downwardapi-volume-86be10b6-0413-4ab1-a7f6-3f504879269c" satisfied condition "success or failure"
Sep 27 21:23:46.381: INFO: Trying to get logs from node macpro-3 pod downwardapi-volume-86be10b6-0413-4ab1-a7f6-3f504879269c container client-container: <nil>
STEP: delete the pod
Sep 27 21:23:46.402: INFO: Waiting for pod downwardapi-volume-86be10b6-0413-4ab1-a7f6-3f504879269c to disappear
Sep 27 21:23:46.403: INFO: Pod downwardapi-volume-86be10b6-0413-4ab1-a7f6-3f504879269c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:23:46.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3934" for this suite.
Sep 27 21:23:52.417: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:23:52.493: INFO: namespace downward-api-3934 deletion completed in 6.087523336s

• [SLOW TEST:8.278 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:23:52.493: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9474
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: executing a command with run --rm and attach with stdin
Sep 27 21:23:52.645: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 --namespace=kubectl-9474 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Sep 27 21:23:55.803: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Sep 27 21:23:55.803: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:23:57.808: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9474" for this suite.
Sep 27 21:24:03.822: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:24:03.896: INFO: namespace kubectl-9474 deletion completed in 6.085540949s

• [SLOW TEST:11.403 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:24:03.896: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7618
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on node default medium
Sep 27 21:24:04.056: INFO: Waiting up to 5m0s for pod "pod-3d497a91-765c-40e7-977f-2640ada20ce4" in namespace "emptydir-7618" to be "success or failure"
Sep 27 21:24:04.058: INFO: Pod "pod-3d497a91-765c-40e7-977f-2640ada20ce4": Phase="Pending", Reason="", readiness=false. Elapsed: 1.778962ms
Sep 27 21:24:06.061: INFO: Pod "pod-3d497a91-765c-40e7-977f-2640ada20ce4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004323387s
STEP: Saw pod success
Sep 27 21:24:06.061: INFO: Pod "pod-3d497a91-765c-40e7-977f-2640ada20ce4" satisfied condition "success or failure"
Sep 27 21:24:06.063: INFO: Trying to get logs from node macpro-1 pod pod-3d497a91-765c-40e7-977f-2640ada20ce4 container test-container: <nil>
STEP: delete the pod
Sep 27 21:24:06.086: INFO: Waiting for pod pod-3d497a91-765c-40e7-977f-2640ada20ce4 to disappear
Sep 27 21:24:06.088: INFO: Pod pod-3d497a91-765c-40e7-977f-2640ada20ce4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:24:06.088: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7618" for this suite.
Sep 27 21:24:12.109: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:24:12.179: INFO: namespace emptydir-7618 deletion completed in 6.088526267s

• [SLOW TEST:8.283 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:24:12.179: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1901
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on node default medium
Sep 27 21:24:12.339: INFO: Waiting up to 5m0s for pod "pod-004e20f6-7270-43cf-bf83-a334fe504ec4" in namespace "emptydir-1901" to be "success or failure"
Sep 27 21:24:12.341: INFO: Pod "pod-004e20f6-7270-43cf-bf83-a334fe504ec4": Phase="Pending", Reason="", readiness=false. Elapsed: 1.873229ms
Sep 27 21:24:14.343: INFO: Pod "pod-004e20f6-7270-43cf-bf83-a334fe504ec4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004566329s
STEP: Saw pod success
Sep 27 21:24:14.343: INFO: Pod "pod-004e20f6-7270-43cf-bf83-a334fe504ec4" satisfied condition "success or failure"
Sep 27 21:24:14.345: INFO: Trying to get logs from node macpro-3 pod pod-004e20f6-7270-43cf-bf83-a334fe504ec4 container test-container: <nil>
STEP: delete the pod
Sep 27 21:24:14.368: INFO: Waiting for pod pod-004e20f6-7270-43cf-bf83-a334fe504ec4 to disappear
Sep 27 21:24:14.369: INFO: Pod pod-004e20f6-7270-43cf-bf83-a334fe504ec4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:24:14.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1901" for this suite.
Sep 27 21:24:20.387: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:24:20.458: INFO: namespace emptydir-1901 deletion completed in 6.085988914s

• [SLOW TEST:8.279 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:24:20.458: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8918
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Sep 27 21:24:23.137: INFO: Successfully updated pod "annotationupdatec46040ca-086b-4eee-9488-59bdfb05cc23"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:24:25.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8918" for this suite.
Sep 27 21:24:47.161: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:24:47.236: INFO: namespace downward-api-8918 deletion completed in 22.085265864s

• [SLOW TEST:26.778 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:24:47.236: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-5092
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-rprh2 in namespace proxy-5092
I0927 21:24:47.431799      18 runners.go:180] Created replication controller with name: proxy-service-rprh2, namespace: proxy-5092, replica count: 1
I0927 21:24:48.482207      18 runners.go:180] proxy-service-rprh2 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0927 21:24:49.482372      18 runners.go:180] proxy-service-rprh2 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0927 21:24:50.482558      18 runners.go:180] proxy-service-rprh2 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0927 21:24:51.482648      18 runners.go:180] proxy-service-rprh2 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0927 21:24:52.482817      18 runners.go:180] proxy-service-rprh2 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0927 21:24:53.482982      18 runners.go:180] proxy-service-rprh2 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0927 21:24:54.483191      18 runners.go:180] proxy-service-rprh2 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0927 21:24:55.483346      18 runners.go:180] proxy-service-rprh2 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0927 21:24:56.483451      18 runners.go:180] proxy-service-rprh2 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0927 21:24:57.483617      18 runners.go:180] proxy-service-rprh2 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0927 21:24:58.483767      18 runners.go:180] proxy-service-rprh2 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0927 21:24:59.483928      18 runners.go:180] proxy-service-rprh2 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Sep 27 21:24:59.486: INFO: setup took 12.096490168s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Sep 27 21:24:59.490: INFO: (0) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx/proxy/rewriteme">test</a> (200; 3.846648ms)
Sep 27 21:24:59.490: INFO: (0) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:162/proxy/: bar (200; 4.023574ms)
Sep 27 21:24:59.490: INFO: (0) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:1080/proxy/rewriteme">test<... (200; 4.053128ms)
Sep 27 21:24:59.490: INFO: (0) /api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:160/proxy/: foo (200; 4.05179ms)
Sep 27 21:24:59.490: INFO: (0) /api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:1080/proxy/rewriteme">... (200; 4.117656ms)
Sep 27 21:24:59.490: INFO: (0) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:160/proxy/: foo (200; 4.070433ms)
Sep 27 21:24:59.490: INFO: (0) /api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:162/proxy/: bar (200; 4.241769ms)
Sep 27 21:24:59.490: INFO: (0) /api/v1/namespaces/proxy-5092/services/http:proxy-service-rprh2:portname1/proxy/: foo (200; 4.442704ms)
Sep 27 21:24:59.491: INFO: (0) /api/v1/namespaces/proxy-5092/services/proxy-service-rprh2:portname1/proxy/: foo (200; 5.189257ms)
Sep 27 21:24:59.491: INFO: (0) /api/v1/namespaces/proxy-5092/services/http:proxy-service-rprh2:portname2/proxy/: bar (200; 5.267563ms)
Sep 27 21:24:59.491: INFO: (0) /api/v1/namespaces/proxy-5092/services/proxy-service-rprh2:portname2/proxy/: bar (200; 5.34168ms)
Sep 27 21:24:59.495: INFO: (0) /api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:443/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:443/proxy/tlsrewritem... (200; 8.604378ms)
Sep 27 21:24:59.495: INFO: (0) /api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:460/proxy/: tls baz (200; 8.73834ms)
Sep 27 21:24:59.495: INFO: (0) /api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:462/proxy/: tls qux (200; 8.755721ms)
Sep 27 21:24:59.495: INFO: (0) /api/v1/namespaces/proxy-5092/services/https:proxy-service-rprh2:tlsportname1/proxy/: tls baz (200; 9.08961ms)
Sep 27 21:24:59.496: INFO: (0) /api/v1/namespaces/proxy-5092/services/https:proxy-service-rprh2:tlsportname2/proxy/: tls qux (200; 10.310158ms)
Sep 27 21:24:59.499: INFO: (1) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:160/proxy/: foo (200; 2.727018ms)
Sep 27 21:24:59.499: INFO: (1) /api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:460/proxy/: tls baz (200; 2.854212ms)
Sep 27 21:24:59.499: INFO: (1) /api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:160/proxy/: foo (200; 2.900278ms)
Sep 27 21:24:59.499: INFO: (1) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:1080/proxy/rewriteme">test<... (200; 2.968894ms)
Sep 27 21:24:59.499: INFO: (1) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:162/proxy/: bar (200; 3.017818ms)
Sep 27 21:24:59.499: INFO: (1) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx/proxy/rewriteme">test</a> (200; 3.041753ms)
Sep 27 21:24:59.500: INFO: (1) /api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:443/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:443/proxy/tlsrewritem... (200; 3.064952ms)
Sep 27 21:24:59.500: INFO: (1) /api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:462/proxy/: tls qux (200; 3.215004ms)
Sep 27 21:24:59.500: INFO: (1) /api/v1/namespaces/proxy-5092/services/https:proxy-service-rprh2:tlsportname1/proxy/: tls baz (200; 3.869979ms)
Sep 27 21:24:59.501: INFO: (1) /api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:1080/proxy/rewriteme">... (200; 4.482188ms)
Sep 27 21:24:59.501: INFO: (1) /api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:162/proxy/: bar (200; 4.555329ms)
Sep 27 21:24:59.501: INFO: (1) /api/v1/namespaces/proxy-5092/services/http:proxy-service-rprh2:portname2/proxy/: bar (200; 4.518778ms)
Sep 27 21:24:59.501: INFO: (1) /api/v1/namespaces/proxy-5092/services/proxy-service-rprh2:portname1/proxy/: foo (200; 4.539771ms)
Sep 27 21:24:59.501: INFO: (1) /api/v1/namespaces/proxy-5092/services/http:proxy-service-rprh2:portname1/proxy/: foo (200; 4.713359ms)
Sep 27 21:24:59.501: INFO: (1) /api/v1/namespaces/proxy-5092/services/https:proxy-service-rprh2:tlsportname2/proxy/: tls qux (200; 4.859302ms)
Sep 27 21:24:59.501: INFO: (1) /api/v1/namespaces/proxy-5092/services/proxy-service-rprh2:portname2/proxy/: bar (200; 4.901553ms)
Sep 27 21:24:59.503: INFO: (2) /api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:162/proxy/: bar (200; 2.034929ms)
Sep 27 21:24:59.504: INFO: (2) /api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:1080/proxy/rewriteme">... (200; 2.677085ms)
Sep 27 21:24:59.504: INFO: (2) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:162/proxy/: bar (200; 2.715077ms)
Sep 27 21:24:59.504: INFO: (2) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx/proxy/rewriteme">test</a> (200; 2.95705ms)
Sep 27 21:24:59.504: INFO: (2) /api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:462/proxy/: tls qux (200; 2.945592ms)
Sep 27 21:24:59.504: INFO: (2) /api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:460/proxy/: tls baz (200; 2.999343ms)
Sep 27 21:24:59.505: INFO: (2) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:160/proxy/: foo (200; 3.307537ms)
Sep 27 21:24:59.505: INFO: (2) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:1080/proxy/rewriteme">test<... (200; 3.396123ms)
Sep 27 21:24:59.505: INFO: (2) /api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:160/proxy/: foo (200; 3.433807ms)
Sep 27 21:24:59.505: INFO: (2) /api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:443/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:443/proxy/tlsrewritem... (200; 3.440387ms)
Sep 27 21:24:59.505: INFO: (2) /api/v1/namespaces/proxy-5092/services/https:proxy-service-rprh2:tlsportname2/proxy/: tls qux (200; 3.95932ms)
Sep 27 21:24:59.506: INFO: (2) /api/v1/namespaces/proxy-5092/services/http:proxy-service-rprh2:portname2/proxy/: bar (200; 4.603615ms)
Sep 27 21:24:59.506: INFO: (2) /api/v1/namespaces/proxy-5092/services/proxy-service-rprh2:portname2/proxy/: bar (200; 4.628335ms)
Sep 27 21:24:59.506: INFO: (2) /api/v1/namespaces/proxy-5092/services/proxy-service-rprh2:portname1/proxy/: foo (200; 4.55676ms)
Sep 27 21:24:59.507: INFO: (2) /api/v1/namespaces/proxy-5092/services/https:proxy-service-rprh2:tlsportname1/proxy/: tls baz (200; 5.150545ms)
Sep 27 21:24:59.507: INFO: (2) /api/v1/namespaces/proxy-5092/services/http:proxy-service-rprh2:portname1/proxy/: foo (200; 5.189925ms)
Sep 27 21:24:59.509: INFO: (3) /api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:460/proxy/: tls baz (200; 2.139867ms)
Sep 27 21:24:59.510: INFO: (3) /api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:1080/proxy/rewriteme">... (200; 3.024067ms)
Sep 27 21:24:59.510: INFO: (3) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:160/proxy/: foo (200; 3.023246ms)
Sep 27 21:24:59.510: INFO: (3) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:1080/proxy/rewriteme">test<... (200; 3.138689ms)
Sep 27 21:24:59.510: INFO: (3) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:162/proxy/: bar (200; 3.155912ms)
Sep 27 21:24:59.510: INFO: (3) /api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:160/proxy/: foo (200; 3.12325ms)
Sep 27 21:24:59.510: INFO: (3) /api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:162/proxy/: bar (200; 3.111957ms)
Sep 27 21:24:59.510: INFO: (3) /api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:462/proxy/: tls qux (200; 3.153172ms)
Sep 27 21:24:59.510: INFO: (3) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx/proxy/rewriteme">test</a> (200; 3.137998ms)
Sep 27 21:24:59.510: INFO: (3) /api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:443/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:443/proxy/tlsrewritem... (200; 3.477285ms)
Sep 27 21:24:59.511: INFO: (3) /api/v1/namespaces/proxy-5092/services/https:proxy-service-rprh2:tlsportname1/proxy/: tls baz (200; 4.231844ms)
Sep 27 21:24:59.511: INFO: (3) /api/v1/namespaces/proxy-5092/services/http:proxy-service-rprh2:portname1/proxy/: foo (200; 4.78134ms)
Sep 27 21:24:59.512: INFO: (3) /api/v1/namespaces/proxy-5092/services/https:proxy-service-rprh2:tlsportname2/proxy/: tls qux (200; 4.779056ms)
Sep 27 21:24:59.512: INFO: (3) /api/v1/namespaces/proxy-5092/services/proxy-service-rprh2:portname1/proxy/: foo (200; 4.80879ms)
Sep 27 21:24:59.512: INFO: (3) /api/v1/namespaces/proxy-5092/services/proxy-service-rprh2:portname2/proxy/: bar (200; 4.785527ms)
Sep 27 21:24:59.512: INFO: (3) /api/v1/namespaces/proxy-5092/services/http:proxy-service-rprh2:portname2/proxy/: bar (200; 4.833011ms)
Sep 27 21:24:59.517: INFO: (4) /api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:462/proxy/: tls qux (200; 4.980162ms)
Sep 27 21:24:59.517: INFO: (4) /api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:1080/proxy/rewriteme">... (200; 4.943633ms)
Sep 27 21:24:59.517: INFO: (4) /api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:160/proxy/: foo (200; 4.951321ms)
Sep 27 21:24:59.517: INFO: (4) /api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:162/proxy/: bar (200; 5.472232ms)
Sep 27 21:24:59.517: INFO: (4) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:1080/proxy/rewriteme">test<... (200; 5.49957ms)
Sep 27 21:24:59.517: INFO: (4) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:160/proxy/: foo (200; 5.534669ms)
Sep 27 21:24:59.517: INFO: (4) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:162/proxy/: bar (200; 5.681531ms)
Sep 27 21:24:59.517: INFO: (4) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx/proxy/rewriteme">test</a> (200; 5.748978ms)
Sep 27 21:24:59.517: INFO: (4) /api/v1/namespaces/proxy-5092/services/http:proxy-service-rprh2:portname1/proxy/: foo (200; 5.816049ms)
Sep 27 21:24:59.517: INFO: (4) /api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:443/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:443/proxy/tlsrewritem... (200; 5.756876ms)
Sep 27 21:24:59.518: INFO: (4) /api/v1/namespaces/proxy-5092/services/https:proxy-service-rprh2:tlsportname1/proxy/: tls baz (200; 5.94304ms)
Sep 27 21:24:59.518: INFO: (4) /api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:460/proxy/: tls baz (200; 5.950491ms)
Sep 27 21:24:59.518: INFO: (4) /api/v1/namespaces/proxy-5092/services/proxy-service-rprh2:portname2/proxy/: bar (200; 6.245175ms)
Sep 27 21:24:59.519: INFO: (4) /api/v1/namespaces/proxy-5092/services/proxy-service-rprh2:portname1/proxy/: foo (200; 6.890166ms)
Sep 27 21:24:59.519: INFO: (4) /api/v1/namespaces/proxy-5092/services/http:proxy-service-rprh2:portname2/proxy/: bar (200; 6.970088ms)
Sep 27 21:24:59.519: INFO: (4) /api/v1/namespaces/proxy-5092/services/https:proxy-service-rprh2:tlsportname2/proxy/: tls qux (200; 7.060044ms)
Sep 27 21:24:59.521: INFO: (5) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:1080/proxy/rewriteme">test<... (200; 2.522049ms)
Sep 27 21:24:59.521: INFO: (5) /api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:160/proxy/: foo (200; 2.610214ms)
Sep 27 21:24:59.521: INFO: (5) /api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:462/proxy/: tls qux (200; 2.571813ms)
Sep 27 21:24:59.526: INFO: (5) /api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:162/proxy/: bar (200; 6.830255ms)
Sep 27 21:24:59.526: INFO: (5) /api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:460/proxy/: tls baz (200; 6.808788ms)
Sep 27 21:24:59.526: INFO: (5) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:162/proxy/: bar (200; 6.838435ms)
Sep 27 21:24:59.526: INFO: (5) /api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:1080/proxy/rewriteme">... (200; 6.821424ms)
Sep 27 21:24:59.526: INFO: (5) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx/proxy/rewriteme">test</a> (200; 6.845752ms)
Sep 27 21:24:59.526: INFO: (5) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:160/proxy/: foo (200; 6.903547ms)
Sep 27 21:24:59.526: INFO: (5) /api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:443/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:443/proxy/tlsrewritem... (200; 6.963061ms)
Sep 27 21:24:59.526: INFO: (5) /api/v1/namespaces/proxy-5092/services/proxy-service-rprh2:portname1/proxy/: foo (200; 7.374773ms)
Sep 27 21:24:59.526: INFO: (5) /api/v1/namespaces/proxy-5092/services/proxy-service-rprh2:portname2/proxy/: bar (200; 7.449994ms)
Sep 27 21:24:59.526: INFO: (5) /api/v1/namespaces/proxy-5092/services/http:proxy-service-rprh2:portname2/proxy/: bar (200; 7.440365ms)
Sep 27 21:24:59.526: INFO: (5) /api/v1/namespaces/proxy-5092/services/https:proxy-service-rprh2:tlsportname2/proxy/: tls qux (200; 7.571676ms)
Sep 27 21:24:59.530: INFO: (5) /api/v1/namespaces/proxy-5092/services/http:proxy-service-rprh2:portname1/proxy/: foo (200; 11.21445ms)
Sep 27 21:24:59.530: INFO: (5) /api/v1/namespaces/proxy-5092/services/https:proxy-service-rprh2:tlsportname1/proxy/: tls baz (200; 11.350565ms)
Sep 27 21:24:59.533: INFO: (6) /api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:460/proxy/: tls baz (200; 2.215753ms)
Sep 27 21:24:59.533: INFO: (6) /api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:162/proxy/: bar (200; 2.879757ms)
Sep 27 21:24:59.533: INFO: (6) /api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:1080/proxy/rewriteme">... (200; 2.926971ms)
Sep 27 21:24:59.533: INFO: (6) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:160/proxy/: foo (200; 2.902986ms)
Sep 27 21:24:59.533: INFO: (6) /api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:443/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:443/proxy/tlsrewritem... (200; 2.996373ms)
Sep 27 21:24:59.533: INFO: (6) /api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:160/proxy/: foo (200; 3.031844ms)
Sep 27 21:24:59.533: INFO: (6) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx/proxy/rewriteme">test</a> (200; 3.048921ms)
Sep 27 21:24:59.533: INFO: (6) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:1080/proxy/rewriteme">test<... (200; 3.071869ms)
Sep 27 21:24:59.533: INFO: (6) /api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:462/proxy/: tls qux (200; 3.124946ms)
Sep 27 21:24:59.534: INFO: (6) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:162/proxy/: bar (200; 3.218547ms)
Sep 27 21:24:59.534: INFO: (6) /api/v1/namespaces/proxy-5092/services/https:proxy-service-rprh2:tlsportname2/proxy/: tls qux (200; 4.092617ms)
Sep 27 21:24:59.534: INFO: (6) /api/v1/namespaces/proxy-5092/services/http:proxy-service-rprh2:portname2/proxy/: bar (200; 4.106884ms)
Sep 27 21:24:59.535: INFO: (6) /api/v1/namespaces/proxy-5092/services/http:proxy-service-rprh2:portname1/proxy/: foo (200; 4.653947ms)
Sep 27 21:24:59.535: INFO: (6) /api/v1/namespaces/proxy-5092/services/https:proxy-service-rprh2:tlsportname1/proxy/: tls baz (200; 4.732823ms)
Sep 27 21:24:59.535: INFO: (6) /api/v1/namespaces/proxy-5092/services/proxy-service-rprh2:portname1/proxy/: foo (200; 4.7455ms)
Sep 27 21:24:59.535: INFO: (6) /api/v1/namespaces/proxy-5092/services/proxy-service-rprh2:portname2/proxy/: bar (200; 4.689607ms)
Sep 27 21:24:59.538: INFO: (7) /api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:162/proxy/: bar (200; 2.842131ms)
Sep 27 21:24:59.538: INFO: (7) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:160/proxy/: foo (200; 2.932259ms)
Sep 27 21:24:59.538: INFO: (7) /api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:460/proxy/: tls baz (200; 3.018422ms)
Sep 27 21:24:59.538: INFO: (7) /api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:443/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:443/proxy/tlsrewritem... (200; 3.007808ms)
Sep 27 21:24:59.538: INFO: (7) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:1080/proxy/rewriteme">test<... (200; 3.067356ms)
Sep 27 21:24:59.538: INFO: (7) /api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:160/proxy/: foo (200; 2.996356ms)
Sep 27 21:24:59.538: INFO: (7) /api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:462/proxy/: tls qux (200; 3.153104ms)
Sep 27 21:24:59.538: INFO: (7) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:162/proxy/: bar (200; 3.205838ms)
Sep 27 21:24:59.539: INFO: (7) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx/proxy/rewriteme">test</a> (200; 3.524237ms)
Sep 27 21:24:59.539: INFO: (7) /api/v1/namespaces/proxy-5092/services/https:proxy-service-rprh2:tlsportname1/proxy/: tls baz (200; 3.721255ms)
Sep 27 21:24:59.539: INFO: (7) /api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:1080/proxy/rewriteme">... (200; 3.648846ms)
Sep 27 21:24:59.539: INFO: (7) /api/v1/namespaces/proxy-5092/services/http:proxy-service-rprh2:portname1/proxy/: foo (200; 4.125956ms)
Sep 27 21:24:59.539: INFO: (7) /api/v1/namespaces/proxy-5092/services/proxy-service-rprh2:portname1/proxy/: foo (200; 4.221336ms)
Sep 27 21:24:59.539: INFO: (7) /api/v1/namespaces/proxy-5092/services/https:proxy-service-rprh2:tlsportname2/proxy/: tls qux (200; 4.293702ms)
Sep 27 21:24:59.540: INFO: (7) /api/v1/namespaces/proxy-5092/services/proxy-service-rprh2:portname2/proxy/: bar (200; 4.798763ms)
Sep 27 21:24:59.540: INFO: (7) /api/v1/namespaces/proxy-5092/services/http:proxy-service-rprh2:portname2/proxy/: bar (200; 4.860713ms)
Sep 27 21:24:59.542: INFO: (8) /api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:462/proxy/: tls qux (200; 2.167887ms)
Sep 27 21:24:59.543: INFO: (8) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:160/proxy/: foo (200; 2.600466ms)
Sep 27 21:24:59.543: INFO: (8) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:1080/proxy/rewriteme">test<... (200; 2.716636ms)
Sep 27 21:24:59.543: INFO: (8) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:162/proxy/: bar (200; 2.887135ms)
Sep 27 21:24:59.543: INFO: (8) /api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:160/proxy/: foo (200; 2.919007ms)
Sep 27 21:24:59.543: INFO: (8) /api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:460/proxy/: tls baz (200; 3.021565ms)
Sep 27 21:24:59.543: INFO: (8) /api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:443/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:443/proxy/tlsrewritem... (200; 3.01577ms)
Sep 27 21:24:59.543: INFO: (8) /api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:162/proxy/: bar (200; 3.243173ms)
Sep 27 21:24:59.543: INFO: (8) /api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:1080/proxy/rewriteme">... (200; 3.300133ms)
Sep 27 21:24:59.544: INFO: (8) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx/proxy/rewriteme">test</a> (200; 3.429469ms)
Sep 27 21:24:59.544: INFO: (8) /api/v1/namespaces/proxy-5092/services/https:proxy-service-rprh2:tlsportname1/proxy/: tls baz (200; 3.560863ms)
Sep 27 21:24:59.546: INFO: (8) /api/v1/namespaces/proxy-5092/services/proxy-service-rprh2:portname2/proxy/: bar (200; 5.445858ms)
Sep 27 21:24:59.546: INFO: (8) /api/v1/namespaces/proxy-5092/services/http:proxy-service-rprh2:portname1/proxy/: foo (200; 6.159523ms)
Sep 27 21:24:59.546: INFO: (8) /api/v1/namespaces/proxy-5092/services/proxy-service-rprh2:portname1/proxy/: foo (200; 6.233553ms)
Sep 27 21:24:59.546: INFO: (8) /api/v1/namespaces/proxy-5092/services/https:proxy-service-rprh2:tlsportname2/proxy/: tls qux (200; 6.242833ms)
Sep 27 21:24:59.547: INFO: (8) /api/v1/namespaces/proxy-5092/services/http:proxy-service-rprh2:portname2/proxy/: bar (200; 6.694009ms)
Sep 27 21:24:59.549: INFO: (9) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:1080/proxy/rewriteme">test<... (200; 2.236486ms)
Sep 27 21:24:59.550: INFO: (9) /api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:1080/proxy/rewriteme">... (200; 3.086751ms)
Sep 27 21:24:59.550: INFO: (9) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx/proxy/rewriteme">test</a> (200; 3.091017ms)
Sep 27 21:24:59.550: INFO: (9) /api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:162/proxy/: bar (200; 3.22865ms)
Sep 27 21:24:59.550: INFO: (9) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:160/proxy/: foo (200; 3.241785ms)
Sep 27 21:24:59.550: INFO: (9) /api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:443/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:443/proxy/tlsrewritem... (200; 3.245436ms)
Sep 27 21:24:59.550: INFO: (9) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:162/proxy/: bar (200; 3.243791ms)
Sep 27 21:24:59.550: INFO: (9) /api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:160/proxy/: foo (200; 3.347652ms)
Sep 27 21:24:59.550: INFO: (9) /api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:462/proxy/: tls qux (200; 3.421977ms)
Sep 27 21:24:59.550: INFO: (9) /api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:460/proxy/: tls baz (200; 3.505631ms)
Sep 27 21:24:59.551: INFO: (9) /api/v1/namespaces/proxy-5092/services/http:proxy-service-rprh2:portname1/proxy/: foo (200; 4.228157ms)
Sep 27 21:24:59.552: INFO: (9) /api/v1/namespaces/proxy-5092/services/proxy-service-rprh2:portname2/proxy/: bar (200; 5.016918ms)
Sep 27 21:24:59.552: INFO: (9) /api/v1/namespaces/proxy-5092/services/https:proxy-service-rprh2:tlsportname1/proxy/: tls baz (200; 5.18305ms)
Sep 27 21:24:59.552: INFO: (9) /api/v1/namespaces/proxy-5092/services/proxy-service-rprh2:portname1/proxy/: foo (200; 5.203057ms)
Sep 27 21:24:59.552: INFO: (9) /api/v1/namespaces/proxy-5092/services/http:proxy-service-rprh2:portname2/proxy/: bar (200; 5.242351ms)
Sep 27 21:24:59.552: INFO: (9) /api/v1/namespaces/proxy-5092/services/https:proxy-service-rprh2:tlsportname2/proxy/: tls qux (200; 5.217952ms)
Sep 27 21:24:59.555: INFO: (10) /api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:160/proxy/: foo (200; 2.618752ms)
Sep 27 21:24:59.555: INFO: (10) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:162/proxy/: bar (200; 2.688611ms)
Sep 27 21:24:59.555: INFO: (10) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:1080/proxy/rewriteme">test<... (200; 2.856473ms)
Sep 27 21:24:59.555: INFO: (10) /api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:462/proxy/: tls qux (200; 2.895074ms)
Sep 27 21:24:59.555: INFO: (10) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:160/proxy/: foo (200; 2.969967ms)
Sep 27 21:24:59.555: INFO: (10) /api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:1080/proxy/rewriteme">... (200; 2.931399ms)
Sep 27 21:24:59.555: INFO: (10) /api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:162/proxy/: bar (200; 3.017306ms)
Sep 27 21:24:59.555: INFO: (10) /api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:460/proxy/: tls baz (200; 3.070322ms)
Sep 27 21:24:59.555: INFO: (10) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx/proxy/rewriteme">test</a> (200; 3.068889ms)
Sep 27 21:24:59.555: INFO: (10) /api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:443/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:443/proxy/tlsrewritem... (200; 3.173411ms)
Sep 27 21:24:59.556: INFO: (10) /api/v1/namespaces/proxy-5092/services/http:proxy-service-rprh2:portname1/proxy/: foo (200; 3.425549ms)
Sep 27 21:24:59.556: INFO: (10) /api/v1/namespaces/proxy-5092/services/https:proxy-service-rprh2:tlsportname1/proxy/: tls baz (200; 4.216207ms)
Sep 27 21:24:59.557: INFO: (10) /api/v1/namespaces/proxy-5092/services/http:proxy-service-rprh2:portname2/proxy/: bar (200; 4.813918ms)
Sep 27 21:24:59.557: INFO: (10) /api/v1/namespaces/proxy-5092/services/proxy-service-rprh2:portname1/proxy/: foo (200; 4.775637ms)
Sep 27 21:24:59.557: INFO: (10) /api/v1/namespaces/proxy-5092/services/proxy-service-rprh2:portname2/proxy/: bar (200; 4.891662ms)
Sep 27 21:24:59.557: INFO: (10) /api/v1/namespaces/proxy-5092/services/https:proxy-service-rprh2:tlsportname2/proxy/: tls qux (200; 4.928336ms)
Sep 27 21:24:59.560: INFO: (11) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:160/proxy/: foo (200; 2.838372ms)
Sep 27 21:24:59.560: INFO: (11) /api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:160/proxy/: foo (200; 3.038559ms)
Sep 27 21:24:59.560: INFO: (11) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:1080/proxy/rewriteme">test<... (200; 3.061806ms)
Sep 27 21:24:59.560: INFO: (11) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx/proxy/rewriteme">test</a> (200; 3.053058ms)
Sep 27 21:24:59.560: INFO: (11) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:162/proxy/: bar (200; 3.076888ms)
Sep 27 21:24:59.560: INFO: (11) /api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:443/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:443/proxy/tlsrewritem... (200; 3.098919ms)
Sep 27 21:24:59.561: INFO: (11) /api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:162/proxy/: bar (200; 3.258255ms)
Sep 27 21:24:59.561: INFO: (11) /api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:1080/proxy/rewriteme">... (200; 3.323124ms)
Sep 27 21:24:59.561: INFO: (11) /api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:460/proxy/: tls baz (200; 3.40429ms)
Sep 27 21:24:59.561: INFO: (11) /api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:462/proxy/: tls qux (200; 3.459652ms)
Sep 27 21:24:59.561: INFO: (11) /api/v1/namespaces/proxy-5092/services/https:proxy-service-rprh2:tlsportname1/proxy/: tls baz (200; 3.665121ms)
Sep 27 21:24:59.561: INFO: (11) /api/v1/namespaces/proxy-5092/services/proxy-service-rprh2:portname1/proxy/: foo (200; 4.131672ms)
Sep 27 21:24:59.561: INFO: (11) /api/v1/namespaces/proxy-5092/services/https:proxy-service-rprh2:tlsportname2/proxy/: tls qux (200; 4.223753ms)
Sep 27 21:24:59.562: INFO: (11) /api/v1/namespaces/proxy-5092/services/http:proxy-service-rprh2:portname1/proxy/: foo (200; 4.769162ms)
Sep 27 21:24:59.562: INFO: (11) /api/v1/namespaces/proxy-5092/services/http:proxy-service-rprh2:portname2/proxy/: bar (200; 4.768119ms)
Sep 27 21:24:59.562: INFO: (11) /api/v1/namespaces/proxy-5092/services/proxy-service-rprh2:portname2/proxy/: bar (200; 4.84896ms)
Sep 27 21:24:59.564: INFO: (12) /api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:1080/proxy/rewriteme">... (200; 2.040005ms)
Sep 27 21:24:59.565: INFO: (12) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx/proxy/rewriteme">test</a> (200; 2.83205ms)
Sep 27 21:24:59.565: INFO: (12) /api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:160/proxy/: foo (200; 2.830286ms)
Sep 27 21:24:59.565: INFO: (12) /api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:443/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:443/proxy/tlsrewritem... (200; 2.848073ms)
Sep 27 21:24:59.565: INFO: (12) /api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:162/proxy/: bar (200; 3.052478ms)
Sep 27 21:24:59.565: INFO: (12) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:162/proxy/: bar (200; 3.107608ms)
Sep 27 21:24:59.565: INFO: (12) /api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:462/proxy/: tls qux (200; 3.036118ms)
Sep 27 21:24:59.565: INFO: (12) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:1080/proxy/rewriteme">test<... (200; 3.083565ms)
Sep 27 21:24:59.565: INFO: (12) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:160/proxy/: foo (200; 3.178749ms)
Sep 27 21:24:59.566: INFO: (12) /api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:460/proxy/: tls baz (200; 3.432819ms)
Sep 27 21:24:59.566: INFO: (12) /api/v1/namespaces/proxy-5092/services/proxy-service-rprh2:portname2/proxy/: bar (200; 3.932939ms)
Sep 27 21:24:59.567: INFO: (12) /api/v1/namespaces/proxy-5092/services/proxy-service-rprh2:portname1/proxy/: foo (200; 4.85223ms)
Sep 27 21:24:59.567: INFO: (12) /api/v1/namespaces/proxy-5092/services/http:proxy-service-rprh2:portname1/proxy/: foo (200; 4.835527ms)
Sep 27 21:24:59.567: INFO: (12) /api/v1/namespaces/proxy-5092/services/https:proxy-service-rprh2:tlsportname1/proxy/: tls baz (200; 4.846227ms)
Sep 27 21:24:59.567: INFO: (12) /api/v1/namespaces/proxy-5092/services/http:proxy-service-rprh2:portname2/proxy/: bar (200; 4.857412ms)
Sep 27 21:24:59.567: INFO: (12) /api/v1/namespaces/proxy-5092/services/https:proxy-service-rprh2:tlsportname2/proxy/: tls qux (200; 4.87778ms)
Sep 27 21:24:59.570: INFO: (13) /api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:162/proxy/: bar (200; 2.805601ms)
Sep 27 21:24:59.570: INFO: (13) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:160/proxy/: foo (200; 2.770598ms)
Sep 27 21:24:59.570: INFO: (13) /api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:160/proxy/: foo (200; 3.039902ms)
Sep 27 21:24:59.570: INFO: (13) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:162/proxy/: bar (200; 3.065112ms)
Sep 27 21:24:59.570: INFO: (13) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:1080/proxy/rewriteme">test<... (200; 3.268634ms)
Sep 27 21:24:59.571: INFO: (13) /api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:443/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:443/proxy/tlsrewritem... (200; 3.353095ms)
Sep 27 21:24:59.571: INFO: (13) /api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:1080/proxy/rewriteme">... (200; 3.349518ms)
Sep 27 21:24:59.571: INFO: (13) /api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:462/proxy/: tls qux (200; 3.544768ms)
Sep 27 21:24:59.571: INFO: (13) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx/proxy/rewriteme">test</a> (200; 3.529916ms)
Sep 27 21:24:59.571: INFO: (13) /api/v1/namespaces/proxy-5092/services/http:proxy-service-rprh2:portname2/proxy/: bar (200; 3.619488ms)
Sep 27 21:24:59.571: INFO: (13) /api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:460/proxy/: tls baz (200; 3.555099ms)
Sep 27 21:24:59.571: INFO: (13) /api/v1/namespaces/proxy-5092/services/proxy-service-rprh2:portname1/proxy/: foo (200; 4.184522ms)
Sep 27 21:24:59.571: INFO: (13) /api/v1/namespaces/proxy-5092/services/http:proxy-service-rprh2:portname1/proxy/: foo (200; 4.208428ms)
Sep 27 21:24:59.572: INFO: (13) /api/v1/namespaces/proxy-5092/services/proxy-service-rprh2:portname2/proxy/: bar (200; 4.837869ms)
Sep 27 21:24:59.572: INFO: (13) /api/v1/namespaces/proxy-5092/services/https:proxy-service-rprh2:tlsportname2/proxy/: tls qux (200; 5.008603ms)
Sep 27 21:24:59.572: INFO: (13) /api/v1/namespaces/proxy-5092/services/https:proxy-service-rprh2:tlsportname1/proxy/: tls baz (200; 5.031823ms)
Sep 27 21:24:59.574: INFO: (14) /api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:1080/proxy/rewriteme">... (200; 2.138799ms)
Sep 27 21:24:59.575: INFO: (14) /api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:160/proxy/: foo (200; 2.431426ms)
Sep 27 21:24:59.575: INFO: (14) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx/proxy/rewriteme">test</a> (200; 2.599428ms)
Sep 27 21:24:59.575: INFO: (14) /api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:162/proxy/: bar (200; 2.641474ms)
Sep 27 21:24:59.575: INFO: (14) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:162/proxy/: bar (200; 2.771866ms)
Sep 27 21:24:59.575: INFO: (14) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:1080/proxy/rewriteme">test<... (200; 2.777273ms)
Sep 27 21:24:59.575: INFO: (14) /api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:443/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:443/proxy/tlsrewritem... (200; 2.792913ms)
Sep 27 21:24:59.575: INFO: (14) /api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:462/proxy/: tls qux (200; 2.815112ms)
Sep 27 21:24:59.575: INFO: (14) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:160/proxy/: foo (200; 2.896083ms)
Sep 27 21:24:59.576: INFO: (14) /api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:460/proxy/: tls baz (200; 3.169431ms)
Sep 27 21:24:59.576: INFO: (14) /api/v1/namespaces/proxy-5092/services/https:proxy-service-rprh2:tlsportname1/proxy/: tls baz (200; 3.92491ms)
Sep 27 21:24:59.577: INFO: (14) /api/v1/namespaces/proxy-5092/services/proxy-service-rprh2:portname1/proxy/: foo (200; 4.644179ms)
Sep 27 21:24:59.577: INFO: (14) /api/v1/namespaces/proxy-5092/services/http:proxy-service-rprh2:portname2/proxy/: bar (200; 4.601763ms)
Sep 27 21:24:59.577: INFO: (14) /api/v1/namespaces/proxy-5092/services/http:proxy-service-rprh2:portname1/proxy/: foo (200; 4.665064ms)
Sep 27 21:24:59.577: INFO: (14) /api/v1/namespaces/proxy-5092/services/proxy-service-rprh2:portname2/proxy/: bar (200; 4.653805ms)
Sep 27 21:24:59.577: INFO: (14) /api/v1/namespaces/proxy-5092/services/https:proxy-service-rprh2:tlsportname2/proxy/: tls qux (200; 4.646455ms)
Sep 27 21:24:59.580: INFO: (15) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:162/proxy/: bar (200; 2.709502ms)
Sep 27 21:24:59.580: INFO: (15) /api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:162/proxy/: bar (200; 2.895119ms)
Sep 27 21:24:59.580: INFO: (15) /api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:160/proxy/: foo (200; 2.894825ms)
Sep 27 21:24:59.580: INFO: (15) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx/proxy/rewriteme">test</a> (200; 2.891234ms)
Sep 27 21:24:59.580: INFO: (15) /api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:1080/proxy/rewriteme">... (200; 2.987467ms)
Sep 27 21:24:59.580: INFO: (15) /api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:462/proxy/: tls qux (200; 3.059142ms)
Sep 27 21:24:59.581: INFO: (15) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:160/proxy/: foo (200; 3.503305ms)
Sep 27 21:24:59.581: INFO: (15) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:1080/proxy/rewriteme">test<... (200; 3.547647ms)
Sep 27 21:24:59.581: INFO: (15) /api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:443/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:443/proxy/tlsrewritem... (200; 3.638946ms)
Sep 27 21:24:59.581: INFO: (15) /api/v1/namespaces/proxy-5092/services/https:proxy-service-rprh2:tlsportname1/proxy/: tls baz (200; 3.786848ms)
Sep 27 21:24:59.581: INFO: (15) /api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:460/proxy/: tls baz (200; 3.754079ms)
Sep 27 21:24:59.581: INFO: (15) /api/v1/namespaces/proxy-5092/services/https:proxy-service-rprh2:tlsportname2/proxy/: tls qux (200; 4.009813ms)
Sep 27 21:24:59.582: INFO: (15) /api/v1/namespaces/proxy-5092/services/proxy-service-rprh2:portname1/proxy/: foo (200; 4.814534ms)
Sep 27 21:24:59.582: INFO: (15) /api/v1/namespaces/proxy-5092/services/http:proxy-service-rprh2:portname1/proxy/: foo (200; 4.830609ms)
Sep 27 21:24:59.582: INFO: (15) /api/v1/namespaces/proxy-5092/services/proxy-service-rprh2:portname2/proxy/: bar (200; 4.878575ms)
Sep 27 21:24:59.582: INFO: (15) /api/v1/namespaces/proxy-5092/services/http:proxy-service-rprh2:portname2/proxy/: bar (200; 4.842482ms)
Sep 27 21:24:59.585: INFO: (16) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:160/proxy/: foo (200; 2.781097ms)
Sep 27 21:24:59.585: INFO: (16) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx/proxy/rewriteme">test</a> (200; 2.905482ms)
Sep 27 21:24:59.585: INFO: (16) /api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:460/proxy/: tls baz (200; 2.998431ms)
Sep 27 21:24:59.585: INFO: (16) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:1080/proxy/rewriteme">test<... (200; 3.071691ms)
Sep 27 21:24:59.585: INFO: (16) /api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:443/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:443/proxy/tlsrewritem... (200; 3.009384ms)
Sep 27 21:24:59.585: INFO: (16) /api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:162/proxy/: bar (200; 3.084439ms)
Sep 27 21:24:59.585: INFO: (16) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:162/proxy/: bar (200; 3.150633ms)
Sep 27 21:24:59.585: INFO: (16) /api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:160/proxy/: foo (200; 3.172625ms)
Sep 27 21:24:59.585: INFO: (16) /api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:1080/proxy/rewriteme">... (200; 3.411256ms)
Sep 27 21:24:59.586: INFO: (16) /api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:462/proxy/: tls qux (200; 3.594868ms)
Sep 27 21:24:59.586: INFO: (16) /api/v1/namespaces/proxy-5092/services/https:proxy-service-rprh2:tlsportname1/proxy/: tls baz (200; 3.704347ms)
Sep 27 21:24:59.586: INFO: (16) /api/v1/namespaces/proxy-5092/services/http:proxy-service-rprh2:portname1/proxy/: foo (200; 3.787068ms)
Sep 27 21:24:59.586: INFO: (16) /api/v1/namespaces/proxy-5092/services/proxy-service-rprh2:portname1/proxy/: foo (200; 4.120593ms)
Sep 27 21:24:59.587: INFO: (16) /api/v1/namespaces/proxy-5092/services/proxy-service-rprh2:portname2/proxy/: bar (200; 5.115671ms)
Sep 27 21:24:59.587: INFO: (16) /api/v1/namespaces/proxy-5092/services/https:proxy-service-rprh2:tlsportname2/proxy/: tls qux (200; 5.174428ms)
Sep 27 21:24:59.587: INFO: (16) /api/v1/namespaces/proxy-5092/services/http:proxy-service-rprh2:portname2/proxy/: bar (200; 5.100961ms)
Sep 27 21:24:59.598: INFO: (17) /api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:160/proxy/: foo (200; 10.733666ms)
Sep 27 21:24:59.598: INFO: (17) /api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:1080/proxy/rewriteme">... (200; 10.721109ms)
Sep 27 21:24:59.598: INFO: (17) /api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:443/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:443/proxy/tlsrewritem... (200; 10.718238ms)
Sep 27 21:24:59.598: INFO: (17) /api/v1/namespaces/proxy-5092/services/https:proxy-service-rprh2:tlsportname1/proxy/: tls baz (200; 10.828857ms)
Sep 27 21:24:59.598: INFO: (17) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx/proxy/rewriteme">test</a> (200; 10.757413ms)
Sep 27 21:24:59.598: INFO: (17) /api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:460/proxy/: tls baz (200; 10.789487ms)
Sep 27 21:24:59.598: INFO: (17) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:160/proxy/: foo (200; 10.838181ms)
Sep 27 21:24:59.598: INFO: (17) /api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:162/proxy/: bar (200; 10.91591ms)
Sep 27 21:24:59.598: INFO: (17) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:1080/proxy/rewriteme">test<... (200; 10.902334ms)
Sep 27 21:24:59.598: INFO: (17) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:162/proxy/: bar (200; 11.032344ms)
Sep 27 21:24:59.598: INFO: (17) /api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:462/proxy/: tls qux (200; 11.266621ms)
Sep 27 21:24:59.599: INFO: (17) /api/v1/namespaces/proxy-5092/services/https:proxy-service-rprh2:tlsportname2/proxy/: tls qux (200; 11.888131ms)
Sep 27 21:24:59.600: INFO: (17) /api/v1/namespaces/proxy-5092/services/http:proxy-service-rprh2:portname1/proxy/: foo (200; 12.595817ms)
Sep 27 21:24:59.600: INFO: (17) /api/v1/namespaces/proxy-5092/services/proxy-service-rprh2:portname2/proxy/: bar (200; 12.619906ms)
Sep 27 21:24:59.600: INFO: (17) /api/v1/namespaces/proxy-5092/services/http:proxy-service-rprh2:portname2/proxy/: bar (200; 12.572371ms)
Sep 27 21:24:59.600: INFO: (17) /api/v1/namespaces/proxy-5092/services/proxy-service-rprh2:portname1/proxy/: foo (200; 12.574659ms)
Sep 27 21:24:59.603: INFO: (18) /api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:1080/proxy/rewriteme">... (200; 2.745439ms)
Sep 27 21:24:59.603: INFO: (18) /api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:162/proxy/: bar (200; 2.781609ms)
Sep 27 21:24:59.603: INFO: (18) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:160/proxy/: foo (200; 3.016124ms)
Sep 27 21:24:59.603: INFO: (18) /api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:462/proxy/: tls qux (200; 3.002527ms)
Sep 27 21:24:59.603: INFO: (18) /api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:443/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:443/proxy/tlsrewritem... (200; 2.99931ms)
Sep 27 21:24:59.603: INFO: (18) /api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:160/proxy/: foo (200; 3.223167ms)
Sep 27 21:24:59.603: INFO: (18) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:1080/proxy/rewriteme">test<... (200; 3.252426ms)
Sep 27 21:24:59.603: INFO: (18) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx/proxy/rewriteme">test</a> (200; 3.178533ms)
Sep 27 21:24:59.603: INFO: (18) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:162/proxy/: bar (200; 3.43775ms)
Sep 27 21:24:59.603: INFO: (18) /api/v1/namespaces/proxy-5092/services/proxy-service-rprh2:portname1/proxy/: foo (200; 3.495085ms)
Sep 27 21:24:59.603: INFO: (18) /api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:460/proxy/: tls baz (200; 3.592887ms)
Sep 27 21:24:59.604: INFO: (18) /api/v1/namespaces/proxy-5092/services/https:proxy-service-rprh2:tlsportname2/proxy/: tls qux (200; 4.003101ms)
Sep 27 21:24:59.605: INFO: (18) /api/v1/namespaces/proxy-5092/services/http:proxy-service-rprh2:portname1/proxy/: foo (200; 4.549642ms)
Sep 27 21:24:59.605: INFO: (18) /api/v1/namespaces/proxy-5092/services/proxy-service-rprh2:portname2/proxy/: bar (200; 4.510399ms)
Sep 27 21:24:59.605: INFO: (18) /api/v1/namespaces/proxy-5092/services/http:proxy-service-rprh2:portname2/proxy/: bar (200; 4.619243ms)
Sep 27 21:24:59.605: INFO: (18) /api/v1/namespaces/proxy-5092/services/https:proxy-service-rprh2:tlsportname1/proxy/: tls baz (200; 4.737779ms)
Sep 27 21:24:59.607: INFO: (19) /api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:1080/proxy/rewriteme">... (200; 2.157486ms)
Sep 27 21:24:59.608: INFO: (19) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:162/proxy/: bar (200; 2.924687ms)
Sep 27 21:24:59.608: INFO: (19) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:160/proxy/: foo (200; 2.978872ms)
Sep 27 21:24:59.608: INFO: (19) /api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:162/proxy/: bar (200; 3.056796ms)
Sep 27 21:24:59.608: INFO: (19) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx/proxy/rewriteme">test</a> (200; 3.209065ms)
Sep 27 21:24:59.608: INFO: (19) /api/v1/namespaces/proxy-5092/pods/http:proxy-service-rprh2-2cqtx:160/proxy/: foo (200; 3.221674ms)
Sep 27 21:24:59.608: INFO: (19) /api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:460/proxy/: tls baz (200; 3.182206ms)
Sep 27 21:24:59.608: INFO: (19) /api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:443/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:443/proxy/tlsrewritem... (200; 3.254148ms)
Sep 27 21:24:59.608: INFO: (19) /api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5092/pods/proxy-service-rprh2-2cqtx:1080/proxy/rewriteme">test<... (200; 3.208402ms)
Sep 27 21:24:59.608: INFO: (19) /api/v1/namespaces/proxy-5092/pods/https:proxy-service-rprh2-2cqtx:462/proxy/: tls qux (200; 3.301498ms)
Sep 27 21:24:59.609: INFO: (19) /api/v1/namespaces/proxy-5092/services/http:proxy-service-rprh2:portname2/proxy/: bar (200; 4.193965ms)
Sep 27 21:24:59.609: INFO: (19) /api/v1/namespaces/proxy-5092/services/https:proxy-service-rprh2:tlsportname2/proxy/: tls qux (200; 4.360941ms)
Sep 27 21:24:59.610: INFO: (19) /api/v1/namespaces/proxy-5092/services/proxy-service-rprh2:portname1/proxy/: foo (200; 5.073773ms)
Sep 27 21:24:59.610: INFO: (19) /api/v1/namespaces/proxy-5092/services/https:proxy-service-rprh2:tlsportname1/proxy/: tls baz (200; 5.167043ms)
Sep 27 21:24:59.610: INFO: (19) /api/v1/namespaces/proxy-5092/services/http:proxy-service-rprh2:portname1/proxy/: foo (200; 5.15734ms)
Sep 27 21:24:59.610: INFO: (19) /api/v1/namespaces/proxy-5092/services/proxy-service-rprh2:portname2/proxy/: bar (200; 5.128796ms)
STEP: deleting ReplicationController proxy-service-rprh2 in namespace proxy-5092, will wait for the garbage collector to delete the pods
Sep 27 21:24:59.674: INFO: Deleting ReplicationController proxy-service-rprh2 took: 12.319138ms
Sep 27 21:24:59.975: INFO: Terminating ReplicationController proxy-service-rprh2 pods took: 300.119076ms
[AfterEach] version v1
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:25:02.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-5092" for this suite.
Sep 27 21:25:08.390: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:25:08.459: INFO: namespace proxy-5092 deletion completed in 6.080865555s

• [SLOW TEST:21.223 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:25:08.459: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1140
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep 27 21:25:08.618: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5e1237fc-ed90-459e-91d2-87b7c1dec7fc" in namespace "downward-api-1140" to be "success or failure"
Sep 27 21:25:08.620: INFO: Pod "downwardapi-volume-5e1237fc-ed90-459e-91d2-87b7c1dec7fc": Phase="Pending", Reason="", readiness=false. Elapsed: 1.933933ms
Sep 27 21:25:10.622: INFO: Pod "downwardapi-volume-5e1237fc-ed90-459e-91d2-87b7c1dec7fc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004452603s
STEP: Saw pod success
Sep 27 21:25:10.623: INFO: Pod "downwardapi-volume-5e1237fc-ed90-459e-91d2-87b7c1dec7fc" satisfied condition "success or failure"
Sep 27 21:25:10.624: INFO: Trying to get logs from node macpro-2 pod downwardapi-volume-5e1237fc-ed90-459e-91d2-87b7c1dec7fc container client-container: <nil>
STEP: delete the pod
Sep 27 21:25:10.649: INFO: Waiting for pod downwardapi-volume-5e1237fc-ed90-459e-91d2-87b7c1dec7fc to disappear
Sep 27 21:25:10.651: INFO: Pod downwardapi-volume-5e1237fc-ed90-459e-91d2-87b7c1dec7fc no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:25:10.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1140" for this suite.
Sep 27 21:25:16.665: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:25:16.735: INFO: namespace downward-api-1140 deletion completed in 6.081432208s

• [SLOW TEST:8.276 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:25:16.735: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-2731
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: getting the auto-created API token
STEP: reading a file in the container
Sep 27 21:25:19.411: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-2731 pod-service-account-24f967f9-2e2f-42ae-a2b1-df5230230277 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Sep 27 21:25:19.566: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-2731 pod-service-account-24f967f9-2e2f-42ae-a2b1-df5230230277 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Sep 27 21:25:19.711: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-2731 pod-service-account-24f967f9-2e2f-42ae-a2b1-df5230230277 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:25:19.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-2731" for this suite.
Sep 27 21:25:25.873: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:25:25.945: INFO: namespace svcaccounts-2731 deletion completed in 6.083387225s

• [SLOW TEST:9.209 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:25:25.945: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-5304
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 27 21:25:26.093: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:25:28.135: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5304" for this suite.
Sep 27 21:26:12.149: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:26:12.220: INFO: namespace pods-5304 deletion completed in 44.081919422s

• [SLOW TEST:46.275 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:26:12.220: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9406
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-fe235648-9cdc-454c-8eca-82d318a66124
STEP: Creating a pod to test consume configMaps
Sep 27 21:26:12.385: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-3fcc326d-4bda-4b1d-9821-0e9f6fed5deb" in namespace "projected-9406" to be "success or failure"
Sep 27 21:26:12.387: INFO: Pod "pod-projected-configmaps-3fcc326d-4bda-4b1d-9821-0e9f6fed5deb": Phase="Pending", Reason="", readiness=false. Elapsed: 1.877089ms
Sep 27 21:26:14.389: INFO: Pod "pod-projected-configmaps-3fcc326d-4bda-4b1d-9821-0e9f6fed5deb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004290408s
STEP: Saw pod success
Sep 27 21:26:14.389: INFO: Pod "pod-projected-configmaps-3fcc326d-4bda-4b1d-9821-0e9f6fed5deb" satisfied condition "success or failure"
Sep 27 21:26:14.391: INFO: Trying to get logs from node macpro-2 pod pod-projected-configmaps-3fcc326d-4bda-4b1d-9821-0e9f6fed5deb container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 27 21:26:14.411: INFO: Waiting for pod pod-projected-configmaps-3fcc326d-4bda-4b1d-9821-0e9f6fed5deb to disappear
Sep 27 21:26:14.412: INFO: Pod pod-projected-configmaps-3fcc326d-4bda-4b1d-9821-0e9f6fed5deb no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:26:14.412: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9406" for this suite.
Sep 27 21:26:20.427: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:26:20.498: INFO: namespace projected-9406 deletion completed in 6.083434752s

• [SLOW TEST:8.279 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:26:20.498: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3117
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep 27 21:26:20.651: INFO: Waiting up to 5m0s for pod "downwardapi-volume-15b883ff-50d7-46a9-b57d-1af4af350b22" in namespace "downward-api-3117" to be "success or failure"
Sep 27 21:26:20.653: INFO: Pod "downwardapi-volume-15b883ff-50d7-46a9-b57d-1af4af350b22": Phase="Pending", Reason="", readiness=false. Elapsed: 1.85071ms
Sep 27 21:26:22.656: INFO: Pod "downwardapi-volume-15b883ff-50d7-46a9-b57d-1af4af350b22": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004676768s
STEP: Saw pod success
Sep 27 21:26:22.656: INFO: Pod "downwardapi-volume-15b883ff-50d7-46a9-b57d-1af4af350b22" satisfied condition "success or failure"
Sep 27 21:26:22.658: INFO: Trying to get logs from node macpro-2 pod downwardapi-volume-15b883ff-50d7-46a9-b57d-1af4af350b22 container client-container: <nil>
STEP: delete the pod
Sep 27 21:26:22.688: INFO: Waiting for pod downwardapi-volume-15b883ff-50d7-46a9-b57d-1af4af350b22 to disappear
Sep 27 21:26:22.690: INFO: Pod downwardapi-volume-15b883ff-50d7-46a9-b57d-1af4af350b22 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:26:22.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3117" for this suite.
Sep 27 21:26:28.703: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:26:28.776: INFO: namespace downward-api-3117 deletion completed in 6.083706048s

• [SLOW TEST:8.278 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:26:28.776: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7580
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting the proxy server
Sep 27 21:26:28.927: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-741451867 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:26:28.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7580" for this suite.
Sep 27 21:26:34.994: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:26:35.064: INFO: namespace kubectl-7580 deletion completed in 6.081325055s

• [SLOW TEST:6.287 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:26:35.064: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-4519
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 27 21:26:35.280: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"e69e896a-1f44-4141-996e-1bc61ef406ca", Controller:(*bool)(0xc003550dc2), BlockOwnerDeletion:(*bool)(0xc003550dc3)}}
Sep 27 21:26:35.293: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"04134c9b-f40d-427b-ad43-8ed42f1e6f86", Controller:(*bool)(0xc0030a6eba), BlockOwnerDeletion:(*bool)(0xc0030a6ebb)}}
Sep 27 21:26:35.319: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"6bb88063-596b-4e0d-902b-25d148ce1998", Controller:(*bool)(0xc0030a70ca), BlockOwnerDeletion:(*bool)(0xc0030a70cb)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:26:40.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4519" for this suite.
Sep 27 21:26:46.349: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:26:46.420: INFO: namespace gc-4519 deletion completed in 6.089065814s

• [SLOW TEST:11.357 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:26:46.421: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4185
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1686
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep 27 21:26:46.568: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-4185'
Sep 27 21:26:46.647: INFO: stderr: ""
Sep 27 21:26:46.647: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1691
Sep 27 21:26:46.652: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 delete pods e2e-test-nginx-pod --namespace=kubectl-4185'
Sep 27 21:26:51.436: INFO: stderr: ""
Sep 27 21:26:51.436: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:26:51.436: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4185" for this suite.
Sep 27 21:26:57.451: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:26:57.527: INFO: namespace kubectl-4185 deletion completed in 6.088081201s

• [SLOW TEST:11.106 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:26:57.527: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-4118
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Sep 27 21:26:57.676: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:27:01.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4118" for this suite.
Sep 27 21:27:07.267: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:27:07.337: INFO: namespace init-container-4118 deletion completed in 6.082057995s

• [SLOW TEST:9.809 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:27:07.337: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-9607
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Sep 27 21:27:09.502: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:27:09.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-9607" for this suite.
Sep 27 21:27:15.550: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:27:15.620: INFO: namespace container-runtime-9607 deletion completed in 6.091081262s

• [SLOW TEST:8.283 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:27:15.621: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-3677
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod busybox-d2c24487-f35c-4ab3-a193-bf79f1f9bfee in namespace container-probe-3677
Sep 27 21:27:17.787: INFO: Started pod busybox-d2c24487-f35c-4ab3-a193-bf79f1f9bfee in namespace container-probe-3677
STEP: checking the pod's current state and verifying that restartCount is present
Sep 27 21:27:17.788: INFO: Initial restart count of pod busybox-d2c24487-f35c-4ab3-a193-bf79f1f9bfee is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:31:18.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3677" for this suite.
Sep 27 21:31:24.174: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:31:24.245: INFO: namespace container-probe-3677 deletion completed in 6.085730075s

• [SLOW TEST:248.624 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:31:24.245: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3993
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-876e5677-1552-42bd-b926-d914378f70e7
STEP: Creating a pod to test consume configMaps
Sep 27 21:31:24.405: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f9b14329-0e52-45c6-824b-a4e550a67278" in namespace "projected-3993" to be "success or failure"
Sep 27 21:31:24.413: INFO: Pod "pod-projected-configmaps-f9b14329-0e52-45c6-824b-a4e550a67278": Phase="Pending", Reason="", readiness=false. Elapsed: 8.019983ms
Sep 27 21:31:26.416: INFO: Pod "pod-projected-configmaps-f9b14329-0e52-45c6-824b-a4e550a67278": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01059095s
STEP: Saw pod success
Sep 27 21:31:26.416: INFO: Pod "pod-projected-configmaps-f9b14329-0e52-45c6-824b-a4e550a67278" satisfied condition "success or failure"
Sep 27 21:31:26.418: INFO: Trying to get logs from node macpro-2 pod pod-projected-configmaps-f9b14329-0e52-45c6-824b-a4e550a67278 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 27 21:31:26.442: INFO: Waiting for pod pod-projected-configmaps-f9b14329-0e52-45c6-824b-a4e550a67278 to disappear
Sep 27 21:31:26.444: INFO: Pod pod-projected-configmaps-f9b14329-0e52-45c6-824b-a4e550a67278 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:31:26.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3993" for this suite.
Sep 27 21:31:32.458: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:31:32.540: INFO: namespace projected-3993 deletion completed in 6.094140783s

• [SLOW TEST:8.296 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:31:32.541: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-8795
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Sep 27 21:31:33.032: INFO: Pod name wrapped-volume-race-d87db58c-a4bf-4d2a-b0d0-65ceec3a680a: Found 0 pods out of 5
Sep 27 21:31:38.041: INFO: Pod name wrapped-volume-race-d87db58c-a4bf-4d2a-b0d0-65ceec3a680a: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-d87db58c-a4bf-4d2a-b0d0-65ceec3a680a in namespace emptydir-wrapper-8795, will wait for the garbage collector to delete the pods
Sep 27 21:31:48.121: INFO: Deleting ReplicationController wrapped-volume-race-d87db58c-a4bf-4d2a-b0d0-65ceec3a680a took: 12.437631ms
Sep 27 21:31:48.421: INFO: Terminating ReplicationController wrapped-volume-race-d87db58c-a4bf-4d2a-b0d0-65ceec3a680a pods took: 300.18866ms
STEP: Creating RC which spawns configmap-volume pods
Sep 27 21:32:32.539: INFO: Pod name wrapped-volume-race-3cdea477-608d-4ee9-bd7e-d1a6f0ff7525: Found 0 pods out of 5
Sep 27 21:32:37.543: INFO: Pod name wrapped-volume-race-3cdea477-608d-4ee9-bd7e-d1a6f0ff7525: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-3cdea477-608d-4ee9-bd7e-d1a6f0ff7525 in namespace emptydir-wrapper-8795, will wait for the garbage collector to delete the pods
Sep 27 21:32:49.634: INFO: Deleting ReplicationController wrapped-volume-race-3cdea477-608d-4ee9-bd7e-d1a6f0ff7525 took: 8.87448ms
Sep 27 21:32:49.934: INFO: Terminating ReplicationController wrapped-volume-race-3cdea477-608d-4ee9-bd7e-d1a6f0ff7525 pods took: 300.194226ms
STEP: Creating RC which spawns configmap-volume pods
Sep 27 21:33:23.770: INFO: Pod name wrapped-volume-race-9db13d2a-fe5d-4ef1-a72b-d2be7dcb184c: Found 0 pods out of 5
Sep 27 21:33:28.774: INFO: Pod name wrapped-volume-race-9db13d2a-fe5d-4ef1-a72b-d2be7dcb184c: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-9db13d2a-fe5d-4ef1-a72b-d2be7dcb184c in namespace emptydir-wrapper-8795, will wait for the garbage collector to delete the pods
Sep 27 21:33:40.851: INFO: Deleting ReplicationController wrapped-volume-race-9db13d2a-fe5d-4ef1-a72b-d2be7dcb184c took: 9.449158ms
Sep 27 21:33:41.151: INFO: Terminating ReplicationController wrapped-volume-race-9db13d2a-fe5d-4ef1-a72b-d2be7dcb184c pods took: 300.137276ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:34:22.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-8795" for this suite.
Sep 27 21:34:30.355: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:34:30.428: INFO: namespace emptydir-wrapper-8795 deletion completed in 8.091159027s

• [SLOW TEST:177.888 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:34:30.428: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9649
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on tmpfs
Sep 27 21:34:30.595: INFO: Waiting up to 5m0s for pod "pod-486cf458-7f03-44ff-b1d5-5fb164b2ba56" in namespace "emptydir-9649" to be "success or failure"
Sep 27 21:34:30.597: INFO: Pod "pod-486cf458-7f03-44ff-b1d5-5fb164b2ba56": Phase="Pending", Reason="", readiness=false. Elapsed: 1.923009ms
Sep 27 21:34:32.600: INFO: Pod "pod-486cf458-7f03-44ff-b1d5-5fb164b2ba56": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004903573s
STEP: Saw pod success
Sep 27 21:34:32.600: INFO: Pod "pod-486cf458-7f03-44ff-b1d5-5fb164b2ba56" satisfied condition "success or failure"
Sep 27 21:34:32.602: INFO: Trying to get logs from node macpro-3 pod pod-486cf458-7f03-44ff-b1d5-5fb164b2ba56 container test-container: <nil>
STEP: delete the pod
Sep 27 21:34:32.636: INFO: Waiting for pod pod-486cf458-7f03-44ff-b1d5-5fb164b2ba56 to disappear
Sep 27 21:34:32.638: INFO: Pod pod-486cf458-7f03-44ff-b1d5-5fb164b2ba56 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:34:32.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9649" for this suite.
Sep 27 21:34:38.652: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:34:38.720: INFO: namespace emptydir-9649 deletion completed in 6.079025669s

• [SLOW TEST:8.291 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:34:38.721: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-4070
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating replication controller my-hostname-basic-a8490309-b59e-4bde-b9a9-d3b525f58c70
Sep 27 21:34:38.886: INFO: Pod name my-hostname-basic-a8490309-b59e-4bde-b9a9-d3b525f58c70: Found 0 pods out of 1
Sep 27 21:34:43.889: INFO: Pod name my-hostname-basic-a8490309-b59e-4bde-b9a9-d3b525f58c70: Found 1 pods out of 1
Sep 27 21:34:43.889: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-a8490309-b59e-4bde-b9a9-d3b525f58c70" are running
Sep 27 21:34:43.891: INFO: Pod "my-hostname-basic-a8490309-b59e-4bde-b9a9-d3b525f58c70-6gvmr" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-27 21:34:38 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-27 21:34:41 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-27 21:34:41 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-27 21:34:38 +0000 UTC Reason: Message:}])
Sep 27 21:34:43.891: INFO: Trying to dial the pod
Sep 27 21:34:48.899: INFO: Controller my-hostname-basic-a8490309-b59e-4bde-b9a9-d3b525f58c70: Got expected result from replica 1 [my-hostname-basic-a8490309-b59e-4bde-b9a9-d3b525f58c70-6gvmr]: "my-hostname-basic-a8490309-b59e-4bde-b9a9-d3b525f58c70-6gvmr", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:34:48.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-4070" for this suite.
Sep 27 21:34:54.913: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:34:54.983: INFO: namespace replication-controller-4070 deletion completed in 6.081457304s

• [SLOW TEST:16.263 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:34:54.984: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1309
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating Redis RC
Sep 27 21:34:55.135: INFO: namespace kubectl-1309
Sep 27 21:34:55.135: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 create -f - --namespace=kubectl-1309'
Sep 27 21:34:55.845: INFO: stderr: ""
Sep 27 21:34:55.845: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Sep 27 21:34:56.847: INFO: Selector matched 1 pods for map[app:redis]
Sep 27 21:34:56.847: INFO: Found 0 / 1
Sep 27 21:34:57.848: INFO: Selector matched 1 pods for map[app:redis]
Sep 27 21:34:57.848: INFO: Found 0 / 1
Sep 27 21:34:58.848: INFO: Selector matched 1 pods for map[app:redis]
Sep 27 21:34:58.848: INFO: Found 1 / 1
Sep 27 21:34:58.848: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Sep 27 21:34:58.850: INFO: Selector matched 1 pods for map[app:redis]
Sep 27 21:34:58.850: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Sep 27 21:34:58.850: INFO: wait on redis-master startup in kubectl-1309 
Sep 27 21:34:58.850: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 logs redis-master-vq545 redis-master --namespace=kubectl-1309'
Sep 27 21:34:58.930: INFO: stderr: ""
Sep 27 21:34:58.930: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 27 Sep 21:34:57.668 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 27 Sep 21:34:57.668 # Server started, Redis version 3.2.12\n1:M 27 Sep 21:34:57.668 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 27 Sep 21:34:57.668 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Sep 27 21:34:58.930: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-1309'
Sep 27 21:34:59.022: INFO: stderr: ""
Sep 27 21:34:59.022: INFO: stdout: "service/rm2 exposed\n"
Sep 27 21:34:59.032: INFO: Service rm2 in namespace kubectl-1309 found.
STEP: exposing service
Sep 27 21:35:01.037: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-1309'
Sep 27 21:35:01.119: INFO: stderr: ""
Sep 27 21:35:01.119: INFO: stdout: "service/rm3 exposed\n"
Sep 27 21:35:01.123: INFO: Service rm3 in namespace kubectl-1309 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:35:03.128: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1309" for this suite.
Sep 27 21:35:25.143: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:35:25.213: INFO: namespace kubectl-1309 deletion completed in 22.081922258s

• [SLOW TEST:30.229 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl expose
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create services for rc  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:35:25.213: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-9600
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Sep 27 21:35:27.376: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:35:27.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-9600" for this suite.
Sep 27 21:35:33.411: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:35:33.481: INFO: namespace container-runtime-9600 deletion completed in 6.081360985s

• [SLOW TEST:8.268 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:35:33.481: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-5482
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-5482
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep 27 21:35:33.629: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Sep 27 21:35:57.755: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.153.45:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5482 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 27 21:35:57.755: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
Sep 27 21:35:57.856: INFO: Found all expected endpoints: [netserver-0]
Sep 27 21:35:57.865: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.151.236:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5482 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 27 21:35:57.865: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
Sep 27 21:35:57.954: INFO: Found all expected endpoints: [netserver-1]
Sep 27 21:35:57.957: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.150.172:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5482 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 27 21:35:57.957: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
Sep 27 21:35:58.042: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:35:58.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5482" for this suite.
Sep 27 21:36:14.058: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:36:14.129: INFO: namespace pod-network-test-5482 deletion completed in 16.08371571s

• [SLOW TEST:40.648 seconds]
[sig-network] Networking
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:36:14.129: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2492
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-4b0be486-f7c1-45ed-890e-eb9753831de0
STEP: Creating a pod to test consume configMaps
Sep 27 21:36:14.297: INFO: Waiting up to 5m0s for pod "pod-configmaps-f7170b13-879d-440f-b828-4a949fc89e58" in namespace "configmap-2492" to be "success or failure"
Sep 27 21:36:14.299: INFO: Pod "pod-configmaps-f7170b13-879d-440f-b828-4a949fc89e58": Phase="Pending", Reason="", readiness=false. Elapsed: 1.907746ms
Sep 27 21:36:16.302: INFO: Pod "pod-configmaps-f7170b13-879d-440f-b828-4a949fc89e58": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004654992s
STEP: Saw pod success
Sep 27 21:36:16.302: INFO: Pod "pod-configmaps-f7170b13-879d-440f-b828-4a949fc89e58" satisfied condition "success or failure"
Sep 27 21:36:16.310: INFO: Trying to get logs from node macpro-3 pod pod-configmaps-f7170b13-879d-440f-b828-4a949fc89e58 container configmap-volume-test: <nil>
STEP: delete the pod
Sep 27 21:36:16.329: INFO: Waiting for pod pod-configmaps-f7170b13-879d-440f-b828-4a949fc89e58 to disappear
Sep 27 21:36:16.331: INFO: Pod pod-configmaps-f7170b13-879d-440f-b828-4a949fc89e58 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:36:16.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2492" for this suite.
Sep 27 21:36:22.345: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:36:22.417: INFO: namespace configmap-2492 deletion completed in 6.083350625s

• [SLOW TEST:8.288 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:36:22.417: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-1190
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:36:24.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1190" for this suite.
Sep 27 21:37:02.604: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:37:02.672: INFO: namespace kubelet-test-1190 deletion completed in 38.07950184s

• [SLOW TEST:40.254 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:37:02.672: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4097
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the initial replication controller
Sep 27 21:37:02.816: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 create -f - --namespace=kubectl-4097'
Sep 27 21:37:03.015: INFO: stderr: ""
Sep 27 21:37:03.015: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep 27 21:37:03.015: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4097'
Sep 27 21:37:03.085: INFO: stderr: ""
Sep 27 21:37:03.085: INFO: stdout: "update-demo-nautilus-mj4b7 update-demo-nautilus-wv4bm "
Sep 27 21:37:03.085: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 get pods update-demo-nautilus-mj4b7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4097'
Sep 27 21:37:03.144: INFO: stderr: ""
Sep 27 21:37:03.144: INFO: stdout: ""
Sep 27 21:37:03.144: INFO: update-demo-nautilus-mj4b7 is created but not running
Sep 27 21:37:08.145: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4097'
Sep 27 21:37:08.207: INFO: stderr: ""
Sep 27 21:37:08.207: INFO: stdout: "update-demo-nautilus-mj4b7 update-demo-nautilus-wv4bm "
Sep 27 21:37:08.207: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 get pods update-demo-nautilus-mj4b7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4097'
Sep 27 21:37:08.274: INFO: stderr: ""
Sep 27 21:37:08.274: INFO: stdout: "true"
Sep 27 21:37:08.274: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 get pods update-demo-nautilus-mj4b7 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4097'
Sep 27 21:37:08.333: INFO: stderr: ""
Sep 27 21:37:08.333: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 27 21:37:08.333: INFO: validating pod update-demo-nautilus-mj4b7
Sep 27 21:37:08.337: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 27 21:37:08.337: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 27 21:37:08.337: INFO: update-demo-nautilus-mj4b7 is verified up and running
Sep 27 21:37:08.337: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 get pods update-demo-nautilus-wv4bm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4097'
Sep 27 21:37:08.397: INFO: stderr: ""
Sep 27 21:37:08.397: INFO: stdout: "true"
Sep 27 21:37:08.397: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 get pods update-demo-nautilus-wv4bm -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4097'
Sep 27 21:37:08.456: INFO: stderr: ""
Sep 27 21:37:08.456: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 27 21:37:08.456: INFO: validating pod update-demo-nautilus-wv4bm
Sep 27 21:37:08.460: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 27 21:37:08.460: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 27 21:37:08.460: INFO: update-demo-nautilus-wv4bm is verified up and running
STEP: rolling-update to new replication controller
Sep 27 21:37:08.461: INFO: scanned /root for discovery docs: <nil>
Sep 27 21:37:08.461: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-4097'
Sep 27 21:37:30.826: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Sep 27 21:37:30.826: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep 27 21:37:30.826: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4097'
Sep 27 21:37:30.890: INFO: stderr: ""
Sep 27 21:37:30.890: INFO: stdout: "update-demo-kitten-bmtk6 update-demo-kitten-tdkf4 "
Sep 27 21:37:30.890: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 get pods update-demo-kitten-bmtk6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4097'
Sep 27 21:37:30.951: INFO: stderr: ""
Sep 27 21:37:30.951: INFO: stdout: "true"
Sep 27 21:37:30.951: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 get pods update-demo-kitten-bmtk6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4097'
Sep 27 21:37:31.012: INFO: stderr: ""
Sep 27 21:37:31.012: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Sep 27 21:37:31.012: INFO: validating pod update-demo-kitten-bmtk6
Sep 27 21:37:31.016: INFO: got data: {
  "image": "kitten.jpg"
}

Sep 27 21:37:31.016: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Sep 27 21:37:31.016: INFO: update-demo-kitten-bmtk6 is verified up and running
Sep 27 21:37:31.016: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 get pods update-demo-kitten-tdkf4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4097'
Sep 27 21:37:31.077: INFO: stderr: ""
Sep 27 21:37:31.077: INFO: stdout: "true"
Sep 27 21:37:31.077: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 get pods update-demo-kitten-tdkf4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4097'
Sep 27 21:37:31.135: INFO: stderr: ""
Sep 27 21:37:31.135: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Sep 27 21:37:31.135: INFO: validating pod update-demo-kitten-tdkf4
Sep 27 21:37:31.139: INFO: got data: {
  "image": "kitten.jpg"
}

Sep 27 21:37:31.139: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Sep 27 21:37:31.139: INFO: update-demo-kitten-tdkf4 is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:37:31.139: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4097" for this suite.
Sep 27 21:37:53.152: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:37:53.236: INFO: namespace kubectl-4097 deletion completed in 22.0943227s

• [SLOW TEST:50.564 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:37:53.236: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-9163
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-map-220935eb-9f58-460a-9e77-37747e24d64c
STEP: Creating a pod to test consume secrets
Sep 27 21:37:53.395: INFO: Waiting up to 5m0s for pod "pod-secrets-0a281137-06a8-4da5-95f3-9ea8664d3221" in namespace "secrets-9163" to be "success or failure"
Sep 27 21:37:53.397: INFO: Pod "pod-secrets-0a281137-06a8-4da5-95f3-9ea8664d3221": Phase="Pending", Reason="", readiness=false. Elapsed: 1.77387ms
Sep 27 21:37:55.400: INFO: Pod "pod-secrets-0a281137-06a8-4da5-95f3-9ea8664d3221": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004622698s
STEP: Saw pod success
Sep 27 21:37:55.400: INFO: Pod "pod-secrets-0a281137-06a8-4da5-95f3-9ea8664d3221" satisfied condition "success or failure"
Sep 27 21:37:55.402: INFO: Trying to get logs from node macpro-3 pod pod-secrets-0a281137-06a8-4da5-95f3-9ea8664d3221 container secret-volume-test: <nil>
STEP: delete the pod
Sep 27 21:37:55.432: INFO: Waiting for pod pod-secrets-0a281137-06a8-4da5-95f3-9ea8664d3221 to disappear
Sep 27 21:37:55.434: INFO: Pod pod-secrets-0a281137-06a8-4da5-95f3-9ea8664d3221 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:37:55.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9163" for this suite.
Sep 27 21:38:01.450: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:38:01.520: INFO: namespace secrets-9163 deletion completed in 6.083492284s

• [SLOW TEST:8.285 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:38:01.520: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2560
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep 27 21:38:01.688: INFO: Waiting up to 5m0s for pod "downwardapi-volume-14e436a0-8dd3-4914-9a93-df38f43902fa" in namespace "projected-2560" to be "success or failure"
Sep 27 21:38:01.690: INFO: Pod "downwardapi-volume-14e436a0-8dd3-4914-9a93-df38f43902fa": Phase="Pending", Reason="", readiness=false. Elapsed: 1.781235ms
Sep 27 21:38:03.693: INFO: Pod "downwardapi-volume-14e436a0-8dd3-4914-9a93-df38f43902fa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004492723s
STEP: Saw pod success
Sep 27 21:38:03.693: INFO: Pod "downwardapi-volume-14e436a0-8dd3-4914-9a93-df38f43902fa" satisfied condition "success or failure"
Sep 27 21:38:03.695: INFO: Trying to get logs from node macpro-1 pod downwardapi-volume-14e436a0-8dd3-4914-9a93-df38f43902fa container client-container: <nil>
STEP: delete the pod
Sep 27 21:38:03.721: INFO: Waiting for pod downwardapi-volume-14e436a0-8dd3-4914-9a93-df38f43902fa to disappear
Sep 27 21:38:03.723: INFO: Pod downwardapi-volume-14e436a0-8dd3-4914-9a93-df38f43902fa no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:38:03.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2560" for this suite.
Sep 27 21:38:09.737: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:38:09.808: INFO: namespace projected-2560 deletion completed in 6.082154148s

• [SLOW TEST:8.287 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:38:09.808: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-459
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-cfe27adf-a52c-4fac-9083-8fcef8f2ea14
STEP: Creating a pod to test consume configMaps
Sep 27 21:38:09.975: INFO: Waiting up to 5m0s for pod "pod-configmaps-1cec7f68-1536-4e5d-a93f-56aa5e9deec3" in namespace "configmap-459" to be "success or failure"
Sep 27 21:38:09.977: INFO: Pod "pod-configmaps-1cec7f68-1536-4e5d-a93f-56aa5e9deec3": Phase="Pending", Reason="", readiness=false. Elapsed: 1.853312ms
Sep 27 21:38:11.980: INFO: Pod "pod-configmaps-1cec7f68-1536-4e5d-a93f-56aa5e9deec3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004826761s
STEP: Saw pod success
Sep 27 21:38:11.980: INFO: Pod "pod-configmaps-1cec7f68-1536-4e5d-a93f-56aa5e9deec3" satisfied condition "success or failure"
Sep 27 21:38:11.982: INFO: Trying to get logs from node macpro-2 pod pod-configmaps-1cec7f68-1536-4e5d-a93f-56aa5e9deec3 container configmap-volume-test: <nil>
STEP: delete the pod
Sep 27 21:38:12.008: INFO: Waiting for pod pod-configmaps-1cec7f68-1536-4e5d-a93f-56aa5e9deec3 to disappear
Sep 27 21:38:12.009: INFO: Pod pod-configmaps-1cec7f68-1536-4e5d-a93f-56aa5e9deec3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:38:12.010: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-459" for this suite.
Sep 27 21:38:18.024: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:38:18.098: INFO: namespace configmap-459 deletion completed in 6.085581881s

• [SLOW TEST:8.290 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:38:18.098: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4188
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep 27 21:38:18.259: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e57058d2-c279-4ca2-adb7-23175921ff90" in namespace "projected-4188" to be "success or failure"
Sep 27 21:38:18.261: INFO: Pod "downwardapi-volume-e57058d2-c279-4ca2-adb7-23175921ff90": Phase="Pending", Reason="", readiness=false. Elapsed: 1.847778ms
Sep 27 21:38:20.263: INFO: Pod "downwardapi-volume-e57058d2-c279-4ca2-adb7-23175921ff90": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004769243s
Sep 27 21:38:22.266: INFO: Pod "downwardapi-volume-e57058d2-c279-4ca2-adb7-23175921ff90": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007391433s
STEP: Saw pod success
Sep 27 21:38:22.266: INFO: Pod "downwardapi-volume-e57058d2-c279-4ca2-adb7-23175921ff90" satisfied condition "success or failure"
Sep 27 21:38:22.268: INFO: Trying to get logs from node macpro-2 pod downwardapi-volume-e57058d2-c279-4ca2-adb7-23175921ff90 container client-container: <nil>
STEP: delete the pod
Sep 27 21:38:22.292: INFO: Waiting for pod downwardapi-volume-e57058d2-c279-4ca2-adb7-23175921ff90 to disappear
Sep 27 21:38:22.294: INFO: Pod downwardapi-volume-e57058d2-c279-4ca2-adb7-23175921ff90 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:38:22.294: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4188" for this suite.
Sep 27 21:38:28.308: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:38:28.389: INFO: namespace projected-4188 deletion completed in 6.092631918s

• [SLOW TEST:10.291 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:38:28.390: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7299
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name cm-test-opt-del-a3b75e53-a684-4726-a5d7-7e6ac5aa1b9b
STEP: Creating configMap with name cm-test-opt-upd-8a406abf-a64b-4ce2-b2f5-d3f539900f39
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-a3b75e53-a684-4726-a5d7-7e6ac5aa1b9b
STEP: Updating configmap cm-test-opt-upd-8a406abf-a64b-4ce2-b2f5-d3f539900f39
STEP: Creating configMap with name cm-test-opt-create-55891bb2-dcda-4ce5-a42e-79c6dd03ed72
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:39:44.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7299" for this suite.
Sep 27 21:40:06.955: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:40:07.036: INFO: namespace projected-7299 deletion completed in 22.092754085s

• [SLOW TEST:98.646 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:40:07.036: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9844
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 27 21:40:07.185: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 create -f - --namespace=kubectl-9844'
Sep 27 21:40:07.377: INFO: stderr: ""
Sep 27 21:40:07.377: INFO: stdout: "replicationcontroller/redis-master created\n"
Sep 27 21:40:07.377: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 create -f - --namespace=kubectl-9844'
Sep 27 21:40:07.591: INFO: stderr: ""
Sep 27 21:40:07.591: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Sep 27 21:40:08.594: INFO: Selector matched 1 pods for map[app:redis]
Sep 27 21:40:08.594: INFO: Found 0 / 1
Sep 27 21:40:09.594: INFO: Selector matched 1 pods for map[app:redis]
Sep 27 21:40:09.594: INFO: Found 1 / 1
Sep 27 21:40:09.594: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Sep 27 21:40:09.596: INFO: Selector matched 1 pods for map[app:redis]
Sep 27 21:40:09.596: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Sep 27 21:40:09.596: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 describe pod redis-master-2nlf9 --namespace=kubectl-9844'
Sep 27 21:40:09.669: INFO: stderr: ""
Sep 27 21:40:09.669: INFO: stdout: "Name:           redis-master-2nlf9\nNamespace:      kubectl-9844\nPriority:       0\nNode:           macpro-2/10.10.10.5\nStart Time:     Fri, 27 Sep 2019 21:40:07 +0000\nLabels:         app=redis\n                role=master\nAnnotations:    cni.projectcalico.org/podIP: 192.168.150.176/32\n                kubernetes.io/psp: e2e-test-privileged-psp\nStatus:         Running\nIP:             192.168.150.176\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://6cb542b4d6bfe4ab89bf6605bbc46c38a703a525b46ae976598068e2bedd0e50\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Fri, 27 Sep 2019 21:40:08 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-7pkbt (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-7pkbt:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-7pkbt\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  2s    default-scheduler  Successfully assigned kubectl-9844/redis-master-2nlf9 to macpro-2\n  Normal  Pulled     1s    kubelet, macpro-2  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    1s    kubelet, macpro-2  Created container redis-master\n  Normal  Started    1s    kubelet, macpro-2  Started container redis-master\n"
Sep 27 21:40:09.669: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 describe rc redis-master --namespace=kubectl-9844'
Sep 27 21:40:09.747: INFO: stderr: ""
Sep 27 21:40:09.747: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-9844\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: redis-master-2nlf9\n"
Sep 27 21:40:09.747: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 describe service redis-master --namespace=kubectl-9844'
Sep 27 21:40:09.818: INFO: stderr: ""
Sep 27 21:40:09.818: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-9844\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.109.45.237\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         192.168.150.176:6379\nSession Affinity:  None\nEvents:            <none>\n"
Sep 27 21:40:09.820: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 describe node macpro-1'
Sep 27 21:40:09.907: INFO: stderr: ""
Sep 27 21:40:09.907: INFO: stdout: "Name:               macpro-1\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=macpro-1\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/master=\nAnnotations:        kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 10.10.10.4/24\n                    projectcalico.org/IPv4IPIPTunnelAddr: 192.168.151.192\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Thu, 08 Aug 2019 01:50:17 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Thu, 08 Aug 2019 02:05:44 +0000   Thu, 08 Aug 2019 02:05:44 +0000   CalicoIsUp                   Calico is running on this node\n  MemoryPressure       False   Fri, 27 Sep 2019 21:39:58 +0000   Thu, 08 Aug 2019 01:50:13 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Fri, 27 Sep 2019 21:39:58 +0000   Thu, 08 Aug 2019 01:50:13 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Fri, 27 Sep 2019 21:39:58 +0000   Thu, 08 Aug 2019 01:50:13 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Fri, 27 Sep 2019 21:39:58 +0000   Tue, 13 Aug 2019 03:45:01 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  10.10.10.4\n  Hostname:    macpro-1\nCapacity:\n cpu:                24\n ephemeral-storage:  944258648Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             66003696Ki\n pods:               110\nAllocatable:\n cpu:                24\n ephemeral-storage:  870228768556\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             65901296Ki\n pods:               110\nSystem Info:\n Machine ID:                 0cb3c3463e984bfaa3a034f05ba278fc\n System UUID:                26c0191a-6414-5557-ad28-a8a963c01d2d\n Boot ID:                    4c89e8e9-0494-4bbb-9ad9-4ee1a4b4131f\n Kernel Version:             4.19.43-coreos\n OS Image:                   Container Linux by CoreOS 2079.4.0 (Rhyolite)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.6.3\n Kubelet Version:            v1.15.1\n Kube-Proxy Version:         v1.15.1\nPodCIDR:                     192.168.0.0/24\nNon-terminated Pods:         (13 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  default                    orka-5c9d6bfc94-rxjt9                                      0 (0%)        0 (0%)      0 (0%)           0 (0%)         91m\n  default                    rethinkdb-57544557d7-kssqr                                 250m (1%)     0 (0%)      500Mi (0%)       0 (0%)         50d\n  kube-system                calico-kube-controllers-7bd78b474d-t2lgl                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         50d\n  kube-system                calico-node-6vk4s                                          250m (1%)     0 (0%)      0 (0%)           0 (0%)         50d\n  kube-system                coredns-5c98db65d4-9bgxc                                   100m (0%)     0 (0%)      70Mi (0%)        170Mi (0%)     50d\n  kube-system                coredns-5c98db65d4-hxb4g                                   100m (0%)     0 (0%)      70Mi (0%)        170Mi (0%)     50d\n  kube-system                etcd-macpro-1                                              0 (0%)        0 (0%)      0 (0%)           0 (0%)         50d\n  kube-system                kube-controller-manager-macpro-1                           200m (0%)     0 (0%)      0 (0%)           0 (0%)         50d\n  kube-system                kube-proxy-zgndg                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         50d\n  kube-system                kube-scheduler-macpro-1                                    100m (0%)     0 (0%)      0 (0%)           0 (0%)         50d\n  metallb-system             controller-55d74449-q2f47                                  100m (0%)     100m (0%)   100Mi (0%)       100Mi (0%)     50d\n  metallb-system             speaker-msvrw                                              100m (0%)     100m (0%)   100Mi (0%)       100Mi (0%)     50d\n  sonobuoy                   sonobuoy-systemd-logs-daemon-set-3ff1c1a60c394bba-c5zcw    0 (0%)        0 (0%)      0 (0%)           0 (0%)         23m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                1200m (5%)  200m (0%)\n  memory             840Mi (1%)  540Mi (0%)\n  ephemeral-storage  0 (0%)      0 (0%)\nEvents:              <none>\n"
Sep 27 21:40:09.907: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 describe namespace kubectl-9844'
Sep 27 21:40:09.975: INFO: stderr: ""
Sep 27 21:40:09.975: INFO: stdout: "Name:         kubectl-9844\nLabels:       e2e-framework=kubectl\n              e2e-run=24d25b09-58b8-4d09-9136-b13c1aef9d6c\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:40:09.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9844" for this suite.
Sep 27 21:40:31.989: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:40:32.064: INFO: namespace kubectl-9844 deletion completed in 22.086749588s

• [SLOW TEST:25.029 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl describe
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:40:32.065: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-1983
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 27 21:40:32.231: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Sep 27 21:40:37.234: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Sep 27 21:40:37.234: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Sep 27 21:40:37.249: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-1983,SelfLink:/apis/apps/v1/namespaces/deployment-1983/deployments/test-cleanup-deployment,UID:63ca334e-c75b-4f00-9034-b7e283cbe4f1,ResourceVersion:7622330,Generation:1,CreationTimestamp:2019-09-27 21:40:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Sep 27 21:40:37.253: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
Sep 27 21:40:37.253: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Sep 27 21:40:37.253: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:deployment-1983,SelfLink:/apis/apps/v1/namespaces/deployment-1983/replicasets/test-cleanup-controller,UID:68d104fb-1ff2-4719-b2f0-9726da6e498a,ResourceVersion:7622331,Generation:1,CreationTimestamp:2019-09-27 21:40:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 63ca334e-c75b-4f00-9034-b7e283cbe4f1 0xc000400be7 0xc000400be8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Sep 27 21:40:37.256: INFO: Pod "test-cleanup-controller-vd2xj" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-vd2xj,GenerateName:test-cleanup-controller-,Namespace:deployment-1983,SelfLink:/api/v1/namespaces/deployment-1983/pods/test-cleanup-controller-vd2xj,UID:96c1fb50-ab61-48f2-86ca-747c16355fbb,ResourceVersion:7622324,Generation:0,CreationTimestamp:2019-09-27 21:40:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.153.50/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller 68d104fb-1ff2-4719-b2f0-9726da6e498a 0xc0022960f7 0xc0022960f8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-k6cxp {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-k6cxp,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-k6cxp true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:macpro-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002296170} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002296190}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:40:32 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:40:33 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:40:33 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:40:32 +0000 UTC  }],Message:,Reason:,HostIP:10.10.10.6,PodIP:192.168.153.50,StartTime:2019-09-27 21:40:32 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-27 21:40:33 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://df82a543f53185c995e10068fc69ccdd3f9ce5e114273ab0acfe31a29931a14f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:40:37.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1983" for this suite.
Sep 27 21:40:43.290: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:40:43.361: INFO: namespace deployment-1983 deletion completed in 6.102396656s

• [SLOW TEST:11.296 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:40:43.361: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3345
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1457
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep 27 21:40:43.513: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-3345'
Sep 27 21:40:43.583: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep 27 21:40:43.583: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Sep 27 21:40:43.604: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-ftj94]
Sep 27 21:40:43.604: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-ftj94" in namespace "kubectl-3345" to be "running and ready"
Sep 27 21:40:43.608: INFO: Pod "e2e-test-nginx-rc-ftj94": Phase="Pending", Reason="", readiness=false. Elapsed: 4.127241ms
Sep 27 21:40:45.611: INFO: Pod "e2e-test-nginx-rc-ftj94": Phase="Running", Reason="", readiness=true. Elapsed: 2.007142206s
Sep 27 21:40:45.611: INFO: Pod "e2e-test-nginx-rc-ftj94" satisfied condition "running and ready"
Sep 27 21:40:45.611: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-ftj94]
Sep 27 21:40:45.611: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 logs rc/e2e-test-nginx-rc --namespace=kubectl-3345'
Sep 27 21:40:45.689: INFO: stderr: ""
Sep 27 21:40:45.689: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1462
Sep 27 21:40:45.689: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 delete rc e2e-test-nginx-rc --namespace=kubectl-3345'
Sep 27 21:40:45.759: INFO: stderr: ""
Sep 27 21:40:45.759: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:40:45.759: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3345" for this suite.
Sep 27 21:40:51.776: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:40:51.845: INFO: namespace kubectl-3345 deletion completed in 6.080421972s

• [SLOW TEST:8.484 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:40:51.845: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6169
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep 27 21:40:51.998: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2cc8be49-7204-463e-931f-721e5ba01303" in namespace "downward-api-6169" to be "success or failure"
Sep 27 21:40:52.000: INFO: Pod "downwardapi-volume-2cc8be49-7204-463e-931f-721e5ba01303": Phase="Pending", Reason="", readiness=false. Elapsed: 1.987093ms
Sep 27 21:40:54.003: INFO: Pod "downwardapi-volume-2cc8be49-7204-463e-931f-721e5ba01303": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004716328s
STEP: Saw pod success
Sep 27 21:40:54.003: INFO: Pod "downwardapi-volume-2cc8be49-7204-463e-931f-721e5ba01303" satisfied condition "success or failure"
Sep 27 21:40:54.005: INFO: Trying to get logs from node macpro-1 pod downwardapi-volume-2cc8be49-7204-463e-931f-721e5ba01303 container client-container: <nil>
STEP: delete the pod
Sep 27 21:40:54.029: INFO: Waiting for pod downwardapi-volume-2cc8be49-7204-463e-931f-721e5ba01303 to disappear
Sep 27 21:40:54.030: INFO: Pod downwardapi-volume-2cc8be49-7204-463e-931f-721e5ba01303 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:40:54.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6169" for this suite.
Sep 27 21:41:00.044: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:41:00.117: INFO: namespace downward-api-6169 deletion completed in 6.084587189s

• [SLOW TEST:8.272 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:41:00.118: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-8526
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 27 21:41:18.282: INFO: Container started at 2019-09-27 21:41:01 +0000 UTC, pod became ready at 2019-09-27 21:41:18 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:41:18.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8526" for this suite.
Sep 27 21:41:40.300: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:41:40.381: INFO: namespace container-probe-8526 deletion completed in 22.09574745s

• [SLOW TEST:40.263 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:41:40.381: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-9795
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:41:44.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9795" for this suite.
Sep 27 21:41:50.560: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:41:50.630: INFO: namespace kubelet-test-9795 deletion completed in 6.081312458s

• [SLOW TEST:10.249 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:41:50.630: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-8640
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-8640.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-8640.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8640.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-8640.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-8640.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8640.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 27 21:41:54.817: INFO: DNS probes using dns-8640/dns-test-90123a75-0929-45f1-8b74-4b7ba4ab09f6 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:41:54.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8640" for this suite.
Sep 27 21:42:00.859: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:42:00.930: INFO: namespace dns-8640 deletion completed in 6.087265196s

• [SLOW TEST:10.300 seconds]
[sig-network] DNS
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:42:00.930: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8389
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-62216d5b-eabc-4ff0-8394-0f5573580a36
STEP: Creating a pod to test consume configMaps
Sep 27 21:42:01.096: INFO: Waiting up to 5m0s for pod "pod-configmaps-3d419127-36cd-437e-bb42-49c1ebd364f4" in namespace "configmap-8389" to be "success or failure"
Sep 27 21:42:01.097: INFO: Pod "pod-configmaps-3d419127-36cd-437e-bb42-49c1ebd364f4": Phase="Pending", Reason="", readiness=false. Elapsed: 1.894803ms
Sep 27 21:42:03.100: INFO: Pod "pod-configmaps-3d419127-36cd-437e-bb42-49c1ebd364f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004401264s
STEP: Saw pod success
Sep 27 21:42:03.100: INFO: Pod "pod-configmaps-3d419127-36cd-437e-bb42-49c1ebd364f4" satisfied condition "success or failure"
Sep 27 21:42:03.102: INFO: Trying to get logs from node macpro-2 pod pod-configmaps-3d419127-36cd-437e-bb42-49c1ebd364f4 container configmap-volume-test: <nil>
STEP: delete the pod
Sep 27 21:42:03.123: INFO: Waiting for pod pod-configmaps-3d419127-36cd-437e-bb42-49c1ebd364f4 to disappear
Sep 27 21:42:03.125: INFO: Pod pod-configmaps-3d419127-36cd-437e-bb42-49c1ebd364f4 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:42:03.125: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8389" for this suite.
Sep 27 21:42:09.139: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:42:09.216: INFO: namespace configmap-8389 deletion completed in 6.087924125s

• [SLOW TEST:8.285 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:42:09.216: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3740
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep 27 21:42:09.377: INFO: Waiting up to 5m0s for pod "downwardapi-volume-827a8598-0550-4a35-a83c-2b72d4f5768a" in namespace "downward-api-3740" to be "success or failure"
Sep 27 21:42:09.379: INFO: Pod "downwardapi-volume-827a8598-0550-4a35-a83c-2b72d4f5768a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010842ms
Sep 27 21:42:11.382: INFO: Pod "downwardapi-volume-827a8598-0550-4a35-a83c-2b72d4f5768a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005132471s
STEP: Saw pod success
Sep 27 21:42:11.382: INFO: Pod "downwardapi-volume-827a8598-0550-4a35-a83c-2b72d4f5768a" satisfied condition "success or failure"
Sep 27 21:42:11.384: INFO: Trying to get logs from node macpro-3 pod downwardapi-volume-827a8598-0550-4a35-a83c-2b72d4f5768a container client-container: <nil>
STEP: delete the pod
Sep 27 21:42:11.413: INFO: Waiting for pod downwardapi-volume-827a8598-0550-4a35-a83c-2b72d4f5768a to disappear
Sep 27 21:42:11.415: INFO: Pod downwardapi-volume-827a8598-0550-4a35-a83c-2b72d4f5768a no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:42:11.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3740" for this suite.
Sep 27 21:42:17.429: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:42:17.499: INFO: namespace downward-api-3740 deletion completed in 6.081508589s

• [SLOW TEST:8.283 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:42:17.499: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2142
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Sep 27 21:42:20.185: INFO: Successfully updated pod "labelsupdate72b8600d-e2e6-4e3b-b3eb-53ddaa968559"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:42:22.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2142" for this suite.
Sep 27 21:42:44.212: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:42:44.283: INFO: namespace downward-api-2142 deletion completed in 22.082987954s

• [SLOW TEST:26.784 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:42:44.283: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-4847
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod busybox-aba751ec-20be-43f0-8a52-a4cba953aad2 in namespace container-probe-4847
Sep 27 21:42:46.467: INFO: Started pod busybox-aba751ec-20be-43f0-8a52-a4cba953aad2 in namespace container-probe-4847
STEP: checking the pod's current state and verifying that restartCount is present
Sep 27 21:42:46.468: INFO: Initial restart count of pod busybox-aba751ec-20be-43f0-8a52-a4cba953aad2 is 0
Sep 27 21:43:40.548: INFO: Restart count of pod container-probe-4847/busybox-aba751ec-20be-43f0-8a52-a4cba953aad2 is now 1 (54.079429286s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:43:40.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4847" for this suite.
Sep 27 21:43:46.576: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:43:46.646: INFO: namespace container-probe-4847 deletion completed in 6.082086307s

• [SLOW TEST:62.362 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:43:46.646: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3847
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on tmpfs
Sep 27 21:43:46.800: INFO: Waiting up to 5m0s for pod "pod-01786e97-064b-4924-b250-116cb3f89119" in namespace "emptydir-3847" to be "success or failure"
Sep 27 21:43:46.801: INFO: Pod "pod-01786e97-064b-4924-b250-116cb3f89119": Phase="Pending", Reason="", readiness=false. Elapsed: 1.88519ms
Sep 27 21:43:48.804: INFO: Pod "pod-01786e97-064b-4924-b250-116cb3f89119": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004825575s
STEP: Saw pod success
Sep 27 21:43:48.804: INFO: Pod "pod-01786e97-064b-4924-b250-116cb3f89119" satisfied condition "success or failure"
Sep 27 21:43:48.806: INFO: Trying to get logs from node macpro-2 pod pod-01786e97-064b-4924-b250-116cb3f89119 container test-container: <nil>
STEP: delete the pod
Sep 27 21:43:48.827: INFO: Waiting for pod pod-01786e97-064b-4924-b250-116cb3f89119 to disappear
Sep 27 21:43:48.829: INFO: Pod pod-01786e97-064b-4924-b250-116cb3f89119 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:43:48.829: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3847" for this suite.
Sep 27 21:43:54.843: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:43:54.913: INFO: namespace emptydir-3847 deletion completed in 6.081459121s

• [SLOW TEST:8.267 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:43:54.913: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8403
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on node default medium
Sep 27 21:43:55.075: INFO: Waiting up to 5m0s for pod "pod-e43174df-c527-4912-9fc0-ba2adef32c38" in namespace "emptydir-8403" to be "success or failure"
Sep 27 21:43:55.077: INFO: Pod "pod-e43174df-c527-4912-9fc0-ba2adef32c38": Phase="Pending", Reason="", readiness=false. Elapsed: 1.804742ms
Sep 27 21:43:57.080: INFO: Pod "pod-e43174df-c527-4912-9fc0-ba2adef32c38": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004502642s
Sep 27 21:43:59.083: INFO: Pod "pod-e43174df-c527-4912-9fc0-ba2adef32c38": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007254314s
STEP: Saw pod success
Sep 27 21:43:59.083: INFO: Pod "pod-e43174df-c527-4912-9fc0-ba2adef32c38" satisfied condition "success or failure"
Sep 27 21:43:59.085: INFO: Trying to get logs from node macpro-1 pod pod-e43174df-c527-4912-9fc0-ba2adef32c38 container test-container: <nil>
STEP: delete the pod
Sep 27 21:43:59.117: INFO: Waiting for pod pod-e43174df-c527-4912-9fc0-ba2adef32c38 to disappear
Sep 27 21:43:59.119: INFO: Pod pod-e43174df-c527-4912-9fc0-ba2adef32c38 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:43:59.119: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8403" for this suite.
Sep 27 21:44:05.136: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:44:05.206: INFO: namespace emptydir-8403 deletion completed in 6.085532788s

• [SLOW TEST:10.294 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:44:05.207: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-616
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-616
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-616
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-616
Sep 27 21:44:05.377: INFO: Found 0 stateful pods, waiting for 1
Sep 27 21:44:15.379: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Sep 27 21:44:15.382: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 exec --namespace=statefulset-616 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep 27 21:44:15.546: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep 27 21:44:15.546: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep 27 21:44:15.546: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep 27 21:44:15.549: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Sep 27 21:44:25.552: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep 27 21:44:25.552: INFO: Waiting for statefulset status.replicas updated to 0
Sep 27 21:44:25.567: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999713s
Sep 27 21:44:26.570: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.997811648s
Sep 27 21:44:27.573: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.99491959s
Sep 27 21:44:28.577: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.992325006s
Sep 27 21:44:29.580: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.988220971s
Sep 27 21:44:30.583: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.98568453s
Sep 27 21:44:31.585: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.982618215s
Sep 27 21:44:32.588: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.979843653s
Sep 27 21:44:33.591: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.976916701s
Sep 27 21:44:34.594: INFO: Verifying statefulset ss doesn't scale past 1 for another 973.83496ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-616
Sep 27 21:44:35.597: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 exec --namespace=statefulset-616 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 27 21:44:35.756: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep 27 21:44:35.756: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep 27 21:44:35.756: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep 27 21:44:35.759: INFO: Found 1 stateful pods, waiting for 3
Sep 27 21:44:45.762: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Sep 27 21:44:45.762: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Sep 27 21:44:45.762: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Sep 27 21:44:45.766: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 exec --namespace=statefulset-616 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep 27 21:44:45.926: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep 27 21:44:45.926: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep 27 21:44:45.926: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep 27 21:44:45.926: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 exec --namespace=statefulset-616 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep 27 21:44:46.091: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep 27 21:44:46.091: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep 27 21:44:46.091: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep 27 21:44:46.091: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 exec --namespace=statefulset-616 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep 27 21:44:46.255: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep 27 21:44:46.255: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep 27 21:44:46.255: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep 27 21:44:46.255: INFO: Waiting for statefulset status.replicas updated to 0
Sep 27 21:44:46.257: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Sep 27 21:44:56.263: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep 27 21:44:56.263: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Sep 27 21:44:56.263: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Sep 27 21:44:56.274: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999688s
Sep 27 21:44:57.277: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.997498119s
Sep 27 21:44:58.280: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.994463066s
Sep 27 21:44:59.283: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.99132925s
Sep 27 21:45:00.286: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.988375002s
Sep 27 21:45:01.289: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.98557263s
Sep 27 21:45:02.292: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.982452072s
Sep 27 21:45:03.296: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.978910671s
Sep 27 21:45:04.299: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.975515172s
Sep 27 21:45:05.302: INFO: Verifying statefulset ss doesn't scale past 3 for another 972.509184ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-616
Sep 27 21:45:06.305: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 exec --namespace=statefulset-616 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 27 21:45:06.981: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep 27 21:45:06.981: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep 27 21:45:06.981: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep 27 21:45:06.981: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 exec --namespace=statefulset-616 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 27 21:45:07.142: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep 27 21:45:07.142: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep 27 21:45:07.142: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep 27 21:45:07.142: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 exec --namespace=statefulset-616 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 27 21:45:07.313: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep 27 21:45:07.313: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep 27 21:45:07.313: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep 27 21:45:07.313: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Sep 27 21:45:27.324: INFO: Deleting all statefulset in ns statefulset-616
Sep 27 21:45:27.326: INFO: Scaling statefulset ss to 0
Sep 27 21:45:27.333: INFO: Waiting for statefulset status.replicas updated to 0
Sep 27 21:45:27.335: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:45:27.347: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-616" for this suite.
Sep 27 21:45:33.361: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:45:33.430: INFO: namespace statefulset-616 deletion completed in 6.080752452s

• [SLOW TEST:88.224 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:45:33.430: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8837
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on node default medium
Sep 27 21:45:33.590: INFO: Waiting up to 5m0s for pod "pod-28f672fb-4298-4d1c-80e0-9bca3623a739" in namespace "emptydir-8837" to be "success or failure"
Sep 27 21:45:33.592: INFO: Pod "pod-28f672fb-4298-4d1c-80e0-9bca3623a739": Phase="Pending", Reason="", readiness=false. Elapsed: 1.749008ms
Sep 27 21:45:35.595: INFO: Pod "pod-28f672fb-4298-4d1c-80e0-9bca3623a739": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004477463s
STEP: Saw pod success
Sep 27 21:45:35.595: INFO: Pod "pod-28f672fb-4298-4d1c-80e0-9bca3623a739" satisfied condition "success or failure"
Sep 27 21:45:35.597: INFO: Trying to get logs from node macpro-2 pod pod-28f672fb-4298-4d1c-80e0-9bca3623a739 container test-container: <nil>
STEP: delete the pod
Sep 27 21:45:35.621: INFO: Waiting for pod pod-28f672fb-4298-4d1c-80e0-9bca3623a739 to disappear
Sep 27 21:45:35.623: INFO: Pod pod-28f672fb-4298-4d1c-80e0-9bca3623a739 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:45:35.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8837" for this suite.
Sep 27 21:45:41.637: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:45:41.710: INFO: namespace emptydir-8837 deletion completed in 6.084127635s

• [SLOW TEST:8.280 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:45:41.710: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-3646
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Sep 27 21:45:41.888: INFO: Number of nodes with available pods: 0
Sep 27 21:45:41.888: INFO: Node macpro-1 is running more than one daemon pod
Sep 27 21:45:42.894: INFO: Number of nodes with available pods: 0
Sep 27 21:45:42.894: INFO: Node macpro-1 is running more than one daemon pod
Sep 27 21:45:43.894: INFO: Number of nodes with available pods: 3
Sep 27 21:45:43.894: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Sep 27 21:45:43.914: INFO: Number of nodes with available pods: 2
Sep 27 21:45:43.914: INFO: Node macpro-2 is running more than one daemon pod
Sep 27 21:45:44.920: INFO: Number of nodes with available pods: 2
Sep 27 21:45:44.920: INFO: Node macpro-2 is running more than one daemon pod
Sep 27 21:45:45.919: INFO: Number of nodes with available pods: 2
Sep 27 21:45:45.919: INFO: Node macpro-2 is running more than one daemon pod
Sep 27 21:45:46.920: INFO: Number of nodes with available pods: 2
Sep 27 21:45:46.920: INFO: Node macpro-2 is running more than one daemon pod
Sep 27 21:45:47.927: INFO: Number of nodes with available pods: 2
Sep 27 21:45:47.927: INFO: Node macpro-2 is running more than one daemon pod
Sep 27 21:45:48.919: INFO: Number of nodes with available pods: 2
Sep 27 21:45:48.919: INFO: Node macpro-2 is running more than one daemon pod
Sep 27 21:45:49.919: INFO: Number of nodes with available pods: 3
Sep 27 21:45:49.919: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3646, will wait for the garbage collector to delete the pods
Sep 27 21:45:49.982: INFO: Deleting DaemonSet.extensions daemon-set took: 8.707012ms
Sep 27 21:45:50.082: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.111082ms
Sep 27 21:45:53.784: INFO: Number of nodes with available pods: 0
Sep 27 21:45:53.784: INFO: Number of running nodes: 0, number of available pods: 0
Sep 27 21:45:53.787: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-3646/daemonsets","resourceVersion":"7623640"},"items":null}

Sep 27 21:45:53.788: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-3646/pods","resourceVersion":"7623640"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:45:53.797: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3646" for this suite.
Sep 27 21:45:59.815: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:45:59.888: INFO: namespace daemonsets-3646 deletion completed in 6.088384165s

• [SLOW TEST:18.178 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:45:59.888: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-237
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a replication controller
Sep 27 21:46:00.038: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 create -f - --namespace=kubectl-237'
Sep 27 21:46:00.240: INFO: stderr: ""
Sep 27 21:46:00.240: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep 27 21:46:00.240: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-237'
Sep 27 21:46:00.306: INFO: stderr: ""
Sep 27 21:46:00.306: INFO: stdout: "update-demo-nautilus-gpnjb update-demo-nautilus-gwl9d "
Sep 27 21:46:00.306: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 get pods update-demo-nautilus-gpnjb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-237'
Sep 27 21:46:00.367: INFO: stderr: ""
Sep 27 21:46:00.367: INFO: stdout: ""
Sep 27 21:46:00.367: INFO: update-demo-nautilus-gpnjb is created but not running
Sep 27 21:46:05.367: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-237'
Sep 27 21:46:05.429: INFO: stderr: ""
Sep 27 21:46:05.429: INFO: stdout: "update-demo-nautilus-gpnjb update-demo-nautilus-gwl9d "
Sep 27 21:46:05.429: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 get pods update-demo-nautilus-gpnjb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-237'
Sep 27 21:46:05.489: INFO: stderr: ""
Sep 27 21:46:05.489: INFO: stdout: "true"
Sep 27 21:46:05.489: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 get pods update-demo-nautilus-gpnjb -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-237'
Sep 27 21:46:05.551: INFO: stderr: ""
Sep 27 21:46:05.551: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 27 21:46:05.551: INFO: validating pod update-demo-nautilus-gpnjb
Sep 27 21:46:05.555: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 27 21:46:05.555: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 27 21:46:05.555: INFO: update-demo-nautilus-gpnjb is verified up and running
Sep 27 21:46:05.555: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 get pods update-demo-nautilus-gwl9d -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-237'
Sep 27 21:46:05.613: INFO: stderr: ""
Sep 27 21:46:05.613: INFO: stdout: "true"
Sep 27 21:46:05.613: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 get pods update-demo-nautilus-gwl9d -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-237'
Sep 27 21:46:05.672: INFO: stderr: ""
Sep 27 21:46:05.672: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 27 21:46:05.672: INFO: validating pod update-demo-nautilus-gwl9d
Sep 27 21:46:05.676: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 27 21:46:05.676: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 27 21:46:05.676: INFO: update-demo-nautilus-gwl9d is verified up and running
STEP: scaling down the replication controller
Sep 27 21:46:05.677: INFO: scanned /root for discovery docs: <nil>
Sep 27 21:46:05.677: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-237'
Sep 27 21:46:06.769: INFO: stderr: ""
Sep 27 21:46:06.769: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep 27 21:46:06.769: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-237'
Sep 27 21:46:06.831: INFO: stderr: ""
Sep 27 21:46:06.831: INFO: stdout: "update-demo-nautilus-gpnjb update-demo-nautilus-gwl9d "
STEP: Replicas for name=update-demo: expected=1 actual=2
Sep 27 21:46:11.831: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-237'
Sep 27 21:46:11.893: INFO: stderr: ""
Sep 27 21:46:11.893: INFO: stdout: "update-demo-nautilus-gpnjb "
Sep 27 21:46:11.893: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 get pods update-demo-nautilus-gpnjb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-237'
Sep 27 21:46:11.952: INFO: stderr: ""
Sep 27 21:46:11.952: INFO: stdout: "true"
Sep 27 21:46:11.952: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 get pods update-demo-nautilus-gpnjb -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-237'
Sep 27 21:46:12.011: INFO: stderr: ""
Sep 27 21:46:12.011: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 27 21:46:12.011: INFO: validating pod update-demo-nautilus-gpnjb
Sep 27 21:46:12.014: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 27 21:46:12.014: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 27 21:46:12.014: INFO: update-demo-nautilus-gpnjb is verified up and running
STEP: scaling up the replication controller
Sep 27 21:46:12.016: INFO: scanned /root for discovery docs: <nil>
Sep 27 21:46:12.016: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-237'
Sep 27 21:46:13.115: INFO: stderr: ""
Sep 27 21:46:13.115: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep 27 21:46:13.115: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-237'
Sep 27 21:46:13.179: INFO: stderr: ""
Sep 27 21:46:13.179: INFO: stdout: "update-demo-nautilus-bzm2g update-demo-nautilus-gpnjb "
Sep 27 21:46:13.179: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 get pods update-demo-nautilus-bzm2g -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-237'
Sep 27 21:46:13.242: INFO: stderr: ""
Sep 27 21:46:13.242: INFO: stdout: ""
Sep 27 21:46:13.242: INFO: update-demo-nautilus-bzm2g is created but not running
Sep 27 21:46:18.242: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-237'
Sep 27 21:46:18.303: INFO: stderr: ""
Sep 27 21:46:18.303: INFO: stdout: "update-demo-nautilus-bzm2g update-demo-nautilus-gpnjb "
Sep 27 21:46:18.303: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 get pods update-demo-nautilus-bzm2g -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-237'
Sep 27 21:46:18.363: INFO: stderr: ""
Sep 27 21:46:18.363: INFO: stdout: "true"
Sep 27 21:46:18.363: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 get pods update-demo-nautilus-bzm2g -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-237'
Sep 27 21:46:18.426: INFO: stderr: ""
Sep 27 21:46:18.426: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 27 21:46:18.426: INFO: validating pod update-demo-nautilus-bzm2g
Sep 27 21:46:18.429: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 27 21:46:18.429: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 27 21:46:18.429: INFO: update-demo-nautilus-bzm2g is verified up and running
Sep 27 21:46:18.429: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 get pods update-demo-nautilus-gpnjb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-237'
Sep 27 21:46:18.489: INFO: stderr: ""
Sep 27 21:46:18.489: INFO: stdout: "true"
Sep 27 21:46:18.489: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 get pods update-demo-nautilus-gpnjb -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-237'
Sep 27 21:46:18.548: INFO: stderr: ""
Sep 27 21:46:18.548: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 27 21:46:18.548: INFO: validating pod update-demo-nautilus-gpnjb
Sep 27 21:46:18.551: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 27 21:46:18.551: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 27 21:46:18.551: INFO: update-demo-nautilus-gpnjb is verified up and running
STEP: using delete to clean up resources
Sep 27 21:46:18.551: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 delete --grace-period=0 --force -f - --namespace=kubectl-237'
Sep 27 21:46:18.617: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 27 21:46:18.617: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Sep 27 21:46:18.617: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-237'
Sep 27 21:46:18.684: INFO: stderr: "No resources found.\n"
Sep 27 21:46:18.684: INFO: stdout: ""
Sep 27 21:46:18.684: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 get pods -l name=update-demo --namespace=kubectl-237 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep 27 21:46:18.748: INFO: stderr: ""
Sep 27 21:46:18.748: INFO: stdout: "update-demo-nautilus-bzm2g\nupdate-demo-nautilus-gpnjb\n"
Sep 27 21:46:19.248: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-237'
Sep 27 21:46:19.316: INFO: stderr: "No resources found.\n"
Sep 27 21:46:19.316: INFO: stdout: ""
Sep 27 21:46:19.316: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 get pods -l name=update-demo --namespace=kubectl-237 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep 27 21:46:19.383: INFO: stderr: ""
Sep 27 21:46:19.383: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:46:19.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-237" for this suite.
Sep 27 21:46:41.398: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:46:41.467: INFO: namespace kubectl-237 deletion completed in 22.080668973s

• [SLOW TEST:41.579 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:46:41.467: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-2725
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Sep 27 21:46:41.615: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep 27 21:46:41.621: INFO: Waiting for terminating namespaces to be deleted...
Sep 27 21:46:41.623: INFO: 
Logging pods the kubelet thinks is on node macpro-1 before test
Sep 27 21:46:41.628: INFO: kube-proxy-zgndg from kube-system started at 2019-08-08 01:50:37 +0000 UTC (1 container statuses recorded)
Sep 27 21:46:41.628: INFO: 	Container kube-proxy ready: true, restart count 0
Sep 27 21:46:41.628: INFO: calico-node-6vk4s from kube-system started at 2019-08-08 02:05:40 +0000 UTC (1 container statuses recorded)
Sep 27 21:46:41.628: INFO: 	Container calico-node ready: true, restart count 0
Sep 27 21:46:41.628: INFO: kube-apiserver-macpro-1 from kube-system started at 2019-08-13 03:41:36 +0000 UTC (1 container statuses recorded)
Sep 27 21:46:41.628: INFO: 	Container kube-apiserver ready: true, restart count 0
Sep 27 21:46:41.628: INFO: calico-kube-controllers-7bd78b474d-t2lgl from kube-system started at 2019-08-08 02:05:40 +0000 UTC (1 container statuses recorded)
Sep 27 21:46:41.628: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Sep 27 21:46:41.628: INFO: etcd-macpro-1 from kube-system started at 2019-08-13 03:43:55 +0000 UTC (1 container statuses recorded)
Sep 27 21:46:41.628: INFO: 	Container etcd ready: true, restart count 0
Sep 27 21:46:41.628: INFO: kube-controller-manager-macpro-1 from kube-system started at 2019-08-08 01:50:11 +0000 UTC (1 container statuses recorded)
Sep 27 21:46:41.628: INFO: 	Container kube-controller-manager ready: true, restart count 8
Sep 27 21:46:41.628: INFO: coredns-5c98db65d4-9bgxc from kube-system started at 2019-08-08 01:50:51 +0000 UTC (1 container statuses recorded)
Sep 27 21:46:41.628: INFO: 	Container coredns ready: true, restart count 7
Sep 27 21:46:41.628: INFO: speaker-msvrw from metallb-system started at 2019-08-08 02:15:42 +0000 UTC (1 container statuses recorded)
Sep 27 21:46:41.628: INFO: 	Container speaker ready: true, restart count 0
Sep 27 21:46:41.628: INFO: sonobuoy-systemd-logs-daemon-set-3ff1c1a60c394bba-c5zcw from sonobuoy started at 2019-09-27 21:16:41 +0000 UTC (2 container statuses recorded)
Sep 27 21:46:41.628: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 27 21:46:41.628: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 27 21:46:41.628: INFO: kube-scheduler-macpro-1 from kube-system started at 2019-08-13 03:43:55 +0000 UTC (1 container statuses recorded)
Sep 27 21:46:41.628: INFO: 	Container kube-scheduler ready: true, restart count 9
Sep 27 21:46:41.628: INFO: orka-5c9d6bfc94-rxjt9 from default started at 2019-09-27 20:09:01 +0000 UTC (1 container statuses recorded)
Sep 27 21:46:41.628: INFO: 	Container orka ready: true, restart count 0
Sep 27 21:46:41.628: INFO: coredns-5c98db65d4-hxb4g from kube-system started at 2019-08-08 01:50:47 +0000 UTC (1 container statuses recorded)
Sep 27 21:46:41.628: INFO: 	Container coredns ready: true, restart count 7
Sep 27 21:46:41.628: INFO: controller-55d74449-q2f47 from metallb-system started at 2019-08-08 02:15:42 +0000 UTC (1 container statuses recorded)
Sep 27 21:46:41.628: INFO: 	Container controller ready: true, restart count 0
Sep 27 21:46:41.628: INFO: rethinkdb-57544557d7-kssqr from default started at 2019-08-08 17:32:36 +0000 UTC (1 container statuses recorded)
Sep 27 21:46:41.628: INFO: 	Container rethinkdb ready: true, restart count 0
Sep 27 21:46:41.628: INFO: 
Logging pods the kubelet thinks is on node macpro-2 before test
Sep 27 21:46:41.633: INFO: speaker-w9jlq from metallb-system started at 2019-08-11 23:04:22 +0000 UTC (1 container statuses recorded)
Sep 27 21:46:41.633: INFO: 	Container speaker ready: true, restart count 0
Sep 27 21:46:41.633: INFO: kube-apiserver-macpro-2 from kube-system started at 2019-08-13 03:41:23 +0000 UTC (1 container statuses recorded)
Sep 27 21:46:41.633: INFO: 	Container kube-apiserver ready: true, restart count 0
Sep 27 21:46:41.633: INFO: kube-controller-manager-macpro-2 from kube-system started at 2019-08-08 02:20:59 +0000 UTC (1 container statuses recorded)
Sep 27 21:46:41.633: INFO: 	Container kube-controller-manager ready: true, restart count 1
Sep 27 21:46:41.633: INFO: etcd-macpro-2 from kube-system started at 2019-08-08 02:20:59 +0000 UTC (1 container statuses recorded)
Sep 27 21:46:41.633: INFO: 	Container etcd ready: true, restart count 0
Sep 27 21:46:41.633: INFO: sonobuoy from sonobuoy started at 2019-09-27 21:15:55 +0000 UTC (1 container statuses recorded)
Sep 27 21:46:41.633: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Sep 27 21:46:41.633: INFO: sonobuoy-systemd-logs-daemon-set-3ff1c1a60c394bba-rcrrv from sonobuoy started at 2019-09-27 21:16:41 +0000 UTC (2 container statuses recorded)
Sep 27 21:46:41.633: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 27 21:46:41.633: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 27 21:46:41.633: INFO: kube-scheduler-macpro-2 from kube-system started at 2019-08-13 03:43:55 +0000 UTC (1 container statuses recorded)
Sep 27 21:46:41.633: INFO: 	Container kube-scheduler ready: true, restart count 2
Sep 27 21:46:41.633: INFO: calico-node-7tmv4 from kube-system started at 2019-08-08 02:20:59 +0000 UTC (1 container statuses recorded)
Sep 27 21:46:41.633: INFO: 	Container calico-node ready: true, restart count 0
Sep 27 21:46:41.633: INFO: kube-proxy-s7hbl from kube-system started at 2019-08-08 02:20:59 +0000 UTC (1 container statuses recorded)
Sep 27 21:46:41.633: INFO: 	Container kube-proxy ready: true, restart count 0
Sep 27 21:46:41.633: INFO: 
Logging pods the kubelet thinks is on node macpro-3 before test
Sep 27 21:46:41.639: INFO: kube-scheduler-macpro-3 from kube-system started at 2019-08-08 02:21:06 +0000 UTC (1 container statuses recorded)
Sep 27 21:46:41.639: INFO: 	Container kube-scheduler ready: true, restart count 0
Sep 27 21:46:41.639: INFO: nfs-server-pod from default started at 2019-09-26 21:59:12 +0000 UTC (1 container statuses recorded)
Sep 27 21:46:41.639: INFO: 	Container nfs-server-container ready: true, restart count 0
Sep 27 21:46:41.639: INFO: sonobuoy-systemd-logs-daemon-set-3ff1c1a60c394bba-fvsn5 from sonobuoy started at 2019-09-27 21:16:41 +0000 UTC (2 container statuses recorded)
Sep 27 21:46:41.639: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 27 21:46:41.639: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 27 21:46:41.639: INFO: calico-node-ctgww from kube-system started at 2019-08-08 02:21:44 +0000 UTC (1 container statuses recorded)
Sep 27 21:46:41.639: INFO: 	Container calico-node ready: true, restart count 0
Sep 27 21:46:41.639: INFO: etcd-macpro-3 from kube-system started at 2019-08-13 03:43:55 +0000 UTC (1 container statuses recorded)
Sep 27 21:46:41.639: INFO: 	Container etcd ready: true, restart count 2
Sep 27 21:46:41.639: INFO: kube-apiserver-macpro-3 from kube-system started at 2019-08-13 03:43:55 +0000 UTC (1 container statuses recorded)
Sep 27 21:46:41.639: INFO: 	Container kube-apiserver ready: true, restart count 0
Sep 27 21:46:41.639: INFO: kube-proxy-kfvg6 from kube-system started at 2019-08-08 02:21:08 +0000 UTC (1 container statuses recorded)
Sep 27 21:46:41.639: INFO: 	Container kube-proxy ready: true, restart count 0
Sep 27 21:46:41.639: INFO: kube-controller-manager-macpro-3 from kube-system started at 2019-08-13 03:43:55 +0000 UTC (1 container statuses recorded)
Sep 27 21:46:41.639: INFO: 	Container kube-controller-manager ready: true, restart count 2
Sep 27 21:46:41.639: INFO: speaker-t4xwn from metallb-system started at 2019-08-11 23:04:22 +0000 UTC (1 container statuses recorded)
Sep 27 21:46:41.639: INFO: 	Container speaker ready: true, restart count 0
Sep 27 21:46:41.639: INFO: sonobuoy-e2e-job-e236daee93b24985 from sonobuoy started at 2019-09-27 21:16:00 +0000 UTC (2 container statuses recorded)
Sep 27 21:46:41.639: INFO: 	Container e2e ready: true, restart count 0
Sep 27 21:46:41.639: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: verifying the node has the label node macpro-1
STEP: verifying the node has the label node macpro-2
STEP: verifying the node has the label node macpro-3
Sep 27 21:46:41.692: INFO: Pod nfs-server-pod requesting resource cpu=0m on Node macpro-3
Sep 27 21:46:41.692: INFO: Pod orka-5c9d6bfc94-rxjt9 requesting resource cpu=0m on Node macpro-1
Sep 27 21:46:41.692: INFO: Pod rethinkdb-57544557d7-kssqr requesting resource cpu=250m on Node macpro-1
Sep 27 21:46:41.692: INFO: Pod calico-kube-controllers-7bd78b474d-t2lgl requesting resource cpu=0m on Node macpro-1
Sep 27 21:46:41.692: INFO: Pod calico-node-6vk4s requesting resource cpu=250m on Node macpro-1
Sep 27 21:46:41.692: INFO: Pod calico-node-7tmv4 requesting resource cpu=250m on Node macpro-2
Sep 27 21:46:41.692: INFO: Pod calico-node-ctgww requesting resource cpu=250m on Node macpro-3
Sep 27 21:46:41.692: INFO: Pod coredns-5c98db65d4-9bgxc requesting resource cpu=100m on Node macpro-1
Sep 27 21:46:41.692: INFO: Pod coredns-5c98db65d4-hxb4g requesting resource cpu=100m on Node macpro-1
Sep 27 21:46:41.692: INFO: Pod etcd-macpro-1 requesting resource cpu=0m on Node macpro-1
Sep 27 21:46:41.692: INFO: Pod etcd-macpro-2 requesting resource cpu=0m on Node macpro-2
Sep 27 21:46:41.692: INFO: Pod etcd-macpro-3 requesting resource cpu=0m on Node macpro-3
Sep 27 21:46:41.692: INFO: Pod kube-controller-manager-macpro-1 requesting resource cpu=200m on Node macpro-1
Sep 27 21:46:41.692: INFO: Pod kube-controller-manager-macpro-2 requesting resource cpu=200m on Node macpro-2
Sep 27 21:46:41.692: INFO: Pod kube-controller-manager-macpro-3 requesting resource cpu=200m on Node macpro-3
Sep 27 21:46:41.692: INFO: Pod kube-proxy-kfvg6 requesting resource cpu=0m on Node macpro-3
Sep 27 21:46:41.692: INFO: Pod kube-proxy-s7hbl requesting resource cpu=0m on Node macpro-2
Sep 27 21:46:41.692: INFO: Pod kube-proxy-zgndg requesting resource cpu=0m on Node macpro-1
Sep 27 21:46:41.692: INFO: Pod kube-scheduler-macpro-1 requesting resource cpu=100m on Node macpro-1
Sep 27 21:46:41.692: INFO: Pod kube-scheduler-macpro-2 requesting resource cpu=100m on Node macpro-2
Sep 27 21:46:41.692: INFO: Pod kube-scheduler-macpro-3 requesting resource cpu=100m on Node macpro-3
Sep 27 21:46:41.692: INFO: Pod controller-55d74449-q2f47 requesting resource cpu=100m on Node macpro-1
Sep 27 21:46:41.692: INFO: Pod speaker-msvrw requesting resource cpu=100m on Node macpro-1
Sep 27 21:46:41.692: INFO: Pod speaker-t4xwn requesting resource cpu=100m on Node macpro-3
Sep 27 21:46:41.692: INFO: Pod speaker-w9jlq requesting resource cpu=100m on Node macpro-2
Sep 27 21:46:41.692: INFO: Pod sonobuoy requesting resource cpu=0m on Node macpro-2
Sep 27 21:46:41.692: INFO: Pod sonobuoy-e2e-job-e236daee93b24985 requesting resource cpu=0m on Node macpro-3
Sep 27 21:46:41.692: INFO: Pod sonobuoy-systemd-logs-daemon-set-3ff1c1a60c394bba-c5zcw requesting resource cpu=0m on Node macpro-1
Sep 27 21:46:41.692: INFO: Pod sonobuoy-systemd-logs-daemon-set-3ff1c1a60c394bba-fvsn5 requesting resource cpu=0m on Node macpro-3
Sep 27 21:46:41.692: INFO: Pod sonobuoy-systemd-logs-daemon-set-3ff1c1a60c394bba-rcrrv requesting resource cpu=0m on Node macpro-2
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-55b9eaf3-5f66-4baa-808b-38d72e2fd865.15c869cd8fd9d9b0], Reason = [Scheduled], Message = [Successfully assigned sched-pred-2725/filler-pod-55b9eaf3-5f66-4baa-808b-38d72e2fd865 to macpro-3]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-55b9eaf3-5f66-4baa-808b-38d72e2fd865.15c869cdbf6e9a1f], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-55b9eaf3-5f66-4baa-808b-38d72e2fd865.15c869cdc59b80b5], Reason = [Created], Message = [Created container filler-pod-55b9eaf3-5f66-4baa-808b-38d72e2fd865]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-55b9eaf3-5f66-4baa-808b-38d72e2fd865.15c869cdce82d408], Reason = [Started], Message = [Started container filler-pod-55b9eaf3-5f66-4baa-808b-38d72e2fd865]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9a1903f3-bb9d-44f0-9d43-2d1f00f41bbe.15c869cd8e37a6f9], Reason = [Scheduled], Message = [Successfully assigned sched-pred-2725/filler-pod-9a1903f3-bb9d-44f0-9d43-2d1f00f41bbe to macpro-1]
STEP: Considering event: 
Type = [Warning], Name = [filler-pod-9a1903f3-bb9d-44f0-9d43-2d1f00f41bbe.15c869cdd6838fe4], Reason = [FailedCreatePodSandBox], Message = [Failed create pod sandbox: rpc error: code = Unknown desc = failed to set up sandbox container "9ee735becfbb23371db6db728f656741a6ba66cd4f6bc7037c0417ac62d83788" network for pod "filler-pod-9a1903f3-bb9d-44f0-9d43-2d1f00f41bbe": NetworkPlugin cni failed to set up pod "filler-pod-9a1903f3-bb9d-44f0-9d43-2d1f00f41bbe_sched-pred-2725" network: error adding host side routes for interface: cali99dbc6f0d1b, error: route (Ifindex: 149, Dst: 192.168.151.193/32, Scope: 253) already exists for an interface other than 'cali99dbc6f0d1b']
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9a1903f3-bb9d-44f0-9d43-2d1f00f41bbe.15c869cdf25bfa4c], Reason = [SandboxChanged], Message = [Pod sandbox changed, it will be killed and re-created.]
STEP: Considering event: 
Type = [Warning], Name = [filler-pod-9a1903f3-bb9d-44f0-9d43-2d1f00f41bbe.15c869ce292020f1], Reason = [FailedCreatePodSandBox], Message = [Failed create pod sandbox: rpc error: code = Unknown desc = failed to set up sandbox container "50f45090b586305b11e202ef86bf9fcbddc2d84f0c21762f56926385e5717831" network for pod "filler-pod-9a1903f3-bb9d-44f0-9d43-2d1f00f41bbe": NetworkPlugin cni failed to set up pod "filler-pod-9a1903f3-bb9d-44f0-9d43-2d1f00f41bbe_sched-pred-2725" network: error adding host side routes for interface: cali99dbc6f0d1b, error: route (Ifindex: 150, Dst: 192.168.151.194/32, Scope: 253) already exists for an interface other than 'cali99dbc6f0d1b']
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9a1903f3-bb9d-44f0-9d43-2d1f00f41bbe.15c869ce500df3f0], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9a1903f3-bb9d-44f0-9d43-2d1f00f41bbe.15c869ce5536a933], Reason = [Created], Message = [Created container filler-pod-9a1903f3-bb9d-44f0-9d43-2d1f00f41bbe]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9a1903f3-bb9d-44f0-9d43-2d1f00f41bbe.15c869ce5d8ae491], Reason = [Started], Message = [Started container filler-pod-9a1903f3-bb9d-44f0-9d43-2d1f00f41bbe]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d3dd553e-cce9-4a7e-aa95-c896524882a0.15c869cd8ef8bb86], Reason = [Scheduled], Message = [Successfully assigned sched-pred-2725/filler-pod-d3dd553e-cce9-4a7e-aa95-c896524882a0 to macpro-2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d3dd553e-cce9-4a7e-aa95-c896524882a0.15c869cdc0d5e488], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d3dd553e-cce9-4a7e-aa95-c896524882a0.15c869cdc7ac1f56], Reason = [Created], Message = [Created container filler-pod-d3dd553e-cce9-4a7e-aa95-c896524882a0]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d3dd553e-cce9-4a7e-aa95-c896524882a0.15c869cdd0094621], Reason = [Started], Message = [Started container filler-pod-d3dd553e-cce9-4a7e-aa95-c896524882a0]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15c869ce7ee0684f], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node macpro-1
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node macpro-2
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node macpro-3
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:46:46.804: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2725" for this suite.
Sep 27 21:46:52.817: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:46:52.892: INFO: namespace sched-pred-2725 deletion completed in 6.086057603s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:11.425 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:46:52.893: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-931
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: validating cluster-info
Sep 27 21:46:53.041: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 cluster-info'
Sep 27 21:46:53.103: INFO: stderr: ""
Sep 27 21:46:53.103: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:46:53.103: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-931" for this suite.
Sep 27 21:46:59.118: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:46:59.190: INFO: namespace kubectl-931 deletion completed in 6.084121883s

• [SLOW TEST:6.298 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:46:59.191: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5885
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Sep 27 21:46:59.348: INFO: Waiting up to 5m0s for pod "downward-api-6e06e3b0-d477-42c7-8296-ce1e050294aa" in namespace "downward-api-5885" to be "success or failure"
Sep 27 21:46:59.350: INFO: Pod "downward-api-6e06e3b0-d477-42c7-8296-ce1e050294aa": Phase="Pending", Reason="", readiness=false. Elapsed: 1.87553ms
Sep 27 21:47:01.352: INFO: Pod "downward-api-6e06e3b0-d477-42c7-8296-ce1e050294aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004789507s
STEP: Saw pod success
Sep 27 21:47:01.352: INFO: Pod "downward-api-6e06e3b0-d477-42c7-8296-ce1e050294aa" satisfied condition "success or failure"
Sep 27 21:47:01.354: INFO: Trying to get logs from node macpro-3 pod downward-api-6e06e3b0-d477-42c7-8296-ce1e050294aa container dapi-container: <nil>
STEP: delete the pod
Sep 27 21:47:01.378: INFO: Waiting for pod downward-api-6e06e3b0-d477-42c7-8296-ce1e050294aa to disappear
Sep 27 21:47:01.379: INFO: Pod downward-api-6e06e3b0-d477-42c7-8296-ce1e050294aa no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:47:01.379: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5885" for this suite.
Sep 27 21:47:07.393: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:47:07.462: INFO: namespace downward-api-5885 deletion completed in 6.079928628s

• [SLOW TEST:8.271 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:47:07.462: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-773
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-773, will wait for the garbage collector to delete the pods
Sep 27 21:47:11.683: INFO: Deleting Job.batch foo took: 9.737952ms
Sep 27 21:47:11.983: INFO: Terminating Job.batch foo pods took: 300.35296ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:47:44.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-773" for this suite.
Sep 27 21:47:50.202: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:47:50.278: INFO: namespace job-773 deletion completed in 6.089989159s

• [SLOW TEST:42.816 seconds]
[sig-apps] Job
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:47:50.278: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-3877
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3877.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3877.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 27 21:47:52.461: INFO: DNS probes using dns-3877/dns-test-35fd8bbc-26e6-456a-b5ee-ca402068ece4 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:47:52.483: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3877" for this suite.
Sep 27 21:47:58.499: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:47:58.567: INFO: namespace dns-3877 deletion completed in 6.081858569s

• [SLOW TEST:8.289 seconds]
[sig-network] DNS
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:47:58.567: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4165
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Sep 27 21:48:01.252: INFO: Successfully updated pod "labelsupdate44ce357b-9c33-43cc-a282-436ac7a175b1"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:48:03.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4165" for this suite.
Sep 27 21:48:25.284: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:48:25.369: INFO: namespace projected-4165 deletion completed in 22.096359092s

• [SLOW TEST:26.802 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:48:25.369: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6289
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name projected-secret-test-7dbb0ed3-b3f9-4da0-ae6b-bbb0effe5073
STEP: Creating a pod to test consume secrets
Sep 27 21:48:25.532: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-00ec41ae-d23b-48a9-a066-1c295fba43df" in namespace "projected-6289" to be "success or failure"
Sep 27 21:48:25.534: INFO: Pod "pod-projected-secrets-00ec41ae-d23b-48a9-a066-1c295fba43df": Phase="Pending", Reason="", readiness=false. Elapsed: 2.390027ms
Sep 27 21:48:27.537: INFO: Pod "pod-projected-secrets-00ec41ae-d23b-48a9-a066-1c295fba43df": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004888647s
STEP: Saw pod success
Sep 27 21:48:27.537: INFO: Pod "pod-projected-secrets-00ec41ae-d23b-48a9-a066-1c295fba43df" satisfied condition "success or failure"
Sep 27 21:48:27.539: INFO: Trying to get logs from node macpro-2 pod pod-projected-secrets-00ec41ae-d23b-48a9-a066-1c295fba43df container secret-volume-test: <nil>
STEP: delete the pod
Sep 27 21:48:27.566: INFO: Waiting for pod pod-projected-secrets-00ec41ae-d23b-48a9-a066-1c295fba43df to disappear
Sep 27 21:48:27.568: INFO: Pod pod-projected-secrets-00ec41ae-d23b-48a9-a066-1c295fba43df no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:48:27.568: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6289" for this suite.
Sep 27 21:48:33.585: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:48:33.654: INFO: namespace projected-6289 deletion completed in 6.082379795s

• [SLOW TEST:8.285 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:48:33.655: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-989
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir volume type on tmpfs
Sep 27 21:48:33.815: INFO: Waiting up to 5m0s for pod "pod-7d10856b-54e0-4f38-956e-f0909890992c" in namespace "emptydir-989" to be "success or failure"
Sep 27 21:48:33.817: INFO: Pod "pod-7d10856b-54e0-4f38-956e-f0909890992c": Phase="Pending", Reason="", readiness=false. Elapsed: 1.966859ms
Sep 27 21:48:35.820: INFO: Pod "pod-7d10856b-54e0-4f38-956e-f0909890992c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004854663s
Sep 27 21:48:37.823: INFO: Pod "pod-7d10856b-54e0-4f38-956e-f0909890992c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007539776s
STEP: Saw pod success
Sep 27 21:48:37.823: INFO: Pod "pod-7d10856b-54e0-4f38-956e-f0909890992c" satisfied condition "success or failure"
Sep 27 21:48:37.828: INFO: Trying to get logs from node macpro-3 pod pod-7d10856b-54e0-4f38-956e-f0909890992c container test-container: <nil>
STEP: delete the pod
Sep 27 21:48:37.856: INFO: Waiting for pod pod-7d10856b-54e0-4f38-956e-f0909890992c to disappear
Sep 27 21:48:37.858: INFO: Pod pod-7d10856b-54e0-4f38-956e-f0909890992c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:48:37.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-989" for this suite.
Sep 27 21:48:43.873: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:48:43.941: INFO: namespace emptydir-989 deletion completed in 6.079568795s

• [SLOW TEST:10.286 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:48:43.941: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9538
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1211
STEP: creating the pod
Sep 27 21:48:44.089: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 create -f - --namespace=kubectl-9538'
Sep 27 21:48:44.289: INFO: stderr: ""
Sep 27 21:48:44.289: INFO: stdout: "pod/pause created\n"
Sep 27 21:48:44.289: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Sep 27 21:48:44.289: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-9538" to be "running and ready"
Sep 27 21:48:44.294: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 4.926835ms
Sep 27 21:48:46.296: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.007581501s
Sep 27 21:48:46.296: INFO: Pod "pause" satisfied condition "running and ready"
Sep 27 21:48:46.296: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: adding the label testing-label with value testing-label-value to a pod
Sep 27 21:48:46.296: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 label pods pause testing-label=testing-label-value --namespace=kubectl-9538'
Sep 27 21:48:46.364: INFO: stderr: ""
Sep 27 21:48:46.364: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Sep 27 21:48:46.365: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 get pod pause -L testing-label --namespace=kubectl-9538'
Sep 27 21:48:46.425: INFO: stderr: ""
Sep 27 21:48:46.425: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Sep 27 21:48:46.425: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 label pods pause testing-label- --namespace=kubectl-9538'
Sep 27 21:48:46.493: INFO: stderr: ""
Sep 27 21:48:46.493: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Sep 27 21:48:46.493: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 get pod pause -L testing-label --namespace=kubectl-9538'
Sep 27 21:48:46.554: INFO: stderr: ""
Sep 27 21:48:46.554: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1218
STEP: using delete to clean up resources
Sep 27 21:48:46.554: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 delete --grace-period=0 --force -f - --namespace=kubectl-9538'
Sep 27 21:48:46.631: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 27 21:48:46.631: INFO: stdout: "pod \"pause\" force deleted\n"
Sep 27 21:48:46.631: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 get rc,svc -l name=pause --no-headers --namespace=kubectl-9538'
Sep 27 21:48:46.697: INFO: stderr: "No resources found.\n"
Sep 27 21:48:46.697: INFO: stdout: ""
Sep 27 21:48:46.697: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 get pods -l name=pause --namespace=kubectl-9538 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep 27 21:48:46.757: INFO: stderr: ""
Sep 27 21:48:46.757: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:48:46.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9538" for this suite.
Sep 27 21:48:52.772: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:48:52.844: INFO: namespace kubectl-9538 deletion completed in 6.083609129s

• [SLOW TEST:8.903 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl label
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:48:52.844: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3688
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep 27 21:48:53.004: INFO: Waiting up to 5m0s for pod "downwardapi-volume-333e57bf-1263-4506-b456-2de636c5f875" in namespace "downward-api-3688" to be "success or failure"
Sep 27 21:48:53.006: INFO: Pod "downwardapi-volume-333e57bf-1263-4506-b456-2de636c5f875": Phase="Pending", Reason="", readiness=false. Elapsed: 2.106357ms
Sep 27 21:48:55.009: INFO: Pod "downwardapi-volume-333e57bf-1263-4506-b456-2de636c5f875": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004710654s
STEP: Saw pod success
Sep 27 21:48:55.009: INFO: Pod "downwardapi-volume-333e57bf-1263-4506-b456-2de636c5f875" satisfied condition "success or failure"
Sep 27 21:48:55.011: INFO: Trying to get logs from node macpro-2 pod downwardapi-volume-333e57bf-1263-4506-b456-2de636c5f875 container client-container: <nil>
STEP: delete the pod
Sep 27 21:48:55.035: INFO: Waiting for pod downwardapi-volume-333e57bf-1263-4506-b456-2de636c5f875 to disappear
Sep 27 21:48:55.037: INFO: Pod downwardapi-volume-333e57bf-1263-4506-b456-2de636c5f875 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:48:55.037: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3688" for this suite.
Sep 27 21:49:01.054: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:49:01.125: INFO: namespace downward-api-3688 deletion completed in 6.084797728s

• [SLOW TEST:8.281 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:49:01.125: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-330
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep 27 21:49:01.287: INFO: Waiting up to 5m0s for pod "downwardapi-volume-195c65c2-ba66-45f0-954b-a08b726f1e09" in namespace "downward-api-330" to be "success or failure"
Sep 27 21:49:01.289: INFO: Pod "downwardapi-volume-195c65c2-ba66-45f0-954b-a08b726f1e09": Phase="Pending", Reason="", readiness=false. Elapsed: 1.858354ms
Sep 27 21:49:03.292: INFO: Pod "downwardapi-volume-195c65c2-ba66-45f0-954b-a08b726f1e09": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005033951s
STEP: Saw pod success
Sep 27 21:49:03.292: INFO: Pod "downwardapi-volume-195c65c2-ba66-45f0-954b-a08b726f1e09" satisfied condition "success or failure"
Sep 27 21:49:03.294: INFO: Trying to get logs from node macpro-2 pod downwardapi-volume-195c65c2-ba66-45f0-954b-a08b726f1e09 container client-container: <nil>
STEP: delete the pod
Sep 27 21:49:03.318: INFO: Waiting for pod downwardapi-volume-195c65c2-ba66-45f0-954b-a08b726f1e09 to disappear
Sep 27 21:49:03.319: INFO: Pod downwardapi-volume-195c65c2-ba66-45f0-954b-a08b726f1e09 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:49:03.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-330" for this suite.
Sep 27 21:49:09.333: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:49:09.403: INFO: namespace downward-api-330 deletion completed in 6.08081338s

• [SLOW TEST:8.278 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:49:09.403: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3439
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-184c99c1-c18f-4e8e-9506-665896f03f3b
STEP: Creating a pod to test consume configMaps
Sep 27 21:49:09.572: INFO: Waiting up to 5m0s for pod "pod-configmaps-a3a3ae30-89e8-4a7d-b4a2-6b22d65f2018" in namespace "configmap-3439" to be "success or failure"
Sep 27 21:49:09.574: INFO: Pod "pod-configmaps-a3a3ae30-89e8-4a7d-b4a2-6b22d65f2018": Phase="Pending", Reason="", readiness=false. Elapsed: 1.913268ms
Sep 27 21:49:11.577: INFO: Pod "pod-configmaps-a3a3ae30-89e8-4a7d-b4a2-6b22d65f2018": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00487575s
STEP: Saw pod success
Sep 27 21:49:11.577: INFO: Pod "pod-configmaps-a3a3ae30-89e8-4a7d-b4a2-6b22d65f2018" satisfied condition "success or failure"
Sep 27 21:49:11.579: INFO: Trying to get logs from node macpro-1 pod pod-configmaps-a3a3ae30-89e8-4a7d-b4a2-6b22d65f2018 container configmap-volume-test: <nil>
STEP: delete the pod
Sep 27 21:49:11.603: INFO: Waiting for pod pod-configmaps-a3a3ae30-89e8-4a7d-b4a2-6b22d65f2018 to disappear
Sep 27 21:49:11.605: INFO: Pod pod-configmaps-a3a3ae30-89e8-4a7d-b4a2-6b22d65f2018 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:49:11.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3439" for this suite.
Sep 27 21:49:17.626: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:49:17.700: INFO: namespace configmap-3439 deletion completed in 6.092748368s

• [SLOW TEST:8.297 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:49:17.701: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6275
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1293
STEP: creating an rc
Sep 27 21:49:17.848: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 create -f - --namespace=kubectl-6275'
Sep 27 21:49:17.989: INFO: stderr: ""
Sep 27 21:49:17.989: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Waiting for Redis master to start.
Sep 27 21:49:18.991: INFO: Selector matched 1 pods for map[app:redis]
Sep 27 21:49:18.991: INFO: Found 0 / 1
Sep 27 21:49:19.991: INFO: Selector matched 1 pods for map[app:redis]
Sep 27 21:49:19.991: INFO: Found 1 / 1
Sep 27 21:49:19.991: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Sep 27 21:49:19.993: INFO: Selector matched 1 pods for map[app:redis]
Sep 27 21:49:19.993: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Sep 27 21:49:19.993: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 logs redis-master-btvmt redis-master --namespace=kubectl-6275'
Sep 27 21:49:20.065: INFO: stderr: ""
Sep 27 21:49:20.065: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 27 Sep 21:49:19.007 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 27 Sep 21:49:19.007 # Server started, Redis version 3.2.12\n1:M 27 Sep 21:49:19.007 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 27 Sep 21:49:19.007 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Sep 27 21:49:20.065: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 log redis-master-btvmt redis-master --namespace=kubectl-6275 --tail=1'
Sep 27 21:49:20.141: INFO: stderr: ""
Sep 27 21:49:20.141: INFO: stdout: "1:M 27 Sep 21:49:19.007 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Sep 27 21:49:20.141: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 log redis-master-btvmt redis-master --namespace=kubectl-6275 --limit-bytes=1'
Sep 27 21:49:20.211: INFO: stderr: ""
Sep 27 21:49:20.211: INFO: stdout: " "
STEP: exposing timestamps
Sep 27 21:49:20.211: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 log redis-master-btvmt redis-master --namespace=kubectl-6275 --tail=1 --timestamps'
Sep 27 21:49:20.280: INFO: stderr: ""
Sep 27 21:49:20.280: INFO: stdout: "2019-09-27T21:49:19.00748691Z 1:M 27 Sep 21:49:19.007 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Sep 27 21:49:22.780: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 log redis-master-btvmt redis-master --namespace=kubectl-6275 --since=1s'
Sep 27 21:49:22.849: INFO: stderr: ""
Sep 27 21:49:22.850: INFO: stdout: ""
Sep 27 21:49:22.850: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 log redis-master-btvmt redis-master --namespace=kubectl-6275 --since=24h'
Sep 27 21:49:22.922: INFO: stderr: ""
Sep 27 21:49:22.922: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 27 Sep 21:49:19.007 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 27 Sep 21:49:19.007 # Server started, Redis version 3.2.12\n1:M 27 Sep 21:49:19.007 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 27 Sep 21:49:19.007 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1299
STEP: using delete to clean up resources
Sep 27 21:49:22.922: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 delete --grace-period=0 --force -f - --namespace=kubectl-6275'
Sep 27 21:49:22.988: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 27 21:49:22.988: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Sep 27 21:49:22.988: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 get rc,svc -l name=nginx --no-headers --namespace=kubectl-6275'
Sep 27 21:49:23.052: INFO: stderr: "No resources found.\n"
Sep 27 21:49:23.052: INFO: stdout: ""
Sep 27 21:49:23.052: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 get pods -l name=nginx --namespace=kubectl-6275 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep 27 21:49:23.113: INFO: stderr: ""
Sep 27 21:49:23.113: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:49:23.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6275" for this suite.
Sep 27 21:49:29.128: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:49:29.199: INFO: namespace kubectl-6275 deletion completed in 6.08239529s

• [SLOW TEST:11.498 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl logs
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:49:29.199: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-8134
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override arguments
Sep 27 21:49:29.364: INFO: Waiting up to 5m0s for pod "client-containers-07d581b2-52f0-4d16-92f5-e012072c9f0b" in namespace "containers-8134" to be "success or failure"
Sep 27 21:49:29.366: INFO: Pod "client-containers-07d581b2-52f0-4d16-92f5-e012072c9f0b": Phase="Pending", Reason="", readiness=false. Elapsed: 1.942679ms
Sep 27 21:49:31.368: INFO: Pod "client-containers-07d581b2-52f0-4d16-92f5-e012072c9f0b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00460566s
Sep 27 21:49:33.371: INFO: Pod "client-containers-07d581b2-52f0-4d16-92f5-e012072c9f0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007412149s
STEP: Saw pod success
Sep 27 21:49:33.371: INFO: Pod "client-containers-07d581b2-52f0-4d16-92f5-e012072c9f0b" satisfied condition "success or failure"
Sep 27 21:49:33.373: INFO: Trying to get logs from node macpro-2 pod client-containers-07d581b2-52f0-4d16-92f5-e012072c9f0b container test-container: <nil>
STEP: delete the pod
Sep 27 21:49:33.394: INFO: Waiting for pod client-containers-07d581b2-52f0-4d16-92f5-e012072c9f0b to disappear
Sep 27 21:49:33.395: INFO: Pod client-containers-07d581b2-52f0-4d16-92f5-e012072c9f0b no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:49:33.396: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8134" for this suite.
Sep 27 21:49:39.413: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:49:39.484: INFO: namespace containers-8134 deletion completed in 6.08547048s

• [SLOW TEST:10.285 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:49:39.484: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-833
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 27 21:49:39.637: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Sep 27 21:49:39.646: INFO: Pod name sample-pod: Found 0 pods out of 1
Sep 27 21:49:44.649: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Sep 27 21:49:44.649: INFO: Creating deployment "test-rolling-update-deployment"
Sep 27 21:49:44.655: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Sep 27 21:49:44.659: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Sep 27 21:49:46.664: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Sep 27 21:49:46.666: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Sep 27 21:49:46.675: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-833,SelfLink:/apis/apps/v1/namespaces/deployment-833/deployments/test-rolling-update-deployment,UID:f7b7be4d-0767-4238-bca2-13e7509e8ebb,ResourceVersion:7624789,Generation:1,CreationTimestamp:2019-09-27 21:49:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-09-27 21:49:44 +0000 UTC 2019-09-27 21:49:44 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-09-27 21:49:46 +0000 UTC 2019-09-27 21:49:44 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-79f6b9d75c" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Sep 27 21:49:46.677: INFO: New ReplicaSet "test-rolling-update-deployment-79f6b9d75c" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79f6b9d75c,GenerateName:,Namespace:deployment-833,SelfLink:/apis/apps/v1/namespaces/deployment-833/replicasets/test-rolling-update-deployment-79f6b9d75c,UID:3497accb-8edc-47b0-b949-18735890e387,ResourceVersion:7624778,Generation:1,CreationTimestamp:2019-09-27 21:49:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment f7b7be4d-0767-4238-bca2-13e7509e8ebb 0xc003984a17 0xc003984a18}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Sep 27 21:49:46.677: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Sep 27 21:49:46.677: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-833,SelfLink:/apis/apps/v1/namespaces/deployment-833/replicasets/test-rolling-update-controller,UID:c0cec043-6a29-4122-9551-594cbf59d63d,ResourceVersion:7624788,Generation:2,CreationTimestamp:2019-09-27 21:49:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment f7b7be4d-0767-4238-bca2-13e7509e8ebb 0xc003984947 0xc003984948}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep 27 21:49:46.683: INFO: Pod "test-rolling-update-deployment-79f6b9d75c-gvtjr" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79f6b9d75c-gvtjr,GenerateName:test-rolling-update-deployment-79f6b9d75c-,Namespace:deployment-833,SelfLink:/api/v1/namespaces/deployment-833/pods/test-rolling-update-deployment-79f6b9d75c-gvtjr,UID:3cebdbfd-8203-4e8a-9fc4-ff2adfef61c6,ResourceVersion:7624777,Generation:0,CreationTimestamp:2019-09-27 21:49:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.150.130/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-79f6b9d75c 3497accb-8edc-47b0-b949-18735890e387 0xc003985317 0xc003985318}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-pk7sq {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-pk7sq,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-pk7sq true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:macpro-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003985390} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0039853b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:49:44 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:49:46 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:49:46 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:49:44 +0000 UTC  }],Message:,Reason:,HostIP:10.10.10.5,PodIP:192.168.150.130,StartTime:2019-09-27 21:49:44 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-09-27 21:49:45 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://bfff3b31833354e92ae219ff6237fd963119fd7841183b6485a7aac9d8ff2445}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:49:46.683: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-833" for this suite.
Sep 27 21:49:52.710: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:49:52.781: INFO: namespace deployment-833 deletion completed in 6.09609637s

• [SLOW TEST:13.298 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:49:52.782: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-508
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Sep 27 21:49:55.472: INFO: Successfully updated pod "annotationupdate99787ef3-4f18-4dd2-9e28-3a2965a0018a"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:49:57.484: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-508" for this suite.
Sep 27 21:50:19.497: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:50:19.580: INFO: namespace projected-508 deletion completed in 22.093291472s

• [SLOW TEST:26.798 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:50:19.580: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5309
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 27 21:50:19.726: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 version'
Sep 27 21:50:19.801: INFO: stderr: ""
Sep 27 21:50:19.801: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.2\", GitCommit:\"f6278300bebbb750328ac16ee6dd3aa7d3549568\", GitTreeState:\"clean\", BuildDate:\"2019-08-05T09:23:26Z\", GoVersion:\"go1.12.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.2\", GitCommit:\"f6278300bebbb750328ac16ee6dd3aa7d3549568\", GitTreeState:\"clean\", BuildDate:\"2019-08-05T09:15:22Z\", GoVersion:\"go1.12.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:50:19.801: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5309" for this suite.
Sep 27 21:50:25.818: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:50:25.901: INFO: namespace kubectl-5309 deletion completed in 6.097263397s

• [SLOW TEST:6.321 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl version
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:50:25.902: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7224
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1558
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep 27 21:50:26.046: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/apps.v1 --namespace=kubectl-7224'
Sep 27 21:50:26.122: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep 27 21:50:26.122: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
Sep 27 21:50:30.139: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 delete deployment e2e-test-nginx-deployment --namespace=kubectl-7224'
Sep 27 21:50:30.206: INFO: stderr: ""
Sep 27 21:50:30.206: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:50:30.206: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7224" for this suite.
Sep 27 21:50:52.226: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:50:52.295: INFO: namespace kubectl-7224 deletion completed in 22.080081513s

• [SLOW TEST:26.393 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:50:52.295: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7110
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name s-test-opt-del-ba0a979e-e445-407f-8f8e-82dc583e42a5
STEP: Creating secret with name s-test-opt-upd-0725c169-9cbd-4fc0-af50-31bd371d9d59
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-ba0a979e-e445-407f-8f8e-82dc583e42a5
STEP: Updating secret s-test-opt-upd-0725c169-9cbd-4fc0-af50-31bd371d9d59
STEP: Creating secret with name s-test-opt-create-cc0775b7-9185-48bb-bfcf-96282bd9575c
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:52:22.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7110" for this suite.
Sep 27 21:52:44.871: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:52:44.943: INFO: namespace projected-7110 deletion completed in 22.083817023s

• [SLOW TEST:112.649 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:52:44.944: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-3236
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:53:45.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3236" for this suite.
Sep 27 21:54:07.120: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:54:07.194: INFO: namespace container-probe-3236 deletion completed in 22.085135918s

• [SLOW TEST:82.250 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:54:07.194: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-9404
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Sep 27 21:54:07.342: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:54:21.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9404" for this suite.
Sep 27 21:54:27.457: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:54:27.526: INFO: namespace pods-9404 deletion completed in 6.086959595s

• [SLOW TEST:20.332 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:54:27.526: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4772
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1613
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep 27 21:54:27.679: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-4772'
Sep 27 21:54:27.754: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep 27 21:54:27.754: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1618
Sep 27 21:54:27.765: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 delete jobs e2e-test-nginx-job --namespace=kubectl-4772'
Sep 27 21:54:27.835: INFO: stderr: ""
Sep 27 21:54:27.835: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:54:27.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4772" for this suite.
Sep 27 21:54:33.849: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:54:33.922: INFO: namespace kubectl-4772 deletion completed in 6.083859748s

• [SLOW TEST:6.396 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run job
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:54:33.922: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7694
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-upd-bcfe79d0-ea7b-4d63-85d6-dfea13ec8fcb
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:54:36.119: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7694" for this suite.
Sep 27 21:54:58.138: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:54:58.217: INFO: namespace configmap-7694 deletion completed in 22.095299963s

• [SLOW TEST:24.295 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:54:58.217: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4663
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a replication controller
Sep 27 21:54:58.363: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 create -f - --namespace=kubectl-4663'
Sep 27 21:54:58.571: INFO: stderr: ""
Sep 27 21:54:58.571: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep 27 21:54:58.571: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4663'
Sep 27 21:54:58.647: INFO: stderr: ""
Sep 27 21:54:58.647: INFO: stdout: "update-demo-nautilus-24www update-demo-nautilus-c2m74 "
Sep 27 21:54:58.647: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 get pods update-demo-nautilus-24www -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4663'
Sep 27 21:54:58.708: INFO: stderr: ""
Sep 27 21:54:58.708: INFO: stdout: ""
Sep 27 21:54:58.708: INFO: update-demo-nautilus-24www is created but not running
Sep 27 21:55:03.708: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4663'
Sep 27 21:55:03.773: INFO: stderr: ""
Sep 27 21:55:03.773: INFO: stdout: "update-demo-nautilus-24www update-demo-nautilus-c2m74 "
Sep 27 21:55:03.773: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 get pods update-demo-nautilus-24www -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4663'
Sep 27 21:55:03.833: INFO: stderr: ""
Sep 27 21:55:03.833: INFO: stdout: "true"
Sep 27 21:55:03.833: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 get pods update-demo-nautilus-24www -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4663'
Sep 27 21:55:03.894: INFO: stderr: ""
Sep 27 21:55:03.894: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 27 21:55:03.894: INFO: validating pod update-demo-nautilus-24www
Sep 27 21:55:03.898: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 27 21:55:03.898: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 27 21:55:03.898: INFO: update-demo-nautilus-24www is verified up and running
Sep 27 21:55:03.898: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 get pods update-demo-nautilus-c2m74 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4663'
Sep 27 21:55:03.959: INFO: stderr: ""
Sep 27 21:55:03.959: INFO: stdout: "true"
Sep 27 21:55:03.959: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 get pods update-demo-nautilus-c2m74 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4663'
Sep 27 21:55:04.018: INFO: stderr: ""
Sep 27 21:55:04.018: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 27 21:55:04.018: INFO: validating pod update-demo-nautilus-c2m74
Sep 27 21:55:04.022: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 27 21:55:04.022: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 27 21:55:04.022: INFO: update-demo-nautilus-c2m74 is verified up and running
STEP: using delete to clean up resources
Sep 27 21:55:04.022: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 delete --grace-period=0 --force -f - --namespace=kubectl-4663'
Sep 27 21:55:04.092: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 27 21:55:04.092: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Sep 27 21:55:04.092: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-4663'
Sep 27 21:55:04.156: INFO: stderr: "No resources found.\n"
Sep 27 21:55:04.156: INFO: stdout: ""
Sep 27 21:55:04.156: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 get pods -l name=update-demo --namespace=kubectl-4663 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep 27 21:55:04.215: INFO: stderr: ""
Sep 27 21:55:04.215: INFO: stdout: "update-demo-nautilus-24www\nupdate-demo-nautilus-c2m74\n"
Sep 27 21:55:04.716: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-4663'
Sep 27 21:55:04.781: INFO: stderr: "No resources found.\n"
Sep 27 21:55:04.781: INFO: stdout: ""
Sep 27 21:55:04.781: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 get pods -l name=update-demo --namespace=kubectl-4663 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep 27 21:55:04.842: INFO: stderr: ""
Sep 27 21:55:04.842: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:55:04.842: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4663" for this suite.
Sep 27 21:55:26.856: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:55:26.929: INFO: namespace kubectl-4663 deletion completed in 22.083484856s

• [SLOW TEST:28.711 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:55:26.930: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-8441
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Sep 27 21:55:57.121: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0927 21:55:57.121367      18 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:55:57.121: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8441" for this suite.
Sep 27 21:56:03.135: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:56:03.206: INFO: namespace gc-8441 deletion completed in 6.082420286s

• [SLOW TEST:36.276 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:56:03.206: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-4600
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Sep 27 21:56:13.382: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0927 21:56:13.382355      18 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:56:13.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4600" for this suite.
Sep 27 21:56:19.396: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:56:19.477: INFO: namespace gc-4600 deletion completed in 6.092267007s

• [SLOW TEST:16.271 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:56:19.477: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-6975
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0927 21:56:59.685475      18 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep 27 21:56:59.685: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:56:59.685: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6975" for this suite.
Sep 27 21:57:05.709: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:57:05.798: INFO: namespace gc-6975 deletion completed in 6.110410573s

• [SLOW TEST:46.321 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:57:05.798: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-4239
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test use defaults
Sep 27 21:57:05.994: INFO: Waiting up to 5m0s for pod "client-containers-4219c3da-cbb5-42e7-973d-2ebfefa193b2" in namespace "containers-4239" to be "success or failure"
Sep 27 21:57:05.996: INFO: Pod "client-containers-4219c3da-cbb5-42e7-973d-2ebfefa193b2": Phase="Pending", Reason="", readiness=false. Elapsed: 1.815044ms
Sep 27 21:57:07.999: INFO: Pod "client-containers-4219c3da-cbb5-42e7-973d-2ebfefa193b2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004332947s
STEP: Saw pod success
Sep 27 21:57:07.999: INFO: Pod "client-containers-4219c3da-cbb5-42e7-973d-2ebfefa193b2" satisfied condition "success or failure"
Sep 27 21:57:08.001: INFO: Trying to get logs from node macpro-3 pod client-containers-4219c3da-cbb5-42e7-973d-2ebfefa193b2 container test-container: <nil>
STEP: delete the pod
Sep 27 21:57:08.025: INFO: Waiting for pod client-containers-4219c3da-cbb5-42e7-973d-2ebfefa193b2 to disappear
Sep 27 21:57:08.027: INFO: Pod client-containers-4219c3da-cbb5-42e7-973d-2ebfefa193b2 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:57:08.027: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-4239" for this suite.
Sep 27 21:57:14.045: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:57:14.120: INFO: namespace containers-4239 deletion completed in 6.090831184s

• [SLOW TEST:8.323 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:57:14.121: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1260
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1722
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep 27 21:57:14.265: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=kubectl-1260'
Sep 27 21:57:14.852: INFO: stderr: ""
Sep 27 21:57:14.852: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Sep 27 21:57:19.903: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 get pod e2e-test-nginx-pod --namespace=kubectl-1260 -o json'
Sep 27 21:57:19.962: INFO: stderr: ""
Sep 27 21:57:19.962: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"192.168.153.7/32\",\n            \"kubernetes.io/psp\": \"e2e-test-privileged-psp\"\n        },\n        \"creationTimestamp\": \"2019-09-27T21:57:14Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"kubectl-1260\",\n        \"resourceVersion\": \"7626442\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-1260/pods/e2e-test-nginx-pod\",\n        \"uid\": \"fb027d49-5e57-4a13-967b-674bf2349b42\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-c5kjq\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"macpro-3\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-c5kjq\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-c5kjq\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-09-27T21:57:14Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-09-27T21:57:16Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-09-27T21:57:16Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-09-27T21:57:14Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://65e258933ead2b3dce785e5deef687ca2e13260fa9765ec85bdf1709ce63a735\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-09-27T21:57:15Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.10.10.6\",\n        \"phase\": \"Running\",\n        \"podIP\": \"192.168.153.7\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-09-27T21:57:14Z\"\n    }\n}\n"
STEP: replace the image in the pod
Sep 27 21:57:19.962: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 replace -f - --namespace=kubectl-1260'
Sep 27 21:57:20.162: INFO: stderr: ""
Sep 27 21:57:20.162: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1727
Sep 27 21:57:20.168: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 delete pods e2e-test-nginx-pod --namespace=kubectl-1260'
Sep 27 21:57:22.147: INFO: stderr: ""
Sep 27 21:57:22.147: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:57:22.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1260" for this suite.
Sep 27 21:57:28.161: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:57:28.233: INFO: namespace kubectl-1260 deletion completed in 6.082971777s

• [SLOW TEST:14.112 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl replace
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:57:28.233: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-6197
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Sep 27 21:57:28.375: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep 27 21:57:28.380: INFO: Waiting for terminating namespaces to be deleted...
Sep 27 21:57:28.382: INFO: 
Logging pods the kubelet thinks is on node macpro-1 before test
Sep 27 21:57:28.388: INFO: calico-kube-controllers-7bd78b474d-t2lgl from kube-system started at 2019-08-08 02:05:40 +0000 UTC (1 container statuses recorded)
Sep 27 21:57:28.388: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Sep 27 21:57:28.388: INFO: etcd-macpro-1 from kube-system started at 2019-08-13 03:43:55 +0000 UTC (1 container statuses recorded)
Sep 27 21:57:28.388: INFO: 	Container etcd ready: true, restart count 0
Sep 27 21:57:28.388: INFO: kube-controller-manager-macpro-1 from kube-system started at 2019-08-08 01:50:11 +0000 UTC (1 container statuses recorded)
Sep 27 21:57:28.388: INFO: 	Container kube-controller-manager ready: true, restart count 8
Sep 27 21:57:28.388: INFO: coredns-5c98db65d4-9bgxc from kube-system started at 2019-08-08 01:50:51 +0000 UTC (1 container statuses recorded)
Sep 27 21:57:28.388: INFO: 	Container coredns ready: true, restart count 7
Sep 27 21:57:28.388: INFO: speaker-msvrw from metallb-system started at 2019-08-08 02:15:42 +0000 UTC (1 container statuses recorded)
Sep 27 21:57:28.388: INFO: 	Container speaker ready: true, restart count 0
Sep 27 21:57:28.388: INFO: sonobuoy-systemd-logs-daemon-set-3ff1c1a60c394bba-c5zcw from sonobuoy started at 2019-09-27 21:16:41 +0000 UTC (2 container statuses recorded)
Sep 27 21:57:28.388: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 27 21:57:28.388: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 27 21:57:28.388: INFO: coredns-5c98db65d4-hxb4g from kube-system started at 2019-08-08 01:50:47 +0000 UTC (1 container statuses recorded)
Sep 27 21:57:28.388: INFO: 	Container coredns ready: true, restart count 7
Sep 27 21:57:28.388: INFO: controller-55d74449-q2f47 from metallb-system started at 2019-08-08 02:15:42 +0000 UTC (1 container statuses recorded)
Sep 27 21:57:28.388: INFO: 	Container controller ready: true, restart count 0
Sep 27 21:57:28.388: INFO: rethinkdb-57544557d7-kssqr from default started at 2019-08-08 17:32:36 +0000 UTC (1 container statuses recorded)
Sep 27 21:57:28.388: INFO: 	Container rethinkdb ready: true, restart count 0
Sep 27 21:57:28.388: INFO: kube-scheduler-macpro-1 from kube-system started at 2019-08-13 03:43:55 +0000 UTC (1 container statuses recorded)
Sep 27 21:57:28.388: INFO: 	Container kube-scheduler ready: true, restart count 9
Sep 27 21:57:28.388: INFO: orka-5c9d6bfc94-rxjt9 from default started at 2019-09-27 20:09:01 +0000 UTC (1 container statuses recorded)
Sep 27 21:57:28.388: INFO: 	Container orka ready: true, restart count 0
Sep 27 21:57:28.388: INFO: kube-proxy-zgndg from kube-system started at 2019-08-08 01:50:37 +0000 UTC (1 container statuses recorded)
Sep 27 21:57:28.388: INFO: 	Container kube-proxy ready: true, restart count 0
Sep 27 21:57:28.388: INFO: calico-node-6vk4s from kube-system started at 2019-08-08 02:05:40 +0000 UTC (1 container statuses recorded)
Sep 27 21:57:28.388: INFO: 	Container calico-node ready: true, restart count 0
Sep 27 21:57:28.388: INFO: kube-apiserver-macpro-1 from kube-system started at 2019-08-13 03:41:36 +0000 UTC (1 container statuses recorded)
Sep 27 21:57:28.388: INFO: 	Container kube-apiserver ready: true, restart count 0
Sep 27 21:57:28.388: INFO: 
Logging pods the kubelet thinks is on node macpro-2 before test
Sep 27 21:57:28.393: INFO: speaker-w9jlq from metallb-system started at 2019-08-11 23:04:22 +0000 UTC (1 container statuses recorded)
Sep 27 21:57:28.393: INFO: 	Container speaker ready: true, restart count 0
Sep 27 21:57:28.393: INFO: kube-apiserver-macpro-2 from kube-system started at 2019-08-13 03:41:23 +0000 UTC (1 container statuses recorded)
Sep 27 21:57:28.393: INFO: 	Container kube-apiserver ready: true, restart count 0
Sep 27 21:57:28.393: INFO: kube-controller-manager-macpro-2 from kube-system started at 2019-08-08 02:20:59 +0000 UTC (1 container statuses recorded)
Sep 27 21:57:28.393: INFO: 	Container kube-controller-manager ready: true, restart count 1
Sep 27 21:57:28.393: INFO: etcd-macpro-2 from kube-system started at 2019-08-08 02:20:59 +0000 UTC (1 container statuses recorded)
Sep 27 21:57:28.393: INFO: 	Container etcd ready: true, restart count 0
Sep 27 21:57:28.393: INFO: sonobuoy from sonobuoy started at 2019-09-27 21:15:55 +0000 UTC (1 container statuses recorded)
Sep 27 21:57:28.393: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Sep 27 21:57:28.393: INFO: sonobuoy-systemd-logs-daemon-set-3ff1c1a60c394bba-rcrrv from sonobuoy started at 2019-09-27 21:16:41 +0000 UTC (2 container statuses recorded)
Sep 27 21:57:28.393: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 27 21:57:28.393: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 27 21:57:28.393: INFO: kube-scheduler-macpro-2 from kube-system started at 2019-08-13 03:43:55 +0000 UTC (1 container statuses recorded)
Sep 27 21:57:28.393: INFO: 	Container kube-scheduler ready: true, restart count 2
Sep 27 21:57:28.393: INFO: calico-node-7tmv4 from kube-system started at 2019-08-08 02:20:59 +0000 UTC (1 container statuses recorded)
Sep 27 21:57:28.393: INFO: 	Container calico-node ready: true, restart count 0
Sep 27 21:57:28.393: INFO: kube-proxy-s7hbl from kube-system started at 2019-08-08 02:20:59 +0000 UTC (1 container statuses recorded)
Sep 27 21:57:28.393: INFO: 	Container kube-proxy ready: true, restart count 0
Sep 27 21:57:28.393: INFO: 
Logging pods the kubelet thinks is on node macpro-3 before test
Sep 27 21:57:28.398: INFO: calico-node-ctgww from kube-system started at 2019-08-08 02:21:44 +0000 UTC (1 container statuses recorded)
Sep 27 21:57:28.398: INFO: 	Container calico-node ready: true, restart count 0
Sep 27 21:57:28.398: INFO: etcd-macpro-3 from kube-system started at 2019-08-13 03:43:55 +0000 UTC (1 container statuses recorded)
Sep 27 21:57:28.398: INFO: 	Container etcd ready: true, restart count 2
Sep 27 21:57:28.398: INFO: kube-apiserver-macpro-3 from kube-system started at 2019-08-13 03:43:55 +0000 UTC (1 container statuses recorded)
Sep 27 21:57:28.398: INFO: 	Container kube-apiserver ready: true, restart count 0
Sep 27 21:57:28.398: INFO: kube-proxy-kfvg6 from kube-system started at 2019-08-08 02:21:08 +0000 UTC (1 container statuses recorded)
Sep 27 21:57:28.398: INFO: 	Container kube-proxy ready: true, restart count 0
Sep 27 21:57:28.398: INFO: kube-controller-manager-macpro-3 from kube-system started at 2019-08-13 03:43:55 +0000 UTC (1 container statuses recorded)
Sep 27 21:57:28.398: INFO: 	Container kube-controller-manager ready: true, restart count 2
Sep 27 21:57:28.398: INFO: speaker-t4xwn from metallb-system started at 2019-08-11 23:04:22 +0000 UTC (1 container statuses recorded)
Sep 27 21:57:28.398: INFO: 	Container speaker ready: true, restart count 0
Sep 27 21:57:28.398: INFO: sonobuoy-e2e-job-e236daee93b24985 from sonobuoy started at 2019-09-27 21:16:00 +0000 UTC (2 container statuses recorded)
Sep 27 21:57:28.398: INFO: 	Container e2e ready: true, restart count 0
Sep 27 21:57:28.398: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 27 21:57:28.398: INFO: sonobuoy-systemd-logs-daemon-set-3ff1c1a60c394bba-fvsn5 from sonobuoy started at 2019-09-27 21:16:41 +0000 UTC (2 container statuses recorded)
Sep 27 21:57:28.398: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 27 21:57:28.398: INFO: 	Container systemd-logs ready: true, restart count 0
Sep 27 21:57:28.398: INFO: kube-scheduler-macpro-3 from kube-system started at 2019-08-08 02:21:06 +0000 UTC (1 container statuses recorded)
Sep 27 21:57:28.398: INFO: 	Container kube-scheduler ready: true, restart count 0
Sep 27 21:57:28.398: INFO: nfs-server-pod from default started at 2019-09-26 21:59:12 +0000 UTC (1 container statuses recorded)
Sep 27 21:57:28.398: INFO: 	Container nfs-server-container ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15c86a64210c2e31], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:57:29.424: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-6197" for this suite.
Sep 27 21:57:35.445: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:57:35.514: INFO: namespace sched-pred-6197 deletion completed in 6.087293129s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:7.281 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:57:35.514: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1002
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep 27 21:57:35.675: INFO: Waiting up to 5m0s for pod "downwardapi-volume-54fefbcb-c06d-463a-aa82-77c8ac92e4ef" in namespace "projected-1002" to be "success or failure"
Sep 27 21:57:35.677: INFO: Pod "downwardapi-volume-54fefbcb-c06d-463a-aa82-77c8ac92e4ef": Phase="Pending", Reason="", readiness=false. Elapsed: 1.877023ms
Sep 27 21:57:37.679: INFO: Pod "downwardapi-volume-54fefbcb-c06d-463a-aa82-77c8ac92e4ef": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004394799s
STEP: Saw pod success
Sep 27 21:57:37.679: INFO: Pod "downwardapi-volume-54fefbcb-c06d-463a-aa82-77c8ac92e4ef" satisfied condition "success or failure"
Sep 27 21:57:37.681: INFO: Trying to get logs from node macpro-1 pod downwardapi-volume-54fefbcb-c06d-463a-aa82-77c8ac92e4ef container client-container: <nil>
STEP: delete the pod
Sep 27 21:57:37.704: INFO: Waiting for pod downwardapi-volume-54fefbcb-c06d-463a-aa82-77c8ac92e4ef to disappear
Sep 27 21:57:37.706: INFO: Pod downwardapi-volume-54fefbcb-c06d-463a-aa82-77c8ac92e4ef no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:57:37.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1002" for this suite.
Sep 27 21:57:43.720: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:57:43.789: INFO: namespace projected-1002 deletion completed in 6.080055732s

• [SLOW TEST:8.274 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:57:43.789: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in events-2920
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Sep 27 21:57:47.952: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-44f80fa3-7625-4033-90ae-c21431c35ace,GenerateName:,Namespace:events-2920,SelfLink:/api/v1/namespaces/events-2920/pods/send-events-44f80fa3-7625-4033-90ae-c21431c35ace,UID:6be62fba-18b0-4402-ada4-6b6d79c53341,ResourceVersion:7626587,Generation:0,CreationTimestamp:2019-09-27 21:57:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 935181957,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.150.141/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kwp4k {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kwp4k,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-kwp4k true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:macpro-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0034a6e80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0034a6ea0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:57:43 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:57:46 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:57:46 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 21:57:43 +0000 UTC  }],Message:,Reason:,HostIP:10.10.10.5,PodIP:192.168.150.141,StartTime:2019-09-27 21:57:43 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-09-27 21:57:45 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://d871b7244a8531cbc87093180d5cb71d7cc3de3eef860884c9f088438495a3ad}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Sep 27 21:57:49.955: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Sep 27 21:57:51.958: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:57:51.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-2920" for this suite.
Sep 27 21:58:31.986: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:58:32.060: INFO: namespace events-2920 deletion completed in 40.086118918s

• [SLOW TEST:48.272 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:58:32.061: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1168
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-projected-all-test-volume-93647e81-26be-4f6b-b1fd-ed29a5e55b36
STEP: Creating secret with name secret-projected-all-test-volume-a2316919-2784-41dd-9027-7611a59c93f2
STEP: Creating a pod to test Check all projections for projected volume plugin
Sep 27 21:58:32.234: INFO: Waiting up to 5m0s for pod "projected-volume-c7a694f9-65f8-440a-adc0-9c9cb80c04a8" in namespace "projected-1168" to be "success or failure"
Sep 27 21:58:32.236: INFO: Pod "projected-volume-c7a694f9-65f8-440a-adc0-9c9cb80c04a8": Phase="Pending", Reason="", readiness=false. Elapsed: 1.785802ms
Sep 27 21:58:34.239: INFO: Pod "projected-volume-c7a694f9-65f8-440a-adc0-9c9cb80c04a8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004833938s
STEP: Saw pod success
Sep 27 21:58:34.239: INFO: Pod "projected-volume-c7a694f9-65f8-440a-adc0-9c9cb80c04a8" satisfied condition "success or failure"
Sep 27 21:58:34.241: INFO: Trying to get logs from node macpro-3 pod projected-volume-c7a694f9-65f8-440a-adc0-9c9cb80c04a8 container projected-all-volume-test: <nil>
STEP: delete the pod
Sep 27 21:58:34.268: INFO: Waiting for pod projected-volume-c7a694f9-65f8-440a-adc0-9c9cb80c04a8 to disappear
Sep 27 21:58:34.269: INFO: Pod projected-volume-c7a694f9-65f8-440a-adc0-9c9cb80c04a8 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:58:34.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1168" for this suite.
Sep 27 21:58:40.284: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:58:40.365: INFO: namespace projected-1168 deletion completed in 6.092824108s

• [SLOW TEST:8.304 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:58:40.365: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4269
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name s-test-opt-del-fd1e1719-bdee-4ef6-afd0-3eb2b9bd7d70
STEP: Creating secret with name s-test-opt-upd-66292bde-aad7-4eaf-af61-160635d275c5
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-fd1e1719-bdee-4ef6-afd0-3eb2b9bd7d70
STEP: Updating secret s-test-opt-upd-66292bde-aad7-4eaf-af61-160635d275c5
STEP: Creating secret with name s-test-opt-create-fb6445d9-eac4-4ab3-b242-951bf343f723
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:58:44.619: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4269" for this suite.
Sep 27 21:59:06.634: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:59:06.705: INFO: namespace secrets-4269 deletion completed in 22.083329622s

• [SLOW TEST:26.340 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:59:06.705: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-1144
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Sep 27 21:59:12.878: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
W0927 21:59:12.878383      18 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep 27 21:59:12.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1144" for this suite.
Sep 27 21:59:18.901: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 21:59:18.970: INFO: namespace gc-1144 deletion completed in 6.089098526s

• [SLOW TEST:12.265 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 21:59:18.970: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-kubelet-etc-hosts-1373
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Sep 27 21:59:23.162: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1373 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 27 21:59:23.162: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
Sep 27 21:59:23.243: INFO: Exec stderr: ""
Sep 27 21:59:23.243: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1373 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 27 21:59:23.243: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
Sep 27 21:59:23.321: INFO: Exec stderr: ""
Sep 27 21:59:23.321: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1373 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 27 21:59:23.321: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
Sep 27 21:59:23.399: INFO: Exec stderr: ""
Sep 27 21:59:23.399: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1373 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 27 21:59:23.399: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
Sep 27 21:59:23.479: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Sep 27 21:59:23.479: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1373 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 27 21:59:23.479: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
Sep 27 21:59:23.558: INFO: Exec stderr: ""
Sep 27 21:59:23.558: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1373 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 27 21:59:23.558: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
Sep 27 21:59:23.638: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Sep 27 21:59:23.638: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1373 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 27 21:59:23.638: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
Sep 27 21:59:23.733: INFO: Exec stderr: ""
Sep 27 21:59:23.733: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1373 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 27 21:59:23.733: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
Sep 27 21:59:23.815: INFO: Exec stderr: ""
Sep 27 21:59:23.815: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1373 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 27 21:59:23.815: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
Sep 27 21:59:23.896: INFO: Exec stderr: ""
Sep 27 21:59:23.896: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1373 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 27 21:59:23.896: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
Sep 27 21:59:23.977: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 21:59:23.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-1373" for this suite.
Sep 27 22:00:13.992: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:00:14.062: INFO: namespace e2e-kubelet-etc-hosts-1373 deletion completed in 50.081809417s

• [SLOW TEST:55.092 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:00:14.062: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3413
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: validating api versions
Sep 27 22:00:14.209: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 api-versions'
Sep 27 22:00:14.294: INFO: stderr: ""
Sep 27 22:00:14.294: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\ncrd.projectcalico.org/v1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:00:14.294: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3413" for this suite.
Sep 27 22:00:20.311: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:00:20.383: INFO: namespace kubectl-3413 deletion completed in 6.085196988s

• [SLOW TEST:6.320 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:00:20.383: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-8172
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test substitution in container's args
Sep 27 22:00:20.546: INFO: Waiting up to 5m0s for pod "var-expansion-d3b8c242-fec9-472e-886d-ac9c669c1aad" in namespace "var-expansion-8172" to be "success or failure"
Sep 27 22:00:20.548: INFO: Pod "var-expansion-d3b8c242-fec9-472e-886d-ac9c669c1aad": Phase="Pending", Reason="", readiness=false. Elapsed: 1.834665ms
Sep 27 22:00:22.550: INFO: Pod "var-expansion-d3b8c242-fec9-472e-886d-ac9c669c1aad": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004517922s
STEP: Saw pod success
Sep 27 22:00:22.550: INFO: Pod "var-expansion-d3b8c242-fec9-472e-886d-ac9c669c1aad" satisfied condition "success or failure"
Sep 27 22:00:22.552: INFO: Trying to get logs from node macpro-2 pod var-expansion-d3b8c242-fec9-472e-886d-ac9c669c1aad container dapi-container: <nil>
STEP: delete the pod
Sep 27 22:00:22.589: INFO: Waiting for pod var-expansion-d3b8c242-fec9-472e-886d-ac9c669c1aad to disappear
Sep 27 22:00:22.590: INFO: Pod var-expansion-d3b8c242-fec9-472e-886d-ac9c669c1aad no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:00:22.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-8172" for this suite.
Sep 27 22:00:28.604: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:00:28.688: INFO: namespace var-expansion-8172 deletion completed in 6.094709023s

• [SLOW TEST:8.305 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:00:28.688: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename aggregator
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in aggregator-4201
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:76
Sep 27 22:00:28.836: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Registering the sample API server.
Sep 27 22:00:29.662: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Sep 27 22:00:31.725: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705218429, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705218429, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705218429, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705218429, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 27 22:00:42.355: INFO: Waited 8.617159995s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:67
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:00:42.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-4201" for this suite.
Sep 27 22:00:48.946: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:00:49.018: INFO: namespace aggregator-4201 deletion completed in 6.164147772s

• [SLOW TEST:20.330 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:00:49.018: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-9866
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Sep 27 22:00:49.185: INFO: Pod name pod-release: Found 0 pods out of 1
Sep 27 22:00:54.188: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:00:54.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-9866" for this suite.
Sep 27 22:01:00.256: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:01:00.329: INFO: namespace replication-controller-9866 deletion completed in 6.097042133s

• [SLOW TEST:11.311 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:01:00.330: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-7289
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating service multi-endpoint-test in namespace services-7289
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7289 to expose endpoints map[]
Sep 27 22:01:00.512: INFO: Get endpoints failed (8.628317ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Sep 27 22:01:01.515: INFO: successfully validated that service multi-endpoint-test in namespace services-7289 exposes endpoints map[] (1.01121189s elapsed)
STEP: Creating pod pod1 in namespace services-7289
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7289 to expose endpoints map[pod1:[100]]
Sep 27 22:01:03.544: INFO: successfully validated that service multi-endpoint-test in namespace services-7289 exposes endpoints map[pod1:[100]] (2.02071072s elapsed)
STEP: Creating pod pod2 in namespace services-7289
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7289 to expose endpoints map[pod1:[100] pod2:[101]]
Sep 27 22:01:05.583: INFO: successfully validated that service multi-endpoint-test in namespace services-7289 exposes endpoints map[pod1:[100] pod2:[101]] (2.027764899s elapsed)
STEP: Deleting pod pod1 in namespace services-7289
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7289 to expose endpoints map[pod2:[101]]
Sep 27 22:01:06.608: INFO: successfully validated that service multi-endpoint-test in namespace services-7289 exposes endpoints map[pod2:[101]] (1.014006604s elapsed)
STEP: Deleting pod pod2 in namespace services-7289
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7289 to expose endpoints map[]
Sep 27 22:01:06.630: INFO: successfully validated that service multi-endpoint-test in namespace services-7289 exposes endpoints map[] (11.840867ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:01:06.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7289" for this suite.
Sep 27 22:01:12.680: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:01:12.748: INFO: namespace services-7289 deletion completed in 6.07958408s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:12.418 seconds]
[sig-network] Services
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:01:12.748: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-4550
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Sep 27 22:01:12.903: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:01:17.064: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4550" for this suite.
Sep 27 22:01:39.078: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:01:39.147: INFO: namespace init-container-4550 deletion completed in 22.080220779s

• [SLOW TEST:26.399 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:01:39.147: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9354
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-601fe5db-50ab-452d-8c84-a7f79c5aaa4b
STEP: Creating a pod to test consume secrets
Sep 27 22:01:39.313: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a299c1b2-b4a6-421b-a0dc-0bb5d9b65f31" in namespace "projected-9354" to be "success or failure"
Sep 27 22:01:39.315: INFO: Pod "pod-projected-secrets-a299c1b2-b4a6-421b-a0dc-0bb5d9b65f31": Phase="Pending", Reason="", readiness=false. Elapsed: 1.810834ms
Sep 27 22:01:41.318: INFO: Pod "pod-projected-secrets-a299c1b2-b4a6-421b-a0dc-0bb5d9b65f31": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004735222s
STEP: Saw pod success
Sep 27 22:01:41.318: INFO: Pod "pod-projected-secrets-a299c1b2-b4a6-421b-a0dc-0bb5d9b65f31" satisfied condition "success or failure"
Sep 27 22:01:41.320: INFO: Trying to get logs from node macpro-3 pod pod-projected-secrets-a299c1b2-b4a6-421b-a0dc-0bb5d9b65f31 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep 27 22:01:41.348: INFO: Waiting for pod pod-projected-secrets-a299c1b2-b4a6-421b-a0dc-0bb5d9b65f31 to disappear
Sep 27 22:01:41.350: INFO: Pod pod-projected-secrets-a299c1b2-b4a6-421b-a0dc-0bb5d9b65f31 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:01:41.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9354" for this suite.
Sep 27 22:01:47.368: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:01:47.436: INFO: namespace projected-9354 deletion completed in 6.082736022s

• [SLOW TEST:8.289 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:01:47.436: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-8601
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 27 22:01:47.585: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Sep 27 22:01:49.617: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:01:50.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-8601" for this suite.
Sep 27 22:01:56.646: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:01:56.717: INFO: namespace replication-controller-8601 deletion completed in 6.082241038s

• [SLOW TEST:9.281 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:01:56.717: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-4932
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-8032
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-6971
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:02:21.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-4932" for this suite.
Sep 27 22:02:27.233: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:02:27.303: INFO: namespace namespaces-4932 deletion completed in 6.081581003s
STEP: Destroying namespace "nsdeletetest-8032" for this suite.
Sep 27 22:02:27.305: INFO: Namespace nsdeletetest-8032 was already deleted
STEP: Destroying namespace "nsdeletetest-6971" for this suite.
Sep 27 22:02:33.316: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:02:33.391: INFO: namespace nsdeletetest-6971 deletion completed in 6.086631013s

• [SLOW TEST:36.674 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:02:33.391: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-7427
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test substitution in container's command
Sep 27 22:02:33.547: INFO: Waiting up to 5m0s for pod "var-expansion-a28df691-707f-45aa-9219-944cbfbb3c4b" in namespace "var-expansion-7427" to be "success or failure"
Sep 27 22:02:33.549: INFO: Pod "var-expansion-a28df691-707f-45aa-9219-944cbfbb3c4b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.047343ms
Sep 27 22:02:35.552: INFO: Pod "var-expansion-a28df691-707f-45aa-9219-944cbfbb3c4b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004753359s
STEP: Saw pod success
Sep 27 22:02:35.552: INFO: Pod "var-expansion-a28df691-707f-45aa-9219-944cbfbb3c4b" satisfied condition "success or failure"
Sep 27 22:02:35.554: INFO: Trying to get logs from node macpro-1 pod var-expansion-a28df691-707f-45aa-9219-944cbfbb3c4b container dapi-container: <nil>
STEP: delete the pod
Sep 27 22:02:35.583: INFO: Waiting for pod var-expansion-a28df691-707f-45aa-9219-944cbfbb3c4b to disappear
Sep 27 22:02:35.585: INFO: Pod var-expansion-a28df691-707f-45aa-9219-944cbfbb3c4b no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:02:35.585: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7427" for this suite.
Sep 27 22:02:41.598: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:02:41.670: INFO: namespace var-expansion-7427 deletion completed in 6.082432897s

• [SLOW TEST:8.278 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:02:41.670: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-6020
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-downwardapi-dxhh
STEP: Creating a pod to test atomic-volume-subpath
Sep 27 22:02:41.853: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-dxhh" in namespace "subpath-6020" to be "success or failure"
Sep 27 22:02:41.855: INFO: Pod "pod-subpath-test-downwardapi-dxhh": Phase="Pending", Reason="", readiness=false. Elapsed: 1.929797ms
Sep 27 22:02:43.858: INFO: Pod "pod-subpath-test-downwardapi-dxhh": Phase="Running", Reason="", readiness=true. Elapsed: 2.004593345s
Sep 27 22:02:45.861: INFO: Pod "pod-subpath-test-downwardapi-dxhh": Phase="Running", Reason="", readiness=true. Elapsed: 4.007439034s
Sep 27 22:02:47.863: INFO: Pod "pod-subpath-test-downwardapi-dxhh": Phase="Running", Reason="", readiness=true. Elapsed: 6.010082251s
Sep 27 22:02:49.866: INFO: Pod "pod-subpath-test-downwardapi-dxhh": Phase="Running", Reason="", readiness=true. Elapsed: 8.012576176s
Sep 27 22:02:51.869: INFO: Pod "pod-subpath-test-downwardapi-dxhh": Phase="Running", Reason="", readiness=true. Elapsed: 10.01553552s
Sep 27 22:02:53.872: INFO: Pod "pod-subpath-test-downwardapi-dxhh": Phase="Running", Reason="", readiness=true. Elapsed: 12.018632814s
Sep 27 22:02:55.875: INFO: Pod "pod-subpath-test-downwardapi-dxhh": Phase="Running", Reason="", readiness=true. Elapsed: 14.021465246s
Sep 27 22:02:57.877: INFO: Pod "pod-subpath-test-downwardapi-dxhh": Phase="Running", Reason="", readiness=true. Elapsed: 16.023940912s
Sep 27 22:02:59.880: INFO: Pod "pod-subpath-test-downwardapi-dxhh": Phase="Running", Reason="", readiness=true. Elapsed: 18.026425224s
Sep 27 22:03:01.883: INFO: Pod "pod-subpath-test-downwardapi-dxhh": Phase="Running", Reason="", readiness=true. Elapsed: 20.029967849s
Sep 27 22:03:03.886: INFO: Pod "pod-subpath-test-downwardapi-dxhh": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.032581512s
STEP: Saw pod success
Sep 27 22:03:03.886: INFO: Pod "pod-subpath-test-downwardapi-dxhh" satisfied condition "success or failure"
Sep 27 22:03:03.888: INFO: Trying to get logs from node macpro-2 pod pod-subpath-test-downwardapi-dxhh container test-container-subpath-downwardapi-dxhh: <nil>
STEP: delete the pod
Sep 27 22:03:03.912: INFO: Waiting for pod pod-subpath-test-downwardapi-dxhh to disappear
Sep 27 22:03:03.914: INFO: Pod pod-subpath-test-downwardapi-dxhh no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-dxhh
Sep 27 22:03:03.914: INFO: Deleting pod "pod-subpath-test-downwardapi-dxhh" in namespace "subpath-6020"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:03:03.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6020" for this suite.
Sep 27 22:03:09.930: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:03:10.001: INFO: namespace subpath-6020 deletion completed in 6.08272301s

• [SLOW TEST:28.331 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:03:10.001: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-7226
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Sep 27 22:03:10.150: INFO: PodSpec: initContainers in spec.initContainers
Sep 27 22:03:57.473: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-7352148e-4393-479b-8724-47150a10d100", GenerateName:"", Namespace:"init-container-7226", SelfLink:"/api/v1/namespaces/init-container-7226/pods/pod-init-7352148e-4393-479b-8724-47150a10d100", UID:"3ee707a8-75c6-442e-bb76-8bf410a7925e", ResourceVersion:"7628292", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63705218590, loc:(*time.Location)(0x80bfa40)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"150154889"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"192.168.150.150/32", "kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-66bsk", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc003438300), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-66bsk", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-66bsk", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-66bsk", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001d9fa68), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"macpro-2", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc00328b500), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001d9faf0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001d9fb10)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc001d9fb18), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc001d9fb1c), PreemptionPolicy:(*v1.PreemptionPolicy)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705218590, loc:(*time.Location)(0x80bfa40)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705218590, loc:(*time.Location)(0x80bfa40)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705218590, loc:(*time.Location)(0x80bfa40)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705218590, loc:(*time.Location)(0x80bfa40)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.10.10.5", PodIP:"192.168.150.150", StartTime:(*v1.Time)(0xc00379c0e0), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002aba310)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002aba380)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://2e23667503c55ffcfe2c7787d1c8e22bed40455618c84c59bc0bb22a98c2add5"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00379c120), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00379c100), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:03:57.473: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-7226" for this suite.
Sep 27 22:04:19.495: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:04:19.572: INFO: namespace init-container-7226 deletion completed in 22.096315488s

• [SLOW TEST:69.571 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:04:19.573: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3081
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Starting the proxy
Sep 27 22:04:19.732: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-741451867 proxy --unix-socket=/tmp/kubectl-proxy-unix145959442/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:04:19.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3081" for this suite.
Sep 27 22:04:25.792: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:04:25.866: INFO: namespace kubectl-3081 deletion completed in 6.085570557s

• [SLOW TEST:6.293 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:04:25.866: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5880
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with configMap that has name projected-configmap-test-upd-c1aef939-ae51-45be-b628-9a4497331b31
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-c1aef939-ae51-45be-b628-9a4497331b31
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:04:30.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5880" for this suite.
Sep 27 22:04:52.093: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:04:52.167: INFO: namespace projected-5880 deletion completed in 22.089212971s

• [SLOW TEST:26.301 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:04:52.167: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-8217
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Sep 27 22:04:52.318: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-8217,SelfLink:/api/v1/namespaces/watch-8217/configmaps/e2e-watch-test-configmap-a,UID:c9ec769f-6e78-48d4-bc50-04cc4a3874cf,ResourceVersion:7628465,Generation:0,CreationTimestamp:2019-09-27 22:04:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep 27 22:04:52.318: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-8217,SelfLink:/api/v1/namespaces/watch-8217/configmaps/e2e-watch-test-configmap-a,UID:c9ec769f-6e78-48d4-bc50-04cc4a3874cf,ResourceVersion:7628465,Generation:0,CreationTimestamp:2019-09-27 22:04:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Sep 27 22:05:02.327: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-8217,SelfLink:/api/v1/namespaces/watch-8217/configmaps/e2e-watch-test-configmap-a,UID:c9ec769f-6e78-48d4-bc50-04cc4a3874cf,ResourceVersion:7628484,Generation:0,CreationTimestamp:2019-09-27 22:04:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Sep 27 22:05:02.327: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-8217,SelfLink:/api/v1/namespaces/watch-8217/configmaps/e2e-watch-test-configmap-a,UID:c9ec769f-6e78-48d4-bc50-04cc4a3874cf,ResourceVersion:7628484,Generation:0,CreationTimestamp:2019-09-27 22:04:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Sep 27 22:05:12.336: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-8217,SelfLink:/api/v1/namespaces/watch-8217/configmaps/e2e-watch-test-configmap-a,UID:c9ec769f-6e78-48d4-bc50-04cc4a3874cf,ResourceVersion:7628504,Generation:0,CreationTimestamp:2019-09-27 22:04:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep 27 22:05:12.336: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-8217,SelfLink:/api/v1/namespaces/watch-8217/configmaps/e2e-watch-test-configmap-a,UID:c9ec769f-6e78-48d4-bc50-04cc4a3874cf,ResourceVersion:7628504,Generation:0,CreationTimestamp:2019-09-27 22:04:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Sep 27 22:05:22.345: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-8217,SelfLink:/api/v1/namespaces/watch-8217/configmaps/e2e-watch-test-configmap-a,UID:c9ec769f-6e78-48d4-bc50-04cc4a3874cf,ResourceVersion:7628523,Generation:0,CreationTimestamp:2019-09-27 22:04:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep 27 22:05:22.345: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-8217,SelfLink:/api/v1/namespaces/watch-8217/configmaps/e2e-watch-test-configmap-a,UID:c9ec769f-6e78-48d4-bc50-04cc4a3874cf,ResourceVersion:7628523,Generation:0,CreationTimestamp:2019-09-27 22:04:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Sep 27 22:05:32.354: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-8217,SelfLink:/api/v1/namespaces/watch-8217/configmaps/e2e-watch-test-configmap-b,UID:40973811-a9ef-4203-86ad-38666fba35bb,ResourceVersion:7628542,Generation:0,CreationTimestamp:2019-09-27 22:05:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep 27 22:05:32.354: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-8217,SelfLink:/api/v1/namespaces/watch-8217/configmaps/e2e-watch-test-configmap-b,UID:40973811-a9ef-4203-86ad-38666fba35bb,ResourceVersion:7628542,Generation:0,CreationTimestamp:2019-09-27 22:05:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Sep 27 22:05:42.364: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-8217,SelfLink:/api/v1/namespaces/watch-8217/configmaps/e2e-watch-test-configmap-b,UID:40973811-a9ef-4203-86ad-38666fba35bb,ResourceVersion:7628561,Generation:0,CreationTimestamp:2019-09-27 22:05:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep 27 22:05:42.364: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-8217,SelfLink:/api/v1/namespaces/watch-8217/configmaps/e2e-watch-test-configmap-b,UID:40973811-a9ef-4203-86ad-38666fba35bb,ResourceVersion:7628561,Generation:0,CreationTimestamp:2019-09-27 22:05:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:05:52.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8217" for this suite.
Sep 27 22:05:58.379: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:05:58.449: INFO: namespace watch-8217 deletion completed in 6.082243863s

• [SLOW TEST:66.282 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:05:58.449: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svc-latency-1056
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating replication controller svc-latency-rc in namespace svc-latency-1056
I0927 22:05:58.609062      18 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: svc-latency-1056, replica count: 1
I0927 22:05:59.659347      18 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0927 22:06:00.659498      18 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Sep 27 22:06:00.781: INFO: Created: latency-svc-xb496
Sep 27 22:06:00.786: INFO: Got endpoints: latency-svc-xb496 [27.232107ms]
Sep 27 22:06:00.815: INFO: Created: latency-svc-h8f2z
Sep 27 22:06:00.815: INFO: Got endpoints: latency-svc-h8f2z [28.499993ms]
Sep 27 22:06:00.832: INFO: Created: latency-svc-mwpdv
Sep 27 22:06:00.837: INFO: Got endpoints: latency-svc-mwpdv [50.222189ms]
Sep 27 22:06:00.854: INFO: Created: latency-svc-67z9v
Sep 27 22:06:00.863: INFO: Got endpoints: latency-svc-67z9v [76.199758ms]
Sep 27 22:06:00.880: INFO: Created: latency-svc-hr2dq
Sep 27 22:06:00.885: INFO: Got endpoints: latency-svc-hr2dq [97.936803ms]
Sep 27 22:06:00.908: INFO: Created: latency-svc-kdkdw
Sep 27 22:06:00.913: INFO: Got endpoints: latency-svc-kdkdw [126.704748ms]
Sep 27 22:06:00.935: INFO: Created: latency-svc-2ns7c
Sep 27 22:06:00.943: INFO: Got endpoints: latency-svc-2ns7c [156.352012ms]
Sep 27 22:06:00.961: INFO: Created: latency-svc-qbd64
Sep 27 22:06:00.967: INFO: Got endpoints: latency-svc-qbd64 [180.120319ms]
Sep 27 22:06:00.988: INFO: Created: latency-svc-ggvtx
Sep 27 22:06:01.008: INFO: Got endpoints: latency-svc-ggvtx [221.697634ms]
Sep 27 22:06:01.016: INFO: Created: latency-svc-kw44c
Sep 27 22:06:01.021: INFO: Got endpoints: latency-svc-kw44c [234.712097ms]
Sep 27 22:06:01.045: INFO: Created: latency-svc-2bpgn
Sep 27 22:06:01.054: INFO: Got endpoints: latency-svc-2bpgn [267.670082ms]
Sep 27 22:06:01.071: INFO: Created: latency-svc-hhj7f
Sep 27 22:06:01.076: INFO: Got endpoints: latency-svc-hhj7f [288.964087ms]
Sep 27 22:06:01.090: INFO: Created: latency-svc-zpfsm
Sep 27 22:06:01.099: INFO: Got endpoints: latency-svc-zpfsm [312.650731ms]
Sep 27 22:06:01.121: INFO: Created: latency-svc-w8q4p
Sep 27 22:06:01.126: INFO: Got endpoints: latency-svc-w8q4p [339.536854ms]
Sep 27 22:06:01.158: INFO: Created: latency-svc-bklpl
Sep 27 22:06:01.158: INFO: Got endpoints: latency-svc-bklpl [371.517093ms]
Sep 27 22:06:01.178: INFO: Created: latency-svc-nkmp7
Sep 27 22:06:01.184: INFO: Got endpoints: latency-svc-nkmp7 [396.96905ms]
Sep 27 22:06:01.202: INFO: Created: latency-svc-24p5x
Sep 27 22:06:01.208: INFO: Got endpoints: latency-svc-24p5x [392.694481ms]
Sep 27 22:06:01.227: INFO: Created: latency-svc-hv9cd
Sep 27 22:06:01.234: INFO: Got endpoints: latency-svc-hv9cd [397.520471ms]
Sep 27 22:06:01.249: INFO: Created: latency-svc-mj4x7
Sep 27 22:06:01.257: INFO: Got endpoints: latency-svc-mj4x7 [394.233884ms]
Sep 27 22:06:01.279: INFO: Created: latency-svc-zkgrt
Sep 27 22:06:01.284: INFO: Got endpoints: latency-svc-zkgrt [399.35747ms]
Sep 27 22:06:01.301: INFO: Created: latency-svc-nxn5f
Sep 27 22:06:01.308: INFO: Got endpoints: latency-svc-nxn5f [394.749877ms]
Sep 27 22:06:01.326: INFO: Created: latency-svc-7npjx
Sep 27 22:06:01.331: INFO: Got endpoints: latency-svc-7npjx [387.910212ms]
Sep 27 22:06:01.353: INFO: Created: latency-svc-r6d72
Sep 27 22:06:01.361: INFO: Got endpoints: latency-svc-r6d72 [394.682765ms]
Sep 27 22:06:01.388: INFO: Created: latency-svc-nllxx
Sep 27 22:06:01.388: INFO: Got endpoints: latency-svc-nllxx [380.174794ms]
Sep 27 22:06:01.407: INFO: Created: latency-svc-lvlgw
Sep 27 22:06:01.416: INFO: Got endpoints: latency-svc-lvlgw [394.349715ms]
Sep 27 22:06:01.431: INFO: Created: latency-svc-k2nvb
Sep 27 22:06:01.436: INFO: Got endpoints: latency-svc-k2nvb [381.474603ms]
Sep 27 22:06:01.452: INFO: Created: latency-svc-rc2bp
Sep 27 22:06:01.479: INFO: Got endpoints: latency-svc-rc2bp [402.887297ms]
Sep 27 22:06:01.479: INFO: Created: latency-svc-2zphc
Sep 27 22:06:01.504: INFO: Got endpoints: latency-svc-2zphc [404.592323ms]
Sep 27 22:06:01.509: INFO: Created: latency-svc-ngvg7
Sep 27 22:06:01.515: INFO: Got endpoints: latency-svc-ngvg7 [388.720087ms]
Sep 27 22:06:01.531: INFO: Created: latency-svc-sgkpb
Sep 27 22:06:01.536: INFO: Got endpoints: latency-svc-sgkpb [378.192392ms]
Sep 27 22:06:01.551: INFO: Created: latency-svc-7w496
Sep 27 22:06:01.557: INFO: Got endpoints: latency-svc-7w496 [373.912876ms]
Sep 27 22:06:01.572: INFO: Created: latency-svc-ppr6d
Sep 27 22:06:01.597: INFO: Created: latency-svc-5kmhc
Sep 27 22:06:01.597: INFO: Got endpoints: latency-svc-ppr6d [389.03883ms]
Sep 27 22:06:01.620: INFO: Got endpoints: latency-svc-5kmhc [385.948349ms]
Sep 27 22:06:01.629: INFO: Created: latency-svc-cfl94
Sep 27 22:06:01.635: INFO: Got endpoints: latency-svc-cfl94 [377.615101ms]
Sep 27 22:06:01.650: INFO: Created: latency-svc-r9gzm
Sep 27 22:06:01.656: INFO: Got endpoints: latency-svc-r9gzm [371.958069ms]
Sep 27 22:06:01.673: INFO: Created: latency-svc-ngpbk
Sep 27 22:06:01.678: INFO: Got endpoints: latency-svc-ngpbk [369.614293ms]
Sep 27 22:06:01.692: INFO: Created: latency-svc-5sggf
Sep 27 22:06:01.719: INFO: Created: latency-svc-5hvhv
Sep 27 22:06:01.739: INFO: Got endpoints: latency-svc-5hvhv [377.919125ms]
Sep 27 22:06:01.739: INFO: Got endpoints: latency-svc-5sggf [408.447813ms]
Sep 27 22:06:01.748: INFO: Created: latency-svc-j2d9j
Sep 27 22:06:01.751: INFO: Got endpoints: latency-svc-j2d9j [362.508378ms]
Sep 27 22:06:01.769: INFO: Created: latency-svc-vqc62
Sep 27 22:06:01.774: INFO: Got endpoints: latency-svc-vqc62 [358.562214ms]
Sep 27 22:06:01.794: INFO: Created: latency-svc-t9rtw
Sep 27 22:06:01.799: INFO: Got endpoints: latency-svc-t9rtw [363.473955ms]
Sep 27 22:06:01.822: INFO: Created: latency-svc-kqfp4
Sep 27 22:06:01.837: INFO: Got endpoints: latency-svc-kqfp4 [358.610734ms]
Sep 27 22:06:01.860: INFO: Created: latency-svc-5dvds
Sep 27 22:06:01.860: INFO: Got endpoints: latency-svc-5dvds [355.714235ms]
Sep 27 22:06:01.877: INFO: Created: latency-svc-nffkj
Sep 27 22:06:01.890: INFO: Got endpoints: latency-svc-nffkj [375.315958ms]
Sep 27 22:06:01.909: INFO: Created: latency-svc-f7rhq
Sep 27 22:06:01.915: INFO: Got endpoints: latency-svc-f7rhq [378.363394ms]
Sep 27 22:06:01.929: INFO: Created: latency-svc-8wq6h
Sep 27 22:06:01.955: INFO: Got endpoints: latency-svc-8wq6h [398.032168ms]
Sep 27 22:06:01.956: INFO: Created: latency-svc-mf96t
Sep 27 22:06:01.978: INFO: Got endpoints: latency-svc-mf96t [380.725368ms]
Sep 27 22:06:01.986: INFO: Created: latency-svc-c8vwm
Sep 27 22:06:01.991: INFO: Got endpoints: latency-svc-c8vwm [370.903962ms]
Sep 27 22:06:02.009: INFO: Created: latency-svc-l749x
Sep 27 22:06:02.014: INFO: Got endpoints: latency-svc-l749x [379.534566ms]
Sep 27 22:06:02.031: INFO: Created: latency-svc-dz98h
Sep 27 22:06:02.036: INFO: Got endpoints: latency-svc-dz98h [379.83821ms]
Sep 27 22:06:02.053: INFO: Created: latency-svc-x9f9n
Sep 27 22:06:02.072: INFO: Got endpoints: latency-svc-x9f9n [393.740393ms]
Sep 27 22:06:02.077: INFO: Created: latency-svc-fq527
Sep 27 22:06:02.099: INFO: Got endpoints: latency-svc-fq527 [359.312537ms]
Sep 27 22:06:02.107: INFO: Created: latency-svc-s4bsg
Sep 27 22:06:02.113: INFO: Got endpoints: latency-svc-s4bsg [373.280012ms]
Sep 27 22:06:02.128: INFO: Created: latency-svc-p8x5g
Sep 27 22:06:02.140: INFO: Got endpoints: latency-svc-p8x5g [388.600361ms]
Sep 27 22:06:02.153: INFO: Created: latency-svc-9xw5z
Sep 27 22:06:02.159: INFO: Got endpoints: latency-svc-9xw5z [384.2118ms]
Sep 27 22:06:02.186: INFO: Created: latency-svc-m9b78
Sep 27 22:06:02.188: INFO: Got endpoints: latency-svc-m9b78 [389.140786ms]
Sep 27 22:06:02.214: INFO: Created: latency-svc-vkgl2
Sep 27 22:06:02.214: INFO: Got endpoints: latency-svc-vkgl2 [376.394976ms]
Sep 27 22:06:02.233: INFO: Created: latency-svc-98r2g
Sep 27 22:06:02.242: INFO: Got endpoints: latency-svc-98r2g [382.743451ms]
Sep 27 22:06:02.256: INFO: Created: latency-svc-4lzg7
Sep 27 22:06:02.265: INFO: Got endpoints: latency-svc-4lzg7 [374.524365ms]
Sep 27 22:06:02.286: INFO: Created: latency-svc-dssnj
Sep 27 22:06:02.302: INFO: Got endpoints: latency-svc-dssnj [387.206014ms]
Sep 27 22:06:02.310: INFO: Created: latency-svc-p7ltj
Sep 27 22:06:02.338: INFO: Got endpoints: latency-svc-p7ltj [382.183519ms]
Sep 27 22:06:02.338: INFO: Created: latency-svc-w49fw
Sep 27 22:06:02.356: INFO: Created: latency-svc-csqp9
Sep 27 22:06:02.375: INFO: Created: latency-svc-9xclb
Sep 27 22:06:02.396: INFO: Got endpoints: latency-svc-w49fw [418.129072ms]
Sep 27 22:06:02.401: INFO: Created: latency-svc-xbfnb
Sep 27 22:06:02.419: INFO: Created: latency-svc-gzfjc
Sep 27 22:06:02.445: INFO: Got endpoints: latency-svc-csqp9 [453.646958ms]
Sep 27 22:06:02.449: INFO: Created: latency-svc-tndnl
Sep 27 22:06:02.467: INFO: Created: latency-svc-kdmzt
Sep 27 22:06:02.487: INFO: Created: latency-svc-74vpk
Sep 27 22:06:02.491: INFO: Got endpoints: latency-svc-9xclb [476.272597ms]
Sep 27 22:06:02.508: INFO: Created: latency-svc-f9pgt
Sep 27 22:06:02.533: INFO: Created: latency-svc-6294r
Sep 27 22:06:02.538: INFO: Got endpoints: latency-svc-xbfnb [501.74774ms]
Sep 27 22:06:02.567: INFO: Created: latency-svc-qmkjz
Sep 27 22:06:02.590: INFO: Got endpoints: latency-svc-gzfjc [518.670579ms]
Sep 27 22:06:02.594: INFO: Created: latency-svc-4fj66
Sep 27 22:06:02.615: INFO: Created: latency-svc-6sw8v
Sep 27 22:06:02.636: INFO: Created: latency-svc-jk9xh
Sep 27 22:06:02.642: INFO: Got endpoints: latency-svc-tndnl [543.623793ms]
Sep 27 22:06:02.678: INFO: Created: latency-svc-pk94q
Sep 27 22:06:02.697: INFO: Got endpoints: latency-svc-kdmzt [584.45951ms]
Sep 27 22:06:02.702: INFO: Created: latency-svc-vm59r
Sep 27 22:06:02.720: INFO: Created: latency-svc-7mzlk
Sep 27 22:06:02.740: INFO: Got endpoints: latency-svc-74vpk [600.027864ms]
Sep 27 22:06:02.744: INFO: Created: latency-svc-mlg46
Sep 27 22:06:02.770: INFO: Created: latency-svc-vmmc5
Sep 27 22:06:02.794: INFO: Got endpoints: latency-svc-f9pgt [635.742551ms]
Sep 27 22:06:02.799: INFO: Created: latency-svc-tlp29
Sep 27 22:06:02.822: INFO: Created: latency-svc-rnzbw
Sep 27 22:06:02.837: INFO: Got endpoints: latency-svc-6294r [648.757317ms]
Sep 27 22:06:02.846: INFO: Created: latency-svc-rnqcs
Sep 27 22:06:02.863: INFO: Created: latency-svc-57c92
Sep 27 22:06:02.894: INFO: Got endpoints: latency-svc-qmkjz [679.89037ms]
Sep 27 22:06:02.894: INFO: Created: latency-svc-p8pnp
Sep 27 22:06:02.921: INFO: Created: latency-svc-szssv
Sep 27 22:06:02.937: INFO: Got endpoints: latency-svc-4fj66 [694.12035ms]
Sep 27 22:06:02.942: INFO: Created: latency-svc-dlggs
Sep 27 22:06:02.964: INFO: Created: latency-svc-rn4b9
Sep 27 22:06:02.988: INFO: Got endpoints: latency-svc-6sw8v [722.830137ms]
Sep 27 22:06:03.011: INFO: Created: latency-svc-nph8c
Sep 27 22:06:03.036: INFO: Got endpoints: latency-svc-jk9xh [734.440351ms]
Sep 27 22:06:03.058: INFO: Created: latency-svc-p5k96
Sep 27 22:06:03.087: INFO: Got endpoints: latency-svc-pk94q [749.004629ms]
Sep 27 22:06:03.113: INFO: Created: latency-svc-t9mjg
Sep 27 22:06:03.143: INFO: Got endpoints: latency-svc-vm59r [746.860375ms]
Sep 27 22:06:03.162: INFO: Created: latency-svc-98f5m
Sep 27 22:06:03.190: INFO: Got endpoints: latency-svc-7mzlk [744.623089ms]
Sep 27 22:06:03.215: INFO: Created: latency-svc-v4527
Sep 27 22:06:03.236: INFO: Got endpoints: latency-svc-mlg46 [745.696717ms]
Sep 27 22:06:03.267: INFO: Created: latency-svc-wtj6d
Sep 27 22:06:03.286: INFO: Got endpoints: latency-svc-vmmc5 [748.507572ms]
Sep 27 22:06:03.312: INFO: Created: latency-svc-xmdbh
Sep 27 22:06:03.339: INFO: Got endpoints: latency-svc-tlp29 [748.533839ms]
Sep 27 22:06:03.374: INFO: Created: latency-svc-9dtk4
Sep 27 22:06:03.387: INFO: Got endpoints: latency-svc-rnzbw [744.149531ms]
Sep 27 22:06:03.406: INFO: Created: latency-svc-z6nz9
Sep 27 22:06:03.437: INFO: Got endpoints: latency-svc-rnqcs [739.304152ms]
Sep 27 22:06:03.463: INFO: Created: latency-svc-r4q9m
Sep 27 22:06:03.492: INFO: Got endpoints: latency-svc-57c92 [752.712766ms]
Sep 27 22:06:03.513: INFO: Created: latency-svc-8q5qt
Sep 27 22:06:03.540: INFO: Got endpoints: latency-svc-p8pnp [745.607205ms]
Sep 27 22:06:03.564: INFO: Created: latency-svc-5km2z
Sep 27 22:06:03.598: INFO: Got endpoints: latency-svc-szssv [760.30352ms]
Sep 27 22:06:03.619: INFO: Created: latency-svc-mt78z
Sep 27 22:06:03.636: INFO: Got endpoints: latency-svc-dlggs [742.81823ms]
Sep 27 22:06:03.660: INFO: Created: latency-svc-5hv87
Sep 27 22:06:03.686: INFO: Got endpoints: latency-svc-rn4b9 [749.71701ms]
Sep 27 22:06:03.717: INFO: Created: latency-svc-6c97m
Sep 27 22:06:03.740: INFO: Got endpoints: latency-svc-nph8c [752.014071ms]
Sep 27 22:06:03.759: INFO: Created: latency-svc-5mll2
Sep 27 22:06:03.788: INFO: Got endpoints: latency-svc-p5k96 [751.518496ms]
Sep 27 22:06:03.808: INFO: Created: latency-svc-7rpq6
Sep 27 22:06:03.840: INFO: Got endpoints: latency-svc-t9mjg [753.089167ms]
Sep 27 22:06:03.860: INFO: Created: latency-svc-8bf9n
Sep 27 22:06:03.886: INFO: Got endpoints: latency-svc-98f5m [743.737116ms]
Sep 27 22:06:03.911: INFO: Created: latency-svc-d5w25
Sep 27 22:06:03.940: INFO: Got endpoints: latency-svc-v4527 [750.029327ms]
Sep 27 22:06:03.959: INFO: Created: latency-svc-klhp5
Sep 27 22:06:03.986: INFO: Got endpoints: latency-svc-wtj6d [750.068736ms]
Sep 27 22:06:04.006: INFO: Created: latency-svc-b5dtw
Sep 27 22:06:04.049: INFO: Got endpoints: latency-svc-xmdbh [762.721786ms]
Sep 27 22:06:04.077: INFO: Created: latency-svc-xrkhj
Sep 27 22:06:04.086: INFO: Got endpoints: latency-svc-9dtk4 [747.455754ms]
Sep 27 22:06:04.107: INFO: Created: latency-svc-gbm48
Sep 27 22:06:04.136: INFO: Got endpoints: latency-svc-z6nz9 [749.829124ms]
Sep 27 22:06:04.175: INFO: Created: latency-svc-ph82m
Sep 27 22:06:04.187: INFO: Got endpoints: latency-svc-r4q9m [750.178409ms]
Sep 27 22:06:04.208: INFO: Created: latency-svc-hl7dw
Sep 27 22:06:04.240: INFO: Got endpoints: latency-svc-8q5qt [747.526751ms]
Sep 27 22:06:04.283: INFO: Created: latency-svc-rvgkx
Sep 27 22:06:04.287: INFO: Got endpoints: latency-svc-5km2z [746.725649ms]
Sep 27 22:06:04.310: INFO: Created: latency-svc-s9r9d
Sep 27 22:06:04.336: INFO: Got endpoints: latency-svc-mt78z [738.772079ms]
Sep 27 22:06:04.359: INFO: Created: latency-svc-bzbq5
Sep 27 22:06:04.400: INFO: Got endpoints: latency-svc-5hv87 [763.359724ms]
Sep 27 22:06:04.420: INFO: Created: latency-svc-6kzf8
Sep 27 22:06:04.437: INFO: Got endpoints: latency-svc-6c97m [750.310114ms]
Sep 27 22:06:04.456: INFO: Created: latency-svc-hk7x2
Sep 27 22:06:04.490: INFO: Got endpoints: latency-svc-5mll2 [750.475622ms]
Sep 27 22:06:04.521: INFO: Created: latency-svc-g6mqx
Sep 27 22:06:04.537: INFO: Got endpoints: latency-svc-7rpq6 [748.479715ms]
Sep 27 22:06:04.560: INFO: Created: latency-svc-sfst4
Sep 27 22:06:04.587: INFO: Got endpoints: latency-svc-8bf9n [746.724566ms]
Sep 27 22:06:04.615: INFO: Created: latency-svc-vr9ph
Sep 27 22:06:04.637: INFO: Got endpoints: latency-svc-d5w25 [750.326834ms]
Sep 27 22:06:04.659: INFO: Created: latency-svc-hz5pj
Sep 27 22:06:04.690: INFO: Got endpoints: latency-svc-klhp5 [750.101959ms]
Sep 27 22:06:04.715: INFO: Created: latency-svc-7lx68
Sep 27 22:06:04.740: INFO: Got endpoints: latency-svc-b5dtw [753.712792ms]
Sep 27 22:06:04.760: INFO: Created: latency-svc-kxm49
Sep 27 22:06:04.786: INFO: Got endpoints: latency-svc-xrkhj [737.652108ms]
Sep 27 22:06:04.807: INFO: Created: latency-svc-ggpf7
Sep 27 22:06:04.836: INFO: Got endpoints: latency-svc-gbm48 [750.16514ms]
Sep 27 22:06:04.864: INFO: Created: latency-svc-lrpkf
Sep 27 22:06:04.887: INFO: Got endpoints: latency-svc-ph82m [750.320962ms]
Sep 27 22:06:04.910: INFO: Created: latency-svc-79jvp
Sep 27 22:06:04.937: INFO: Got endpoints: latency-svc-hl7dw [749.827455ms]
Sep 27 22:06:04.967: INFO: Created: latency-svc-7l88j
Sep 27 22:06:04.986: INFO: Got endpoints: latency-svc-rvgkx [746.220593ms]
Sep 27 22:06:05.007: INFO: Created: latency-svc-vz9s6
Sep 27 22:06:05.040: INFO: Got endpoints: latency-svc-s9r9d [752.964022ms]
Sep 27 22:06:05.061: INFO: Created: latency-svc-64gcg
Sep 27 22:06:05.090: INFO: Got endpoints: latency-svc-bzbq5 [753.8326ms]
Sep 27 22:06:05.124: INFO: Created: latency-svc-kv9sw
Sep 27 22:06:05.137: INFO: Got endpoints: latency-svc-6kzf8 [736.936317ms]
Sep 27 22:06:05.161: INFO: Created: latency-svc-tthfq
Sep 27 22:06:05.194: INFO: Got endpoints: latency-svc-hk7x2 [757.834662ms]
Sep 27 22:06:05.214: INFO: Created: latency-svc-xlltx
Sep 27 22:06:05.237: INFO: Got endpoints: latency-svc-g6mqx [746.365ms]
Sep 27 22:06:05.261: INFO: Created: latency-svc-hrqgr
Sep 27 22:06:05.292: INFO: Got endpoints: latency-svc-sfst4 [755.775948ms]
Sep 27 22:06:05.318: INFO: Created: latency-svc-pq558
Sep 27 22:06:05.336: INFO: Got endpoints: latency-svc-vr9ph [749.714568ms]
Sep 27 22:06:05.357: INFO: Created: latency-svc-bmmsb
Sep 27 22:06:05.387: INFO: Got endpoints: latency-svc-hz5pj [750.378229ms]
Sep 27 22:06:05.408: INFO: Created: latency-svc-wx4r8
Sep 27 22:06:05.440: INFO: Got endpoints: latency-svc-7lx68 [750.010156ms]
Sep 27 22:06:05.463: INFO: Created: latency-svc-vqwjl
Sep 27 22:06:05.487: INFO: Got endpoints: latency-svc-kxm49 [746.58541ms]
Sep 27 22:06:05.515: INFO: Created: latency-svc-bktmw
Sep 27 22:06:05.541: INFO: Got endpoints: latency-svc-ggpf7 [754.105709ms]
Sep 27 22:06:05.562: INFO: Created: latency-svc-r2xqr
Sep 27 22:06:05.587: INFO: Got endpoints: latency-svc-lrpkf [750.021595ms]
Sep 27 22:06:05.607: INFO: Created: latency-svc-bsccb
Sep 27 22:06:05.640: INFO: Got endpoints: latency-svc-79jvp [752.880598ms]
Sep 27 22:06:05.671: INFO: Created: latency-svc-l5kmm
Sep 27 22:06:05.686: INFO: Got endpoints: latency-svc-7l88j [749.857711ms]
Sep 27 22:06:05.706: INFO: Created: latency-svc-5vsjt
Sep 27 22:06:05.738: INFO: Got endpoints: latency-svc-vz9s6 [751.867188ms]
Sep 27 22:06:05.769: INFO: Created: latency-svc-qrqlf
Sep 27 22:06:05.790: INFO: Got endpoints: latency-svc-64gcg [750.066806ms]
Sep 27 22:06:05.813: INFO: Created: latency-svc-x7z2s
Sep 27 22:06:05.837: INFO: Got endpoints: latency-svc-kv9sw [746.534193ms]
Sep 27 22:06:05.860: INFO: Created: latency-svc-9fbhc
Sep 27 22:06:05.887: INFO: Got endpoints: latency-svc-tthfq [749.809463ms]
Sep 27 22:06:05.907: INFO: Created: latency-svc-xl7sr
Sep 27 22:06:05.936: INFO: Got endpoints: latency-svc-xlltx [741.923265ms]
Sep 27 22:06:05.958: INFO: Created: latency-svc-twh8t
Sep 27 22:06:05.995: INFO: Got endpoints: latency-svc-hrqgr [758.481031ms]
Sep 27 22:06:06.016: INFO: Created: latency-svc-8bqrj
Sep 27 22:06:06.037: INFO: Got endpoints: latency-svc-pq558 [744.238787ms]
Sep 27 22:06:06.056: INFO: Created: latency-svc-2qw9d
Sep 27 22:06:06.100: INFO: Got endpoints: latency-svc-bmmsb [764.051732ms]
Sep 27 22:06:06.121: INFO: Created: latency-svc-pn7n9
Sep 27 22:06:06.140: INFO: Got endpoints: latency-svc-wx4r8 [752.849491ms]
Sep 27 22:06:06.159: INFO: Created: latency-svc-4l7q9
Sep 27 22:06:06.190: INFO: Got endpoints: latency-svc-vqwjl [750.342013ms]
Sep 27 22:06:06.220: INFO: Created: latency-svc-hgwv4
Sep 27 22:06:06.236: INFO: Got endpoints: latency-svc-bktmw [749.610967ms]
Sep 27 22:06:06.259: INFO: Created: latency-svc-zmjlj
Sep 27 22:06:06.290: INFO: Got endpoints: latency-svc-r2xqr [749.042764ms]
Sep 27 22:06:06.327: INFO: Created: latency-svc-q5hjk
Sep 27 22:06:06.339: INFO: Got endpoints: latency-svc-bsccb [752.687945ms]
Sep 27 22:06:06.361: INFO: Created: latency-svc-k2zsq
Sep 27 22:06:06.386: INFO: Got endpoints: latency-svc-l5kmm [746.647142ms]
Sep 27 22:06:06.406: INFO: Created: latency-svc-94zp9
Sep 27 22:06:06.440: INFO: Got endpoints: latency-svc-5vsjt [753.278162ms]
Sep 27 22:06:06.464: INFO: Created: latency-svc-bgq5s
Sep 27 22:06:06.487: INFO: Got endpoints: latency-svc-qrqlf [748.478159ms]
Sep 27 22:06:06.513: INFO: Created: latency-svc-zmqc9
Sep 27 22:06:06.537: INFO: Got endpoints: latency-svc-x7z2s [747.323663ms]
Sep 27 22:06:06.561: INFO: Created: latency-svc-t6vwd
Sep 27 22:06:06.587: INFO: Got endpoints: latency-svc-9fbhc [749.882946ms]
Sep 27 22:06:06.607: INFO: Created: latency-svc-2n9rf
Sep 27 22:06:06.636: INFO: Got endpoints: latency-svc-xl7sr [749.763659ms]
Sep 27 22:06:06.673: INFO: Created: latency-svc-zgcwz
Sep 27 22:06:06.686: INFO: Got endpoints: latency-svc-twh8t [749.969738ms]
Sep 27 22:06:06.706: INFO: Created: latency-svc-7fkdc
Sep 27 22:06:06.737: INFO: Got endpoints: latency-svc-8bqrj [741.315448ms]
Sep 27 22:06:06.758: INFO: Created: latency-svc-v5xvf
Sep 27 22:06:06.787: INFO: Got endpoints: latency-svc-2qw9d [749.90758ms]
Sep 27 22:06:06.808: INFO: Created: latency-svc-6s8cj
Sep 27 22:06:06.840: INFO: Got endpoints: latency-svc-pn7n9 [739.455613ms]
Sep 27 22:06:06.860: INFO: Created: latency-svc-wjbqp
Sep 27 22:06:06.889: INFO: Got endpoints: latency-svc-4l7q9 [749.341379ms]
Sep 27 22:06:06.910: INFO: Created: latency-svc-qmftp
Sep 27 22:06:06.937: INFO: Got endpoints: latency-svc-hgwv4 [746.529231ms]
Sep 27 22:06:06.959: INFO: Created: latency-svc-86cnj
Sep 27 22:06:06.999: INFO: Got endpoints: latency-svc-zmjlj [762.261236ms]
Sep 27 22:06:07.025: INFO: Created: latency-svc-gdkz8
Sep 27 22:06:07.037: INFO: Got endpoints: latency-svc-q5hjk [746.800268ms]
Sep 27 22:06:07.058: INFO: Created: latency-svc-b2lfc
Sep 27 22:06:07.086: INFO: Got endpoints: latency-svc-k2zsq [747.107765ms]
Sep 27 22:06:07.117: INFO: Created: latency-svc-nj8hn
Sep 27 22:06:07.136: INFO: Got endpoints: latency-svc-94zp9 [750.080006ms]
Sep 27 22:06:07.157: INFO: Created: latency-svc-pkgwh
Sep 27 22:06:07.190: INFO: Got endpoints: latency-svc-bgq5s [750.212066ms]
Sep 27 22:06:07.212: INFO: Created: latency-svc-44x67
Sep 27 22:06:07.236: INFO: Got endpoints: latency-svc-zmqc9 [749.54108ms]
Sep 27 22:06:07.258: INFO: Created: latency-svc-mpxpz
Sep 27 22:06:07.287: INFO: Got endpoints: latency-svc-t6vwd [749.351629ms]
Sep 27 22:06:07.310: INFO: Created: latency-svc-r9rh5
Sep 27 22:06:07.338: INFO: Got endpoints: latency-svc-2n9rf [751.474386ms]
Sep 27 22:06:07.363: INFO: Created: latency-svc-wjg2t
Sep 27 22:06:07.390: INFO: Got endpoints: latency-svc-zgcwz [753.342497ms]
Sep 27 22:06:07.409: INFO: Created: latency-svc-79c9m
Sep 27 22:06:07.436: INFO: Got endpoints: latency-svc-7fkdc [749.974993ms]
Sep 27 22:06:07.468: INFO: Created: latency-svc-xxfvs
Sep 27 22:06:07.487: INFO: Got endpoints: latency-svc-v5xvf [749.997695ms]
Sep 27 22:06:07.509: INFO: Created: latency-svc-fgtpn
Sep 27 22:06:07.543: INFO: Got endpoints: latency-svc-6s8cj [756.721347ms]
Sep 27 22:06:07.582: INFO: Created: latency-svc-dp4dl
Sep 27 22:06:07.587: INFO: Got endpoints: latency-svc-wjbqp [746.637571ms]
Sep 27 22:06:07.607: INFO: Created: latency-svc-fjvcj
Sep 27 22:06:07.636: INFO: Got endpoints: latency-svc-qmftp [747.056065ms]
Sep 27 22:06:07.658: INFO: Created: latency-svc-jwh6f
Sep 27 22:06:07.687: INFO: Got endpoints: latency-svc-86cnj [749.801182ms]
Sep 27 22:06:07.709: INFO: Created: latency-svc-hqwwh
Sep 27 22:06:07.740: INFO: Got endpoints: latency-svc-gdkz8 [740.946526ms]
Sep 27 22:06:07.762: INFO: Created: latency-svc-fqbk6
Sep 27 22:06:07.798: INFO: Got endpoints: latency-svc-b2lfc [761.109814ms]
Sep 27 22:06:07.820: INFO: Created: latency-svc-zp5s8
Sep 27 22:06:07.837: INFO: Got endpoints: latency-svc-nj8hn [750.158324ms]
Sep 27 22:06:07.856: INFO: Created: latency-svc-c7d9d
Sep 27 22:06:07.890: INFO: Got endpoints: latency-svc-pkgwh [753.211443ms]
Sep 27 22:06:07.923: INFO: Created: latency-svc-rn8wp
Sep 27 22:06:07.939: INFO: Got endpoints: latency-svc-44x67 [749.425334ms]
Sep 27 22:06:07.962: INFO: Created: latency-svc-5n9tf
Sep 27 22:06:07.986: INFO: Got endpoints: latency-svc-mpxpz [750.181506ms]
Sep 27 22:06:08.006: INFO: Created: latency-svc-2v9dd
Sep 27 22:06:08.037: INFO: Got endpoints: latency-svc-r9rh5 [749.974752ms]
Sep 27 22:06:08.074: INFO: Created: latency-svc-bgx7r
Sep 27 22:06:08.092: INFO: Got endpoints: latency-svc-wjg2t [753.357952ms]
Sep 27 22:06:08.115: INFO: Created: latency-svc-56hzc
Sep 27 22:06:08.142: INFO: Got endpoints: latency-svc-79c9m [752.615332ms]
Sep 27 22:06:08.162: INFO: Created: latency-svc-glvhf
Sep 27 22:06:08.190: INFO: Got endpoints: latency-svc-xxfvs [753.311804ms]
Sep 27 22:06:08.210: INFO: Created: latency-svc-7q2rp
Sep 27 22:06:08.239: INFO: Got endpoints: latency-svc-fgtpn [752.194848ms]
Sep 27 22:06:08.268: INFO: Created: latency-svc-clzxl
Sep 27 22:06:08.287: INFO: Got endpoints: latency-svc-dp4dl [743.334643ms]
Sep 27 22:06:08.306: INFO: Created: latency-svc-krh64
Sep 27 22:06:08.340: INFO: Got endpoints: latency-svc-fjvcj [753.288442ms]
Sep 27 22:06:08.380: INFO: Created: latency-svc-vvbrx
Sep 27 22:06:08.386: INFO: Got endpoints: latency-svc-jwh6f [749.893024ms]
Sep 27 22:06:08.416: INFO: Created: latency-svc-9f2jh
Sep 27 22:06:08.436: INFO: Got endpoints: latency-svc-hqwwh [749.69071ms]
Sep 27 22:06:08.457: INFO: Created: latency-svc-4fg24
Sep 27 22:06:08.490: INFO: Got endpoints: latency-svc-fqbk6 [749.816838ms]
Sep 27 22:06:08.517: INFO: Created: latency-svc-htlqx
Sep 27 22:06:08.540: INFO: Got endpoints: latency-svc-zp5s8 [742.250725ms]
Sep 27 22:06:08.559: INFO: Created: latency-svc-vghs4
Sep 27 22:06:08.600: INFO: Got endpoints: latency-svc-c7d9d [763.800587ms]
Sep 27 22:06:08.622: INFO: Created: latency-svc-nshnb
Sep 27 22:06:08.637: INFO: Got endpoints: latency-svc-rn8wp [746.804343ms]
Sep 27 22:06:08.686: INFO: Got endpoints: latency-svc-5n9tf [746.888528ms]
Sep 27 22:06:08.737: INFO: Got endpoints: latency-svc-2v9dd [750.11059ms]
Sep 27 22:06:08.786: INFO: Got endpoints: latency-svc-bgx7r [749.864147ms]
Sep 27 22:06:08.840: INFO: Got endpoints: latency-svc-56hzc [748.216018ms]
Sep 27 22:06:08.890: INFO: Got endpoints: latency-svc-glvhf [747.530613ms]
Sep 27 22:06:08.939: INFO: Got endpoints: latency-svc-7q2rp [749.557598ms]
Sep 27 22:06:08.987: INFO: Got endpoints: latency-svc-clzxl [747.962391ms]
Sep 27 22:06:09.043: INFO: Got endpoints: latency-svc-krh64 [756.418565ms]
Sep 27 22:06:09.086: INFO: Got endpoints: latency-svc-vvbrx [746.544265ms]
Sep 27 22:06:09.138: INFO: Got endpoints: latency-svc-9f2jh [751.144709ms]
Sep 27 22:06:09.189: INFO: Got endpoints: latency-svc-4fg24 [752.457948ms]
Sep 27 22:06:09.240: INFO: Got endpoints: latency-svc-htlqx [750.280661ms]
Sep 27 22:06:09.286: INFO: Got endpoints: latency-svc-vghs4 [746.375882ms]
Sep 27 22:06:09.334: INFO: Got endpoints: latency-svc-nshnb [733.853938ms]
Sep 27 22:06:09.334: INFO: Latencies: [28.499993ms 50.222189ms 76.199758ms 97.936803ms 126.704748ms 156.352012ms 180.120319ms 221.697634ms 234.712097ms 267.670082ms 288.964087ms 312.650731ms 339.536854ms 355.714235ms 358.562214ms 358.610734ms 359.312537ms 362.508378ms 363.473955ms 369.614293ms 370.903962ms 371.517093ms 371.958069ms 373.280012ms 373.912876ms 374.524365ms 375.315958ms 376.394976ms 377.615101ms 377.919125ms 378.192392ms 378.363394ms 379.534566ms 379.83821ms 380.174794ms 380.725368ms 381.474603ms 382.183519ms 382.743451ms 384.2118ms 385.948349ms 387.206014ms 387.910212ms 388.600361ms 388.720087ms 389.03883ms 389.140786ms 392.694481ms 393.740393ms 394.233884ms 394.349715ms 394.682765ms 394.749877ms 396.96905ms 397.520471ms 398.032168ms 399.35747ms 402.887297ms 404.592323ms 408.447813ms 418.129072ms 453.646958ms 476.272597ms 501.74774ms 518.670579ms 543.623793ms 584.45951ms 600.027864ms 635.742551ms 648.757317ms 679.89037ms 694.12035ms 722.830137ms 733.853938ms 734.440351ms 736.936317ms 737.652108ms 738.772079ms 739.304152ms 739.455613ms 740.946526ms 741.315448ms 741.923265ms 742.250725ms 742.81823ms 743.334643ms 743.737116ms 744.149531ms 744.238787ms 744.623089ms 745.607205ms 745.696717ms 746.220593ms 746.365ms 746.375882ms 746.529231ms 746.534193ms 746.544265ms 746.58541ms 746.637571ms 746.647142ms 746.724566ms 746.725649ms 746.800268ms 746.804343ms 746.860375ms 746.888528ms 747.056065ms 747.107765ms 747.323663ms 747.455754ms 747.526751ms 747.530613ms 747.962391ms 748.216018ms 748.478159ms 748.479715ms 748.507572ms 748.533839ms 749.004629ms 749.042764ms 749.341379ms 749.351629ms 749.425334ms 749.54108ms 749.557598ms 749.610967ms 749.69071ms 749.714568ms 749.71701ms 749.763659ms 749.801182ms 749.809463ms 749.816838ms 749.827455ms 749.829124ms 749.857711ms 749.864147ms 749.882946ms 749.893024ms 749.90758ms 749.969738ms 749.974752ms 749.974993ms 749.997695ms 750.010156ms 750.021595ms 750.029327ms 750.066806ms 750.068736ms 750.080006ms 750.101959ms 750.11059ms 750.158324ms 750.16514ms 750.178409ms 750.181506ms 750.212066ms 750.280661ms 750.310114ms 750.320962ms 750.326834ms 750.342013ms 750.378229ms 750.475622ms 751.144709ms 751.474386ms 751.518496ms 751.867188ms 752.014071ms 752.194848ms 752.457948ms 752.615332ms 752.687945ms 752.712766ms 752.849491ms 752.880598ms 752.964022ms 753.089167ms 753.211443ms 753.278162ms 753.288442ms 753.311804ms 753.342497ms 753.357952ms 753.712792ms 753.8326ms 754.105709ms 755.775948ms 756.418565ms 756.721347ms 757.834662ms 758.481031ms 760.30352ms 761.109814ms 762.261236ms 762.721786ms 763.359724ms 763.800587ms 764.051732ms]
Sep 27 22:06:09.334: INFO: 50 %ile: 746.647142ms
Sep 27 22:06:09.334: INFO: 90 %ile: 753.278162ms
Sep 27 22:06:09.334: INFO: 99 %ile: 763.800587ms
Sep 27 22:06:09.334: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:06:09.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-1056" for this suite.
Sep 27 22:06:23.349: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:06:23.418: INFO: namespace svc-latency-1056 deletion completed in 14.08076181s

• [SLOW TEST:24.969 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:06:23.418: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9682
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-5e5862cc-0015-4d04-8a4c-1b5a23ca19fa
STEP: Creating a pod to test consume configMaps
Sep 27 22:06:23.581: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ae151031-d6c9-402b-ba8b-8a92deda1481" in namespace "projected-9682" to be "success or failure"
Sep 27 22:06:23.583: INFO: Pod "pod-projected-configmaps-ae151031-d6c9-402b-ba8b-8a92deda1481": Phase="Pending", Reason="", readiness=false. Elapsed: 1.806034ms
Sep 27 22:06:25.588: INFO: Pod "pod-projected-configmaps-ae151031-d6c9-402b-ba8b-8a92deda1481": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006534392s
STEP: Saw pod success
Sep 27 22:06:25.588: INFO: Pod "pod-projected-configmaps-ae151031-d6c9-402b-ba8b-8a92deda1481" satisfied condition "success or failure"
Sep 27 22:06:25.594: INFO: Trying to get logs from node macpro-3 pod pod-projected-configmaps-ae151031-d6c9-402b-ba8b-8a92deda1481 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 27 22:06:25.622: INFO: Waiting for pod pod-projected-configmaps-ae151031-d6c9-402b-ba8b-8a92deda1481 to disappear
Sep 27 22:06:25.624: INFO: Pod pod-projected-configmaps-ae151031-d6c9-402b-ba8b-8a92deda1481 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:06:25.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9682" for this suite.
Sep 27 22:06:31.638: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:06:31.711: INFO: namespace projected-9682 deletion completed in 6.084413945s

• [SLOW TEST:8.293 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:06:31.711: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-2882
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating secret secrets-2882/secret-test-51ba8627-5dfa-4594-a293-4c0f556777dd
STEP: Creating a pod to test consume secrets
Sep 27 22:06:31.871: INFO: Waiting up to 5m0s for pod "pod-configmaps-d7d8a419-b30c-4da2-8a0e-e85d7cb4b0cf" in namespace "secrets-2882" to be "success or failure"
Sep 27 22:06:31.880: INFO: Pod "pod-configmaps-d7d8a419-b30c-4da2-8a0e-e85d7cb4b0cf": Phase="Pending", Reason="", readiness=false. Elapsed: 9.307754ms
Sep 27 22:06:33.883: INFO: Pod "pod-configmaps-d7d8a419-b30c-4da2-8a0e-e85d7cb4b0cf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012240124s
STEP: Saw pod success
Sep 27 22:06:33.883: INFO: Pod "pod-configmaps-d7d8a419-b30c-4da2-8a0e-e85d7cb4b0cf" satisfied condition "success or failure"
Sep 27 22:06:33.885: INFO: Trying to get logs from node macpro-1 pod pod-configmaps-d7d8a419-b30c-4da2-8a0e-e85d7cb4b0cf container env-test: <nil>
STEP: delete the pod
Sep 27 22:06:33.912: INFO: Waiting for pod pod-configmaps-d7d8a419-b30c-4da2-8a0e-e85d7cb4b0cf to disappear
Sep 27 22:06:33.914: INFO: Pod pod-configmaps-d7d8a419-b30c-4da2-8a0e-e85d7cb4b0cf no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:06:33.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2882" for this suite.
Sep 27 22:06:39.929: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:06:40.000: INFO: namespace secrets-2882 deletion completed in 6.08313478s

• [SLOW TEST:8.289 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:06:40.000: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9817
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on tmpfs
Sep 27 22:06:40.158: INFO: Waiting up to 5m0s for pod "pod-641c428e-6870-40e2-a110-87d33c09ec42" in namespace "emptydir-9817" to be "success or failure"
Sep 27 22:06:40.160: INFO: Pod "pod-641c428e-6870-40e2-a110-87d33c09ec42": Phase="Pending", Reason="", readiness=false. Elapsed: 1.971835ms
Sep 27 22:06:42.162: INFO: Pod "pod-641c428e-6870-40e2-a110-87d33c09ec42": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004395188s
Sep 27 22:06:44.165: INFO: Pod "pod-641c428e-6870-40e2-a110-87d33c09ec42": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007173643s
STEP: Saw pod success
Sep 27 22:06:44.165: INFO: Pod "pod-641c428e-6870-40e2-a110-87d33c09ec42" satisfied condition "success or failure"
Sep 27 22:06:44.167: INFO: Trying to get logs from node macpro-2 pod pod-641c428e-6870-40e2-a110-87d33c09ec42 container test-container: <nil>
STEP: delete the pod
Sep 27 22:06:44.194: INFO: Waiting for pod pod-641c428e-6870-40e2-a110-87d33c09ec42 to disappear
Sep 27 22:06:44.196: INFO: Pod pod-641c428e-6870-40e2-a110-87d33c09ec42 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:06:44.196: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9817" for this suite.
Sep 27 22:06:50.210: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:06:50.280: INFO: namespace emptydir-9817 deletion completed in 6.080898381s

• [SLOW TEST:10.280 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:06:50.280: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-8111
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: getting the auto-created API token
Sep 27 22:06:50.953: INFO: created pod pod-service-account-defaultsa
Sep 27 22:06:50.953: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Sep 27 22:06:50.959: INFO: created pod pod-service-account-mountsa
Sep 27 22:06:50.959: INFO: pod pod-service-account-mountsa service account token volume mount: true
Sep 27 22:06:50.982: INFO: created pod pod-service-account-nomountsa
Sep 27 22:06:50.983: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Sep 27 22:06:51.001: INFO: created pod pod-service-account-defaultsa-mountspec
Sep 27 22:06:51.001: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Sep 27 22:06:51.028: INFO: created pod pod-service-account-mountsa-mountspec
Sep 27 22:06:51.028: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Sep 27 22:06:51.045: INFO: created pod pod-service-account-nomountsa-mountspec
Sep 27 22:06:51.045: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Sep 27 22:06:51.063: INFO: created pod pod-service-account-defaultsa-nomountspec
Sep 27 22:06:51.063: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Sep 27 22:06:51.086: INFO: created pod pod-service-account-mountsa-nomountspec
Sep 27 22:06:51.086: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Sep 27 22:06:51.107: INFO: created pod pod-service-account-nomountsa-nomountspec
Sep 27 22:06:51.107: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:06:51.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-8111" for this suite.
Sep 27 22:06:57.167: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:06:57.236: INFO: namespace svcaccounts-8111 deletion completed in 6.115898259s

• [SLOW TEST:6.956 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:06:57.236: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7856
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-4004025d-ec46-4641-b403-2374727f3328
STEP: Creating a pod to test consume configMaps
Sep 27 22:06:57.405: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-26ae737b-e58d-44ba-afb3-c3d9a97378d4" in namespace "projected-7856" to be "success or failure"
Sep 27 22:06:57.406: INFO: Pod "pod-projected-configmaps-26ae737b-e58d-44ba-afb3-c3d9a97378d4": Phase="Pending", Reason="", readiness=false. Elapsed: 1.836807ms
Sep 27 22:06:59.409: INFO: Pod "pod-projected-configmaps-26ae737b-e58d-44ba-afb3-c3d9a97378d4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004815285s
STEP: Saw pod success
Sep 27 22:06:59.409: INFO: Pod "pod-projected-configmaps-26ae737b-e58d-44ba-afb3-c3d9a97378d4" satisfied condition "success or failure"
Sep 27 22:06:59.411: INFO: Trying to get logs from node macpro-3 pod pod-projected-configmaps-26ae737b-e58d-44ba-afb3-c3d9a97378d4 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 27 22:06:59.437: INFO: Waiting for pod pod-projected-configmaps-26ae737b-e58d-44ba-afb3-c3d9a97378d4 to disappear
Sep 27 22:06:59.439: INFO: Pod pod-projected-configmaps-26ae737b-e58d-44ba-afb3-c3d9a97378d4 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:06:59.439: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7856" for this suite.
Sep 27 22:07:05.452: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:07:05.523: INFO: namespace projected-7856 deletion completed in 6.081557151s

• [SLOW TEST:8.287 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:07:05.523: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-9650
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:07:28.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-9650" for this suite.
Sep 27 22:07:34.876: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:07:34.947: INFO: namespace container-runtime-9650 deletion completed in 6.088183559s

• [SLOW TEST:29.424 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    when starting a container that exits
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:07:34.948: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5642
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap that has name configmap-test-emptyKey-85c14a3e-9ce4-4359-8513-3e0edadd4167
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:07:35.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5642" for this suite.
Sep 27 22:07:41.108: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:07:41.180: INFO: namespace configmap-5642 deletion completed in 6.083181708s

• [SLOW TEST:6.232 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:07:41.180: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6607
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep 27 22:07:41.344: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5a0ea5e6-997d-48fa-8bcb-51ac577d6eca" in namespace "downward-api-6607" to be "success or failure"
Sep 27 22:07:41.346: INFO: Pod "downwardapi-volume-5a0ea5e6-997d-48fa-8bcb-51ac577d6eca": Phase="Pending", Reason="", readiness=false. Elapsed: 1.863791ms
Sep 27 22:07:43.349: INFO: Pod "downwardapi-volume-5a0ea5e6-997d-48fa-8bcb-51ac577d6eca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004589508s
STEP: Saw pod success
Sep 27 22:07:43.349: INFO: Pod "downwardapi-volume-5a0ea5e6-997d-48fa-8bcb-51ac577d6eca" satisfied condition "success or failure"
Sep 27 22:07:43.351: INFO: Trying to get logs from node macpro-1 pod downwardapi-volume-5a0ea5e6-997d-48fa-8bcb-51ac577d6eca container client-container: <nil>
STEP: delete the pod
Sep 27 22:07:43.376: INFO: Waiting for pod downwardapi-volume-5a0ea5e6-997d-48fa-8bcb-51ac577d6eca to disappear
Sep 27 22:07:43.378: INFO: Pod downwardapi-volume-5a0ea5e6-997d-48fa-8bcb-51ac577d6eca no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:07:43.378: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6607" for this suite.
Sep 27 22:07:49.401: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:07:49.472: INFO: namespace downward-api-6607 deletion completed in 6.091269939s

• [SLOW TEST:8.292 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:07:49.472: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-1956
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override all
Sep 27 22:07:49.628: INFO: Waiting up to 5m0s for pod "client-containers-6aeb87a9-6a83-4f08-b435-81e236b4abde" in namespace "containers-1956" to be "success or failure"
Sep 27 22:07:49.629: INFO: Pod "client-containers-6aeb87a9-6a83-4f08-b435-81e236b4abde": Phase="Pending", Reason="", readiness=false. Elapsed: 1.76957ms
Sep 27 22:07:51.632: INFO: Pod "client-containers-6aeb87a9-6a83-4f08-b435-81e236b4abde": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004466846s
STEP: Saw pod success
Sep 27 22:07:51.632: INFO: Pod "client-containers-6aeb87a9-6a83-4f08-b435-81e236b4abde" satisfied condition "success or failure"
Sep 27 22:07:51.634: INFO: Trying to get logs from node macpro-2 pod client-containers-6aeb87a9-6a83-4f08-b435-81e236b4abde container test-container: <nil>
STEP: delete the pod
Sep 27 22:07:51.658: INFO: Waiting for pod client-containers-6aeb87a9-6a83-4f08-b435-81e236b4abde to disappear
Sep 27 22:07:51.660: INFO: Pod client-containers-6aeb87a9-6a83-4f08-b435-81e236b4abde no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:07:51.660: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-1956" for this suite.
Sep 27 22:07:57.673: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:07:57.745: INFO: namespace containers-1956 deletion completed in 6.082252649s

• [SLOW TEST:8.273 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:07:57.745: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-5196
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-5196
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep 27 22:07:57.903: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Sep 27 22:08:20.019: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.153.30:8080/dial?request=hostName&protocol=http&host=192.168.153.24&port=8080&tries=1'] Namespace:pod-network-test-5196 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 27 22:08:20.019: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
Sep 27 22:08:20.110: INFO: Waiting for endpoints: map[]
Sep 27 22:08:20.112: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.153.30:8080/dial?request=hostName&protocol=http&host=192.168.150.153&port=8080&tries=1'] Namespace:pod-network-test-5196 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 27 22:08:20.112: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
Sep 27 22:08:20.199: INFO: Waiting for endpoints: map[]
Sep 27 22:08:20.201: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.153.30:8080/dial?request=hostName&protocol=http&host=192.168.151.228&port=8080&tries=1'] Namespace:pod-network-test-5196 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 27 22:08:20.201: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
Sep 27 22:08:20.290: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:08:20.290: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5196" for this suite.
Sep 27 22:08:42.305: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:08:42.376: INFO: namespace pod-network-test-5196 deletion completed in 22.082641632s

• [SLOW TEST:44.631 seconds]
[sig-network] Networking
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:08:42.376: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-5482
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:08:44.589: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-5482" for this suite.
Sep 27 22:08:50.608: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:08:50.682: INFO: namespace emptydir-wrapper-5482 deletion completed in 6.09100679s

• [SLOW TEST:8.306 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:08:50.682: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-3274
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3274.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-3274.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3274.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-3274.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-3274.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-3274.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-3274.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-3274.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-3274.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-3274.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-3274.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-3274.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3274.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 78.115.99.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.99.115.78_udp@PTR;check="$$(dig +tcp +noall +answer +search 78.115.99.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.99.115.78_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3274.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-3274.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3274.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-3274.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-3274.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-3274.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-3274.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-3274.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-3274.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-3274.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-3274.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-3274.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3274.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 78.115.99.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.99.115.78_udp@PTR;check="$$(dig +tcp +noall +answer +search 78.115.99.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.99.115.78_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 27 22:08:54.903: INFO: Unable to read wheezy_udp@dns-test-service.dns-3274.svc.cluster.local from pod dns-3274/dns-test-e1abee28-b377-45ee-ae27-def122234c9c: the server could not find the requested resource (get pods dns-test-e1abee28-b377-45ee-ae27-def122234c9c)
Sep 27 22:08:54.905: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3274.svc.cluster.local from pod dns-3274/dns-test-e1abee28-b377-45ee-ae27-def122234c9c: the server could not find the requested resource (get pods dns-test-e1abee28-b377-45ee-ae27-def122234c9c)
Sep 27 22:08:54.908: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3274.svc.cluster.local from pod dns-3274/dns-test-e1abee28-b377-45ee-ae27-def122234c9c: the server could not find the requested resource (get pods dns-test-e1abee28-b377-45ee-ae27-def122234c9c)
Sep 27 22:08:54.926: INFO: Unable to read jessie_udp@dns-test-service.dns-3274.svc.cluster.local from pod dns-3274/dns-test-e1abee28-b377-45ee-ae27-def122234c9c: the server could not find the requested resource (get pods dns-test-e1abee28-b377-45ee-ae27-def122234c9c)
Sep 27 22:08:54.929: INFO: Unable to read jessie_tcp@dns-test-service.dns-3274.svc.cluster.local from pod dns-3274/dns-test-e1abee28-b377-45ee-ae27-def122234c9c: the server could not find the requested resource (get pods dns-test-e1abee28-b377-45ee-ae27-def122234c9c)
Sep 27 22:08:54.948: INFO: Lookups using dns-3274/dns-test-e1abee28-b377-45ee-ae27-def122234c9c failed for: [wheezy_udp@dns-test-service.dns-3274.svc.cluster.local wheezy_tcp@dns-test-service.dns-3274.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-3274.svc.cluster.local jessie_udp@dns-test-service.dns-3274.svc.cluster.local jessie_tcp@dns-test-service.dns-3274.svc.cluster.local]

Sep 27 22:08:59.951: INFO: Unable to read wheezy_udp@dns-test-service.dns-3274.svc.cluster.local from pod dns-3274/dns-test-e1abee28-b377-45ee-ae27-def122234c9c: the server could not find the requested resource (get pods dns-test-e1abee28-b377-45ee-ae27-def122234c9c)
Sep 27 22:08:59.953: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3274.svc.cluster.local from pod dns-3274/dns-test-e1abee28-b377-45ee-ae27-def122234c9c: the server could not find the requested resource (get pods dns-test-e1abee28-b377-45ee-ae27-def122234c9c)
Sep 27 22:08:59.975: INFO: Unable to read jessie_udp@dns-test-service.dns-3274.svc.cluster.local from pod dns-3274/dns-test-e1abee28-b377-45ee-ae27-def122234c9c: the server could not find the requested resource (get pods dns-test-e1abee28-b377-45ee-ae27-def122234c9c)
Sep 27 22:08:59.977: INFO: Unable to read jessie_tcp@dns-test-service.dns-3274.svc.cluster.local from pod dns-3274/dns-test-e1abee28-b377-45ee-ae27-def122234c9c: the server could not find the requested resource (get pods dns-test-e1abee28-b377-45ee-ae27-def122234c9c)
Sep 27 22:08:59.996: INFO: Lookups using dns-3274/dns-test-e1abee28-b377-45ee-ae27-def122234c9c failed for: [wheezy_udp@dns-test-service.dns-3274.svc.cluster.local wheezy_tcp@dns-test-service.dns-3274.svc.cluster.local jessie_udp@dns-test-service.dns-3274.svc.cluster.local jessie_tcp@dns-test-service.dns-3274.svc.cluster.local]

Sep 27 22:09:04.951: INFO: Unable to read wheezy_udp@dns-test-service.dns-3274.svc.cluster.local from pod dns-3274/dns-test-e1abee28-b377-45ee-ae27-def122234c9c: the server could not find the requested resource (get pods dns-test-e1abee28-b377-45ee-ae27-def122234c9c)
Sep 27 22:09:04.953: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3274.svc.cluster.local from pod dns-3274/dns-test-e1abee28-b377-45ee-ae27-def122234c9c: the server could not find the requested resource (get pods dns-test-e1abee28-b377-45ee-ae27-def122234c9c)
Sep 27 22:09:04.974: INFO: Unable to read jessie_udp@dns-test-service.dns-3274.svc.cluster.local from pod dns-3274/dns-test-e1abee28-b377-45ee-ae27-def122234c9c: the server could not find the requested resource (get pods dns-test-e1abee28-b377-45ee-ae27-def122234c9c)
Sep 27 22:09:04.976: INFO: Unable to read jessie_tcp@dns-test-service.dns-3274.svc.cluster.local from pod dns-3274/dns-test-e1abee28-b377-45ee-ae27-def122234c9c: the server could not find the requested resource (get pods dns-test-e1abee28-b377-45ee-ae27-def122234c9c)
Sep 27 22:09:04.995: INFO: Lookups using dns-3274/dns-test-e1abee28-b377-45ee-ae27-def122234c9c failed for: [wheezy_udp@dns-test-service.dns-3274.svc.cluster.local wheezy_tcp@dns-test-service.dns-3274.svc.cluster.local jessie_udp@dns-test-service.dns-3274.svc.cluster.local jessie_tcp@dns-test-service.dns-3274.svc.cluster.local]

Sep 27 22:09:09.951: INFO: Unable to read wheezy_udp@dns-test-service.dns-3274.svc.cluster.local from pod dns-3274/dns-test-e1abee28-b377-45ee-ae27-def122234c9c: the server could not find the requested resource (get pods dns-test-e1abee28-b377-45ee-ae27-def122234c9c)
Sep 27 22:09:09.953: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3274.svc.cluster.local from pod dns-3274/dns-test-e1abee28-b377-45ee-ae27-def122234c9c: the server could not find the requested resource (get pods dns-test-e1abee28-b377-45ee-ae27-def122234c9c)
Sep 27 22:09:09.973: INFO: Unable to read jessie_udp@dns-test-service.dns-3274.svc.cluster.local from pod dns-3274/dns-test-e1abee28-b377-45ee-ae27-def122234c9c: the server could not find the requested resource (get pods dns-test-e1abee28-b377-45ee-ae27-def122234c9c)
Sep 27 22:09:09.975: INFO: Unable to read jessie_tcp@dns-test-service.dns-3274.svc.cluster.local from pod dns-3274/dns-test-e1abee28-b377-45ee-ae27-def122234c9c: the server could not find the requested resource (get pods dns-test-e1abee28-b377-45ee-ae27-def122234c9c)
Sep 27 22:09:09.994: INFO: Lookups using dns-3274/dns-test-e1abee28-b377-45ee-ae27-def122234c9c failed for: [wheezy_udp@dns-test-service.dns-3274.svc.cluster.local wheezy_tcp@dns-test-service.dns-3274.svc.cluster.local jessie_udp@dns-test-service.dns-3274.svc.cluster.local jessie_tcp@dns-test-service.dns-3274.svc.cluster.local]

Sep 27 22:09:14.951: INFO: Unable to read wheezy_udp@dns-test-service.dns-3274.svc.cluster.local from pod dns-3274/dns-test-e1abee28-b377-45ee-ae27-def122234c9c: the server could not find the requested resource (get pods dns-test-e1abee28-b377-45ee-ae27-def122234c9c)
Sep 27 22:09:14.954: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3274.svc.cluster.local from pod dns-3274/dns-test-e1abee28-b377-45ee-ae27-def122234c9c: the server could not find the requested resource (get pods dns-test-e1abee28-b377-45ee-ae27-def122234c9c)
Sep 27 22:09:14.975: INFO: Unable to read jessie_udp@dns-test-service.dns-3274.svc.cluster.local from pod dns-3274/dns-test-e1abee28-b377-45ee-ae27-def122234c9c: the server could not find the requested resource (get pods dns-test-e1abee28-b377-45ee-ae27-def122234c9c)
Sep 27 22:09:14.977: INFO: Unable to read jessie_tcp@dns-test-service.dns-3274.svc.cluster.local from pod dns-3274/dns-test-e1abee28-b377-45ee-ae27-def122234c9c: the server could not find the requested resource (get pods dns-test-e1abee28-b377-45ee-ae27-def122234c9c)
Sep 27 22:09:14.997: INFO: Lookups using dns-3274/dns-test-e1abee28-b377-45ee-ae27-def122234c9c failed for: [wheezy_udp@dns-test-service.dns-3274.svc.cluster.local wheezy_tcp@dns-test-service.dns-3274.svc.cluster.local jessie_udp@dns-test-service.dns-3274.svc.cluster.local jessie_tcp@dns-test-service.dns-3274.svc.cluster.local]

Sep 27 22:09:19.951: INFO: Unable to read wheezy_udp@dns-test-service.dns-3274.svc.cluster.local from pod dns-3274/dns-test-e1abee28-b377-45ee-ae27-def122234c9c: the server could not find the requested resource (get pods dns-test-e1abee28-b377-45ee-ae27-def122234c9c)
Sep 27 22:09:19.953: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3274.svc.cluster.local from pod dns-3274/dns-test-e1abee28-b377-45ee-ae27-def122234c9c: the server could not find the requested resource (get pods dns-test-e1abee28-b377-45ee-ae27-def122234c9c)
Sep 27 22:09:19.975: INFO: Unable to read jessie_udp@dns-test-service.dns-3274.svc.cluster.local from pod dns-3274/dns-test-e1abee28-b377-45ee-ae27-def122234c9c: the server could not find the requested resource (get pods dns-test-e1abee28-b377-45ee-ae27-def122234c9c)
Sep 27 22:09:19.977: INFO: Unable to read jessie_tcp@dns-test-service.dns-3274.svc.cluster.local from pod dns-3274/dns-test-e1abee28-b377-45ee-ae27-def122234c9c: the server could not find the requested resource (get pods dns-test-e1abee28-b377-45ee-ae27-def122234c9c)
Sep 27 22:09:19.997: INFO: Lookups using dns-3274/dns-test-e1abee28-b377-45ee-ae27-def122234c9c failed for: [wheezy_udp@dns-test-service.dns-3274.svc.cluster.local wheezy_tcp@dns-test-service.dns-3274.svc.cluster.local jessie_udp@dns-test-service.dns-3274.svc.cluster.local jessie_tcp@dns-test-service.dns-3274.svc.cluster.local]

Sep 27 22:09:24.996: INFO: DNS probes using dns-3274/dns-test-e1abee28-b377-45ee-ae27-def122234c9c succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:09:25.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3274" for this suite.
Sep 27 22:09:31.117: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:09:31.187: INFO: namespace dns-3274 deletion completed in 6.082005445s

• [SLOW TEST:40.504 seconds]
[sig-network] DNS
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:09:31.187: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-6424
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 27 22:09:31.338: INFO: Creating deployment "test-recreate-deployment"
Sep 27 22:09:31.348: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Sep 27 22:09:31.352: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
Sep 27 22:09:33.357: INFO: Waiting deployment "test-recreate-deployment" to complete
Sep 27 22:09:33.359: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705218971, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705218971, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705218971, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705218971, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-6df85df6b9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 27 22:09:35.362: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Sep 27 22:09:35.373: INFO: Updating deployment test-recreate-deployment
Sep 27 22:09:35.373: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Sep 27 22:09:35.474: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-6424,SelfLink:/apis/apps/v1/namespaces/deployment-6424/deployments/test-recreate-deployment,UID:49ea815a-d8ea-41c4-8d1b-dd08ed60bb18,ResourceVersion:7630980,Generation:2,CreationTimestamp:2019-09-27 22:09:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-09-27 22:09:35 +0000 UTC 2019-09-27 22:09:35 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-09-27 22:09:35 +0000 UTC 2019-09-27 22:09:31 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-5c8c9cc69d" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Sep 27 22:09:35.483: INFO: New ReplicaSet "test-recreate-deployment-5c8c9cc69d" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5c8c9cc69d,GenerateName:,Namespace:deployment-6424,SelfLink:/apis/apps/v1/namespaces/deployment-6424/replicasets/test-recreate-deployment-5c8c9cc69d,UID:d946b88f-8946-4a35-9735-b249b6e0d9fa,ResourceVersion:7630978,Generation:1,CreationTimestamp:2019-09-27 22:09:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 49ea815a-d8ea-41c4-8d1b-dd08ed60bb18 0xc00372ee37 0xc00372ee38}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep 27 22:09:35.483: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Sep 27 22:09:35.483: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-6df85df6b9,GenerateName:,Namespace:deployment-6424,SelfLink:/apis/apps/v1/namespaces/deployment-6424/replicasets/test-recreate-deployment-6df85df6b9,UID:4fb013fc-aa7b-4382-8e18-e614f4c875b3,ResourceVersion:7630968,Generation:2,CreationTimestamp:2019-09-27 22:09:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 49ea815a-d8ea-41c4-8d1b-dd08ed60bb18 0xc00372ef07 0xc00372ef08}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep 27 22:09:35.485: INFO: Pod "test-recreate-deployment-5c8c9cc69d-h742d" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5c8c9cc69d-h742d,GenerateName:test-recreate-deployment-5c8c9cc69d-,Namespace:deployment-6424,SelfLink:/api/v1/namespaces/deployment-6424/pods/test-recreate-deployment-5c8c9cc69d-h742d,UID:b2e818d3-6ab2-4782-883a-a3b5dda438aa,ResourceVersion:7630981,Generation:0,CreationTimestamp:2019-09-27 22:09:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-5c8c9cc69d d946b88f-8946-4a35-9735-b249b6e0d9fa 0xc00372f7e7 0xc00372f7e8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4qgrc {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4qgrc,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4qgrc true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:macpro-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00372f860} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00372f880}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:09:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:09:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:09:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:09:35 +0000 UTC  }],Message:,Reason:,HostIP:10.10.10.5,PodIP:,StartTime:2019-09-27 22:09:35 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:09:35.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6424" for this suite.
Sep 27 22:09:41.500: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:09:41.569: INFO: namespace deployment-6424 deletion completed in 6.080686274s

• [SLOW TEST:10.382 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:09:41.570: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5448
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir volume type on node default medium
Sep 27 22:09:41.726: INFO: Waiting up to 5m0s for pod "pod-7f8054b4-be3a-41ff-8e5e-9784873a652c" in namespace "emptydir-5448" to be "success or failure"
Sep 27 22:09:41.728: INFO: Pod "pod-7f8054b4-be3a-41ff-8e5e-9784873a652c": Phase="Pending", Reason="", readiness=false. Elapsed: 1.831556ms
Sep 27 22:09:43.731: INFO: Pod "pod-7f8054b4-be3a-41ff-8e5e-9784873a652c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004574094s
Sep 27 22:09:45.734: INFO: Pod "pod-7f8054b4-be3a-41ff-8e5e-9784873a652c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007309715s
STEP: Saw pod success
Sep 27 22:09:45.734: INFO: Pod "pod-7f8054b4-be3a-41ff-8e5e-9784873a652c" satisfied condition "success or failure"
Sep 27 22:09:45.736: INFO: Trying to get logs from node macpro-3 pod pod-7f8054b4-be3a-41ff-8e5e-9784873a652c container test-container: <nil>
STEP: delete the pod
Sep 27 22:09:45.759: INFO: Waiting for pod pod-7f8054b4-be3a-41ff-8e5e-9784873a652c to disappear
Sep 27 22:09:45.761: INFO: Pod pod-7f8054b4-be3a-41ff-8e5e-9784873a652c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:09:45.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5448" for this suite.
Sep 27 22:09:51.774: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:09:51.845: INFO: namespace emptydir-5448 deletion completed in 6.081250411s

• [SLOW TEST:10.275 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:09:51.845: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-3977
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-configmap-5k7h
STEP: Creating a pod to test atomic-volume-subpath
Sep 27 22:09:52.015: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-5k7h" in namespace "subpath-3977" to be "success or failure"
Sep 27 22:09:52.017: INFO: Pod "pod-subpath-test-configmap-5k7h": Phase="Pending", Reason="", readiness=false. Elapsed: 1.884727ms
Sep 27 22:09:54.020: INFO: Pod "pod-subpath-test-configmap-5k7h": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004676314s
Sep 27 22:09:56.023: INFO: Pod "pod-subpath-test-configmap-5k7h": Phase="Running", Reason="", readiness=true. Elapsed: 4.007409013s
Sep 27 22:09:58.025: INFO: Pod "pod-subpath-test-configmap-5k7h": Phase="Running", Reason="", readiness=true. Elapsed: 6.01020402s
Sep 27 22:10:00.028: INFO: Pod "pod-subpath-test-configmap-5k7h": Phase="Running", Reason="", readiness=true. Elapsed: 8.012847562s
Sep 27 22:10:02.031: INFO: Pod "pod-subpath-test-configmap-5k7h": Phase="Running", Reason="", readiness=true. Elapsed: 10.016039648s
Sep 27 22:10:04.034: INFO: Pod "pod-subpath-test-configmap-5k7h": Phase="Running", Reason="", readiness=true. Elapsed: 12.018709599s
Sep 27 22:10:06.037: INFO: Pod "pod-subpath-test-configmap-5k7h": Phase="Running", Reason="", readiness=true. Elapsed: 14.021727409s
Sep 27 22:10:08.040: INFO: Pod "pod-subpath-test-configmap-5k7h": Phase="Running", Reason="", readiness=true. Elapsed: 16.024504771s
Sep 27 22:10:10.042: INFO: Pod "pod-subpath-test-configmap-5k7h": Phase="Running", Reason="", readiness=true. Elapsed: 18.027293928s
Sep 27 22:10:12.046: INFO: Pod "pod-subpath-test-configmap-5k7h": Phase="Running", Reason="", readiness=true. Elapsed: 20.03053805s
Sep 27 22:10:14.048: INFO: Pod "pod-subpath-test-configmap-5k7h": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.032918358s
STEP: Saw pod success
Sep 27 22:10:14.048: INFO: Pod "pod-subpath-test-configmap-5k7h" satisfied condition "success or failure"
Sep 27 22:10:14.050: INFO: Trying to get logs from node macpro-1 pod pod-subpath-test-configmap-5k7h container test-container-subpath-configmap-5k7h: <nil>
STEP: delete the pod
Sep 27 22:10:14.076: INFO: Waiting for pod pod-subpath-test-configmap-5k7h to disappear
Sep 27 22:10:14.078: INFO: Pod pod-subpath-test-configmap-5k7h no longer exists
STEP: Deleting pod pod-subpath-test-configmap-5k7h
Sep 27 22:10:14.078: INFO: Deleting pod "pod-subpath-test-configmap-5k7h" in namespace "subpath-3977"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:10:14.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-3977" for this suite.
Sep 27 22:10:20.095: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:10:20.167: INFO: namespace subpath-3977 deletion completed in 6.084895052s

• [SLOW TEST:28.323 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:10:20.168: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-6019
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-6019
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-6019
STEP: Creating statefulset with conflicting port in namespace statefulset-6019
STEP: Waiting until pod test-pod will start running in namespace statefulset-6019
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-6019
Sep 27 22:10:24.351: INFO: Observed stateful pod in namespace: statefulset-6019, name: ss-0, uid: aa0e9a6d-2f89-4614-9403-66ffe7dbdf5c, status phase: Pending. Waiting for statefulset controller to delete.
Sep 27 22:10:24.742: INFO: Observed stateful pod in namespace: statefulset-6019, name: ss-0, uid: aa0e9a6d-2f89-4614-9403-66ffe7dbdf5c, status phase: Failed. Waiting for statefulset controller to delete.
Sep 27 22:10:24.756: INFO: Observed stateful pod in namespace: statefulset-6019, name: ss-0, uid: aa0e9a6d-2f89-4614-9403-66ffe7dbdf5c, status phase: Failed. Waiting for statefulset controller to delete.
Sep 27 22:10:24.765: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-6019
STEP: Removing pod with conflicting port in namespace statefulset-6019
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-6019 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Sep 27 22:10:28.814: INFO: Deleting all statefulset in ns statefulset-6019
Sep 27 22:10:28.816: INFO: Scaling statefulset ss to 0
Sep 27 22:10:38.836: INFO: Waiting for statefulset status.replicas updated to 0
Sep 27 22:10:38.838: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:10:38.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6019" for this suite.
Sep 27 22:10:44.865: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:10:44.938: INFO: namespace statefulset-6019 deletion completed in 6.083826666s

• [SLOW TEST:24.770 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:10:44.938: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-8509
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Sep 27 22:10:45.125: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-8509,SelfLink:/api/v1/namespaces/watch-8509/configmaps/e2e-watch-test-resource-version,UID:16892b58-5025-4703-b57a-18a5d4aa7544,ResourceVersion:7631364,Generation:0,CreationTimestamp:2019-09-27 22:10:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep 27 22:10:45.125: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-8509,SelfLink:/api/v1/namespaces/watch-8509/configmaps/e2e-watch-test-resource-version,UID:16892b58-5025-4703-b57a-18a5d4aa7544,ResourceVersion:7631365,Generation:0,CreationTimestamp:2019-09-27 22:10:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:10:45.125: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8509" for this suite.
Sep 27 22:10:51.145: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:10:51.225: INFO: namespace watch-8509 deletion completed in 6.097501778s

• [SLOW TEST:6.287 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:10:51.226: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4660
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-3783e040-bb67-47e7-b051-6ea94e817630
STEP: Creating a pod to test consume configMaps
Sep 27 22:10:51.395: INFO: Waiting up to 5m0s for pod "pod-configmaps-731e29f7-81c9-4536-a6ec-ba87d8024272" in namespace "configmap-4660" to be "success or failure"
Sep 27 22:10:51.397: INFO: Pod "pod-configmaps-731e29f7-81c9-4536-a6ec-ba87d8024272": Phase="Pending", Reason="", readiness=false. Elapsed: 1.932834ms
Sep 27 22:10:53.400: INFO: Pod "pod-configmaps-731e29f7-81c9-4536-a6ec-ba87d8024272": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004459232s
STEP: Saw pod success
Sep 27 22:10:53.400: INFO: Pod "pod-configmaps-731e29f7-81c9-4536-a6ec-ba87d8024272" satisfied condition "success or failure"
Sep 27 22:10:53.402: INFO: Trying to get logs from node macpro-2 pod pod-configmaps-731e29f7-81c9-4536-a6ec-ba87d8024272 container configmap-volume-test: <nil>
STEP: delete the pod
Sep 27 22:10:53.426: INFO: Waiting for pod pod-configmaps-731e29f7-81c9-4536-a6ec-ba87d8024272 to disappear
Sep 27 22:10:53.427: INFO: Pod pod-configmaps-731e29f7-81c9-4536-a6ec-ba87d8024272 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:10:53.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4660" for this suite.
Sep 27 22:10:59.441: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:10:59.512: INFO: namespace configmap-4660 deletion completed in 6.082078405s

• [SLOW TEST:8.286 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:10:59.512: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-6909
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 27 22:10:59.676: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Sep 27 22:10:59.694: INFO: Number of nodes with available pods: 0
Sep 27 22:10:59.694: INFO: Node macpro-1 is running more than one daemon pod
Sep 27 22:11:00.700: INFO: Number of nodes with available pods: 0
Sep 27 22:11:00.700: INFO: Node macpro-1 is running more than one daemon pod
Sep 27 22:11:01.703: INFO: Number of nodes with available pods: 3
Sep 27 22:11:01.703: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Sep 27 22:11:01.730: INFO: Wrong image for pod: daemon-set-rzmzs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 22:11:01.730: INFO: Wrong image for pod: daemon-set-tldkj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 22:11:01.730: INFO: Wrong image for pod: daemon-set-v8mtf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 22:11:02.742: INFO: Wrong image for pod: daemon-set-rzmzs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 22:11:02.742: INFO: Wrong image for pod: daemon-set-tldkj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 22:11:02.742: INFO: Wrong image for pod: daemon-set-v8mtf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 22:11:03.743: INFO: Wrong image for pod: daemon-set-rzmzs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 22:11:03.743: INFO: Wrong image for pod: daemon-set-tldkj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 22:11:03.743: INFO: Wrong image for pod: daemon-set-v8mtf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 22:11:04.742: INFO: Wrong image for pod: daemon-set-rzmzs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 22:11:04.742: INFO: Wrong image for pod: daemon-set-tldkj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 22:11:04.742: INFO: Pod daemon-set-tldkj is not available
Sep 27 22:11:04.742: INFO: Wrong image for pod: daemon-set-v8mtf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 22:11:05.742: INFO: Wrong image for pod: daemon-set-rzmzs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 22:11:05.742: INFO: Wrong image for pod: daemon-set-tldkj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 22:11:05.742: INFO: Pod daemon-set-tldkj is not available
Sep 27 22:11:05.742: INFO: Wrong image for pod: daemon-set-v8mtf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 22:11:06.742: INFO: Wrong image for pod: daemon-set-rzmzs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 22:11:06.742: INFO: Wrong image for pod: daemon-set-tldkj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 22:11:06.742: INFO: Pod daemon-set-tldkj is not available
Sep 27 22:11:06.742: INFO: Wrong image for pod: daemon-set-v8mtf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 22:11:07.742: INFO: Wrong image for pod: daemon-set-rzmzs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 22:11:07.742: INFO: Wrong image for pod: daemon-set-tldkj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 22:11:07.742: INFO: Pod daemon-set-tldkj is not available
Sep 27 22:11:07.742: INFO: Wrong image for pod: daemon-set-v8mtf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 22:11:08.742: INFO: Wrong image for pod: daemon-set-rzmzs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 22:11:08.742: INFO: Wrong image for pod: daemon-set-tldkj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 22:11:08.742: INFO: Pod daemon-set-tldkj is not available
Sep 27 22:11:08.742: INFO: Wrong image for pod: daemon-set-v8mtf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 22:11:09.742: INFO: Wrong image for pod: daemon-set-rzmzs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 22:11:09.742: INFO: Wrong image for pod: daemon-set-tldkj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 22:11:09.742: INFO: Pod daemon-set-tldkj is not available
Sep 27 22:11:09.742: INFO: Wrong image for pod: daemon-set-v8mtf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 22:11:10.742: INFO: Wrong image for pod: daemon-set-rzmzs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 22:11:10.742: INFO: Wrong image for pod: daemon-set-tldkj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 22:11:10.742: INFO: Pod daemon-set-tldkj is not available
Sep 27 22:11:10.742: INFO: Wrong image for pod: daemon-set-v8mtf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 22:11:11.742: INFO: Pod daemon-set-dpfq7 is not available
Sep 27 22:11:11.742: INFO: Wrong image for pod: daemon-set-rzmzs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 22:11:11.742: INFO: Wrong image for pod: daemon-set-v8mtf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 22:11:12.742: INFO: Pod daemon-set-dpfq7 is not available
Sep 27 22:11:12.742: INFO: Wrong image for pod: daemon-set-rzmzs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 22:11:12.742: INFO: Wrong image for pod: daemon-set-v8mtf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 22:11:13.742: INFO: Wrong image for pod: daemon-set-rzmzs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 22:11:13.742: INFO: Wrong image for pod: daemon-set-v8mtf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 22:11:14.742: INFO: Wrong image for pod: daemon-set-rzmzs. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 22:11:14.742: INFO: Pod daemon-set-rzmzs is not available
Sep 27 22:11:14.742: INFO: Wrong image for pod: daemon-set-v8mtf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 22:11:15.742: INFO: Pod daemon-set-fgstv is not available
Sep 27 22:11:15.742: INFO: Wrong image for pod: daemon-set-v8mtf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 22:11:16.742: INFO: Pod daemon-set-fgstv is not available
Sep 27 22:11:16.742: INFO: Wrong image for pod: daemon-set-v8mtf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 22:11:17.742: INFO: Wrong image for pod: daemon-set-v8mtf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 22:11:18.742: INFO: Wrong image for pod: daemon-set-v8mtf. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 27 22:11:18.742: INFO: Pod daemon-set-v8mtf is not available
Sep 27 22:11:19.742: INFO: Pod daemon-set-r69kd is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Sep 27 22:11:19.750: INFO: Number of nodes with available pods: 2
Sep 27 22:11:19.750: INFO: Node macpro-3 is running more than one daemon pod
Sep 27 22:11:20.756: INFO: Number of nodes with available pods: 2
Sep 27 22:11:20.756: INFO: Node macpro-3 is running more than one daemon pod
Sep 27 22:11:21.756: INFO: Number of nodes with available pods: 3
Sep 27 22:11:21.756: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6909, will wait for the garbage collector to delete the pods
Sep 27 22:11:21.828: INFO: Deleting DaemonSet.extensions daemon-set took: 9.61878ms
Sep 27 22:11:22.128: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.142816ms
Sep 27 22:11:25.732: INFO: Number of nodes with available pods: 0
Sep 27 22:11:25.732: INFO: Number of running nodes: 0, number of available pods: 0
Sep 27 22:11:25.734: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-6909/daemonsets","resourceVersion":"7631624"},"items":null}

Sep 27 22:11:25.735: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-6909/pods","resourceVersion":"7631624"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:11:25.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6909" for this suite.
Sep 27 22:11:31.759: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:11:31.828: INFO: namespace daemonsets-6909 deletion completed in 6.080356165s

• [SLOW TEST:32.316 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:11:31.828: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-654
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-00699c92-583c-4171-b300-c852f9bd4d6b
STEP: Creating a pod to test consume configMaps
Sep 27 22:11:31.997: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-592dfb89-bd2d-459d-b349-ef4e48b848c8" in namespace "projected-654" to be "success or failure"
Sep 27 22:11:31.999: INFO: Pod "pod-projected-configmaps-592dfb89-bd2d-459d-b349-ef4e48b848c8": Phase="Pending", Reason="", readiness=false. Elapsed: 1.891148ms
Sep 27 22:11:34.002: INFO: Pod "pod-projected-configmaps-592dfb89-bd2d-459d-b349-ef4e48b848c8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004697734s
STEP: Saw pod success
Sep 27 22:11:34.002: INFO: Pod "pod-projected-configmaps-592dfb89-bd2d-459d-b349-ef4e48b848c8" satisfied condition "success or failure"
Sep 27 22:11:34.004: INFO: Trying to get logs from node macpro-3 pod pod-projected-configmaps-592dfb89-bd2d-459d-b349-ef4e48b848c8 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 27 22:11:34.034: INFO: Waiting for pod pod-projected-configmaps-592dfb89-bd2d-459d-b349-ef4e48b848c8 to disappear
Sep 27 22:11:34.036: INFO: Pod pod-projected-configmaps-592dfb89-bd2d-459d-b349-ef4e48b848c8 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:11:34.036: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-654" for this suite.
Sep 27 22:11:40.050: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:11:40.120: INFO: namespace projected-654 deletion completed in 6.081214803s

• [SLOW TEST:8.292 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:11:40.120: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-4635
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test env composition
Sep 27 22:11:40.281: INFO: Waiting up to 5m0s for pod "var-expansion-f9227e09-6c5b-47f0-b041-e8b6adf2667d" in namespace "var-expansion-4635" to be "success or failure"
Sep 27 22:11:40.283: INFO: Pod "var-expansion-f9227e09-6c5b-47f0-b041-e8b6adf2667d": Phase="Pending", Reason="", readiness=false. Elapsed: 1.838649ms
Sep 27 22:11:42.286: INFO: Pod "var-expansion-f9227e09-6c5b-47f0-b041-e8b6adf2667d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004650834s
STEP: Saw pod success
Sep 27 22:11:42.286: INFO: Pod "var-expansion-f9227e09-6c5b-47f0-b041-e8b6adf2667d" satisfied condition "success or failure"
Sep 27 22:11:42.288: INFO: Trying to get logs from node macpro-1 pod var-expansion-f9227e09-6c5b-47f0-b041-e8b6adf2667d container dapi-container: <nil>
STEP: delete the pod
Sep 27 22:11:42.311: INFO: Waiting for pod var-expansion-f9227e09-6c5b-47f0-b041-e8b6adf2667d to disappear
Sep 27 22:11:42.313: INFO: Pod var-expansion-f9227e09-6c5b-47f0-b041-e8b6adf2667d no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:11:42.313: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4635" for this suite.
Sep 27 22:11:48.327: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:11:48.399: INFO: namespace var-expansion-4635 deletion completed in 6.083385213s

• [SLOW TEST:8.279 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:11:48.399: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5147
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-dd38a12a-e43f-4238-b5e8-d62ca5e23b4e
STEP: Creating a pod to test consume secrets
Sep 27 22:11:48.572: INFO: Waiting up to 5m0s for pod "pod-secrets-e16c6319-2eb2-437e-b6f4-9bf084c3bcb1" in namespace "secrets-5147" to be "success or failure"
Sep 27 22:11:48.574: INFO: Pod "pod-secrets-e16c6319-2eb2-437e-b6f4-9bf084c3bcb1": Phase="Pending", Reason="", readiness=false. Elapsed: 1.855962ms
Sep 27 22:11:50.576: INFO: Pod "pod-secrets-e16c6319-2eb2-437e-b6f4-9bf084c3bcb1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004414172s
STEP: Saw pod success
Sep 27 22:11:50.576: INFO: Pod "pod-secrets-e16c6319-2eb2-437e-b6f4-9bf084c3bcb1" satisfied condition "success or failure"
Sep 27 22:11:50.579: INFO: Trying to get logs from node macpro-2 pod pod-secrets-e16c6319-2eb2-437e-b6f4-9bf084c3bcb1 container secret-volume-test: <nil>
STEP: delete the pod
Sep 27 22:11:50.611: INFO: Waiting for pod pod-secrets-e16c6319-2eb2-437e-b6f4-9bf084c3bcb1 to disappear
Sep 27 22:11:50.613: INFO: Pod pod-secrets-e16c6319-2eb2-437e-b6f4-9bf084c3bcb1 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:11:50.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5147" for this suite.
Sep 27 22:11:56.634: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:11:56.705: INFO: namespace secrets-5147 deletion completed in 6.089334808s

• [SLOW TEST:8.306 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:11:56.705: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6826
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1421
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep 27 22:11:56.852: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-6826'
Sep 27 22:11:57.468: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep 27 22:11:57.468: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1427
Sep 27 22:11:59.485: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 delete deployment e2e-test-nginx-deployment --namespace=kubectl-6826'
Sep 27 22:11:59.552: INFO: stderr: ""
Sep 27 22:11:59.552: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:11:59.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6826" for this suite.
Sep 27 22:12:21.573: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:12:21.644: INFO: namespace kubectl-6826 deletion completed in 22.082584825s

• [SLOW TEST:24.939 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run default
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:12:21.644: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-3566
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:12:27.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3566" for this suite.
Sep 27 22:12:33.401: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:12:33.472: INFO: namespace watch-3566 deletion completed in 6.1728958s

• [SLOW TEST:11.828 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:12:33.472: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7571
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on tmpfs
Sep 27 22:12:33.630: INFO: Waiting up to 5m0s for pod "pod-5b0b14e9-e53b-434b-959a-e91d1a18ab9b" in namespace "emptydir-7571" to be "success or failure"
Sep 27 22:12:33.632: INFO: Pod "pod-5b0b14e9-e53b-434b-959a-e91d1a18ab9b": Phase="Pending", Reason="", readiness=false. Elapsed: 1.721446ms
Sep 27 22:12:35.635: INFO: Pod "pod-5b0b14e9-e53b-434b-959a-e91d1a18ab9b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004404025s
STEP: Saw pod success
Sep 27 22:12:35.635: INFO: Pod "pod-5b0b14e9-e53b-434b-959a-e91d1a18ab9b" satisfied condition "success or failure"
Sep 27 22:12:35.637: INFO: Trying to get logs from node macpro-1 pod pod-5b0b14e9-e53b-434b-959a-e91d1a18ab9b container test-container: <nil>
STEP: delete the pod
Sep 27 22:12:35.660: INFO: Waiting for pod pod-5b0b14e9-e53b-434b-959a-e91d1a18ab9b to disappear
Sep 27 22:12:35.662: INFO: Pod pod-5b0b14e9-e53b-434b-959a-e91d1a18ab9b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:12:35.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7571" for this suite.
Sep 27 22:12:41.675: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:12:41.747: INFO: namespace emptydir-7571 deletion completed in 6.082519825s

• [SLOW TEST:8.274 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:12:41.747: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-7346
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 27 22:12:41.902: INFO: (0) /api/v1/nodes/macpro-1/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.686594ms)
Sep 27 22:12:41.905: INFO: (1) /api/v1/nodes/macpro-1/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.146556ms)
Sep 27 22:12:41.908: INFO: (2) /api/v1/nodes/macpro-1/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.842014ms)
Sep 27 22:12:41.911: INFO: (3) /api/v1/nodes/macpro-1/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.837098ms)
Sep 27 22:12:41.914: INFO: (4) /api/v1/nodes/macpro-1/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.226188ms)
Sep 27 22:12:41.917: INFO: (5) /api/v1/nodes/macpro-1/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.565209ms)
Sep 27 22:12:41.920: INFO: (6) /api/v1/nodes/macpro-1/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.895506ms)
Sep 27 22:12:41.923: INFO: (7) /api/v1/nodes/macpro-1/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.713613ms)
Sep 27 22:12:41.925: INFO: (8) /api/v1/nodes/macpro-1/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.831263ms)
Sep 27 22:12:41.928: INFO: (9) /api/v1/nodes/macpro-1/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.867065ms)
Sep 27 22:12:41.932: INFO: (10) /api/v1/nodes/macpro-1/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.240738ms)
Sep 27 22:12:41.934: INFO: (11) /api/v1/nodes/macpro-1/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.656446ms)
Sep 27 22:12:41.937: INFO: (12) /api/v1/nodes/macpro-1/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.803558ms)
Sep 27 22:12:41.940: INFO: (13) /api/v1/nodes/macpro-1/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.784925ms)
Sep 27 22:12:41.943: INFO: (14) /api/v1/nodes/macpro-1/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.83473ms)
Sep 27 22:12:41.946: INFO: (15) /api/v1/nodes/macpro-1/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.846531ms)
Sep 27 22:12:41.948: INFO: (16) /api/v1/nodes/macpro-1/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.834836ms)
Sep 27 22:12:41.951: INFO: (17) /api/v1/nodes/macpro-1/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.75157ms)
Sep 27 22:12:41.954: INFO: (18) /api/v1/nodes/macpro-1/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.644672ms)
Sep 27 22:12:41.957: INFO: (19) /api/v1/nodes/macpro-1/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.71681ms)
[AfterEach] version v1
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:12:41.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-7346" for this suite.
Sep 27 22:12:47.974: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:12:48.046: INFO: namespace proxy-7346 deletion completed in 6.086342s

• [SLOW TEST:6.299 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:12:48.046: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-5709
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Sep 27 22:12:50.731: INFO: Successfully updated pod "pod-update-activedeadlineseconds-d35a93f3-c3b3-4ea0-b412-c955f93b0088"
Sep 27 22:12:50.731: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-d35a93f3-c3b3-4ea0-b412-c955f93b0088" in namespace "pods-5709" to be "terminated due to deadline exceeded"
Sep 27 22:12:50.733: INFO: Pod "pod-update-activedeadlineseconds-d35a93f3-c3b3-4ea0-b412-c955f93b0088": Phase="Running", Reason="", readiness=true. Elapsed: 1.777238ms
Sep 27 22:12:52.736: INFO: Pod "pod-update-activedeadlineseconds-d35a93f3-c3b3-4ea0-b412-c955f93b0088": Phase="Running", Reason="", readiness=true. Elapsed: 2.005168534s
Sep 27 22:12:54.739: INFO: Pod "pod-update-activedeadlineseconds-d35a93f3-c3b3-4ea0-b412-c955f93b0088": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.007740459s
Sep 27 22:12:54.739: INFO: Pod "pod-update-activedeadlineseconds-d35a93f3-c3b3-4ea0-b412-c955f93b0088" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:12:54.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5709" for this suite.
Sep 27 22:13:00.754: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:13:00.837: INFO: namespace pods-5709 deletion completed in 6.095330788s

• [SLOW TEST:12.791 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:13:00.837: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-4793
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-projected-tncn
STEP: Creating a pod to test atomic-volume-subpath
Sep 27 22:13:01.019: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-tncn" in namespace "subpath-4793" to be "success or failure"
Sep 27 22:13:01.021: INFO: Pod "pod-subpath-test-projected-tncn": Phase="Pending", Reason="", readiness=false. Elapsed: 1.950663ms
Sep 27 22:13:03.024: INFO: Pod "pod-subpath-test-projected-tncn": Phase="Running", Reason="", readiness=true. Elapsed: 2.004963884s
Sep 27 22:13:05.027: INFO: Pod "pod-subpath-test-projected-tncn": Phase="Running", Reason="", readiness=true. Elapsed: 4.007746854s
Sep 27 22:13:07.029: INFO: Pod "pod-subpath-test-projected-tncn": Phase="Running", Reason="", readiness=true. Elapsed: 6.010474283s
Sep 27 22:13:09.032: INFO: Pod "pod-subpath-test-projected-tncn": Phase="Running", Reason="", readiness=true. Elapsed: 8.013105467s
Sep 27 22:13:11.035: INFO: Pod "pod-subpath-test-projected-tncn": Phase="Running", Reason="", readiness=true. Elapsed: 10.015856945s
Sep 27 22:13:13.038: INFO: Pod "pod-subpath-test-projected-tncn": Phase="Running", Reason="", readiness=true. Elapsed: 12.01886676s
Sep 27 22:13:15.041: INFO: Pod "pod-subpath-test-projected-tncn": Phase="Running", Reason="", readiness=true. Elapsed: 14.021563271s
Sep 27 22:13:17.043: INFO: Pod "pod-subpath-test-projected-tncn": Phase="Running", Reason="", readiness=true. Elapsed: 16.024430815s
Sep 27 22:13:19.046: INFO: Pod "pod-subpath-test-projected-tncn": Phase="Running", Reason="", readiness=true. Elapsed: 18.026918127s
Sep 27 22:13:21.049: INFO: Pod "pod-subpath-test-projected-tncn": Phase="Running", Reason="", readiness=true. Elapsed: 20.02974983s
Sep 27 22:13:23.052: INFO: Pod "pod-subpath-test-projected-tncn": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.033071879s
STEP: Saw pod success
Sep 27 22:13:23.052: INFO: Pod "pod-subpath-test-projected-tncn" satisfied condition "success or failure"
Sep 27 22:13:23.054: INFO: Trying to get logs from node macpro-1 pod pod-subpath-test-projected-tncn container test-container-subpath-projected-tncn: <nil>
STEP: delete the pod
Sep 27 22:13:23.080: INFO: Waiting for pod pod-subpath-test-projected-tncn to disappear
Sep 27 22:13:23.082: INFO: Pod pod-subpath-test-projected-tncn no longer exists
STEP: Deleting pod pod-subpath-test-projected-tncn
Sep 27 22:13:23.082: INFO: Deleting pod "pod-subpath-test-projected-tncn" in namespace "subpath-4793"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:13:23.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4793" for this suite.
Sep 27 22:13:29.108: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:13:29.181: INFO: namespace subpath-4793 deletion completed in 6.087071617s

• [SLOW TEST:28.344 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:13:29.181: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-4091
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-configmap-lqgc
STEP: Creating a pod to test atomic-volume-subpath
Sep 27 22:13:29.357: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-lqgc" in namespace "subpath-4091" to be "success or failure"
Sep 27 22:13:29.359: INFO: Pod "pod-subpath-test-configmap-lqgc": Phase="Pending", Reason="", readiness=false. Elapsed: 1.875363ms
Sep 27 22:13:31.366: INFO: Pod "pod-subpath-test-configmap-lqgc": Phase="Running", Reason="", readiness=true. Elapsed: 2.009294695s
Sep 27 22:13:33.369: INFO: Pod "pod-subpath-test-configmap-lqgc": Phase="Running", Reason="", readiness=true. Elapsed: 4.012022455s
Sep 27 22:13:35.372: INFO: Pod "pod-subpath-test-configmap-lqgc": Phase="Running", Reason="", readiness=true. Elapsed: 6.014654237s
Sep 27 22:13:37.374: INFO: Pod "pod-subpath-test-configmap-lqgc": Phase="Running", Reason="", readiness=true. Elapsed: 8.01711754s
Sep 27 22:13:39.377: INFO: Pod "pod-subpath-test-configmap-lqgc": Phase="Running", Reason="", readiness=true. Elapsed: 10.019770331s
Sep 27 22:13:41.380: INFO: Pod "pod-subpath-test-configmap-lqgc": Phase="Running", Reason="", readiness=true. Elapsed: 12.022467483s
Sep 27 22:13:43.383: INFO: Pod "pod-subpath-test-configmap-lqgc": Phase="Running", Reason="", readiness=true. Elapsed: 14.025474034s
Sep 27 22:13:45.385: INFO: Pod "pod-subpath-test-configmap-lqgc": Phase="Running", Reason="", readiness=true. Elapsed: 16.028076139s
Sep 27 22:13:47.388: INFO: Pod "pod-subpath-test-configmap-lqgc": Phase="Running", Reason="", readiness=true. Elapsed: 18.030831976s
Sep 27 22:13:49.390: INFO: Pod "pod-subpath-test-configmap-lqgc": Phase="Running", Reason="", readiness=true. Elapsed: 20.033201243s
Sep 27 22:13:51.393: INFO: Pod "pod-subpath-test-configmap-lqgc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.03557749s
STEP: Saw pod success
Sep 27 22:13:51.393: INFO: Pod "pod-subpath-test-configmap-lqgc" satisfied condition "success or failure"
Sep 27 22:13:51.395: INFO: Trying to get logs from node macpro-1 pod pod-subpath-test-configmap-lqgc container test-container-subpath-configmap-lqgc: <nil>
STEP: delete the pod
Sep 27 22:13:51.422: INFO: Waiting for pod pod-subpath-test-configmap-lqgc to disappear
Sep 27 22:13:51.423: INFO: Pod pod-subpath-test-configmap-lqgc no longer exists
STEP: Deleting pod pod-subpath-test-configmap-lqgc
Sep 27 22:13:51.423: INFO: Deleting pod "pod-subpath-test-configmap-lqgc" in namespace "subpath-4091"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:13:51.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4091" for this suite.
Sep 27 22:13:57.439: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:13:57.511: INFO: namespace subpath-4091 deletion completed in 6.082713359s

• [SLOW TEST:28.330 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:13:57.511: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-6833
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 27 22:13:57.664: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:14:01.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6833" for this suite.
Sep 27 22:14:43.795: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:14:43.866: INFO: namespace pods-6833 deletion completed in 42.082565796s

• [SLOW TEST:46.356 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:14:43.866: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7598
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Sep 27 22:14:48.036: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 exec pod-sharedvolume-9162366b-4b38-4734-9760-5b8a868bbd25 -c busybox-main-container --namespace=emptydir-7598 -- cat /usr/share/volumeshare/shareddata.txt'
Sep 27 22:14:48.194: INFO: stderr: ""
Sep 27 22:14:48.194: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:14:48.194: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7598" for this suite.
Sep 27 22:14:54.210: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:14:54.281: INFO: namespace emptydir-7598 deletion completed in 6.083031726s

• [SLOW TEST:10.415 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:14:54.281: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9334
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-upd-88816792-d79b-4f34-bcce-ee63c210065e
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-88816792-d79b-4f34-bcce-ee63c210065e
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:14:58.493: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9334" for this suite.
Sep 27 22:15:20.513: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:15:20.583: INFO: namespace configmap-9334 deletion completed in 22.087615792s

• [SLOW TEST:26.302 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:15:20.583: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6154
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-726aa097-e4c5-4457-9944-cbd8c3003f4c
STEP: Creating a pod to test consume configMaps
Sep 27 22:15:20.760: INFO: Waiting up to 5m0s for pod "pod-configmaps-5e38c10f-4133-40dd-9282-41d4e1d90bb3" in namespace "configmap-6154" to be "success or failure"
Sep 27 22:15:20.762: INFO: Pod "pod-configmaps-5e38c10f-4133-40dd-9282-41d4e1d90bb3": Phase="Pending", Reason="", readiness=false. Elapsed: 1.93776ms
Sep 27 22:15:22.765: INFO: Pod "pod-configmaps-5e38c10f-4133-40dd-9282-41d4e1d90bb3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005194371s
STEP: Saw pod success
Sep 27 22:15:22.765: INFO: Pod "pod-configmaps-5e38c10f-4133-40dd-9282-41d4e1d90bb3" satisfied condition "success or failure"
Sep 27 22:15:22.767: INFO: Trying to get logs from node macpro-2 pod pod-configmaps-5e38c10f-4133-40dd-9282-41d4e1d90bb3 container configmap-volume-test: <nil>
STEP: delete the pod
Sep 27 22:15:22.795: INFO: Waiting for pod pod-configmaps-5e38c10f-4133-40dd-9282-41d4e1d90bb3 to disappear
Sep 27 22:15:22.797: INFO: Pod pod-configmaps-5e38c10f-4133-40dd-9282-41d4e1d90bb3 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:15:22.797: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6154" for this suite.
Sep 27 22:15:28.812: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:15:28.885: INFO: namespace configmap-6154 deletion completed in 6.084980636s

• [SLOW TEST:8.301 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:15:28.885: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-9901
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override command
Sep 27 22:15:29.043: INFO: Waiting up to 5m0s for pod "client-containers-80a1286b-014f-415c-962b-d867e670c67d" in namespace "containers-9901" to be "success or failure"
Sep 27 22:15:29.045: INFO: Pod "client-containers-80a1286b-014f-415c-962b-d867e670c67d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006829ms
Sep 27 22:15:31.048: INFO: Pod "client-containers-80a1286b-014f-415c-962b-d867e670c67d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004984141s
STEP: Saw pod success
Sep 27 22:15:31.048: INFO: Pod "client-containers-80a1286b-014f-415c-962b-d867e670c67d" satisfied condition "success or failure"
Sep 27 22:15:31.050: INFO: Trying to get logs from node macpro-3 pod client-containers-80a1286b-014f-415c-962b-d867e670c67d container test-container: <nil>
STEP: delete the pod
Sep 27 22:15:31.074: INFO: Waiting for pod client-containers-80a1286b-014f-415c-962b-d867e670c67d to disappear
Sep 27 22:15:31.075: INFO: Pod client-containers-80a1286b-014f-415c-962b-d867e670c67d no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:15:31.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-9901" for this suite.
Sep 27 22:15:37.090: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:15:37.162: INFO: namespace containers-9901 deletion completed in 6.083963859s

• [SLOW TEST:8.277 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:15:37.162: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1632
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name cm-test-opt-del-bb33b67d-ab74-463c-b130-c98573b7ee2f
STEP: Creating configMap with name cm-test-opt-upd-ed94e187-67e7-4f28-9bc9-abb9b61c46a0
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-bb33b67d-ab74-463c-b130-c98573b7ee2f
STEP: Updating configmap cm-test-opt-upd-ed94e187-67e7-4f28-9bc9-abb9b61c46a0
STEP: Creating configMap with name cm-test-opt-create-509a876c-862d-425e-a451-6515083d62d5
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:17:09.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1632" for this suite.
Sep 27 22:17:31.785: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:17:31.859: INFO: namespace configmap-1632 deletion completed in 22.086326581s

• [SLOW TEST:114.697 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:17:31.860: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-8695
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:17:34.038: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-8695" for this suite.
Sep 27 22:18:24.052: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:18:24.131: INFO: namespace kubelet-test-8695 deletion completed in 50.090776088s

• [SLOW TEST:52.272 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command in a pod
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:18:24.132: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9024
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-66f2dc0b-6ecc-40f0-8c83-7dcbac2f107b
STEP: Creating a pod to test consume configMaps
Sep 27 22:18:24.294: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ac82423d-fd9c-426e-afa5-fa2ec0fc3b99" in namespace "projected-9024" to be "success or failure"
Sep 27 22:18:24.302: INFO: Pod "pod-projected-configmaps-ac82423d-fd9c-426e-afa5-fa2ec0fc3b99": Phase="Pending", Reason="", readiness=false. Elapsed: 8.570978ms
Sep 27 22:18:26.305: INFO: Pod "pod-projected-configmaps-ac82423d-fd9c-426e-afa5-fa2ec0fc3b99": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011462251s
STEP: Saw pod success
Sep 27 22:18:26.305: INFO: Pod "pod-projected-configmaps-ac82423d-fd9c-426e-afa5-fa2ec0fc3b99" satisfied condition "success or failure"
Sep 27 22:18:26.307: INFO: Trying to get logs from node macpro-3 pod pod-projected-configmaps-ac82423d-fd9c-426e-afa5-fa2ec0fc3b99 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 27 22:18:26.332: INFO: Waiting for pod pod-projected-configmaps-ac82423d-fd9c-426e-afa5-fa2ec0fc3b99 to disappear
Sep 27 22:18:26.334: INFO: Pod pod-projected-configmaps-ac82423d-fd9c-426e-afa5-fa2ec0fc3b99 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:18:26.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9024" for this suite.
Sep 27 22:18:32.348: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:18:32.420: INFO: namespace projected-9024 deletion completed in 6.084103924s

• [SLOW TEST:8.289 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:18:32.420: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-5844
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod liveness-b1485f36-b82f-429c-85d4-c56dea4688da in namespace container-probe-5844
Sep 27 22:18:34.586: INFO: Started pod liveness-b1485f36-b82f-429c-85d4-c56dea4688da in namespace container-probe-5844
STEP: checking the pod's current state and verifying that restartCount is present
Sep 27 22:18:34.588: INFO: Initial restart count of pod liveness-b1485f36-b82f-429c-85d4-c56dea4688da is 0
Sep 27 22:19:00.630: INFO: Restart count of pod container-probe-5844/liveness-b1485f36-b82f-429c-85d4-c56dea4688da is now 1 (26.042150105s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:19:00.645: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5844" for this suite.
Sep 27 22:19:06.664: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:19:06.733: INFO: namespace container-probe-5844 deletion completed in 6.085496112s

• [SLOW TEST:34.312 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:19:06.733: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1145
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep 27 22:19:06.890: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9b3c71e2-c04d-4084-81a4-9099d706523b" in namespace "projected-1145" to be "success or failure"
Sep 27 22:19:06.892: INFO: Pod "downwardapi-volume-9b3c71e2-c04d-4084-81a4-9099d706523b": Phase="Pending", Reason="", readiness=false. Elapsed: 1.980233ms
Sep 27 22:19:08.895: INFO: Pod "downwardapi-volume-9b3c71e2-c04d-4084-81a4-9099d706523b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004825394s
STEP: Saw pod success
Sep 27 22:19:08.895: INFO: Pod "downwardapi-volume-9b3c71e2-c04d-4084-81a4-9099d706523b" satisfied condition "success or failure"
Sep 27 22:19:08.897: INFO: Trying to get logs from node macpro-2 pod downwardapi-volume-9b3c71e2-c04d-4084-81a4-9099d706523b container client-container: <nil>
STEP: delete the pod
Sep 27 22:19:08.921: INFO: Waiting for pod downwardapi-volume-9b3c71e2-c04d-4084-81a4-9099d706523b to disappear
Sep 27 22:19:08.922: INFO: Pod downwardapi-volume-9b3c71e2-c04d-4084-81a4-9099d706523b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:19:08.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1145" for this suite.
Sep 27 22:19:14.936: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:19:15.007: INFO: namespace projected-1145 deletion completed in 6.082458282s

• [SLOW TEST:8.274 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:19:15.008: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6352
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on node default medium
Sep 27 22:19:15.169: INFO: Waiting up to 5m0s for pod "pod-63b0244e-ff07-48a0-8ac2-2162690d7adf" in namespace "emptydir-6352" to be "success or failure"
Sep 27 22:19:15.171: INFO: Pod "pod-63b0244e-ff07-48a0-8ac2-2162690d7adf": Phase="Pending", Reason="", readiness=false. Elapsed: 1.997524ms
Sep 27 22:19:17.174: INFO: Pod "pod-63b0244e-ff07-48a0-8ac2-2162690d7adf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00508273s
Sep 27 22:19:19.176: INFO: Pod "pod-63b0244e-ff07-48a0-8ac2-2162690d7adf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007488507s
STEP: Saw pod success
Sep 27 22:19:19.176: INFO: Pod "pod-63b0244e-ff07-48a0-8ac2-2162690d7adf" satisfied condition "success or failure"
Sep 27 22:19:19.178: INFO: Trying to get logs from node macpro-3 pod pod-63b0244e-ff07-48a0-8ac2-2162690d7adf container test-container: <nil>
STEP: delete the pod
Sep 27 22:19:19.202: INFO: Waiting for pod pod-63b0244e-ff07-48a0-8ac2-2162690d7adf to disappear
Sep 27 22:19:19.203: INFO: Pod pod-63b0244e-ff07-48a0-8ac2-2162690d7adf no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:19:19.203: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6352" for this suite.
Sep 27 22:19:25.221: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:19:25.291: INFO: namespace emptydir-6352 deletion completed in 6.08526541s

• [SLOW TEST:10.284 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:19:25.291: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-832
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-3ab5136d-4f05-4dd6-b699-12904dfcd5c6
STEP: Creating a pod to test consume secrets
Sep 27 22:19:25.453: INFO: Waiting up to 5m0s for pod "pod-secrets-6f2982f7-f5a6-41eb-a752-77eb28d9b4ac" in namespace "secrets-832" to be "success or failure"
Sep 27 22:19:25.455: INFO: Pod "pod-secrets-6f2982f7-f5a6-41eb-a752-77eb28d9b4ac": Phase="Pending", Reason="", readiness=false. Elapsed: 1.931174ms
Sep 27 22:19:27.458: INFO: Pod "pod-secrets-6f2982f7-f5a6-41eb-a752-77eb28d9b4ac": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004560726s
STEP: Saw pod success
Sep 27 22:19:27.458: INFO: Pod "pod-secrets-6f2982f7-f5a6-41eb-a752-77eb28d9b4ac" satisfied condition "success or failure"
Sep 27 22:19:27.460: INFO: Trying to get logs from node macpro-3 pod pod-secrets-6f2982f7-f5a6-41eb-a752-77eb28d9b4ac container secret-volume-test: <nil>
STEP: delete the pod
Sep 27 22:19:27.490: INFO: Waiting for pod pod-secrets-6f2982f7-f5a6-41eb-a752-77eb28d9b4ac to disappear
Sep 27 22:19:27.492: INFO: Pod pod-secrets-6f2982f7-f5a6-41eb-a752-77eb28d9b4ac no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:19:27.492: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-832" for this suite.
Sep 27 22:19:33.506: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:19:33.580: INFO: namespace secrets-832 deletion completed in 6.085589918s

• [SLOW TEST:8.289 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:19:33.580: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9917
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Sep 27 22:19:33.742: INFO: Waiting up to 5m0s for pod "downward-api-1d4c3a68-1970-44aa-bb40-1d4cabd1a933" in namespace "downward-api-9917" to be "success or failure"
Sep 27 22:19:33.744: INFO: Pod "downward-api-1d4c3a68-1970-44aa-bb40-1d4cabd1a933": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03591ms
Sep 27 22:19:35.747: INFO: Pod "downward-api-1d4c3a68-1970-44aa-bb40-1d4cabd1a933": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00503097s
Sep 27 22:19:37.750: INFO: Pod "downward-api-1d4c3a68-1970-44aa-bb40-1d4cabd1a933": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007845475s
STEP: Saw pod success
Sep 27 22:19:37.750: INFO: Pod "downward-api-1d4c3a68-1970-44aa-bb40-1d4cabd1a933" satisfied condition "success or failure"
Sep 27 22:19:37.753: INFO: Trying to get logs from node macpro-3 pod downward-api-1d4c3a68-1970-44aa-bb40-1d4cabd1a933 container dapi-container: <nil>
STEP: delete the pod
Sep 27 22:19:37.772: INFO: Waiting for pod downward-api-1d4c3a68-1970-44aa-bb40-1d4cabd1a933 to disappear
Sep 27 22:19:37.774: INFO: Pod downward-api-1d4c3a68-1970-44aa-bb40-1d4cabd1a933 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:19:37.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9917" for this suite.
Sep 27 22:19:43.791: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:19:43.861: INFO: namespace downward-api-9917 deletion completed in 6.084191635s

• [SLOW TEST:10.281 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:19:43.861: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-5139
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:19:46.038: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-5139" for this suite.
Sep 27 22:20:36.052: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:20:36.120: INFO: namespace kubelet-test-5139 deletion completed in 50.079192175s

• [SLOW TEST:52.259 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a read only busybox container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:20:36.120: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-4306
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 27 22:20:36.285: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Sep 27 22:20:36.296: INFO: Number of nodes with available pods: 0
Sep 27 22:20:36.296: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Sep 27 22:20:36.325: INFO: Number of nodes with available pods: 0
Sep 27 22:20:36.325: INFO: Node macpro-1 is running more than one daemon pod
Sep 27 22:20:37.328: INFO: Number of nodes with available pods: 0
Sep 27 22:20:37.328: INFO: Node macpro-1 is running more than one daemon pod
Sep 27 22:20:38.328: INFO: Number of nodes with available pods: 1
Sep 27 22:20:38.328: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Sep 27 22:20:38.345: INFO: Number of nodes with available pods: 1
Sep 27 22:20:38.345: INFO: Number of running nodes: 0, number of available pods: 1
Sep 27 22:20:39.348: INFO: Number of nodes with available pods: 0
Sep 27 22:20:39.348: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Sep 27 22:20:39.364: INFO: Number of nodes with available pods: 0
Sep 27 22:20:39.364: INFO: Node macpro-1 is running more than one daemon pod
Sep 27 22:20:40.366: INFO: Number of nodes with available pods: 0
Sep 27 22:20:40.366: INFO: Node macpro-1 is running more than one daemon pod
Sep 27 22:20:41.366: INFO: Number of nodes with available pods: 0
Sep 27 22:20:41.366: INFO: Node macpro-1 is running more than one daemon pod
Sep 27 22:20:42.366: INFO: Number of nodes with available pods: 0
Sep 27 22:20:42.366: INFO: Node macpro-1 is running more than one daemon pod
Sep 27 22:20:43.366: INFO: Number of nodes with available pods: 0
Sep 27 22:20:43.366: INFO: Node macpro-1 is running more than one daemon pod
Sep 27 22:20:44.367: INFO: Number of nodes with available pods: 1
Sep 27 22:20:44.367: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4306, will wait for the garbage collector to delete the pods
Sep 27 22:20:44.432: INFO: Deleting DaemonSet.extensions daemon-set took: 8.67315ms
Sep 27 22:20:44.732: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.210338ms
Sep 27 22:20:48.335: INFO: Number of nodes with available pods: 0
Sep 27 22:20:48.335: INFO: Number of running nodes: 0, number of available pods: 0
Sep 27 22:20:48.337: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-4306/daemonsets","resourceVersion":"7633631"},"items":null}

Sep 27 22:20:48.339: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-4306/pods","resourceVersion":"7633631"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:20:48.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4306" for this suite.
Sep 27 22:20:54.371: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:20:54.447: INFO: namespace daemonsets-4306 deletion completed in 6.087001262s

• [SLOW TEST:18.327 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:20:54.447: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7161
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep 27 22:20:54.605: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2b38bcb7-0805-4635-9d15-26c17294b72d" in namespace "projected-7161" to be "success or failure"
Sep 27 22:20:54.607: INFO: Pod "downwardapi-volume-2b38bcb7-0805-4635-9d15-26c17294b72d": Phase="Pending", Reason="", readiness=false. Elapsed: 1.909394ms
Sep 27 22:20:56.610: INFO: Pod "downwardapi-volume-2b38bcb7-0805-4635-9d15-26c17294b72d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004453706s
STEP: Saw pod success
Sep 27 22:20:56.610: INFO: Pod "downwardapi-volume-2b38bcb7-0805-4635-9d15-26c17294b72d" satisfied condition "success or failure"
Sep 27 22:20:56.612: INFO: Trying to get logs from node macpro-1 pod downwardapi-volume-2b38bcb7-0805-4635-9d15-26c17294b72d container client-container: <nil>
STEP: delete the pod
Sep 27 22:20:56.638: INFO: Waiting for pod downwardapi-volume-2b38bcb7-0805-4635-9d15-26c17294b72d to disappear
Sep 27 22:20:56.639: INFO: Pod downwardapi-volume-2b38bcb7-0805-4635-9d15-26c17294b72d no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:20:56.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7161" for this suite.
Sep 27 22:21:02.655: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:21:02.724: INFO: namespace projected-7161 deletion completed in 6.081771194s

• [SLOW TEST:8.276 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:21:02.724: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-1478
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-028836da-5710-4e29-8bac-40d1cdb49d0d
STEP: Creating a pod to test consume secrets
Sep 27 22:21:02.896: INFO: Waiting up to 5m0s for pod "pod-secrets-1852afb8-6627-4ccb-9e8a-6cae402f5688" in namespace "secrets-1478" to be "success or failure"
Sep 27 22:21:02.898: INFO: Pod "pod-secrets-1852afb8-6627-4ccb-9e8a-6cae402f5688": Phase="Pending", Reason="", readiness=false. Elapsed: 1.765412ms
Sep 27 22:21:04.901: INFO: Pod "pod-secrets-1852afb8-6627-4ccb-9e8a-6cae402f5688": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004344745s
Sep 27 22:21:06.903: INFO: Pod "pod-secrets-1852afb8-6627-4ccb-9e8a-6cae402f5688": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006327348s
STEP: Saw pod success
Sep 27 22:21:06.903: INFO: Pod "pod-secrets-1852afb8-6627-4ccb-9e8a-6cae402f5688" satisfied condition "success or failure"
Sep 27 22:21:06.905: INFO: Trying to get logs from node macpro-2 pod pod-secrets-1852afb8-6627-4ccb-9e8a-6cae402f5688 container secret-volume-test: <nil>
STEP: delete the pod
Sep 27 22:21:06.928: INFO: Waiting for pod pod-secrets-1852afb8-6627-4ccb-9e8a-6cae402f5688 to disappear
Sep 27 22:21:06.930: INFO: Pod pod-secrets-1852afb8-6627-4ccb-9e8a-6cae402f5688 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:21:06.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1478" for this suite.
Sep 27 22:21:12.944: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:21:13.024: INFO: namespace secrets-1478 deletion completed in 6.091344607s

• [SLOW TEST:10.300 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:21:13.024: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2759
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep 27 22:21:13.182: INFO: Waiting up to 5m0s for pod "downwardapi-volume-26776bdc-a44b-4dd8-97ac-9973db7cc8a8" in namespace "projected-2759" to be "success or failure"
Sep 27 22:21:13.183: INFO: Pod "downwardapi-volume-26776bdc-a44b-4dd8-97ac-9973db7cc8a8": Phase="Pending", Reason="", readiness=false. Elapsed: 1.923375ms
Sep 27 22:21:15.186: INFO: Pod "downwardapi-volume-26776bdc-a44b-4dd8-97ac-9973db7cc8a8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004813503s
STEP: Saw pod success
Sep 27 22:21:15.186: INFO: Pod "downwardapi-volume-26776bdc-a44b-4dd8-97ac-9973db7cc8a8" satisfied condition "success or failure"
Sep 27 22:21:15.188: INFO: Trying to get logs from node macpro-3 pod downwardapi-volume-26776bdc-a44b-4dd8-97ac-9973db7cc8a8 container client-container: <nil>
STEP: delete the pod
Sep 27 22:21:15.209: INFO: Waiting for pod downwardapi-volume-26776bdc-a44b-4dd8-97ac-9973db7cc8a8 to disappear
Sep 27 22:21:15.211: INFO: Pod downwardapi-volume-26776bdc-a44b-4dd8-97ac-9973db7cc8a8 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:21:15.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2759" for this suite.
Sep 27 22:21:21.228: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:21:21.304: INFO: namespace projected-2759 deletion completed in 6.090744932s

• [SLOW TEST:8.280 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:21:21.305: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-2434
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-2434
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a new StatefulSet
Sep 27 22:21:21.476: INFO: Found 0 stateful pods, waiting for 3
Sep 27 22:21:31.479: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Sep 27 22:21:31.479: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Sep 27 22:21:31.479: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Sep 27 22:21:31.512: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Sep 27 22:21:41.550: INFO: Updating stateful set ss2
Sep 27 22:21:41.574: INFO: Waiting for Pod statefulset-2434/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Restoring Pods to the correct revision when they are deleted
Sep 27 22:21:51.666: INFO: Found 2 stateful pods, waiting for 3
Sep 27 22:22:01.669: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Sep 27 22:22:01.669: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Sep 27 22:22:01.669: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Sep 27 22:22:01.696: INFO: Updating stateful set ss2
Sep 27 22:22:01.720: INFO: Waiting for Pod statefulset-2434/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Sep 27 22:22:11.744: INFO: Updating stateful set ss2
Sep 27 22:22:11.755: INFO: Waiting for StatefulSet statefulset-2434/ss2 to complete update
Sep 27 22:22:11.755: INFO: Waiting for Pod statefulset-2434/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Sep 27 22:22:21.760: INFO: Waiting for StatefulSet statefulset-2434/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Sep 27 22:22:31.760: INFO: Deleting all statefulset in ns statefulset-2434
Sep 27 22:22:31.762: INFO: Scaling statefulset ss2 to 0
Sep 27 22:22:41.778: INFO: Waiting for statefulset status.replicas updated to 0
Sep 27 22:22:41.781: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:22:41.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2434" for this suite.
Sep 27 22:22:47.813: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:22:47.891: INFO: namespace statefulset-2434 deletion completed in 6.088288083s

• [SLOW TEST:86.586 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:22:47.891: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9941
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap configmap-9941/configmap-test-b48fcc67-7072-434e-8490-9603ec697a1d
STEP: Creating a pod to test consume configMaps
Sep 27 22:22:48.055: INFO: Waiting up to 5m0s for pod "pod-configmaps-59d4d702-1672-4703-87f9-6a890ab048f5" in namespace "configmap-9941" to be "success or failure"
Sep 27 22:22:48.056: INFO: Pod "pod-configmaps-59d4d702-1672-4703-87f9-6a890ab048f5": Phase="Pending", Reason="", readiness=false. Elapsed: 1.834312ms
Sep 27 22:22:50.059: INFO: Pod "pod-configmaps-59d4d702-1672-4703-87f9-6a890ab048f5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004165369s
STEP: Saw pod success
Sep 27 22:22:50.059: INFO: Pod "pod-configmaps-59d4d702-1672-4703-87f9-6a890ab048f5" satisfied condition "success or failure"
Sep 27 22:22:50.061: INFO: Trying to get logs from node macpro-2 pod pod-configmaps-59d4d702-1672-4703-87f9-6a890ab048f5 container env-test: <nil>
STEP: delete the pod
Sep 27 22:22:50.089: INFO: Waiting for pod pod-configmaps-59d4d702-1672-4703-87f9-6a890ab048f5 to disappear
Sep 27 22:22:50.090: INFO: Pod pod-configmaps-59d4d702-1672-4703-87f9-6a890ab048f5 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:22:50.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9941" for this suite.
Sep 27 22:22:56.104: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:22:56.176: INFO: namespace configmap-9941 deletion completed in 6.082870373s

• [SLOW TEST:8.285 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:22:56.176: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-270
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep 27 22:22:56.338: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7bcead00-6d41-4207-b616-f3b43337539b" in namespace "projected-270" to be "success or failure"
Sep 27 22:22:56.340: INFO: Pod "downwardapi-volume-7bcead00-6d41-4207-b616-f3b43337539b": Phase="Pending", Reason="", readiness=false. Elapsed: 1.74122ms
Sep 27 22:22:58.342: INFO: Pod "downwardapi-volume-7bcead00-6d41-4207-b616-f3b43337539b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004382354s
STEP: Saw pod success
Sep 27 22:22:58.342: INFO: Pod "downwardapi-volume-7bcead00-6d41-4207-b616-f3b43337539b" satisfied condition "success or failure"
Sep 27 22:22:58.345: INFO: Trying to get logs from node macpro-1 pod downwardapi-volume-7bcead00-6d41-4207-b616-f3b43337539b container client-container: <nil>
STEP: delete the pod
Sep 27 22:22:58.373: INFO: Waiting for pod downwardapi-volume-7bcead00-6d41-4207-b616-f3b43337539b to disappear
Sep 27 22:22:58.376: INFO: Pod downwardapi-volume-7bcead00-6d41-4207-b616-f3b43337539b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:22:58.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-270" for this suite.
Sep 27 22:23:04.389: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:23:04.462: INFO: namespace projected-270 deletion completed in 6.084247095s

• [SLOW TEST:8.287 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:23:04.463: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-9972
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-9972
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a new StatefulSet
Sep 27 22:23:04.634: INFO: Found 0 stateful pods, waiting for 3
Sep 27 22:23:14.638: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Sep 27 22:23:14.638: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Sep 27 22:23:14.638: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Sep 27 22:23:14.645: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 exec --namespace=statefulset-9972 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep 27 22:23:15.337: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep 27 22:23:15.337: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep 27 22:23:15.337: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Sep 27 22:23:25.367: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Sep 27 22:23:35.387: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 exec --namespace=statefulset-9972 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 27 22:23:35.552: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep 27 22:23:35.552: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep 27 22:23:35.552: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep 27 22:23:45.568: INFO: Waiting for StatefulSet statefulset-9972/ss2 to complete update
Sep 27 22:23:45.568: INFO: Waiting for Pod statefulset-9972/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Rolling back to a previous revision
Sep 27 22:23:55.572: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 exec --namespace=statefulset-9972 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep 27 22:23:55.741: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep 27 22:23:55.741: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep 27 22:23:55.741: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep 27 22:24:05.781: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Sep 27 22:24:15.802: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 exec --namespace=statefulset-9972 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 27 22:24:15.967: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep 27 22:24:15.967: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep 27 22:24:15.967: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep 27 22:24:35.981: INFO: Waiting for StatefulSet statefulset-9972/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Sep 27 22:24:45.987: INFO: Deleting all statefulset in ns statefulset-9972
Sep 27 22:24:45.989: INFO: Scaling statefulset ss2 to 0
Sep 27 22:24:56.002: INFO: Waiting for statefulset status.replicas updated to 0
Sep 27 22:24:56.004: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:24:56.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9972" for this suite.
Sep 27 22:25:02.039: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:25:02.113: INFO: namespace statefulset-9972 deletion completed in 6.093811358s

• [SLOW TEST:117.650 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:25:02.113: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-4585
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating pod
Sep 27 22:25:04.296: INFO: Pod pod-hostip-85dce4fa-a629-41e8-8ad1-efd073e902fc has hostIP: 10.10.10.5
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:25:04.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4585" for this suite.
Sep 27 22:25:26.317: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:25:26.387: INFO: namespace pods-4585 deletion completed in 22.088498604s

• [SLOW TEST:24.274 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:25:26.388: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-9818
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Sep 27 22:25:26.549: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-9818,SelfLink:/api/v1/namespaces/watch-9818/configmaps/e2e-watch-test-watch-closed,UID:273861e2-e0ce-4ccc-889a-7e5791db893a,ResourceVersion:7635034,Generation:0,CreationTimestamp:2019-09-27 22:25:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep 27 22:25:26.549: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-9818,SelfLink:/api/v1/namespaces/watch-9818/configmaps/e2e-watch-test-watch-closed,UID:273861e2-e0ce-4ccc-889a-7e5791db893a,ResourceVersion:7635035,Generation:0,CreationTimestamp:2019-09-27 22:25:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Sep 27 22:25:26.569: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-9818,SelfLink:/api/v1/namespaces/watch-9818/configmaps/e2e-watch-test-watch-closed,UID:273861e2-e0ce-4ccc-889a-7e5791db893a,ResourceVersion:7635036,Generation:0,CreationTimestamp:2019-09-27 22:25:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep 27 22:25:26.569: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-9818,SelfLink:/api/v1/namespaces/watch-9818/configmaps/e2e-watch-test-watch-closed,UID:273861e2-e0ce-4ccc-889a-7e5791db893a,ResourceVersion:7635037,Generation:0,CreationTimestamp:2019-09-27 22:25:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:25:26.569: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-9818" for this suite.
Sep 27 22:25:32.583: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:25:32.661: INFO: namespace watch-9818 deletion completed in 6.088987569s

• [SLOW TEST:6.273 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:25:32.661: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6828
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep 27 22:25:32.828: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f2362795-29ad-4e5e-8576-7886a6d19e81" in namespace "projected-6828" to be "success or failure"
Sep 27 22:25:32.830: INFO: Pod "downwardapi-volume-f2362795-29ad-4e5e-8576-7886a6d19e81": Phase="Pending", Reason="", readiness=false. Elapsed: 1.904332ms
Sep 27 22:25:34.833: INFO: Pod "downwardapi-volume-f2362795-29ad-4e5e-8576-7886a6d19e81": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00535446s
STEP: Saw pod success
Sep 27 22:25:34.833: INFO: Pod "downwardapi-volume-f2362795-29ad-4e5e-8576-7886a6d19e81" satisfied condition "success or failure"
Sep 27 22:25:34.835: INFO: Trying to get logs from node macpro-3 pod downwardapi-volume-f2362795-29ad-4e5e-8576-7886a6d19e81 container client-container: <nil>
STEP: delete the pod
Sep 27 22:25:34.864: INFO: Waiting for pod downwardapi-volume-f2362795-29ad-4e5e-8576-7886a6d19e81 to disappear
Sep 27 22:25:34.866: INFO: Pod downwardapi-volume-f2362795-29ad-4e5e-8576-7886a6d19e81 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:25:34.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6828" for this suite.
Sep 27 22:25:40.882: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:25:40.952: INFO: namespace projected-6828 deletion completed in 6.083708863s

• [SLOW TEST:8.291 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:25:40.952: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-2449
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:25:44.139: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-2449" for this suite.
Sep 27 22:26:06.157: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:26:06.228: INFO: namespace replication-controller-2449 deletion completed in 22.086256143s

• [SLOW TEST:25.276 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:26:06.228: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-4216
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-4216
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep 27 22:26:06.378: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Sep 27 22:26:26.485: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.150.178:8080/dial?request=hostName&protocol=udp&host=192.168.150.177&port=8081&tries=1'] Namespace:pod-network-test-4216 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 27 22:26:26.485: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
Sep 27 22:26:26.585: INFO: Waiting for endpoints: map[]
Sep 27 22:26:26.590: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.150.178:8080/dial?request=hostName&protocol=udp&host=192.168.153.47&port=8081&tries=1'] Namespace:pod-network-test-4216 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 27 22:26:26.590: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
Sep 27 22:26:26.684: INFO: Waiting for endpoints: map[]
Sep 27 22:26:26.687: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.150.178:8080/dial?request=hostName&protocol=udp&host=192.168.151.253&port=8081&tries=1'] Namespace:pod-network-test-4216 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 27 22:26:26.687: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
Sep 27 22:26:26.771: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:26:26.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-4216" for this suite.
Sep 27 22:26:48.790: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:26:48.862: INFO: namespace pod-network-test-4216 deletion completed in 22.086914727s

• [SLOW TEST:42.634 seconds]
[sig-network] Networking
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:26:48.862: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-2469
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 27 22:26:49.014: INFO: Creating ReplicaSet my-hostname-basic-abdaa6aa-44c3-4d08-af5c-6847cc3261c4
Sep 27 22:26:49.022: INFO: Pod name my-hostname-basic-abdaa6aa-44c3-4d08-af5c-6847cc3261c4: Found 0 pods out of 1
Sep 27 22:26:54.025: INFO: Pod name my-hostname-basic-abdaa6aa-44c3-4d08-af5c-6847cc3261c4: Found 1 pods out of 1
Sep 27 22:26:54.025: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-abdaa6aa-44c3-4d08-af5c-6847cc3261c4" is running
Sep 27 22:26:54.028: INFO: Pod "my-hostname-basic-abdaa6aa-44c3-4d08-af5c-6847cc3261c4-cgwcv" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-27 22:26:49 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-27 22:26:50 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-27 22:26:50 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-27 22:26:49 +0000 UTC Reason: Message:}])
Sep 27 22:26:54.028: INFO: Trying to dial the pod
Sep 27 22:26:59.036: INFO: Controller my-hostname-basic-abdaa6aa-44c3-4d08-af5c-6847cc3261c4: Got expected result from replica 1 [my-hostname-basic-abdaa6aa-44c3-4d08-af5c-6847cc3261c4-cgwcv]: "my-hostname-basic-abdaa6aa-44c3-4d08-af5c-6847cc3261c4-cgwcv", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:26:59.036: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-2469" for this suite.
Sep 27 22:27:05.050: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:27:05.120: INFO: namespace replicaset-2469 deletion completed in 6.081151487s

• [SLOW TEST:16.258 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:27:05.120: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-4326
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 27 22:27:05.275: INFO: (0) /api/v1/nodes/macpro-1:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 4.281293ms)
Sep 27 22:27:05.278: INFO: (1) /api/v1/nodes/macpro-1:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.816196ms)
Sep 27 22:27:05.280: INFO: (2) /api/v1/nodes/macpro-1:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.537174ms)
Sep 27 22:27:05.283: INFO: (3) /api/v1/nodes/macpro-1:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.797417ms)
Sep 27 22:27:05.286: INFO: (4) /api/v1/nodes/macpro-1:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.008086ms)
Sep 27 22:27:05.289: INFO: (5) /api/v1/nodes/macpro-1:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.99665ms)
Sep 27 22:27:05.292: INFO: (6) /api/v1/nodes/macpro-1:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.922629ms)
Sep 27 22:27:05.295: INFO: (7) /api/v1/nodes/macpro-1:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.820864ms)
Sep 27 22:27:05.298: INFO: (8) /api/v1/nodes/macpro-1:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.745745ms)
Sep 27 22:27:05.301: INFO: (9) /api/v1/nodes/macpro-1:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.738938ms)
Sep 27 22:27:05.304: INFO: (10) /api/v1/nodes/macpro-1:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.957928ms)
Sep 27 22:27:05.306: INFO: (11) /api/v1/nodes/macpro-1:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.868526ms)
Sep 27 22:27:05.309: INFO: (12) /api/v1/nodes/macpro-1:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.897641ms)
Sep 27 22:27:05.312: INFO: (13) /api/v1/nodes/macpro-1:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.937189ms)
Sep 27 22:27:05.315: INFO: (14) /api/v1/nodes/macpro-1:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.98337ms)
Sep 27 22:27:05.318: INFO: (15) /api/v1/nodes/macpro-1:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.983975ms)
Sep 27 22:27:05.321: INFO: (16) /api/v1/nodes/macpro-1:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.9782ms)
Sep 27 22:27:05.324: INFO: (17) /api/v1/nodes/macpro-1:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.815802ms)
Sep 27 22:27:05.327: INFO: (18) /api/v1/nodes/macpro-1:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 3.104107ms)
Sep 27 22:27:05.330: INFO: (19) /api/v1/nodes/macpro-1:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 2.766202ms)
[AfterEach] version v1
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:27:05.330: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-4326" for this suite.
Sep 27 22:27:11.345: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:27:11.415: INFO: namespace proxy-4326 deletion completed in 6.082128368s

• [SLOW TEST:6.295 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:27:11.415: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-3396
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-3396
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating stateful set ss in namespace statefulset-3396
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-3396
Sep 27 22:27:11.583: INFO: Found 0 stateful pods, waiting for 1
Sep 27 22:27:21.586: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Sep 27 22:27:21.588: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 exec --namespace=statefulset-3396 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep 27 22:27:21.758: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep 27 22:27:21.758: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep 27 22:27:21.758: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep 27 22:27:21.761: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Sep 27 22:27:31.767: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep 27 22:27:31.767: INFO: Waiting for statefulset status.replicas updated to 0
Sep 27 22:27:31.791: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Sep 27 22:27:31.791: INFO: ss-0  macpro-2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:11 +0000 UTC  }]
Sep 27 22:27:31.791: INFO: ss-1            Pending         []
Sep 27 22:27:31.791: INFO: 
Sep 27 22:27:31.791: INFO: StatefulSet ss has not reached scale 3, at 2
Sep 27 22:27:32.794: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.992222858s
Sep 27 22:27:33.797: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.988762842s
Sep 27 22:27:34.800: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.985938546s
Sep 27 22:27:35.804: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.982648549s
Sep 27 22:27:36.807: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.979292959s
Sep 27 22:27:37.810: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.976240346s
Sep 27 22:27:38.820: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.97274144s
Sep 27 22:27:39.823: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.962855112s
Sep 27 22:27:40.826: INFO: Verifying statefulset ss doesn't scale past 3 for another 959.982355ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-3396
Sep 27 22:27:41.830: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 exec --namespace=statefulset-3396 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 27 22:27:41.997: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep 27 22:27:41.997: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep 27 22:27:41.997: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep 27 22:27:41.997: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 exec --namespace=statefulset-3396 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 27 22:27:42.146: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Sep 27 22:27:42.146: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep 27 22:27:42.146: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep 27 22:27:42.146: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 exec --namespace=statefulset-3396 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 27 22:27:42.318: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Sep 27 22:27:42.318: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep 27 22:27:42.318: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep 27 22:27:42.322: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Sep 27 22:27:52.325: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Sep 27 22:27:52.325: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Sep 27 22:27:52.325: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Sep 27 22:27:52.328: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 exec --namespace=statefulset-3396 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep 27 22:27:52.488: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep 27 22:27:52.488: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep 27 22:27:52.488: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep 27 22:27:52.488: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 exec --namespace=statefulset-3396 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep 27 22:27:52.639: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep 27 22:27:52.639: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep 27 22:27:52.639: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep 27 22:27:52.639: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 exec --namespace=statefulset-3396 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep 27 22:27:52.815: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep 27 22:27:52.815: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep 27 22:27:52.815: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep 27 22:27:52.815: INFO: Waiting for statefulset status.replicas updated to 0
Sep 27 22:27:52.817: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Sep 27 22:28:02.823: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep 27 22:28:02.823: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Sep 27 22:28:02.823: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Sep 27 22:28:02.852: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Sep 27 22:28:02.852: INFO: ss-0  macpro-2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:11 +0000 UTC  }]
Sep 27 22:28:02.852: INFO: ss-1  macpro-3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:31 +0000 UTC  }]
Sep 27 22:28:02.852: INFO: ss-2  macpro-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:31 +0000 UTC  }]
Sep 27 22:28:02.852: INFO: 
Sep 27 22:28:02.852: INFO: StatefulSet ss has not reached scale 0, at 3
Sep 27 22:28:03.856: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Sep 27 22:28:03.856: INFO: ss-0  macpro-2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:11 +0000 UTC  }]
Sep 27 22:28:03.856: INFO: ss-1  macpro-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:31 +0000 UTC  }]
Sep 27 22:28:03.856: INFO: ss-2  macpro-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:31 +0000 UTC  }]
Sep 27 22:28:03.856: INFO: 
Sep 27 22:28:03.856: INFO: StatefulSet ss has not reached scale 0, at 3
Sep 27 22:28:04.859: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Sep 27 22:28:04.859: INFO: ss-0  macpro-2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:11 +0000 UTC  }]
Sep 27 22:28:04.859: INFO: ss-1  macpro-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:31 +0000 UTC  }]
Sep 27 22:28:04.859: INFO: ss-2  macpro-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:31 +0000 UTC  }]
Sep 27 22:28:04.859: INFO: 
Sep 27 22:28:04.859: INFO: StatefulSet ss has not reached scale 0, at 3
Sep 27 22:28:05.863: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Sep 27 22:28:05.863: INFO: ss-0  macpro-2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:11 +0000 UTC  }]
Sep 27 22:28:05.863: INFO: ss-1  macpro-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:31 +0000 UTC  }]
Sep 27 22:28:05.863: INFO: ss-2  macpro-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:31 +0000 UTC  }]
Sep 27 22:28:05.863: INFO: 
Sep 27 22:28:05.863: INFO: StatefulSet ss has not reached scale 0, at 3
Sep 27 22:28:06.866: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Sep 27 22:28:06.866: INFO: ss-0  macpro-2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:11 +0000 UTC  }]
Sep 27 22:28:06.866: INFO: ss-1  macpro-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:31 +0000 UTC  }]
Sep 27 22:28:06.866: INFO: ss-2  macpro-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:31 +0000 UTC  }]
Sep 27 22:28:06.866: INFO: 
Sep 27 22:28:06.866: INFO: StatefulSet ss has not reached scale 0, at 3
Sep 27 22:28:07.869: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Sep 27 22:28:07.869: INFO: ss-0  macpro-2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:11 +0000 UTC  }]
Sep 27 22:28:07.869: INFO: ss-1  macpro-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:31 +0000 UTC  }]
Sep 27 22:28:07.869: INFO: ss-2  macpro-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:31 +0000 UTC  }]
Sep 27 22:28:07.869: INFO: 
Sep 27 22:28:07.869: INFO: StatefulSet ss has not reached scale 0, at 3
Sep 27 22:28:08.872: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Sep 27 22:28:08.872: INFO: ss-0  macpro-2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:11 +0000 UTC  }]
Sep 27 22:28:08.872: INFO: ss-1  macpro-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:31 +0000 UTC  }]
Sep 27 22:28:08.872: INFO: ss-2  macpro-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:31 +0000 UTC  }]
Sep 27 22:28:08.872: INFO: 
Sep 27 22:28:08.872: INFO: StatefulSet ss has not reached scale 0, at 3
Sep 27 22:28:09.876: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Sep 27 22:28:09.876: INFO: ss-0  macpro-2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:11 +0000 UTC  }]
Sep 27 22:28:09.876: INFO: ss-1  macpro-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:31 +0000 UTC  }]
Sep 27 22:28:09.876: INFO: ss-2  macpro-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:31 +0000 UTC  }]
Sep 27 22:28:09.876: INFO: 
Sep 27 22:28:09.876: INFO: StatefulSet ss has not reached scale 0, at 3
Sep 27 22:28:10.879: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Sep 27 22:28:10.879: INFO: ss-0  macpro-2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:52 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:11 +0000 UTC  }]
Sep 27 22:28:10.879: INFO: ss-1  macpro-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:31 +0000 UTC  }]
Sep 27 22:28:10.879: INFO: ss-2  macpro-1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:53 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:27:31 +0000 UTC  }]
Sep 27 22:28:10.879: INFO: 
Sep 27 22:28:10.879: INFO: StatefulSet ss has not reached scale 0, at 3
Sep 27 22:28:11.882: INFO: Verifying statefulset ss doesn't scale past 0 for another 955.215468ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-3396
Sep 27 22:28:12.885: INFO: Scaling statefulset ss to 0
Sep 27 22:28:12.892: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Sep 27 22:28:12.894: INFO: Deleting all statefulset in ns statefulset-3396
Sep 27 22:28:12.896: INFO: Scaling statefulset ss to 0
Sep 27 22:28:12.903: INFO: Waiting for statefulset status.replicas updated to 0
Sep 27 22:28:12.905: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:28:12.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3396" for this suite.
Sep 27 22:28:18.931: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:28:19.004: INFO: namespace statefulset-3396 deletion completed in 6.084384521s

• [SLOW TEST:67.589 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:28:19.004: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-9103
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:28:19.205: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9103" for this suite.
Sep 27 22:28:25.219: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:28:25.295: INFO: namespace kubelet-test-9103 deletion completed in 6.086713104s

• [SLOW TEST:6.290 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:28:25.295: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9859
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating Redis RC
Sep 27 22:28:25.441: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 create -f - --namespace=kubectl-9859'
Sep 27 22:28:25.636: INFO: stderr: ""
Sep 27 22:28:25.636: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Sep 27 22:28:26.640: INFO: Selector matched 1 pods for map[app:redis]
Sep 27 22:28:26.640: INFO: Found 0 / 1
Sep 27 22:28:27.640: INFO: Selector matched 1 pods for map[app:redis]
Sep 27 22:28:27.640: INFO: Found 1 / 1
Sep 27 22:28:27.640: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Sep 27 22:28:27.642: INFO: Selector matched 1 pods for map[app:redis]
Sep 27 22:28:27.642: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Sep 27 22:28:27.642: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 patch pod redis-master-z9khh --namespace=kubectl-9859 -p {"metadata":{"annotations":{"x":"y"}}}'
Sep 27 22:28:27.711: INFO: stderr: ""
Sep 27 22:28:27.711: INFO: stdout: "pod/redis-master-z9khh patched\n"
STEP: checking annotations
Sep 27 22:28:27.714: INFO: Selector matched 1 pods for map[app:redis]
Sep 27 22:28:27.714: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:28:27.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9859" for this suite.
Sep 27 22:28:49.727: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:28:49.797: INFO: namespace kubectl-9859 deletion completed in 22.081083208s

• [SLOW TEST:24.502 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl patch
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:28:49.798: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4651
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Sep 27 22:28:49.966: INFO: Waiting up to 5m0s for pod "downward-api-9231dd13-43e4-401f-94be-2ff203126a3f" in namespace "downward-api-4651" to be "success or failure"
Sep 27 22:28:49.968: INFO: Pod "downward-api-9231dd13-43e4-401f-94be-2ff203126a3f": Phase="Pending", Reason="", readiness=false. Elapsed: 1.794968ms
Sep 27 22:28:51.971: INFO: Pod "downward-api-9231dd13-43e4-401f-94be-2ff203126a3f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00468462s
Sep 27 22:28:53.974: INFO: Pod "downward-api-9231dd13-43e4-401f-94be-2ff203126a3f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007315269s
STEP: Saw pod success
Sep 27 22:28:53.974: INFO: Pod "downward-api-9231dd13-43e4-401f-94be-2ff203126a3f" satisfied condition "success or failure"
Sep 27 22:28:53.976: INFO: Trying to get logs from node macpro-1 pod downward-api-9231dd13-43e4-401f-94be-2ff203126a3f container dapi-container: <nil>
STEP: delete the pod
Sep 27 22:28:54.001: INFO: Waiting for pod downward-api-9231dd13-43e4-401f-94be-2ff203126a3f to disappear
Sep 27 22:28:54.002: INFO: Pod downward-api-9231dd13-43e4-401f-94be-2ff203126a3f no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:28:54.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4651" for this suite.
Sep 27 22:29:00.017: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:29:00.089: INFO: namespace downward-api-4651 deletion completed in 6.083618699s

• [SLOW TEST:10.291 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:29:00.089: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-3486
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating service endpoint-test2 in namespace services-3486
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3486 to expose endpoints map[]
Sep 27 22:29:00.265: INFO: successfully validated that service endpoint-test2 in namespace services-3486 exposes endpoints map[] (1.837952ms elapsed)
STEP: Creating pod pod1 in namespace services-3486
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3486 to expose endpoints map[pod1:[80]]
Sep 27 22:29:02.296: INFO: successfully validated that service endpoint-test2 in namespace services-3486 exposes endpoints map[pod1:[80]] (2.017659055s elapsed)
STEP: Creating pod pod2 in namespace services-3486
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3486 to expose endpoints map[pod1:[80] pod2:[80]]
Sep 27 22:29:04.332: INFO: successfully validated that service endpoint-test2 in namespace services-3486 exposes endpoints map[pod1:[80] pod2:[80]] (2.029144102s elapsed)
STEP: Deleting pod pod1 in namespace services-3486
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3486 to expose endpoints map[pod2:[80]]
Sep 27 22:29:04.356: INFO: successfully validated that service endpoint-test2 in namespace services-3486 exposes endpoints map[pod2:[80]] (12.403131ms elapsed)
STEP: Deleting pod pod2 in namespace services-3486
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3486 to expose endpoints map[]
Sep 27 22:29:05.374: INFO: successfully validated that service endpoint-test2 in namespace services-3486 exposes endpoints map[] (1.010622383s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:29:05.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3486" for this suite.
Sep 27 22:29:11.427: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:29:11.504: INFO: namespace services-3486 deletion completed in 6.088458623s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:11.415 seconds]
[sig-network] Services
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:29:11.504: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-3083
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-3083
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep 27 22:29:11.652: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Sep 27 22:29:35.761: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.151.199 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3083 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 27 22:29:35.761: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
Sep 27 22:29:36.840: INFO: Found all expected endpoints: [netserver-0]
Sep 27 22:29:36.842: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.150.181 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3083 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 27 22:29:36.843: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
Sep 27 22:29:37.922: INFO: Found all expected endpoints: [netserver-1]
Sep 27 22:29:37.924: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.153.51 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3083 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 27 22:29:37.924: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
Sep 27 22:29:39.003: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:29:39.003: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3083" for this suite.
Sep 27 22:30:01.018: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:30:01.091: INFO: namespace pod-network-test-3083 deletion completed in 22.084157996s

• [SLOW TEST:49.586 seconds]
[sig-network] Networking
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:30:01.091: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-3259
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod liveness-f907f58c-cf0a-43a8-b35f-6a8b88059ce4 in namespace container-probe-3259
Sep 27 22:30:03.253: INFO: Started pod liveness-f907f58c-cf0a-43a8-b35f-6a8b88059ce4 in namespace container-probe-3259
STEP: checking the pod's current state and verifying that restartCount is present
Sep 27 22:30:03.255: INFO: Initial restart count of pod liveness-f907f58c-cf0a-43a8-b35f-6a8b88059ce4 is 0
Sep 27 22:30:21.287: INFO: Restart count of pod container-probe-3259/liveness-f907f58c-cf0a-43a8-b35f-6a8b88059ce4 is now 1 (18.031956986s elapsed)
Sep 27 22:30:41.313: INFO: Restart count of pod container-probe-3259/liveness-f907f58c-cf0a-43a8-b35f-6a8b88059ce4 is now 2 (38.058268687s elapsed)
Sep 27 22:30:59.338: INFO: Restart count of pod container-probe-3259/liveness-f907f58c-cf0a-43a8-b35f-6a8b88059ce4 is now 3 (56.082862284s elapsed)
Sep 27 22:31:19.365: INFO: Restart count of pod container-probe-3259/liveness-f907f58c-cf0a-43a8-b35f-6a8b88059ce4 is now 4 (1m16.110151596s elapsed)
Sep 27 22:32:25.464: INFO: Restart count of pod container-probe-3259/liveness-f907f58c-cf0a-43a8-b35f-6a8b88059ce4 is now 5 (2m22.208587718s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:32:25.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3259" for this suite.
Sep 27 22:32:31.502: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:32:31.582: INFO: namespace container-probe-3259 deletion completed in 6.092431048s

• [SLOW TEST:150.491 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:32:31.582: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-9636
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-459
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-2729
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:32:38.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-9636" for this suite.
Sep 27 22:32:44.080: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:32:44.153: INFO: namespace namespaces-9636 deletion completed in 6.084846892s
STEP: Destroying namespace "nsdeletetest-459" for this suite.
Sep 27 22:32:44.155: INFO: Namespace nsdeletetest-459 was already deleted
STEP: Destroying namespace "nsdeletetest-2729" for this suite.
Sep 27 22:32:50.170: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:32:50.252: INFO: namespace nsdeletetest-2729 deletion completed in 6.097154246s

• [SLOW TEST:18.670 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:32:50.252: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5460
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on node default medium
Sep 27 22:32:50.411: INFO: Waiting up to 5m0s for pod "pod-907c03e8-bfd2-476e-b7bb-b0dbc3fe3910" in namespace "emptydir-5460" to be "success or failure"
Sep 27 22:32:50.413: INFO: Pod "pod-907c03e8-bfd2-476e-b7bb-b0dbc3fe3910": Phase="Pending", Reason="", readiness=false. Elapsed: 1.846753ms
Sep 27 22:32:52.416: INFO: Pod "pod-907c03e8-bfd2-476e-b7bb-b0dbc3fe3910": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004820821s
STEP: Saw pod success
Sep 27 22:32:52.416: INFO: Pod "pod-907c03e8-bfd2-476e-b7bb-b0dbc3fe3910" satisfied condition "success or failure"
Sep 27 22:32:52.418: INFO: Trying to get logs from node macpro-1 pod pod-907c03e8-bfd2-476e-b7bb-b0dbc3fe3910 container test-container: <nil>
STEP: delete the pod
Sep 27 22:32:52.442: INFO: Waiting for pod pod-907c03e8-bfd2-476e-b7bb-b0dbc3fe3910 to disappear
Sep 27 22:32:52.444: INFO: Pod pod-907c03e8-bfd2-476e-b7bb-b0dbc3fe3910 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:32:52.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5460" for this suite.
Sep 27 22:32:58.458: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:32:58.528: INFO: namespace emptydir-5460 deletion completed in 6.082292276s

• [SLOW TEST:8.276 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:32:58.529: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-3149
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Sep 27 22:33:08.785: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0927 22:33:08.785941      18 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:33:08.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3149" for this suite.
Sep 27 22:33:14.800: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:33:14.876: INFO: namespace gc-3149 deletion completed in 6.088027444s

• [SLOW TEST:16.348 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:33:14.877: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-1724
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Sep 27 22:33:17.047: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:33:17.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1724" for this suite.
Sep 27 22:33:23.086: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:33:23.160: INFO: namespace container-runtime-1724 deletion completed in 6.091587845s

• [SLOW TEST:8.284 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:33:23.160: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7162
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on tmpfs
Sep 27 22:33:23.317: INFO: Waiting up to 5m0s for pod "pod-669ac78b-3115-41cb-a261-6c7bfa916477" in namespace "emptydir-7162" to be "success or failure"
Sep 27 22:33:23.318: INFO: Pod "pod-669ac78b-3115-41cb-a261-6c7bfa916477": Phase="Pending", Reason="", readiness=false. Elapsed: 1.78341ms
Sep 27 22:33:25.321: INFO: Pod "pod-669ac78b-3115-41cb-a261-6c7bfa916477": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004510248s
STEP: Saw pod success
Sep 27 22:33:25.321: INFO: Pod "pod-669ac78b-3115-41cb-a261-6c7bfa916477" satisfied condition "success or failure"
Sep 27 22:33:25.324: INFO: Trying to get logs from node macpro-1 pod pod-669ac78b-3115-41cb-a261-6c7bfa916477 container test-container: <nil>
STEP: delete the pod
Sep 27 22:33:25.348: INFO: Waiting for pod pod-669ac78b-3115-41cb-a261-6c7bfa916477 to disappear
Sep 27 22:33:25.350: INFO: Pod pod-669ac78b-3115-41cb-a261-6c7bfa916477 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:33:25.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7162" for this suite.
Sep 27 22:33:31.364: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:33:31.434: INFO: namespace emptydir-7162 deletion completed in 6.080831445s

• [SLOW TEST:8.273 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:33:31.434: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-3596
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Sep 27 22:33:35.629: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep 27 22:33:35.631: INFO: Pod pod-with-prestop-http-hook still exists
Sep 27 22:33:37.632: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep 27 22:33:37.635: INFO: Pod pod-with-prestop-http-hook still exists
Sep 27 22:33:39.632: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep 27 22:33:39.634: INFO: Pod pod-with-prestop-http-hook still exists
Sep 27 22:33:41.632: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep 27 22:33:41.635: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:33:41.642: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-3596" for this suite.
Sep 27 22:34:03.657: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:34:03.731: INFO: namespace container-lifecycle-hook-3596 deletion completed in 22.085856053s

• [SLOW TEST:32.297 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:34:03.731: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8596
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Sep 27 22:34:03.895: INFO: Waiting up to 5m0s for pod "downward-api-45734b5e-96e8-4063-a327-eedd701bf513" in namespace "downward-api-8596" to be "success or failure"
Sep 27 22:34:03.897: INFO: Pod "downward-api-45734b5e-96e8-4063-a327-eedd701bf513": Phase="Pending", Reason="", readiness=false. Elapsed: 1.989453ms
Sep 27 22:34:05.900: INFO: Pod "downward-api-45734b5e-96e8-4063-a327-eedd701bf513": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004592206s
STEP: Saw pod success
Sep 27 22:34:05.900: INFO: Pod "downward-api-45734b5e-96e8-4063-a327-eedd701bf513" satisfied condition "success or failure"
Sep 27 22:34:05.902: INFO: Trying to get logs from node macpro-1 pod downward-api-45734b5e-96e8-4063-a327-eedd701bf513 container dapi-container: <nil>
STEP: delete the pod
Sep 27 22:34:05.930: INFO: Waiting for pod downward-api-45734b5e-96e8-4063-a327-eedd701bf513 to disappear
Sep 27 22:34:05.932: INFO: Pod downward-api-45734b5e-96e8-4063-a327-eedd701bf513 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:34:05.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8596" for this suite.
Sep 27 22:34:11.946: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:34:12.024: INFO: namespace downward-api-8596 deletion completed in 6.089718487s

• [SLOW TEST:8.293 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:34:12.025: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-5832
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Sep 27 22:34:12.214: INFO: Number of nodes with available pods: 0
Sep 27 22:34:12.214: INFO: Node macpro-1 is running more than one daemon pod
Sep 27 22:34:13.229: INFO: Number of nodes with available pods: 0
Sep 27 22:34:13.229: INFO: Node macpro-1 is running more than one daemon pod
Sep 27 22:34:14.220: INFO: Number of nodes with available pods: 2
Sep 27 22:34:14.220: INFO: Node macpro-2 is running more than one daemon pod
Sep 27 22:34:15.219: INFO: Number of nodes with available pods: 3
Sep 27 22:34:15.219: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Sep 27 22:34:15.241: INFO: Number of nodes with available pods: 3
Sep 27 22:34:15.241: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5832, will wait for the garbage collector to delete the pods
Sep 27 22:34:16.318: INFO: Deleting DaemonSet.extensions daemon-set took: 15.616816ms
Sep 27 22:34:16.618: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.17317ms
Sep 27 22:34:31.520: INFO: Number of nodes with available pods: 0
Sep 27 22:34:31.520: INFO: Number of running nodes: 0, number of available pods: 0
Sep 27 22:34:31.522: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-5832/daemonsets","resourceVersion":"7637371"},"items":null}

Sep 27 22:34:31.524: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-5832/pods","resourceVersion":"7637371"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:34:31.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5832" for this suite.
Sep 27 22:34:37.549: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:34:37.622: INFO: namespace daemonsets-5832 deletion completed in 6.084967872s

• [SLOW TEST:25.597 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:34:37.622: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-1600
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Sep 27 22:34:41.843: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep 27 22:34:41.845: INFO: Pod pod-with-poststart-http-hook still exists
Sep 27 22:34:43.846: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep 27 22:34:43.848: INFO: Pod pod-with-poststart-http-hook still exists
Sep 27 22:34:45.846: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep 27 22:34:45.848: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:34:45.848: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-1600" for this suite.
Sep 27 22:35:07.862: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:35:07.935: INFO: namespace container-lifecycle-hook-1600 deletion completed in 22.083968731s

• [SLOW TEST:30.313 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:35:07.935: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8108
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-ddbe6350-7202-485f-881a-39e0a03e7692
STEP: Creating a pod to test consume secrets
Sep 27 22:35:08.105: INFO: Waiting up to 5m0s for pod "pod-secrets-62f02a50-09d3-41fa-b2d8-60c4b6185530" in namespace "secrets-8108" to be "success or failure"
Sep 27 22:35:08.107: INFO: Pod "pod-secrets-62f02a50-09d3-41fa-b2d8-60c4b6185530": Phase="Pending", Reason="", readiness=false. Elapsed: 1.961027ms
Sep 27 22:35:10.109: INFO: Pod "pod-secrets-62f02a50-09d3-41fa-b2d8-60c4b6185530": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004658651s
STEP: Saw pod success
Sep 27 22:35:10.109: INFO: Pod "pod-secrets-62f02a50-09d3-41fa-b2d8-60c4b6185530" satisfied condition "success or failure"
Sep 27 22:35:10.112: INFO: Trying to get logs from node macpro-1 pod pod-secrets-62f02a50-09d3-41fa-b2d8-60c4b6185530 container secret-env-test: <nil>
STEP: delete the pod
Sep 27 22:35:10.132: INFO: Waiting for pod pod-secrets-62f02a50-09d3-41fa-b2d8-60c4b6185530 to disappear
Sep 27 22:35:10.134: INFO: Pod pod-secrets-62f02a50-09d3-41fa-b2d8-60c4b6185530 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:35:10.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8108" for this suite.
Sep 27 22:35:16.148: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:35:16.221: INFO: namespace secrets-8108 deletion completed in 6.084212765s

• [SLOW TEST:8.286 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:35:16.221: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-6459
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 27 22:35:16.368: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:35:17.417: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-6459" for this suite.
Sep 27 22:35:23.432: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:35:23.515: INFO: namespace custom-resource-definition-6459 deletion completed in 6.093982989s

• [SLOW TEST:7.293 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:35:23.515: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-3502
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Sep 27 22:35:25.695: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-741451867 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Sep 27 22:35:35.760: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:35:35.762: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3502" for this suite.
Sep 27 22:35:41.779: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:35:41.853: INFO: namespace pods-3502 deletion completed in 6.088801131s

• [SLOW TEST:18.339 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be submitted and removed [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:35:41.854: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8513
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-map-196f4ecb-032e-441c-a52d-4843fbeb3574
STEP: Creating a pod to test consume secrets
Sep 27 22:35:42.024: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b0dc916c-3554-44b5-a5c0-667f8bd1e0b3" in namespace "projected-8513" to be "success or failure"
Sep 27 22:35:42.025: INFO: Pod "pod-projected-secrets-b0dc916c-3554-44b5-a5c0-667f8bd1e0b3": Phase="Pending", Reason="", readiness=false. Elapsed: 1.894298ms
Sep 27 22:35:44.028: INFO: Pod "pod-projected-secrets-b0dc916c-3554-44b5-a5c0-667f8bd1e0b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004796018s
STEP: Saw pod success
Sep 27 22:35:44.028: INFO: Pod "pod-projected-secrets-b0dc916c-3554-44b5-a5c0-667f8bd1e0b3" satisfied condition "success or failure"
Sep 27 22:35:44.031: INFO: Trying to get logs from node macpro-3 pod pod-projected-secrets-b0dc916c-3554-44b5-a5c0-667f8bd1e0b3 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep 27 22:35:44.061: INFO: Waiting for pod pod-projected-secrets-b0dc916c-3554-44b5-a5c0-667f8bd1e0b3 to disappear
Sep 27 22:35:44.071: INFO: Pod pod-projected-secrets-b0dc916c-3554-44b5-a5c0-667f8bd1e0b3 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:35:44.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8513" for this suite.
Sep 27 22:35:50.085: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:35:50.157: INFO: namespace projected-8513 deletion completed in 6.083361777s

• [SLOW TEST:8.303 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:35:50.157: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-4385
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 27 22:35:50.310: INFO: Pod name rollover-pod: Found 0 pods out of 1
Sep 27 22:35:55.312: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Sep 27 22:35:55.312: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Sep 27 22:35:57.315: INFO: Creating deployment "test-rollover-deployment"
Sep 27 22:35:57.324: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Sep 27 22:35:59.329: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Sep 27 22:35:59.334: INFO: Ensure that both replica sets have 1 created replica
Sep 27 22:35:59.339: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Sep 27 22:35:59.347: INFO: Updating deployment test-rollover-deployment
Sep 27 22:35:59.347: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Sep 27 22:36:01.359: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Sep 27 22:36:01.363: INFO: Make sure deployment "test-rollover-deployment" is complete
Sep 27 22:36:01.369: INFO: all replica sets need to contain the pod-template-hash label
Sep 27 22:36:01.369: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705220557, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705220557, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705220561, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705220557, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 27 22:36:03.375: INFO: all replica sets need to contain the pod-template-hash label
Sep 27 22:36:03.375: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705220557, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705220557, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705220561, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705220557, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 27 22:36:05.375: INFO: all replica sets need to contain the pod-template-hash label
Sep 27 22:36:05.375: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705220557, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705220557, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705220561, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705220557, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 27 22:36:07.375: INFO: all replica sets need to contain the pod-template-hash label
Sep 27 22:36:07.375: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705220557, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705220557, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705220561, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705220557, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 27 22:36:09.375: INFO: all replica sets need to contain the pod-template-hash label
Sep 27 22:36:09.375: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705220557, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705220557, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63705220561, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63705220557, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 27 22:36:11.375: INFO: 
Sep 27 22:36:11.375: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Sep 27 22:36:11.381: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-4385,SelfLink:/apis/apps/v1/namespaces/deployment-4385/deployments/test-rollover-deployment,UID:ea0621e1-ea39-4803-9110-1376c91a5f64,ResourceVersion:7637844,Generation:2,CreationTimestamp:2019-09-27 22:35:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-09-27 22:35:57 +0000 UTC 2019-09-27 22:35:57 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-09-27 22:36:11 +0000 UTC 2019-09-27 22:35:57 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-854595fc44" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Sep 27 22:36:11.384: INFO: New ReplicaSet "test-rollover-deployment-854595fc44" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-854595fc44,GenerateName:,Namespace:deployment-4385,SelfLink:/apis/apps/v1/namespaces/deployment-4385/replicasets/test-rollover-deployment-854595fc44,UID:3843de61-470e-47d9-8f0a-f973fed5a4d1,ResourceVersion:7637833,Generation:2,CreationTimestamp:2019-09-27 22:35:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment ea0621e1-ea39-4803-9110-1376c91a5f64 0xc00312d737 0xc00312d738}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Sep 27 22:36:11.384: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Sep 27 22:36:11.384: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-4385,SelfLink:/apis/apps/v1/namespaces/deployment-4385/replicasets/test-rollover-controller,UID:06b8d230-7ca9-4870-a85b-9aa35d21104d,ResourceVersion:7637842,Generation:2,CreationTimestamp:2019-09-27 22:35:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment ea0621e1-ea39-4803-9110-1376c91a5f64 0xc00312d667 0xc00312d668}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep 27 22:36:11.384: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-9b8b997cf,GenerateName:,Namespace:deployment-4385,SelfLink:/apis/apps/v1/namespaces/deployment-4385/replicasets/test-rollover-deployment-9b8b997cf,UID:f43fbacf-02d9-4820-b40c-db8fc42b2c79,ResourceVersion:7637796,Generation:2,CreationTimestamp:2019-09-27 22:35:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment ea0621e1-ea39-4803-9110-1376c91a5f64 0xc00312d800 0xc00312d801}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep 27 22:36:11.386: INFO: Pod "test-rollover-deployment-854595fc44-lghhd" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-854595fc44-lghhd,GenerateName:test-rollover-deployment-854595fc44-,Namespace:deployment-4385,SelfLink:/api/v1/namespaces/deployment-4385/pods/test-rollover-deployment-854595fc44-lghhd,UID:2f8bb6cf-06b2-49db-bd47-e92422acf48a,ResourceVersion:7637814,Generation:0,CreationTimestamp:2019-09-27 22:35:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{cni.projectcalico.org/podIP: 192.168.153.61/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-854595fc44 3843de61-470e-47d9-8f0a-f973fed5a4d1 0xc0034f4407 0xc0034f4408}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-d9nxz {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-d9nxz,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-d9nxz true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:macpro-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0034f4480} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0034f44a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:35:59 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:36:01 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:36:01 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-27 22:35:59 +0000 UTC  }],Message:,Reason:,HostIP:10.10.10.6,PodIP:192.168.153.61,StartTime:2019-09-27 22:35:59 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-09-27 22:36:00 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://b62ace632550fac0c691a5c741acc25d8307a947a2d322b9db325ab202d2c136}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:36:11.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4385" for this suite.
Sep 27 22:36:17.401: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:36:17.471: INFO: namespace deployment-4385 deletion completed in 6.082392126s

• [SLOW TEST:27.314 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:36:17.471: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3089
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-14ffff3d-a4a0-41a0-bb76-395a1f5db815
STEP: Creating a pod to test consume secrets
Sep 27 22:36:17.638: INFO: Waiting up to 5m0s for pod "pod-secrets-15c620aa-c95d-4fef-b969-7a0dd8d910c4" in namespace "secrets-3089" to be "success or failure"
Sep 27 22:36:17.640: INFO: Pod "pod-secrets-15c620aa-c95d-4fef-b969-7a0dd8d910c4": Phase="Pending", Reason="", readiness=false. Elapsed: 1.817004ms
Sep 27 22:36:19.643: INFO: Pod "pod-secrets-15c620aa-c95d-4fef-b969-7a0dd8d910c4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004461599s
STEP: Saw pod success
Sep 27 22:36:19.643: INFO: Pod "pod-secrets-15c620aa-c95d-4fef-b969-7a0dd8d910c4" satisfied condition "success or failure"
Sep 27 22:36:19.645: INFO: Trying to get logs from node macpro-1 pod pod-secrets-15c620aa-c95d-4fef-b969-7a0dd8d910c4 container secret-volume-test: <nil>
STEP: delete the pod
Sep 27 22:36:19.668: INFO: Waiting for pod pod-secrets-15c620aa-c95d-4fef-b969-7a0dd8d910c4 to disappear
Sep 27 22:36:19.670: INFO: Pod pod-secrets-15c620aa-c95d-4fef-b969-7a0dd8d910c4 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:36:19.670: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3089" for this suite.
Sep 27 22:36:25.684: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:36:25.755: INFO: namespace secrets-3089 deletion completed in 6.082369668s

• [SLOW TEST:8.284 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:36:25.755: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-6816
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Sep 27 22:36:25.926: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-6816,SelfLink:/api/v1/namespaces/watch-6816/configmaps/e2e-watch-test-label-changed,UID:d4d7d8d5-4341-4cdb-932f-e07485249f65,ResourceVersion:7637953,Generation:0,CreationTimestamp:2019-09-27 22:36:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep 27 22:36:25.926: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-6816,SelfLink:/api/v1/namespaces/watch-6816/configmaps/e2e-watch-test-label-changed,UID:d4d7d8d5-4341-4cdb-932f-e07485249f65,ResourceVersion:7637954,Generation:0,CreationTimestamp:2019-09-27 22:36:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Sep 27 22:36:25.926: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-6816,SelfLink:/api/v1/namespaces/watch-6816/configmaps/e2e-watch-test-label-changed,UID:d4d7d8d5-4341-4cdb-932f-e07485249f65,ResourceVersion:7637955,Generation:0,CreationTimestamp:2019-09-27 22:36:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Sep 27 22:36:35.961: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-6816,SelfLink:/api/v1/namespaces/watch-6816/configmaps/e2e-watch-test-label-changed,UID:d4d7d8d5-4341-4cdb-932f-e07485249f65,ResourceVersion:7637976,Generation:0,CreationTimestamp:2019-09-27 22:36:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep 27 22:36:35.961: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-6816,SelfLink:/api/v1/namespaces/watch-6816/configmaps/e2e-watch-test-label-changed,UID:d4d7d8d5-4341-4cdb-932f-e07485249f65,ResourceVersion:7637977,Generation:0,CreationTimestamp:2019-09-27 22:36:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Sep 27 22:36:35.961: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-6816,SelfLink:/api/v1/namespaces/watch-6816/configmaps/e2e-watch-test-label-changed,UID:d4d7d8d5-4341-4cdb-932f-e07485249f65,ResourceVersion:7637978,Generation:0,CreationTimestamp:2019-09-27 22:36:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:36:35.961: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6816" for this suite.
Sep 27 22:36:41.976: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:36:42.046: INFO: namespace watch-6816 deletion completed in 6.082278284s

• [SLOW TEST:16.291 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:36:42.047: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-9047
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:36:42.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9047" for this suite.
Sep 27 22:36:48.215: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:36:48.287: INFO: namespace services-9047 deletion completed in 6.086253938s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:6.240 seconds]
[sig-network] Services
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide secure master service  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:36:48.287: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7739
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep 27 22:36:48.449: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d5b6ade4-e006-4b9d-ab4b-558fb3c0c27d" in namespace "downward-api-7739" to be "success or failure"
Sep 27 22:36:48.456: INFO: Pod "downwardapi-volume-d5b6ade4-e006-4b9d-ab4b-558fb3c0c27d": Phase="Pending", Reason="", readiness=false. Elapsed: 7.234782ms
Sep 27 22:36:50.459: INFO: Pod "downwardapi-volume-d5b6ade4-e006-4b9d-ab4b-558fb3c0c27d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009887378s
STEP: Saw pod success
Sep 27 22:36:50.459: INFO: Pod "downwardapi-volume-d5b6ade4-e006-4b9d-ab4b-558fb3c0c27d" satisfied condition "success or failure"
Sep 27 22:36:50.461: INFO: Trying to get logs from node macpro-2 pod downwardapi-volume-d5b6ade4-e006-4b9d-ab4b-558fb3c0c27d container client-container: <nil>
STEP: delete the pod
Sep 27 22:36:50.485: INFO: Waiting for pod downwardapi-volume-d5b6ade4-e006-4b9d-ab4b-558fb3c0c27d to disappear
Sep 27 22:36:50.486: INFO: Pod downwardapi-volume-d5b6ade4-e006-4b9d-ab4b-558fb3c0c27d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:36:50.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7739" for this suite.
Sep 27 22:36:56.500: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:36:56.570: INFO: namespace downward-api-7739 deletion completed in 6.080481942s

• [SLOW TEST:8.283 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:36:56.570: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-1029
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Sep 27 22:36:56.723: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep 27 22:36:56.729: INFO: Waiting for terminating namespaces to be deleted...
Sep 27 22:36:56.731: INFO: 
Logging pods the kubelet thinks is on node macpro-1 before test
Sep 27 22:36:56.737: INFO: speaker-msvrw from metallb-system started at 2019-08-08 02:15:42 +0000 UTC (1 container statuses recorded)
Sep 27 22:36:56.737: INFO: 	Container speaker ready: true, restart count 0
Sep 27 22:36:56.737: INFO: sonobuoy-systemd-logs-daemon-set-3ff1c1a60c394bba-c5zcw from sonobuoy started at 2019-09-27 21:16:41 +0000 UTC (2 container statuses recorded)
Sep 27 22:36:56.737: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Sep 27 22:36:56.737: INFO: 	Container systemd-logs ready: true, restart count 1
Sep 27 22:36:56.737: INFO: coredns-5c98db65d4-9bgxc from kube-system started at 2019-08-08 01:50:51 +0000 UTC (1 container statuses recorded)
Sep 27 22:36:56.737: INFO: 	Container coredns ready: true, restart count 7
Sep 27 22:36:56.737: INFO: controller-55d74449-q2f47 from metallb-system started at 2019-08-08 02:15:42 +0000 UTC (1 container statuses recorded)
Sep 27 22:36:56.737: INFO: 	Container controller ready: true, restart count 0
Sep 27 22:36:56.737: INFO: rethinkdb-57544557d7-kssqr from default started at 2019-08-08 17:32:36 +0000 UTC (1 container statuses recorded)
Sep 27 22:36:56.737: INFO: 	Container rethinkdb ready: true, restart count 0
Sep 27 22:36:56.737: INFO: kube-scheduler-macpro-1 from kube-system started at 2019-08-13 03:43:55 +0000 UTC (1 container statuses recorded)
Sep 27 22:36:56.737: INFO: 	Container kube-scheduler ready: true, restart count 9
Sep 27 22:36:56.737: INFO: orka-5c9d6bfc94-rxjt9 from default started at 2019-09-27 20:09:01 +0000 UTC (1 container statuses recorded)
Sep 27 22:36:56.737: INFO: 	Container orka ready: true, restart count 0
Sep 27 22:36:56.737: INFO: coredns-5c98db65d4-hxb4g from kube-system started at 2019-08-08 01:50:47 +0000 UTC (1 container statuses recorded)
Sep 27 22:36:56.737: INFO: 	Container coredns ready: true, restart count 7
Sep 27 22:36:56.737: INFO: calico-node-6vk4s from kube-system started at 2019-08-08 02:05:40 +0000 UTC (1 container statuses recorded)
Sep 27 22:36:56.737: INFO: 	Container calico-node ready: true, restart count 0
Sep 27 22:36:56.737: INFO: kube-apiserver-macpro-1 from kube-system started at 2019-08-13 03:41:36 +0000 UTC (1 container statuses recorded)
Sep 27 22:36:56.737: INFO: 	Container kube-apiserver ready: true, restart count 0
Sep 27 22:36:56.737: INFO: kube-proxy-zgndg from kube-system started at 2019-08-08 01:50:37 +0000 UTC (1 container statuses recorded)
Sep 27 22:36:56.737: INFO: 	Container kube-proxy ready: true, restart count 0
Sep 27 22:36:56.737: INFO: etcd-macpro-1 from kube-system started at 2019-08-13 03:43:55 +0000 UTC (1 container statuses recorded)
Sep 27 22:36:56.737: INFO: 	Container etcd ready: true, restart count 0
Sep 27 22:36:56.737: INFO: kube-controller-manager-macpro-1 from kube-system started at 2019-08-08 01:50:11 +0000 UTC (1 container statuses recorded)
Sep 27 22:36:56.737: INFO: 	Container kube-controller-manager ready: true, restart count 8
Sep 27 22:36:56.737: INFO: calico-kube-controllers-7bd78b474d-t2lgl from kube-system started at 2019-08-08 02:05:40 +0000 UTC (1 container statuses recorded)
Sep 27 22:36:56.737: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Sep 27 22:36:56.737: INFO: 
Logging pods the kubelet thinks is on node macpro-2 before test
Sep 27 22:36:56.743: INFO: calico-node-7tmv4 from kube-system started at 2019-08-08 02:20:59 +0000 UTC (1 container statuses recorded)
Sep 27 22:36:56.743: INFO: 	Container calico-node ready: true, restart count 0
Sep 27 22:36:56.743: INFO: kube-proxy-s7hbl from kube-system started at 2019-08-08 02:20:59 +0000 UTC (1 container statuses recorded)
Sep 27 22:36:56.743: INFO: 	Container kube-proxy ready: true, restart count 0
Sep 27 22:36:56.743: INFO: speaker-w9jlq from metallb-system started at 2019-08-11 23:04:22 +0000 UTC (1 container statuses recorded)
Sep 27 22:36:56.743: INFO: 	Container speaker ready: true, restart count 0
Sep 27 22:36:56.743: INFO: kube-apiserver-macpro-2 from kube-system started at 2019-08-13 03:41:23 +0000 UTC (1 container statuses recorded)
Sep 27 22:36:56.743: INFO: 	Container kube-apiserver ready: true, restart count 0
Sep 27 22:36:56.743: INFO: kube-controller-manager-macpro-2 from kube-system started at 2019-08-08 02:20:59 +0000 UTC (1 container statuses recorded)
Sep 27 22:36:56.743: INFO: 	Container kube-controller-manager ready: true, restart count 1
Sep 27 22:36:56.743: INFO: etcd-macpro-2 from kube-system started at 2019-08-08 02:20:59 +0000 UTC (1 container statuses recorded)
Sep 27 22:36:56.743: INFO: 	Container etcd ready: true, restart count 0
Sep 27 22:36:56.743: INFO: sonobuoy from sonobuoy started at 2019-09-27 21:15:55 +0000 UTC (1 container statuses recorded)
Sep 27 22:36:56.743: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Sep 27 22:36:56.743: INFO: sonobuoy-systemd-logs-daemon-set-3ff1c1a60c394bba-rcrrv from sonobuoy started at 2019-09-27 21:16:41 +0000 UTC (2 container statuses recorded)
Sep 27 22:36:56.743: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Sep 27 22:36:56.743: INFO: 	Container systemd-logs ready: true, restart count 1
Sep 27 22:36:56.743: INFO: kube-scheduler-macpro-2 from kube-system started at 2019-08-13 03:43:55 +0000 UTC (1 container statuses recorded)
Sep 27 22:36:56.743: INFO: 	Container kube-scheduler ready: true, restart count 2
Sep 27 22:36:56.743: INFO: 
Logging pods the kubelet thinks is on node macpro-3 before test
Sep 27 22:36:56.748: INFO: speaker-t4xwn from metallb-system started at 2019-08-11 23:04:22 +0000 UTC (1 container statuses recorded)
Sep 27 22:36:56.748: INFO: 	Container speaker ready: true, restart count 0
Sep 27 22:36:56.748: INFO: sonobuoy-e2e-job-e236daee93b24985 from sonobuoy started at 2019-09-27 21:16:00 +0000 UTC (2 container statuses recorded)
Sep 27 22:36:56.748: INFO: 	Container e2e ready: true, restart count 0
Sep 27 22:36:56.748: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 27 22:36:56.748: INFO: nfs-server-pod from default started at 2019-09-26 21:59:12 +0000 UTC (1 container statuses recorded)
Sep 27 22:36:56.748: INFO: 	Container nfs-server-container ready: true, restart count 0
Sep 27 22:36:56.748: INFO: sonobuoy-systemd-logs-daemon-set-3ff1c1a60c394bba-fvsn5 from sonobuoy started at 2019-09-27 21:16:41 +0000 UTC (2 container statuses recorded)
Sep 27 22:36:56.748: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Sep 27 22:36:56.748: INFO: 	Container systemd-logs ready: true, restart count 1
Sep 27 22:36:56.748: INFO: kube-scheduler-macpro-3 from kube-system started at 2019-08-08 02:21:06 +0000 UTC (1 container statuses recorded)
Sep 27 22:36:56.748: INFO: 	Container kube-scheduler ready: true, restart count 0
Sep 27 22:36:56.748: INFO: kube-apiserver-macpro-3 from kube-system started at 2019-08-13 03:43:55 +0000 UTC (1 container statuses recorded)
Sep 27 22:36:56.748: INFO: 	Container kube-apiserver ready: true, restart count 0
Sep 27 22:36:56.748: INFO: calico-node-ctgww from kube-system started at 2019-08-08 02:21:44 +0000 UTC (1 container statuses recorded)
Sep 27 22:36:56.748: INFO: 	Container calico-node ready: true, restart count 0
Sep 27 22:36:56.748: INFO: etcd-macpro-3 from kube-system started at 2019-08-13 03:43:55 +0000 UTC (1 container statuses recorded)
Sep 27 22:36:56.748: INFO: 	Container etcd ready: true, restart count 2
Sep 27 22:36:56.748: INFO: kube-proxy-kfvg6 from kube-system started at 2019-08-08 02:21:08 +0000 UTC (1 container statuses recorded)
Sep 27 22:36:56.748: INFO: 	Container kube-proxy ready: true, restart count 0
Sep 27 22:36:56.748: INFO: kube-controller-manager-macpro-3 from kube-system started at 2019-08-13 03:43:55 +0000 UTC (1 container statuses recorded)
Sep 27 22:36:56.748: INFO: 	Container kube-controller-manager ready: true, restart count 2
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-9a237dad-d113-48b4-82c4-a334d3c5466f 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-9a237dad-d113-48b4-82c4-a334d3c5466f off the node macpro-3
STEP: verifying the node doesn't have the label kubernetes.io/e2e-9a237dad-d113-48b4-82c4-a334d3c5466f
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:37:00.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-1029" for this suite.
Sep 27 22:37:08.846: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:37:08.916: INFO: namespace sched-pred-1029 deletion completed in 8.086548753s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:12.346 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:37:08.916: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9432
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1517
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep 27 22:37:09.068: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-9432'
Sep 27 22:37:09.645: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep 27 22:37:09.645: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Sep 27 22:37:09.659: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Sep 27 22:37:09.664: INFO: scanned /root for discovery docs: <nil>
Sep 27 22:37:09.664: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-9432'
Sep 27 22:37:25.416: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Sep 27 22:37:25.416: INFO: stdout: "Created e2e-test-nginx-rc-c49255c6b4fe2de8c40d3faf556c3146\nScaling up e2e-test-nginx-rc-c49255c6b4fe2de8c40d3faf556c3146 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-c49255c6b4fe2de8c40d3faf556c3146 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-c49255c6b4fe2de8c40d3faf556c3146 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Sep 27 22:37:25.416: INFO: stdout: "Created e2e-test-nginx-rc-c49255c6b4fe2de8c40d3faf556c3146\nScaling up e2e-test-nginx-rc-c49255c6b4fe2de8c40d3faf556c3146 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-c49255c6b4fe2de8c40d3faf556c3146 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-c49255c6b4fe2de8c40d3faf556c3146 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Sep 27 22:37:25.416: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-9432'
Sep 27 22:37:25.479: INFO: stderr: ""
Sep 27 22:37:25.479: INFO: stdout: "e2e-test-nginx-rc-c49255c6b4fe2de8c40d3faf556c3146-lck28 "
Sep 27 22:37:25.479: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 get pods e2e-test-nginx-rc-c49255c6b4fe2de8c40d3faf556c3146-lck28 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9432'
Sep 27 22:37:25.541: INFO: stderr: ""
Sep 27 22:37:25.541: INFO: stdout: "true"
Sep 27 22:37:25.541: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 get pods e2e-test-nginx-rc-c49255c6b4fe2de8c40d3faf556c3146-lck28 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9432'
Sep 27 22:37:25.600: INFO: stderr: ""
Sep 27 22:37:25.600: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Sep 27 22:37:25.600: INFO: e2e-test-nginx-rc-c49255c6b4fe2de8c40d3faf556c3146-lck28 is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1523
Sep 27 22:37:25.600: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 delete rc e2e-test-nginx-rc --namespace=kubectl-9432'
Sep 27 22:37:25.666: INFO: stderr: ""
Sep 27 22:37:25.666: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:37:25.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9432" for this suite.
Sep 27 22:37:31.684: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:37:31.755: INFO: namespace kubectl-9432 deletion completed in 6.085843709s

• [SLOW TEST:22.839 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:37:31.756: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5743
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-7c534129-7332-4497-8989-3514bef9cf98
STEP: Creating a pod to test consume secrets
Sep 27 22:37:31.928: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e11cd8b5-ab0c-41f4-9b0e-eab6e9aabdac" in namespace "projected-5743" to be "success or failure"
Sep 27 22:37:31.930: INFO: Pod "pod-projected-secrets-e11cd8b5-ab0c-41f4-9b0e-eab6e9aabdac": Phase="Pending", Reason="", readiness=false. Elapsed: 1.77608ms
Sep 27 22:37:33.933: INFO: Pod "pod-projected-secrets-e11cd8b5-ab0c-41f4-9b0e-eab6e9aabdac": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004427927s
STEP: Saw pod success
Sep 27 22:37:33.933: INFO: Pod "pod-projected-secrets-e11cd8b5-ab0c-41f4-9b0e-eab6e9aabdac" satisfied condition "success or failure"
Sep 27 22:37:33.935: INFO: Trying to get logs from node macpro-3 pod pod-projected-secrets-e11cd8b5-ab0c-41f4-9b0e-eab6e9aabdac container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep 27 22:37:33.962: INFO: Waiting for pod pod-projected-secrets-e11cd8b5-ab0c-41f4-9b0e-eab6e9aabdac to disappear
Sep 27 22:37:33.964: INFO: Pod pod-projected-secrets-e11cd8b5-ab0c-41f4-9b0e-eab6e9aabdac no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:37:33.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5743" for this suite.
Sep 27 22:37:39.978: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:37:40.048: INFO: namespace projected-5743 deletion completed in 6.08215875s

• [SLOW TEST:8.293 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:37:40.049: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-6674
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-secret-sbw6
STEP: Creating a pod to test atomic-volume-subpath
Sep 27 22:37:40.214: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-sbw6" in namespace "subpath-6674" to be "success or failure"
Sep 27 22:37:40.216: INFO: Pod "pod-subpath-test-secret-sbw6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.961749ms
Sep 27 22:37:42.219: INFO: Pod "pod-subpath-test-secret-sbw6": Phase="Running", Reason="", readiness=true. Elapsed: 2.004999513s
Sep 27 22:37:44.222: INFO: Pod "pod-subpath-test-secret-sbw6": Phase="Running", Reason="", readiness=true. Elapsed: 4.007855316s
Sep 27 22:37:46.225: INFO: Pod "pod-subpath-test-secret-sbw6": Phase="Running", Reason="", readiness=true. Elapsed: 6.010606533s
Sep 27 22:37:48.228: INFO: Pod "pod-subpath-test-secret-sbw6": Phase="Running", Reason="", readiness=true. Elapsed: 8.013533413s
Sep 27 22:37:50.230: INFO: Pod "pod-subpath-test-secret-sbw6": Phase="Running", Reason="", readiness=true. Elapsed: 10.016006164s
Sep 27 22:37:52.233: INFO: Pod "pod-subpath-test-secret-sbw6": Phase="Running", Reason="", readiness=true. Elapsed: 12.018935374s
Sep 27 22:37:54.236: INFO: Pod "pod-subpath-test-secret-sbw6": Phase="Running", Reason="", readiness=true. Elapsed: 14.021770215s
Sep 27 22:37:56.239: INFO: Pod "pod-subpath-test-secret-sbw6": Phase="Running", Reason="", readiness=true. Elapsed: 16.024319759s
Sep 27 22:37:58.242: INFO: Pod "pod-subpath-test-secret-sbw6": Phase="Running", Reason="", readiness=true. Elapsed: 18.027194893s
Sep 27 22:38:00.244: INFO: Pod "pod-subpath-test-secret-sbw6": Phase="Running", Reason="", readiness=true. Elapsed: 20.030022886s
Sep 27 22:38:02.252: INFO: Pod "pod-subpath-test-secret-sbw6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.03739267s
STEP: Saw pod success
Sep 27 22:38:02.252: INFO: Pod "pod-subpath-test-secret-sbw6" satisfied condition "success or failure"
Sep 27 22:38:02.261: INFO: Trying to get logs from node macpro-1 pod pod-subpath-test-secret-sbw6 container test-container-subpath-secret-sbw6: <nil>
STEP: delete the pod
Sep 27 22:38:02.281: INFO: Waiting for pod pod-subpath-test-secret-sbw6 to disappear
Sep 27 22:38:02.283: INFO: Pod pod-subpath-test-secret-sbw6 no longer exists
STEP: Deleting pod pod-subpath-test-secret-sbw6
Sep 27 22:38:02.283: INFO: Deleting pod "pod-subpath-test-secret-sbw6" in namespace "subpath-6674"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:38:02.285: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6674" for this suite.
Sep 27 22:38:08.299: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:38:08.370: INFO: namespace subpath-6674 deletion completed in 6.082255405s

• [SLOW TEST:28.321 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:38:08.370: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-4701
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 27 22:38:10.566: INFO: Waiting up to 5m0s for pod "client-envvars-e9533775-1ef0-4e23-98b4-5759776b9544" in namespace "pods-4701" to be "success or failure"
Sep 27 22:38:10.568: INFO: Pod "client-envvars-e9533775-1ef0-4e23-98b4-5759776b9544": Phase="Pending", Reason="", readiness=false. Elapsed: 1.859022ms
Sep 27 22:38:12.570: INFO: Pod "client-envvars-e9533775-1ef0-4e23-98b4-5759776b9544": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004571682s
STEP: Saw pod success
Sep 27 22:38:12.570: INFO: Pod "client-envvars-e9533775-1ef0-4e23-98b4-5759776b9544" satisfied condition "success or failure"
Sep 27 22:38:12.578: INFO: Trying to get logs from node macpro-3 pod client-envvars-e9533775-1ef0-4e23-98b4-5759776b9544 container env3cont: <nil>
STEP: delete the pod
Sep 27 22:38:12.599: INFO: Waiting for pod client-envvars-e9533775-1ef0-4e23-98b4-5759776b9544 to disappear
Sep 27 22:38:12.601: INFO: Pod client-envvars-e9533775-1ef0-4e23-98b4-5759776b9544 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:38:12.601: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4701" for this suite.
Sep 27 22:38:50.614: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:38:50.685: INFO: namespace pods-4701 deletion completed in 38.081329997s

• [SLOW TEST:42.315 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:38:50.685: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-3763
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Sep 27 22:38:53.876: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:38:54.889: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-3763" for this suite.
Sep 27 22:39:16.907: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:39:16.975: INFO: namespace replicaset-3763 deletion completed in 22.083071819s

• [SLOW TEST:26.290 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:39:16.976: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-8939
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Sep 27 22:39:17.127: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:39:21.003: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-8939" for this suite.
Sep 27 22:39:27.018: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:39:27.090: INFO: namespace init-container-8939 deletion completed in 6.08440985s

• [SLOW TEST:10.115 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:39:27.091: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4948
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-7af6bf0f-c5e1-4ffd-bd1e-30ffa4c55c3a
STEP: Creating a pod to test consume configMaps
Sep 27 22:39:27.251: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-91dfdae2-dc72-4044-a57c-200f32157b0c" in namespace "projected-4948" to be "success or failure"
Sep 27 22:39:27.253: INFO: Pod "pod-projected-configmaps-91dfdae2-dc72-4044-a57c-200f32157b0c": Phase="Pending", Reason="", readiness=false. Elapsed: 1.942028ms
Sep 27 22:39:29.256: INFO: Pod "pod-projected-configmaps-91dfdae2-dc72-4044-a57c-200f32157b0c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004687355s
STEP: Saw pod success
Sep 27 22:39:29.256: INFO: Pod "pod-projected-configmaps-91dfdae2-dc72-4044-a57c-200f32157b0c" satisfied condition "success or failure"
Sep 27 22:39:29.258: INFO: Trying to get logs from node macpro-1 pod pod-projected-configmaps-91dfdae2-dc72-4044-a57c-200f32157b0c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 27 22:39:29.288: INFO: Waiting for pod pod-projected-configmaps-91dfdae2-dc72-4044-a57c-200f32157b0c to disappear
Sep 27 22:39:29.290: INFO: Pod pod-projected-configmaps-91dfdae2-dc72-4044-a57c-200f32157b0c no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:39:29.290: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4948" for this suite.
Sep 27 22:39:35.303: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:39:35.375: INFO: namespace projected-4948 deletion completed in 6.082841389s

• [SLOW TEST:8.285 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:39:35.376: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-9964
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Sep 27 22:39:39.576: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 27 22:39:39.578: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 27 22:39:41.578: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 27 22:39:41.581: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 27 22:39:43.578: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 27 22:39:43.580: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 27 22:39:45.578: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 27 22:39:45.581: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 27 22:39:47.578: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 27 22:39:47.581: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 27 22:39:49.578: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 27 22:39:49.581: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 27 22:39:51.578: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 27 22:39:51.581: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 27 22:39:53.578: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 27 22:39:53.581: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 27 22:39:55.578: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 27 22:39:55.580: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 27 22:39:57.578: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 27 22:39:57.581: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 27 22:39:59.578: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 27 22:39:59.581: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 27 22:40:01.578: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 27 22:40:01.581: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:40:01.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9964" for this suite.
Sep 27 22:40:23.599: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:40:23.676: INFO: namespace container-lifecycle-hook-9964 deletion completed in 22.092312483s

• [SLOW TEST:48.300 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:40:23.676: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4118
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep 27 22:40:23.848: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c62a96cb-c8c7-4eb1-8607-4bdbd199847d" in namespace "projected-4118" to be "success or failure"
Sep 27 22:40:23.850: INFO: Pod "downwardapi-volume-c62a96cb-c8c7-4eb1-8607-4bdbd199847d": Phase="Pending", Reason="", readiness=false. Elapsed: 1.853785ms
Sep 27 22:40:25.853: INFO: Pod "downwardapi-volume-c62a96cb-c8c7-4eb1-8607-4bdbd199847d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004779508s
STEP: Saw pod success
Sep 27 22:40:25.853: INFO: Pod "downwardapi-volume-c62a96cb-c8c7-4eb1-8607-4bdbd199847d" satisfied condition "success or failure"
Sep 27 22:40:25.855: INFO: Trying to get logs from node macpro-1 pod downwardapi-volume-c62a96cb-c8c7-4eb1-8607-4bdbd199847d container client-container: <nil>
STEP: delete the pod
Sep 27 22:40:25.878: INFO: Waiting for pod downwardapi-volume-c62a96cb-c8c7-4eb1-8607-4bdbd199847d to disappear
Sep 27 22:40:25.880: INFO: Pod downwardapi-volume-c62a96cb-c8c7-4eb1-8607-4bdbd199847d no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:40:25.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4118" for this suite.
Sep 27 22:40:31.898: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:40:31.970: INFO: namespace projected-4118 deletion completed in 6.087313368s

• [SLOW TEST:8.294 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:40:31.970: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-4566
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Sep 27 22:40:34.657: INFO: Successfully updated pod "pod-update-193a83ae-60d9-450a-89c6-cb9acae3d413"
STEP: verifying the updated pod is in kubernetes
Sep 27 22:40:34.661: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:40:34.661: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4566" for this suite.
Sep 27 22:40:56.678: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:40:56.750: INFO: namespace pods-4566 deletion completed in 22.086478172s

• [SLOW TEST:24.780 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:40:56.751: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-1130
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
Sep 27 22:40:57.948: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0927 22:40:57.948092      18 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:40:57.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1130" for this suite.
Sep 27 22:41:03.962: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:41:04.031: INFO: namespace gc-1130 deletion completed in 6.080617061s

• [SLOW TEST:7.281 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:41:04.031: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2902
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-c0d2950a-b97f-4e62-bc2f-9d7ae0e420d8
STEP: Creating a pod to test consume secrets
Sep 27 22:41:04.206: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-4df5efec-b5b2-4d5a-a6e5-163eed6ed621" in namespace "projected-2902" to be "success or failure"
Sep 27 22:41:04.207: INFO: Pod "pod-projected-secrets-4df5efec-b5b2-4d5a-a6e5-163eed6ed621": Phase="Pending", Reason="", readiness=false. Elapsed: 1.92172ms
Sep 27 22:41:06.210: INFO: Pod "pod-projected-secrets-4df5efec-b5b2-4d5a-a6e5-163eed6ed621": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004566542s
STEP: Saw pod success
Sep 27 22:41:06.210: INFO: Pod "pod-projected-secrets-4df5efec-b5b2-4d5a-a6e5-163eed6ed621" satisfied condition "success or failure"
Sep 27 22:41:06.212: INFO: Trying to get logs from node macpro-2 pod pod-projected-secrets-4df5efec-b5b2-4d5a-a6e5-163eed6ed621 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep 27 22:41:06.232: INFO: Waiting for pod pod-projected-secrets-4df5efec-b5b2-4d5a-a6e5-163eed6ed621 to disappear
Sep 27 22:41:06.234: INFO: Pod pod-projected-secrets-4df5efec-b5b2-4d5a-a6e5-163eed6ed621 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:41:06.234: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2902" for this suite.
Sep 27 22:41:12.247: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:41:12.319: INFO: namespace projected-2902 deletion completed in 6.082964911s

• [SLOW TEST:8.288 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:41:12.320: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in hostpath-7302
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test hostPath mode
Sep 27 22:41:12.489: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-7302" to be "success or failure"
Sep 27 22:41:12.494: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 5.426428ms
Sep 27 22:41:14.497: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008008867s
STEP: Saw pod success
Sep 27 22:41:14.497: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Sep 27 22:41:14.499: INFO: Trying to get logs from node macpro-3 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Sep 27 22:41:14.525: INFO: Waiting for pod pod-host-path-test to disappear
Sep 27 22:41:14.527: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:41:14.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-7302" for this suite.
Sep 27 22:41:20.541: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:41:20.612: INFO: namespace hostpath-7302 deletion completed in 6.082675014s

• [SLOW TEST:8.293 seconds]
[sig-storage] HostPath
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:41:20.612: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-885
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating all guestbook components
Sep 27 22:41:20.767: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Sep 27 22:41:20.767: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 create -f - --namespace=kubectl-885'
Sep 27 22:41:20.978: INFO: stderr: ""
Sep 27 22:41:20.978: INFO: stdout: "service/redis-slave created\n"
Sep 27 22:41:20.978: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Sep 27 22:41:20.978: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 create -f - --namespace=kubectl-885'
Sep 27 22:41:21.202: INFO: stderr: ""
Sep 27 22:41:21.202: INFO: stdout: "service/redis-master created\n"
Sep 27 22:41:21.202: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Sep 27 22:41:21.202: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 create -f - --namespace=kubectl-885'
Sep 27 22:41:21.414: INFO: stderr: ""
Sep 27 22:41:21.414: INFO: stdout: "service/frontend created\n"
Sep 27 22:41:21.414: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Sep 27 22:41:21.414: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 create -f - --namespace=kubectl-885'
Sep 27 22:41:21.613: INFO: stderr: ""
Sep 27 22:41:21.613: INFO: stdout: "deployment.apps/frontend created\n"
Sep 27 22:41:21.613: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Sep 27 22:41:21.613: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 create -f - --namespace=kubectl-885'
Sep 27 22:41:21.758: INFO: stderr: ""
Sep 27 22:41:21.758: INFO: stdout: "deployment.apps/redis-master created\n"
Sep 27 22:41:21.758: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Sep 27 22:41:21.758: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 create -f - --namespace=kubectl-885'
Sep 27 22:41:21.970: INFO: stderr: ""
Sep 27 22:41:21.970: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Sep 27 22:41:21.970: INFO: Waiting for all frontend pods to be Running.
Sep 27 22:41:57.022: INFO: Waiting for frontend to serve content.
Sep 27 22:42:02.039: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection timed out [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection time...', 110)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stre in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Sep 27 22:42:07.050: INFO: Trying to add a new entry to the guestbook.
Sep 27 22:42:07.061: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Sep 27 22:42:07.070: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 delete --grace-period=0 --force -f - --namespace=kubectl-885'
Sep 27 22:42:07.162: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 27 22:42:07.162: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Sep 27 22:42:07.162: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 delete --grace-period=0 --force -f - --namespace=kubectl-885'
Sep 27 22:42:07.258: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 27 22:42:07.258: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Sep 27 22:42:07.258: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 delete --grace-period=0 --force -f - --namespace=kubectl-885'
Sep 27 22:42:07.350: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 27 22:42:07.350: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Sep 27 22:42:07.351: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 delete --grace-period=0 --force -f - --namespace=kubectl-885'
Sep 27 22:42:07.421: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 27 22:42:07.421: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Sep 27 22:42:07.421: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 delete --grace-period=0 --force -f - --namespace=kubectl-885'
Sep 27 22:42:07.487: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 27 22:42:07.487: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Sep 27 22:42:07.487: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-741451867 delete --grace-period=0 --force -f - --namespace=kubectl-885'
Sep 27 22:42:07.555: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 27 22:42:07.555: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:42:07.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-885" for this suite.
Sep 27 22:42:45.570: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:42:45.639: INFO: namespace kubectl-885 deletion completed in 38.080945887s

• [SLOW TEST:85.027 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Guestbook application
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:42:45.639: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4057
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on tmpfs
Sep 27 22:42:45.800: INFO: Waiting up to 5m0s for pod "pod-fbb879e1-0d9c-4381-ab68-ae413b70a964" in namespace "emptydir-4057" to be "success or failure"
Sep 27 22:42:45.802: INFO: Pod "pod-fbb879e1-0d9c-4381-ab68-ae413b70a964": Phase="Pending", Reason="", readiness=false. Elapsed: 1.898653ms
Sep 27 22:42:47.805: INFO: Pod "pod-fbb879e1-0d9c-4381-ab68-ae413b70a964": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004476134s
STEP: Saw pod success
Sep 27 22:42:47.805: INFO: Pod "pod-fbb879e1-0d9c-4381-ab68-ae413b70a964" satisfied condition "success or failure"
Sep 27 22:42:47.807: INFO: Trying to get logs from node macpro-1 pod pod-fbb879e1-0d9c-4381-ab68-ae413b70a964 container test-container: <nil>
STEP: delete the pod
Sep 27 22:42:47.830: INFO: Waiting for pod pod-fbb879e1-0d9c-4381-ab68-ae413b70a964 to disappear
Sep 27 22:42:47.832: INFO: Pod pod-fbb879e1-0d9c-4381-ab68-ae413b70a964 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:42:47.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4057" for this suite.
Sep 27 22:42:53.847: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:42:53.925: INFO: namespace emptydir-4057 deletion completed in 6.090110965s

• [SLOW TEST:8.286 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:42:53.925: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-7167
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Sep 27 22:42:58.118: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 27 22:42:58.120: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 27 22:43:00.121: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 27 22:43:00.123: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 27 22:43:02.121: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 27 22:43:02.123: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 27 22:43:04.121: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 27 22:43:04.123: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 27 22:43:06.121: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 27 22:43:06.123: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 27 22:43:08.121: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 27 22:43:08.123: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 27 22:43:10.121: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 27 22:43:10.123: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 27 22:43:12.121: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 27 22:43:12.123: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 27 22:43:14.121: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 27 22:43:14.123: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 27 22:43:16.121: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 27 22:43:16.123: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 27 22:43:18.121: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 27 22:43:18.123: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 27 22:43:20.121: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 27 22:43:20.123: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 27 22:43:22.121: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 27 22:43:22.123: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:43:22.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-7167" for this suite.
Sep 27 22:43:44.146: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:43:44.221: INFO: namespace container-lifecycle-hook-7167 deletion completed in 22.087971094s

• [SLOW TEST:50.296 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:43:44.222: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6690
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-map-8a15f6e2-8397-4a0b-bfa8-34cd1b8297d5
STEP: Creating a pod to test consume secrets
Sep 27 22:43:44.392: INFO: Waiting up to 5m0s for pod "pod-secrets-cad17870-acb3-421f-a53f-5995a6eca900" in namespace "secrets-6690" to be "success or failure"
Sep 27 22:43:44.402: INFO: Pod "pod-secrets-cad17870-acb3-421f-a53f-5995a6eca900": Phase="Pending", Reason="", readiness=false. Elapsed: 9.263036ms
Sep 27 22:43:46.404: INFO: Pod "pod-secrets-cad17870-acb3-421f-a53f-5995a6eca900": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011932379s
STEP: Saw pod success
Sep 27 22:43:46.404: INFO: Pod "pod-secrets-cad17870-acb3-421f-a53f-5995a6eca900" satisfied condition "success or failure"
Sep 27 22:43:46.406: INFO: Trying to get logs from node macpro-3 pod pod-secrets-cad17870-acb3-421f-a53f-5995a6eca900 container secret-volume-test: <nil>
STEP: delete the pod
Sep 27 22:43:46.431: INFO: Waiting for pod pod-secrets-cad17870-acb3-421f-a53f-5995a6eca900 to disappear
Sep 27 22:43:46.433: INFO: Pod pod-secrets-cad17870-acb3-421f-a53f-5995a6eca900 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:43:46.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6690" for this suite.
Sep 27 22:43:52.450: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:43:52.521: INFO: namespace secrets-6690 deletion completed in 6.082444725s

• [SLOW TEST:8.300 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:43:52.522: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in prestop-1194
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating server pod server in namespace prestop-1194
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-1194
STEP: Deleting pre-stop pod
Sep 27 22:44:03.723: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:44:03.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-1194" for this suite.
Sep 27 22:44:41.756: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:44:41.834: INFO: namespace prestop-1194 deletion completed in 38.101290903s

• [SLOW TEST:49.313 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 27 22:44:41.834: INFO: >>> kubeConfig: /tmp/kubeconfig-741451867
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6325
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name secret-emptykey-test-82ac6a10-4f17-4957-8eba-8af0601fed8f
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 27 22:44:41.992: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6325" for this suite.
Sep 27 22:44:48.007: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 27 22:44:48.085: INFO: namespace secrets-6325 deletion completed in 6.09011663s

• [SLOW TEST:6.251 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSep 27 22:44:48.085: INFO: Running AfterSuite actions on all nodes
Sep 27 22:44:48.085: INFO: Running AfterSuite actions on node 1
Sep 27 22:44:48.085: INFO: Skipping dumping logs from cluster

Ran 215 of 4413 Specs in 5303.403 seconds
SUCCESS! -- 215 Passed | 0 Failed | 0 Pending | 4198 Skipped
PASS

Ginkgo ran 1 suite in 1h28m24.49849046s
Test Suite Passed
