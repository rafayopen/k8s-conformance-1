I1222 21:19:17.278407      15 test_context.go:406] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-800494845
I1222 21:19:17.278600      15 e2e.go:243] Starting e2e run "3fe299f7-d80a-4872-88a8-bdd8a596ced7" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1577049555 - Will randomize all specs
Will run 215 of 4412 specs

Dec 22 21:19:17.678: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
Dec 22 21:19:17.681: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Dec 22 21:19:17.696: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Dec 22 21:19:17.754: INFO: 9 / 9 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Dec 22 21:19:17.758: INFO: expected 5 pod replicas in namespace 'kube-system', 5 are Running and Ready.
Dec 22 21:19:17.758: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Dec 22 21:19:17.767: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Dec 22 21:19:17.767: INFO: e2e test version: v1.15.7
Dec 22 21:19:17.770: INFO: kube-apiserver version: v1.15.7
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:19:17.772: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename custom-resource-definition
Dec 22 21:19:17.795: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec 22 21:19:17.797: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:19:18.337: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-1964" for this suite.
Dec 22 21:19:24.346: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:19:24.414: INFO: namespace custom-resource-definition-1964 deletion completed in 6.074560052s

â€¢ [SLOW TEST:6.643 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:19:24.414: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec 22 21:19:24.436: INFO: Pod name rollover-pod: Found 0 pods out of 1
Dec 22 21:19:29.439: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec 22 21:19:29.439: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Dec 22 21:19:31.441: INFO: Creating deployment "test-rollover-deployment"
Dec 22 21:19:31.446: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Dec 22 21:19:33.454: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Dec 22 21:19:33.462: INFO: Ensure that both replica sets have 1 created replica
Dec 22 21:19:33.466: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Dec 22 21:19:33.472: INFO: Updating deployment test-rollover-deployment
Dec 22 21:19:33.472: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Dec 22 21:19:35.481: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Dec 22 21:19:35.485: INFO: Make sure deployment "test-rollover-deployment" is complete
Dec 22 21:19:35.488: INFO: all replica sets need to contain the pod-template-hash label
Dec 22 21:19:35.489: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712646371, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712646371, loc:(*time.Location)(0x7ed0a00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712646373, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712646371, loc:(*time.Location)(0x7ed0a00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 22 21:19:37.496: INFO: all replica sets need to contain the pod-template-hash label
Dec 22 21:19:37.496: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712646371, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712646371, loc:(*time.Location)(0x7ed0a00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712646377, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712646371, loc:(*time.Location)(0x7ed0a00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 22 21:19:39.494: INFO: all replica sets need to contain the pod-template-hash label
Dec 22 21:19:39.494: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712646371, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712646371, loc:(*time.Location)(0x7ed0a00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712646377, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712646371, loc:(*time.Location)(0x7ed0a00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 22 21:19:41.494: INFO: all replica sets need to contain the pod-template-hash label
Dec 22 21:19:41.494: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712646371, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712646371, loc:(*time.Location)(0x7ed0a00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712646377, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712646371, loc:(*time.Location)(0x7ed0a00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 22 21:19:43.497: INFO: all replica sets need to contain the pod-template-hash label
Dec 22 21:19:43.497: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712646371, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712646371, loc:(*time.Location)(0x7ed0a00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712646377, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712646371, loc:(*time.Location)(0x7ed0a00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 22 21:19:45.496: INFO: all replica sets need to contain the pod-template-hash label
Dec 22 21:19:45.496: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712646371, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712646371, loc:(*time.Location)(0x7ed0a00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712646377, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712646371, loc:(*time.Location)(0x7ed0a00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 22 21:19:47.496: INFO: 
Dec 22 21:19:47.496: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Dec 22 21:19:47.502: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-9343,SelfLink:/apis/apps/v1/namespaces/deployment-9343/deployments/test-rollover-deployment,UID:319ef408-a364-44b9-80f4-1f7d76f82f90,ResourceVersion:1771,Generation:2,CreationTimestamp:2019-12-22 21:19:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-12-22 21:19:31 +0000 UTC 2019-12-22 21:19:31 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-12-22 21:19:47 +0000 UTC 2019-12-22 21:19:31 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-854595fc44" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Dec 22 21:19:47.504: INFO: New ReplicaSet "test-rollover-deployment-854595fc44" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-854595fc44,GenerateName:,Namespace:deployment-9343,SelfLink:/apis/apps/v1/namespaces/deployment-9343/replicasets/test-rollover-deployment-854595fc44,UID:6ae4b5ec-ff90-4ba5-ab95-9830600820d8,ResourceVersion:1761,Generation:2,CreationTimestamp:2019-12-22 21:19:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 319ef408-a364-44b9-80f4-1f7d76f82f90 0xc001a6de17 0xc001a6de18}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Dec 22 21:19:47.505: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Dec 22 21:19:47.505: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-9343,SelfLink:/apis/apps/v1/namespaces/deployment-9343/replicasets/test-rollover-controller,UID:3b2126e8-7b8b-4c44-b4d1-bafd7bfd2fd8,ResourceVersion:1770,Generation:2,CreationTimestamp:2019-12-22 21:19:24 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 319ef408-a364-44b9-80f4-1f7d76f82f90 0xc001a6dd3f 0xc001a6dd50}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec 22 21:19:47.505: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-9b8b997cf,GenerateName:,Namespace:deployment-9343,SelfLink:/apis/apps/v1/namespaces/deployment-9343/replicasets/test-rollover-deployment-9b8b997cf,UID:b07f5e1e-5bfe-43bf-8113-9da96b7825cb,ResourceVersion:1721,Generation:2,CreationTimestamp:2019-12-22 21:19:31 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 319ef408-a364-44b9-80f4-1f7d76f82f90 0xc001a6ded0 0xc001a6ded1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec 22 21:19:47.508: INFO: Pod "test-rollover-deployment-854595fc44-8p5hl" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-854595fc44-8p5hl,GenerateName:test-rollover-deployment-854595fc44-,Namespace:deployment-9343,SelfLink:/api/v1/namespaces/deployment-9343/pods/test-rollover-deployment-854595fc44-8p5hl,UID:92741026-6c9a-4a59-8285-2e381987951e,ResourceVersion:1743,Generation:0,CreationTimestamp:2019-12-22 21:19:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.20.27.3/32,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-854595fc44 6ae4b5ec-ff90-4ba5-ab95-9830600820d8 0xc001d3caa7 0xc001d3caa8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wkrn6 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wkrn6,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-wkrn6 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-121.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:19:33 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:19:37 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:19:37 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:19:33 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.121,PodIP:10.20.27.3,StartTime:2019-12-22 21:19:33 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-12-22 21:19:36 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://cd3e62aa4d4557f8e467b0ac88b92d7d6e19780f7c592a286e9d46852fb8baec}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:19:47.508: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9343" for this suite.
Dec 22 21:19:53.523: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:19:53.719: INFO: namespace deployment-9343 deletion completed in 6.209189269s

â€¢ [SLOW TEST:29.305 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:19:53.720: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec 22 21:19:53.740: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9ac93481-61e2-414f-9e9e-12b3bd3c104a" in namespace "downward-api-3091" to be "success or failure"
Dec 22 21:19:53.743: INFO: Pod "downwardapi-volume-9ac93481-61e2-414f-9e9e-12b3bd3c104a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.603448ms
Dec 22 21:19:55.745: INFO: Pod "downwardapi-volume-9ac93481-61e2-414f-9e9e-12b3bd3c104a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005112837s
Dec 22 21:19:57.748: INFO: Pod "downwardapi-volume-9ac93481-61e2-414f-9e9e-12b3bd3c104a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008397954s
STEP: Saw pod success
Dec 22 21:19:57.748: INFO: Pod "downwardapi-volume-9ac93481-61e2-414f-9e9e-12b3bd3c104a" satisfied condition "success or failure"
Dec 22 21:19:57.751: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod downwardapi-volume-9ac93481-61e2-414f-9e9e-12b3bd3c104a container client-container: <nil>
STEP: delete the pod
Dec 22 21:19:57.781: INFO: Waiting for pod downwardapi-volume-9ac93481-61e2-414f-9e9e-12b3bd3c104a to disappear
Dec 22 21:19:57.782: INFO: Pod downwardapi-volume-9ac93481-61e2-414f-9e9e-12b3bd3c104a no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:19:57.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3091" for this suite.
Dec 22 21:20:03.799: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:20:03.904: INFO: namespace downward-api-3091 deletion completed in 6.115858727s

â€¢ [SLOW TEST:10.184 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:20:03.905: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec 22 21:20:03.942: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a7cb0e96-7d7c-46b0-95f4-e002f1a019ee" in namespace "projected-2720" to be "success or failure"
Dec 22 21:20:03.945: INFO: Pod "downwardapi-volume-a7cb0e96-7d7c-46b0-95f4-e002f1a019ee": Phase="Pending", Reason="", readiness=false. Elapsed: 3.457659ms
Dec 22 21:20:05.953: INFO: Pod "downwardapi-volume-a7cb0e96-7d7c-46b0-95f4-e002f1a019ee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011403457s
STEP: Saw pod success
Dec 22 21:20:05.953: INFO: Pod "downwardapi-volume-a7cb0e96-7d7c-46b0-95f4-e002f1a019ee" satisfied condition "success or failure"
Dec 22 21:20:05.960: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod downwardapi-volume-a7cb0e96-7d7c-46b0-95f4-e002f1a019ee container client-container: <nil>
STEP: delete the pod
Dec 22 21:20:05.983: INFO: Waiting for pod downwardapi-volume-a7cb0e96-7d7c-46b0-95f4-e002f1a019ee to disappear
Dec 22 21:20:05.986: INFO: Pod downwardapi-volume-a7cb0e96-7d7c-46b0-95f4-e002f1a019ee no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:20:05.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2720" for this suite.
Dec 22 21:20:12.001: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:20:12.058: INFO: namespace projected-2720 deletion completed in 6.064574561s

â€¢ [SLOW TEST:8.153 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:20:12.059: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-7d76373f-d925-4a35-bee6-3f75f7b3b9ec
STEP: Creating a pod to test consume secrets
Dec 22 21:20:12.132: INFO: Waiting up to 5m0s for pod "pod-secrets-9e4d7e32-d0a7-47c5-b148-6e33e0f8b337" in namespace "secrets-9013" to be "success or failure"
Dec 22 21:20:12.140: INFO: Pod "pod-secrets-9e4d7e32-d0a7-47c5-b148-6e33e0f8b337": Phase="Pending", Reason="", readiness=false. Elapsed: 7.912063ms
Dec 22 21:20:14.143: INFO: Pod "pod-secrets-9e4d7e32-d0a7-47c5-b148-6e33e0f8b337": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010561768s
Dec 22 21:20:16.145: INFO: Pod "pod-secrets-9e4d7e32-d0a7-47c5-b148-6e33e0f8b337": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012822636s
STEP: Saw pod success
Dec 22 21:20:16.145: INFO: Pod "pod-secrets-9e4d7e32-d0a7-47c5-b148-6e33e0f8b337" satisfied condition "success or failure"
Dec 22 21:20:16.147: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod pod-secrets-9e4d7e32-d0a7-47c5-b148-6e33e0f8b337 container secret-env-test: <nil>
STEP: delete the pod
Dec 22 21:20:16.163: INFO: Waiting for pod pod-secrets-9e4d7e32-d0a7-47c5-b148-6e33e0f8b337 to disappear
Dec 22 21:20:16.167: INFO: Pod pod-secrets-9e4d7e32-d0a7-47c5-b148-6e33e0f8b337 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:20:16.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9013" for this suite.
Dec 22 21:20:22.176: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:20:22.317: INFO: namespace secrets-9013 deletion completed in 6.147181735s

â€¢ [SLOW TEST:10.259 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:20:22.318: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir volume type on tmpfs
Dec 22 21:20:22.345: INFO: Waiting up to 5m0s for pod "pod-f7ae3cf1-4a03-4c7f-8d67-5c0ca3b231a7" in namespace "emptydir-1550" to be "success or failure"
Dec 22 21:20:22.349: INFO: Pod "pod-f7ae3cf1-4a03-4c7f-8d67-5c0ca3b231a7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.384747ms
Dec 22 21:20:24.351: INFO: Pod "pod-f7ae3cf1-4a03-4c7f-8d67-5c0ca3b231a7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006709568s
STEP: Saw pod success
Dec 22 21:20:24.352: INFO: Pod "pod-f7ae3cf1-4a03-4c7f-8d67-5c0ca3b231a7" satisfied condition "success or failure"
Dec 22 21:20:24.353: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod pod-f7ae3cf1-4a03-4c7f-8d67-5c0ca3b231a7 container test-container: <nil>
STEP: delete the pod
Dec 22 21:20:24.371: INFO: Waiting for pod pod-f7ae3cf1-4a03-4c7f-8d67-5c0ca3b231a7 to disappear
Dec 22 21:20:24.373: INFO: Pod pod-f7ae3cf1-4a03-4c7f-8d67-5c0ca3b231a7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:20:24.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1550" for this suite.
Dec 22 21:20:30.382: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:20:30.435: INFO: namespace emptydir-1550 deletion completed in 6.059359125s

â€¢ [SLOW TEST:8.117 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:20:30.435: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec 22 21:20:30.456: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Dec 22 21:20:35.459: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec 22 21:20:35.459: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Dec 22 21:20:39.482: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-3840,SelfLink:/apis/apps/v1/namespaces/deployment-3840/deployments/test-cleanup-deployment,UID:5a08e8c0-a48a-4d14-8eda-0f901ce21bf9,ResourceVersion:2063,Generation:1,CreationTimestamp:2019-12-22 21:20:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 1,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-12-22 21:20:35 +0000 UTC 2019-12-22 21:20:35 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-12-22 21:20:38 +0000 UTC 2019-12-22 21:20:35 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-cleanup-deployment-55bbcbc84c" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Dec 22 21:20:39.484: INFO: New ReplicaSet "test-cleanup-deployment-55bbcbc84c" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55bbcbc84c,GenerateName:,Namespace:deployment-3840,SelfLink:/apis/apps/v1/namespaces/deployment-3840/replicasets/test-cleanup-deployment-55bbcbc84c,UID:22d99c16-69ef-4cd9-8398-bcc2208ca810,ResourceVersion:2053,Generation:1,CreationTimestamp:2019-12-22 21:20:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 5a08e8c0-a48a-4d14-8eda-0f901ce21bf9 0xc002a58b77 0xc002a58b78}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Dec 22 21:20:39.486: INFO: Pod "test-cleanup-deployment-55bbcbc84c-cckrs" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55bbcbc84c-cckrs,GenerateName:test-cleanup-deployment-55bbcbc84c-,Namespace:deployment-3840,SelfLink:/api/v1/namespaces/deployment-3840/pods/test-cleanup-deployment-55bbcbc84c-cckrs,UID:2bda5b4c-8650-4cb2-be4a-8a11ad0efe40,ResourceVersion:2052,Generation:0,CreationTimestamp:2019-12-22 21:20:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.20.29.195/32,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-55bbcbc84c 22d99c16-69ef-4cd9-8398-bcc2208ca810 0xc002a59177 0xc002a59178}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nfmzv {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nfmzv,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-nfmzv true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-187.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:20:35 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:20:38 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:20:38 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:20:35 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.187,PodIP:10.20.29.195,StartTime:2019-12-22 21:20:35 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-12-22 21:20:38 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://99a1d270493efbda76f59a0451ef076bb133c947198e80fde970a85e2f06dfa2}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:20:39.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3840" for this suite.
Dec 22 21:20:45.494: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:20:45.711: INFO: namespace deployment-3840 deletion completed in 6.222561058s

â€¢ [SLOW TEST:15.276 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:20:45.711: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Dec 22 21:20:45.777: INFO: PodSpec: initContainers in spec.initContainers
Dec 22 21:21:31.271: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-f193572a-e545-471f-8cf4-581881e2ebe7", GenerateName:"", Namespace:"init-container-8615", SelfLink:"/api/v1/namespaces/init-container-8615/pods/pod-init-f193572a-e545-471f-8cf4-581881e2ebe7", UID:"48584f9e-5e07-4739-b187-789f916a128d", ResourceVersion:"2207", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63712646445, loc:(*time.Location)(0x7ed0a00)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"777651768"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"10.20.29.196/32"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-njs4t", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc002018940), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-njs4t", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-njs4t", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-njs4t", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0030fc178), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"ip-10-0-1-187.us-west-2.compute.internal", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc003092060), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration(nil), HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0030fc230), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0030fc234), PreemptionPolicy:(*v1.PreemptionPolicy)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712646445, loc:(*time.Location)(0x7ed0a00)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712646445, loc:(*time.Location)(0x7ed0a00)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712646445, loc:(*time.Location)(0x7ed0a00)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712646445, loc:(*time.Location)(0x7ed0a00)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.0.1.187", PodIP:"10.20.29.196", StartTime:(*v1.Time)(0xc0030f60c0), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002d8c070)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002d8c0e0)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://917d98bfc578171274b6157d4d16fb8a05fccfa327752ca1e5b58acb87342b58"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0030f6100), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0030f60e0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:21:31.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-8615" for this suite.
Dec 22 21:21:53.283: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:21:53.454: INFO: namespace init-container-8615 deletion completed in 22.178856434s

â€¢ [SLOW TEST:67.742 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:21:53.454: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1557
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec 22 21:21:53.543: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/apps.v1 --namespace=kubectl-9091'
Dec 22 21:21:53.857: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec 22 21:21:53.857: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1562
Dec 22 21:21:55.865: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 delete deployment e2e-test-nginx-deployment --namespace=kubectl-9091'
Dec 22 21:21:55.959: INFO: stderr: ""
Dec 22 21:21:55.959: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:21:55.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9091" for this suite.
Dec 22 21:22:17.968: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:22:18.216: INFO: namespace kubectl-9091 deletion completed in 22.253956401s

â€¢ [SLOW TEST:24.762 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:22:18.216: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod liveness-a6b66c85-564d-4a8e-86d0-3696a6a41001 in namespace container-probe-9396
Dec 22 21:22:22.253: INFO: Started pod liveness-a6b66c85-564d-4a8e-86d0-3696a6a41001 in namespace container-probe-9396
STEP: checking the pod's current state and verifying that restartCount is present
Dec 22 21:22:22.255: INFO: Initial restart count of pod liveness-a6b66c85-564d-4a8e-86d0-3696a6a41001 is 0
Dec 22 21:22:36.277: INFO: Restart count of pod container-probe-9396/liveness-a6b66c85-564d-4a8e-86d0-3696a6a41001 is now 1 (14.022391727s elapsed)
Dec 22 21:22:56.310: INFO: Restart count of pod container-probe-9396/liveness-a6b66c85-564d-4a8e-86d0-3696a6a41001 is now 2 (34.054984313s elapsed)
Dec 22 21:23:16.346: INFO: Restart count of pod container-probe-9396/liveness-a6b66c85-564d-4a8e-86d0-3696a6a41001 is now 3 (54.090943288s elapsed)
Dec 22 21:23:36.373: INFO: Restart count of pod container-probe-9396/liveness-a6b66c85-564d-4a8e-86d0-3696a6a41001 is now 4 (1m14.118424553s elapsed)
Dec 22 21:24:46.470: INFO: Restart count of pod container-probe-9396/liveness-a6b66c85-564d-4a8e-86d0-3696a6a41001 is now 5 (2m24.215009404s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:24:46.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9396" for this suite.
Dec 22 21:24:52.487: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:24:52.610: INFO: namespace container-probe-9396 deletion completed in 6.12973372s

â€¢ [SLOW TEST:154.394 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:24:52.610: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec 22 21:25:14.637: INFO: Container started at 2019-12-22 21:24:54 +0000 UTC, pod became ready at 2019-12-22 21:25:13 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:25:14.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1229" for this suite.
Dec 22 21:25:36.646: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:25:36.716: INFO: namespace container-probe-1229 deletion completed in 22.076161835s

â€¢ [SLOW TEST:44.106 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:25:36.717: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Dec 22 21:25:36.988: INFO: Pod name wrapped-volume-race-ae5f003d-6523-4a31-a773-ae538d726da5: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-ae5f003d-6523-4a31-a773-ae538d726da5 in namespace emptydir-wrapper-6443, will wait for the garbage collector to delete the pods
Dec 22 21:25:53.095: INFO: Deleting ReplicationController wrapped-volume-race-ae5f003d-6523-4a31-a773-ae538d726da5 took: 10.453897ms
Dec 22 21:25:53.595: INFO: Terminating ReplicationController wrapped-volume-race-ae5f003d-6523-4a31-a773-ae538d726da5 pods took: 500.295445ms
STEP: Creating RC which spawns configmap-volume pods
Dec 22 21:26:33.307: INFO: Pod name wrapped-volume-race-9ac13171-791e-4e52-878b-ed34aea50f92: Found 0 pods out of 5
Dec 22 21:26:38.313: INFO: Pod name wrapped-volume-race-9ac13171-791e-4e52-878b-ed34aea50f92: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-9ac13171-791e-4e52-878b-ed34aea50f92 in namespace emptydir-wrapper-6443, will wait for the garbage collector to delete the pods
Dec 22 21:26:48.385: INFO: Deleting ReplicationController wrapped-volume-race-9ac13171-791e-4e52-878b-ed34aea50f92 took: 6.386197ms
Dec 22 21:26:48.786: INFO: Terminating ReplicationController wrapped-volume-race-9ac13171-791e-4e52-878b-ed34aea50f92 pods took: 400.294081ms
STEP: Creating RC which spawns configmap-volume pods
Dec 22 21:27:32.309: INFO: Pod name wrapped-volume-race-923b3778-8c2d-44e6-a5fb-30770372a473: Found 0 pods out of 5
Dec 22 21:27:37.316: INFO: Pod name wrapped-volume-race-923b3778-8c2d-44e6-a5fb-30770372a473: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-923b3778-8c2d-44e6-a5fb-30770372a473 in namespace emptydir-wrapper-6443, will wait for the garbage collector to delete the pods
Dec 22 21:27:49.417: INFO: Deleting ReplicationController wrapped-volume-race-923b3778-8c2d-44e6-a5fb-30770372a473 took: 5.612883ms
Dec 22 21:27:49.817: INFO: Terminating ReplicationController wrapped-volume-race-923b3778-8c2d-44e6-a5fb-30770372a473 pods took: 400.243918ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:28:32.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-6443" for this suite.
Dec 22 21:28:38.603: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:28:38.710: INFO: namespace emptydir-wrapper-6443 deletion completed in 6.112387407s

â€¢ [SLOW TEST:181.993 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:28:38.710: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:28:40.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-8637" for this suite.
Dec 22 21:29:24.757: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:29:24.915: INFO: namespace kubelet-test-8637 deletion completed in 44.16657731s

â€¢ [SLOW TEST:46.205 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a read only busybox container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:29:24.916: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-7c4c8e5d-da59-4c61-a8e8-bf3c1c9f7c45
STEP: Creating a pod to test consume configMaps
Dec 22 21:29:24.938: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-8e765e5d-fdeb-44b7-a169-366a909e0266" in namespace "projected-7187" to be "success or failure"
Dec 22 21:29:24.940: INFO: Pod "pod-projected-configmaps-8e765e5d-fdeb-44b7-a169-366a909e0266": Phase="Pending", Reason="", readiness=false. Elapsed: 2.212923ms
Dec 22 21:29:26.943: INFO: Pod "pod-projected-configmaps-8e765e5d-fdeb-44b7-a169-366a909e0266": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004622023s
STEP: Saw pod success
Dec 22 21:29:26.943: INFO: Pod "pod-projected-configmaps-8e765e5d-fdeb-44b7-a169-366a909e0266" satisfied condition "success or failure"
Dec 22 21:29:26.944: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod pod-projected-configmaps-8e765e5d-fdeb-44b7-a169-366a909e0266 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 22 21:29:26.963: INFO: Waiting for pod pod-projected-configmaps-8e765e5d-fdeb-44b7-a169-366a909e0266 to disappear
Dec 22 21:29:26.965: INFO: Pod pod-projected-configmaps-8e765e5d-fdeb-44b7-a169-366a909e0266 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:29:26.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7187" for this suite.
Dec 22 21:29:32.975: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:29:33.033: INFO: namespace projected-7187 deletion completed in 6.065383481s

â€¢ [SLOW TEST:8.117 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:29:33.033: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec 22 21:29:33.051: INFO: Creating deployment "nginx-deployment"
Dec 22 21:29:33.053: INFO: Waiting for observed generation 1
Dec 22 21:29:35.057: INFO: Waiting for all required pods to come up
Dec 22 21:29:35.061: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Dec 22 21:29:43.071: INFO: Waiting for deployment "nginx-deployment" to complete
Dec 22 21:29:43.074: INFO: Updating deployment "nginx-deployment" with a non-existent image
Dec 22 21:29:43.079: INFO: Updating deployment nginx-deployment
Dec 22 21:29:43.079: INFO: Waiting for observed generation 2
Dec 22 21:29:45.085: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Dec 22 21:29:45.087: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Dec 22 21:29:45.091: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Dec 22 21:29:45.098: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Dec 22 21:29:45.098: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Dec 22 21:29:45.101: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Dec 22 21:29:45.104: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Dec 22 21:29:45.104: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Dec 22 21:29:45.111: INFO: Updating deployment nginx-deployment
Dec 22 21:29:45.111: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Dec 22 21:29:45.126: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Dec 22 21:29:47.149: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Dec 22 21:29:47.154: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-1502,SelfLink:/apis/apps/v1/namespaces/deployment-1502/deployments/nginx-deployment,UID:37949c9f-6b64-475b-88f1-6300e2d2ab59,ResourceVersion:4416,Generation:3,CreationTimestamp:2019-12-22 21:29:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2019-12-22 21:29:45 +0000 UTC 2019-12-22 21:29:45 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-12-22 21:29:45 +0000 UTC 2019-12-22 21:29:33 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-55fb7cb77f" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Dec 22 21:29:47.157: INFO: New ReplicaSet "nginx-deployment-55fb7cb77f" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f,GenerateName:,Namespace:deployment-1502,SelfLink:/apis/apps/v1/namespaces/deployment-1502/replicasets/nginx-deployment-55fb7cb77f,UID:e42fc2b8-08d6-4a27-bbf1-88f185907091,ResourceVersion:4415,Generation:3,CreationTimestamp:2019-12-22 21:29:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 37949c9f-6b64-475b-88f1-6300e2d2ab59 0xc002959427 0xc002959428}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec 22 21:29:47.157: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Dec 22 21:29:47.157: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498,GenerateName:,Namespace:deployment-1502,SelfLink:/apis/apps/v1/namespaces/deployment-1502/replicasets/nginx-deployment-7b8c6f4498,UID:1c02151b-fecb-4886-8106-d5e89215fc09,ResourceVersion:4393,Generation:3,CreationTimestamp:2019-12-22 21:29:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 37949c9f-6b64-475b-88f1-6300e2d2ab59 0xc0029594f7 0xc0029594f8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Dec 22 21:29:47.164: INFO: Pod "nginx-deployment-55fb7cb77f-2x2v4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-2x2v4,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-1502,SelfLink:/api/v1/namespaces/deployment-1502/pods/nginx-deployment-55fb7cb77f-2x2v4,UID:98d094f6-42e6-43d9-831e-abcbb80fde5a,ResourceVersion:4369,Generation:0,CreationTimestamp:2019-12-22 21:29:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f e42fc2b8-08d6-4a27-bbf1-88f185907091 0xc0018e3650 0xc0018e3651}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5hrzh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hrzh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5hrzh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-121.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.121,PodIP:,StartTime:2019-12-22 21:29:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 22 21:29:47.164: INFO: Pod "nginx-deployment-55fb7cb77f-4dj8l" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-4dj8l,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-1502,SelfLink:/api/v1/namespaces/deployment-1502/pods/nginx-deployment-55fb7cb77f-4dj8l,UID:a4fd0353-795b-463b-8432-87c6426d702b,ResourceVersion:4301,Generation:0,CreationTimestamp:2019-12-22 21:29:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.20.27.35/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f e42fc2b8-08d6-4a27-bbf1-88f185907091 0xc0018e3780 0xc0018e3781}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5hrzh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hrzh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5hrzh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-121.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:43 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.121,PodIP:,StartTime:2019-12-22 21:29:43 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 22 21:29:47.165: INFO: Pod "nginx-deployment-55fb7cb77f-4mjks" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-4mjks,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-1502,SelfLink:/api/v1/namespaces/deployment-1502/pods/nginx-deployment-55fb7cb77f-4mjks,UID:8dd11a35-a88e-4a50-8ddd-6a183aaace3c,ResourceVersion:4316,Generation:0,CreationTimestamp:2019-12-22 21:29:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.20.29.201/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f e42fc2b8-08d6-4a27-bbf1-88f185907091 0xc0018e38b0 0xc0018e38b1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5hrzh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hrzh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5hrzh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-187.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:43 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.187,PodIP:,StartTime:2019-12-22 21:29:43 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 22 21:29:47.165: INFO: Pod "nginx-deployment-55fb7cb77f-5n9mh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-5n9mh,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-1502,SelfLink:/api/v1/namespaces/deployment-1502/pods/nginx-deployment-55fb7cb77f-5n9mh,UID:f7ef37cd-3ed6-4249-9d0c-c92a881d5311,ResourceVersion:4317,Generation:0,CreationTimestamp:2019-12-22 21:29:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.20.29.202/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f e42fc2b8-08d6-4a27-bbf1-88f185907091 0xc0018e39e0 0xc0018e39e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5hrzh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hrzh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5hrzh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-187.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:43 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.187,PodIP:,StartTime:2019-12-22 21:29:43 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 22 21:29:47.165: INFO: Pod "nginx-deployment-55fb7cb77f-6smkq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-6smkq,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-1502,SelfLink:/api/v1/namespaces/deployment-1502/pods/nginx-deployment-55fb7cb77f-6smkq,UID:0a9f5b92-f445-4ceb-a0c9-05fa62190ef2,ResourceVersion:4305,Generation:0,CreationTimestamp:2019-12-22 21:29:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.20.27.36/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f e42fc2b8-08d6-4a27-bbf1-88f185907091 0xc0018e3b10 0xc0018e3b11}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5hrzh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hrzh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5hrzh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-121.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:43 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.121,PodIP:,StartTime:2019-12-22 21:29:43 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 22 21:29:47.165: INFO: Pod "nginx-deployment-55fb7cb77f-7pcf2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-7pcf2,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-1502,SelfLink:/api/v1/namespaces/deployment-1502/pods/nginx-deployment-55fb7cb77f-7pcf2,UID:59798a4b-6776-43d0-b83f-f9675f3f7cf3,ResourceVersion:4429,Generation:0,CreationTimestamp:2019-12-22 21:29:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f e42fc2b8-08d6-4a27-bbf1-88f185907091 0xc0018e3c30 0xc0018e3c31}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5hrzh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hrzh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5hrzh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-187.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.187,PodIP:,StartTime:2019-12-22 21:29:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 22 21:29:47.166: INFO: Pod "nginx-deployment-55fb7cb77f-b9h75" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-b9h75,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-1502,SelfLink:/api/v1/namespaces/deployment-1502/pods/nginx-deployment-55fb7cb77f-b9h75,UID:6af79295-ff2d-421a-ac89-f64385935db2,ResourceVersion:4401,Generation:0,CreationTimestamp:2019-12-22 21:29:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f e42fc2b8-08d6-4a27-bbf1-88f185907091 0xc0018e3d50 0xc0018e3d51}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5hrzh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hrzh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5hrzh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-187.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.187,PodIP:,StartTime:2019-12-22 21:29:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 22 21:29:47.166: INFO: Pod "nginx-deployment-55fb7cb77f-f7knc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-f7knc,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-1502,SelfLink:/api/v1/namespaces/deployment-1502/pods/nginx-deployment-55fb7cb77f-f7knc,UID:86cfe6ab-52ea-4bd3-88f4-417e178fe630,ResourceVersion:4322,Generation:0,CreationTimestamp:2019-12-22 21:29:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.20.29.203/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f e42fc2b8-08d6-4a27-bbf1-88f185907091 0xc0018e3e80 0xc0018e3e81}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5hrzh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hrzh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5hrzh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-187.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:43 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.187,PodIP:,StartTime:2019-12-22 21:29:43 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 22 21:29:47.166: INFO: Pod "nginx-deployment-55fb7cb77f-f7wxp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-f7wxp,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-1502,SelfLink:/api/v1/namespaces/deployment-1502/pods/nginx-deployment-55fb7cb77f-f7wxp,UID:49f55cbb-bd50-42f7-ad41-01a857f4a644,ResourceVersion:4441,Generation:0,CreationTimestamp:2019-12-22 21:29:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f e42fc2b8-08d6-4a27-bbf1-88f185907091 0xc0018e3fc0 0xc0018e3fc1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5hrzh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hrzh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5hrzh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-121.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.121,PodIP:,StartTime:2019-12-22 21:29:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 22 21:29:47.166: INFO: Pod "nginx-deployment-55fb7cb77f-jgq9c" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-jgq9c,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-1502,SelfLink:/api/v1/namespaces/deployment-1502/pods/nginx-deployment-55fb7cb77f-jgq9c,UID:bded90d7-300e-451a-b0d4-ef235c7d375f,ResourceVersion:4442,Generation:0,CreationTimestamp:2019-12-22 21:29:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f e42fc2b8-08d6-4a27-bbf1-88f185907091 0xc001c360e0 0xc001c360e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5hrzh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hrzh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5hrzh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-187.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.187,PodIP:,StartTime:2019-12-22 21:29:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 22 21:29:47.167: INFO: Pod "nginx-deployment-55fb7cb77f-l8n49" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-l8n49,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-1502,SelfLink:/api/v1/namespaces/deployment-1502/pods/nginx-deployment-55fb7cb77f-l8n49,UID:07a6c07b-a435-43d3-a296-727d33e21ad9,ResourceVersion:4420,Generation:0,CreationTimestamp:2019-12-22 21:29:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f e42fc2b8-08d6-4a27-bbf1-88f185907091 0xc001c36200 0xc001c36201}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5hrzh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hrzh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5hrzh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-121.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.121,PodIP:,StartTime:2019-12-22 21:29:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 22 21:29:47.167: INFO: Pod "nginx-deployment-55fb7cb77f-lxj2x" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-lxj2x,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-1502,SelfLink:/api/v1/namespaces/deployment-1502/pods/nginx-deployment-55fb7cb77f-lxj2x,UID:2553a65e-4834-4b0d-8e8d-46f68ad3e1d6,ResourceVersion:4431,Generation:0,CreationTimestamp:2019-12-22 21:29:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f e42fc2b8-08d6-4a27-bbf1-88f185907091 0xc001c36320 0xc001c36321}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5hrzh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hrzh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5hrzh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-121.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.121,PodIP:,StartTime:2019-12-22 21:29:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 22 21:29:47.167: INFO: Pod "nginx-deployment-55fb7cb77f-r7vrg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-r7vrg,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-1502,SelfLink:/api/v1/namespaces/deployment-1502/pods/nginx-deployment-55fb7cb77f-r7vrg,UID:1638023c-44db-4c72-a08c-c0308d61cf8c,ResourceVersion:4411,Generation:0,CreationTimestamp:2019-12-22 21:29:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f e42fc2b8-08d6-4a27-bbf1-88f185907091 0xc001c36440 0xc001c36441}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5hrzh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hrzh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-5hrzh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-187.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.187,PodIP:,StartTime:2019-12-22 21:29:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 22 21:29:47.167: INFO: Pod "nginx-deployment-7b8c6f4498-4pch4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-4pch4,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1502,SelfLink:/api/v1/namespaces/deployment-1502/pods/nginx-deployment-7b8c6f4498-4pch4,UID:8162f8a5-7f9f-48b1-9ad6-322921ddfff0,ResourceVersion:4413,Generation:0,CreationTimestamp:2019-12-22 21:29:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 1c02151b-fecb-4886-8106-d5e89215fc09 0xc001c36560 0xc001c36561}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5hrzh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hrzh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5hrzh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-121.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.121,PodIP:,StartTime:2019-12-22 21:29:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 22 21:29:47.167: INFO: Pod "nginx-deployment-7b8c6f4498-694ll" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-694ll,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1502,SelfLink:/api/v1/namespaces/deployment-1502/pods/nginx-deployment-7b8c6f4498-694ll,UID:47f466c4-5a62-4112-8df2-1de1632f4e10,ResourceVersion:4378,Generation:0,CreationTimestamp:2019-12-22 21:29:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 1c02151b-fecb-4886-8106-d5e89215fc09 0xc001c36660 0xc001c36661}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5hrzh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hrzh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5hrzh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-187.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 22 21:29:47.168: INFO: Pod "nginx-deployment-7b8c6f4498-8shzs" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-8shzs,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1502,SelfLink:/api/v1/namespaces/deployment-1502/pods/nginx-deployment-7b8c6f4498-8shzs,UID:9cc0ca7b-944a-43d1-a4b1-0f8147567fc9,ResourceVersion:4398,Generation:0,CreationTimestamp:2019-12-22 21:29:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 1c02151b-fecb-4886-8106-d5e89215fc09 0xc001c36720 0xc001c36721}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5hrzh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hrzh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5hrzh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-187.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.187,PodIP:,StartTime:2019-12-22 21:29:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 22 21:29:47.168: INFO: Pod "nginx-deployment-7b8c6f4498-dwphn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-dwphn,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1502,SelfLink:/api/v1/namespaces/deployment-1502/pods/nginx-deployment-7b8c6f4498-dwphn,UID:6f78d8d7-ddc8-475c-affe-adb15113921d,ResourceVersion:4443,Generation:0,CreationTimestamp:2019-12-22 21:29:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 1c02151b-fecb-4886-8106-d5e89215fc09 0xc001c36820 0xc001c36821}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5hrzh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hrzh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5hrzh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-121.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.121,PodIP:,StartTime:2019-12-22 21:29:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 22 21:29:47.168: INFO: Pod "nginx-deployment-7b8c6f4498-f2flv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-f2flv,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1502,SelfLink:/api/v1/namespaces/deployment-1502/pods/nginx-deployment-7b8c6f4498-f2flv,UID:67fcbba2-ec3a-49c3-9f5f-6b4b961cc3ad,ResourceVersion:4390,Generation:0,CreationTimestamp:2019-12-22 21:29:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 1c02151b-fecb-4886-8106-d5e89215fc09 0xc001c36920 0xc001c36921}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5hrzh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hrzh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5hrzh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-121.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.121,PodIP:,StartTime:2019-12-22 21:29:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 22 21:29:47.168: INFO: Pod "nginx-deployment-7b8c6f4498-f7mkw" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-f7mkw,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1502,SelfLink:/api/v1/namespaces/deployment-1502/pods/nginx-deployment-7b8c6f4498-f7mkw,UID:1df17ed0-49a6-4141-a6cd-16c66c0bdb10,ResourceVersion:4202,Generation:0,CreationTimestamp:2019-12-22 21:29:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.20.27.30/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 1c02151b-fecb-4886-8106-d5e89215fc09 0xc001c36a30 0xc001c36a31}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5hrzh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hrzh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5hrzh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-121.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:33 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:36 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:36 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:33 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.121,PodIP:10.20.27.30,StartTime:2019-12-22 21:29:33 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-12-22 21:29:35 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://6ec241961a66ea68ec3bc9ac22b774aabbd97a1efd388ee0e5a6407e7a87d607}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 22 21:29:47.169: INFO: Pod "nginx-deployment-7b8c6f4498-jpwqk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-jpwqk,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1502,SelfLink:/api/v1/namespaces/deployment-1502/pods/nginx-deployment-7b8c6f4498-jpwqk,UID:f6c749c1-7c4d-44bb-87ae-ac33d41a5b14,ResourceVersion:4419,Generation:0,CreationTimestamp:2019-12-22 21:29:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 1c02151b-fecb-4886-8106-d5e89215fc09 0xc001c36b40 0xc001c36b41}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5hrzh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hrzh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5hrzh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-187.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.187,PodIP:,StartTime:2019-12-22 21:29:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 22 21:29:47.169: INFO: Pod "nginx-deployment-7b8c6f4498-k44lb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-k44lb,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1502,SelfLink:/api/v1/namespaces/deployment-1502/pods/nginx-deployment-7b8c6f4498-k44lb,UID:46dd2b88-e69a-4368-9c07-f14efb2ac8bd,ResourceVersion:4352,Generation:0,CreationTimestamp:2019-12-22 21:29:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 1c02151b-fecb-4886-8106-d5e89215fc09 0xc001c36c40 0xc001c36c41}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5hrzh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hrzh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5hrzh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-187.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.187,PodIP:,StartTime:2019-12-22 21:29:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 22 21:29:47.169: INFO: Pod "nginx-deployment-7b8c6f4498-l4twg" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-l4twg,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1502,SelfLink:/api/v1/namespaces/deployment-1502/pods/nginx-deployment-7b8c6f4498-l4twg,UID:b6f6c1bd-50e0-474d-b74c-71c0c3b973ff,ResourceVersion:4190,Generation:0,CreationTimestamp:2019-12-22 21:29:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.20.27.34/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 1c02151b-fecb-4886-8106-d5e89215fc09 0xc001c36d50 0xc001c36d51}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5hrzh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hrzh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5hrzh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-121.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:33 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:36 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:36 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:33 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.121,PodIP:10.20.27.34,StartTime:2019-12-22 21:29:33 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-12-22 21:29:36 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://81b49b824eb925d904d77d47c849204a73267dd6e00c0c00104544db9644fbf9}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 22 21:29:47.169: INFO: Pod "nginx-deployment-7b8c6f4498-lddsg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-lddsg,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1502,SelfLink:/api/v1/namespaces/deployment-1502/pods/nginx-deployment-7b8c6f4498-lddsg,UID:8157cd1f-c20e-4199-af37-a358362ae941,ResourceVersion:4384,Generation:0,CreationTimestamp:2019-12-22 21:29:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 1c02151b-fecb-4886-8106-d5e89215fc09 0xc001c36e60 0xc001c36e61}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5hrzh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hrzh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5hrzh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-187.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.187,PodIP:,StartTime:2019-12-22 21:29:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 22 21:29:47.169: INFO: Pod "nginx-deployment-7b8c6f4498-ll57s" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-ll57s,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1502,SelfLink:/api/v1/namespaces/deployment-1502/pods/nginx-deployment-7b8c6f4498-ll57s,UID:69320008-a867-4d88-8273-48bcb607180f,ResourceVersion:4447,Generation:0,CreationTimestamp:2019-12-22 21:29:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 1c02151b-fecb-4886-8106-d5e89215fc09 0xc001c36f60 0xc001c36f61}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5hrzh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hrzh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5hrzh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-187.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.187,PodIP:,StartTime:2019-12-22 21:29:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 22 21:29:47.169: INFO: Pod "nginx-deployment-7b8c6f4498-mc2dk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-mc2dk,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1502,SelfLink:/api/v1/namespaces/deployment-1502/pods/nginx-deployment-7b8c6f4498-mc2dk,UID:04fd23bf-4299-4e78-8c8f-80bfd9c462d2,ResourceVersion:4412,Generation:0,CreationTimestamp:2019-12-22 21:29:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 1c02151b-fecb-4886-8106-d5e89215fc09 0xc001c37070 0xc001c37071}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5hrzh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hrzh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5hrzh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-121.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.121,PodIP:,StartTime:2019-12-22 21:29:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 22 21:29:47.170: INFO: Pod "nginx-deployment-7b8c6f4498-n7cd8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-n7cd8,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1502,SelfLink:/api/v1/namespaces/deployment-1502/pods/nginx-deployment-7b8c6f4498-n7cd8,UID:3a6f7739-3d1f-4328-897d-dbfd628caab0,ResourceVersion:4403,Generation:0,CreationTimestamp:2019-12-22 21:29:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 1c02151b-fecb-4886-8106-d5e89215fc09 0xc001c37170 0xc001c37171}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5hrzh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hrzh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5hrzh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-121.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.121,PodIP:,StartTime:2019-12-22 21:29:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 22 21:29:47.170: INFO: Pod "nginx-deployment-7b8c6f4498-nh26w" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-nh26w,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1502,SelfLink:/api/v1/namespaces/deployment-1502/pods/nginx-deployment-7b8c6f4498-nh26w,UID:f2162949-7083-4c3c-a170-0ed514ca1606,ResourceVersion:4193,Generation:0,CreationTimestamp:2019-12-22 21:29:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.20.27.32/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 1c02151b-fecb-4886-8106-d5e89215fc09 0xc001c37280 0xc001c37281}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5hrzh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hrzh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5hrzh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-121.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:33 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:36 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:36 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:33 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.121,PodIP:10.20.27.32,StartTime:2019-12-22 21:29:33 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-12-22 21:29:36 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://cad795d251e5c3def4685d1546c32f72689dc3e8321cd6a93c5ddaf88a577d73}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 22 21:29:47.170: INFO: Pod "nginx-deployment-7b8c6f4498-q8mt2" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-q8mt2,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1502,SelfLink:/api/v1/namespaces/deployment-1502/pods/nginx-deployment-7b8c6f4498-q8mt2,UID:eb200c68-8e23-4382-803a-08bc03ca4826,ResourceVersion:4196,Generation:0,CreationTimestamp:2019-12-22 21:29:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.20.27.29/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 1c02151b-fecb-4886-8106-d5e89215fc09 0xc001c373a0 0xc001c373a1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5hrzh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hrzh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5hrzh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-121.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:33 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:36 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:36 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:33 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.121,PodIP:10.20.27.29,StartTime:2019-12-22 21:29:33 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-12-22 21:29:35 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://8242574874f3d19aac149d3a653d79e2f0ac1573d9751b1384f167e60045c7ab}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 22 21:29:47.170: INFO: Pod "nginx-deployment-7b8c6f4498-r547r" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-r547r,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1502,SelfLink:/api/v1/namespaces/deployment-1502/pods/nginx-deployment-7b8c6f4498-r547r,UID:ff8d1867-aa02-48d8-a7ae-ae83d6726b0c,ResourceVersion:4199,Generation:0,CreationTimestamp:2019-12-22 21:29:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.20.27.33/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 1c02151b-fecb-4886-8106-d5e89215fc09 0xc001c374c0 0xc001c374c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5hrzh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hrzh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5hrzh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-121.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:33 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:36 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:36 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:33 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.121,PodIP:10.20.27.33,StartTime:2019-12-22 21:29:33 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-12-22 21:29:36 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://af5a251d787f25c2d600b6b8da11a255d17699606c6420d45f0639da6a847938}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 22 21:29:47.170: INFO: Pod "nginx-deployment-7b8c6f4498-rl57w" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-rl57w,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1502,SelfLink:/api/v1/namespaces/deployment-1502/pods/nginx-deployment-7b8c6f4498-rl57w,UID:a71bdcdb-cd95-493b-81e5-52a6763b11c0,ResourceVersion:4439,Generation:0,CreationTimestamp:2019-12-22 21:29:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 1c02151b-fecb-4886-8106-d5e89215fc09 0xc001c375d0 0xc001c375d1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5hrzh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hrzh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5hrzh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-187.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:45 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.187,PodIP:,StartTime:2019-12-22 21:29:45 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 22 21:29:47.170: INFO: Pod "nginx-deployment-7b8c6f4498-sb4rc" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-sb4rc,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1502,SelfLink:/api/v1/namespaces/deployment-1502/pods/nginx-deployment-7b8c6f4498-sb4rc,UID:44f9b63e-0ff9-48c1-871f-ac373c193fe5,ResourceVersion:4206,Generation:0,CreationTimestamp:2019-12-22 21:29:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.20.27.31/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 1c02151b-fecb-4886-8106-d5e89215fc09 0xc001c376e0 0xc001c376e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5hrzh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hrzh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5hrzh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-121.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:33 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:36 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:36 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:33 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.121,PodIP:10.20.27.31,StartTime:2019-12-22 21:29:33 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-12-22 21:29:35 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://b110e9dc10525edd1ccbeadb2f9c68aed1eec84a7dabe36f155130bb831a5ca6}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 22 21:29:47.171: INFO: Pod "nginx-deployment-7b8c6f4498-x26wz" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-x26wz,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1502,SelfLink:/api/v1/namespaces/deployment-1502/pods/nginx-deployment-7b8c6f4498-x26wz,UID:eccf4d6f-4295-4d66-978b-1b8e9ef63316,ResourceVersion:4220,Generation:0,CreationTimestamp:2019-12-22 21:29:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.20.29.198/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 1c02151b-fecb-4886-8106-d5e89215fc09 0xc001c37800 0xc001c37801}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5hrzh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hrzh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5hrzh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-187.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:33 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:39 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:39 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:33 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.187,PodIP:10.20.29.198,StartTime:2019-12-22 21:29:33 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-12-22 21:29:38 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://0ad844124661dcb96ad2926cc2cb4d0064d2e2e1d61c85a7a4b46e100c262127}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec 22 21:29:47.171: INFO: Pod "nginx-deployment-7b8c6f4498-xs25n" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-xs25n,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-1502,SelfLink:/api/v1/namespaces/deployment-1502/pods/nginx-deployment-7b8c6f4498-xs25n,UID:1bdcd353-5dde-4e26-8fd6-26ab6f052f77,ResourceVersion:4213,Generation:0,CreationTimestamp:2019-12-22 21:29:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.20.29.197/32,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 1c02151b-fecb-4886-8106-d5e89215fc09 0xc001c37920 0xc001c37921}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5hrzh {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5hrzh,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5hrzh true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-187.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:33 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:38 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:38 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:29:33 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.187,PodIP:10.20.29.197,StartTime:2019-12-22 21:29:33 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-12-22 21:29:37 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://77b8be6be7aded2d13902d7e3e319fa2d32b408525a1315bd433c86e49e6ea2a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:29:47.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1502" for this suite.
Dec 22 21:29:53.181: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:29:53.558: INFO: namespace deployment-1502 deletion completed in 6.384021517s

â€¢ [SLOW TEST:20.525 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:29:53.558: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:30:01.636: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3451" for this suite.
Dec 22 21:30:07.646: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:30:07.717: INFO: namespace kubelet-test-3451 deletion completed in 6.078327141s

â€¢ [SLOW TEST:14.159 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:30:07.719: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec 22 21:30:07.742: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 version'
Dec 22 21:30:07.847: INFO: stderr: ""
Dec 22 21:30:07.847: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.7\", GitCommit:\"6c143d35bb11d74970e7bc0b6c45b6bfdffc0bd4\", GitTreeState:\"clean\", BuildDate:\"2019-12-11T12:42:56Z\", GoVersion:\"go1.12.12\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.7\", GitCommit:\"6c143d35bb11d74970e7bc0b6c45b6bfdffc0bd4\", GitTreeState:\"clean\", BuildDate:\"2019-12-11T12:34:17Z\", GoVersion:\"go1.12.12\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:30:07.847: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-389" for this suite.
Dec 22 21:30:13.871: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:30:13.930: INFO: namespace kubectl-389 deletion completed in 6.067888293s

â€¢ [SLOW TEST:6.212 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl version
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:30:13.931: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-secret-zpp2
STEP: Creating a pod to test atomic-volume-subpath
Dec 22 21:30:13.959: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-zpp2" in namespace "subpath-7805" to be "success or failure"
Dec 22 21:30:13.963: INFO: Pod "pod-subpath-test-secret-zpp2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.243542ms
Dec 22 21:30:15.966: INFO: Pod "pod-subpath-test-secret-zpp2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006870857s
Dec 22 21:30:17.969: INFO: Pod "pod-subpath-test-secret-zpp2": Phase="Running", Reason="", readiness=true. Elapsed: 4.009593329s
Dec 22 21:30:19.971: INFO: Pod "pod-subpath-test-secret-zpp2": Phase="Running", Reason="", readiness=true. Elapsed: 6.012543361s
Dec 22 21:30:21.975: INFO: Pod "pod-subpath-test-secret-zpp2": Phase="Running", Reason="", readiness=true. Elapsed: 8.015694081s
Dec 22 21:30:23.977: INFO: Pod "pod-subpath-test-secret-zpp2": Phase="Running", Reason="", readiness=true. Elapsed: 10.018572637s
Dec 22 21:30:25.980: INFO: Pod "pod-subpath-test-secret-zpp2": Phase="Running", Reason="", readiness=true. Elapsed: 12.021441341s
Dec 22 21:30:27.983: INFO: Pod "pod-subpath-test-secret-zpp2": Phase="Running", Reason="", readiness=true. Elapsed: 14.023996634s
Dec 22 21:30:29.986: INFO: Pod "pod-subpath-test-secret-zpp2": Phase="Running", Reason="", readiness=true. Elapsed: 16.027184931s
Dec 22 21:30:31.989: INFO: Pod "pod-subpath-test-secret-zpp2": Phase="Running", Reason="", readiness=true. Elapsed: 18.029943048s
Dec 22 21:30:33.991: INFO: Pod "pod-subpath-test-secret-zpp2": Phase="Running", Reason="", readiness=true. Elapsed: 20.032437123s
Dec 22 21:30:35.994: INFO: Pod "pod-subpath-test-secret-zpp2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.035442135s
STEP: Saw pod success
Dec 22 21:30:35.994: INFO: Pod "pod-subpath-test-secret-zpp2" satisfied condition "success or failure"
Dec 22 21:30:35.996: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod pod-subpath-test-secret-zpp2 container test-container-subpath-secret-zpp2: <nil>
STEP: delete the pod
Dec 22 21:30:36.010: INFO: Waiting for pod pod-subpath-test-secret-zpp2 to disappear
Dec 22 21:30:36.012: INFO: Pod pod-subpath-test-secret-zpp2 no longer exists
STEP: Deleting pod pod-subpath-test-secret-zpp2
Dec 22 21:30:36.012: INFO: Deleting pod "pod-subpath-test-secret-zpp2" in namespace "subpath-7805"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:30:36.013: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7805" for this suite.
Dec 22 21:30:42.024: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:30:42.092: INFO: namespace subpath-7805 deletion completed in 6.074958281s

â€¢ [SLOW TEST:28.161 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:30:42.092: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec 22 21:30:42.114: INFO: Waiting up to 5m0s for pod "pod-5d2b3a63-c625-49da-b907-32ec942ad3a3" in namespace "emptydir-4418" to be "success or failure"
Dec 22 21:30:42.117: INFO: Pod "pod-5d2b3a63-c625-49da-b907-32ec942ad3a3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.137208ms
Dec 22 21:30:44.121: INFO: Pod "pod-5d2b3a63-c625-49da-b907-32ec942ad3a3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006704065s
Dec 22 21:30:46.124: INFO: Pod "pod-5d2b3a63-c625-49da-b907-32ec942ad3a3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009637045s
STEP: Saw pod success
Dec 22 21:30:46.124: INFO: Pod "pod-5d2b3a63-c625-49da-b907-32ec942ad3a3" satisfied condition "success or failure"
Dec 22 21:30:46.126: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod pod-5d2b3a63-c625-49da-b907-32ec942ad3a3 container test-container: <nil>
STEP: delete the pod
Dec 22 21:30:46.141: INFO: Waiting for pod pod-5d2b3a63-c625-49da-b907-32ec942ad3a3 to disappear
Dec 22 21:30:46.144: INFO: Pod pod-5d2b3a63-c625-49da-b907-32ec942ad3a3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:30:46.144: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4418" for this suite.
Dec 22 21:30:52.159: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:30:52.333: INFO: namespace emptydir-4418 deletion completed in 6.184841083s

â€¢ [SLOW TEST:10.241 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:30:52.333: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: validating cluster-info
Dec 22 21:30:52.359: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 cluster-info'
Dec 22 21:30:52.438: INFO: stderr: ""
Dec 22 21:30:52.438: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.21.0.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://10.21.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mMetrics-server\x1b[0m is running at \x1b[0;33mhttps://10.21.0.1:443/api/v1/namespaces/kube-system/services/https:metrics-server:/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:30:52.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4054" for this suite.
Dec 22 21:30:58.448: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:30:58.517: INFO: namespace kubectl-4054 deletion completed in 6.076004445s

â€¢ [SLOW TEST:6.184 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:30:58.517: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-2513
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a new StatefulSet
Dec 22 21:30:58.605: INFO: Found 0 stateful pods, waiting for 3
Dec 22 21:31:08.608: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 22 21:31:08.608: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 22 21:31:08.608: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Dec 22 21:31:08.615: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-2513 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 22 21:31:08.826: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Dec 22 21:31:08.826: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 22 21:31:08.827: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Dec 22 21:31:18.853: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Dec 22 21:31:28.870: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-2513 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 22 21:31:29.127: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Dec 22 21:31:29.127: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 22 21:31:29.127: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 22 21:31:39.148: INFO: Waiting for StatefulSet statefulset-2513/ss2 to complete update
Dec 22 21:31:39.148: INFO: Waiting for Pod statefulset-2513/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Dec 22 21:31:39.148: INFO: Waiting for Pod statefulset-2513/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Dec 22 21:31:39.148: INFO: Waiting for Pod statefulset-2513/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Dec 22 21:31:49.153: INFO: Waiting for StatefulSet statefulset-2513/ss2 to complete update
Dec 22 21:31:49.153: INFO: Waiting for Pod statefulset-2513/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Dec 22 21:31:49.153: INFO: Waiting for Pod statefulset-2513/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Dec 22 21:31:59.154: INFO: Waiting for StatefulSet statefulset-2513/ss2 to complete update
Dec 22 21:31:59.154: INFO: Waiting for Pod statefulset-2513/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Rolling back to a previous revision
Dec 22 21:32:09.154: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-2513 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 22 21:32:09.636: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Dec 22 21:32:09.636: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 22 21:32:09.636: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 22 21:32:19.661: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Dec 22 21:32:29.674: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-2513 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 22 21:32:29.917: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Dec 22 21:32:29.917: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 22 21:32:29.917: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 22 21:32:39.932: INFO: Waiting for StatefulSet statefulset-2513/ss2 to complete update
Dec 22 21:32:39.932: INFO: Waiting for Pod statefulset-2513/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Dec 22 21:32:49.941: INFO: Waiting for StatefulSet statefulset-2513/ss2 to complete update
Dec 22 21:32:49.941: INFO: Waiting for Pod statefulset-2513/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Dec 22 21:32:59.939: INFO: Deleting all statefulset in ns statefulset-2513
Dec 22 21:32:59.941: INFO: Scaling statefulset ss2 to 0
Dec 22 21:33:39.976: INFO: Waiting for statefulset status.replicas updated to 0
Dec 22 21:33:39.978: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:33:39.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2513" for this suite.
Dec 22 21:33:45.996: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:33:46.113: INFO: namespace statefulset-2513 deletion completed in 6.124042465s

â€¢ [SLOW TEST:167.595 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:33:46.113: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Dec 22 21:33:48.714: INFO: Successfully updated pod "annotationupdateb16bdf56-1752-4800-8970-82afaad6a6a8"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:33:52.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-997" for this suite.
Dec 22 21:34:14.750: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:34:14.810: INFO: namespace projected-997 deletion completed in 22.066923194s

â€¢ [SLOW TEST:28.697 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:34:14.811: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5016.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-5016.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5016.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-5016.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-5016.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-5016.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-5016.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-5016.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-5016.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-5016.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-5016.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-5016.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5016.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 125.197.21.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.21.197.125_udp@PTR;check="$$(dig +tcp +noall +answer +search 125.197.21.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.21.197.125_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5016.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-5016.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5016.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-5016.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-5016.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-5016.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-5016.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-5016.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-5016.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-5016.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-5016.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-5016.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5016.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 125.197.21.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.21.197.125_udp@PTR;check="$$(dig +tcp +noall +answer +search 125.197.21.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.21.197.125_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 22 21:34:24.874: INFO: Unable to read wheezy_udp@dns-test-service.dns-5016.svc.cluster.local from pod dns-5016/dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d: the server could not find the requested resource (get pods dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d)
Dec 22 21:34:24.877: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5016.svc.cluster.local from pod dns-5016/dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d: the server could not find the requested resource (get pods dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d)
Dec 22 21:34:24.880: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5016.svc.cluster.local from pod dns-5016/dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d: the server could not find the requested resource (get pods dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d)
Dec 22 21:34:24.883: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5016.svc.cluster.local from pod dns-5016/dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d: the server could not find the requested resource (get pods dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d)
Dec 22 21:34:24.912: INFO: Unable to read jessie_udp@dns-test-service.dns-5016.svc.cluster.local from pod dns-5016/dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d: the server could not find the requested resource (get pods dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d)
Dec 22 21:34:24.915: INFO: Unable to read jessie_tcp@dns-test-service.dns-5016.svc.cluster.local from pod dns-5016/dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d: the server could not find the requested resource (get pods dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d)
Dec 22 21:34:24.917: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5016.svc.cluster.local from pod dns-5016/dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d: the server could not find the requested resource (get pods dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d)
Dec 22 21:34:24.919: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5016.svc.cluster.local from pod dns-5016/dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d: the server could not find the requested resource (get pods dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d)
Dec 22 21:34:24.933: INFO: Lookups using dns-5016/dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d failed for: [wheezy_udp@dns-test-service.dns-5016.svc.cluster.local wheezy_tcp@dns-test-service.dns-5016.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-5016.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5016.svc.cluster.local jessie_udp@dns-test-service.dns-5016.svc.cluster.local jessie_tcp@dns-test-service.dns-5016.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5016.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5016.svc.cluster.local]

Dec 22 21:34:29.937: INFO: Unable to read wheezy_udp@dns-test-service.dns-5016.svc.cluster.local from pod dns-5016/dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d: the server could not find the requested resource (get pods dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d)
Dec 22 21:34:29.940: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5016.svc.cluster.local from pod dns-5016/dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d: the server could not find the requested resource (get pods dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d)
Dec 22 21:34:29.943: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5016.svc.cluster.local from pod dns-5016/dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d: the server could not find the requested resource (get pods dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d)
Dec 22 21:34:29.948: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5016.svc.cluster.local from pod dns-5016/dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d: the server could not find the requested resource (get pods dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d)
Dec 22 21:34:29.966: INFO: Unable to read jessie_udp@dns-test-service.dns-5016.svc.cluster.local from pod dns-5016/dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d: the server could not find the requested resource (get pods dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d)
Dec 22 21:34:29.969: INFO: Unable to read jessie_tcp@dns-test-service.dns-5016.svc.cluster.local from pod dns-5016/dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d: the server could not find the requested resource (get pods dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d)
Dec 22 21:34:29.971: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5016.svc.cluster.local from pod dns-5016/dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d: the server could not find the requested resource (get pods dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d)
Dec 22 21:34:29.974: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5016.svc.cluster.local from pod dns-5016/dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d: the server could not find the requested resource (get pods dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d)
Dec 22 21:34:29.993: INFO: Lookups using dns-5016/dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d failed for: [wheezy_udp@dns-test-service.dns-5016.svc.cluster.local wheezy_tcp@dns-test-service.dns-5016.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-5016.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5016.svc.cluster.local jessie_udp@dns-test-service.dns-5016.svc.cluster.local jessie_tcp@dns-test-service.dns-5016.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5016.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5016.svc.cluster.local]

Dec 22 21:34:34.939: INFO: Unable to read wheezy_udp@dns-test-service.dns-5016.svc.cluster.local from pod dns-5016/dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d: the server could not find the requested resource (get pods dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d)
Dec 22 21:34:34.942: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5016.svc.cluster.local from pod dns-5016/dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d: the server could not find the requested resource (get pods dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d)
Dec 22 21:34:34.944: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5016.svc.cluster.local from pod dns-5016/dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d: the server could not find the requested resource (get pods dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d)
Dec 22 21:34:34.946: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5016.svc.cluster.local from pod dns-5016/dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d: the server could not find the requested resource (get pods dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d)
Dec 22 21:34:34.964: INFO: Unable to read jessie_udp@dns-test-service.dns-5016.svc.cluster.local from pod dns-5016/dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d: the server could not find the requested resource (get pods dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d)
Dec 22 21:34:34.966: INFO: Unable to read jessie_tcp@dns-test-service.dns-5016.svc.cluster.local from pod dns-5016/dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d: the server could not find the requested resource (get pods dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d)
Dec 22 21:34:34.968: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5016.svc.cluster.local from pod dns-5016/dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d: the server could not find the requested resource (get pods dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d)
Dec 22 21:34:34.971: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5016.svc.cluster.local from pod dns-5016/dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d: the server could not find the requested resource (get pods dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d)
Dec 22 21:34:34.984: INFO: Lookups using dns-5016/dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d failed for: [wheezy_udp@dns-test-service.dns-5016.svc.cluster.local wheezy_tcp@dns-test-service.dns-5016.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-5016.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5016.svc.cluster.local jessie_udp@dns-test-service.dns-5016.svc.cluster.local jessie_tcp@dns-test-service.dns-5016.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5016.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5016.svc.cluster.local]

Dec 22 21:34:39.937: INFO: Unable to read wheezy_udp@dns-test-service.dns-5016.svc.cluster.local from pod dns-5016/dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d: the server could not find the requested resource (get pods dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d)
Dec 22 21:34:39.940: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5016.svc.cluster.local from pod dns-5016/dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d: the server could not find the requested resource (get pods dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d)
Dec 22 21:34:39.942: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5016.svc.cluster.local from pod dns-5016/dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d: the server could not find the requested resource (get pods dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d)
Dec 22 21:34:39.945: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5016.svc.cluster.local from pod dns-5016/dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d: the server could not find the requested resource (get pods dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d)
Dec 22 21:34:39.965: INFO: Unable to read jessie_udp@dns-test-service.dns-5016.svc.cluster.local from pod dns-5016/dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d: the server could not find the requested resource (get pods dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d)
Dec 22 21:34:39.968: INFO: Unable to read jessie_tcp@dns-test-service.dns-5016.svc.cluster.local from pod dns-5016/dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d: the server could not find the requested resource (get pods dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d)
Dec 22 21:34:39.970: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5016.svc.cluster.local from pod dns-5016/dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d: the server could not find the requested resource (get pods dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d)
Dec 22 21:34:39.972: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5016.svc.cluster.local from pod dns-5016/dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d: the server could not find the requested resource (get pods dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d)
Dec 22 21:34:39.986: INFO: Lookups using dns-5016/dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d failed for: [wheezy_udp@dns-test-service.dns-5016.svc.cluster.local wheezy_tcp@dns-test-service.dns-5016.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-5016.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5016.svc.cluster.local jessie_udp@dns-test-service.dns-5016.svc.cluster.local jessie_tcp@dns-test-service.dns-5016.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5016.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5016.svc.cluster.local]

Dec 22 21:34:44.936: INFO: Unable to read wheezy_udp@dns-test-service.dns-5016.svc.cluster.local from pod dns-5016/dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d: the server could not find the requested resource (get pods dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d)
Dec 22 21:34:44.939: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5016.svc.cluster.local from pod dns-5016/dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d: the server could not find the requested resource (get pods dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d)
Dec 22 21:34:44.941: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5016.svc.cluster.local from pod dns-5016/dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d: the server could not find the requested resource (get pods dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d)
Dec 22 21:34:44.944: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5016.svc.cluster.local from pod dns-5016/dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d: the server could not find the requested resource (get pods dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d)
Dec 22 21:34:44.959: INFO: Unable to read jessie_udp@dns-test-service.dns-5016.svc.cluster.local from pod dns-5016/dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d: the server could not find the requested resource (get pods dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d)
Dec 22 21:34:44.961: INFO: Unable to read jessie_tcp@dns-test-service.dns-5016.svc.cluster.local from pod dns-5016/dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d: the server could not find the requested resource (get pods dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d)
Dec 22 21:34:44.964: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5016.svc.cluster.local from pod dns-5016/dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d: the server could not find the requested resource (get pods dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d)
Dec 22 21:34:44.966: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5016.svc.cluster.local from pod dns-5016/dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d: the server could not find the requested resource (get pods dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d)
Dec 22 21:34:44.978: INFO: Lookups using dns-5016/dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d failed for: [wheezy_udp@dns-test-service.dns-5016.svc.cluster.local wheezy_tcp@dns-test-service.dns-5016.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-5016.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5016.svc.cluster.local jessie_udp@dns-test-service.dns-5016.svc.cluster.local jessie_tcp@dns-test-service.dns-5016.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5016.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5016.svc.cluster.local]

Dec 22 21:34:49.982: INFO: DNS probes using dns-5016/dns-test-f9f7e272-905c-4cb0-af79-1804ab324f4d succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:34:50.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5016" for this suite.
Dec 22 21:34:56.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:34:56.209: INFO: namespace dns-5016 deletion completed in 6.080446695s

â€¢ [SLOW TEST:41.399 seconds]
[sig-network] DNS
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:34:56.210: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec 22 21:34:56.233: INFO: Waiting up to 5m0s for pod "downwardapi-volume-497d131f-8bf8-42a7-80cb-db2e8d87cff1" in namespace "projected-6061" to be "success or failure"
Dec 22 21:34:56.236: INFO: Pod "downwardapi-volume-497d131f-8bf8-42a7-80cb-db2e8d87cff1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.710585ms
Dec 22 21:34:58.238: INFO: Pod "downwardapi-volume-497d131f-8bf8-42a7-80cb-db2e8d87cff1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005015636s
STEP: Saw pod success
Dec 22 21:34:58.238: INFO: Pod "downwardapi-volume-497d131f-8bf8-42a7-80cb-db2e8d87cff1" satisfied condition "success or failure"
Dec 22 21:34:58.241: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod downwardapi-volume-497d131f-8bf8-42a7-80cb-db2e8d87cff1 container client-container: <nil>
STEP: delete the pod
Dec 22 21:34:58.267: INFO: Waiting for pod downwardapi-volume-497d131f-8bf8-42a7-80cb-db2e8d87cff1 to disappear
Dec 22 21:34:58.271: INFO: Pod downwardapi-volume-497d131f-8bf8-42a7-80cb-db2e8d87cff1 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:34:58.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6061" for this suite.
Dec 22 21:35:04.283: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:35:04.377: INFO: namespace projected-6061 deletion completed in 6.103034489s

â€¢ [SLOW TEST:8.168 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:35:04.378: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec 22 21:35:04.408: INFO: Creating ReplicaSet my-hostname-basic-338125d6-9fba-480c-8828-cd8648b5d634
Dec 22 21:35:04.415: INFO: Pod name my-hostname-basic-338125d6-9fba-480c-8828-cd8648b5d634: Found 0 pods out of 1
Dec 22 21:35:09.418: INFO: Pod name my-hostname-basic-338125d6-9fba-480c-8828-cd8648b5d634: Found 1 pods out of 1
Dec 22 21:35:09.418: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-338125d6-9fba-480c-8828-cd8648b5d634" is running
Dec 22 21:35:09.420: INFO: Pod "my-hostname-basic-338125d6-9fba-480c-8828-cd8648b5d634-4r2f2" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-22 21:35:04 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-22 21:35:07 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-22 21:35:07 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-22 21:35:04 +0000 UTC Reason: Message:}])
Dec 22 21:35:09.420: INFO: Trying to dial the pod
Dec 22 21:35:14.427: INFO: Controller my-hostname-basic-338125d6-9fba-480c-8828-cd8648b5d634: Got expected result from replica 1 [my-hostname-basic-338125d6-9fba-480c-8828-cd8648b5d634-4r2f2]: "my-hostname-basic-338125d6-9fba-480c-8828-cd8648b5d634-4r2f2", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:35:14.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-7923" for this suite.
Dec 22 21:35:20.436: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:35:20.511: INFO: namespace replicaset-7923 deletion completed in 6.081502712s

â€¢ [SLOW TEST:16.133 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:35:20.511: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:35:22.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7249" for this suite.
Dec 22 21:36:06.556: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:36:06.625: INFO: namespace kubelet-test-7249 deletion completed in 44.076792966s

â€¢ [SLOW TEST:46.113 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:36:06.625: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-613
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-613
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-613
Dec 22 21:36:06.724: INFO: Found 0 stateful pods, waiting for 1
Dec 22 21:36:16.726: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Dec 22 21:36:16.729: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-613 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 22 21:36:17.099: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Dec 22 21:36:17.099: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 22 21:36:17.099: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 22 21:36:17.104: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec 22 21:36:27.107: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 22 21:36:27.107: INFO: Waiting for statefulset status.replicas updated to 0
Dec 22 21:36:27.117: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999741s
Dec 22 21:36:28.121: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.996666218s
Dec 22 21:36:29.123: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.993570921s
Dec 22 21:36:30.126: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.990687993s
Dec 22 21:36:31.129: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.987886259s
Dec 22 21:36:32.132: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.985044866s
Dec 22 21:36:33.135: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.982266423s
Dec 22 21:36:34.138: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.979296366s
Dec 22 21:36:35.141: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.976222401s
Dec 22 21:36:36.144: INFO: Verifying statefulset ss doesn't scale past 1 for another 973.406551ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-613
Dec 22 21:36:37.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-613 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 22 21:36:37.459: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Dec 22 21:36:37.459: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 22 21:36:37.459: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 22 21:36:37.462: INFO: Found 1 stateful pods, waiting for 3
Dec 22 21:36:47.465: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 22 21:36:47.465: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 22 21:36:47.465: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Dec 22 21:36:47.469: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-613 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 22 21:36:47.701: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Dec 22 21:36:47.701: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 22 21:36:47.701: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 22 21:36:47.701: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-613 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 22 21:36:48.002: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Dec 22 21:36:48.002: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 22 21:36:48.002: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 22 21:36:48.002: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-613 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 22 21:36:48.297: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Dec 22 21:36:48.297: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 22 21:36:48.297: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 22 21:36:48.297: INFO: Waiting for statefulset status.replicas updated to 0
Dec 22 21:36:48.309: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Dec 22 21:36:58.314: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 22 21:36:58.314: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec 22 21:36:58.314: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec 22 21:36:58.322: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999807s
Dec 22 21:36:59.326: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996636588s
Dec 22 21:37:00.329: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.993512165s
Dec 22 21:37:01.332: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.990156374s
Dec 22 21:37:02.338: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.986603055s
Dec 22 21:37:03.342: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.98081444s
Dec 22 21:37:04.345: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.977275215s
Dec 22 21:37:05.351: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.974278824s
Dec 22 21:37:06.355: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.968549623s
Dec 22 21:37:07.361: INFO: Verifying statefulset ss doesn't scale past 3 for another 963.706914ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-613
Dec 22 21:37:08.364: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-613 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 22 21:37:08.567: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Dec 22 21:37:08.567: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 22 21:37:08.567: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 22 21:37:08.567: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-613 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 22 21:37:08.780: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Dec 22 21:37:08.780: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 22 21:37:08.780: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 22 21:37:08.780: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-613 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 22 21:37:09.055: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Dec 22 21:37:09.055: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 22 21:37:09.055: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 22 21:37:09.055: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Dec 22 21:37:49.065: INFO: Deleting all statefulset in ns statefulset-613
Dec 22 21:37:49.067: INFO: Scaling statefulset ss to 0
Dec 22 21:37:49.074: INFO: Waiting for statefulset status.replicas updated to 0
Dec 22 21:37:49.076: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:37:49.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-613" for this suite.
Dec 22 21:37:55.107: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:37:55.227: INFO: namespace statefulset-613 deletion completed in 6.138706096s

â€¢ [SLOW TEST:108.602 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:37:55.228: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1721
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec 22 21:37:55.249: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=kubectl-8989'
Dec 22 21:37:55.335: INFO: stderr: ""
Dec 22 21:37:55.335: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Dec 22 21:38:00.386: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 get pod e2e-test-nginx-pod --namespace=kubectl-8989 -o json'
Dec 22 21:38:00.472: INFO: stderr: ""
Dec 22 21:38:00.472: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"10.20.27.61/32\"\n        },\n        \"creationTimestamp\": \"2019-12-22T21:37:55Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"kubectl-8989\",\n        \"resourceVersion\": \"6494\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-8989/pods/e2e-test-nginx-pod\",\n        \"uid\": \"12cb0679-3f58-4aa3-b74b-8f054f2fd812\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-48f24\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"ip-10-0-1-121.us-west-2.compute.internal\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"volumes\": [\n            {\n                \"name\": \"default-token-48f24\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-48f24\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-12-22T21:37:55Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-12-22T21:37:57Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-12-22T21:37:57Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-12-22T21:37:55Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://e5c98741d92b320bb2611f17c8ea5839d1e5846948559b8f1a19cb5e18ab3e92\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-12-22T21:37:56Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.0.1.121\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.20.27.61\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-12-22T21:37:55Z\"\n    }\n}\n"
STEP: replace the image in the pod
Dec 22 21:38:00.472: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 replace -f - --namespace=kubectl-8989'
Dec 22 21:38:00.739: INFO: stderr: ""
Dec 22 21:38:00.739: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1726
Dec 22 21:38:00.742: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 delete pods e2e-test-nginx-pod --namespace=kubectl-8989'
Dec 22 21:38:12.262: INFO: stderr: ""
Dec 22 21:38:12.262: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:38:12.262: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8989" for this suite.
Dec 22 21:38:18.273: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:38:18.415: INFO: namespace kubectl-8989 deletion completed in 6.148629671s

â€¢ [SLOW TEST:23.187 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl replace
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:38:18.415: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec 22 21:38:22.952: INFO: Successfully updated pod "pod-update-activedeadlineseconds-d0ed6a2a-a664-4868-bd59-7b9af8761874"
Dec 22 21:38:22.952: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-d0ed6a2a-a664-4868-bd59-7b9af8761874" in namespace "pods-7397" to be "terminated due to deadline exceeded"
Dec 22 21:38:22.955: INFO: Pod "pod-update-activedeadlineseconds-d0ed6a2a-a664-4868-bd59-7b9af8761874": Phase="Running", Reason="", readiness=true. Elapsed: 2.344833ms
Dec 22 21:38:24.957: INFO: Pod "pod-update-activedeadlineseconds-d0ed6a2a-a664-4868-bd59-7b9af8761874": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.004652927s
Dec 22 21:38:24.957: INFO: Pod "pod-update-activedeadlineseconds-d0ed6a2a-a664-4868-bd59-7b9af8761874" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:38:24.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7397" for this suite.
Dec 22 21:38:30.967: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:38:31.027: INFO: namespace pods-7397 deletion completed in 6.067009112s

â€¢ [SLOW TEST:12.612 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:38:31.027: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-a2ef8e09-b058-466b-bee1-9c605b484912
STEP: Creating a pod to test consume secrets
Dec 22 21:38:31.051: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-684de3e4-2e4e-4c64-a0ff-dd45487c4ae5" in namespace "projected-9054" to be "success or failure"
Dec 22 21:38:31.053: INFO: Pod "pod-projected-secrets-684de3e4-2e4e-4c64-a0ff-dd45487c4ae5": Phase="Pending", Reason="", readiness=false. Elapsed: 1.972353ms
Dec 22 21:38:33.061: INFO: Pod "pod-projected-secrets-684de3e4-2e4e-4c64-a0ff-dd45487c4ae5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009930338s
STEP: Saw pod success
Dec 22 21:38:33.061: INFO: Pod "pod-projected-secrets-684de3e4-2e4e-4c64-a0ff-dd45487c4ae5" satisfied condition "success or failure"
Dec 22 21:38:33.065: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod pod-projected-secrets-684de3e4-2e4e-4c64-a0ff-dd45487c4ae5 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 22 21:38:33.083: INFO: Waiting for pod pod-projected-secrets-684de3e4-2e4e-4c64-a0ff-dd45487c4ae5 to disappear
Dec 22 21:38:33.085: INFO: Pod pod-projected-secrets-684de3e4-2e4e-4c64-a0ff-dd45487c4ae5 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:38:33.085: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9054" for this suite.
Dec 22 21:38:39.111: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:38:39.225: INFO: namespace projected-9054 deletion completed in 6.136884119s

â€¢ [SLOW TEST:8.198 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:38:39.226: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1222 21:38:49.288542      15 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec 22 21:38:49.288: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:38:49.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2657" for this suite.
Dec 22 21:38:55.297: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:38:55.412: INFO: namespace gc-2657 deletion completed in 6.121383171s

â€¢ [SLOW TEST:16.186 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:38:55.413: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-800e4443-41da-4f9d-902f-bf231362158e
STEP: Creating a pod to test consume configMaps
Dec 22 21:38:55.453: INFO: Waiting up to 5m0s for pod "pod-configmaps-b8936e99-9266-40ca-9af1-f316c3cf674c" in namespace "configmap-5041" to be "success or failure"
Dec 22 21:38:55.464: INFO: Pod "pod-configmaps-b8936e99-9266-40ca-9af1-f316c3cf674c": Phase="Pending", Reason="", readiness=false. Elapsed: 11.10375ms
Dec 22 21:38:57.467: INFO: Pod "pod-configmaps-b8936e99-9266-40ca-9af1-f316c3cf674c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013801385s
Dec 22 21:38:59.470: INFO: Pod "pod-configmaps-b8936e99-9266-40ca-9af1-f316c3cf674c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016952999s
STEP: Saw pod success
Dec 22 21:38:59.470: INFO: Pod "pod-configmaps-b8936e99-9266-40ca-9af1-f316c3cf674c" satisfied condition "success or failure"
Dec 22 21:38:59.472: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod pod-configmaps-b8936e99-9266-40ca-9af1-f316c3cf674c container configmap-volume-test: <nil>
STEP: delete the pod
Dec 22 21:38:59.486: INFO: Waiting for pod pod-configmaps-b8936e99-9266-40ca-9af1-f316c3cf674c to disappear
Dec 22 21:38:59.488: INFO: Pod pod-configmaps-b8936e99-9266-40ca-9af1-f316c3cf674c no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:38:59.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5041" for this suite.
Dec 22 21:39:05.497: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:39:05.618: INFO: namespace configmap-5041 deletion completed in 6.127413698s

â€¢ [SLOW TEST:10.205 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:39:05.618: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with configMap that has name projected-configmap-test-upd-bc6f1c98-0039-49b0-9a95-a5186fcfb22e
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-bc6f1c98-0039-49b0-9a95-a5186fcfb22e
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:39:09.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4637" for this suite.
Dec 22 21:39:31.687: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:39:31.817: INFO: namespace projected-4637 deletion completed in 22.136458271s

â€¢ [SLOW TEST:26.198 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:39:31.818: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-37e83838-5ab9-4315-9df5-2e9966d6343f
STEP: Creating a pod to test consume configMaps
Dec 22 21:39:31.862: INFO: Waiting up to 5m0s for pod "pod-configmaps-6f459a1b-d6ef-4f63-9f50-e15b095472c1" in namespace "configmap-9077" to be "success or failure"
Dec 22 21:39:31.865: INFO: Pod "pod-configmaps-6f459a1b-d6ef-4f63-9f50-e15b095472c1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.215327ms
Dec 22 21:39:33.867: INFO: Pod "pod-configmaps-6f459a1b-d6ef-4f63-9f50-e15b095472c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004765183s
STEP: Saw pod success
Dec 22 21:39:33.867: INFO: Pod "pod-configmaps-6f459a1b-d6ef-4f63-9f50-e15b095472c1" satisfied condition "success or failure"
Dec 22 21:39:33.869: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod pod-configmaps-6f459a1b-d6ef-4f63-9f50-e15b095472c1 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 22 21:39:33.882: INFO: Waiting for pod pod-configmaps-6f459a1b-d6ef-4f63-9f50-e15b095472c1 to disappear
Dec 22 21:39:33.884: INFO: Pod pod-configmaps-6f459a1b-d6ef-4f63-9f50-e15b095472c1 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:39:33.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9077" for this suite.
Dec 22 21:39:39.895: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:39:39.956: INFO: namespace configmap-9077 deletion completed in 6.067027348s

â€¢ [SLOW TEST:8.138 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:39:39.956: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-b96baee6-b1d7-426f-8b0e-c9be71fcbebf
STEP: Creating a pod to test consume configMaps
Dec 22 21:39:39.983: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c0e69a6a-c69e-4282-9f36-36a9b622b309" in namespace "projected-6742" to be "success or failure"
Dec 22 21:39:39.986: INFO: Pod "pod-projected-configmaps-c0e69a6a-c69e-4282-9f36-36a9b622b309": Phase="Pending", Reason="", readiness=false. Elapsed: 3.012885ms
Dec 22 21:39:41.988: INFO: Pod "pod-projected-configmaps-c0e69a6a-c69e-4282-9f36-36a9b622b309": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005465157s
STEP: Saw pod success
Dec 22 21:39:41.988: INFO: Pod "pod-projected-configmaps-c0e69a6a-c69e-4282-9f36-36a9b622b309" satisfied condition "success or failure"
Dec 22 21:39:41.990: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod pod-projected-configmaps-c0e69a6a-c69e-4282-9f36-36a9b622b309 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 22 21:39:42.004: INFO: Waiting for pod pod-projected-configmaps-c0e69a6a-c69e-4282-9f36-36a9b622b309 to disappear
Dec 22 21:39:42.005: INFO: Pod pod-projected-configmaps-c0e69a6a-c69e-4282-9f36-36a9b622b309 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:39:42.005: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6742" for this suite.
Dec 22 21:39:48.016: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:39:48.112: INFO: namespace projected-6742 deletion completed in 6.103686933s

â€¢ [SLOW TEST:8.156 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:39:48.112: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-0a4c49c6-ca9d-42a8-92b2-e61421a3b58f
STEP: Creating a pod to test consume configMaps
Dec 22 21:39:48.136: INFO: Waiting up to 5m0s for pod "pod-configmaps-584f8e76-63e1-407c-aac2-b3a53af735b5" in namespace "configmap-895" to be "success or failure"
Dec 22 21:39:48.139: INFO: Pod "pod-configmaps-584f8e76-63e1-407c-aac2-b3a53af735b5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.367259ms
Dec 22 21:39:50.143: INFO: Pod "pod-configmaps-584f8e76-63e1-407c-aac2-b3a53af735b5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006454681s
STEP: Saw pod success
Dec 22 21:39:50.143: INFO: Pod "pod-configmaps-584f8e76-63e1-407c-aac2-b3a53af735b5" satisfied condition "success or failure"
Dec 22 21:39:50.145: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod pod-configmaps-584f8e76-63e1-407c-aac2-b3a53af735b5 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 22 21:39:50.167: INFO: Waiting for pod pod-configmaps-584f8e76-63e1-407c-aac2-b3a53af735b5 to disappear
Dec 22 21:39:50.169: INFO: Pod pod-configmaps-584f8e76-63e1-407c-aac2-b3a53af735b5 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:39:50.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-895" for this suite.
Dec 22 21:39:56.187: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:39:56.243: INFO: namespace configmap-895 deletion completed in 6.069743341s

â€¢ [SLOW TEST:8.131 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:39:56.243: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating service endpoint-test2 in namespace services-8073
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8073 to expose endpoints map[]
Dec 22 21:39:56.276: INFO: successfully validated that service endpoint-test2 in namespace services-8073 exposes endpoints map[] (5.660301ms elapsed)
STEP: Creating pod pod1 in namespace services-8073
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8073 to expose endpoints map[pod1:[80]]
Dec 22 21:39:58.302: INFO: successfully validated that service endpoint-test2 in namespace services-8073 exposes endpoints map[pod1:[80]] (2.018651295s elapsed)
STEP: Creating pod pod2 in namespace services-8073
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8073 to expose endpoints map[pod1:[80] pod2:[80]]
Dec 22 21:40:00.333: INFO: successfully validated that service endpoint-test2 in namespace services-8073 exposes endpoints map[pod1:[80] pod2:[80]] (2.027569815s elapsed)
STEP: Deleting pod pod1 in namespace services-8073
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8073 to expose endpoints map[pod2:[80]]
Dec 22 21:40:00.366: INFO: successfully validated that service endpoint-test2 in namespace services-8073 exposes endpoints map[pod2:[80]] (26.4395ms elapsed)
STEP: Deleting pod pod2 in namespace services-8073
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8073 to expose endpoints map[]
Dec 22 21:40:00.378: INFO: successfully validated that service endpoint-test2 in namespace services-8073 exposes endpoints map[] (5.400423ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:40:00.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8073" for this suite.
Dec 22 21:40:22.404: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:40:22.519: INFO: namespace services-8073 deletion completed in 22.124045997s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

â€¢ [SLOW TEST:26.276 seconds]
[sig-network] Services
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:40:22.519: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec 22 21:40:22.543: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f298156b-3e96-4dd3-a424-f6834db7a2ff" in namespace "projected-9922" to be "success or failure"
Dec 22 21:40:22.547: INFO: Pod "downwardapi-volume-f298156b-3e96-4dd3-a424-f6834db7a2ff": Phase="Pending", Reason="", readiness=false. Elapsed: 3.852148ms
Dec 22 21:40:24.549: INFO: Pod "downwardapi-volume-f298156b-3e96-4dd3-a424-f6834db7a2ff": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006510802s
STEP: Saw pod success
Dec 22 21:40:24.549: INFO: Pod "downwardapi-volume-f298156b-3e96-4dd3-a424-f6834db7a2ff" satisfied condition "success or failure"
Dec 22 21:40:24.551: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod downwardapi-volume-f298156b-3e96-4dd3-a424-f6834db7a2ff container client-container: <nil>
STEP: delete the pod
Dec 22 21:40:24.568: INFO: Waiting for pod downwardapi-volume-f298156b-3e96-4dd3-a424-f6834db7a2ff to disappear
Dec 22 21:40:24.571: INFO: Pod downwardapi-volume-f298156b-3e96-4dd3-a424-f6834db7a2ff no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:40:24.571: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9922" for this suite.
Dec 22 21:40:30.580: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:40:30.640: INFO: namespace projected-9922 deletion completed in 6.066482042s

â€¢ [SLOW TEST:8.121 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:40:30.640: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec 22 21:40:30.679: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"4b51f308-bbd6-4bec-a4c3-3a2ee6fca761", Controller:(*bool)(0xc0027d15ba), BlockOwnerDeletion:(*bool)(0xc0027d15bb)}}
Dec 22 21:40:30.684: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"0ae1371b-243c-4afc-a8d1-9576c6cd62c4", Controller:(*bool)(0xc0029ed606), BlockOwnerDeletion:(*bool)(0xc0029ed607)}}
Dec 22 21:40:30.688: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"63af4f9f-039f-4efb-92b4-b679d5e1cab5", Controller:(*bool)(0xc0027d1736), BlockOwnerDeletion:(*bool)(0xc0027d1737)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:40:35.698: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9026" for this suite.
Dec 22 21:40:41.707: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:40:41.809: INFO: namespace gc-9026 deletion completed in 6.108186749s

â€¢ [SLOW TEST:11.169 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:40:41.809: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec 22 21:40:41.830: INFO: Waiting up to 5m0s for pod "pod-58aac079-0c9b-4867-8d56-7d4846111625" in namespace "emptydir-8662" to be "success or failure"
Dec 22 21:40:41.832: INFO: Pod "pod-58aac079-0c9b-4867-8d56-7d4846111625": Phase="Pending", Reason="", readiness=false. Elapsed: 1.99028ms
Dec 22 21:40:43.835: INFO: Pod "pod-58aac079-0c9b-4867-8d56-7d4846111625": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004683595s
STEP: Saw pod success
Dec 22 21:40:43.835: INFO: Pod "pod-58aac079-0c9b-4867-8d56-7d4846111625" satisfied condition "success or failure"
Dec 22 21:40:43.837: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod pod-58aac079-0c9b-4867-8d56-7d4846111625 container test-container: <nil>
STEP: delete the pod
Dec 22 21:40:43.851: INFO: Waiting for pod pod-58aac079-0c9b-4867-8d56-7d4846111625 to disappear
Dec 22 21:40:43.853: INFO: Pod pod-58aac079-0c9b-4867-8d56-7d4846111625 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:40:43.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8662" for this suite.
Dec 22 21:40:49.861: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:40:49.920: INFO: namespace emptydir-8662 deletion completed in 6.064675314s

â€¢ [SLOW TEST:8.111 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:40:49.920: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a replication controller
Dec 22 21:40:49.939: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 create -f - --namespace=kubectl-1651'
Dec 22 21:40:50.183: INFO: stderr: ""
Dec 22 21:40:50.183: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 22 21:40:50.183: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1651'
Dec 22 21:40:50.273: INFO: stderr: ""
Dec 22 21:40:50.273: INFO: stdout: "update-demo-nautilus-bj97c update-demo-nautilus-kbj5b "
Dec 22 21:40:50.273: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 get pods update-demo-nautilus-bj97c -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1651'
Dec 22 21:40:50.340: INFO: stderr: ""
Dec 22 21:40:50.340: INFO: stdout: ""
Dec 22 21:40:50.340: INFO: update-demo-nautilus-bj97c is created but not running
Dec 22 21:40:55.341: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1651'
Dec 22 21:40:55.420: INFO: stderr: ""
Dec 22 21:40:55.420: INFO: stdout: "update-demo-nautilus-bj97c update-demo-nautilus-kbj5b "
Dec 22 21:40:55.421: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 get pods update-demo-nautilus-bj97c -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1651'
Dec 22 21:40:55.508: INFO: stderr: ""
Dec 22 21:40:55.508: INFO: stdout: "true"
Dec 22 21:40:55.508: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 get pods update-demo-nautilus-bj97c -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1651'
Dec 22 21:40:55.591: INFO: stderr: ""
Dec 22 21:40:55.592: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 22 21:40:55.592: INFO: validating pod update-demo-nautilus-bj97c
Dec 22 21:40:55.595: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 22 21:40:55.595: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 22 21:40:55.595: INFO: update-demo-nautilus-bj97c is verified up and running
Dec 22 21:40:55.595: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 get pods update-demo-nautilus-kbj5b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1651'
Dec 22 21:40:55.679: INFO: stderr: ""
Dec 22 21:40:55.679: INFO: stdout: "true"
Dec 22 21:40:55.679: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 get pods update-demo-nautilus-kbj5b -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1651'
Dec 22 21:40:55.766: INFO: stderr: ""
Dec 22 21:40:55.766: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 22 21:40:55.766: INFO: validating pod update-demo-nautilus-kbj5b
Dec 22 21:40:55.771: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 22 21:40:55.771: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 22 21:40:55.771: INFO: update-demo-nautilus-kbj5b is verified up and running
STEP: scaling down the replication controller
Dec 22 21:40:55.773: INFO: scanned /root for discovery docs: <nil>
Dec 22 21:40:55.773: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-1651'
Dec 22 21:40:56.884: INFO: stderr: ""
Dec 22 21:40:56.885: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 22 21:40:56.885: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1651'
Dec 22 21:40:56.958: INFO: stderr: ""
Dec 22 21:40:56.958: INFO: stdout: "update-demo-nautilus-bj97c update-demo-nautilus-kbj5b "
STEP: Replicas for name=update-demo: expected=1 actual=2
Dec 22 21:41:01.958: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1651'
Dec 22 21:41:02.069: INFO: stderr: ""
Dec 22 21:41:02.069: INFO: stdout: "update-demo-nautilus-bj97c update-demo-nautilus-kbj5b "
STEP: Replicas for name=update-demo: expected=1 actual=2
Dec 22 21:41:07.069: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1651'
Dec 22 21:41:07.152: INFO: stderr: ""
Dec 22 21:41:07.152: INFO: stdout: "update-demo-nautilus-kbj5b "
Dec 22 21:41:07.152: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 get pods update-demo-nautilus-kbj5b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1651'
Dec 22 21:41:07.233: INFO: stderr: ""
Dec 22 21:41:07.233: INFO: stdout: "true"
Dec 22 21:41:07.233: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 get pods update-demo-nautilus-kbj5b -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1651'
Dec 22 21:41:07.309: INFO: stderr: ""
Dec 22 21:41:07.309: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 22 21:41:07.309: INFO: validating pod update-demo-nautilus-kbj5b
Dec 22 21:41:07.312: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 22 21:41:07.312: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 22 21:41:07.312: INFO: update-demo-nautilus-kbj5b is verified up and running
STEP: scaling up the replication controller
Dec 22 21:41:07.314: INFO: scanned /root for discovery docs: <nil>
Dec 22 21:41:07.314: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-1651'
Dec 22 21:41:07.433: INFO: stderr: ""
Dec 22 21:41:07.433: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 22 21:41:07.433: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1651'
Dec 22 21:41:07.513: INFO: stderr: ""
Dec 22 21:41:07.513: INFO: stdout: "update-demo-nautilus-kbj5b update-demo-nautilus-pfjqh "
Dec 22 21:41:07.513: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 get pods update-demo-nautilus-kbj5b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1651'
Dec 22 21:41:07.589: INFO: stderr: ""
Dec 22 21:41:07.589: INFO: stdout: "true"
Dec 22 21:41:07.589: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 get pods update-demo-nautilus-kbj5b -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1651'
Dec 22 21:41:07.676: INFO: stderr: ""
Dec 22 21:41:07.676: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 22 21:41:07.676: INFO: validating pod update-demo-nautilus-kbj5b
Dec 22 21:41:07.679: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 22 21:41:07.679: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 22 21:41:07.679: INFO: update-demo-nautilus-kbj5b is verified up and running
Dec 22 21:41:07.679: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 get pods update-demo-nautilus-pfjqh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1651'
Dec 22 21:41:07.748: INFO: stderr: ""
Dec 22 21:41:07.748: INFO: stdout: ""
Dec 22 21:41:07.748: INFO: update-demo-nautilus-pfjqh is created but not running
Dec 22 21:41:12.748: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1651'
Dec 22 21:41:12.816: INFO: stderr: ""
Dec 22 21:41:12.816: INFO: stdout: "update-demo-nautilus-kbj5b update-demo-nautilus-pfjqh "
Dec 22 21:41:12.816: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 get pods update-demo-nautilus-kbj5b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1651'
Dec 22 21:41:12.882: INFO: stderr: ""
Dec 22 21:41:12.882: INFO: stdout: "true"
Dec 22 21:41:12.882: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 get pods update-demo-nautilus-kbj5b -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1651'
Dec 22 21:41:12.949: INFO: stderr: ""
Dec 22 21:41:12.949: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 22 21:41:12.949: INFO: validating pod update-demo-nautilus-kbj5b
Dec 22 21:41:12.951: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 22 21:41:12.951: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 22 21:41:12.951: INFO: update-demo-nautilus-kbj5b is verified up and running
Dec 22 21:41:12.951: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 get pods update-demo-nautilus-pfjqh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1651'
Dec 22 21:41:13.021: INFO: stderr: ""
Dec 22 21:41:13.021: INFO: stdout: "true"
Dec 22 21:41:13.021: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 get pods update-demo-nautilus-pfjqh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1651'
Dec 22 21:41:13.090: INFO: stderr: ""
Dec 22 21:41:13.090: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 22 21:41:13.090: INFO: validating pod update-demo-nautilus-pfjqh
Dec 22 21:41:13.095: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 22 21:41:13.095: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 22 21:41:13.095: INFO: update-demo-nautilus-pfjqh is verified up and running
STEP: using delete to clean up resources
Dec 22 21:41:13.096: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 delete --grace-period=0 --force -f - --namespace=kubectl-1651'
Dec 22 21:41:13.172: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 22 21:41:13.172: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec 22 21:41:13.172: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-1651'
Dec 22 21:41:13.248: INFO: stderr: "No resources found.\n"
Dec 22 21:41:13.248: INFO: stdout: ""
Dec 22 21:41:13.248: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 get pods -l name=update-demo --namespace=kubectl-1651 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 22 21:41:13.324: INFO: stderr: ""
Dec 22 21:41:13.324: INFO: stdout: "update-demo-nautilus-kbj5b\nupdate-demo-nautilus-pfjqh\n"
Dec 22 21:41:13.825: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-1651'
Dec 22 21:41:13.924: INFO: stderr: "No resources found.\n"
Dec 22 21:41:13.924: INFO: stdout: ""
Dec 22 21:41:13.924: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 get pods -l name=update-demo --namespace=kubectl-1651 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 22 21:41:14.025: INFO: stderr: ""
Dec 22 21:41:14.025: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:41:14.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1651" for this suite.
Dec 22 21:41:20.038: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:41:20.112: INFO: namespace kubectl-1651 deletion completed in 6.083126457s

â€¢ [SLOW TEST:30.192 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:41:20.112: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-4232, will wait for the garbage collector to delete the pods
Dec 22 21:41:24.258: INFO: Deleting Job.batch foo took: 6.005332ms
Dec 22 21:41:24.658: INFO: Terminating Job.batch foo pods took: 400.211508ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:42:05.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-4232" for this suite.
Dec 22 21:42:11.376: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:42:11.510: INFO: namespace job-4232 deletion completed in 6.142913916s

â€¢ [SLOW TEST:51.398 seconds]
[sig-apps] Job
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:42:11.510: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec 22 21:42:11.528: INFO: Creating deployment "test-recreate-deployment"
Dec 22 21:42:11.530: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Dec 22 21:42:11.540: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Dec 22 21:42:13.545: INFO: Waiting deployment "test-recreate-deployment" to complete
Dec 22 21:42:13.547: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712647731, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712647731, loc:(*time.Location)(0x7ed0a00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712647731, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712647731, loc:(*time.Location)(0x7ed0a00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-6df85df6b9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 22 21:42:15.552: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Dec 22 21:42:15.560: INFO: Updating deployment test-recreate-deployment
Dec 22 21:42:15.560: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Dec 22 21:42:15.678: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-2543,SelfLink:/apis/apps/v1/namespaces/deployment-2543/deployments/test-recreate-deployment,UID:2c5e1250-14f5-4a4a-b276-2fabb961d7fc,ResourceVersion:7775,Generation:2,CreationTimestamp:2019-12-22 21:42:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-12-22 21:42:15 +0000 UTC 2019-12-22 21:42:15 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-12-22 21:42:15 +0000 UTC 2019-12-22 21:42:11 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-5c8c9cc69d" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Dec 22 21:42:15.683: INFO: New ReplicaSet "test-recreate-deployment-5c8c9cc69d" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5c8c9cc69d,GenerateName:,Namespace:deployment-2543,SelfLink:/apis/apps/v1/namespaces/deployment-2543/replicasets/test-recreate-deployment-5c8c9cc69d,UID:cf40b31e-16f0-4284-b4a0-1f04da68c2de,ResourceVersion:7774,Generation:1,CreationTimestamp:2019-12-22 21:42:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 2c5e1250-14f5-4a4a-b276-2fabb961d7fc 0xc002804227 0xc002804228}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec 22 21:42:15.683: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Dec 22 21:42:15.683: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-6df85df6b9,GenerateName:,Namespace:deployment-2543,SelfLink:/apis/apps/v1/namespaces/deployment-2543/replicasets/test-recreate-deployment-6df85df6b9,UID:7ac8a51e-15f1-4135-8642-8a567dd2333f,ResourceVersion:7762,Generation:2,CreationTimestamp:2019-12-22 21:42:11 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 2c5e1250-14f5-4a4a-b276-2fabb961d7fc 0xc0028042e7 0xc0028042e8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec 22 21:42:15.685: INFO: Pod "test-recreate-deployment-5c8c9cc69d-7cg28" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5c8c9cc69d-7cg28,GenerateName:test-recreate-deployment-5c8c9cc69d-,Namespace:deployment-2543,SelfLink:/api/v1/namespaces/deployment-2543/pods/test-recreate-deployment-5c8c9cc69d-7cg28,UID:5a82fcfd-dd45-46ec-8d83-bcd0b6172f8f,ResourceVersion:7776,Generation:0,CreationTimestamp:2019-12-22 21:42:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-5c8c9cc69d cf40b31e-16f0-4284-b4a0-1f04da68c2de 0xc002804bb7 0xc002804bb8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-skvk7 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-skvk7,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-skvk7 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-121.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:42:15 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:42:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:42:15 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 21:42:15 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.121,PodIP:,StartTime:2019-12-22 21:42:15 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:42:15.685: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2543" for this suite.
Dec 22 21:42:21.694: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:42:21.753: INFO: namespace deployment-2543 deletion completed in 6.065687232s

â€¢ [SLOW TEST:10.243 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:42:21.753: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1516
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec 22 21:42:21.771: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-7241'
Dec 22 21:42:22.061: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec 22 21:42:22.061: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Dec 22 21:42:22.070: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Dec 22 21:42:22.071: INFO: scanned /root for discovery docs: <nil>
Dec 22 21:42:22.071: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-7241'
Dec 22 21:42:37.849: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Dec 22 21:42:37.849: INFO: stdout: "Created e2e-test-nginx-rc-6092826381be120cdabff7fd9fd1e14e\nScaling up e2e-test-nginx-rc-6092826381be120cdabff7fd9fd1e14e from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-6092826381be120cdabff7fd9fd1e14e up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-6092826381be120cdabff7fd9fd1e14e to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Dec 22 21:42:37.849: INFO: stdout: "Created e2e-test-nginx-rc-6092826381be120cdabff7fd9fd1e14e\nScaling up e2e-test-nginx-rc-6092826381be120cdabff7fd9fd1e14e from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-6092826381be120cdabff7fd9fd1e14e up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-6092826381be120cdabff7fd9fd1e14e to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Dec 22 21:42:37.849: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-7241'
Dec 22 21:42:37.937: INFO: stderr: ""
Dec 22 21:42:37.937: INFO: stdout: "e2e-test-nginx-rc-6092826381be120cdabff7fd9fd1e14e-vhzmp "
Dec 22 21:42:37.937: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 get pods e2e-test-nginx-rc-6092826381be120cdabff7fd9fd1e14e-vhzmp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7241'
Dec 22 21:42:38.024: INFO: stderr: ""
Dec 22 21:42:38.024: INFO: stdout: "true"
Dec 22 21:42:38.024: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 get pods e2e-test-nginx-rc-6092826381be120cdabff7fd9fd1e14e-vhzmp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7241'
Dec 22 21:42:38.106: INFO: stderr: ""
Dec 22 21:42:38.106: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Dec 22 21:42:38.106: INFO: e2e-test-nginx-rc-6092826381be120cdabff7fd9fd1e14e-vhzmp is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1522
Dec 22 21:42:38.106: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 delete rc e2e-test-nginx-rc --namespace=kubectl-7241'
Dec 22 21:42:38.209: INFO: stderr: ""
Dec 22 21:42:38.209: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:42:38.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7241" for this suite.
Dec 22 21:42:44.227: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:42:44.330: INFO: namespace kubectl-7241 deletion completed in 6.117284836s

â€¢ [SLOW TEST:22.577 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:42:44.331: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Dec 22 21:42:44.388: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-7318,SelfLink:/api/v1/namespaces/watch-7318/configmaps/e2e-watch-test-watch-closed,UID:8551cef8-1e61-4c1c-9755-aaaaf79b03fb,ResourceVersion:7951,Generation:0,CreationTimestamp:2019-12-22 21:42:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 22 21:42:44.388: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-7318,SelfLink:/api/v1/namespaces/watch-7318/configmaps/e2e-watch-test-watch-closed,UID:8551cef8-1e61-4c1c-9755-aaaaf79b03fb,ResourceVersion:7952,Generation:0,CreationTimestamp:2019-12-22 21:42:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Dec 22 21:42:44.399: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-7318,SelfLink:/api/v1/namespaces/watch-7318/configmaps/e2e-watch-test-watch-closed,UID:8551cef8-1e61-4c1c-9755-aaaaf79b03fb,ResourceVersion:7953,Generation:0,CreationTimestamp:2019-12-22 21:42:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 22 21:42:44.400: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-7318,SelfLink:/api/v1/namespaces/watch-7318/configmaps/e2e-watch-test-watch-closed,UID:8551cef8-1e61-4c1c-9755-aaaaf79b03fb,ResourceVersion:7954,Generation:0,CreationTimestamp:2019-12-22 21:42:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:42:44.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7318" for this suite.
Dec 22 21:42:50.410: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:42:50.511: INFO: namespace watch-7318 deletion completed in 6.10823206s

â€¢ [SLOW TEST:6.180 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:42:50.511: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec 22 21:42:50.551: INFO: DaemonSet pods can't tolerate node ip-10-0-1-168.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 22 21:42:50.553: INFO: Number of nodes with available pods: 0
Dec 22 21:42:50.553: INFO: Node ip-10-0-1-121.us-west-2.compute.internal is running more than one daemon pod
Dec 22 21:42:51.557: INFO: DaemonSet pods can't tolerate node ip-10-0-1-168.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 22 21:42:51.559: INFO: Number of nodes with available pods: 0
Dec 22 21:42:51.559: INFO: Node ip-10-0-1-121.us-west-2.compute.internal is running more than one daemon pod
Dec 22 21:42:52.556: INFO: DaemonSet pods can't tolerate node ip-10-0-1-168.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 22 21:42:52.559: INFO: Number of nodes with available pods: 1
Dec 22 21:42:52.559: INFO: Node ip-10-0-1-121.us-west-2.compute.internal is running more than one daemon pod
Dec 22 21:42:53.559: INFO: DaemonSet pods can't tolerate node ip-10-0-1-168.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 22 21:42:53.562: INFO: Number of nodes with available pods: 2
Dec 22 21:42:53.562: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Dec 22 21:42:53.606: INFO: DaemonSet pods can't tolerate node ip-10-0-1-168.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 22 21:42:53.610: INFO: Number of nodes with available pods: 2
Dec 22 21:42:53.610: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1965, will wait for the garbage collector to delete the pods
Dec 22 21:42:54.674: INFO: Deleting DaemonSet.extensions daemon-set took: 4.648393ms
Dec 22 21:42:55.074: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.200299ms
Dec 22 21:44:32.277: INFO: Number of nodes with available pods: 0
Dec 22 21:44:32.277: INFO: Number of running nodes: 0, number of available pods: 0
Dec 22 21:44:32.280: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1965/daemonsets","resourceVersion":"8191"},"items":null}

Dec 22 21:44:32.282: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1965/pods","resourceVersion":"8191"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:44:32.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1965" for this suite.
Dec 22 21:44:38.305: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:44:38.364: INFO: namespace daemonsets-1965 deletion completed in 6.067274917s

â€¢ [SLOW TEST:107.853 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:44:38.364: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Dec 22 21:44:38.399: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 22 21:44:38.412: INFO: Waiting for terminating namespaces to be deleted...
Dec 22 21:44:38.414: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-1-121.us-west-2.compute.internal before test
Dec 22 21:44:38.419: INFO: sonobuoy from sonobuoy started at 2019-12-22 21:18:58 +0000 UTC (1 container statuses recorded)
Dec 22 21:44:38.419: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 22 21:44:38.419: INFO: calico-node-r5hns from kube-system started at 2019-12-22 21:13:22 +0000 UTC (1 container statuses recorded)
Dec 22 21:44:38.419: INFO: 	Container calico-node ready: true, restart count 0
Dec 22 21:44:38.419: INFO: sonobuoy-systemd-logs-daemon-set-42c521be8b344bae-qnvsn from sonobuoy started at 2019-12-22 21:19:03 +0000 UTC (2 container statuses recorded)
Dec 22 21:44:38.419: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 22 21:44:38.419: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 22 21:44:38.419: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-1-187.us-west-2.compute.internal before test
Dec 22 21:44:38.443: INFO: calico-node-bnxjf from kube-system started at 2019-12-22 21:13:27 +0000 UTC (1 container statuses recorded)
Dec 22 21:44:38.443: INFO: 	Container calico-node ready: true, restart count 0
Dec 22 21:44:38.443: INFO: sonobuoy-e2e-job-bfd4ea5b59194b8d from sonobuoy started at 2019-12-22 21:19:02 +0000 UTC (2 container statuses recorded)
Dec 22 21:44:38.443: INFO: 	Container e2e ready: true, restart count 0
Dec 22 21:44:38.443: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 22 21:44:38.443: INFO: sonobuoy-systemd-logs-daemon-set-42c521be8b344bae-95gp6 from sonobuoy started at 2019-12-22 21:19:03 +0000 UTC (2 container statuses recorded)
Dec 22 21:44:38.443: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 22 21:44:38.443: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: verifying the node has the label node ip-10-0-1-121.us-west-2.compute.internal
STEP: verifying the node has the label node ip-10-0-1-187.us-west-2.compute.internal
Dec 22 21:44:38.499: INFO: Pod calico-node-bnxjf requesting resource cpu=250m on Node ip-10-0-1-187.us-west-2.compute.internal
Dec 22 21:44:38.499: INFO: Pod calico-node-r5hns requesting resource cpu=250m on Node ip-10-0-1-121.us-west-2.compute.internal
Dec 22 21:44:38.499: INFO: Pod sonobuoy requesting resource cpu=0m on Node ip-10-0-1-121.us-west-2.compute.internal
Dec 22 21:44:38.499: INFO: Pod sonobuoy-e2e-job-bfd4ea5b59194b8d requesting resource cpu=0m on Node ip-10-0-1-187.us-west-2.compute.internal
Dec 22 21:44:38.499: INFO: Pod sonobuoy-systemd-logs-daemon-set-42c521be8b344bae-95gp6 requesting resource cpu=0m on Node ip-10-0-1-187.us-west-2.compute.internal
Dec 22 21:44:38.499: INFO: Pod sonobuoy-systemd-logs-daemon-set-42c521be8b344bae-qnvsn requesting resource cpu=0m on Node ip-10-0-1-121.us-west-2.compute.internal
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-4f37295a-9a12-47a9-9155-7af2fcfdb940.15e2cf99afcb01d9], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8534/filler-pod-4f37295a-9a12-47a9-9155-7af2fcfdb940 to ip-10-0-1-187.us-west-2.compute.internal]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-4f37295a-9a12-47a9-9155-7af2fcfdb940.15e2cf99e3ed4c59], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-4f37295a-9a12-47a9-9155-7af2fcfdb940.15e2cf99e75c35c4], Reason = [Created], Message = [Created container filler-pod-4f37295a-9a12-47a9-9155-7af2fcfdb940]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-4f37295a-9a12-47a9-9155-7af2fcfdb940.15e2cf99f1a51522], Reason = [Started], Message = [Started container filler-pod-4f37295a-9a12-47a9-9155-7af2fcfdb940]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6dcf6c44-64e0-4368-a1dc-9e3116957d38.15e2cf99afa9654a], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8534/filler-pod-6dcf6c44-64e0-4368-a1dc-9e3116957d38 to ip-10-0-1-121.us-west-2.compute.internal]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6dcf6c44-64e0-4368-a1dc-9e3116957d38.15e2cf99e3fe2cd3], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6dcf6c44-64e0-4368-a1dc-9e3116957d38.15e2cf99e791e3a8], Reason = [Created], Message = [Created container filler-pod-6dcf6c44-64e0-4368-a1dc-9e3116957d38]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6dcf6c44-64e0-4368-a1dc-9e3116957d38.15e2cf99f31ddefe], Reason = [Started], Message = [Started container filler-pod-6dcf6c44-64e0-4368-a1dc-9e3116957d38]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15e2cf9a9f0826b3], Reason = [FailedScheduling], Message = [0/3 nodes are available: 1 node(s) had taints that the pod didn't tolerate, 2 Insufficient cpu.]
STEP: removing the label node off the node ip-10-0-1-121.us-west-2.compute.internal
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node ip-10-0-1-187.us-west-2.compute.internal
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:44:43.585: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-8534" for this suite.
Dec 22 21:44:49.601: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:44:49.667: INFO: namespace sched-pred-8534 deletion completed in 6.076819061s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

â€¢ [SLOW TEST:11.303 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:44:49.667: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test use defaults
Dec 22 21:44:49.758: INFO: Waiting up to 5m0s for pod "client-containers-658cc116-a6be-4c4d-a50d-cb3660e3bf84" in namespace "containers-3425" to be "success or failure"
Dec 22 21:44:49.764: INFO: Pod "client-containers-658cc116-a6be-4c4d-a50d-cb3660e3bf84": Phase="Pending", Reason="", readiness=false. Elapsed: 6.069069ms
Dec 22 21:44:51.767: INFO: Pod "client-containers-658cc116-a6be-4c4d-a50d-cb3660e3bf84": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008474127s
Dec 22 21:44:53.769: INFO: Pod "client-containers-658cc116-a6be-4c4d-a50d-cb3660e3bf84": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010975787s
STEP: Saw pod success
Dec 22 21:44:53.769: INFO: Pod "client-containers-658cc116-a6be-4c4d-a50d-cb3660e3bf84" satisfied condition "success or failure"
Dec 22 21:44:53.771: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod client-containers-658cc116-a6be-4c4d-a50d-cb3660e3bf84 container test-container: <nil>
STEP: delete the pod
Dec 22 21:44:53.787: INFO: Waiting for pod client-containers-658cc116-a6be-4c4d-a50d-cb3660e3bf84 to disappear
Dec 22 21:44:53.789: INFO: Pod client-containers-658cc116-a6be-4c4d-a50d-cb3660e3bf84 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:44:53.789: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3425" for this suite.
Dec 22 21:44:59.800: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:44:59.855: INFO: namespace containers-3425 deletion completed in 6.062959661s

â€¢ [SLOW TEST:10.188 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:44:59.856: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec 22 21:44:59.877: INFO: Waiting up to 5m0s for pod "pod-cd05052b-7e32-4d3f-bfa8-045d953e7e3b" in namespace "emptydir-9049" to be "success or failure"
Dec 22 21:44:59.879: INFO: Pod "pod-cd05052b-7e32-4d3f-bfa8-045d953e7e3b": Phase="Pending", Reason="", readiness=false. Elapsed: 1.930448ms
Dec 22 21:45:01.882: INFO: Pod "pod-cd05052b-7e32-4d3f-bfa8-045d953e7e3b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004396658s
Dec 22 21:45:03.887: INFO: Pod "pod-cd05052b-7e32-4d3f-bfa8-045d953e7e3b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009252757s
STEP: Saw pod success
Dec 22 21:45:03.887: INFO: Pod "pod-cd05052b-7e32-4d3f-bfa8-045d953e7e3b" satisfied condition "success or failure"
Dec 22 21:45:03.889: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod pod-cd05052b-7e32-4d3f-bfa8-045d953e7e3b container test-container: <nil>
STEP: delete the pod
Dec 22 21:45:03.903: INFO: Waiting for pod pod-cd05052b-7e32-4d3f-bfa8-045d953e7e3b to disappear
Dec 22 21:45:03.905: INFO: Pod pod-cd05052b-7e32-4d3f-bfa8-045d953e7e3b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:45:03.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9049" for this suite.
Dec 22 21:45:09.915: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:45:09.976: INFO: namespace emptydir-9049 deletion completed in 6.068057556s

â€¢ [SLOW TEST:10.120 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:45:09.976: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:46:10.001: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5850" for this suite.
Dec 22 21:46:32.015: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:46:32.112: INFO: namespace container-probe-5850 deletion completed in 22.105679496s

â€¢ [SLOW TEST:82.136 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:46:32.112: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec 22 21:46:34.171: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:46:34.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-6965" for this suite.
Dec 22 21:46:40.211: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:46:40.287: INFO: namespace container-runtime-6965 deletion completed in 6.08689345s

â€¢ [SLOW TEST:8.175 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:46:40.288: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W1222 21:46:50.329843      15 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec 22 21:46:50.329: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:46:50.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4362" for this suite.
Dec 22 21:46:56.338: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:46:56.420: INFO: namespace gc-4362 deletion completed in 6.088379456s

â€¢ [SLOW TEST:16.132 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:46:56.421: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Dec 22 21:47:26.499: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1222 21:47:26.499206      15 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:47:26.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7715" for this suite.
Dec 22 21:47:32.508: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:47:32.602: INFO: namespace gc-7715 deletion completed in 6.100936374s

â€¢ [SLOW TEST:36.182 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:47:32.602: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:47:36.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-8286" for this suite.
Dec 22 21:47:42.716: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:47:42.812: INFO: namespace emptydir-wrapper-8286 deletion completed in 6.109103743s

â€¢ [SLOW TEST:10.210 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:47:42.813: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec 22 21:47:42.843: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b0df663c-461f-4995-a8d0-92cfea467c6d" in namespace "downward-api-6349" to be "success or failure"
Dec 22 21:47:42.847: INFO: Pod "downwardapi-volume-b0df663c-461f-4995-a8d0-92cfea467c6d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.827603ms
Dec 22 21:47:44.850: INFO: Pod "downwardapi-volume-b0df663c-461f-4995-a8d0-92cfea467c6d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006855528s
Dec 22 21:47:46.853: INFO: Pod "downwardapi-volume-b0df663c-461f-4995-a8d0-92cfea467c6d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009613535s
STEP: Saw pod success
Dec 22 21:47:46.853: INFO: Pod "downwardapi-volume-b0df663c-461f-4995-a8d0-92cfea467c6d" satisfied condition "success or failure"
Dec 22 21:47:46.856: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod downwardapi-volume-b0df663c-461f-4995-a8d0-92cfea467c6d container client-container: <nil>
STEP: delete the pod
Dec 22 21:47:46.873: INFO: Waiting for pod downwardapi-volume-b0df663c-461f-4995-a8d0-92cfea467c6d to disappear
Dec 22 21:47:46.878: INFO: Pod downwardapi-volume-b0df663c-461f-4995-a8d0-92cfea467c6d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:47:46.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6349" for this suite.
Dec 22 21:47:52.891: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:47:53.010: INFO: namespace downward-api-6349 deletion completed in 6.126538402s

â€¢ [SLOW TEST:10.196 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:47:53.010: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-map-636eeab4-553c-4d9b-ba4b-c456af96c54a
STEP: Creating a pod to test consume secrets
Dec 22 21:47:53.040: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-895e4831-9337-4f4c-a8d1-d4e4b767a04e" in namespace "projected-1947" to be "success or failure"
Dec 22 21:47:53.051: INFO: Pod "pod-projected-secrets-895e4831-9337-4f4c-a8d1-d4e4b767a04e": Phase="Pending", Reason="", readiness=false. Elapsed: 11.419828ms
Dec 22 21:47:55.054: INFO: Pod "pod-projected-secrets-895e4831-9337-4f4c-a8d1-d4e4b767a04e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014074045s
Dec 22 21:47:57.057: INFO: Pod "pod-projected-secrets-895e4831-9337-4f4c-a8d1-d4e4b767a04e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017715495s
STEP: Saw pod success
Dec 22 21:47:57.057: INFO: Pod "pod-projected-secrets-895e4831-9337-4f4c-a8d1-d4e4b767a04e" satisfied condition "success or failure"
Dec 22 21:47:57.060: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod pod-projected-secrets-895e4831-9337-4f4c-a8d1-d4e4b767a04e container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 22 21:47:57.083: INFO: Waiting for pod pod-projected-secrets-895e4831-9337-4f4c-a8d1-d4e4b767a04e to disappear
Dec 22 21:47:57.087: INFO: Pod pod-projected-secrets-895e4831-9337-4f4c-a8d1-d4e4b767a04e no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:47:57.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1947" for this suite.
Dec 22 21:48:03.131: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:48:03.227: INFO: namespace projected-1947 deletion completed in 6.133609532s

â€¢ [SLOW TEST:10.217 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:48:03.228: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-6c1c2084-a961-4bc2-a96b-dda710ebd114
STEP: Creating a pod to test consume configMaps
Dec 22 21:48:03.257: INFO: Waiting up to 5m0s for pod "pod-configmaps-e02f16d5-327b-414d-8972-c01565b4884c" in namespace "configmap-6273" to be "success or failure"
Dec 22 21:48:03.264: INFO: Pod "pod-configmaps-e02f16d5-327b-414d-8972-c01565b4884c": Phase="Pending", Reason="", readiness=false. Elapsed: 7.697739ms
Dec 22 21:48:05.268: INFO: Pod "pod-configmaps-e02f16d5-327b-414d-8972-c01565b4884c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010980624s
STEP: Saw pod success
Dec 22 21:48:05.268: INFO: Pod "pod-configmaps-e02f16d5-327b-414d-8972-c01565b4884c" satisfied condition "success or failure"
Dec 22 21:48:05.271: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod pod-configmaps-e02f16d5-327b-414d-8972-c01565b4884c container configmap-volume-test: <nil>
STEP: delete the pod
Dec 22 21:48:05.295: INFO: Waiting for pod pod-configmaps-e02f16d5-327b-414d-8972-c01565b4884c to disappear
Dec 22 21:48:05.300: INFO: Pod pod-configmaps-e02f16d5-327b-414d-8972-c01565b4884c no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:48:05.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6273" for this suite.
Dec 22 21:48:11.312: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:48:11.377: INFO: namespace configmap-6273 deletion completed in 6.07336946s

â€¢ [SLOW TEST:8.149 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:48:11.377: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec 22 21:48:11.401: INFO: Waiting up to 5m0s for pod "downwardapi-volume-369fae3b-7f28-44df-875e-45530839ff49" in namespace "projected-2055" to be "success or failure"
Dec 22 21:48:11.404: INFO: Pod "downwardapi-volume-369fae3b-7f28-44df-875e-45530839ff49": Phase="Pending", Reason="", readiness=false. Elapsed: 3.274458ms
Dec 22 21:48:13.407: INFO: Pod "downwardapi-volume-369fae3b-7f28-44df-875e-45530839ff49": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005920559s
STEP: Saw pod success
Dec 22 21:48:13.407: INFO: Pod "downwardapi-volume-369fae3b-7f28-44df-875e-45530839ff49" satisfied condition "success or failure"
Dec 22 21:48:13.409: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod downwardapi-volume-369fae3b-7f28-44df-875e-45530839ff49 container client-container: <nil>
STEP: delete the pod
Dec 22 21:48:13.447: INFO: Waiting for pod downwardapi-volume-369fae3b-7f28-44df-875e-45530839ff49 to disappear
Dec 22 21:48:13.456: INFO: Pod downwardapi-volume-369fae3b-7f28-44df-875e-45530839ff49 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:48:13.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2055" for this suite.
Dec 22 21:48:19.473: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:48:19.613: INFO: namespace projected-2055 deletion completed in 6.152731104s

â€¢ [SLOW TEST:8.236 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:48:19.613: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod test-webserver-8a7c77cc-65d7-44ae-87a8-b21d92ff631c in namespace container-probe-3728
Dec 22 21:48:21.642: INFO: Started pod test-webserver-8a7c77cc-65d7-44ae-87a8-b21d92ff631c in namespace container-probe-3728
STEP: checking the pod's current state and verifying that restartCount is present
Dec 22 21:48:21.644: INFO: Initial restart count of pod test-webserver-8a7c77cc-65d7-44ae-87a8-b21d92ff631c is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:52:22.070: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3728" for this suite.
Dec 22 21:52:28.086: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:52:28.152: INFO: namespace container-probe-3728 deletion completed in 6.075025067s

â€¢ [SLOW TEST:248.539 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:52:28.152: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-bf469042-a7cf-475e-ab2b-829de1f13f0d
STEP: Creating a pod to test consume secrets
Dec 22 21:52:28.179: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-1ce16f26-018b-4742-aec9-570898dd1d3a" in namespace "projected-9680" to be "success or failure"
Dec 22 21:52:28.181: INFO: Pod "pod-projected-secrets-1ce16f26-018b-4742-aec9-570898dd1d3a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.663786ms
Dec 22 21:52:30.183: INFO: Pod "pod-projected-secrets-1ce16f26-018b-4742-aec9-570898dd1d3a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004435687s
Dec 22 21:52:32.188: INFO: Pod "pod-projected-secrets-1ce16f26-018b-4742-aec9-570898dd1d3a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00919661s
STEP: Saw pod success
Dec 22 21:52:32.188: INFO: Pod "pod-projected-secrets-1ce16f26-018b-4742-aec9-570898dd1d3a" satisfied condition "success or failure"
Dec 22 21:52:32.191: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod pod-projected-secrets-1ce16f26-018b-4742-aec9-570898dd1d3a container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 22 21:52:32.208: INFO: Waiting for pod pod-projected-secrets-1ce16f26-018b-4742-aec9-570898dd1d3a to disappear
Dec 22 21:52:32.213: INFO: Pod pod-projected-secrets-1ce16f26-018b-4742-aec9-570898dd1d3a no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:52:32.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9680" for this suite.
Dec 22 21:52:38.226: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:52:38.301: INFO: namespace projected-9680 deletion completed in 6.084500879s

â€¢ [SLOW TEST:10.148 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:52:38.301: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test substitution in container's args
Dec 22 21:52:38.331: INFO: Waiting up to 5m0s for pod "var-expansion-43086c19-4201-4e81-8f44-975ec354733c" in namespace "var-expansion-8085" to be "success or failure"
Dec 22 21:52:38.333: INFO: Pod "var-expansion-43086c19-4201-4e81-8f44-975ec354733c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.351947ms
Dec 22 21:52:40.336: INFO: Pod "var-expansion-43086c19-4201-4e81-8f44-975ec354733c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004944564s
Dec 22 21:52:42.339: INFO: Pod "var-expansion-43086c19-4201-4e81-8f44-975ec354733c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008018278s
STEP: Saw pod success
Dec 22 21:52:42.339: INFO: Pod "var-expansion-43086c19-4201-4e81-8f44-975ec354733c" satisfied condition "success or failure"
Dec 22 21:52:42.341: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod var-expansion-43086c19-4201-4e81-8f44-975ec354733c container dapi-container: <nil>
STEP: delete the pod
Dec 22 21:52:42.357: INFO: Waiting for pod var-expansion-43086c19-4201-4e81-8f44-975ec354733c to disappear
Dec 22 21:52:42.360: INFO: Pod var-expansion-43086c19-4201-4e81-8f44-975ec354733c no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:52:42.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-8085" for this suite.
Dec 22 21:52:48.372: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:52:48.504: INFO: namespace var-expansion-8085 deletion completed in 6.14031588s

â€¢ [SLOW TEST:10.203 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:52:48.504: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-projected-all-test-volume-f7d3d95a-23e5-4ca8-a913-f925b363da89
STEP: Creating secret with name secret-projected-all-test-volume-00e7f464-f076-4b65-87db-df55ea98e49e
STEP: Creating a pod to test Check all projections for projected volume plugin
Dec 22 21:52:48.533: INFO: Waiting up to 5m0s for pod "projected-volume-7122b78d-bfa9-48cb-baa8-f6f1f5f3d30c" in namespace "projected-8468" to be "success or failure"
Dec 22 21:52:48.537: INFO: Pod "projected-volume-7122b78d-bfa9-48cb-baa8-f6f1f5f3d30c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.390701ms
Dec 22 21:52:50.540: INFO: Pod "projected-volume-7122b78d-bfa9-48cb-baa8-f6f1f5f3d30c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007029615s
Dec 22 21:52:52.543: INFO: Pod "projected-volume-7122b78d-bfa9-48cb-baa8-f6f1f5f3d30c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009905912s
STEP: Saw pod success
Dec 22 21:52:52.543: INFO: Pod "projected-volume-7122b78d-bfa9-48cb-baa8-f6f1f5f3d30c" satisfied condition "success or failure"
Dec 22 21:52:52.545: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod projected-volume-7122b78d-bfa9-48cb-baa8-f6f1f5f3d30c container projected-all-volume-test: <nil>
STEP: delete the pod
Dec 22 21:52:52.560: INFO: Waiting for pod projected-volume-7122b78d-bfa9-48cb-baa8-f6f1f5f3d30c to disappear
Dec 22 21:52:52.562: INFO: Pod projected-volume-7122b78d-bfa9-48cb-baa8-f6f1f5f3d30c no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:52:52.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8468" for this suite.
Dec 22 21:52:58.574: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:52:58.760: INFO: namespace projected-8468 deletion completed in 6.193867891s

â€¢ [SLOW TEST:10.255 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:52:58.760: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Dec 22 21:52:58.834: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-2092,SelfLink:/api/v1/namespaces/watch-2092/configmaps/e2e-watch-test-configmap-a,UID:d036df50-d03a-4bdd-b14e-abf9a2809611,ResourceVersion:9554,Generation:0,CreationTimestamp:2019-12-22 21:52:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 22 21:52:58.834: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-2092,SelfLink:/api/v1/namespaces/watch-2092/configmaps/e2e-watch-test-configmap-a,UID:d036df50-d03a-4bdd-b14e-abf9a2809611,ResourceVersion:9554,Generation:0,CreationTimestamp:2019-12-22 21:52:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Dec 22 21:53:08.840: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-2092,SelfLink:/api/v1/namespaces/watch-2092/configmaps/e2e-watch-test-configmap-a,UID:d036df50-d03a-4bdd-b14e-abf9a2809611,ResourceVersion:9571,Generation:0,CreationTimestamp:2019-12-22 21:52:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Dec 22 21:53:08.840: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-2092,SelfLink:/api/v1/namespaces/watch-2092/configmaps/e2e-watch-test-configmap-a,UID:d036df50-d03a-4bdd-b14e-abf9a2809611,ResourceVersion:9571,Generation:0,CreationTimestamp:2019-12-22 21:52:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Dec 22 21:53:18.855: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-2092,SelfLink:/api/v1/namespaces/watch-2092/configmaps/e2e-watch-test-configmap-a,UID:d036df50-d03a-4bdd-b14e-abf9a2809611,ResourceVersion:9586,Generation:0,CreationTimestamp:2019-12-22 21:52:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 22 21:53:18.855: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-2092,SelfLink:/api/v1/namespaces/watch-2092/configmaps/e2e-watch-test-configmap-a,UID:d036df50-d03a-4bdd-b14e-abf9a2809611,ResourceVersion:9586,Generation:0,CreationTimestamp:2019-12-22 21:52:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Dec 22 21:53:28.860: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-2092,SelfLink:/api/v1/namespaces/watch-2092/configmaps/e2e-watch-test-configmap-a,UID:d036df50-d03a-4bdd-b14e-abf9a2809611,ResourceVersion:9601,Generation:0,CreationTimestamp:2019-12-22 21:52:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 22 21:53:28.860: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-2092,SelfLink:/api/v1/namespaces/watch-2092/configmaps/e2e-watch-test-configmap-a,UID:d036df50-d03a-4bdd-b14e-abf9a2809611,ResourceVersion:9601,Generation:0,CreationTimestamp:2019-12-22 21:52:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Dec 22 21:53:38.874: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-2092,SelfLink:/api/v1/namespaces/watch-2092/configmaps/e2e-watch-test-configmap-b,UID:b82616f9-f17d-475f-b8b1-68f9501d02ca,ResourceVersion:9616,Generation:0,CreationTimestamp:2019-12-22 21:53:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 22 21:53:38.874: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-2092,SelfLink:/api/v1/namespaces/watch-2092/configmaps/e2e-watch-test-configmap-b,UID:b82616f9-f17d-475f-b8b1-68f9501d02ca,ResourceVersion:9616,Generation:0,CreationTimestamp:2019-12-22 21:53:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Dec 22 21:53:48.880: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-2092,SelfLink:/api/v1/namespaces/watch-2092/configmaps/e2e-watch-test-configmap-b,UID:b82616f9-f17d-475f-b8b1-68f9501d02ca,ResourceVersion:9632,Generation:0,CreationTimestamp:2019-12-22 21:53:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 22 21:53:48.880: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-2092,SelfLink:/api/v1/namespaces/watch-2092/configmaps/e2e-watch-test-configmap-b,UID:b82616f9-f17d-475f-b8b1-68f9501d02ca,ResourceVersion:9632,Generation:0,CreationTimestamp:2019-12-22 21:53:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:53:58.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2092" for this suite.
Dec 22 21:54:04.893: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:54:05.005: INFO: namespace watch-2092 deletion completed in 6.120015717s

â€¢ [SLOW TEST:66.245 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:54:05.005: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-map-ed1c533e-4343-4133-9a7f-87566496bc05
STEP: Creating a pod to test consume secrets
Dec 22 21:54:05.033: INFO: Waiting up to 5m0s for pod "pod-secrets-c77c66f9-51ef-4ff7-8f1e-19772408a6c3" in namespace "secrets-7248" to be "success or failure"
Dec 22 21:54:05.037: INFO: Pod "pod-secrets-c77c66f9-51ef-4ff7-8f1e-19772408a6c3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.525217ms
Dec 22 21:54:07.042: INFO: Pod "pod-secrets-c77c66f9-51ef-4ff7-8f1e-19772408a6c3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008973244s
Dec 22 21:54:09.044: INFO: Pod "pod-secrets-c77c66f9-51ef-4ff7-8f1e-19772408a6c3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011720162s
STEP: Saw pod success
Dec 22 21:54:09.044: INFO: Pod "pod-secrets-c77c66f9-51ef-4ff7-8f1e-19772408a6c3" satisfied condition "success or failure"
Dec 22 21:54:09.047: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod pod-secrets-c77c66f9-51ef-4ff7-8f1e-19772408a6c3 container secret-volume-test: <nil>
STEP: delete the pod
Dec 22 21:54:09.062: INFO: Waiting for pod pod-secrets-c77c66f9-51ef-4ff7-8f1e-19772408a6c3 to disappear
Dec 22 21:54:09.065: INFO: Pod pod-secrets-c77c66f9-51ef-4ff7-8f1e-19772408a6c3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:54:09.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7248" for this suite.
Dec 22 21:54:15.088: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:54:15.233: INFO: namespace secrets-7248 deletion completed in 6.164333043s

â€¢ [SLOW TEST:10.228 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:54:15.234: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-configmap-6qjr
STEP: Creating a pod to test atomic-volume-subpath
Dec 22 21:54:15.334: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-6qjr" in namespace "subpath-5660" to be "success or failure"
Dec 22 21:54:15.336: INFO: Pod "pod-subpath-test-configmap-6qjr": Phase="Pending", Reason="", readiness=false. Elapsed: 2.463415ms
Dec 22 21:54:17.339: INFO: Pod "pod-subpath-test-configmap-6qjr": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005042319s
Dec 22 21:54:19.342: INFO: Pod "pod-subpath-test-configmap-6qjr": Phase="Running", Reason="", readiness=true. Elapsed: 4.008520743s
Dec 22 21:54:21.347: INFO: Pod "pod-subpath-test-configmap-6qjr": Phase="Running", Reason="", readiness=true. Elapsed: 6.013028372s
Dec 22 21:54:23.350: INFO: Pod "pod-subpath-test-configmap-6qjr": Phase="Running", Reason="", readiness=true. Elapsed: 8.016889752s
Dec 22 21:54:25.353: INFO: Pod "pod-subpath-test-configmap-6qjr": Phase="Running", Reason="", readiness=true. Elapsed: 10.019463292s
Dec 22 21:54:27.356: INFO: Pod "pod-subpath-test-configmap-6qjr": Phase="Running", Reason="", readiness=true. Elapsed: 12.022229296s
Dec 22 21:54:29.358: INFO: Pod "pod-subpath-test-configmap-6qjr": Phase="Running", Reason="", readiness=true. Elapsed: 14.024810554s
Dec 22 21:54:31.364: INFO: Pod "pod-subpath-test-configmap-6qjr": Phase="Running", Reason="", readiness=true. Elapsed: 16.030422408s
Dec 22 21:54:33.367: INFO: Pod "pod-subpath-test-configmap-6qjr": Phase="Running", Reason="", readiness=true. Elapsed: 18.033755236s
Dec 22 21:54:35.370: INFO: Pod "pod-subpath-test-configmap-6qjr": Phase="Running", Reason="", readiness=true. Elapsed: 20.036866243s
Dec 22 21:54:37.381: INFO: Pod "pod-subpath-test-configmap-6qjr": Phase="Running", Reason="", readiness=true. Elapsed: 22.047604891s
Dec 22 21:54:39.384: INFO: Pod "pod-subpath-test-configmap-6qjr": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.050237548s
STEP: Saw pod success
Dec 22 21:54:39.384: INFO: Pod "pod-subpath-test-configmap-6qjr" satisfied condition "success or failure"
Dec 22 21:54:39.386: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod pod-subpath-test-configmap-6qjr container test-container-subpath-configmap-6qjr: <nil>
STEP: delete the pod
Dec 22 21:54:39.402: INFO: Waiting for pod pod-subpath-test-configmap-6qjr to disappear
Dec 22 21:54:39.404: INFO: Pod pod-subpath-test-configmap-6qjr no longer exists
STEP: Deleting pod pod-subpath-test-configmap-6qjr
Dec 22 21:54:39.404: INFO: Deleting pod "pod-subpath-test-configmap-6qjr" in namespace "subpath-5660"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:54:39.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5660" for this suite.
Dec 22 21:54:45.417: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:54:45.530: INFO: namespace subpath-5660 deletion completed in 6.120449375s

â€¢ [SLOW TEST:30.296 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:54:45.530: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:54:51.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-2454" for this suite.
Dec 22 21:54:57.690: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:54:57.980: INFO: namespace namespaces-2454 deletion completed in 6.298339915s
STEP: Destroying namespace "nsdeletetest-7582" for this suite.
Dec 22 21:54:57.983: INFO: Namespace nsdeletetest-7582 was already deleted
STEP: Destroying namespace "nsdeletetest-2595" for this suite.
Dec 22 21:55:03.992: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:55:04.115: INFO: namespace nsdeletetest-2595 deletion completed in 6.132407178s

â€¢ [SLOW TEST:18.586 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:55:04.115: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-3612.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-3612.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3612.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-3612.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-3612.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3612.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 22 21:55:06.205: INFO: DNS probes using dns-3612/dns-test-87bca140-266c-4d37-9fa9-8311b53e4e3e succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:55:06.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3612" for this suite.
Dec 22 21:55:12.245: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:55:12.411: INFO: namespace dns-3612 deletion completed in 6.18412243s

â€¢ [SLOW TEST:8.295 seconds]
[sig-network] DNS
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:55:12.412: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating service multi-endpoint-test in namespace services-7412
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7412 to expose endpoints map[]
Dec 22 21:55:12.455: INFO: Get endpoints failed (5.257483ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Dec 22 21:55:13.458: INFO: successfully validated that service multi-endpoint-test in namespace services-7412 exposes endpoints map[] (1.00842279s elapsed)
STEP: Creating pod pod1 in namespace services-7412
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7412 to expose endpoints map[pod1:[100]]
Dec 22 21:55:15.497: INFO: successfully validated that service multi-endpoint-test in namespace services-7412 exposes endpoints map[pod1:[100]] (2.033124234s elapsed)
STEP: Creating pod pod2 in namespace services-7412
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7412 to expose endpoints map[pod1:[100] pod2:[101]]
Dec 22 21:55:17.544: INFO: successfully validated that service multi-endpoint-test in namespace services-7412 exposes endpoints map[pod1:[100] pod2:[101]] (2.038511923s elapsed)
STEP: Deleting pod pod1 in namespace services-7412
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7412 to expose endpoints map[pod2:[101]]
Dec 22 21:55:18.560: INFO: successfully validated that service multi-endpoint-test in namespace services-7412 exposes endpoints map[pod2:[101]] (1.011706063s elapsed)
STEP: Deleting pod pod2 in namespace services-7412
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7412 to expose endpoints map[]
Dec 22 21:55:19.575: INFO: successfully validated that service multi-endpoint-test in namespace services-7412 exposes endpoints map[] (1.009266656s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:55:19.589: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7412" for this suite.
Dec 22 21:55:39.617: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:55:39.706: INFO: namespace services-7412 deletion completed in 20.102494717s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

â€¢ [SLOW TEST:27.295 seconds]
[sig-network] Services
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:55:39.707: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-map-11a758b9-d9c4-4bdb-a2cd-2d625f343e14
STEP: Creating a pod to test consume secrets
Dec 22 21:55:39.734: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-89a2cb21-808e-4175-9395-aa1d3ef4c8ae" in namespace "projected-4688" to be "success or failure"
Dec 22 21:55:39.737: INFO: Pod "pod-projected-secrets-89a2cb21-808e-4175-9395-aa1d3ef4c8ae": Phase="Pending", Reason="", readiness=false. Elapsed: 2.545301ms
Dec 22 21:55:41.740: INFO: Pod "pod-projected-secrets-89a2cb21-808e-4175-9395-aa1d3ef4c8ae": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005396456s
STEP: Saw pod success
Dec 22 21:55:41.740: INFO: Pod "pod-projected-secrets-89a2cb21-808e-4175-9395-aa1d3ef4c8ae" satisfied condition "success or failure"
Dec 22 21:55:41.742: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod pod-projected-secrets-89a2cb21-808e-4175-9395-aa1d3ef4c8ae container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 22 21:55:41.755: INFO: Waiting for pod pod-projected-secrets-89a2cb21-808e-4175-9395-aa1d3ef4c8ae to disappear
Dec 22 21:55:41.757: INFO: Pod pod-projected-secrets-89a2cb21-808e-4175-9395-aa1d3ef4c8ae no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:55:41.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4688" for this suite.
Dec 22 21:55:47.770: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:55:47.834: INFO: namespace projected-4688 deletion completed in 6.07317978s

â€¢ [SLOW TEST:8.127 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:55:47.834: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-2562
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 22 21:55:47.856: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec 22 21:56:07.909: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.20.27.34:8080/dial?request=hostName&protocol=http&host=10.20.27.29&port=8080&tries=1'] Namespace:pod-network-test-2562 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 22 21:56:07.909: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
Dec 22 21:56:08.084: INFO: Waiting for endpoints: map[]
Dec 22 21:56:08.088: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.20.27.34:8080/dial?request=hostName&protocol=http&host=10.20.29.234&port=8080&tries=1'] Namespace:pod-network-test-2562 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 22 21:56:08.088: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
Dec 22 21:56:08.228: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:56:08.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-2562" for this suite.
Dec 22 21:56:30.239: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:56:30.318: INFO: namespace pod-network-test-2562 deletion completed in 22.08665499s

â€¢ [SLOW TEST:42.484 seconds]
[sig-network] Networking
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:56:30.318: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec 22 21:56:30.363: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Dec 22 21:56:30.373: INFO: DaemonSet pods can't tolerate node ip-10-0-1-168.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 22 21:56:30.375: INFO: Number of nodes with available pods: 0
Dec 22 21:56:30.375: INFO: Node ip-10-0-1-121.us-west-2.compute.internal is running more than one daemon pod
Dec 22 21:56:31.378: INFO: DaemonSet pods can't tolerate node ip-10-0-1-168.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 22 21:56:31.381: INFO: Number of nodes with available pods: 0
Dec 22 21:56:31.381: INFO: Node ip-10-0-1-121.us-west-2.compute.internal is running more than one daemon pod
Dec 22 21:56:32.379: INFO: DaemonSet pods can't tolerate node ip-10-0-1-168.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 22 21:56:32.382: INFO: Number of nodes with available pods: 1
Dec 22 21:56:32.382: INFO: Node ip-10-0-1-121.us-west-2.compute.internal is running more than one daemon pod
Dec 22 21:56:33.380: INFO: DaemonSet pods can't tolerate node ip-10-0-1-168.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 22 21:56:33.383: INFO: Number of nodes with available pods: 2
Dec 22 21:56:33.383: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Dec 22 21:56:33.430: INFO: Wrong image for pod: daemon-set-hghg5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec 22 21:56:33.430: INFO: Wrong image for pod: daemon-set-n5d2t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec 22 21:56:33.434: INFO: DaemonSet pods can't tolerate node ip-10-0-1-168.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 22 21:56:34.437: INFO: Wrong image for pod: daemon-set-hghg5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec 22 21:56:34.437: INFO: Wrong image for pod: daemon-set-n5d2t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec 22 21:56:34.442: INFO: DaemonSet pods can't tolerate node ip-10-0-1-168.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 22 21:56:35.439: INFO: Wrong image for pod: daemon-set-hghg5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec 22 21:56:35.439: INFO: Wrong image for pod: daemon-set-n5d2t. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec 22 21:56:35.439: INFO: Pod daemon-set-n5d2t is not available
Dec 22 21:56:35.442: INFO: DaemonSet pods can't tolerate node ip-10-0-1-168.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 22 21:56:36.438: INFO: Wrong image for pod: daemon-set-hghg5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec 22 21:56:36.438: INFO: Pod daemon-set-k2f5s is not available
Dec 22 21:56:36.441: INFO: DaemonSet pods can't tolerate node ip-10-0-1-168.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 22 21:56:37.438: INFO: Wrong image for pod: daemon-set-hghg5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec 22 21:56:37.438: INFO: Pod daemon-set-k2f5s is not available
Dec 22 21:56:37.441: INFO: DaemonSet pods can't tolerate node ip-10-0-1-168.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 22 21:56:38.443: INFO: Wrong image for pod: daemon-set-hghg5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec 22 21:56:38.459: INFO: DaemonSet pods can't tolerate node ip-10-0-1-168.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 22 21:56:39.437: INFO: Wrong image for pod: daemon-set-hghg5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec 22 21:56:39.441: INFO: DaemonSet pods can't tolerate node ip-10-0-1-168.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 22 21:56:40.437: INFO: Wrong image for pod: daemon-set-hghg5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec 22 21:56:40.437: INFO: Pod daemon-set-hghg5 is not available
Dec 22 21:56:40.440: INFO: DaemonSet pods can't tolerate node ip-10-0-1-168.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 22 21:56:41.438: INFO: Pod daemon-set-9tmt9 is not available
Dec 22 21:56:41.443: INFO: DaemonSet pods can't tolerate node ip-10-0-1-168.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Dec 22 21:56:41.447: INFO: DaemonSet pods can't tolerate node ip-10-0-1-168.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 22 21:56:41.450: INFO: Number of nodes with available pods: 1
Dec 22 21:56:41.450: INFO: Node ip-10-0-1-121.us-west-2.compute.internal is running more than one daemon pod
Dec 22 21:56:42.454: INFO: DaemonSet pods can't tolerate node ip-10-0-1-168.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 22 21:56:42.457: INFO: Number of nodes with available pods: 1
Dec 22 21:56:42.457: INFO: Node ip-10-0-1-121.us-west-2.compute.internal is running more than one daemon pod
Dec 22 21:56:43.454: INFO: DaemonSet pods can't tolerate node ip-10-0-1-168.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 22 21:56:43.457: INFO: Number of nodes with available pods: 2
Dec 22 21:56:43.457: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3481, will wait for the garbage collector to delete the pods
Dec 22 21:56:43.541: INFO: Deleting DaemonSet.extensions daemon-set took: 10.118133ms
Dec 22 21:56:43.941: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.203067ms
Dec 22 21:56:55.344: INFO: Number of nodes with available pods: 0
Dec 22 21:56:55.344: INFO: Number of running nodes: 0, number of available pods: 0
Dec 22 21:56:55.347: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-3481/daemonsets","resourceVersion":"10342"},"items":null}

Dec 22 21:56:55.351: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-3481/pods","resourceVersion":"10342"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:56:55.359: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3481" for this suite.
Dec 22 21:57:01.370: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:57:01.601: INFO: namespace daemonsets-3481 deletion completed in 6.237788012s

â€¢ [SLOW TEST:31.282 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:57:01.602: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec 22 21:57:01.628: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c212559c-1358-43c4-ac0f-2724049d8736" in namespace "projected-2720" to be "success or failure"
Dec 22 21:57:01.632: INFO: Pod "downwardapi-volume-c212559c-1358-43c4-ac0f-2724049d8736": Phase="Pending", Reason="", readiness=false. Elapsed: 3.509361ms
Dec 22 21:57:03.636: INFO: Pod "downwardapi-volume-c212559c-1358-43c4-ac0f-2724049d8736": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008146366s
STEP: Saw pod success
Dec 22 21:57:03.636: INFO: Pod "downwardapi-volume-c212559c-1358-43c4-ac0f-2724049d8736" satisfied condition "success or failure"
Dec 22 21:57:03.645: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod downwardapi-volume-c212559c-1358-43c4-ac0f-2724049d8736 container client-container: <nil>
STEP: delete the pod
Dec 22 21:57:03.678: INFO: Waiting for pod downwardapi-volume-c212559c-1358-43c4-ac0f-2724049d8736 to disappear
Dec 22 21:57:03.685: INFO: Pod downwardapi-volume-c212559c-1358-43c4-ac0f-2724049d8736 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:57:03.685: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2720" for this suite.
Dec 22 21:57:09.705: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:57:09.767: INFO: namespace projected-2720 deletion completed in 6.078768686s

â€¢ [SLOW TEST:8.166 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:57:09.768: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec 22 21:57:12.307: INFO: Successfully updated pod "pod-update-d00b7141-1502-4caa-8a4c-b431be89a29d"
STEP: verifying the updated pod is in kubernetes
Dec 22 21:57:12.317: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:57:12.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3850" for this suite.
Dec 22 21:57:34.329: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:57:34.397: INFO: namespace pods-3850 deletion completed in 22.075280435s

â€¢ [SLOW TEST:24.629 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:57:34.397: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-map-7fae41cc-7802-4a0b-9c2a-98a01c769e5f
STEP: Creating a pod to test consume secrets
Dec 22 21:57:34.475: INFO: Waiting up to 5m0s for pod "pod-secrets-172509a6-6515-4377-a796-4a22fa1d35da" in namespace "secrets-9499" to be "success or failure"
Dec 22 21:57:34.477: INFO: Pod "pod-secrets-172509a6-6515-4377-a796-4a22fa1d35da": Phase="Pending", Reason="", readiness=false. Elapsed: 2.384914ms
Dec 22 21:57:36.481: INFO: Pod "pod-secrets-172509a6-6515-4377-a796-4a22fa1d35da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00584516s
STEP: Saw pod success
Dec 22 21:57:36.481: INFO: Pod "pod-secrets-172509a6-6515-4377-a796-4a22fa1d35da" satisfied condition "success or failure"
Dec 22 21:57:36.483: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod pod-secrets-172509a6-6515-4377-a796-4a22fa1d35da container secret-volume-test: <nil>
STEP: delete the pod
Dec 22 21:57:36.499: INFO: Waiting for pod pod-secrets-172509a6-6515-4377-a796-4a22fa1d35da to disappear
Dec 22 21:57:36.503: INFO: Pod pod-secrets-172509a6-6515-4377-a796-4a22fa1d35da no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:57:36.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9499" for this suite.
Dec 22 21:57:42.514: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:57:42.574: INFO: namespace secrets-9499 deletion completed in 6.066611208s

â€¢ [SLOW TEST:8.177 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:57:42.574: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1210
STEP: creating the pod
Dec 22 21:57:42.602: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 create -f - --namespace=kubectl-710'
Dec 22 21:57:43.213: INFO: stderr: ""
Dec 22 21:57:43.213: INFO: stdout: "pod/pause created\n"
Dec 22 21:57:43.213: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Dec 22 21:57:43.213: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-710" to be "running and ready"
Dec 22 21:57:43.217: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 4.501552ms
Dec 22 21:57:45.220: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007259521s
Dec 22 21:57:47.223: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.009934658s
Dec 22 21:57:47.223: INFO: Pod "pause" satisfied condition "running and ready"
Dec 22 21:57:47.223: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: adding the label testing-label with value testing-label-value to a pod
Dec 22 21:57:47.223: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 label pods pause testing-label=testing-label-value --namespace=kubectl-710'
Dec 22 21:57:47.305: INFO: stderr: ""
Dec 22 21:57:47.305: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Dec 22 21:57:47.305: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 get pod pause -L testing-label --namespace=kubectl-710'
Dec 22 21:57:47.401: INFO: stderr: ""
Dec 22 21:57:47.401: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Dec 22 21:57:47.401: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 label pods pause testing-label- --namespace=kubectl-710'
Dec 22 21:57:47.478: INFO: stderr: ""
Dec 22 21:57:47.478: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Dec 22 21:57:47.478: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 get pod pause -L testing-label --namespace=kubectl-710'
Dec 22 21:57:47.551: INFO: stderr: ""
Dec 22 21:57:47.551: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1217
STEP: using delete to clean up resources
Dec 22 21:57:47.551: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 delete --grace-period=0 --force -f - --namespace=kubectl-710'
Dec 22 21:57:47.630: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 22 21:57:47.630: INFO: stdout: "pod \"pause\" force deleted\n"
Dec 22 21:57:47.630: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 get rc,svc -l name=pause --no-headers --namespace=kubectl-710'
Dec 22 21:57:47.709: INFO: stderr: "No resources found.\n"
Dec 22 21:57:47.709: INFO: stdout: ""
Dec 22 21:57:47.709: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 get pods -l name=pause --namespace=kubectl-710 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 22 21:57:47.781: INFO: stderr: ""
Dec 22 21:57:47.781: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:57:47.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-710" for this suite.
Dec 22 21:57:53.793: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:57:53.900: INFO: namespace kubectl-710 deletion completed in 6.115605598s

â€¢ [SLOW TEST:11.326 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl label
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:57:53.900: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec 22 21:57:53.922: INFO: Waiting up to 5m0s for pod "pod-7bfc4d93-a551-4dd7-8e66-b9fcace8d283" in namespace "emptydir-3300" to be "success or failure"
Dec 22 21:57:53.924: INFO: Pod "pod-7bfc4d93-a551-4dd7-8e66-b9fcace8d283": Phase="Pending", Reason="", readiness=false. Elapsed: 2.240031ms
Dec 22 21:57:55.928: INFO: Pod "pod-7bfc4d93-a551-4dd7-8e66-b9fcace8d283": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005840992s
STEP: Saw pod success
Dec 22 21:57:55.928: INFO: Pod "pod-7bfc4d93-a551-4dd7-8e66-b9fcace8d283" satisfied condition "success or failure"
Dec 22 21:57:55.931: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod pod-7bfc4d93-a551-4dd7-8e66-b9fcace8d283 container test-container: <nil>
STEP: delete the pod
Dec 22 21:57:55.951: INFO: Waiting for pod pod-7bfc4d93-a551-4dd7-8e66-b9fcace8d283 to disappear
Dec 22 21:57:55.954: INFO: Pod pod-7bfc4d93-a551-4dd7-8e66-b9fcace8d283 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:57:55.954: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3300" for this suite.
Dec 22 21:58:01.967: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:58:02.114: INFO: namespace emptydir-3300 deletion completed in 6.155895208s

â€¢ [SLOW TEST:8.214 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:58:02.114: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec 22 21:58:02.166: INFO: (0) /api/v1/nodes/ip-10-0-1-121.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.487938ms)
Dec 22 21:58:02.170: INFO: (1) /api/v1/nodes/ip-10-0-1-121.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.958389ms)
Dec 22 21:58:02.174: INFO: (2) /api/v1/nodes/ip-10-0-1-121.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.064383ms)
Dec 22 21:58:02.178: INFO: (3) /api/v1/nodes/ip-10-0-1-121.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.587298ms)
Dec 22 21:58:02.181: INFO: (4) /api/v1/nodes/ip-10-0-1-121.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.263097ms)
Dec 22 21:58:02.191: INFO: (5) /api/v1/nodes/ip-10-0-1-121.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 9.238365ms)
Dec 22 21:58:02.195: INFO: (6) /api/v1/nodes/ip-10-0-1-121.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.12707ms)
Dec 22 21:58:02.198: INFO: (7) /api/v1/nodes/ip-10-0-1-121.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.385021ms)
Dec 22 21:58:02.201: INFO: (8) /api/v1/nodes/ip-10-0-1-121.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.254627ms)
Dec 22 21:58:02.206: INFO: (9) /api/v1/nodes/ip-10-0-1-121.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.873016ms)
Dec 22 21:58:02.219: INFO: (10) /api/v1/nodes/ip-10-0-1-121.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 12.856267ms)
Dec 22 21:58:02.232: INFO: (11) /api/v1/nodes/ip-10-0-1-121.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 13.053514ms)
Dec 22 21:58:02.238: INFO: (12) /api/v1/nodes/ip-10-0-1-121.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 5.357168ms)
Dec 22 21:58:02.245: INFO: (13) /api/v1/nodes/ip-10-0-1-121.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 7.600705ms)
Dec 22 21:58:02.250: INFO: (14) /api/v1/nodes/ip-10-0-1-121.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.485069ms)
Dec 22 21:58:02.262: INFO: (15) /api/v1/nodes/ip-10-0-1-121.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 12.189017ms)
Dec 22 21:58:02.267: INFO: (16) /api/v1/nodes/ip-10-0-1-121.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 5.205908ms)
Dec 22 21:58:02.272: INFO: (17) /api/v1/nodes/ip-10-0-1-121.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.850896ms)
Dec 22 21:58:02.278: INFO: (18) /api/v1/nodes/ip-10-0-1-121.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 5.442416ms)
Dec 22 21:58:02.283: INFO: (19) /api/v1/nodes/ip-10-0-1-121.us-west-2.compute.internal/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.792424ms)
[AfterEach] version v1
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:58:02.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-5386" for this suite.
Dec 22 21:58:08.297: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:58:08.398: INFO: namespace proxy-5386 deletion completed in 6.110817928s

â€¢ [SLOW TEST:6.284 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:58:08.399: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name cm-test-opt-del-a0c5a3a9-0331-4d73-a382-3b3ac8b8b41f
STEP: Creating configMap with name cm-test-opt-upd-b731b9d2-9534-46b4-bbcb-3854196d0549
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-a0c5a3a9-0331-4d73-a382-3b3ac8b8b41f
STEP: Updating configmap cm-test-opt-upd-b731b9d2-9534-46b4-bbcb-3854196d0549
STEP: Creating configMap with name cm-test-opt-create-4b1bb930-555a-40c0-805f-27428f0c33c5
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:59:22.804: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2114" for this suite.
Dec 22 21:59:44.817: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 21:59:44.903: INFO: namespace configmap-2114 deletion completed in 22.095337116s

â€¢ [SLOW TEST:96.504 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 21:59:44.903: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating pod
Dec 22 21:59:48.986: INFO: Pod pod-hostip-d2e57c97-d185-4e4e-9687-d0b5b14c689b has hostIP: 10.0.1.121
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 21:59:48.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4792" for this suite.
Dec 22 22:00:10.997: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:00:11.121: INFO: namespace pods-4792 deletion completed in 22.13070627s

â€¢ [SLOW TEST:26.218 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:00:11.122: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec 22 22:00:11.142: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:00:15.173: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3522" for this suite.
Dec 22 22:00:53.185: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:00:53.295: INFO: namespace pods-3522 deletion completed in 38.117659742s

â€¢ [SLOW TEST:42.173 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:00:53.295: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-9a4d98dd-d564-44fe-bcf8-5d093fbf9706
STEP: Creating a pod to test consume secrets
Dec 22 22:00:53.324: INFO: Waiting up to 5m0s for pod "pod-secrets-5d0d584d-2f09-451a-b1ab-8ec97c031ba8" in namespace "secrets-5151" to be "success or failure"
Dec 22 22:00:53.333: INFO: Pod "pod-secrets-5d0d584d-2f09-451a-b1ab-8ec97c031ba8": Phase="Pending", Reason="", readiness=false. Elapsed: 8.427699ms
Dec 22 22:00:55.341: INFO: Pod "pod-secrets-5d0d584d-2f09-451a-b1ab-8ec97c031ba8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016472451s
STEP: Saw pod success
Dec 22 22:00:55.341: INFO: Pod "pod-secrets-5d0d584d-2f09-451a-b1ab-8ec97c031ba8" satisfied condition "success or failure"
Dec 22 22:00:55.344: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod pod-secrets-5d0d584d-2f09-451a-b1ab-8ec97c031ba8 container secret-volume-test: <nil>
STEP: delete the pod
Dec 22 22:00:55.375: INFO: Waiting for pod pod-secrets-5d0d584d-2f09-451a-b1ab-8ec97c031ba8 to disappear
Dec 22 22:00:55.382: INFO: Pod pod-secrets-5d0d584d-2f09-451a-b1ab-8ec97c031ba8 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:00:55.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5151" for this suite.
Dec 22 22:01:01.408: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:01:01.558: INFO: namespace secrets-5151 deletion completed in 6.167703253s

â€¢ [SLOW TEST:8.264 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:01:01.559: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec 22 22:01:01.585: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a5540638-4130-42fd-9b0e-883b56f136b2" in namespace "projected-8703" to be "success or failure"
Dec 22 22:01:01.588: INFO: Pod "downwardapi-volume-a5540638-4130-42fd-9b0e-883b56f136b2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.710422ms
Dec 22 22:01:03.594: INFO: Pod "downwardapi-volume-a5540638-4130-42fd-9b0e-883b56f136b2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00819276s
STEP: Saw pod success
Dec 22 22:01:03.594: INFO: Pod "downwardapi-volume-a5540638-4130-42fd-9b0e-883b56f136b2" satisfied condition "success or failure"
Dec 22 22:01:03.599: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod downwardapi-volume-a5540638-4130-42fd-9b0e-883b56f136b2 container client-container: <nil>
STEP: delete the pod
Dec 22 22:01:03.618: INFO: Waiting for pod downwardapi-volume-a5540638-4130-42fd-9b0e-883b56f136b2 to disappear
Dec 22 22:01:03.624: INFO: Pod downwardapi-volume-a5540638-4130-42fd-9b0e-883b56f136b2 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:01:03.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8703" for this suite.
Dec 22 22:01:09.644: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:01:09.813: INFO: namespace projected-8703 deletion completed in 6.180316044s

â€¢ [SLOW TEST:8.254 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:01:09.813: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override arguments
Dec 22 22:01:09.901: INFO: Waiting up to 5m0s for pod "client-containers-40e6a55b-90d6-4b2a-a846-5567f5d35089" in namespace "containers-8802" to be "success or failure"
Dec 22 22:01:09.905: INFO: Pod "client-containers-40e6a55b-90d6-4b2a-a846-5567f5d35089": Phase="Pending", Reason="", readiness=false. Elapsed: 3.982454ms
Dec 22 22:01:11.908: INFO: Pod "client-containers-40e6a55b-90d6-4b2a-a846-5567f5d35089": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007285778s
STEP: Saw pod success
Dec 22 22:01:11.909: INFO: Pod "client-containers-40e6a55b-90d6-4b2a-a846-5567f5d35089" satisfied condition "success or failure"
Dec 22 22:01:11.913: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod client-containers-40e6a55b-90d6-4b2a-a846-5567f5d35089 container test-container: <nil>
STEP: delete the pod
Dec 22 22:01:11.929: INFO: Waiting for pod client-containers-40e6a55b-90d6-4b2a-a846-5567f5d35089 to disappear
Dec 22 22:01:11.931: INFO: Pod client-containers-40e6a55b-90d6-4b2a-a846-5567f5d35089 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:01:11.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8802" for this suite.
Dec 22 22:01:17.945: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:01:18.054: INFO: namespace containers-8802 deletion completed in 6.119073354s

â€¢ [SLOW TEST:8.241 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:01:18.055: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-downwardapi-p4ps
STEP: Creating a pod to test atomic-volume-subpath
Dec 22 22:01:18.086: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-p4ps" in namespace "subpath-6899" to be "success or failure"
Dec 22 22:01:18.088: INFO: Pod "pod-subpath-test-downwardapi-p4ps": Phase="Pending", Reason="", readiness=false. Elapsed: 1.915548ms
Dec 22 22:01:20.091: INFO: Pod "pod-subpath-test-downwardapi-p4ps": Phase="Running", Reason="", readiness=true. Elapsed: 2.00489455s
Dec 22 22:01:22.095: INFO: Pod "pod-subpath-test-downwardapi-p4ps": Phase="Running", Reason="", readiness=true. Elapsed: 4.008675109s
Dec 22 22:01:24.100: INFO: Pod "pod-subpath-test-downwardapi-p4ps": Phase="Running", Reason="", readiness=true. Elapsed: 6.013940316s
Dec 22 22:01:26.103: INFO: Pod "pod-subpath-test-downwardapi-p4ps": Phase="Running", Reason="", readiness=true. Elapsed: 8.016654153s
Dec 22 22:01:28.106: INFO: Pod "pod-subpath-test-downwardapi-p4ps": Phase="Running", Reason="", readiness=true. Elapsed: 10.019753377s
Dec 22 22:01:30.109: INFO: Pod "pod-subpath-test-downwardapi-p4ps": Phase="Running", Reason="", readiness=true. Elapsed: 12.022340556s
Dec 22 22:01:32.111: INFO: Pod "pod-subpath-test-downwardapi-p4ps": Phase="Running", Reason="", readiness=true. Elapsed: 14.025056425s
Dec 22 22:01:34.119: INFO: Pod "pod-subpath-test-downwardapi-p4ps": Phase="Running", Reason="", readiness=true. Elapsed: 16.032789337s
Dec 22 22:01:36.122: INFO: Pod "pod-subpath-test-downwardapi-p4ps": Phase="Running", Reason="", readiness=true. Elapsed: 18.035882357s
Dec 22 22:01:38.125: INFO: Pod "pod-subpath-test-downwardapi-p4ps": Phase="Running", Reason="", readiness=true. Elapsed: 20.038840353s
Dec 22 22:01:40.131: INFO: Pod "pod-subpath-test-downwardapi-p4ps": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.044171617s
STEP: Saw pod success
Dec 22 22:01:40.131: INFO: Pod "pod-subpath-test-downwardapi-p4ps" satisfied condition "success or failure"
Dec 22 22:01:40.133: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod pod-subpath-test-downwardapi-p4ps container test-container-subpath-downwardapi-p4ps: <nil>
STEP: delete the pod
Dec 22 22:01:40.149: INFO: Waiting for pod pod-subpath-test-downwardapi-p4ps to disappear
Dec 22 22:01:40.151: INFO: Pod pod-subpath-test-downwardapi-p4ps no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-p4ps
Dec 22 22:01:40.151: INFO: Deleting pod "pod-subpath-test-downwardapi-p4ps" in namespace "subpath-6899"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:01:40.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6899" for this suite.
Dec 22 22:01:46.169: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:01:46.298: INFO: namespace subpath-6899 deletion completed in 6.141582293s

â€¢ [SLOW TEST:28.244 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:01:46.298: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec 22 22:01:46.328: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Dec 22 22:01:46.333: INFO: Number of nodes with available pods: 0
Dec 22 22:01:46.333: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Dec 22 22:01:46.348: INFO: Number of nodes with available pods: 0
Dec 22 22:01:46.348: INFO: Node ip-10-0-1-121.us-west-2.compute.internal is running more than one daemon pod
Dec 22 22:01:47.355: INFO: Number of nodes with available pods: 0
Dec 22 22:01:47.355: INFO: Node ip-10-0-1-121.us-west-2.compute.internal is running more than one daemon pod
Dec 22 22:01:48.351: INFO: Number of nodes with available pods: 1
Dec 22 22:01:48.351: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Dec 22 22:01:48.366: INFO: Number of nodes with available pods: 1
Dec 22 22:01:48.366: INFO: Number of running nodes: 0, number of available pods: 1
Dec 22 22:01:49.369: INFO: Number of nodes with available pods: 0
Dec 22 22:01:49.369: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Dec 22 22:01:49.375: INFO: Number of nodes with available pods: 0
Dec 22 22:01:49.375: INFO: Node ip-10-0-1-121.us-west-2.compute.internal is running more than one daemon pod
Dec 22 22:01:50.378: INFO: Number of nodes with available pods: 0
Dec 22 22:01:50.378: INFO: Node ip-10-0-1-121.us-west-2.compute.internal is running more than one daemon pod
Dec 22 22:01:51.378: INFO: Number of nodes with available pods: 0
Dec 22 22:01:51.378: INFO: Node ip-10-0-1-121.us-west-2.compute.internal is running more than one daemon pod
Dec 22 22:01:52.378: INFO: Number of nodes with available pods: 0
Dec 22 22:01:52.378: INFO: Node ip-10-0-1-121.us-west-2.compute.internal is running more than one daemon pod
Dec 22 22:01:53.378: INFO: Number of nodes with available pods: 0
Dec 22 22:01:53.378: INFO: Node ip-10-0-1-121.us-west-2.compute.internal is running more than one daemon pod
Dec 22 22:01:54.378: INFO: Number of nodes with available pods: 0
Dec 22 22:01:54.378: INFO: Node ip-10-0-1-121.us-west-2.compute.internal is running more than one daemon pod
Dec 22 22:01:55.379: INFO: Number of nodes with available pods: 0
Dec 22 22:01:55.380: INFO: Node ip-10-0-1-121.us-west-2.compute.internal is running more than one daemon pod
Dec 22 22:01:56.378: INFO: Number of nodes with available pods: 0
Dec 22 22:01:56.378: INFO: Node ip-10-0-1-121.us-west-2.compute.internal is running more than one daemon pod
Dec 22 22:01:57.378: INFO: Number of nodes with available pods: 0
Dec 22 22:01:57.378: INFO: Node ip-10-0-1-121.us-west-2.compute.internal is running more than one daemon pod
Dec 22 22:01:58.378: INFO: Number of nodes with available pods: 0
Dec 22 22:01:58.378: INFO: Node ip-10-0-1-121.us-west-2.compute.internal is running more than one daemon pod
Dec 22 22:01:59.384: INFO: Number of nodes with available pods: 0
Dec 22 22:01:59.384: INFO: Node ip-10-0-1-121.us-west-2.compute.internal is running more than one daemon pod
Dec 22 22:02:00.379: INFO: Number of nodes with available pods: 0
Dec 22 22:02:00.379: INFO: Node ip-10-0-1-121.us-west-2.compute.internal is running more than one daemon pod
Dec 22 22:02:01.378: INFO: Number of nodes with available pods: 0
Dec 22 22:02:01.378: INFO: Node ip-10-0-1-121.us-west-2.compute.internal is running more than one daemon pod
Dec 22 22:02:02.378: INFO: Number of nodes with available pods: 0
Dec 22 22:02:02.378: INFO: Node ip-10-0-1-121.us-west-2.compute.internal is running more than one daemon pod
Dec 22 22:02:03.379: INFO: Number of nodes with available pods: 0
Dec 22 22:02:03.379: INFO: Node ip-10-0-1-121.us-west-2.compute.internal is running more than one daemon pod
Dec 22 22:02:04.378: INFO: Number of nodes with available pods: 0
Dec 22 22:02:04.378: INFO: Node ip-10-0-1-121.us-west-2.compute.internal is running more than one daemon pod
Dec 22 22:02:05.378: INFO: Number of nodes with available pods: 1
Dec 22 22:02:05.378: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9757, will wait for the garbage collector to delete the pods
Dec 22 22:02:05.462: INFO: Deleting DaemonSet.extensions daemon-set took: 28.670898ms
Dec 22 22:02:05.863: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.26009ms
Dec 22 22:02:08.565: INFO: Number of nodes with available pods: 0
Dec 22 22:02:08.565: INFO: Number of running nodes: 0, number of available pods: 0
Dec 22 22:02:08.567: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9757/daemonsets","resourceVersion":"11290"},"items":null}

Dec 22 22:02:08.568: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9757/pods","resourceVersion":"11290"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:02:08.586: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9757" for this suite.
Dec 22 22:02:14.596: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:02:14.701: INFO: namespace daemonsets-9757 deletion completed in 6.111518745s

â€¢ [SLOW TEST:28.403 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:02:14.702: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec 22 22:02:14.727: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a82a80e8-5f67-433a-a9a5-09d3e7b450c3" in namespace "downward-api-2986" to be "success or failure"
Dec 22 22:02:14.731: INFO: Pod "downwardapi-volume-a82a80e8-5f67-433a-a9a5-09d3e7b450c3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.361933ms
Dec 22 22:02:16.737: INFO: Pod "downwardapi-volume-a82a80e8-5f67-433a-a9a5-09d3e7b450c3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0098372s
STEP: Saw pod success
Dec 22 22:02:16.737: INFO: Pod "downwardapi-volume-a82a80e8-5f67-433a-a9a5-09d3e7b450c3" satisfied condition "success or failure"
Dec 22 22:02:16.743: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod downwardapi-volume-a82a80e8-5f67-433a-a9a5-09d3e7b450c3 container client-container: <nil>
STEP: delete the pod
Dec 22 22:02:16.775: INFO: Waiting for pod downwardapi-volume-a82a80e8-5f67-433a-a9a5-09d3e7b450c3 to disappear
Dec 22 22:02:16.780: INFO: Pod downwardapi-volume-a82a80e8-5f67-433a-a9a5-09d3e7b450c3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:02:16.780: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2986" for this suite.
Dec 22 22:02:22.796: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:02:22.864: INFO: namespace downward-api-2986 deletion completed in 6.080066051s

â€¢ [SLOW TEST:8.163 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:02:22.864: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Dec 22 22:02:22.934: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:02:25.822: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1428" for this suite.
Dec 22 22:02:31.834: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:02:31.910: INFO: namespace init-container-1428 deletion completed in 6.08416125s

â€¢ [SLOW TEST:9.045 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:02:31.910: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec 22 22:02:31.934: INFO: Waiting up to 5m0s for pod "pod-b32c1301-c531-4d41-bc28-5e720c341ad9" in namespace "emptydir-9442" to be "success or failure"
Dec 22 22:02:31.938: INFO: Pod "pod-b32c1301-c531-4d41-bc28-5e720c341ad9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.116236ms
Dec 22 22:02:33.941: INFO: Pod "pod-b32c1301-c531-4d41-bc28-5e720c341ad9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006706333s
STEP: Saw pod success
Dec 22 22:02:33.941: INFO: Pod "pod-b32c1301-c531-4d41-bc28-5e720c341ad9" satisfied condition "success or failure"
Dec 22 22:02:33.943: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod pod-b32c1301-c531-4d41-bc28-5e720c341ad9 container test-container: <nil>
STEP: delete the pod
Dec 22 22:02:33.957: INFO: Waiting for pod pod-b32c1301-c531-4d41-bc28-5e720c341ad9 to disappear
Dec 22 22:02:33.960: INFO: Pod pod-b32c1301-c531-4d41-bc28-5e720c341ad9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:02:33.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9442" for this suite.
Dec 22 22:02:39.971: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:02:40.048: INFO: namespace emptydir-9442 deletion completed in 6.084248421s

â€¢ [SLOW TEST:8.138 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:02:40.048: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec 22 22:02:40.086: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3aec393b-76eb-43ac-9453-9d294044ae6b" in namespace "downward-api-4209" to be "success or failure"
Dec 22 22:02:40.089: INFO: Pod "downwardapi-volume-3aec393b-76eb-43ac-9453-9d294044ae6b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.51675ms
Dec 22 22:02:42.092: INFO: Pod "downwardapi-volume-3aec393b-76eb-43ac-9453-9d294044ae6b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006206821s
Dec 22 22:02:44.096: INFO: Pod "downwardapi-volume-3aec393b-76eb-43ac-9453-9d294044ae6b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010082289s
STEP: Saw pod success
Dec 22 22:02:44.096: INFO: Pod "downwardapi-volume-3aec393b-76eb-43ac-9453-9d294044ae6b" satisfied condition "success or failure"
Dec 22 22:02:44.098: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod downwardapi-volume-3aec393b-76eb-43ac-9453-9d294044ae6b container client-container: <nil>
STEP: delete the pod
Dec 22 22:02:44.115: INFO: Waiting for pod downwardapi-volume-3aec393b-76eb-43ac-9453-9d294044ae6b to disappear
Dec 22 22:02:44.118: INFO: Pod downwardapi-volume-3aec393b-76eb-43ac-9453-9d294044ae6b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:02:44.118: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4209" for this suite.
Dec 22 22:02:50.136: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:02:50.298: INFO: namespace downward-api-4209 deletion completed in 6.171996313s

â€¢ [SLOW TEST:10.250 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:02:50.299: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Dec 22 22:02:54.332: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec pod-sharedvolume-563e6ccb-3f55-4f98-9fcd-7219f39133a0 -c busybox-main-container --namespace=emptydir-1696 -- cat /usr/share/volumeshare/shareddata.txt'
Dec 22 22:02:54.578: INFO: stderr: ""
Dec 22 22:02:54.578: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:02:54.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1696" for this suite.
Dec 22 22:03:00.594: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:03:00.721: INFO: namespace emptydir-1696 deletion completed in 6.139070469s

â€¢ [SLOW TEST:10.423 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:03:00.722: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:03:03.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-5099" for this suite.
Dec 22 22:03:25.778: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:03:25.915: INFO: namespace replication-controller-5099 deletion completed in 22.144396767s

â€¢ [SLOW TEST:25.193 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:03:25.915: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1685
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec 22 22:03:25.937: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-479'
Dec 22 22:03:26.013: INFO: stderr: ""
Dec 22 22:03:26.013: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1690
Dec 22 22:03:26.021: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 delete pods e2e-test-nginx-pod --namespace=kubectl-479'
Dec 22 22:03:42.255: INFO: stderr: ""
Dec 22 22:03:42.255: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:03:42.255: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-479" for this suite.
Dec 22 22:03:48.267: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:03:48.433: INFO: namespace kubectl-479 deletion completed in 6.17369526s

â€¢ [SLOW TEST:22.518 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:03:48.433: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-jv7qp in namespace proxy-3627
I1222 22:03:48.511176      15 runners.go:180] Created replication controller with name: proxy-service-jv7qp, namespace: proxy-3627, replica count: 1
I1222 22:03:49.562224      15 runners.go:180] proxy-service-jv7qp Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1222 22:03:50.562438      15 runners.go:180] proxy-service-jv7qp Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1222 22:03:51.562648      15 runners.go:180] proxy-service-jv7qp Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1222 22:03:52.562865      15 runners.go:180] proxy-service-jv7qp Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1222 22:03:53.563071      15 runners.go:180] proxy-service-jv7qp Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1222 22:03:54.563262      15 runners.go:180] proxy-service-jv7qp Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1222 22:03:55.563474      15 runners.go:180] proxy-service-jv7qp Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1222 22:03:56.563817      15 runners.go:180] proxy-service-jv7qp Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1222 22:03:57.564113      15 runners.go:180] proxy-service-jv7qp Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1222 22:03:58.564326      15 runners.go:180] proxy-service-jv7qp Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1222 22:03:59.564500      15 runners.go:180] proxy-service-jv7qp Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1222 22:04:00.564691      15 runners.go:180] proxy-service-jv7qp Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 22 22:04:00.567: INFO: setup took 12.110650804s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Dec 22 22:04:00.587: INFO: (0) /api/v1/namespaces/proxy-3627/services/http:proxy-service-jv7qp:portname2/proxy/: bar (200; 19.559932ms)
Dec 22 22:04:00.587: INFO: (0) /api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:162/proxy/: bar (200; 19.184742ms)
Dec 22 22:04:00.587: INFO: (0) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb/proxy/rewriteme">test</a> (200; 19.534592ms)
Dec 22 22:04:00.592: INFO: (0) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:1080/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:1080/proxy/rewriteme">test<... (200; 24.259767ms)
Dec 22 22:04:00.592: INFO: (0) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:160/proxy/: foo (200; 24.937391ms)
Dec 22 22:04:00.593: INFO: (0) /api/v1/namespaces/proxy-3627/services/http:proxy-service-jv7qp:portname1/proxy/: foo (200; 25.63592ms)
Dec 22 22:04:00.593: INFO: (0) /api/v1/namespaces/proxy-3627/services/proxy-service-jv7qp:portname1/proxy/: foo (200; 25.225041ms)
Dec 22 22:04:00.593: INFO: (0) /api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:160/proxy/: foo (200; 25.854587ms)
Dec 22 22:04:00.593: INFO: (0) /api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:1080/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:1080/proxy/rewriteme">... (200; 25.174994ms)
Dec 22 22:04:00.593: INFO: (0) /api/v1/namespaces/proxy-3627/services/proxy-service-jv7qp:portname2/proxy/: bar (200; 25.894216ms)
Dec 22 22:04:00.593: INFO: (0) /api/v1/namespaces/proxy-3627/services/https:proxy-service-jv7qp:tlsportname2/proxy/: tls qux (200; 26.163407ms)
Dec 22 22:04:00.593: INFO: (0) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:162/proxy/: bar (200; 25.887942ms)
Dec 22 22:04:00.593: INFO: (0) /api/v1/namespaces/proxy-3627/services/https:proxy-service-jv7qp:tlsportname1/proxy/: tls baz (200; 26.040227ms)
Dec 22 22:04:00.593: INFO: (0) /api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:443/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:443/proxy/tlsrewritem... (200; 25.986145ms)
Dec 22 22:04:00.593: INFO: (0) /api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:460/proxy/: tls baz (200; 26.198594ms)
Dec 22 22:04:00.594: INFO: (0) /api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:462/proxy/: tls qux (200; 26.853581ms)
Dec 22 22:04:00.603: INFO: (1) /api/v1/namespaces/proxy-3627/services/proxy-service-jv7qp:portname2/proxy/: bar (200; 9.229897ms)
Dec 22 22:04:00.605: INFO: (1) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:1080/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:1080/proxy/rewriteme">test<... (200; 9.93839ms)
Dec 22 22:04:00.605: INFO: (1) /api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:162/proxy/: bar (200; 9.925248ms)
Dec 22 22:04:00.606: INFO: (1) /api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:1080/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:1080/proxy/rewriteme">... (200; 11.00449ms)
Dec 22 22:04:00.606: INFO: (1) /api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:460/proxy/: tls baz (200; 11.467965ms)
Dec 22 22:04:00.606: INFO: (1) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:160/proxy/: foo (200; 11.832015ms)
Dec 22 22:04:00.606: INFO: (1) /api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:462/proxy/: tls qux (200; 11.155266ms)
Dec 22 22:04:00.606: INFO: (1) /api/v1/namespaces/proxy-3627/services/http:proxy-service-jv7qp:portname1/proxy/: foo (200; 12.345624ms)
Dec 22 22:04:00.606: INFO: (1) /api/v1/namespaces/proxy-3627/services/https:proxy-service-jv7qp:tlsportname2/proxy/: tls qux (200; 12.703333ms)
Dec 22 22:04:00.607: INFO: (1) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:162/proxy/: bar (200; 12.474357ms)
Dec 22 22:04:00.607: INFO: (1) /api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:443/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:443/proxy/tlsrewritem... (200; 12.346374ms)
Dec 22 22:04:00.607: INFO: (1) /api/v1/namespaces/proxy-3627/services/https:proxy-service-jv7qp:tlsportname1/proxy/: tls baz (200; 13.115343ms)
Dec 22 22:04:00.607: INFO: (1) /api/v1/namespaces/proxy-3627/services/http:proxy-service-jv7qp:portname2/proxy/: bar (200; 12.920581ms)
Dec 22 22:04:00.607: INFO: (1) /api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:160/proxy/: foo (200; 13.127556ms)
Dec 22 22:04:00.607: INFO: (1) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb/proxy/rewriteme">test</a> (200; 12.913189ms)
Dec 22 22:04:00.609: INFO: (1) /api/v1/namespaces/proxy-3627/services/proxy-service-jv7qp:portname1/proxy/: foo (200; 14.228809ms)
Dec 22 22:04:00.616: INFO: (2) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:1080/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:1080/proxy/rewriteme">test<... (200; 7.198061ms)
Dec 22 22:04:00.618: INFO: (2) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:162/proxy/: bar (200; 8.651386ms)
Dec 22 22:04:00.619: INFO: (2) /api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:1080/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:1080/proxy/rewriteme">... (200; 9.981561ms)
Dec 22 22:04:00.619: INFO: (2) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:160/proxy/: foo (200; 10.204929ms)
Dec 22 22:04:00.619: INFO: (2) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb/proxy/rewriteme">test</a> (200; 10.138935ms)
Dec 22 22:04:00.620: INFO: (2) /api/v1/namespaces/proxy-3627/services/http:proxy-service-jv7qp:portname2/proxy/: bar (200; 10.329692ms)
Dec 22 22:04:00.621: INFO: (2) /api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:160/proxy/: foo (200; 11.795619ms)
Dec 22 22:04:00.621: INFO: (2) /api/v1/namespaces/proxy-3627/services/proxy-service-jv7qp:portname1/proxy/: foo (200; 12.57652ms)
Dec 22 22:04:00.622: INFO: (2) /api/v1/namespaces/proxy-3627/services/https:proxy-service-jv7qp:tlsportname1/proxy/: tls baz (200; 13.318766ms)
Dec 22 22:04:00.622: INFO: (2) /api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:460/proxy/: tls baz (200; 13.261222ms)
Dec 22 22:04:00.623: INFO: (2) /api/v1/namespaces/proxy-3627/services/proxy-service-jv7qp:portname2/proxy/: bar (200; 14.098136ms)
Dec 22 22:04:00.623: INFO: (2) /api/v1/namespaces/proxy-3627/services/http:proxy-service-jv7qp:portname1/proxy/: foo (200; 14.337275ms)
Dec 22 22:04:00.623: INFO: (2) /api/v1/namespaces/proxy-3627/services/https:proxy-service-jv7qp:tlsportname2/proxy/: tls qux (200; 14.717174ms)
Dec 22 22:04:00.624: INFO: (2) /api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:162/proxy/: bar (200; 14.510172ms)
Dec 22 22:04:00.624: INFO: (2) /api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:462/proxy/: tls qux (200; 14.952032ms)
Dec 22 22:04:00.624: INFO: (2) /api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:443/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:443/proxy/tlsrewritem... (200; 15.140675ms)
Dec 22 22:04:00.632: INFO: (3) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:160/proxy/: foo (200; 7.828959ms)
Dec 22 22:04:00.633: INFO: (3) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb/proxy/rewriteme">test</a> (200; 9.023475ms)
Dec 22 22:04:00.633: INFO: (3) /api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:160/proxy/: foo (200; 8.996245ms)
Dec 22 22:04:00.634: INFO: (3) /api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:1080/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:1080/proxy/rewriteme">... (200; 9.01561ms)
Dec 22 22:04:00.634: INFO: (3) /api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:462/proxy/: tls qux (200; 9.678033ms)
Dec 22 22:04:00.636: INFO: (3) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:1080/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:1080/proxy/rewriteme">test<... (200; 11.442504ms)
Dec 22 22:04:00.637: INFO: (3) /api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:460/proxy/: tls baz (200; 12.2434ms)
Dec 22 22:04:00.637: INFO: (3) /api/v1/namespaces/proxy-3627/services/https:proxy-service-jv7qp:tlsportname1/proxy/: tls baz (200; 12.630339ms)
Dec 22 22:04:00.637: INFO: (3) /api/v1/namespaces/proxy-3627/services/https:proxy-service-jv7qp:tlsportname2/proxy/: tls qux (200; 12.276281ms)
Dec 22 22:04:00.637: INFO: (3) /api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:162/proxy/: bar (200; 12.184236ms)
Dec 22 22:04:00.637: INFO: (3) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:162/proxy/: bar (200; 12.782552ms)
Dec 22 22:04:00.638: INFO: (3) /api/v1/namespaces/proxy-3627/services/proxy-service-jv7qp:portname1/proxy/: foo (200; 13.54223ms)
Dec 22 22:04:00.638: INFO: (3) /api/v1/namespaces/proxy-3627/services/http:proxy-service-jv7qp:portname2/proxy/: bar (200; 13.333512ms)
Dec 22 22:04:00.638: INFO: (3) /api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:443/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:443/proxy/tlsrewritem... (200; 13.605374ms)
Dec 22 22:04:00.638: INFO: (3) /api/v1/namespaces/proxy-3627/services/proxy-service-jv7qp:portname2/proxy/: bar (200; 13.752098ms)
Dec 22 22:04:00.638: INFO: (3) /api/v1/namespaces/proxy-3627/services/http:proxy-service-jv7qp:portname1/proxy/: foo (200; 13.834924ms)
Dec 22 22:04:00.648: INFO: (4) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:1080/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:1080/proxy/rewriteme">test<... (200; 8.896945ms)
Dec 22 22:04:00.650: INFO: (4) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:162/proxy/: bar (200; 10.556745ms)
Dec 22 22:04:00.652: INFO: (4) /api/v1/namespaces/proxy-3627/services/proxy-service-jv7qp:portname2/proxy/: bar (200; 13.251581ms)
Dec 22 22:04:00.653: INFO: (4) /api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:460/proxy/: tls baz (200; 13.674725ms)
Dec 22 22:04:00.657: INFO: (4) /api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:160/proxy/: foo (200; 17.536712ms)
Dec 22 22:04:00.657: INFO: (4) /api/v1/namespaces/proxy-3627/services/http:proxy-service-jv7qp:portname1/proxy/: foo (200; 17.868345ms)
Dec 22 22:04:00.657: INFO: (4) /api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:443/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:443/proxy/tlsrewritem... (200; 18.637858ms)
Dec 22 22:04:00.657: INFO: (4) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:160/proxy/: foo (200; 17.573401ms)
Dec 22 22:04:00.657: INFO: (4) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb/proxy/rewriteme">test</a> (200; 18.450201ms)
Dec 22 22:04:00.657: INFO: (4) /api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:1080/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:1080/proxy/rewriteme">... (200; 18.114828ms)
Dec 22 22:04:00.657: INFO: (4) /api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:462/proxy/: tls qux (200; 17.931651ms)
Dec 22 22:04:00.657: INFO: (4) /api/v1/namespaces/proxy-3627/services/https:proxy-service-jv7qp:tlsportname2/proxy/: tls qux (200; 18.032913ms)
Dec 22 22:04:00.658: INFO: (4) /api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:162/proxy/: bar (200; 18.635299ms)
Dec 22 22:04:00.658: INFO: (4) /api/v1/namespaces/proxy-3627/services/proxy-service-jv7qp:portname1/proxy/: foo (200; 19.147188ms)
Dec 22 22:04:00.658: INFO: (4) /api/v1/namespaces/proxy-3627/services/https:proxy-service-jv7qp:tlsportname1/proxy/: tls baz (200; 18.687796ms)
Dec 22 22:04:00.658: INFO: (4) /api/v1/namespaces/proxy-3627/services/http:proxy-service-jv7qp:portname2/proxy/: bar (200; 18.634245ms)
Dec 22 22:04:00.678: INFO: (5) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:162/proxy/: bar (200; 19.540501ms)
Dec 22 22:04:00.687: INFO: (5) /api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:460/proxy/: tls baz (200; 29.396827ms)
Dec 22 22:04:00.691: INFO: (5) /api/v1/namespaces/proxy-3627/services/https:proxy-service-jv7qp:tlsportname2/proxy/: tls qux (200; 33.177058ms)
Dec 22 22:04:00.695: INFO: (5) /api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:462/proxy/: tls qux (200; 37.158136ms)
Dec 22 22:04:00.696: INFO: (5) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb/proxy/rewriteme">test</a> (200; 37.222587ms)
Dec 22 22:04:00.696: INFO: (5) /api/v1/namespaces/proxy-3627/services/proxy-service-jv7qp:portname2/proxy/: bar (200; 37.909025ms)
Dec 22 22:04:00.696: INFO: (5) /api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:162/proxy/: bar (200; 38.10684ms)
Dec 22 22:04:00.696: INFO: (5) /api/v1/namespaces/proxy-3627/services/proxy-service-jv7qp:portname1/proxy/: foo (200; 38.119392ms)
Dec 22 22:04:00.698: INFO: (5) /api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:1080/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:1080/proxy/rewriteme">... (200; 39.894394ms)
Dec 22 22:04:00.698: INFO: (5) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:1080/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:1080/proxy/rewriteme">test<... (200; 39.823203ms)
Dec 22 22:04:00.698: INFO: (5) /api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:160/proxy/: foo (200; 39.955248ms)
Dec 22 22:04:00.698: INFO: (5) /api/v1/namespaces/proxy-3627/services/https:proxy-service-jv7qp:tlsportname1/proxy/: tls baz (200; 40.174669ms)
Dec 22 22:04:00.699: INFO: (5) /api/v1/namespaces/proxy-3627/services/http:proxy-service-jv7qp:portname2/proxy/: bar (200; 40.57052ms)
Dec 22 22:04:00.699: INFO: (5) /api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:443/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:443/proxy/tlsrewritem... (200; 40.175627ms)
Dec 22 22:04:00.699: INFO: (5) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:160/proxy/: foo (200; 40.503231ms)
Dec 22 22:04:00.700: INFO: (5) /api/v1/namespaces/proxy-3627/services/http:proxy-service-jv7qp:portname1/proxy/: foo (200; 41.813004ms)
Dec 22 22:04:00.709: INFO: (6) /api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:443/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:443/proxy/tlsrewritem... (200; 8.383219ms)
Dec 22 22:04:00.710: INFO: (6) /api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:162/proxy/: bar (200; 9.870396ms)
Dec 22 22:04:00.712: INFO: (6) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb/proxy/rewriteme">test</a> (200; 11.200388ms)
Dec 22 22:04:00.712: INFO: (6) /api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:462/proxy/: tls qux (200; 11.190164ms)
Dec 22 22:04:00.712: INFO: (6) /api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:460/proxy/: tls baz (200; 11.558259ms)
Dec 22 22:04:00.712: INFO: (6) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:1080/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:1080/proxy/rewriteme">test<... (200; 11.750744ms)
Dec 22 22:04:00.712: INFO: (6) /api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:160/proxy/: foo (200; 11.310701ms)
Dec 22 22:04:00.712: INFO: (6) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:162/proxy/: bar (200; 12.044613ms)
Dec 22 22:04:00.712: INFO: (6) /api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:1080/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:1080/proxy/rewriteme">... (200; 11.755352ms)
Dec 22 22:04:00.712: INFO: (6) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:160/proxy/: foo (200; 12.03541ms)
Dec 22 22:04:00.714: INFO: (6) /api/v1/namespaces/proxy-3627/services/http:proxy-service-jv7qp:portname1/proxy/: foo (200; 13.21822ms)
Dec 22 22:04:00.714: INFO: (6) /api/v1/namespaces/proxy-3627/services/https:proxy-service-jv7qp:tlsportname1/proxy/: tls baz (200; 13.27295ms)
Dec 22 22:04:00.714: INFO: (6) /api/v1/namespaces/proxy-3627/services/proxy-service-jv7qp:portname1/proxy/: foo (200; 13.444306ms)
Dec 22 22:04:00.714: INFO: (6) /api/v1/namespaces/proxy-3627/services/https:proxy-service-jv7qp:tlsportname2/proxy/: tls qux (200; 13.729046ms)
Dec 22 22:04:00.714: INFO: (6) /api/v1/namespaces/proxy-3627/services/proxy-service-jv7qp:portname2/proxy/: bar (200; 13.605266ms)
Dec 22 22:04:00.714: INFO: (6) /api/v1/namespaces/proxy-3627/services/http:proxy-service-jv7qp:portname2/proxy/: bar (200; 13.928245ms)
Dec 22 22:04:00.726: INFO: (7) /api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:1080/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:1080/proxy/rewriteme">... (200; 10.850248ms)
Dec 22 22:04:00.726: INFO: (7) /api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:160/proxy/: foo (200; 11.687811ms)
Dec 22 22:04:00.726: INFO: (7) /api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:162/proxy/: bar (200; 11.34847ms)
Dec 22 22:04:00.726: INFO: (7) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb/proxy/rewriteme">test</a> (200; 12.16539ms)
Dec 22 22:04:00.726: INFO: (7) /api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:443/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:443/proxy/tlsrewritem... (200; 12.188785ms)
Dec 22 22:04:00.726: INFO: (7) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:162/proxy/: bar (200; 11.944939ms)
Dec 22 22:04:00.729: INFO: (7) /api/v1/namespaces/proxy-3627/services/proxy-service-jv7qp:portname2/proxy/: bar (200; 13.92579ms)
Dec 22 22:04:00.729: INFO: (7) /api/v1/namespaces/proxy-3627/services/http:proxy-service-jv7qp:portname1/proxy/: foo (200; 13.980939ms)
Dec 22 22:04:00.729: INFO: (7) /api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:462/proxy/: tls qux (200; 13.577065ms)
Dec 22 22:04:00.729: INFO: (7) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:1080/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:1080/proxy/rewriteme">test<... (200; 13.632819ms)
Dec 22 22:04:00.729: INFO: (7) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:160/proxy/: foo (200; 14.185219ms)
Dec 22 22:04:00.729: INFO: (7) /api/v1/namespaces/proxy-3627/services/https:proxy-service-jv7qp:tlsportname2/proxy/: tls qux (200; 14.108381ms)
Dec 22 22:04:00.729: INFO: (7) /api/v1/namespaces/proxy-3627/services/http:proxy-service-jv7qp:portname2/proxy/: bar (200; 14.223797ms)
Dec 22 22:04:00.729: INFO: (7) /api/v1/namespaces/proxy-3627/services/https:proxy-service-jv7qp:tlsportname1/proxy/: tls baz (200; 14.802836ms)
Dec 22 22:04:00.729: INFO: (7) /api/v1/namespaces/proxy-3627/services/proxy-service-jv7qp:portname1/proxy/: foo (200; 14.216442ms)
Dec 22 22:04:00.729: INFO: (7) /api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:460/proxy/: tls baz (200; 14.680302ms)
Dec 22 22:04:00.735: INFO: (8) /api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:160/proxy/: foo (200; 5.230009ms)
Dec 22 22:04:00.736: INFO: (8) /api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:162/proxy/: bar (200; 6.88353ms)
Dec 22 22:04:00.736: INFO: (8) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:162/proxy/: bar (200; 6.693867ms)
Dec 22 22:04:00.740: INFO: (8) /api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:443/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:443/proxy/tlsrewritem... (200; 10.289343ms)
Dec 22 22:04:00.741: INFO: (8) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:160/proxy/: foo (200; 11.049437ms)
Dec 22 22:04:00.741: INFO: (8) /api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:462/proxy/: tls qux (200; 10.883028ms)
Dec 22 22:04:00.741: INFO: (8) /api/v1/namespaces/proxy-3627/services/https:proxy-service-jv7qp:tlsportname2/proxy/: tls qux (200; 12.074257ms)
Dec 22 22:04:00.742: INFO: (8) /api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:460/proxy/: tls baz (200; 12.003029ms)
Dec 22 22:04:00.742: INFO: (8) /api/v1/namespaces/proxy-3627/services/http:proxy-service-jv7qp:portname1/proxy/: foo (200; 12.343312ms)
Dec 22 22:04:00.743: INFO: (8) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:1080/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:1080/proxy/rewriteme">test<... (200; 12.697856ms)
Dec 22 22:04:00.743: INFO: (8) /api/v1/namespaces/proxy-3627/services/http:proxy-service-jv7qp:portname2/proxy/: bar (200; 12.925067ms)
Dec 22 22:04:00.744: INFO: (8) /api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:1080/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:1080/proxy/rewriteme">... (200; 14.3153ms)
Dec 22 22:04:00.746: INFO: (8) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb/proxy/rewriteme">test</a> (200; 15.947011ms)
Dec 22 22:04:00.746: INFO: (8) /api/v1/namespaces/proxy-3627/services/https:proxy-service-jv7qp:tlsportname1/proxy/: tls baz (200; 16.863245ms)
Dec 22 22:04:00.748: INFO: (8) /api/v1/namespaces/proxy-3627/services/proxy-service-jv7qp:portname1/proxy/: foo (200; 17.85351ms)
Dec 22 22:04:00.749: INFO: (8) /api/v1/namespaces/proxy-3627/services/proxy-service-jv7qp:portname2/proxy/: bar (200; 19.045204ms)
Dec 22 22:04:00.757: INFO: (9) /api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:460/proxy/: tls baz (200; 7.930904ms)
Dec 22 22:04:00.758: INFO: (9) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb/proxy/rewriteme">test</a> (200; 8.953859ms)
Dec 22 22:04:00.759: INFO: (9) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:1080/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:1080/proxy/rewriteme">test<... (200; 9.987782ms)
Dec 22 22:04:00.759: INFO: (9) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:160/proxy/: foo (200; 10.153191ms)
Dec 22 22:04:00.760: INFO: (9) /api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:462/proxy/: tls qux (200; 10.94724ms)
Dec 22 22:04:00.762: INFO: (9) /api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:162/proxy/: bar (200; 13.288318ms)
Dec 22 22:04:00.763: INFO: (9) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:162/proxy/: bar (200; 13.281642ms)
Dec 22 22:04:00.763: INFO: (9) /api/v1/namespaces/proxy-3627/services/http:proxy-service-jv7qp:portname1/proxy/: foo (200; 13.355205ms)
Dec 22 22:04:00.763: INFO: (9) /api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:1080/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:1080/proxy/rewriteme">... (200; 13.593589ms)
Dec 22 22:04:00.763: INFO: (9) /api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:160/proxy/: foo (200; 13.386291ms)
Dec 22 22:04:00.763: INFO: (9) /api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:443/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:443/proxy/tlsrewritem... (200; 14.025698ms)
Dec 22 22:04:00.763: INFO: (9) /api/v1/namespaces/proxy-3627/services/proxy-service-jv7qp:portname1/proxy/: foo (200; 14.049968ms)
Dec 22 22:04:00.763: INFO: (9) /api/v1/namespaces/proxy-3627/services/https:proxy-service-jv7qp:tlsportname1/proxy/: tls baz (200; 13.689643ms)
Dec 22 22:04:00.763: INFO: (9) /api/v1/namespaces/proxy-3627/services/https:proxy-service-jv7qp:tlsportname2/proxy/: tls qux (200; 14.602201ms)
Dec 22 22:04:00.764: INFO: (9) /api/v1/namespaces/proxy-3627/services/proxy-service-jv7qp:portname2/proxy/: bar (200; 14.151453ms)
Dec 22 22:04:00.764: INFO: (9) /api/v1/namespaces/proxy-3627/services/http:proxy-service-jv7qp:portname2/proxy/: bar (200; 14.776564ms)
Dec 22 22:04:00.768: INFO: (10) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:162/proxy/: bar (200; 4.409621ms)
Dec 22 22:04:00.770: INFO: (10) /api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:460/proxy/: tls baz (200; 6.034151ms)
Dec 22 22:04:00.773: INFO: (10) /api/v1/namespaces/proxy-3627/services/http:proxy-service-jv7qp:portname2/proxy/: bar (200; 8.758874ms)
Dec 22 22:04:00.773: INFO: (10) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:160/proxy/: foo (200; 8.842975ms)
Dec 22 22:04:00.773: INFO: (10) /api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:443/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:443/proxy/tlsrewritem... (200; 8.863034ms)
Dec 22 22:04:00.774: INFO: (10) /api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:462/proxy/: tls qux (200; 9.585785ms)
Dec 22 22:04:00.774: INFO: (10) /api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:162/proxy/: bar (200; 9.701129ms)
Dec 22 22:04:00.777: INFO: (10) /api/v1/namespaces/proxy-3627/services/https:proxy-service-jv7qp:tlsportname2/proxy/: tls qux (200; 12.567447ms)
Dec 22 22:04:00.777: INFO: (10) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb/proxy/rewriteme">test</a> (200; 12.355942ms)
Dec 22 22:04:00.777: INFO: (10) /api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:1080/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:1080/proxy/rewriteme">... (200; 12.312173ms)
Dec 22 22:04:00.777: INFO: (10) /api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:160/proxy/: foo (200; 12.134447ms)
Dec 22 22:04:00.777: INFO: (10) /api/v1/namespaces/proxy-3627/services/proxy-service-jv7qp:portname1/proxy/: foo (200; 12.368975ms)
Dec 22 22:04:00.777: INFO: (10) /api/v1/namespaces/proxy-3627/services/proxy-service-jv7qp:portname2/proxy/: bar (200; 12.964557ms)
Dec 22 22:04:00.778: INFO: (10) /api/v1/namespaces/proxy-3627/services/http:proxy-service-jv7qp:portname1/proxy/: foo (200; 13.29767ms)
Dec 22 22:04:00.778: INFO: (10) /api/v1/namespaces/proxy-3627/services/https:proxy-service-jv7qp:tlsportname1/proxy/: tls baz (200; 13.394196ms)
Dec 22 22:04:00.778: INFO: (10) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:1080/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:1080/proxy/rewriteme">test<... (200; 13.806091ms)
Dec 22 22:04:00.791: INFO: (11) /api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:160/proxy/: foo (200; 12.626714ms)
Dec 22 22:04:00.792: INFO: (11) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:162/proxy/: bar (200; 13.286382ms)
Dec 22 22:04:00.793: INFO: (11) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb/proxy/rewriteme">test</a> (200; 14.71088ms)
Dec 22 22:04:00.793: INFO: (11) /api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:1080/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:1080/proxy/rewriteme">... (200; 14.397794ms)
Dec 22 22:04:00.793: INFO: (11) /api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:162/proxy/: bar (200; 14.576633ms)
Dec 22 22:04:00.794: INFO: (11) /api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:443/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:443/proxy/tlsrewritem... (200; 15.693898ms)
Dec 22 22:04:00.794: INFO: (11) /api/v1/namespaces/proxy-3627/services/https:proxy-service-jv7qp:tlsportname2/proxy/: tls qux (200; 15.711932ms)
Dec 22 22:04:00.795: INFO: (11) /api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:460/proxy/: tls baz (200; 17.153238ms)
Dec 22 22:04:00.795: INFO: (11) /api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:462/proxy/: tls qux (200; 17.137563ms)
Dec 22 22:04:00.796: INFO: (11) /api/v1/namespaces/proxy-3627/services/http:proxy-service-jv7qp:portname1/proxy/: foo (200; 17.296665ms)
Dec 22 22:04:00.796: INFO: (11) /api/v1/namespaces/proxy-3627/services/proxy-service-jv7qp:portname1/proxy/: foo (200; 17.780491ms)
Dec 22 22:04:00.796: INFO: (11) /api/v1/namespaces/proxy-3627/services/http:proxy-service-jv7qp:portname2/proxy/: bar (200; 17.474379ms)
Dec 22 22:04:00.797: INFO: (11) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:1080/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:1080/proxy/rewriteme">test<... (200; 17.72782ms)
Dec 22 22:04:00.797: INFO: (11) /api/v1/namespaces/proxy-3627/services/https:proxy-service-jv7qp:tlsportname1/proxy/: tls baz (200; 18.155187ms)
Dec 22 22:04:00.797: INFO: (11) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:160/proxy/: foo (200; 18.134413ms)
Dec 22 22:04:00.797: INFO: (11) /api/v1/namespaces/proxy-3627/services/proxy-service-jv7qp:portname2/proxy/: bar (200; 18.179582ms)
Dec 22 22:04:00.801: INFO: (12) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:1080/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:1080/proxy/rewriteme">test<... (200; 3.871301ms)
Dec 22 22:04:00.807: INFO: (12) /api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:460/proxy/: tls baz (200; 9.859007ms)
Dec 22 22:04:00.807: INFO: (12) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:160/proxy/: foo (200; 9.717395ms)
Dec 22 22:04:00.808: INFO: (12) /api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:443/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:443/proxy/tlsrewritem... (200; 10.544118ms)
Dec 22 22:04:00.809: INFO: (12) /api/v1/namespaces/proxy-3627/services/http:proxy-service-jv7qp:portname2/proxy/: bar (200; 11.800163ms)
Dec 22 22:04:00.809: INFO: (12) /api/v1/namespaces/proxy-3627/services/https:proxy-service-jv7qp:tlsportname1/proxy/: tls baz (200; 11.655412ms)
Dec 22 22:04:00.811: INFO: (12) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb/proxy/rewriteme">test</a> (200; 14.025015ms)
Dec 22 22:04:00.812: INFO: (12) /api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:162/proxy/: bar (200; 14.347174ms)
Dec 22 22:04:00.812: INFO: (12) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:162/proxy/: bar (200; 15.448695ms)
Dec 22 22:04:00.812: INFO: (12) /api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:1080/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:1080/proxy/rewriteme">... (200; 14.836829ms)
Dec 22 22:04:00.812: INFO: (12) /api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:462/proxy/: tls qux (200; 14.78105ms)
Dec 22 22:04:00.813: INFO: (12) /api/v1/namespaces/proxy-3627/services/https:proxy-service-jv7qp:tlsportname2/proxy/: tls qux (200; 15.607689ms)
Dec 22 22:04:00.813: INFO: (12) /api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:160/proxy/: foo (200; 15.051081ms)
Dec 22 22:04:00.813: INFO: (12) /api/v1/namespaces/proxy-3627/services/proxy-service-jv7qp:portname2/proxy/: bar (200; 15.124212ms)
Dec 22 22:04:00.814: INFO: (12) /api/v1/namespaces/proxy-3627/services/proxy-service-jv7qp:portname1/proxy/: foo (200; 16.1592ms)
Dec 22 22:04:00.814: INFO: (12) /api/v1/namespaces/proxy-3627/services/http:proxy-service-jv7qp:portname1/proxy/: foo (200; 16.260903ms)
Dec 22 22:04:00.825: INFO: (13) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:160/proxy/: foo (200; 10.435219ms)
Dec 22 22:04:00.826: INFO: (13) /api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:443/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:443/proxy/tlsrewritem... (200; 11.698108ms)
Dec 22 22:04:00.826: INFO: (13) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:1080/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:1080/proxy/rewriteme">test<... (200; 11.726358ms)
Dec 22 22:04:00.827: INFO: (13) /api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:460/proxy/: tls baz (200; 12.970415ms)
Dec 22 22:04:00.827: INFO: (13) /api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:160/proxy/: foo (200; 12.716856ms)
Dec 22 22:04:00.828: INFO: (13) /api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:1080/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:1080/proxy/rewriteme">... (200; 13.296622ms)
Dec 22 22:04:00.828: INFO: (13) /api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:162/proxy/: bar (200; 13.270485ms)
Dec 22 22:04:00.828: INFO: (13) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:162/proxy/: bar (200; 13.122955ms)
Dec 22 22:04:00.828: INFO: (13) /api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:462/proxy/: tls qux (200; 13.21233ms)
Dec 22 22:04:00.828: INFO: (13) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb/proxy/rewriteme">test</a> (200; 13.025063ms)
Dec 22 22:04:00.828: INFO: (13) /api/v1/namespaces/proxy-3627/services/proxy-service-jv7qp:portname1/proxy/: foo (200; 13.109642ms)
Dec 22 22:04:00.828: INFO: (13) /api/v1/namespaces/proxy-3627/services/https:proxy-service-jv7qp:tlsportname2/proxy/: tls qux (200; 14.29319ms)
Dec 22 22:04:00.828: INFO: (13) /api/v1/namespaces/proxy-3627/services/http:proxy-service-jv7qp:portname1/proxy/: foo (200; 13.495965ms)
Dec 22 22:04:00.828: INFO: (13) /api/v1/namespaces/proxy-3627/services/http:proxy-service-jv7qp:portname2/proxy/: bar (200; 13.848702ms)
Dec 22 22:04:00.828: INFO: (13) /api/v1/namespaces/proxy-3627/services/proxy-service-jv7qp:portname2/proxy/: bar (200; 13.601088ms)
Dec 22 22:04:00.828: INFO: (13) /api/v1/namespaces/proxy-3627/services/https:proxy-service-jv7qp:tlsportname1/proxy/: tls baz (200; 13.550136ms)
Dec 22 22:04:00.837: INFO: (14) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:162/proxy/: bar (200; 8.283515ms)
Dec 22 22:04:00.837: INFO: (14) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:1080/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:1080/proxy/rewriteme">test<... (200; 8.439862ms)
Dec 22 22:04:00.838: INFO: (14) /api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:460/proxy/: tls baz (200; 9.140226ms)
Dec 22 22:04:00.839: INFO: (14) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb/proxy/rewriteme">test</a> (200; 9.581415ms)
Dec 22 22:04:00.839: INFO: (14) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:160/proxy/: foo (200; 10.176683ms)
Dec 22 22:04:00.840: INFO: (14) /api/v1/namespaces/proxy-3627/services/https:proxy-service-jv7qp:tlsportname1/proxy/: tls baz (200; 10.964797ms)
Dec 22 22:04:00.840: INFO: (14) /api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:1080/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:1080/proxy/rewriteme">... (200; 11.154735ms)
Dec 22 22:04:00.840: INFO: (14) /api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:462/proxy/: tls qux (200; 11.402287ms)
Dec 22 22:04:00.841: INFO: (14) /api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:162/proxy/: bar (200; 11.988134ms)
Dec 22 22:04:00.841: INFO: (14) /api/v1/namespaces/proxy-3627/services/http:proxy-service-jv7qp:portname2/proxy/: bar (200; 12.376362ms)
Dec 22 22:04:00.841: INFO: (14) /api/v1/namespaces/proxy-3627/services/proxy-service-jv7qp:portname2/proxy/: bar (200; 12.404093ms)
Dec 22 22:04:00.841: INFO: (14) /api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:160/proxy/: foo (200; 12.513401ms)
Dec 22 22:04:00.841: INFO: (14) /api/v1/namespaces/proxy-3627/services/http:proxy-service-jv7qp:portname1/proxy/: foo (200; 12.632002ms)
Dec 22 22:04:00.841: INFO: (14) /api/v1/namespaces/proxy-3627/services/proxy-service-jv7qp:portname1/proxy/: foo (200; 12.56555ms)
Dec 22 22:04:00.842: INFO: (14) /api/v1/namespaces/proxy-3627/services/https:proxy-service-jv7qp:tlsportname2/proxy/: tls qux (200; 12.786553ms)
Dec 22 22:04:00.842: INFO: (14) /api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:443/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:443/proxy/tlsrewritem... (200; 12.615949ms)
Dec 22 22:04:00.850: INFO: (15) /api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:462/proxy/: tls qux (200; 8.488883ms)
Dec 22 22:04:00.852: INFO: (15) /api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:160/proxy/: foo (200; 9.648172ms)
Dec 22 22:04:00.854: INFO: (15) /api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:460/proxy/: tls baz (200; 12.325472ms)
Dec 22 22:04:00.854: INFO: (15) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:162/proxy/: bar (200; 12.334075ms)
Dec 22 22:04:00.855: INFO: (15) /api/v1/namespaces/proxy-3627/services/http:proxy-service-jv7qp:portname1/proxy/: foo (200; 13.029479ms)
Dec 22 22:04:00.855: INFO: (15) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:1080/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:1080/proxy/rewriteme">test<... (200; 12.504051ms)
Dec 22 22:04:00.855: INFO: (15) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb/proxy/rewriteme">test</a> (200; 12.636689ms)
Dec 22 22:04:00.856: INFO: (15) /api/v1/namespaces/proxy-3627/services/proxy-service-jv7qp:portname1/proxy/: foo (200; 13.204721ms)
Dec 22 22:04:00.856: INFO: (15) /api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:162/proxy/: bar (200; 13.062863ms)
Dec 22 22:04:00.856: INFO: (15) /api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:1080/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:1080/proxy/rewriteme">... (200; 13.196684ms)
Dec 22 22:04:00.856: INFO: (15) /api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:443/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:443/proxy/tlsrewritem... (200; 13.467807ms)
Dec 22 22:04:00.856: INFO: (15) /api/v1/namespaces/proxy-3627/services/https:proxy-service-jv7qp:tlsportname1/proxy/: tls baz (200; 14.363929ms)
Dec 22 22:04:00.856: INFO: (15) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:160/proxy/: foo (200; 14.116261ms)
Dec 22 22:04:00.857: INFO: (15) /api/v1/namespaces/proxy-3627/services/http:proxy-service-jv7qp:portname2/proxy/: bar (200; 14.50243ms)
Dec 22 22:04:00.857: INFO: (15) /api/v1/namespaces/proxy-3627/services/proxy-service-jv7qp:portname2/proxy/: bar (200; 15.322496ms)
Dec 22 22:04:00.858: INFO: (15) /api/v1/namespaces/proxy-3627/services/https:proxy-service-jv7qp:tlsportname2/proxy/: tls qux (200; 15.794593ms)
Dec 22 22:04:00.862: INFO: (16) /api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:460/proxy/: tls baz (200; 4.031239ms)
Dec 22 22:04:00.866: INFO: (16) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:162/proxy/: bar (200; 6.833812ms)
Dec 22 22:04:00.866: INFO: (16) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:160/proxy/: foo (200; 7.953649ms)
Dec 22 22:04:00.866: INFO: (16) /api/v1/namespaces/proxy-3627/services/http:proxy-service-jv7qp:portname2/proxy/: bar (200; 8.18497ms)
Dec 22 22:04:00.871: INFO: (16) /api/v1/namespaces/proxy-3627/services/https:proxy-service-jv7qp:tlsportname1/proxy/: tls baz (200; 11.403725ms)
Dec 22 22:04:00.871: INFO: (16) /api/v1/namespaces/proxy-3627/services/proxy-service-jv7qp:portname2/proxy/: bar (200; 11.431476ms)
Dec 22 22:04:00.871: INFO: (16) /api/v1/namespaces/proxy-3627/services/proxy-service-jv7qp:portname1/proxy/: foo (200; 11.945958ms)
Dec 22 22:04:00.871: INFO: (16) /api/v1/namespaces/proxy-3627/services/https:proxy-service-jv7qp:tlsportname2/proxy/: tls qux (200; 12.623029ms)
Dec 22 22:04:00.871: INFO: (16) /api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:1080/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:1080/proxy/rewriteme">... (200; 12.222909ms)
Dec 22 22:04:00.872: INFO: (16) /api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:162/proxy/: bar (200; 12.757421ms)
Dec 22 22:04:00.872: INFO: (16) /api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:160/proxy/: foo (200; 12.103292ms)
Dec 22 22:04:00.872: INFO: (16) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb/proxy/rewriteme">test</a> (200; 13.062901ms)
Dec 22 22:04:00.872: INFO: (16) /api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:443/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:443/proxy/tlsrewritem... (200; 13.507772ms)
Dec 22 22:04:00.872: INFO: (16) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:1080/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:1080/proxy/rewriteme">test<... (200; 13.137513ms)
Dec 22 22:04:00.872: INFO: (16) /api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:462/proxy/: tls qux (200; 13.613273ms)
Dec 22 22:04:00.872: INFO: (16) /api/v1/namespaces/proxy-3627/services/http:proxy-service-jv7qp:portname1/proxy/: foo (200; 13.270064ms)
Dec 22 22:04:00.884: INFO: (17) /api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:443/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:443/proxy/tlsrewritem... (200; 10.778693ms)
Dec 22 22:04:00.884: INFO: (17) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb/proxy/rewriteme">test</a> (200; 10.802263ms)
Dec 22 22:04:00.884: INFO: (17) /api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:462/proxy/: tls qux (200; 10.765085ms)
Dec 22 22:04:00.884: INFO: (17) /api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:1080/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:1080/proxy/rewriteme">... (200; 11.499779ms)
Dec 22 22:04:00.884: INFO: (17) /api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:460/proxy/: tls baz (200; 11.78726ms)
Dec 22 22:04:00.884: INFO: (17) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:162/proxy/: bar (200; 10.736663ms)
Dec 22 22:04:00.884: INFO: (17) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:160/proxy/: foo (200; 11.406395ms)
Dec 22 22:04:00.885: INFO: (17) /api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:160/proxy/: foo (200; 11.116698ms)
Dec 22 22:04:00.885: INFO: (17) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:1080/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:1080/proxy/rewriteme">test<... (200; 11.824455ms)
Dec 22 22:04:00.885: INFO: (17) /api/v1/namespaces/proxy-3627/services/http:proxy-service-jv7qp:portname1/proxy/: foo (200; 11.743527ms)
Dec 22 22:04:00.885: INFO: (17) /api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:162/proxy/: bar (200; 11.995198ms)
Dec 22 22:04:00.885: INFO: (17) /api/v1/namespaces/proxy-3627/services/proxy-service-jv7qp:portname2/proxy/: bar (200; 12.189641ms)
Dec 22 22:04:00.889: INFO: (17) /api/v1/namespaces/proxy-3627/services/https:proxy-service-jv7qp:tlsportname1/proxy/: tls baz (200; 15.154824ms)
Dec 22 22:04:00.889: INFO: (17) /api/v1/namespaces/proxy-3627/services/https:proxy-service-jv7qp:tlsportname2/proxy/: tls qux (200; 16.345018ms)
Dec 22 22:04:00.889: INFO: (17) /api/v1/namespaces/proxy-3627/services/http:proxy-service-jv7qp:portname2/proxy/: bar (200; 16.408177ms)
Dec 22 22:04:00.890: INFO: (17) /api/v1/namespaces/proxy-3627/services/proxy-service-jv7qp:portname1/proxy/: foo (200; 16.510448ms)
Dec 22 22:04:00.900: INFO: (18) /api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:162/proxy/: bar (200; 10.530742ms)
Dec 22 22:04:00.904: INFO: (18) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:162/proxy/: bar (200; 13.960006ms)
Dec 22 22:04:00.904: INFO: (18) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:160/proxy/: foo (200; 14.271124ms)
Dec 22 22:04:00.905: INFO: (18) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb/proxy/rewriteme">test</a> (200; 14.33414ms)
Dec 22 22:04:00.905: INFO: (18) /api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:462/proxy/: tls qux (200; 15.114491ms)
Dec 22 22:04:00.905: INFO: (18) /api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:460/proxy/: tls baz (200; 15.46202ms)
Dec 22 22:04:00.905: INFO: (18) /api/v1/namespaces/proxy-3627/services/proxy-service-jv7qp:portname2/proxy/: bar (200; 15.102738ms)
Dec 22 22:04:00.905: INFO: (18) /api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:160/proxy/: foo (200; 15.049231ms)
Dec 22 22:04:00.905: INFO: (18) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:1080/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:1080/proxy/rewriteme">test<... (200; 14.944416ms)
Dec 22 22:04:00.905: INFO: (18) /api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:1080/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:1080/proxy/rewriteme">... (200; 15.568244ms)
Dec 22 22:04:00.905: INFO: (18) /api/v1/namespaces/proxy-3627/services/https:proxy-service-jv7qp:tlsportname1/proxy/: tls baz (200; 15.23056ms)
Dec 22 22:04:00.906: INFO: (18) /api/v1/namespaces/proxy-3627/services/proxy-service-jv7qp:portname1/proxy/: foo (200; 15.664312ms)
Dec 22 22:04:00.906: INFO: (18) /api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:443/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:443/proxy/tlsrewritem... (200; 15.687468ms)
Dec 22 22:04:00.906: INFO: (18) /api/v1/namespaces/proxy-3627/services/https:proxy-service-jv7qp:tlsportname2/proxy/: tls qux (200; 16.264082ms)
Dec 22 22:04:00.906: INFO: (18) /api/v1/namespaces/proxy-3627/services/http:proxy-service-jv7qp:portname1/proxy/: foo (200; 16.164298ms)
Dec 22 22:04:00.906: INFO: (18) /api/v1/namespaces/proxy-3627/services/http:proxy-service-jv7qp:portname2/proxy/: bar (200; 16.385257ms)
Dec 22 22:04:00.917: INFO: (19) /api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:1080/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:1080/proxy/rewriteme">... (200; 10.431705ms)
Dec 22 22:04:00.917: INFO: (19) /api/v1/namespaces/proxy-3627/services/http:proxy-service-jv7qp:portname2/proxy/: bar (200; 10.926594ms)
Dec 22 22:04:00.918: INFO: (19) /api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:162/proxy/: bar (200; 11.700854ms)
Dec 22 22:04:00.918: INFO: (19) /api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:443/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:443/proxy/tlsrewritem... (200; 12.05257ms)
Dec 22 22:04:00.919: INFO: (19) /api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:460/proxy/: tls baz (200; 11.922772ms)
Dec 22 22:04:00.923: INFO: (19) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb/proxy/rewriteme">test</a> (200; 16.540413ms)
Dec 22 22:04:00.923: INFO: (19) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:1080/proxy/: <a href="/api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:1080/proxy/rewriteme">test<... (200; 16.965355ms)
Dec 22 22:04:00.923: INFO: (19) /api/v1/namespaces/proxy-3627/pods/http:proxy-service-jv7qp-2rxsb:160/proxy/: foo (200; 16.800853ms)
Dec 22 22:04:00.924: INFO: (19) /api/v1/namespaces/proxy-3627/services/https:proxy-service-jv7qp:tlsportname2/proxy/: tls qux (200; 17.327972ms)
Dec 22 22:04:00.924: INFO: (19) /api/v1/namespaces/proxy-3627/pods/https:proxy-service-jv7qp-2rxsb:462/proxy/: tls qux (200; 17.262926ms)
Dec 22 22:04:00.924: INFO: (19) /api/v1/namespaces/proxy-3627/services/http:proxy-service-jv7qp:portname1/proxy/: foo (200; 17.456361ms)
Dec 22 22:04:00.924: INFO: (19) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:162/proxy/: bar (200; 17.806144ms)
Dec 22 22:04:00.924: INFO: (19) /api/v1/namespaces/proxy-3627/services/proxy-service-jv7qp:portname2/proxy/: bar (200; 17.446263ms)
Dec 22 22:04:00.924: INFO: (19) /api/v1/namespaces/proxy-3627/services/https:proxy-service-jv7qp:tlsportname1/proxy/: tls baz (200; 17.49067ms)
Dec 22 22:04:00.925: INFO: (19) /api/v1/namespaces/proxy-3627/services/proxy-service-jv7qp:portname1/proxy/: foo (200; 18.0953ms)
Dec 22 22:04:00.925: INFO: (19) /api/v1/namespaces/proxy-3627/pods/proxy-service-jv7qp-2rxsb:160/proxy/: foo (200; 18.490749ms)
STEP: deleting ReplicationController proxy-service-jv7qp in namespace proxy-3627, will wait for the garbage collector to delete the pods
Dec 22 22:04:00.984: INFO: Deleting ReplicationController proxy-service-jv7qp took: 5.894166ms
Dec 22 22:04:01.384: INFO: Terminating ReplicationController proxy-service-jv7qp pods took: 400.184603ms
[AfterEach] version v1
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:04:12.284: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-3627" for this suite.
Dec 22 22:04:18.296: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:04:18.422: INFO: namespace proxy-3627 deletion completed in 6.13417903s

â€¢ [SLOW TEST:29.989 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:04:18.423: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting the proxy server
Dec 22 22:04:18.514: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-800494845 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:04:18.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2868" for this suite.
Dec 22 22:04:24.595: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:04:24.657: INFO: namespace kubectl-2868 deletion completed in 6.068561646s

â€¢ [SLOW TEST:6.234 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:04:24.659: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-projected-w6gh
STEP: Creating a pod to test atomic-volume-subpath
Dec 22 22:04:24.685: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-w6gh" in namespace "subpath-1934" to be "success or failure"
Dec 22 22:04:24.688: INFO: Pod "pod-subpath-test-projected-w6gh": Phase="Pending", Reason="", readiness=false. Elapsed: 2.735409ms
Dec 22 22:04:26.691: INFO: Pod "pod-subpath-test-projected-w6gh": Phase="Running", Reason="", readiness=true. Elapsed: 2.005455386s
Dec 22 22:04:28.694: INFO: Pod "pod-subpath-test-projected-w6gh": Phase="Running", Reason="", readiness=true. Elapsed: 4.008208338s
Dec 22 22:04:30.697: INFO: Pod "pod-subpath-test-projected-w6gh": Phase="Running", Reason="", readiness=true. Elapsed: 6.011179746s
Dec 22 22:04:32.699: INFO: Pod "pod-subpath-test-projected-w6gh": Phase="Running", Reason="", readiness=true. Elapsed: 8.01377443s
Dec 22 22:04:34.702: INFO: Pod "pod-subpath-test-projected-w6gh": Phase="Running", Reason="", readiness=true. Elapsed: 10.016528772s
Dec 22 22:04:36.705: INFO: Pod "pod-subpath-test-projected-w6gh": Phase="Running", Reason="", readiness=true. Elapsed: 12.019359924s
Dec 22 22:04:38.708: INFO: Pod "pod-subpath-test-projected-w6gh": Phase="Running", Reason="", readiness=true. Elapsed: 14.022500519s
Dec 22 22:04:40.714: INFO: Pod "pod-subpath-test-projected-w6gh": Phase="Running", Reason="", readiness=true. Elapsed: 16.02813012s
Dec 22 22:04:42.717: INFO: Pod "pod-subpath-test-projected-w6gh": Phase="Running", Reason="", readiness=true. Elapsed: 18.031322668s
Dec 22 22:04:44.720: INFO: Pod "pod-subpath-test-projected-w6gh": Phase="Running", Reason="", readiness=true. Elapsed: 20.034302239s
Dec 22 22:04:46.722: INFO: Pod "pod-subpath-test-projected-w6gh": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.036659799s
STEP: Saw pod success
Dec 22 22:04:46.722: INFO: Pod "pod-subpath-test-projected-w6gh" satisfied condition "success or failure"
Dec 22 22:04:46.724: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod pod-subpath-test-projected-w6gh container test-container-subpath-projected-w6gh: <nil>
STEP: delete the pod
Dec 22 22:04:46.743: INFO: Waiting for pod pod-subpath-test-projected-w6gh to disappear
Dec 22 22:04:46.745: INFO: Pod pod-subpath-test-projected-w6gh no longer exists
STEP: Deleting pod pod-subpath-test-projected-w6gh
Dec 22 22:04:46.745: INFO: Deleting pod "pod-subpath-test-projected-w6gh" in namespace "subpath-1934"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:04:46.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1934" for this suite.
Dec 22 22:04:52.757: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:04:52.954: INFO: namespace subpath-1934 deletion completed in 6.204252471s

â€¢ [SLOW TEST:28.295 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:04:52.954: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:04:55.021: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1172" for this suite.
Dec 22 22:05:45.032: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:05:45.203: INFO: namespace kubelet-test-1172 deletion completed in 50.178498449s

â€¢ [SLOW TEST:52.249 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command in a pod
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:05:45.203: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec 22 22:05:45.238: INFO: Create a RollingUpdate DaemonSet
Dec 22 22:05:45.241: INFO: Check that daemon pods launch on every node of the cluster
Dec 22 22:05:45.246: INFO: DaemonSet pods can't tolerate node ip-10-0-1-168.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 22 22:05:45.248: INFO: Number of nodes with available pods: 0
Dec 22 22:05:45.248: INFO: Node ip-10-0-1-121.us-west-2.compute.internal is running more than one daemon pod
Dec 22 22:05:46.257: INFO: DaemonSet pods can't tolerate node ip-10-0-1-168.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 22 22:05:46.262: INFO: Number of nodes with available pods: 0
Dec 22 22:05:46.262: INFO: Node ip-10-0-1-121.us-west-2.compute.internal is running more than one daemon pod
Dec 22 22:05:47.253: INFO: DaemonSet pods can't tolerate node ip-10-0-1-168.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 22 22:05:47.256: INFO: Number of nodes with available pods: 1
Dec 22 22:05:47.256: INFO: Node ip-10-0-1-121.us-west-2.compute.internal is running more than one daemon pod
Dec 22 22:05:48.252: INFO: DaemonSet pods can't tolerate node ip-10-0-1-168.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 22 22:05:48.258: INFO: Number of nodes with available pods: 2
Dec 22 22:05:48.258: INFO: Number of running nodes: 2, number of available pods: 2
Dec 22 22:05:48.258: INFO: Update the DaemonSet to trigger a rollout
Dec 22 22:05:48.263: INFO: Updating DaemonSet daemon-set
Dec 22 22:06:03.280: INFO: Roll back the DaemonSet before rollout is complete
Dec 22 22:06:03.286: INFO: Updating DaemonSet daemon-set
Dec 22 22:06:03.286: INFO: Make sure DaemonSet rollback is complete
Dec 22 22:06:03.290: INFO: Wrong image for pod: daemon-set-nrlmm. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Dec 22 22:06:03.290: INFO: Pod daemon-set-nrlmm is not available
Dec 22 22:06:03.295: INFO: DaemonSet pods can't tolerate node ip-10-0-1-168.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 22 22:06:04.323: INFO: Wrong image for pod: daemon-set-nrlmm. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Dec 22 22:06:04.323: INFO: Pod daemon-set-nrlmm is not available
Dec 22 22:06:04.329: INFO: DaemonSet pods can't tolerate node ip-10-0-1-168.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 22 22:06:05.302: INFO: Wrong image for pod: daemon-set-nrlmm. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Dec 22 22:06:05.302: INFO: Pod daemon-set-nrlmm is not available
Dec 22 22:06:05.316: INFO: DaemonSet pods can't tolerate node ip-10-0-1-168.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 22 22:06:06.298: INFO: Wrong image for pod: daemon-set-nrlmm. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Dec 22 22:06:06.299: INFO: Pod daemon-set-nrlmm is not available
Dec 22 22:06:06.302: INFO: DaemonSet pods can't tolerate node ip-10-0-1-168.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 22 22:06:07.301: INFO: Wrong image for pod: daemon-set-nrlmm. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Dec 22 22:06:07.301: INFO: Pod daemon-set-nrlmm is not available
Dec 22 22:06:07.312: INFO: DaemonSet pods can't tolerate node ip-10-0-1-168.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 22 22:06:08.299: INFO: Wrong image for pod: daemon-set-nrlmm. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Dec 22 22:06:08.299: INFO: Pod daemon-set-nrlmm is not available
Dec 22 22:06:08.302: INFO: DaemonSet pods can't tolerate node ip-10-0-1-168.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 22 22:06:09.299: INFO: Wrong image for pod: daemon-set-nrlmm. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Dec 22 22:06:09.299: INFO: Pod daemon-set-nrlmm is not available
Dec 22 22:06:09.303: INFO: DaemonSet pods can't tolerate node ip-10-0-1-168.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 22 22:06:10.299: INFO: Wrong image for pod: daemon-set-nrlmm. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Dec 22 22:06:10.299: INFO: Pod daemon-set-nrlmm is not available
Dec 22 22:06:10.302: INFO: DaemonSet pods can't tolerate node ip-10-0-1-168.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 22 22:06:11.298: INFO: Wrong image for pod: daemon-set-nrlmm. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Dec 22 22:06:11.298: INFO: Pod daemon-set-nrlmm is not available
Dec 22 22:06:11.302: INFO: DaemonSet pods can't tolerate node ip-10-0-1-168.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 22 22:06:12.299: INFO: Pod daemon-set-rqdkq is not available
Dec 22 22:06:12.310: INFO: DaemonSet pods can't tolerate node ip-10-0-1-168.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7828, will wait for the garbage collector to delete the pods
Dec 22 22:06:12.373: INFO: Deleting DaemonSet.extensions daemon-set took: 5.333155ms
Dec 22 22:06:12.773: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.186975ms
Dec 22 22:06:25.377: INFO: Number of nodes with available pods: 0
Dec 22 22:06:25.377: INFO: Number of running nodes: 0, number of available pods: 0
Dec 22 22:06:25.381: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7828/daemonsets","resourceVersion":"12121"},"items":null}

Dec 22 22:06:25.387: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7828/pods","resourceVersion":"12121"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:06:25.407: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7828" for this suite.
Dec 22 22:06:31.441: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:06:31.503: INFO: namespace daemonsets-7828 deletion completed in 6.082315902s

â€¢ [SLOW TEST:46.300 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:06:31.504: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating server pod server in namespace prestop-1460
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-1460
STEP: Deleting pre-stop pod
Dec 22 22:06:42.558: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:06:42.563: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-1460" for this suite.
Dec 22 22:07:24.576: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:07:24.696: INFO: namespace prestop-1460 deletion completed in 42.127746879s

â€¢ [SLOW TEST:53.192 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:07:24.696: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Dec 22 22:07:28.739: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 22 22:07:28.742: INFO: Pod pod-with-prestop-http-hook still exists
Dec 22 22:07:30.742: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 22 22:07:30.745: INFO: Pod pod-with-prestop-http-hook still exists
Dec 22 22:07:32.742: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 22 22:07:32.746: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:07:32.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-5683" for this suite.
Dec 22 22:07:54.772: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:07:54.836: INFO: namespace container-lifecycle-hook-5683 deletion completed in 22.079748415s

â€¢ [SLOW TEST:30.140 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:07:54.836: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec 22 22:07:54.906: INFO: Waiting up to 5m0s for pod "pod-5ab660b7-4726-4881-bbb6-8e9a0313dbcb" in namespace "emptydir-1016" to be "success or failure"
Dec 22 22:07:54.908: INFO: Pod "pod-5ab660b7-4726-4881-bbb6-8e9a0313dbcb": Phase="Pending", Reason="", readiness=false. Elapsed: 1.925707ms
Dec 22 22:07:56.911: INFO: Pod "pod-5ab660b7-4726-4881-bbb6-8e9a0313dbcb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004347222s
Dec 22 22:07:58.913: INFO: Pod "pod-5ab660b7-4726-4881-bbb6-8e9a0313dbcb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006833424s
STEP: Saw pod success
Dec 22 22:07:58.913: INFO: Pod "pod-5ab660b7-4726-4881-bbb6-8e9a0313dbcb" satisfied condition "success or failure"
Dec 22 22:07:58.915: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod pod-5ab660b7-4726-4881-bbb6-8e9a0313dbcb container test-container: <nil>
STEP: delete the pod
Dec 22 22:07:58.928: INFO: Waiting for pod pod-5ab660b7-4726-4881-bbb6-8e9a0313dbcb to disappear
Dec 22 22:07:58.930: INFO: Pod pod-5ab660b7-4726-4881-bbb6-8e9a0313dbcb no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:07:58.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1016" for this suite.
Dec 22 22:08:04.940: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:08:04.996: INFO: namespace emptydir-1016 deletion completed in 6.062937614s

â€¢ [SLOW TEST:10.160 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:08:04.997: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec 22 22:08:05.024: INFO: Waiting up to 5m0s for pod "downwardapi-volume-395fbd20-07a5-460c-82fe-a3e1fc8a8a17" in namespace "projected-6640" to be "success or failure"
Dec 22 22:08:05.029: INFO: Pod "downwardapi-volume-395fbd20-07a5-460c-82fe-a3e1fc8a8a17": Phase="Pending", Reason="", readiness=false. Elapsed: 5.022681ms
Dec 22 22:08:07.032: INFO: Pod "downwardapi-volume-395fbd20-07a5-460c-82fe-a3e1fc8a8a17": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007637106s
Dec 22 22:08:09.034: INFO: Pod "downwardapi-volume-395fbd20-07a5-460c-82fe-a3e1fc8a8a17": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010400787s
STEP: Saw pod success
Dec 22 22:08:09.034: INFO: Pod "downwardapi-volume-395fbd20-07a5-460c-82fe-a3e1fc8a8a17" satisfied condition "success or failure"
Dec 22 22:08:09.037: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod downwardapi-volume-395fbd20-07a5-460c-82fe-a3e1fc8a8a17 container client-container: <nil>
STEP: delete the pod
Dec 22 22:08:09.060: INFO: Waiting for pod downwardapi-volume-395fbd20-07a5-460c-82fe-a3e1fc8a8a17 to disappear
Dec 22 22:08:09.063: INFO: Pod downwardapi-volume-395fbd20-07a5-460c-82fe-a3e1fc8a8a17 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:08:09.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6640" for this suite.
Dec 22 22:08:15.073: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:08:15.248: INFO: namespace projected-6640 deletion completed in 6.181202783s

â€¢ [SLOW TEST:10.251 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:08:15.248: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec 22 22:08:15.343: INFO: DaemonSet pods can't tolerate node ip-10-0-1-168.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 22 22:08:15.345: INFO: Number of nodes with available pods: 0
Dec 22 22:08:15.345: INFO: Node ip-10-0-1-121.us-west-2.compute.internal is running more than one daemon pod
Dec 22 22:08:16.349: INFO: DaemonSet pods can't tolerate node ip-10-0-1-168.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 22 22:08:16.352: INFO: Number of nodes with available pods: 0
Dec 22 22:08:16.352: INFO: Node ip-10-0-1-121.us-west-2.compute.internal is running more than one daemon pod
Dec 22 22:08:17.349: INFO: DaemonSet pods can't tolerate node ip-10-0-1-168.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 22 22:08:17.351: INFO: Number of nodes with available pods: 1
Dec 22 22:08:17.351: INFO: Node ip-10-0-1-121.us-west-2.compute.internal is running more than one daemon pod
Dec 22 22:08:18.355: INFO: DaemonSet pods can't tolerate node ip-10-0-1-168.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 22 22:08:18.365: INFO: Number of nodes with available pods: 2
Dec 22 22:08:18.365: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Dec 22 22:08:18.392: INFO: DaemonSet pods can't tolerate node ip-10-0-1-168.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 22 22:08:18.403: INFO: Number of nodes with available pods: 1
Dec 22 22:08:18.403: INFO: Node ip-10-0-1-187.us-west-2.compute.internal is running more than one daemon pod
Dec 22 22:08:19.415: INFO: DaemonSet pods can't tolerate node ip-10-0-1-168.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 22 22:08:19.418: INFO: Number of nodes with available pods: 1
Dec 22 22:08:19.418: INFO: Node ip-10-0-1-187.us-west-2.compute.internal is running more than one daemon pod
Dec 22 22:08:20.406: INFO: DaemonSet pods can't tolerate node ip-10-0-1-168.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 22 22:08:20.409: INFO: Number of nodes with available pods: 1
Dec 22 22:08:20.409: INFO: Node ip-10-0-1-187.us-west-2.compute.internal is running more than one daemon pod
Dec 22 22:08:21.407: INFO: DaemonSet pods can't tolerate node ip-10-0-1-168.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 22 22:08:21.411: INFO: Number of nodes with available pods: 1
Dec 22 22:08:21.411: INFO: Node ip-10-0-1-187.us-west-2.compute.internal is running more than one daemon pod
Dec 22 22:08:22.407: INFO: DaemonSet pods can't tolerate node ip-10-0-1-168.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 22 22:08:22.409: INFO: Number of nodes with available pods: 1
Dec 22 22:08:22.409: INFO: Node ip-10-0-1-187.us-west-2.compute.internal is running more than one daemon pod
Dec 22 22:08:23.421: INFO: DaemonSet pods can't tolerate node ip-10-0-1-168.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 22 22:08:23.435: INFO: Number of nodes with available pods: 1
Dec 22 22:08:23.435: INFO: Node ip-10-0-1-187.us-west-2.compute.internal is running more than one daemon pod
Dec 22 22:08:24.407: INFO: DaemonSet pods can't tolerate node ip-10-0-1-168.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 22 22:08:24.409: INFO: Number of nodes with available pods: 1
Dec 22 22:08:24.409: INFO: Node ip-10-0-1-187.us-west-2.compute.internal is running more than one daemon pod
Dec 22 22:08:25.408: INFO: DaemonSet pods can't tolerate node ip-10-0-1-168.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 22 22:08:25.411: INFO: Number of nodes with available pods: 1
Dec 22 22:08:25.411: INFO: Node ip-10-0-1-187.us-west-2.compute.internal is running more than one daemon pod
Dec 22 22:08:26.407: INFO: DaemonSet pods can't tolerate node ip-10-0-1-168.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 22 22:08:26.410: INFO: Number of nodes with available pods: 1
Dec 22 22:08:26.410: INFO: Node ip-10-0-1-187.us-west-2.compute.internal is running more than one daemon pod
Dec 22 22:08:27.407: INFO: DaemonSet pods can't tolerate node ip-10-0-1-168.us-west-2.compute.internal with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 22 22:08:27.409: INFO: Number of nodes with available pods: 2
Dec 22 22:08:27.409: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1728, will wait for the garbage collector to delete the pods
Dec 22 22:08:27.468: INFO: Deleting DaemonSet.extensions daemon-set took: 4.645042ms
Dec 22 22:08:27.868: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.239017ms
Dec 22 22:08:35.371: INFO: Number of nodes with available pods: 0
Dec 22 22:08:35.372: INFO: Number of running nodes: 0, number of available pods: 0
Dec 22 22:08:35.373: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1728/daemonsets","resourceVersion":"12587"},"items":null}

Dec 22 22:08:35.375: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1728/pods","resourceVersion":"12587"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:08:35.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1728" for this suite.
Dec 22 22:08:41.397: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:08:41.500: INFO: namespace daemonsets-1728 deletion completed in 6.112654438s

â€¢ [SLOW TEST:26.252 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:08:41.500: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test substitution in container's command
Dec 22 22:08:41.574: INFO: Waiting up to 5m0s for pod "var-expansion-63f58676-d397-458e-b9b2-0b88e4d167af" in namespace "var-expansion-2734" to be "success or failure"
Dec 22 22:08:41.577: INFO: Pod "var-expansion-63f58676-d397-458e-b9b2-0b88e4d167af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.407009ms
Dec 22 22:08:43.587: INFO: Pod "var-expansion-63f58676-d397-458e-b9b2-0b88e4d167af": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012346318s
Dec 22 22:08:45.590: INFO: Pod "var-expansion-63f58676-d397-458e-b9b2-0b88e4d167af": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015435257s
STEP: Saw pod success
Dec 22 22:08:45.590: INFO: Pod "var-expansion-63f58676-d397-458e-b9b2-0b88e4d167af" satisfied condition "success or failure"
Dec 22 22:08:45.592: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod var-expansion-63f58676-d397-458e-b9b2-0b88e4d167af container dapi-container: <nil>
STEP: delete the pod
Dec 22 22:08:45.611: INFO: Waiting for pod var-expansion-63f58676-d397-458e-b9b2-0b88e4d167af to disappear
Dec 22 22:08:45.613: INFO: Pod var-expansion-63f58676-d397-458e-b9b2-0b88e4d167af no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:08:45.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2734" for this suite.
Dec 22 22:08:51.632: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:08:51.751: INFO: namespace var-expansion-2734 deletion completed in 6.134324201s

â€¢ [SLOW TEST:10.251 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:08:51.752: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name secret-emptykey-test-b88ef140-c333-4fc4-8655-f671d393f751
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:08:51.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6191" for this suite.
Dec 22 22:08:57.807: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:08:57.866: INFO: namespace secrets-6191 deletion completed in 6.066656137s

â€¢ [SLOW TEST:6.115 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:08:57.867: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name s-test-opt-del-14ad5df6-2e24-456c-a420-eb2b7124bb1b
STEP: Creating secret with name s-test-opt-upd-2371133f-071e-467e-849b-4e1d2d32a6c5
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-14ad5df6-2e24-456c-a420-eb2b7124bb1b
STEP: Updating secret s-test-opt-upd-2371133f-071e-467e-849b-4e1d2d32a6c5
STEP: Creating secret with name s-test-opt-create-ff97f32c-71d7-41f5-b140-98a005fe631a
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:09:02.043: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5050" for this suite.
Dec 22 22:09:24.076: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:09:24.169: INFO: namespace projected-5050 deletion completed in 22.108951185s

â€¢ [SLOW TEST:26.303 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:09:24.171: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-ef000817-6314-4aae-b987-de6d5b63540d
STEP: Creating a pod to test consume secrets
Dec 22 22:09:24.246: INFO: Waiting up to 5m0s for pod "pod-secrets-c2257405-7f47-4eae-88b9-440d54dcd554" in namespace "secrets-1319" to be "success or failure"
Dec 22 22:09:24.248: INFO: Pod "pod-secrets-c2257405-7f47-4eae-88b9-440d54dcd554": Phase="Pending", Reason="", readiness=false. Elapsed: 1.934944ms
Dec 22 22:09:26.257: INFO: Pod "pod-secrets-c2257405-7f47-4eae-88b9-440d54dcd554": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010857147s
STEP: Saw pod success
Dec 22 22:09:26.257: INFO: Pod "pod-secrets-c2257405-7f47-4eae-88b9-440d54dcd554" satisfied condition "success or failure"
Dec 22 22:09:26.267: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod pod-secrets-c2257405-7f47-4eae-88b9-440d54dcd554 container secret-volume-test: <nil>
STEP: delete the pod
Dec 22 22:09:26.288: INFO: Waiting for pod pod-secrets-c2257405-7f47-4eae-88b9-440d54dcd554 to disappear
Dec 22 22:09:26.291: INFO: Pod pod-secrets-c2257405-7f47-4eae-88b9-440d54dcd554 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:09:26.291: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1319" for this suite.
Dec 22 22:09:32.305: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:09:32.370: INFO: namespace secrets-1319 deletion completed in 6.074057413s

â€¢ [SLOW TEST:8.199 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:09:32.370: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Dec 22 22:09:32.393: INFO: Waiting up to 5m0s for pod "downward-api-da7b8030-53f6-48b9-8efc-4a9c6874d8e7" in namespace "downward-api-7133" to be "success or failure"
Dec 22 22:09:32.395: INFO: Pod "downward-api-da7b8030-53f6-48b9-8efc-4a9c6874d8e7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025776ms
Dec 22 22:09:34.398: INFO: Pod "downward-api-da7b8030-53f6-48b9-8efc-4a9c6874d8e7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004712871s
STEP: Saw pod success
Dec 22 22:09:34.398: INFO: Pod "downward-api-da7b8030-53f6-48b9-8efc-4a9c6874d8e7" satisfied condition "success or failure"
Dec 22 22:09:34.400: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod downward-api-da7b8030-53f6-48b9-8efc-4a9c6874d8e7 container dapi-container: <nil>
STEP: delete the pod
Dec 22 22:09:34.416: INFO: Waiting for pod downward-api-da7b8030-53f6-48b9-8efc-4a9c6874d8e7 to disappear
Dec 22 22:09:34.418: INFO: Pod downward-api-da7b8030-53f6-48b9-8efc-4a9c6874d8e7 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:09:34.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7133" for this suite.
Dec 22 22:09:40.428: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:09:40.511: INFO: namespace downward-api-7133 deletion completed in 6.089878322s

â€¢ [SLOW TEST:8.141 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:09:40.512: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-d27e4cf2-1824-4456-a35d-cbf069d948b4
STEP: Creating a pod to test consume configMaps
Dec 22 22:09:40.585: INFO: Waiting up to 5m0s for pod "pod-configmaps-a8889b98-685f-4b3d-9fa4-4d511fe3635e" in namespace "configmap-432" to be "success or failure"
Dec 22 22:09:40.589: INFO: Pod "pod-configmaps-a8889b98-685f-4b3d-9fa4-4d511fe3635e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.969544ms
Dec 22 22:09:42.592: INFO: Pod "pod-configmaps-a8889b98-685f-4b3d-9fa4-4d511fe3635e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006661753s
STEP: Saw pod success
Dec 22 22:09:42.592: INFO: Pod "pod-configmaps-a8889b98-685f-4b3d-9fa4-4d511fe3635e" satisfied condition "success or failure"
Dec 22 22:09:42.594: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod pod-configmaps-a8889b98-685f-4b3d-9fa4-4d511fe3635e container configmap-volume-test: <nil>
STEP: delete the pod
Dec 22 22:09:42.607: INFO: Waiting for pod pod-configmaps-a8889b98-685f-4b3d-9fa4-4d511fe3635e to disappear
Dec 22 22:09:42.608: INFO: Pod pod-configmaps-a8889b98-685f-4b3d-9fa4-4d511fe3635e no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:09:42.608: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-432" for this suite.
Dec 22 22:09:48.617: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:09:48.671: INFO: namespace configmap-432 deletion completed in 6.060153497s

â€¢ [SLOW TEST:8.159 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:09:48.672: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a replication controller
Dec 22 22:09:48.690: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 create -f - --namespace=kubectl-9270'
Dec 22 22:09:49.083: INFO: stderr: ""
Dec 22 22:09:49.083: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 22 22:09:49.083: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9270'
Dec 22 22:09:49.176: INFO: stderr: ""
Dec 22 22:09:49.176: INFO: stdout: "update-demo-nautilus-kqv6r update-demo-nautilus-vm9vb "
Dec 22 22:09:49.176: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 get pods update-demo-nautilus-kqv6r -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9270'
Dec 22 22:09:49.247: INFO: stderr: ""
Dec 22 22:09:49.247: INFO: stdout: ""
Dec 22 22:09:49.247: INFO: update-demo-nautilus-kqv6r is created but not running
Dec 22 22:09:54.247: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9270'
Dec 22 22:09:54.341: INFO: stderr: ""
Dec 22 22:09:54.341: INFO: stdout: "update-demo-nautilus-kqv6r update-demo-nautilus-vm9vb "
Dec 22 22:09:54.341: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 get pods update-demo-nautilus-kqv6r -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9270'
Dec 22 22:09:54.417: INFO: stderr: ""
Dec 22 22:09:54.417: INFO: stdout: "true"
Dec 22 22:09:54.418: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 get pods update-demo-nautilus-kqv6r -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9270'
Dec 22 22:09:54.501: INFO: stderr: ""
Dec 22 22:09:54.501: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 22 22:09:54.501: INFO: validating pod update-demo-nautilus-kqv6r
Dec 22 22:09:54.504: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 22 22:09:54.505: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 22 22:09:54.505: INFO: update-demo-nautilus-kqv6r is verified up and running
Dec 22 22:09:54.505: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 get pods update-demo-nautilus-vm9vb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9270'
Dec 22 22:09:54.575: INFO: stderr: ""
Dec 22 22:09:54.575: INFO: stdout: "true"
Dec 22 22:09:54.575: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 get pods update-demo-nautilus-vm9vb -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9270'
Dec 22 22:09:54.645: INFO: stderr: ""
Dec 22 22:09:54.645: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 22 22:09:54.645: INFO: validating pod update-demo-nautilus-vm9vb
Dec 22 22:09:54.649: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 22 22:09:54.649: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 22 22:09:54.649: INFO: update-demo-nautilus-vm9vb is verified up and running
STEP: using delete to clean up resources
Dec 22 22:09:54.649: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 delete --grace-period=0 --force -f - --namespace=kubectl-9270'
Dec 22 22:09:54.720: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 22 22:09:54.720: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec 22 22:09:54.720: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-9270'
Dec 22 22:09:54.822: INFO: stderr: "No resources found.\n"
Dec 22 22:09:54.822: INFO: stdout: ""
Dec 22 22:09:54.822: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 get pods -l name=update-demo --namespace=kubectl-9270 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 22 22:09:54.937: INFO: stderr: ""
Dec 22 22:09:54.937: INFO: stdout: "update-demo-nautilus-kqv6r\nupdate-demo-nautilus-vm9vb\n"
Dec 22 22:09:55.437: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-9270'
Dec 22 22:09:55.529: INFO: stderr: "No resources found.\n"
Dec 22 22:09:55.529: INFO: stdout: ""
Dec 22 22:09:55.529: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 get pods -l name=update-demo --namespace=kubectl-9270 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 22 22:09:55.602: INFO: stderr: ""
Dec 22 22:09:55.602: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:09:55.602: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9270" for this suite.
Dec 22 22:10:17.612: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:10:17.701: INFO: namespace kubectl-9270 deletion completed in 22.095258655s

â€¢ [SLOW TEST:29.029 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:10:17.701: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-upd-bbf656bb-3ad9-4967-a8a6-84f048ee79da
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-bbf656bb-3ad9-4967-a8a6-84f048ee79da
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:10:21.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9944" for this suite.
Dec 22 22:10:37.769: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:10:37.898: INFO: namespace configmap-9944 deletion completed in 16.135078109s

â€¢ [SLOW TEST:20.197 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:10:37.898: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1456
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec 22 22:10:37.918: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-1281'
Dec 22 22:10:38.010: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec 22 22:10:38.010: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Dec 22 22:10:38.024: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-xlvkq]
Dec 22 22:10:38.024: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-xlvkq" in namespace "kubectl-1281" to be "running and ready"
Dec 22 22:10:38.026: INFO: Pod "e2e-test-nginx-rc-xlvkq": Phase="Pending", Reason="", readiness=false. Elapsed: 1.75974ms
Dec 22 22:10:40.031: INFO: Pod "e2e-test-nginx-rc-xlvkq": Phase="Running", Reason="", readiness=true. Elapsed: 2.006386287s
Dec 22 22:10:40.031: INFO: Pod "e2e-test-nginx-rc-xlvkq" satisfied condition "running and ready"
Dec 22 22:10:40.031: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-xlvkq]
Dec 22 22:10:40.031: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 logs rc/e2e-test-nginx-rc --namespace=kubectl-1281'
Dec 22 22:10:40.132: INFO: stderr: ""
Dec 22 22:10:40.132: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1461
Dec 22 22:10:40.133: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 delete rc e2e-test-nginx-rc --namespace=kubectl-1281'
Dec 22 22:10:40.211: INFO: stderr: ""
Dec 22 22:10:40.211: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:10:40.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1281" for this suite.
Dec 22 22:11:02.225: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:11:02.305: INFO: namespace kubectl-1281 deletion completed in 22.088242259s

â€¢ [SLOW TEST:24.408 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:11:02.306: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-40b11de4-0d40-4579-ac60-d7c34d89f676
STEP: Creating a pod to test consume configMaps
Dec 22 22:11:02.337: INFO: Waiting up to 5m0s for pod "pod-configmaps-e2415f60-79b3-4f94-a6a1-9732c1a909bb" in namespace "configmap-5843" to be "success or failure"
Dec 22 22:11:02.339: INFO: Pod "pod-configmaps-e2415f60-79b3-4f94-a6a1-9732c1a909bb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.388103ms
Dec 22 22:11:04.342: INFO: Pod "pod-configmaps-e2415f60-79b3-4f94-a6a1-9732c1a909bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004937726s
STEP: Saw pod success
Dec 22 22:11:04.342: INFO: Pod "pod-configmaps-e2415f60-79b3-4f94-a6a1-9732c1a909bb" satisfied condition "success or failure"
Dec 22 22:11:04.343: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod pod-configmaps-e2415f60-79b3-4f94-a6a1-9732c1a909bb container configmap-volume-test: <nil>
STEP: delete the pod
Dec 22 22:11:04.356: INFO: Waiting for pod pod-configmaps-e2415f60-79b3-4f94-a6a1-9732c1a909bb to disappear
Dec 22 22:11:04.358: INFO: Pod pod-configmaps-e2415f60-79b3-4f94-a6a1-9732c1a909bb no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:11:04.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5843" for this suite.
Dec 22 22:11:10.367: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:11:10.423: INFO: namespace configmap-5843 deletion completed in 6.062314655s

â€¢ [SLOW TEST:8.118 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:11:10.424: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec 22 22:11:12.457: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:11:12.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5754" for this suite.
Dec 22 22:11:18.495: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:11:18.550: INFO: namespace container-runtime-5754 deletion completed in 6.06577151s

â€¢ [SLOW TEST:8.127 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:11:18.551: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec 22 22:11:18.573: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c4910296-af37-4833-a98f-611a7f61d471" in namespace "downward-api-7833" to be "success or failure"
Dec 22 22:11:18.578: INFO: Pod "downwardapi-volume-c4910296-af37-4833-a98f-611a7f61d471": Phase="Pending", Reason="", readiness=false. Elapsed: 5.798159ms
Dec 22 22:11:20.581: INFO: Pod "downwardapi-volume-c4910296-af37-4833-a98f-611a7f61d471": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008662667s
STEP: Saw pod success
Dec 22 22:11:20.581: INFO: Pod "downwardapi-volume-c4910296-af37-4833-a98f-611a7f61d471" satisfied condition "success or failure"
Dec 22 22:11:20.583: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod downwardapi-volume-c4910296-af37-4833-a98f-611a7f61d471 container client-container: <nil>
STEP: delete the pod
Dec 22 22:11:20.596: INFO: Waiting for pod downwardapi-volume-c4910296-af37-4833-a98f-611a7f61d471 to disappear
Dec 22 22:11:20.599: INFO: Pod downwardapi-volume-c4910296-af37-4833-a98f-611a7f61d471 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:11:20.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7833" for this suite.
Dec 22 22:11:26.610: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:11:26.674: INFO: namespace downward-api-7833 deletion completed in 6.072196581s

â€¢ [SLOW TEST:8.123 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:11:26.674: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Dec 22 22:11:26.699: INFO: Waiting up to 5m0s for pod "downward-api-70ed00a0-0ce2-4473-a1b8-07325abaeb98" in namespace "downward-api-3505" to be "success or failure"
Dec 22 22:11:26.701: INFO: Pod "downward-api-70ed00a0-0ce2-4473-a1b8-07325abaeb98": Phase="Pending", Reason="", readiness=false. Elapsed: 2.542948ms
Dec 22 22:11:28.704: INFO: Pod "downward-api-70ed00a0-0ce2-4473-a1b8-07325abaeb98": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005352092s
STEP: Saw pod success
Dec 22 22:11:28.704: INFO: Pod "downward-api-70ed00a0-0ce2-4473-a1b8-07325abaeb98" satisfied condition "success or failure"
Dec 22 22:11:28.706: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod downward-api-70ed00a0-0ce2-4473-a1b8-07325abaeb98 container dapi-container: <nil>
STEP: delete the pod
Dec 22 22:11:28.722: INFO: Waiting for pod downward-api-70ed00a0-0ce2-4473-a1b8-07325abaeb98 to disappear
Dec 22 22:11:28.725: INFO: Pod downward-api-70ed00a0-0ce2-4473-a1b8-07325abaeb98 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:11:28.725: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3505" for this suite.
Dec 22 22:11:34.735: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:11:34.794: INFO: namespace downward-api-3505 deletion completed in 6.06623482s

â€¢ [SLOW TEST:8.119 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:11:34.794: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1612
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec 22 22:11:34.810: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-9151'
Dec 22 22:11:34.880: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec 22 22:11:34.880: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1617
Dec 22 22:11:34.884: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 delete jobs e2e-test-nginx-job --namespace=kubectl-9151'
Dec 22 22:11:34.960: INFO: stderr: ""
Dec 22 22:11:34.960: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:11:34.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9151" for this suite.
Dec 22 22:11:40.970: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:11:41.029: INFO: namespace kubectl-9151 deletion completed in 6.065975555s

â€¢ [SLOW TEST:6.235 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run job
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:11:41.029: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating Redis RC
Dec 22 22:11:41.098: INFO: namespace kubectl-6309
Dec 22 22:11:41.098: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 create -f - --namespace=kubectl-6309'
Dec 22 22:11:41.278: INFO: stderr: ""
Dec 22 22:11:41.278: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec 22 22:11:42.281: INFO: Selector matched 1 pods for map[app:redis]
Dec 22 22:11:42.281: INFO: Found 0 / 1
Dec 22 22:11:43.288: INFO: Selector matched 1 pods for map[app:redis]
Dec 22 22:11:43.288: INFO: Found 1 / 1
Dec 22 22:11:43.288: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec 22 22:11:43.294: INFO: Selector matched 1 pods for map[app:redis]
Dec 22 22:11:43.294: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec 22 22:11:43.294: INFO: wait on redis-master startup in kubectl-6309 
Dec 22 22:11:43.294: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 logs redis-master-blsjp redis-master --namespace=kubectl-6309'
Dec 22 22:11:43.722: INFO: stderr: ""
Dec 22 22:11:43.722: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 22 Dec 22:11:42.412 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 22 Dec 22:11:42.412 # Server started, Redis version 3.2.12\n1:M 22 Dec 22:11:42.412 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 22 Dec 22:11:42.412 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Dec 22 22:11:43.722: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-6309'
Dec 22 22:11:43.912: INFO: stderr: ""
Dec 22 22:11:43.912: INFO: stdout: "service/rm2 exposed\n"
Dec 22 22:11:43.918: INFO: Service rm2 in namespace kubectl-6309 found.
STEP: exposing service
Dec 22 22:11:45.922: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-6309'
Dec 22 22:11:46.011: INFO: stderr: ""
Dec 22 22:11:46.011: INFO: stdout: "service/rm3 exposed\n"
Dec 22 22:11:46.015: INFO: Service rm3 in namespace kubectl-6309 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:11:48.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6309" for this suite.
Dec 22 22:12:10.038: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:12:10.301: INFO: namespace kubectl-6309 deletion completed in 22.276803094s

â€¢ [SLOW TEST:29.272 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl expose
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create services for rc  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:12:10.301: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Dec 22 22:12:10.322: INFO: Waiting up to 5m0s for pod "downward-api-85428845-f8cb-46d1-8c2f-9591e0d40edc" in namespace "downward-api-8013" to be "success or failure"
Dec 22 22:12:10.326: INFO: Pod "downward-api-85428845-f8cb-46d1-8c2f-9591e0d40edc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.279703ms
Dec 22 22:12:12.329: INFO: Pod "downward-api-85428845-f8cb-46d1-8c2f-9591e0d40edc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006274669s
STEP: Saw pod success
Dec 22 22:12:12.329: INFO: Pod "downward-api-85428845-f8cb-46d1-8c2f-9591e0d40edc" satisfied condition "success or failure"
Dec 22 22:12:12.331: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod downward-api-85428845-f8cb-46d1-8c2f-9591e0d40edc container dapi-container: <nil>
STEP: delete the pod
Dec 22 22:12:12.347: INFO: Waiting for pod downward-api-85428845-f8cb-46d1-8c2f-9591e0d40edc to disappear
Dec 22 22:12:12.349: INFO: Pod downward-api-85428845-f8cb-46d1-8c2f-9591e0d40edc no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:12:12.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8013" for this suite.
Dec 22 22:12:18.359: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:12:18.501: INFO: namespace downward-api-8013 deletion completed in 6.149132139s

â€¢ [SLOW TEST:8.200 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:12:18.502: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:12:18.524: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8644" for this suite.
Dec 22 22:12:24.534: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:12:24.597: INFO: namespace services-8644 deletion completed in 6.07102776s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

â€¢ [SLOW TEST:6.096 seconds]
[sig-network] Services
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide secure master service  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:12:24.597: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec 22 22:12:24.618: INFO: Waiting up to 5m0s for pod "downwardapi-volume-dad24f41-d2dd-48df-b92f-6363279c908a" in namespace "downward-api-5620" to be "success or failure"
Dec 22 22:12:24.620: INFO: Pod "downwardapi-volume-dad24f41-d2dd-48df-b92f-6363279c908a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.798437ms
Dec 22 22:12:26.624: INFO: Pod "downwardapi-volume-dad24f41-d2dd-48df-b92f-6363279c908a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00581365s
STEP: Saw pod success
Dec 22 22:12:26.624: INFO: Pod "downwardapi-volume-dad24f41-d2dd-48df-b92f-6363279c908a" satisfied condition "success or failure"
Dec 22 22:12:26.628: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod downwardapi-volume-dad24f41-d2dd-48df-b92f-6363279c908a container client-container: <nil>
STEP: delete the pod
Dec 22 22:12:26.653: INFO: Waiting for pod downwardapi-volume-dad24f41-d2dd-48df-b92f-6363279c908a to disappear
Dec 22 22:12:26.656: INFO: Pod downwardapi-volume-dad24f41-d2dd-48df-b92f-6363279c908a no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:12:26.656: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5620" for this suite.
Dec 22 22:12:32.671: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:12:32.726: INFO: namespace downward-api-5620 deletion completed in 6.065262624s

â€¢ [SLOW TEST:8.129 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:12:32.727: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-4064
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 22 22:12:32.795: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec 22 22:12:54.852: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.20.27.38:8080/dial?request=hostName&protocol=udp&host=10.20.29.241&port=8081&tries=1'] Namespace:pod-network-test-4064 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 22 22:12:54.852: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
Dec 22 22:12:55.018: INFO: Waiting for endpoints: map[]
Dec 22 22:12:55.020: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.20.27.38:8080/dial?request=hostName&protocol=udp&host=10.20.27.39&port=8081&tries=1'] Namespace:pod-network-test-4064 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 22 22:12:55.020: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
Dec 22 22:12:55.181: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:12:55.181: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-4064" for this suite.
Dec 22 22:13:17.192: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:13:17.296: INFO: namespace pod-network-test-4064 deletion completed in 22.11130342s

â€¢ [SLOW TEST:44.570 seconds]
[sig-network] Networking
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:13:17.296: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec 22 22:13:17.318: INFO: Waiting up to 5m0s for pod "pod-5bd0bfbb-24f1-468a-921e-f60d0e44b5ef" in namespace "emptydir-1294" to be "success or failure"
Dec 22 22:13:17.323: INFO: Pod "pod-5bd0bfbb-24f1-468a-921e-f60d0e44b5ef": Phase="Pending", Reason="", readiness=false. Elapsed: 4.20472ms
Dec 22 22:13:19.326: INFO: Pod "pod-5bd0bfbb-24f1-468a-921e-f60d0e44b5ef": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007331482s
STEP: Saw pod success
Dec 22 22:13:19.326: INFO: Pod "pod-5bd0bfbb-24f1-468a-921e-f60d0e44b5ef" satisfied condition "success or failure"
Dec 22 22:13:19.328: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod pod-5bd0bfbb-24f1-468a-921e-f60d0e44b5ef container test-container: <nil>
STEP: delete the pod
Dec 22 22:13:19.342: INFO: Waiting for pod pod-5bd0bfbb-24f1-468a-921e-f60d0e44b5ef to disappear
Dec 22 22:13:19.344: INFO: Pod pod-5bd0bfbb-24f1-468a-921e-f60d0e44b5ef no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:13:19.344: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1294" for this suite.
Dec 22 22:13:25.354: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:13:25.419: INFO: namespace emptydir-1294 deletion completed in 6.071389064s

â€¢ [SLOW TEST:8.123 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:13:25.419: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Dec 22 22:13:27.975: INFO: Successfully updated pod "annotationupdate995b0ad9-b7e1-489b-88e1-fa86ce68a4a7"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:13:29.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-830" for this suite.
Dec 22 22:13:52.005: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:13:52.098: INFO: namespace downward-api-830 deletion completed in 22.101443818s

â€¢ [SLOW TEST:26.679 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:13:52.098: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod busybox-e0f47cb3-eb5c-4a05-ab00-b0d75926a835 in namespace container-probe-7954
Dec 22 22:13:54.125: INFO: Started pod busybox-e0f47cb3-eb5c-4a05-ab00-b0d75926a835 in namespace container-probe-7954
STEP: checking the pod's current state and verifying that restartCount is present
Dec 22 22:13:54.127: INFO: Initial restart count of pod busybox-e0f47cb3-eb5c-4a05-ab00-b0d75926a835 is 0
Dec 22 22:14:44.206: INFO: Restart count of pod container-probe-7954/busybox-e0f47cb3-eb5c-4a05-ab00-b0d75926a835 is now 1 (50.079146137s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:14:44.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7954" for this suite.
Dec 22 22:14:50.228: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:14:50.302: INFO: namespace container-probe-7954 deletion completed in 6.082366183s

â€¢ [SLOW TEST:58.204 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:14:50.302: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the initial replication controller
Dec 22 22:14:50.320: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 create -f - --namespace=kubectl-8766'
Dec 22 22:14:50.483: INFO: stderr: ""
Dec 22 22:14:50.483: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 22 22:14:50.483: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8766'
Dec 22 22:14:50.571: INFO: stderr: ""
Dec 22 22:14:50.571: INFO: stdout: "update-demo-nautilus-hv6fr update-demo-nautilus-j4cwj "
Dec 22 22:14:50.571: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 get pods update-demo-nautilus-hv6fr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8766'
Dec 22 22:14:50.646: INFO: stderr: ""
Dec 22 22:14:50.646: INFO: stdout: ""
Dec 22 22:14:50.646: INFO: update-demo-nautilus-hv6fr is created but not running
Dec 22 22:14:55.646: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8766'
Dec 22 22:14:55.738: INFO: stderr: ""
Dec 22 22:14:55.738: INFO: stdout: "update-demo-nautilus-hv6fr update-demo-nautilus-j4cwj "
Dec 22 22:14:55.738: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 get pods update-demo-nautilus-hv6fr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8766'
Dec 22 22:14:55.826: INFO: stderr: ""
Dec 22 22:14:55.826: INFO: stdout: "true"
Dec 22 22:14:55.826: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 get pods update-demo-nautilus-hv6fr -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8766'
Dec 22 22:14:55.909: INFO: stderr: ""
Dec 22 22:14:55.909: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 22 22:14:55.909: INFO: validating pod update-demo-nautilus-hv6fr
Dec 22 22:14:55.913: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 22 22:14:55.913: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 22 22:14:55.913: INFO: update-demo-nautilus-hv6fr is verified up and running
Dec 22 22:14:55.913: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 get pods update-demo-nautilus-j4cwj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8766'
Dec 22 22:14:56.003: INFO: stderr: ""
Dec 22 22:14:56.003: INFO: stdout: "true"
Dec 22 22:14:56.003: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 get pods update-demo-nautilus-j4cwj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8766'
Dec 22 22:14:56.087: INFO: stderr: ""
Dec 22 22:14:56.087: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 22 22:14:56.087: INFO: validating pod update-demo-nautilus-j4cwj
Dec 22 22:14:56.091: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 22 22:14:56.091: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 22 22:14:56.091: INFO: update-demo-nautilus-j4cwj is verified up and running
STEP: rolling-update to new replication controller
Dec 22 22:14:56.093: INFO: scanned /root for discovery docs: <nil>
Dec 22 22:14:56.093: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-8766'
Dec 22 22:15:18.607: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Dec 22 22:15:18.607: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 22 22:15:18.607: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8766'
Dec 22 22:15:18.677: INFO: stderr: ""
Dec 22 22:15:18.677: INFO: stdout: "update-demo-kitten-h2mbr update-demo-kitten-s2pq7 "
Dec 22 22:15:18.677: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 get pods update-demo-kitten-h2mbr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8766'
Dec 22 22:15:18.743: INFO: stderr: ""
Dec 22 22:15:18.743: INFO: stdout: "true"
Dec 22 22:15:18.743: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 get pods update-demo-kitten-h2mbr -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8766'
Dec 22 22:15:18.809: INFO: stderr: ""
Dec 22 22:15:18.809: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Dec 22 22:15:18.809: INFO: validating pod update-demo-kitten-h2mbr
Dec 22 22:15:18.812: INFO: got data: {
  "image": "kitten.jpg"
}

Dec 22 22:15:18.813: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Dec 22 22:15:18.813: INFO: update-demo-kitten-h2mbr is verified up and running
Dec 22 22:15:18.813: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 get pods update-demo-kitten-s2pq7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8766'
Dec 22 22:15:18.879: INFO: stderr: ""
Dec 22 22:15:18.879: INFO: stdout: "true"
Dec 22 22:15:18.879: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 get pods update-demo-kitten-s2pq7 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8766'
Dec 22 22:15:18.946: INFO: stderr: ""
Dec 22 22:15:18.946: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Dec 22 22:15:18.946: INFO: validating pod update-demo-kitten-s2pq7
Dec 22 22:15:18.949: INFO: got data: {
  "image": "kitten.jpg"
}

Dec 22 22:15:18.949: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Dec 22 22:15:18.949: INFO: update-demo-kitten-s2pq7 is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:15:18.949: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8766" for this suite.
Dec 22 22:15:38.959: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:15:39.117: INFO: namespace kubectl-8766 deletion completed in 20.16508715s

â€¢ [SLOW TEST:48.815 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:15:39.118: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec 22 22:15:39.149: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2d13c010-412a-45a8-8f6b-bc4a53cd9067" in namespace "downward-api-2217" to be "success or failure"
Dec 22 22:15:39.156: INFO: Pod "downwardapi-volume-2d13c010-412a-45a8-8f6b-bc4a53cd9067": Phase="Pending", Reason="", readiness=false. Elapsed: 6.911269ms
Dec 22 22:15:41.158: INFO: Pod "downwardapi-volume-2d13c010-412a-45a8-8f6b-bc4a53cd9067": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009575652s
STEP: Saw pod success
Dec 22 22:15:41.158: INFO: Pod "downwardapi-volume-2d13c010-412a-45a8-8f6b-bc4a53cd9067" satisfied condition "success or failure"
Dec 22 22:15:41.161: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod downwardapi-volume-2d13c010-412a-45a8-8f6b-bc4a53cd9067 container client-container: <nil>
STEP: delete the pod
Dec 22 22:15:41.175: INFO: Waiting for pod downwardapi-volume-2d13c010-412a-45a8-8f6b-bc4a53cd9067 to disappear
Dec 22 22:15:41.177: INFO: Pod downwardapi-volume-2d13c010-412a-45a8-8f6b-bc4a53cd9067 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:15:41.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2217" for this suite.
Dec 22 22:15:47.190: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:15:47.255: INFO: namespace downward-api-2217 deletion completed in 6.074437863s

â€¢ [SLOW TEST:8.138 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:15:47.255: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Dec 22 22:15:51.301: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8400 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 22 22:15:51.301: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
Dec 22 22:15:51.467: INFO: Exec stderr: ""
Dec 22 22:15:51.467: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8400 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 22 22:15:51.467: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
Dec 22 22:15:51.613: INFO: Exec stderr: ""
Dec 22 22:15:51.614: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8400 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 22 22:15:51.614: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
Dec 22 22:15:51.761: INFO: Exec stderr: ""
Dec 22 22:15:51.761: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8400 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 22 22:15:51.761: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
Dec 22 22:15:51.913: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Dec 22 22:15:51.913: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8400 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 22 22:15:51.913: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
Dec 22 22:15:52.066: INFO: Exec stderr: ""
Dec 22 22:15:52.066: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8400 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 22 22:15:52.066: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
Dec 22 22:15:52.226: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Dec 22 22:15:52.227: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8400 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 22 22:15:52.227: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
Dec 22 22:15:52.389: INFO: Exec stderr: ""
Dec 22 22:15:52.389: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8400 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 22 22:15:52.389: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
Dec 22 22:15:52.619: INFO: Exec stderr: ""
Dec 22 22:15:52.619: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8400 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 22 22:15:52.619: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
Dec 22 22:15:52.891: INFO: Exec stderr: ""
Dec 22 22:15:52.891: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8400 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 22 22:15:52.892: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
Dec 22 22:15:53.193: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:15:53.193: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-8400" for this suite.
Dec 22 22:16:31.208: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:16:31.318: INFO: namespace e2e-kubelet-etc-hosts-8400 deletion completed in 38.121563333s

â€¢ [SLOW TEST:44.062 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:16:31.318: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W1222 22:17:11.411731      15 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec 22 22:17:11.411: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:17:11.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6544" for this suite.
Dec 22 22:17:17.430: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:17:17.592: INFO: namespace gc-6544 deletion completed in 6.177289719s

â€¢ [SLOW TEST:46.273 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:17:17.593: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod liveness-0b626f73-0105-4abb-9d21-032379311dc4 in namespace container-probe-455
Dec 22 22:17:21.695: INFO: Started pod liveness-0b626f73-0105-4abb-9d21-032379311dc4 in namespace container-probe-455
STEP: checking the pod's current state and verifying that restartCount is present
Dec 22 22:17:21.697: INFO: Initial restart count of pod liveness-0b626f73-0105-4abb-9d21-032379311dc4 is 0
Dec 22 22:17:37.726: INFO: Restart count of pod container-probe-455/liveness-0b626f73-0105-4abb-9d21-032379311dc4 is now 1 (16.028196528s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:17:37.734: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-455" for this suite.
Dec 22 22:17:43.748: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:17:43.927: INFO: namespace container-probe-455 deletion completed in 6.189972054s

â€¢ [SLOW TEST:26.334 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:17:43.927: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec 22 22:17:43.964: INFO: Waiting up to 5m0s for pod "pod-20de71ca-9537-4d46-b097-74f3209830ab" in namespace "emptydir-5302" to be "success or failure"
Dec 22 22:17:43.973: INFO: Pod "pod-20de71ca-9537-4d46-b097-74f3209830ab": Phase="Pending", Reason="", readiness=false. Elapsed: 9.463793ms
Dec 22 22:17:45.987: INFO: Pod "pod-20de71ca-9537-4d46-b097-74f3209830ab": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023624597s
Dec 22 22:17:47.990: INFO: Pod "pod-20de71ca-9537-4d46-b097-74f3209830ab": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026417593s
STEP: Saw pod success
Dec 22 22:17:47.990: INFO: Pod "pod-20de71ca-9537-4d46-b097-74f3209830ab" satisfied condition "success or failure"
Dec 22 22:17:47.992: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod pod-20de71ca-9537-4d46-b097-74f3209830ab container test-container: <nil>
STEP: delete the pod
Dec 22 22:17:48.015: INFO: Waiting for pod pod-20de71ca-9537-4d46-b097-74f3209830ab to disappear
Dec 22 22:17:48.019: INFO: Pod pod-20de71ca-9537-4d46-b097-74f3209830ab no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:17:48.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5302" for this suite.
Dec 22 22:17:54.030: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:17:54.127: INFO: namespace emptydir-5302 deletion completed in 6.104626344s

â€¢ [SLOW TEST:10.200 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:17:54.128: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Dec 22 22:17:58.211: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 22 22:17:58.213: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 22 22:18:00.213: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 22 22:18:00.218: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 22 22:18:02.213: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 22 22:18:02.217: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 22 22:18:04.213: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 22 22:18:04.216: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 22 22:18:06.213: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 22 22:18:06.216: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 22 22:18:08.213: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 22 22:18:08.216: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 22 22:18:10.213: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 22 22:18:10.216: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 22 22:18:12.213: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 22 22:18:12.216: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 22 22:18:14.213: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 22 22:18:14.217: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 22 22:18:16.213: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 22 22:18:16.217: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 22 22:18:18.218: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 22 22:18:18.221: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 22 22:18:20.213: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 22 22:18:20.217: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 22 22:18:22.213: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 22 22:18:22.216: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 22 22:18:24.213: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 22 22:18:24.216: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 22 22:18:26.213: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 22 22:18:26.216: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:18:26.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9280" for this suite.
Dec 22 22:18:48.251: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:18:48.409: INFO: namespace container-lifecycle-hook-9280 deletion completed in 22.165795488s

â€¢ [SLOW TEST:54.281 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:18:48.409: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename aggregator
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:76
Dec 22 22:18:48.428: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Registering the sample API server.
Dec 22 22:18:48.923: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Dec 22 22:18:50.966: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712649928, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712649928, loc:(*time.Location)(0x7ed0a00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712649928, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712649928, loc:(*time.Location)(0x7ed0a00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 22 22:18:52.970: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712649928, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712649928, loc:(*time.Location)(0x7ed0a00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712649928, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712649928, loc:(*time.Location)(0x7ed0a00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 22 22:18:54.969: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712649928, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712649928, loc:(*time.Location)(0x7ed0a00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712649928, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712649928, loc:(*time.Location)(0x7ed0a00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 22 22:18:56.969: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712649928, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712649928, loc:(*time.Location)(0x7ed0a00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712649928, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712649928, loc:(*time.Location)(0x7ed0a00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 22 22:19:00.100: INFO: Waited 1.126912894s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:67
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:19:00.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-6914" for this suite.
Dec 22 22:19:06.804: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:19:06.859: INFO: namespace aggregator-6914 deletion completed in 6.152692525s

â€¢ [SLOW TEST:18.450 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:19:06.860: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec 22 22:19:06.881: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a27ac57e-0ebb-451d-9622-d562caf791fb" in namespace "downward-api-5250" to be "success or failure"
Dec 22 22:19:06.884: INFO: Pod "downwardapi-volume-a27ac57e-0ebb-451d-9622-d562caf791fb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.851123ms
Dec 22 22:19:08.886: INFO: Pod "downwardapi-volume-a27ac57e-0ebb-451d-9622-d562caf791fb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005650042s
STEP: Saw pod success
Dec 22 22:19:08.886: INFO: Pod "downwardapi-volume-a27ac57e-0ebb-451d-9622-d562caf791fb" satisfied condition "success or failure"
Dec 22 22:19:08.888: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod downwardapi-volume-a27ac57e-0ebb-451d-9622-d562caf791fb container client-container: <nil>
STEP: delete the pod
Dec 22 22:19:08.904: INFO: Waiting for pod downwardapi-volume-a27ac57e-0ebb-451d-9622-d562caf791fb to disappear
Dec 22 22:19:08.907: INFO: Pod downwardapi-volume-a27ac57e-0ebb-451d-9622-d562caf791fb no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:19:08.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5250" for this suite.
Dec 22 22:19:14.921: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:19:15.017: INFO: namespace downward-api-5250 deletion completed in 6.103539002s

â€¢ [SLOW TEST:8.157 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:19:15.020: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec 22 22:19:15.121: INFO: (0) /api/v1/nodes/ip-10-0-1-121.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.043422ms)
Dec 22 22:19:15.125: INFO: (1) /api/v1/nodes/ip-10-0-1-121.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.642019ms)
Dec 22 22:19:15.128: INFO: (2) /api/v1/nodes/ip-10-0-1-121.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.382406ms)
Dec 22 22:19:15.132: INFO: (3) /api/v1/nodes/ip-10-0-1-121.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.474845ms)
Dec 22 22:19:15.136: INFO: (4) /api/v1/nodes/ip-10-0-1-121.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.584221ms)
Dec 22 22:19:15.140: INFO: (5) /api/v1/nodes/ip-10-0-1-121.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.628891ms)
Dec 22 22:19:15.143: INFO: (6) /api/v1/nodes/ip-10-0-1-121.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.567768ms)
Dec 22 22:19:15.147: INFO: (7) /api/v1/nodes/ip-10-0-1-121.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.448924ms)
Dec 22 22:19:15.151: INFO: (8) /api/v1/nodes/ip-10-0-1-121.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.507259ms)
Dec 22 22:19:15.154: INFO: (9) /api/v1/nodes/ip-10-0-1-121.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.470414ms)
Dec 22 22:19:15.158: INFO: (10) /api/v1/nodes/ip-10-0-1-121.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.469077ms)
Dec 22 22:19:15.162: INFO: (11) /api/v1/nodes/ip-10-0-1-121.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.59621ms)
Dec 22 22:19:15.166: INFO: (12) /api/v1/nodes/ip-10-0-1-121.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.602625ms)
Dec 22 22:19:15.169: INFO: (13) /api/v1/nodes/ip-10-0-1-121.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.538525ms)
Dec 22 22:19:15.173: INFO: (14) /api/v1/nodes/ip-10-0-1-121.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.539385ms)
Dec 22 22:19:15.177: INFO: (15) /api/v1/nodes/ip-10-0-1-121.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.433391ms)
Dec 22 22:19:15.181: INFO: (16) /api/v1/nodes/ip-10-0-1-121.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.488653ms)
Dec 22 22:19:15.184: INFO: (17) /api/v1/nodes/ip-10-0-1-121.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.35703ms)
Dec 22 22:19:15.188: INFO: (18) /api/v1/nodes/ip-10-0-1-121.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.477223ms)
Dec 22 22:19:15.191: INFO: (19) /api/v1/nodes/ip-10-0-1-121.us-west-2.compute.internal:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.378327ms)
[AfterEach] version v1
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:19:15.192: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-5110" for this suite.
Dec 22 22:19:21.215: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:19:21.280: INFO: namespace proxy-5110 deletion completed in 6.08486444s

â€¢ [SLOW TEST:6.261 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:19:21.281: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test env composition
Dec 22 22:19:21.328: INFO: Waiting up to 5m0s for pod "var-expansion-7496e231-348a-4061-8519-4fc93e431211" in namespace "var-expansion-3812" to be "success or failure"
Dec 22 22:19:21.336: INFO: Pod "var-expansion-7496e231-348a-4061-8519-4fc93e431211": Phase="Pending", Reason="", readiness=false. Elapsed: 6.555394ms
Dec 22 22:19:23.340: INFO: Pod "var-expansion-7496e231-348a-4061-8519-4fc93e431211": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010364926s
STEP: Saw pod success
Dec 22 22:19:23.340: INFO: Pod "var-expansion-7496e231-348a-4061-8519-4fc93e431211" satisfied condition "success or failure"
Dec 22 22:19:23.342: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod var-expansion-7496e231-348a-4061-8519-4fc93e431211 container dapi-container: <nil>
STEP: delete the pod
Dec 22 22:19:23.368: INFO: Waiting for pod var-expansion-7496e231-348a-4061-8519-4fc93e431211 to disappear
Dec 22 22:19:23.372: INFO: Pod var-expansion-7496e231-348a-4061-8519-4fc93e431211 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:19:23.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-3812" for this suite.
Dec 22 22:19:29.388: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:19:29.501: INFO: namespace var-expansion-3812 deletion completed in 6.121508552s

â€¢ [SLOW TEST:8.220 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:19:29.501: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating replication controller svc-latency-rc in namespace svc-latency-6396
I1222 22:19:29.525566      15 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: svc-latency-6396, replica count: 1
I1222 22:19:30.576133      15 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1222 22:19:31.576430      15 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 22 22:19:31.684: INFO: Created: latency-svc-2vv2f
Dec 22 22:19:31.691: INFO: Got endpoints: latency-svc-2vv2f [14.276854ms]
Dec 22 22:19:31.701: INFO: Created: latency-svc-9p5n4
Dec 22 22:19:31.709: INFO: Got endpoints: latency-svc-9p5n4 [18.207252ms]
Dec 22 22:19:31.711: INFO: Created: latency-svc-nfjq8
Dec 22 22:19:31.719: INFO: Created: latency-svc-9lbh8
Dec 22 22:19:31.720: INFO: Got endpoints: latency-svc-nfjq8 [29.233575ms]
Dec 22 22:19:31.725: INFO: Got endpoints: latency-svc-9lbh8 [34.156495ms]
Dec 22 22:19:31.730: INFO: Created: latency-svc-9hqn8
Dec 22 22:19:31.738: INFO: Created: latency-svc-cfwhw
Dec 22 22:19:31.739: INFO: Got endpoints: latency-svc-cfwhw [48.355889ms]
Dec 22 22:19:31.740: INFO: Got endpoints: latency-svc-9hqn8 [48.708542ms]
Dec 22 22:19:31.749: INFO: Created: latency-svc-xcvjs
Dec 22 22:19:31.754: INFO: Created: latency-svc-9lrt6
Dec 22 22:19:31.756: INFO: Got endpoints: latency-svc-xcvjs [64.800887ms]
Dec 22 22:19:31.756: INFO: Got endpoints: latency-svc-9lrt6 [65.158228ms]
Dec 22 22:19:31.767: INFO: Created: latency-svc-cdt8l
Dec 22 22:19:31.773: INFO: Got endpoints: latency-svc-cdt8l [81.392864ms]
Dec 22 22:19:31.774: INFO: Created: latency-svc-6f5xp
Dec 22 22:19:31.783: INFO: Got endpoints: latency-svc-6f5xp [92.204423ms]
Dec 22 22:19:31.783: INFO: Created: latency-svc-qgg48
Dec 22 22:19:31.792: INFO: Created: latency-svc-96qh4
Dec 22 22:19:31.801: INFO: Created: latency-svc-mcjjm
Dec 22 22:19:31.813: INFO: Got endpoints: latency-svc-96qh4 [121.489541ms]
Dec 22 22:19:31.813: INFO: Got endpoints: latency-svc-mcjjm [121.573849ms]
Dec 22 22:19:31.813: INFO: Got endpoints: latency-svc-qgg48 [122.081037ms]
Dec 22 22:19:31.817: INFO: Created: latency-svc-szztq
Dec 22 22:19:31.819: INFO: Got endpoints: latency-svc-szztq [128.32517ms]
Dec 22 22:19:31.821: INFO: Created: latency-svc-chvlp
Dec 22 22:19:31.830: INFO: Got endpoints: latency-svc-chvlp [139.120209ms]
Dec 22 22:19:31.834: INFO: Created: latency-svc-cvx6b
Dec 22 22:19:31.837: INFO: Created: latency-svc-vtjwq
Dec 22 22:19:31.841: INFO: Got endpoints: latency-svc-vtjwq [132.337114ms]
Dec 22 22:19:31.842: INFO: Got endpoints: latency-svc-cvx6b [150.508982ms]
Dec 22 22:19:31.847: INFO: Created: latency-svc-hwstb
Dec 22 22:19:31.857: INFO: Created: latency-svc-nrm2n
Dec 22 22:19:31.859: INFO: Created: latency-svc-c7j6c
Dec 22 22:19:31.866: INFO: Created: latency-svc-c5rxg
Dec 22 22:19:31.871: INFO: Got endpoints: latency-svc-hwstb [145.58227ms]
Dec 22 22:19:31.871: INFO: Got endpoints: latency-svc-nrm2n [150.611021ms]
Dec 22 22:19:31.871: INFO: Got endpoints: latency-svc-c7j6c [131.688491ms]
Dec 22 22:19:31.872: INFO: Got endpoints: latency-svc-c5rxg [132.479328ms]
Dec 22 22:19:31.878: INFO: Created: latency-svc-k7bq2
Dec 22 22:19:31.888: INFO: Got endpoints: latency-svc-k7bq2 [132.561497ms]
Dec 22 22:19:31.902: INFO: Created: latency-svc-jfrjd
Dec 22 22:19:31.902: INFO: Created: latency-svc-6sdpp
Dec 22 22:19:31.912: INFO: Got endpoints: latency-svc-jfrjd [139.851144ms]
Dec 22 22:19:31.925: INFO: Created: latency-svc-pn7s5
Dec 22 22:19:31.926: INFO: Got endpoints: latency-svc-6sdpp [170.148714ms]
Dec 22 22:19:31.927: INFO: Created: latency-svc-c4kbc
Dec 22 22:19:31.929: INFO: Got endpoints: latency-svc-c4kbc [146.365185ms]
Dec 22 22:19:31.936: INFO: Created: latency-svc-fw4kz
Dec 22 22:19:31.940: INFO: Got endpoints: latency-svc-pn7s5 [127.744084ms]
Dec 22 22:19:31.954: INFO: Created: latency-svc-fx76r
Dec 22 22:19:31.954: INFO: Got endpoints: latency-svc-fw4kz [140.545152ms]
Dec 22 22:19:31.956: INFO: Created: latency-svc-sw2h7
Dec 22 22:19:31.967: INFO: Got endpoints: latency-svc-sw2h7 [154.659395ms]
Dec 22 22:19:31.968: INFO: Got endpoints: latency-svc-fx76r [148.66302ms]
Dec 22 22:19:31.976: INFO: Created: latency-svc-2cxsp
Dec 22 22:19:31.978: INFO: Got endpoints: latency-svc-2cxsp [147.765515ms]
Dec 22 22:19:31.986: INFO: Created: latency-svc-mdjd8
Dec 22 22:19:31.986: INFO: Created: latency-svc-mxswg
Dec 22 22:19:31.992: INFO: Created: latency-svc-lm8r2
Dec 22 22:19:31.995: INFO: Got endpoints: latency-svc-mdjd8 [153.198985ms]
Dec 22 22:19:31.995: INFO: Got endpoints: latency-svc-mxswg [152.798488ms]
Dec 22 22:19:32.000: INFO: Got endpoints: latency-svc-lm8r2 [129.239439ms]
Dec 22 22:19:32.002: INFO: Created: latency-svc-kf9sg
Dec 22 22:19:32.008: INFO: Created: latency-svc-ztrqn
Dec 22 22:19:32.015: INFO: Created: latency-svc-lbrww
Dec 22 22:19:32.026: INFO: Got endpoints: latency-svc-ztrqn [155.315964ms]
Dec 22 22:19:32.027: INFO: Got endpoints: latency-svc-kf9sg [155.856461ms]
Dec 22 22:19:32.027: INFO: Got endpoints: latency-svc-lbrww [154.403936ms]
Dec 22 22:19:32.034: INFO: Created: latency-svc-rrhmj
Dec 22 22:19:32.041: INFO: Created: latency-svc-n82j7
Dec 22 22:19:32.047: INFO: Got endpoints: latency-svc-rrhmj [158.37573ms]
Dec 22 22:19:32.057: INFO: Created: latency-svc-zmgh5
Dec 22 22:19:32.057: INFO: Created: latency-svc-w2q9m
Dec 22 22:19:32.057: INFO: Created: latency-svc-zbwmk
Dec 22 22:19:32.072: INFO: Created: latency-svc-pvlfq
Dec 22 22:19:32.076: INFO: Created: latency-svc-xf99f
Dec 22 22:19:32.083: INFO: Created: latency-svc-k9qdn
Dec 22 22:19:32.092: INFO: Created: latency-svc-tbb9x
Dec 22 22:19:32.093: INFO: Created: latency-svc-z5ttl
Dec 22 22:19:32.097: INFO: Got endpoints: latency-svc-n82j7 [184.122429ms]
Dec 22 22:19:32.110: INFO: Created: latency-svc-9mpjq
Dec 22 22:19:32.113: INFO: Created: latency-svc-6t2qk
Dec 22 22:19:32.115: INFO: Created: latency-svc-p56gw
Dec 22 22:19:32.122: INFO: Created: latency-svc-fp6wj
Dec 22 22:19:32.132: INFO: Created: latency-svc-9cfzt
Dec 22 22:19:32.145: INFO: Created: latency-svc-52757
Dec 22 22:19:32.151: INFO: Got endpoints: latency-svc-zbwmk [210.369873ms]
Dec 22 22:19:32.152: INFO: Created: latency-svc-rfwmg
Dec 22 22:19:32.165: INFO: Created: latency-svc-rlzq6
Dec 22 22:19:32.189: INFO: Got endpoints: latency-svc-zmgh5 [262.447024ms]
Dec 22 22:19:32.198: INFO: Created: latency-svc-lpx66
Dec 22 22:19:32.239: INFO: Got endpoints: latency-svc-w2q9m [309.849982ms]
Dec 22 22:19:32.250: INFO: Created: latency-svc-zr7q2
Dec 22 22:19:32.290: INFO: Got endpoints: latency-svc-xf99f [336.256586ms]
Dec 22 22:19:32.347: INFO: Created: latency-svc-26ftz
Dec 22 22:19:32.350: INFO: Got endpoints: latency-svc-pvlfq [382.236719ms]
Dec 22 22:19:32.360: INFO: Created: latency-svc-6z6m6
Dec 22 22:19:32.389: INFO: Got endpoints: latency-svc-tbb9x [421.935272ms]
Dec 22 22:19:32.399: INFO: Created: latency-svc-kj8xv
Dec 22 22:19:32.438: INFO: Got endpoints: latency-svc-k9qdn [460.097047ms]
Dec 22 22:19:32.446: INFO: Created: latency-svc-qrpcn
Dec 22 22:19:32.489: INFO: Got endpoints: latency-svc-z5ttl [492.734842ms]
Dec 22 22:19:32.495: INFO: Created: latency-svc-55l8t
Dec 22 22:19:32.538: INFO: Got endpoints: latency-svc-6t2qk [543.562783ms]
Dec 22 22:19:32.547: INFO: Created: latency-svc-rjz5c
Dec 22 22:19:32.588: INFO: Got endpoints: latency-svc-9mpjq [587.934699ms]
Dec 22 22:19:32.596: INFO: Created: latency-svc-hj8v4
Dec 22 22:19:32.639: INFO: Got endpoints: latency-svc-p56gw [612.023165ms]
Dec 22 22:19:32.645: INFO: Created: latency-svc-tvwnq
Dec 22 22:19:32.688: INFO: Got endpoints: latency-svc-fp6wj [661.258762ms]
Dec 22 22:19:32.694: INFO: Created: latency-svc-kflpf
Dec 22 22:19:32.738: INFO: Got endpoints: latency-svc-9cfzt [711.681685ms]
Dec 22 22:19:32.744: INFO: Created: latency-svc-nhl5w
Dec 22 22:19:32.788: INFO: Got endpoints: latency-svc-52757 [741.002933ms]
Dec 22 22:19:32.798: INFO: Created: latency-svc-zqssc
Dec 22 22:19:32.841: INFO: Got endpoints: latency-svc-rfwmg [743.969366ms]
Dec 22 22:19:32.847: INFO: Created: latency-svc-vknzv
Dec 22 22:19:32.888: INFO: Got endpoints: latency-svc-rlzq6 [737.512975ms]
Dec 22 22:19:32.895: INFO: Created: latency-svc-24wtd
Dec 22 22:19:32.939: INFO: Got endpoints: latency-svc-lpx66 [749.476808ms]
Dec 22 22:19:32.945: INFO: Created: latency-svc-qswlh
Dec 22 22:19:32.989: INFO: Got endpoints: latency-svc-zr7q2 [749.511539ms]
Dec 22 22:19:32.998: INFO: Created: latency-svc-g4zgt
Dec 22 22:19:33.038: INFO: Got endpoints: latency-svc-26ftz [748.22759ms]
Dec 22 22:19:33.046: INFO: Created: latency-svc-ttqc8
Dec 22 22:19:33.090: INFO: Got endpoints: latency-svc-6z6m6 [739.712902ms]
Dec 22 22:19:33.097: INFO: Created: latency-svc-8v7f8
Dec 22 22:19:33.139: INFO: Got endpoints: latency-svc-kj8xv [749.501327ms]
Dec 22 22:19:33.146: INFO: Created: latency-svc-qhd55
Dec 22 22:19:33.190: INFO: Got endpoints: latency-svc-qrpcn [751.599716ms]
Dec 22 22:19:33.197: INFO: Created: latency-svc-t4v4s
Dec 22 22:19:33.240: INFO: Got endpoints: latency-svc-55l8t [750.947539ms]
Dec 22 22:19:33.246: INFO: Created: latency-svc-wb84c
Dec 22 22:19:33.289: INFO: Got endpoints: latency-svc-rjz5c [750.520046ms]
Dec 22 22:19:33.298: INFO: Created: latency-svc-qw9x8
Dec 22 22:19:33.339: INFO: Got endpoints: latency-svc-hj8v4 [750.924879ms]
Dec 22 22:19:33.348: INFO: Created: latency-svc-xwk7g
Dec 22 22:19:33.390: INFO: Got endpoints: latency-svc-tvwnq [751.275224ms]
Dec 22 22:19:33.409: INFO: Created: latency-svc-qhvvv
Dec 22 22:19:33.446: INFO: Got endpoints: latency-svc-kflpf [757.807593ms]
Dec 22 22:19:33.456: INFO: Created: latency-svc-nm4wt
Dec 22 22:19:33.494: INFO: Got endpoints: latency-svc-nhl5w [755.508751ms]
Dec 22 22:19:33.505: INFO: Created: latency-svc-jvb5k
Dec 22 22:19:33.543: INFO: Got endpoints: latency-svc-zqssc [754.282176ms]
Dec 22 22:19:33.563: INFO: Created: latency-svc-sg2td
Dec 22 22:19:33.597: INFO: Got endpoints: latency-svc-vknzv [756.276052ms]
Dec 22 22:19:33.660: INFO: Got endpoints: latency-svc-24wtd [771.160662ms]
Dec 22 22:19:33.668: INFO: Created: latency-svc-hf7h4
Dec 22 22:19:33.674: INFO: Created: latency-svc-7bj77
Dec 22 22:19:33.718: INFO: Got endpoints: latency-svc-qswlh [779.273876ms]
Dec 22 22:19:33.756: INFO: Got endpoints: latency-svc-g4zgt [767.595058ms]
Dec 22 22:19:33.761: INFO: Created: latency-svc-phrbs
Dec 22 22:19:33.765: INFO: Created: latency-svc-p8tlk
Dec 22 22:19:33.790: INFO: Got endpoints: latency-svc-ttqc8 [751.417133ms]
Dec 22 22:19:33.805: INFO: Created: latency-svc-26qx8
Dec 22 22:19:33.838: INFO: Got endpoints: latency-svc-8v7f8 [748.292337ms]
Dec 22 22:19:33.845: INFO: Created: latency-svc-htvbq
Dec 22 22:19:33.890: INFO: Got endpoints: latency-svc-qhd55 [750.579758ms]
Dec 22 22:19:33.900: INFO: Created: latency-svc-g6ppj
Dec 22 22:19:33.938: INFO: Got endpoints: latency-svc-t4v4s [747.889196ms]
Dec 22 22:19:33.946: INFO: Created: latency-svc-cqh4w
Dec 22 22:19:33.988: INFO: Got endpoints: latency-svc-wb84c [748.527272ms]
Dec 22 22:19:33.994: INFO: Created: latency-svc-9jh9v
Dec 22 22:19:34.039: INFO: Got endpoints: latency-svc-qw9x8 [749.740469ms]
Dec 22 22:19:34.044: INFO: Created: latency-svc-ftz9h
Dec 22 22:19:34.093: INFO: Got endpoints: latency-svc-xwk7g [753.694918ms]
Dec 22 22:19:34.137: INFO: Created: latency-svc-828vt
Dec 22 22:19:34.144: INFO: Got endpoints: latency-svc-qhvvv [754.23769ms]
Dec 22 22:19:34.151: INFO: Created: latency-svc-qsmdd
Dec 22 22:19:34.188: INFO: Got endpoints: latency-svc-nm4wt [742.34802ms]
Dec 22 22:19:34.195: INFO: Created: latency-svc-w679x
Dec 22 22:19:34.239: INFO: Got endpoints: latency-svc-jvb5k [745.615887ms]
Dec 22 22:19:34.247: INFO: Created: latency-svc-rknbk
Dec 22 22:19:34.289: INFO: Got endpoints: latency-svc-sg2td [745.930783ms]
Dec 22 22:19:34.297: INFO: Created: latency-svc-nxgsq
Dec 22 22:19:34.339: INFO: Got endpoints: latency-svc-hf7h4 [679.312499ms]
Dec 22 22:19:34.344: INFO: Created: latency-svc-w94cj
Dec 22 22:19:34.388: INFO: Got endpoints: latency-svc-7bj77 [791.113358ms]
Dec 22 22:19:34.399: INFO: Created: latency-svc-mf45s
Dec 22 22:19:34.438: INFO: Got endpoints: latency-svc-phrbs [719.458828ms]
Dec 22 22:19:34.444: INFO: Created: latency-svc-fn78d
Dec 22 22:19:34.488: INFO: Got endpoints: latency-svc-p8tlk [731.652117ms]
Dec 22 22:19:34.495: INFO: Created: latency-svc-wwg9j
Dec 22 22:19:34.538: INFO: Got endpoints: latency-svc-26qx8 [748.369667ms]
Dec 22 22:19:34.545: INFO: Created: latency-svc-hwsvt
Dec 22 22:19:34.588: INFO: Got endpoints: latency-svc-htvbq [749.851383ms]
Dec 22 22:19:34.595: INFO: Created: latency-svc-9hc88
Dec 22 22:19:34.638: INFO: Got endpoints: latency-svc-g6ppj [748.585559ms]
Dec 22 22:19:34.644: INFO: Created: latency-svc-rp9vn
Dec 22 22:19:34.689: INFO: Got endpoints: latency-svc-cqh4w [750.617266ms]
Dec 22 22:19:34.698: INFO: Created: latency-svc-9kjtg
Dec 22 22:19:34.739: INFO: Got endpoints: latency-svc-9jh9v [750.538115ms]
Dec 22 22:19:34.746: INFO: Created: latency-svc-4b66j
Dec 22 22:19:34.788: INFO: Got endpoints: latency-svc-ftz9h [749.39828ms]
Dec 22 22:19:34.797: INFO: Created: latency-svc-4v7h8
Dec 22 22:19:34.838: INFO: Got endpoints: latency-svc-828vt [722.310593ms]
Dec 22 22:19:34.845: INFO: Created: latency-svc-jj4fk
Dec 22 22:19:34.889: INFO: Got endpoints: latency-svc-qsmdd [744.738436ms]
Dec 22 22:19:34.902: INFO: Created: latency-svc-6qtkb
Dec 22 22:19:34.945: INFO: Got endpoints: latency-svc-w679x [757.010502ms]
Dec 22 22:19:34.968: INFO: Created: latency-svc-qtzbl
Dec 22 22:19:34.999: INFO: Got endpoints: latency-svc-rknbk [759.779347ms]
Dec 22 22:19:35.007: INFO: Created: latency-svc-4wqpt
Dec 22 22:19:35.040: INFO: Got endpoints: latency-svc-nxgsq [751.049092ms]
Dec 22 22:19:35.047: INFO: Created: latency-svc-pjck8
Dec 22 22:19:35.095: INFO: Got endpoints: latency-svc-w94cj [756.147238ms]
Dec 22 22:19:35.105: INFO: Created: latency-svc-pw5n9
Dec 22 22:19:35.138: INFO: Got endpoints: latency-svc-mf45s [749.480253ms]
Dec 22 22:19:35.144: INFO: Created: latency-svc-m9gw7
Dec 22 22:19:35.189: INFO: Got endpoints: latency-svc-fn78d [751.526598ms]
Dec 22 22:19:35.196: INFO: Created: latency-svc-dkkls
Dec 22 22:19:35.239: INFO: Got endpoints: latency-svc-wwg9j [750.338977ms]
Dec 22 22:19:35.247: INFO: Created: latency-svc-l7fcg
Dec 22 22:19:35.288: INFO: Got endpoints: latency-svc-hwsvt [749.904662ms]
Dec 22 22:19:35.295: INFO: Created: latency-svc-hdp2s
Dec 22 22:19:35.338: INFO: Got endpoints: latency-svc-9hc88 [749.865923ms]
Dec 22 22:19:35.347: INFO: Created: latency-svc-kfflp
Dec 22 22:19:35.389: INFO: Got endpoints: latency-svc-rp9vn [750.407851ms]
Dec 22 22:19:35.394: INFO: Created: latency-svc-4pxf7
Dec 22 22:19:35.438: INFO: Got endpoints: latency-svc-9kjtg [749.779ms]
Dec 22 22:19:35.450: INFO: Created: latency-svc-grbbm
Dec 22 22:19:35.492: INFO: Got endpoints: latency-svc-4b66j [752.711059ms]
Dec 22 22:19:35.501: INFO: Created: latency-svc-hcv6w
Dec 22 22:19:35.541: INFO: Got endpoints: latency-svc-4v7h8 [753.087888ms]
Dec 22 22:19:35.557: INFO: Created: latency-svc-9bf8c
Dec 22 22:19:35.590: INFO: Got endpoints: latency-svc-jj4fk [751.775236ms]
Dec 22 22:19:35.606: INFO: Created: latency-svc-ng2x7
Dec 22 22:19:35.638: INFO: Got endpoints: latency-svc-6qtkb [749.154229ms]
Dec 22 22:19:35.645: INFO: Created: latency-svc-6hllt
Dec 22 22:19:35.689: INFO: Got endpoints: latency-svc-qtzbl [743.146396ms]
Dec 22 22:19:35.695: INFO: Created: latency-svc-8xrdd
Dec 22 22:19:35.739: INFO: Got endpoints: latency-svc-4wqpt [739.20474ms]
Dec 22 22:19:35.744: INFO: Created: latency-svc-9jf6h
Dec 22 22:19:35.788: INFO: Got endpoints: latency-svc-pjck8 [748.395514ms]
Dec 22 22:19:35.796: INFO: Created: latency-svc-w9f8t
Dec 22 22:19:35.839: INFO: Got endpoints: latency-svc-pw5n9 [744.117909ms]
Dec 22 22:19:35.845: INFO: Created: latency-svc-v2q5d
Dec 22 22:19:35.889: INFO: Got endpoints: latency-svc-m9gw7 [750.839669ms]
Dec 22 22:19:35.894: INFO: Created: latency-svc-k4rgd
Dec 22 22:19:35.938: INFO: Got endpoints: latency-svc-dkkls [748.928319ms]
Dec 22 22:19:35.946: INFO: Created: latency-svc-hvh8s
Dec 22 22:19:35.989: INFO: Got endpoints: latency-svc-l7fcg [750.098083ms]
Dec 22 22:19:35.996: INFO: Created: latency-svc-bcbx6
Dec 22 22:19:36.038: INFO: Got endpoints: latency-svc-hdp2s [750.096694ms]
Dec 22 22:19:36.045: INFO: Created: latency-svc-pt449
Dec 22 22:19:36.089: INFO: Got endpoints: latency-svc-kfflp [750.369629ms]
Dec 22 22:19:36.095: INFO: Created: latency-svc-p2pm4
Dec 22 22:19:36.138: INFO: Got endpoints: latency-svc-4pxf7 [749.523313ms]
Dec 22 22:19:36.145: INFO: Created: latency-svc-pwsxr
Dec 22 22:19:36.188: INFO: Got endpoints: latency-svc-grbbm [749.548089ms]
Dec 22 22:19:36.195: INFO: Created: latency-svc-nmjfv
Dec 22 22:19:36.239: INFO: Got endpoints: latency-svc-hcv6w [747.086035ms]
Dec 22 22:19:36.244: INFO: Created: latency-svc-jnlqz
Dec 22 22:19:36.289: INFO: Got endpoints: latency-svc-9bf8c [747.560154ms]
Dec 22 22:19:36.296: INFO: Created: latency-svc-jv9mg
Dec 22 22:19:36.338: INFO: Got endpoints: latency-svc-ng2x7 [748.182685ms]
Dec 22 22:19:36.345: INFO: Created: latency-svc-btflg
Dec 22 22:19:36.389: INFO: Got endpoints: latency-svc-6hllt [750.306099ms]
Dec 22 22:19:36.395: INFO: Created: latency-svc-tdksb
Dec 22 22:19:36.439: INFO: Got endpoints: latency-svc-8xrdd [750.393411ms]
Dec 22 22:19:36.445: INFO: Created: latency-svc-lbmxh
Dec 22 22:19:36.489: INFO: Got endpoints: latency-svc-9jf6h [750.241758ms]
Dec 22 22:19:36.495: INFO: Created: latency-svc-56x7k
Dec 22 22:19:36.539: INFO: Got endpoints: latency-svc-w9f8t [751.04296ms]
Dec 22 22:19:36.545: INFO: Created: latency-svc-mb6d7
Dec 22 22:19:36.588: INFO: Got endpoints: latency-svc-v2q5d [748.780611ms]
Dec 22 22:19:36.593: INFO: Created: latency-svc-n7fxj
Dec 22 22:19:36.638: INFO: Got endpoints: latency-svc-k4rgd [749.299161ms]
Dec 22 22:19:36.667: INFO: Created: latency-svc-jbrdd
Dec 22 22:19:36.688: INFO: Got endpoints: latency-svc-hvh8s [749.830647ms]
Dec 22 22:19:36.695: INFO: Created: latency-svc-ff5rr
Dec 22 22:19:36.738: INFO: Got endpoints: latency-svc-bcbx6 [749.226537ms]
Dec 22 22:19:36.744: INFO: Created: latency-svc-q5xn5
Dec 22 22:19:36.788: INFO: Got endpoints: latency-svc-pt449 [749.915828ms]
Dec 22 22:19:36.796: INFO: Created: latency-svc-tjdz7
Dec 22 22:19:36.839: INFO: Got endpoints: latency-svc-p2pm4 [749.840844ms]
Dec 22 22:19:36.846: INFO: Created: latency-svc-7tgpj
Dec 22 22:19:36.889: INFO: Got endpoints: latency-svc-pwsxr [750.552718ms]
Dec 22 22:19:36.896: INFO: Created: latency-svc-628ln
Dec 22 22:19:36.938: INFO: Got endpoints: latency-svc-nmjfv [750.34254ms]
Dec 22 22:19:36.945: INFO: Created: latency-svc-xfbhx
Dec 22 22:19:36.988: INFO: Got endpoints: latency-svc-jnlqz [749.163309ms]
Dec 22 22:19:36.995: INFO: Created: latency-svc-7l92g
Dec 22 22:19:37.039: INFO: Got endpoints: latency-svc-jv9mg [749.678791ms]
Dec 22 22:19:37.048: INFO: Created: latency-svc-25v6j
Dec 22 22:19:37.089: INFO: Got endpoints: latency-svc-btflg [749.947772ms]
Dec 22 22:19:37.098: INFO: Created: latency-svc-q57n9
Dec 22 22:19:37.138: INFO: Got endpoints: latency-svc-tdksb [748.970441ms]
Dec 22 22:19:37.145: INFO: Created: latency-svc-h8zgs
Dec 22 22:19:37.189: INFO: Got endpoints: latency-svc-lbmxh [749.592267ms]
Dec 22 22:19:37.196: INFO: Created: latency-svc-296nc
Dec 22 22:19:37.239: INFO: Got endpoints: latency-svc-56x7k [749.645053ms]
Dec 22 22:19:37.246: INFO: Created: latency-svc-tmt4f
Dec 22 22:19:37.288: INFO: Got endpoints: latency-svc-mb6d7 [748.780359ms]
Dec 22 22:19:37.296: INFO: Created: latency-svc-w5blb
Dec 22 22:19:37.338: INFO: Got endpoints: latency-svc-n7fxj [749.940285ms]
Dec 22 22:19:37.345: INFO: Created: latency-svc-xdstd
Dec 22 22:19:37.389: INFO: Got endpoints: latency-svc-jbrdd [751.205716ms]
Dec 22 22:19:37.397: INFO: Created: latency-svc-v65f4
Dec 22 22:19:37.438: INFO: Got endpoints: latency-svc-ff5rr [749.821727ms]
Dec 22 22:19:37.446: INFO: Created: latency-svc-bnjv4
Dec 22 22:19:37.489: INFO: Got endpoints: latency-svc-q5xn5 [750.692534ms]
Dec 22 22:19:37.495: INFO: Created: latency-svc-w4jtt
Dec 22 22:19:37.539: INFO: Got endpoints: latency-svc-tjdz7 [750.425766ms]
Dec 22 22:19:37.545: INFO: Created: latency-svc-rkvfz
Dec 22 22:19:37.588: INFO: Got endpoints: latency-svc-7tgpj [749.181771ms]
Dec 22 22:19:37.594: INFO: Created: latency-svc-6tvmd
Dec 22 22:19:37.639: INFO: Got endpoints: latency-svc-628ln [749.734306ms]
Dec 22 22:19:37.644: INFO: Created: latency-svc-wcclk
Dec 22 22:19:37.688: INFO: Got endpoints: latency-svc-xfbhx [749.307636ms]
Dec 22 22:19:37.695: INFO: Created: latency-svc-g7zdr
Dec 22 22:19:37.739: INFO: Got endpoints: latency-svc-7l92g [751.422227ms]
Dec 22 22:19:37.745: INFO: Created: latency-svc-vcmt8
Dec 22 22:19:37.789: INFO: Got endpoints: latency-svc-25v6j [750.315005ms]
Dec 22 22:19:37.794: INFO: Created: latency-svc-dprkk
Dec 22 22:19:37.838: INFO: Got endpoints: latency-svc-q57n9 [749.566824ms]
Dec 22 22:19:37.846: INFO: Created: latency-svc-42hgg
Dec 22 22:19:37.888: INFO: Got endpoints: latency-svc-h8zgs [750.782504ms]
Dec 22 22:19:37.894: INFO: Created: latency-svc-m6xff
Dec 22 22:19:37.939: INFO: Got endpoints: latency-svc-296nc [750.165541ms]
Dec 22 22:19:37.945: INFO: Created: latency-svc-tx6n2
Dec 22 22:19:37.988: INFO: Got endpoints: latency-svc-tmt4f [749.300861ms]
Dec 22 22:19:37.994: INFO: Created: latency-svc-wp4rl
Dec 22 22:19:38.038: INFO: Got endpoints: latency-svc-w5blb [749.841756ms]
Dec 22 22:19:38.045: INFO: Created: latency-svc-x77v9
Dec 22 22:19:38.088: INFO: Got endpoints: latency-svc-xdstd [750.136331ms]
Dec 22 22:19:38.094: INFO: Created: latency-svc-bbxrg
Dec 22 22:19:38.138: INFO: Got endpoints: latency-svc-v65f4 [748.645985ms]
Dec 22 22:19:38.145: INFO: Created: latency-svc-cv765
Dec 22 22:19:38.188: INFO: Got endpoints: latency-svc-bnjv4 [750.148135ms]
Dec 22 22:19:38.194: INFO: Created: latency-svc-chlqg
Dec 22 22:19:38.238: INFO: Got endpoints: latency-svc-w4jtt [749.085507ms]
Dec 22 22:19:38.246: INFO: Created: latency-svc-jnf6x
Dec 22 22:19:38.289: INFO: Got endpoints: latency-svc-rkvfz [750.175785ms]
Dec 22 22:19:38.295: INFO: Created: latency-svc-jtb65
Dec 22 22:19:38.339: INFO: Got endpoints: latency-svc-6tvmd [750.62205ms]
Dec 22 22:19:38.346: INFO: Created: latency-svc-5d8kf
Dec 22 22:19:38.388: INFO: Got endpoints: latency-svc-wcclk [749.669531ms]
Dec 22 22:19:38.395: INFO: Created: latency-svc-w7ttw
Dec 22 22:19:38.439: INFO: Got endpoints: latency-svc-g7zdr [751.44979ms]
Dec 22 22:19:38.446: INFO: Created: latency-svc-jlmqg
Dec 22 22:19:38.488: INFO: Got endpoints: latency-svc-vcmt8 [748.847874ms]
Dec 22 22:19:38.495: INFO: Created: latency-svc-4qlcn
Dec 22 22:19:38.539: INFO: Got endpoints: latency-svc-dprkk [749.608695ms]
Dec 22 22:19:38.548: INFO: Created: latency-svc-s229j
Dec 22 22:19:38.590: INFO: Got endpoints: latency-svc-42hgg [752.004722ms]
Dec 22 22:19:38.596: INFO: Created: latency-svc-2vc2h
Dec 22 22:19:38.640: INFO: Got endpoints: latency-svc-m6xff [751.06007ms]
Dec 22 22:19:38.646: INFO: Created: latency-svc-cpvjl
Dec 22 22:19:38.689: INFO: Got endpoints: latency-svc-tx6n2 [749.633451ms]
Dec 22 22:19:38.695: INFO: Created: latency-svc-w5klk
Dec 22 22:19:38.740: INFO: Got endpoints: latency-svc-wp4rl [751.921071ms]
Dec 22 22:19:38.748: INFO: Created: latency-svc-jnffx
Dec 22 22:19:38.788: INFO: Got endpoints: latency-svc-x77v9 [750.358566ms]
Dec 22 22:19:38.795: INFO: Created: latency-svc-6dnhq
Dec 22 22:19:38.839: INFO: Got endpoints: latency-svc-bbxrg [750.263372ms]
Dec 22 22:19:38.844: INFO: Created: latency-svc-gsg2v
Dec 22 22:19:38.889: INFO: Got endpoints: latency-svc-cv765 [750.543494ms]
Dec 22 22:19:38.897: INFO: Created: latency-svc-6p6wc
Dec 22 22:19:38.939: INFO: Got endpoints: latency-svc-chlqg [750.869928ms]
Dec 22 22:19:38.948: INFO: Created: latency-svc-nlc8d
Dec 22 22:19:38.989: INFO: Got endpoints: latency-svc-jnf6x [750.945356ms]
Dec 22 22:19:38.999: INFO: Created: latency-svc-cbth6
Dec 22 22:19:39.039: INFO: Got endpoints: latency-svc-jtb65 [749.851274ms]
Dec 22 22:19:39.048: INFO: Created: latency-svc-hpsls
Dec 22 22:19:39.089: INFO: Got endpoints: latency-svc-5d8kf [750.253457ms]
Dec 22 22:19:39.096: INFO: Created: latency-svc-9khdq
Dec 22 22:19:39.141: INFO: Got endpoints: latency-svc-w7ttw [752.806363ms]
Dec 22 22:19:39.149: INFO: Created: latency-svc-dwprx
Dec 22 22:19:39.189: INFO: Got endpoints: latency-svc-jlmqg [749.236064ms]
Dec 22 22:19:39.195: INFO: Created: latency-svc-tmqcn
Dec 22 22:19:39.238: INFO: Got endpoints: latency-svc-4qlcn [750.032594ms]
Dec 22 22:19:39.245: INFO: Created: latency-svc-xzxms
Dec 22 22:19:39.288: INFO: Got endpoints: latency-svc-s229j [749.706536ms]
Dec 22 22:19:39.294: INFO: Created: latency-svc-drpwp
Dec 22 22:19:39.338: INFO: Got endpoints: latency-svc-2vc2h [747.918027ms]
Dec 22 22:19:39.344: INFO: Created: latency-svc-dhrhs
Dec 22 22:19:39.388: INFO: Got endpoints: latency-svc-cpvjl [748.784784ms]
Dec 22 22:19:39.397: INFO: Created: latency-svc-5dbvr
Dec 22 22:19:39.439: INFO: Got endpoints: latency-svc-w5klk [750.143496ms]
Dec 22 22:19:39.446: INFO: Created: latency-svc-n6zxc
Dec 22 22:19:39.488: INFO: Got endpoints: latency-svc-jnffx [748.285366ms]
Dec 22 22:19:39.494: INFO: Created: latency-svc-glsvt
Dec 22 22:19:39.538: INFO: Got endpoints: latency-svc-6dnhq [749.930654ms]
Dec 22 22:19:39.588: INFO: Got endpoints: latency-svc-gsg2v [749.452498ms]
Dec 22 22:19:39.638: INFO: Got endpoints: latency-svc-6p6wc [749.55025ms]
Dec 22 22:19:39.688: INFO: Got endpoints: latency-svc-nlc8d [748.908689ms]
Dec 22 22:19:39.738: INFO: Got endpoints: latency-svc-cbth6 [749.127554ms]
Dec 22 22:19:39.788: INFO: Got endpoints: latency-svc-hpsls [748.972556ms]
Dec 22 22:19:39.838: INFO: Got endpoints: latency-svc-9khdq [749.041838ms]
Dec 22 22:19:39.888: INFO: Got endpoints: latency-svc-dwprx [746.792578ms]
Dec 22 22:19:39.939: INFO: Got endpoints: latency-svc-tmqcn [750.213649ms]
Dec 22 22:19:39.989: INFO: Got endpoints: latency-svc-xzxms [750.227956ms]
Dec 22 22:19:40.038: INFO: Got endpoints: latency-svc-drpwp [749.926525ms]
Dec 22 22:19:40.089: INFO: Got endpoints: latency-svc-dhrhs [750.316692ms]
Dec 22 22:19:40.138: INFO: Got endpoints: latency-svc-5dbvr [749.697577ms]
Dec 22 22:19:40.188: INFO: Got endpoints: latency-svc-n6zxc [749.042249ms]
Dec 22 22:19:40.239: INFO: Got endpoints: latency-svc-glsvt [750.465129ms]
Dec 22 22:19:40.239: INFO: Latencies: [18.207252ms 29.233575ms 34.156495ms 48.355889ms 48.708542ms 64.800887ms 65.158228ms 81.392864ms 92.204423ms 121.489541ms 121.573849ms 122.081037ms 127.744084ms 128.32517ms 129.239439ms 131.688491ms 132.337114ms 132.479328ms 132.561497ms 139.120209ms 139.851144ms 140.545152ms 145.58227ms 146.365185ms 147.765515ms 148.66302ms 150.508982ms 150.611021ms 152.798488ms 153.198985ms 154.403936ms 154.659395ms 155.315964ms 155.856461ms 158.37573ms 170.148714ms 184.122429ms 210.369873ms 262.447024ms 309.849982ms 336.256586ms 382.236719ms 421.935272ms 460.097047ms 492.734842ms 543.562783ms 587.934699ms 612.023165ms 661.258762ms 679.312499ms 711.681685ms 719.458828ms 722.310593ms 731.652117ms 737.512975ms 739.20474ms 739.712902ms 741.002933ms 742.34802ms 743.146396ms 743.969366ms 744.117909ms 744.738436ms 745.615887ms 745.930783ms 746.792578ms 747.086035ms 747.560154ms 747.889196ms 747.918027ms 748.182685ms 748.22759ms 748.285366ms 748.292337ms 748.369667ms 748.395514ms 748.527272ms 748.585559ms 748.645985ms 748.780359ms 748.780611ms 748.784784ms 748.847874ms 748.908689ms 748.928319ms 748.970441ms 748.972556ms 749.041838ms 749.042249ms 749.085507ms 749.127554ms 749.154229ms 749.163309ms 749.181771ms 749.226537ms 749.236064ms 749.299161ms 749.300861ms 749.307636ms 749.39828ms 749.452498ms 749.476808ms 749.480253ms 749.501327ms 749.511539ms 749.523313ms 749.548089ms 749.55025ms 749.566824ms 749.592267ms 749.608695ms 749.633451ms 749.645053ms 749.669531ms 749.678791ms 749.697577ms 749.706536ms 749.734306ms 749.740469ms 749.779ms 749.821727ms 749.830647ms 749.840844ms 749.841756ms 749.851274ms 749.851383ms 749.865923ms 749.904662ms 749.915828ms 749.926525ms 749.930654ms 749.940285ms 749.947772ms 750.032594ms 750.096694ms 750.098083ms 750.136331ms 750.143496ms 750.148135ms 750.165541ms 750.175785ms 750.213649ms 750.227956ms 750.241758ms 750.253457ms 750.263372ms 750.306099ms 750.315005ms 750.316692ms 750.338977ms 750.34254ms 750.358566ms 750.369629ms 750.393411ms 750.407851ms 750.425766ms 750.465129ms 750.520046ms 750.538115ms 750.543494ms 750.552718ms 750.579758ms 750.617266ms 750.62205ms 750.692534ms 750.782504ms 750.839669ms 750.869928ms 750.924879ms 750.945356ms 750.947539ms 751.04296ms 751.049092ms 751.06007ms 751.205716ms 751.275224ms 751.417133ms 751.422227ms 751.44979ms 751.526598ms 751.599716ms 751.775236ms 751.921071ms 752.004722ms 752.711059ms 752.806363ms 753.087888ms 753.694918ms 754.23769ms 754.282176ms 755.508751ms 756.147238ms 756.276052ms 757.010502ms 757.807593ms 759.779347ms 767.595058ms 771.160662ms 779.273876ms 791.113358ms]
Dec 22 22:19:40.239: INFO: 50 %ile: 749.452498ms
Dec 22 22:19:40.239: INFO: 90 %ile: 751.599716ms
Dec 22 22:19:40.239: INFO: 99 %ile: 779.273876ms
Dec 22 22:19:40.239: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:19:40.239: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-6396" for this suite.
Dec 22 22:20:12.251: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:20:12.403: INFO: namespace svc-latency-6396 deletion completed in 32.16080003s

â€¢ [SLOW TEST:42.903 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:20:12.404: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-1717c1cc-59b3-4f72-85a0-471a94a03f8a
STEP: Creating a pod to test consume configMaps
Dec 22 22:20:12.429: INFO: Waiting up to 5m0s for pod "pod-configmaps-da9db535-1bc2-4cae-a6a5-e7769d11bbc7" in namespace "configmap-3407" to be "success or failure"
Dec 22 22:20:12.431: INFO: Pod "pod-configmaps-da9db535-1bc2-4cae-a6a5-e7769d11bbc7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.183862ms
Dec 22 22:20:14.434: INFO: Pod "pod-configmaps-da9db535-1bc2-4cae-a6a5-e7769d11bbc7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004624562s
STEP: Saw pod success
Dec 22 22:20:14.434: INFO: Pod "pod-configmaps-da9db535-1bc2-4cae-a6a5-e7769d11bbc7" satisfied condition "success or failure"
Dec 22 22:20:14.435: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod pod-configmaps-da9db535-1bc2-4cae-a6a5-e7769d11bbc7 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 22 22:20:14.447: INFO: Waiting for pod pod-configmaps-da9db535-1bc2-4cae-a6a5-e7769d11bbc7 to disappear
Dec 22 22:20:14.449: INFO: Pod pod-configmaps-da9db535-1bc2-4cae-a6a5-e7769d11bbc7 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:20:14.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3407" for this suite.
Dec 22 22:20:20.459: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:20:20.512: INFO: namespace configmap-3407 deletion completed in 6.059531845s

â€¢ [SLOW TEST:8.108 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:20:20.512: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec 22 22:20:20.530: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 create -f - --namespace=kubectl-3690'
Dec 22 22:20:21.014: INFO: stderr: ""
Dec 22 22:20:21.014: INFO: stdout: "replicationcontroller/redis-master created\n"
Dec 22 22:20:21.014: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 create -f - --namespace=kubectl-3690'
Dec 22 22:20:21.290: INFO: stderr: ""
Dec 22 22:20:21.290: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec 22 22:20:22.292: INFO: Selector matched 1 pods for map[app:redis]
Dec 22 22:20:22.292: INFO: Found 0 / 1
Dec 22 22:20:23.292: INFO: Selector matched 1 pods for map[app:redis]
Dec 22 22:20:23.293: INFO: Found 1 / 1
Dec 22 22:20:23.293: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec 22 22:20:23.295: INFO: Selector matched 1 pods for map[app:redis]
Dec 22 22:20:23.295: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec 22 22:20:23.295: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 describe pod redis-master-ds6zh --namespace=kubectl-3690'
Dec 22 22:20:23.554: INFO: stderr: ""
Dec 22 22:20:23.554: INFO: stdout: "Name:           redis-master-ds6zh\nNamespace:      kubectl-3690\nPriority:       0\nNode:           ip-10-0-1-121.us-west-2.compute.internal/10.0.1.121\nStart Time:     Sun, 22 Dec 2019 22:20:21 +0000\nLabels:         app=redis\n                role=master\nAnnotations:    cni.projectcalico.org/podIP: 10.20.27.58/32\nStatus:         Running\nIP:             10.20.27.58\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://9850dc2fdb3cc9574f95dcadd470c24b9aa45a729c533cac9319bc720a43e0fa\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Sun, 22 Dec 2019 22:20:22 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-m9dwt (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-m9dwt:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-m9dwt\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     <none>\nEvents:\n  Type    Reason     Age   From                                               Message\n  ----    ------     ----  ----                                               -------\n  Normal  Scheduled  2s    default-scheduler                                  Successfully assigned kubectl-3690/redis-master-ds6zh to ip-10-0-1-121.us-west-2.compute.internal\n  Normal  Pulled     2s    kubelet, ip-10-0-1-121.us-west-2.compute.internal  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    2s    kubelet, ip-10-0-1-121.us-west-2.compute.internal  Created container redis-master\n  Normal  Started    1s    kubelet, ip-10-0-1-121.us-west-2.compute.internal  Started container redis-master\n"
Dec 22 22:20:23.554: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 describe rc redis-master --namespace=kubectl-3690'
Dec 22 22:20:23.813: INFO: stderr: ""
Dec 22 22:20:23.813: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-3690\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: redis-master-ds6zh\n"
Dec 22 22:20:23.813: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 describe service redis-master --namespace=kubectl-3690'
Dec 22 22:20:23.961: INFO: stderr: ""
Dec 22 22:20:23.961: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-3690\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.21.251.246\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.20.27.58:6379\nSession Affinity:  None\nEvents:            <none>\n"
Dec 22 22:20:23.964: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 describe node ip-10-0-1-121.us-west-2.compute.internal'
Dec 22 22:20:24.138: INFO: stderr: ""
Dec 22 22:20:24.138: INFO: stdout: "Name:               ip-10-0-1-121.us-west-2.compute.internal\nRoles:              worker\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=t3.large\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=us-west-2\n                    failure-domain.beta.kubernetes.io/zone=us-west-2b\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=ip-10-0-1-121.us-west-2.compute.internal\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/worker=\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 10.0.1.121/24\n                    projectcalico.org/IPv4IPIPTunnelAddr: 10.20.27.0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Sun, 22 Dec 2019 21:13:21 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Sun, 22 Dec 2019 21:13:33 +0000   Sun, 22 Dec 2019 21:13:33 +0000   CalicoIsUp                   Calico is running on this node\n  MemoryPressure       False   Sun, 22 Dec 2019 22:20:05 +0000   Sun, 22 Dec 2019 21:13:20 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Sun, 22 Dec 2019 22:20:05 +0000   Sun, 22 Dec 2019 21:13:20 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Sun, 22 Dec 2019 22:20:05 +0000   Sun, 22 Dec 2019 21:13:20 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Sun, 22 Dec 2019 22:20:05 +0000   Sun, 22 Dec 2019 21:14:02 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:   10.0.1.121\n  ExternalIP:   34.215.189.82\n  Hostname:     ip-10-0-1-121.us-west-2.compute.internal\n  InternalDNS:  ip-10-0-1-121.us-west-2.compute.internal\n  ExternalDNS:  ec2-34-215-189-82.us-west-2.compute.amazonaws.com\nCapacity:\n attachable-volumes-aws-ebs:  25\n cpu:                         2\n ephemeral-storage:           50758760Ki\n hugepages-1Gi:               0\n hugepages-2Mi:               0\n memory:                      8071184Ki\n pods:                        200\nAllocatable:\n attachable-volumes-aws-ebs:  25\n cpu:                         2\n ephemeral-storage:           46779273139\n hugepages-1Gi:               0\n hugepages-2Mi:               0\n memory:                      7968784Ki\n pods:                        200\nSystem Info:\n Machine ID:                 ec2e4acc79772c003de86153acde29ec\n System UUID:                EC2E4ACC-7977-2C00-3DE8-6153ACDE29EC\n Boot ID:                    a13dbc6e-c203-47cb-8458-76caafb649ad\n Kernel Version:             4.4.0-1050-aws\n OS Image:                   Ubuntu 16.04.3 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.9.9\n Kubelet Version:            v1.15.7\n Kube-Proxy Version:         v1.15.7\nPodCIDR:                     10.20.1.0/24\nProviderID:                  aws:///us-west-2b/i-055e02bf88147b4a9\nNon-terminated Pods:         (4 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                calico-node-r5hns                                          250m (12%)    0 (0%)      0 (0%)           0 (0%)         67m\n  kubectl-3690               redis-master-ds6zh                                         0 (0%)        0 (0%)      0 (0%)           0 (0%)         3s\n  sonobuoy                   sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         61m\n  sonobuoy                   sonobuoy-systemd-logs-daemon-set-42c521be8b344bae-qnvsn    0 (0%)        0 (0%)      0 (0%)           0 (0%)         61m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource                    Requests    Limits\n  --------                    --------    ------\n  cpu                         250m (12%)  0 (0%)\n  memory                      0 (0%)      0 (0%)\n  ephemeral-storage           0 (0%)      0 (0%)\n  attachable-volumes-aws-ebs  0           0\nEvents:                       <none>\n"
Dec 22 22:20:24.138: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 describe namespace kubectl-3690'
Dec 22 22:20:24.329: INFO: stderr: ""
Dec 22 22:20:24.329: INFO: stdout: "Name:         kubectl-3690\nLabels:       e2e-framework=kubectl\n              e2e-run=3fe299f7-d80a-4872-88a8-bdd8a596ced7\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:20:24.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3690" for this suite.
Dec 22 22:20:54.339: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:20:54.498: INFO: namespace kubectl-3690 deletion completed in 30.166861623s

â€¢ [SLOW TEST:33.986 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl describe
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:20:54.499: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec 22 22:20:54.521: INFO: Waiting up to 5m0s for pod "downwardapi-volume-29097799-0f95-42d2-bb41-817962e35710" in namespace "projected-9997" to be "success or failure"
Dec 22 22:20:54.522: INFO: Pod "downwardapi-volume-29097799-0f95-42d2-bb41-817962e35710": Phase="Pending", Reason="", readiness=false. Elapsed: 1.699121ms
Dec 22 22:20:56.525: INFO: Pod "downwardapi-volume-29097799-0f95-42d2-bb41-817962e35710": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004580268s
STEP: Saw pod success
Dec 22 22:20:56.525: INFO: Pod "downwardapi-volume-29097799-0f95-42d2-bb41-817962e35710" satisfied condition "success or failure"
Dec 22 22:20:56.527: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod downwardapi-volume-29097799-0f95-42d2-bb41-817962e35710 container client-container: <nil>
STEP: delete the pod
Dec 22 22:20:56.543: INFO: Waiting for pod downwardapi-volume-29097799-0f95-42d2-bb41-817962e35710 to disappear
Dec 22 22:20:56.545: INFO: Pod downwardapi-volume-29097799-0f95-42d2-bb41-817962e35710 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:20:56.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9997" for this suite.
Dec 22 22:21:02.555: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:21:02.628: INFO: namespace projected-9997 deletion completed in 6.080641893s

â€¢ [SLOW TEST:8.130 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:21:02.628: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override command
Dec 22 22:21:02.711: INFO: Waiting up to 5m0s for pod "client-containers-37550aef-30bb-4cc0-886b-fd918223d18b" in namespace "containers-9953" to be "success or failure"
Dec 22 22:21:02.714: INFO: Pod "client-containers-37550aef-30bb-4cc0-886b-fd918223d18b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.840399ms
Dec 22 22:21:04.717: INFO: Pod "client-containers-37550aef-30bb-4cc0-886b-fd918223d18b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005581063s
STEP: Saw pod success
Dec 22 22:21:04.717: INFO: Pod "client-containers-37550aef-30bb-4cc0-886b-fd918223d18b" satisfied condition "success or failure"
Dec 22 22:21:04.719: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod client-containers-37550aef-30bb-4cc0-886b-fd918223d18b container test-container: <nil>
STEP: delete the pod
Dec 22 22:21:04.731: INFO: Waiting for pod client-containers-37550aef-30bb-4cc0-886b-fd918223d18b to disappear
Dec 22 22:21:04.733: INFO: Pod client-containers-37550aef-30bb-4cc0-886b-fd918223d18b no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:21:04.733: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-9953" for this suite.
Dec 22 22:21:10.742: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:21:10.799: INFO: namespace containers-9953 deletion completed in 6.063711125s

â€¢ [SLOW TEST:8.171 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:21:10.799: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-b432147f-d935-4e64-9953-90f387bce78c
STEP: Creating a pod to test consume configMaps
Dec 22 22:21:10.825: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a879dbb6-611a-4af5-9872-373acd88d16b" in namespace "projected-4771" to be "success or failure"
Dec 22 22:21:10.830: INFO: Pod "pod-projected-configmaps-a879dbb6-611a-4af5-9872-373acd88d16b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.971486ms
Dec 22 22:21:12.833: INFO: Pod "pod-projected-configmaps-a879dbb6-611a-4af5-9872-373acd88d16b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008002665s
STEP: Saw pod success
Dec 22 22:21:12.833: INFO: Pod "pod-projected-configmaps-a879dbb6-611a-4af5-9872-373acd88d16b" satisfied condition "success or failure"
Dec 22 22:21:12.835: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod pod-projected-configmaps-a879dbb6-611a-4af5-9872-373acd88d16b container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 22 22:21:12.849: INFO: Waiting for pod pod-projected-configmaps-a879dbb6-611a-4af5-9872-373acd88d16b to disappear
Dec 22 22:21:12.850: INFO: Pod pod-projected-configmaps-a879dbb6-611a-4af5-9872-373acd88d16b no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:21:12.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4771" for this suite.
Dec 22 22:21:18.860: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:21:18.915: INFO: namespace projected-4771 deletion completed in 6.061695659s

â€¢ [SLOW TEST:8.115 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:21:18.915: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Dec 22 22:21:19.001: INFO: Waiting up to 5m0s for pod "downward-api-ba9ea935-b44b-4482-adc1-eb505e0f06ee" in namespace "downward-api-8733" to be "success or failure"
Dec 22 22:21:19.009: INFO: Pod "downward-api-ba9ea935-b44b-4482-adc1-eb505e0f06ee": Phase="Pending", Reason="", readiness=false. Elapsed: 8.685491ms
Dec 22 22:21:21.012: INFO: Pod "downward-api-ba9ea935-b44b-4482-adc1-eb505e0f06ee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011230921s
STEP: Saw pod success
Dec 22 22:21:21.012: INFO: Pod "downward-api-ba9ea935-b44b-4482-adc1-eb505e0f06ee" satisfied condition "success or failure"
Dec 22 22:21:21.014: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod downward-api-ba9ea935-b44b-4482-adc1-eb505e0f06ee container dapi-container: <nil>
STEP: delete the pod
Dec 22 22:21:21.027: INFO: Waiting for pod downward-api-ba9ea935-b44b-4482-adc1-eb505e0f06ee to disappear
Dec 22 22:21:21.030: INFO: Pod downward-api-ba9ea935-b44b-4482-adc1-eb505e0f06ee no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:21:21.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8733" for this suite.
Dec 22 22:21:27.040: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:21:27.101: INFO: namespace downward-api-8733 deletion completed in 6.067517496s

â€¢ [SLOW TEST:8.185 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:21:27.101: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W1222 22:21:27.674155      15 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec 22 22:21:27.674: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:21:27.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3366" for this suite.
Dec 22 22:21:33.692: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:21:33.748: INFO: namespace gc-3366 deletion completed in 6.067086966s

â€¢ [SLOW TEST:6.647 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:21:33.750: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec 22 22:21:33.771: INFO: Waiting up to 5m0s for pod "pod-7524d365-7d1d-4a2b-923a-5f811530aaab" in namespace "emptydir-7389" to be "success or failure"
Dec 22 22:21:33.774: INFO: Pod "pod-7524d365-7d1d-4a2b-923a-5f811530aaab": Phase="Pending", Reason="", readiness=false. Elapsed: 3.66329ms
Dec 22 22:21:35.777: INFO: Pod "pod-7524d365-7d1d-4a2b-923a-5f811530aaab": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00641129s
STEP: Saw pod success
Dec 22 22:21:35.777: INFO: Pod "pod-7524d365-7d1d-4a2b-923a-5f811530aaab" satisfied condition "success or failure"
Dec 22 22:21:35.779: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod pod-7524d365-7d1d-4a2b-923a-5f811530aaab container test-container: <nil>
STEP: delete the pod
Dec 22 22:21:35.792: INFO: Waiting for pod pod-7524d365-7d1d-4a2b-923a-5f811530aaab to disappear
Dec 22 22:21:35.795: INFO: Pod pod-7524d365-7d1d-4a2b-923a-5f811530aaab no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:21:35.795: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7389" for this suite.
Dec 22 22:21:41.804: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:21:41.898: INFO: namespace emptydir-7389 deletion completed in 6.10041332s

â€¢ [SLOW TEST:8.149 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:21:41.899: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7211.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7211.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 22 22:21:45.946: INFO: DNS probes using dns-7211/dns-test-57e3d336-183c-49e0-9482-95dadfc816eb succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:21:45.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7211" for this suite.
Dec 22 22:21:51.975: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:21:52.209: INFO: namespace dns-7211 deletion completed in 6.243288808s

â€¢ [SLOW TEST:10.310 seconds]
[sig-network] DNS
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:21:52.210: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec 22 22:21:52.233: INFO: Waiting up to 5m0s for pod "pod-1eab4c06-af90-4f70-abdb-df081b5566b5" in namespace "emptydir-267" to be "success or failure"
Dec 22 22:21:52.240: INFO: Pod "pod-1eab4c06-af90-4f70-abdb-df081b5566b5": Phase="Pending", Reason="", readiness=false. Elapsed: 7.45063ms
Dec 22 22:21:54.243: INFO: Pod "pod-1eab4c06-af90-4f70-abdb-df081b5566b5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010031602s
Dec 22 22:21:56.246: INFO: Pod "pod-1eab4c06-af90-4f70-abdb-df081b5566b5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012775927s
STEP: Saw pod success
Dec 22 22:21:56.246: INFO: Pod "pod-1eab4c06-af90-4f70-abdb-df081b5566b5" satisfied condition "success or failure"
Dec 22 22:21:56.248: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod pod-1eab4c06-af90-4f70-abdb-df081b5566b5 container test-container: <nil>
STEP: delete the pod
Dec 22 22:21:56.268: INFO: Waiting for pod pod-1eab4c06-af90-4f70-abdb-df081b5566b5 to disappear
Dec 22 22:21:56.270: INFO: Pod pod-1eab4c06-af90-4f70-abdb-df081b5566b5 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:21:56.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-267" for this suite.
Dec 22 22:22:02.279: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:22:02.401: INFO: namespace emptydir-267 deletion completed in 6.12860299s

â€¢ [SLOW TEST:10.192 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:22:02.401: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:22:07.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8372" for this suite.
Dec 22 22:22:14.057: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:22:14.166: INFO: namespace watch-8372 deletion completed in 6.209483169s

â€¢ [SLOW TEST:11.765 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:22:14.169: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test hostPath mode
Dec 22 22:22:14.195: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-5542" to be "success or failure"
Dec 22 22:22:14.197: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 1.702658ms
Dec 22 22:22:16.200: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00494823s
Dec 22 22:22:18.203: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007710815s
STEP: Saw pod success
Dec 22 22:22:18.203: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Dec 22 22:22:18.205: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Dec 22 22:22:18.220: INFO: Waiting for pod pod-host-path-test to disappear
Dec 22 22:22:18.222: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:22:18.222: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-5542" for this suite.
Dec 22 22:22:24.232: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:22:24.302: INFO: namespace hostpath-5542 deletion completed in 6.077329061s

â€¢ [SLOW TEST:10.134 seconds]
[sig-storage] HostPath
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:22:24.303: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: getting the auto-created API token
STEP: reading a file in the container
Dec 22 22:22:26.833: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-204 pod-service-account-9902df8c-3795-4b25-93e1-6682460b94bc -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Dec 22 22:22:27.061: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-204 pod-service-account-9902df8c-3795-4b25-93e1-6682460b94bc -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Dec 22 22:22:27.273: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-204 pod-service-account-9902df8c-3795-4b25-93e1-6682460b94bc -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:22:27.640: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-204" for this suite.
Dec 22 22:22:33.652: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:22:33.806: INFO: namespace svcaccounts-204 deletion completed in 6.162679628s

â€¢ [SLOW TEST:9.503 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:22:33.806: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-b337bfc8-fbce-4137-86cd-90a682963202
STEP: Creating a pod to test consume configMaps
Dec 22 22:22:33.881: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5b9cab04-3883-42f6-a221-42184fcd4af6" in namespace "projected-6639" to be "success or failure"
Dec 22 22:22:33.884: INFO: Pod "pod-projected-configmaps-5b9cab04-3883-42f6-a221-42184fcd4af6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.812176ms
Dec 22 22:22:35.886: INFO: Pod "pod-projected-configmaps-5b9cab04-3883-42f6-a221-42184fcd4af6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005006529s
STEP: Saw pod success
Dec 22 22:22:35.886: INFO: Pod "pod-projected-configmaps-5b9cab04-3883-42f6-a221-42184fcd4af6" satisfied condition "success or failure"
Dec 22 22:22:35.888: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod pod-projected-configmaps-5b9cab04-3883-42f6-a221-42184fcd4af6 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 22 22:22:35.900: INFO: Waiting for pod pod-projected-configmaps-5b9cab04-3883-42f6-a221-42184fcd4af6 to disappear
Dec 22 22:22:35.902: INFO: Pod pod-projected-configmaps-5b9cab04-3883-42f6-a221-42184fcd4af6 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:22:35.902: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6639" for this suite.
Dec 22 22:22:41.927: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:22:42.011: INFO: namespace projected-6639 deletion completed in 6.106383343s

â€¢ [SLOW TEST:8.204 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:22:42.011: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-5591
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 22 22:22:42.028: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec 22 22:23:08.082: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.20.29.251:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5591 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 22 22:23:08.082: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
Dec 22 22:23:08.242: INFO: Found all expected endpoints: [netserver-0]
Dec 22 22:23:08.245: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.20.27.7:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5591 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 22 22:23:08.245: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
Dec 22 22:23:08.416: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:23:08.416: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5591" for this suite.
Dec 22 22:23:30.439: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:23:30.536: INFO: namespace pod-network-test-5591 deletion completed in 22.115570385s

â€¢ [SLOW TEST:48.525 seconds]
[sig-network] Networking
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:23:30.536: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name s-test-opt-del-907d81fe-3906-4e29-b3db-f6e01111fd7b
STEP: Creating secret with name s-test-opt-upd-6f884dc0-5006-4725-a492-e823662f9408
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-907d81fe-3906-4e29-b3db-f6e01111fd7b
STEP: Updating secret s-test-opt-upd-6f884dc0-5006-4725-a492-e823662f9408
STEP: Creating secret with name s-test-opt-create-0872e203-ed37-412e-83ef-68f6d0236243
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:23:34.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5065" for this suite.
Dec 22 22:23:56.633: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:23:56.687: INFO: namespace secrets-5065 deletion completed in 22.061578626s

â€¢ [SLOW TEST:26.151 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:23:56.687: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec 22 22:24:02.739: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 22 22:24:02.741: INFO: Pod pod-with-poststart-http-hook still exists
Dec 22 22:24:04.741: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 22 22:24:04.744: INFO: Pod pod-with-poststart-http-hook still exists
Dec 22 22:24:06.741: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 22 22:24:06.744: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:24:06.744: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-5065" for this suite.
Dec 22 22:24:28.756: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:24:29.112: INFO: namespace container-lifecycle-hook-5065 deletion completed in 22.365305672s

â€¢ [SLOW TEST:32.425 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:24:29.112: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:24:55.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-3272" for this suite.
Dec 22 22:25:01.333: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:25:01.444: INFO: namespace container-runtime-3272 deletion completed in 6.119109909s

â€¢ [SLOW TEST:32.332 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    when starting a container that exits
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:25:01.444: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating Redis RC
Dec 22 22:25:01.462: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 create -f - --namespace=kubectl-5647'
Dec 22 22:25:01.643: INFO: stderr: ""
Dec 22 22:25:01.643: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec 22 22:25:02.646: INFO: Selector matched 1 pods for map[app:redis]
Dec 22 22:25:02.646: INFO: Found 0 / 1
Dec 22 22:25:03.653: INFO: Selector matched 1 pods for map[app:redis]
Dec 22 22:25:03.653: INFO: Found 1 / 1
Dec 22 22:25:03.653: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Dec 22 22:25:03.656: INFO: Selector matched 1 pods for map[app:redis]
Dec 22 22:25:03.656: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec 22 22:25:03.656: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 patch pod redis-master-wjzm2 --namespace=kubectl-5647 -p {"metadata":{"annotations":{"x":"y"}}}'
Dec 22 22:25:03.761: INFO: stderr: ""
Dec 22 22:25:03.762: INFO: stdout: "pod/redis-master-wjzm2 patched\n"
STEP: checking annotations
Dec 22 22:25:03.764: INFO: Selector matched 1 pods for map[app:redis]
Dec 22 22:25:03.764: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:25:03.764: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5647" for this suite.
Dec 22 22:25:25.774: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:25:25.923: INFO: namespace kubectl-5647 deletion completed in 22.156685177s

â€¢ [SLOW TEST:24.479 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl patch
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:25:25.923: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec 22 22:25:25.988: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bf14e6fb-d2c0-4c0d-b64d-4da00488f6fa" in namespace "projected-169" to be "success or failure"
Dec 22 22:25:25.991: INFO: Pod "downwardapi-volume-bf14e6fb-d2c0-4c0d-b64d-4da00488f6fa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.581088ms
Dec 22 22:25:27.993: INFO: Pod "downwardapi-volume-bf14e6fb-d2c0-4c0d-b64d-4da00488f6fa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005151616s
STEP: Saw pod success
Dec 22 22:25:27.993: INFO: Pod "downwardapi-volume-bf14e6fb-d2c0-4c0d-b64d-4da00488f6fa" satisfied condition "success or failure"
Dec 22 22:25:27.995: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod downwardapi-volume-bf14e6fb-d2c0-4c0d-b64d-4da00488f6fa container client-container: <nil>
STEP: delete the pod
Dec 22 22:25:28.009: INFO: Waiting for pod downwardapi-volume-bf14e6fb-d2c0-4c0d-b64d-4da00488f6fa to disappear
Dec 22 22:25:28.012: INFO: Pod downwardapi-volume-bf14e6fb-d2c0-4c0d-b64d-4da00488f6fa no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:25:28.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-169" for this suite.
Dec 22 22:25:34.021: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:25:34.092: INFO: namespace projected-169 deletion completed in 6.077224092s

â€¢ [SLOW TEST:8.169 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:25:34.092: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Dec 22 22:25:34.133: INFO: Waiting up to 5m0s for pod "downward-api-78363e38-894e-421d-a1ad-21f824a871a7" in namespace "downward-api-5946" to be "success or failure"
Dec 22 22:25:34.136: INFO: Pod "downward-api-78363e38-894e-421d-a1ad-21f824a871a7": Phase="Pending", Reason="", readiness=false. Elapsed: 1.929165ms
Dec 22 22:25:36.138: INFO: Pod "downward-api-78363e38-894e-421d-a1ad-21f824a871a7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004711573s
STEP: Saw pod success
Dec 22 22:25:36.138: INFO: Pod "downward-api-78363e38-894e-421d-a1ad-21f824a871a7" satisfied condition "success or failure"
Dec 22 22:25:36.140: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod downward-api-78363e38-894e-421d-a1ad-21f824a871a7 container dapi-container: <nil>
STEP: delete the pod
Dec 22 22:25:36.154: INFO: Waiting for pod downward-api-78363e38-894e-421d-a1ad-21f824a871a7 to disappear
Dec 22 22:25:36.156: INFO: Pod downward-api-78363e38-894e-421d-a1ad-21f824a871a7 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:25:36.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5946" for this suite.
Dec 22 22:25:42.167: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:25:42.400: INFO: namespace downward-api-5946 deletion completed in 6.240489368s

â€¢ [SLOW TEST:8.308 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:25:42.401: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating secret secrets-6559/secret-test-812d8302-179c-4616-b2da-32f8b3bf35ec
STEP: Creating a pod to test consume secrets
Dec 22 22:25:42.423: INFO: Waiting up to 5m0s for pod "pod-configmaps-6a6407dd-409d-4270-8ca7-b93981fd2882" in namespace "secrets-6559" to be "success or failure"
Dec 22 22:25:42.425: INFO: Pod "pod-configmaps-6a6407dd-409d-4270-8ca7-b93981fd2882": Phase="Pending", Reason="", readiness=false. Elapsed: 2.089278ms
Dec 22 22:25:44.430: INFO: Pod "pod-configmaps-6a6407dd-409d-4270-8ca7-b93981fd2882": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007277182s
STEP: Saw pod success
Dec 22 22:25:44.430: INFO: Pod "pod-configmaps-6a6407dd-409d-4270-8ca7-b93981fd2882" satisfied condition "success or failure"
Dec 22 22:25:44.432: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod pod-configmaps-6a6407dd-409d-4270-8ca7-b93981fd2882 container env-test: <nil>
STEP: delete the pod
Dec 22 22:25:44.445: INFO: Waiting for pod pod-configmaps-6a6407dd-409d-4270-8ca7-b93981fd2882 to disappear
Dec 22 22:25:44.447: INFO: Pod pod-configmaps-6a6407dd-409d-4270-8ca7-b93981fd2882 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:25:44.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6559" for this suite.
Dec 22 22:25:50.456: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:25:50.524: INFO: namespace secrets-6559 deletion completed in 6.073975419s

â€¢ [SLOW TEST:8.123 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:25:50.525: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name projected-secret-test-5dfee2d3-3c12-4785-ab3a-36dc10c683ff
STEP: Creating a pod to test consume secrets
Dec 22 22:25:50.552: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-99cd7619-5abc-456b-b2df-775bcdfb821f" in namespace "projected-9006" to be "success or failure"
Dec 22 22:25:50.556: INFO: Pod "pod-projected-secrets-99cd7619-5abc-456b-b2df-775bcdfb821f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.198697ms
Dec 22 22:25:52.559: INFO: Pod "pod-projected-secrets-99cd7619-5abc-456b-b2df-775bcdfb821f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006862858s
STEP: Saw pod success
Dec 22 22:25:52.559: INFO: Pod "pod-projected-secrets-99cd7619-5abc-456b-b2df-775bcdfb821f" satisfied condition "success or failure"
Dec 22 22:25:52.561: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod pod-projected-secrets-99cd7619-5abc-456b-b2df-775bcdfb821f container secret-volume-test: <nil>
STEP: delete the pod
Dec 22 22:25:52.575: INFO: Waiting for pod pod-projected-secrets-99cd7619-5abc-456b-b2df-775bcdfb821f to disappear
Dec 22 22:25:52.576: INFO: Pod pod-projected-secrets-99cd7619-5abc-456b-b2df-775bcdfb821f no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:25:52.576: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9006" for this suite.
Dec 22 22:25:58.588: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:25:58.700: INFO: namespace projected-9006 deletion completed in 6.121054194s

â€¢ [SLOW TEST:8.176 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:25:58.700: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: executing a command with run --rm and attach with stdin
Dec 22 22:25:58.719: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 --namespace=kubectl-3201 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Dec 22 22:26:00.669: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Dec 22 22:26:00.669: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:26:02.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3201" for this suite.
Dec 22 22:26:08.684: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:26:08.761: INFO: namespace kubectl-3201 deletion completed in 6.084272399s

â€¢ [SLOW TEST:10.061 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:26:08.761: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec 22 22:26:08.780: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:26:10.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2881" for this suite.
Dec 22 22:26:54.935: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:26:55.001: INFO: namespace pods-2881 deletion completed in 44.0730209s

â€¢ [SLOW TEST:46.239 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:26:55.001: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Dec 22 22:26:55.054: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 22 22:26:55.059: INFO: Waiting for terminating namespaces to be deleted...
Dec 22 22:26:55.061: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-1-121.us-west-2.compute.internal before test
Dec 22 22:26:55.064: INFO: sonobuoy from sonobuoy started at 2019-12-22 21:18:58 +0000 UTC (1 container statuses recorded)
Dec 22 22:26:55.064: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 22 22:26:55.064: INFO: sonobuoy-systemd-logs-daemon-set-42c521be8b344bae-qnvsn from sonobuoy started at 2019-12-22 21:19:03 +0000 UTC (2 container statuses recorded)
Dec 22 22:26:55.064: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec 22 22:26:55.064: INFO: 	Container systemd-logs ready: true, restart count 1
Dec 22 22:26:55.064: INFO: calico-node-r5hns from kube-system started at 2019-12-22 21:13:22 +0000 UTC (1 container statuses recorded)
Dec 22 22:26:55.064: INFO: 	Container calico-node ready: true, restart count 0
Dec 22 22:26:55.064: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-1-187.us-west-2.compute.internal before test
Dec 22 22:26:55.068: INFO: calico-node-bnxjf from kube-system started at 2019-12-22 21:13:27 +0000 UTC (1 container statuses recorded)
Dec 22 22:26:55.068: INFO: 	Container calico-node ready: true, restart count 0
Dec 22 22:26:55.068: INFO: sonobuoy-e2e-job-bfd4ea5b59194b8d from sonobuoy started at 2019-12-22 21:19:02 +0000 UTC (2 container statuses recorded)
Dec 22 22:26:55.068: INFO: 	Container e2e ready: true, restart count 0
Dec 22 22:26:55.068: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 22 22:26:55.068: INFO: sonobuoy-systemd-logs-daemon-set-42c521be8b344bae-95gp6 from sonobuoy started at 2019-12-22 21:19:03 +0000 UTC (2 container statuses recorded)
Dec 22 22:26:55.068: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec 22 22:26:55.068: INFO: 	Container systemd-logs ready: true, restart count 1
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15e2d1e847d97ff0], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:26:56.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-3438" for this suite.
Dec 22 22:27:02.114: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:27:02.220: INFO: namespace sched-pred-3438 deletion completed in 6.115795557s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

â€¢ [SLOW TEST:7.219 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:27:02.220: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Dec 22 22:27:02.300: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-6463,SelfLink:/api/v1/namespaces/watch-6463/configmaps/e2e-watch-test-label-changed,UID:5c5bac5c-daa4-4ac6-baea-6d49253f402f,ResourceVersion:18129,Generation:0,CreationTimestamp:2019-12-22 22:27:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 22 22:27:02.300: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-6463,SelfLink:/api/v1/namespaces/watch-6463/configmaps/e2e-watch-test-label-changed,UID:5c5bac5c-daa4-4ac6-baea-6d49253f402f,ResourceVersion:18130,Generation:0,CreationTimestamp:2019-12-22 22:27:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Dec 22 22:27:02.300: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-6463,SelfLink:/api/v1/namespaces/watch-6463/configmaps/e2e-watch-test-label-changed,UID:5c5bac5c-daa4-4ac6-baea-6d49253f402f,ResourceVersion:18131,Generation:0,CreationTimestamp:2019-12-22 22:27:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Dec 22 22:27:12.350: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-6463,SelfLink:/api/v1/namespaces/watch-6463/configmaps/e2e-watch-test-label-changed,UID:5c5bac5c-daa4-4ac6-baea-6d49253f402f,ResourceVersion:18149,Generation:0,CreationTimestamp:2019-12-22 22:27:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 22 22:27:12.351: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-6463,SelfLink:/api/v1/namespaces/watch-6463/configmaps/e2e-watch-test-label-changed,UID:5c5bac5c-daa4-4ac6-baea-6d49253f402f,ResourceVersion:18150,Generation:0,CreationTimestamp:2019-12-22 22:27:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Dec 22 22:27:12.351: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-6463,SelfLink:/api/v1/namespaces/watch-6463/configmaps/e2e-watch-test-label-changed,UID:5c5bac5c-daa4-4ac6-baea-6d49253f402f,ResourceVersion:18151,Generation:0,CreationTimestamp:2019-12-22 22:27:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:27:12.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6463" for this suite.
Dec 22 22:27:18.360: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:27:18.525: INFO: namespace watch-6463 deletion completed in 6.170918039s

â€¢ [SLOW TEST:16.305 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:27:18.525: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-9600
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-9600
STEP: Creating statefulset with conflicting port in namespace statefulset-9600
STEP: Waiting until pod test-pod will start running in namespace statefulset-9600
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-9600
Dec 22 22:27:22.587: INFO: Observed stateful pod in namespace: statefulset-9600, name: ss-0, uid: 7fa0ec2f-64f0-48ad-a419-85afcf3c7837, status phase: Pending. Waiting for statefulset controller to delete.
Dec 22 22:27:23.171: INFO: Observed stateful pod in namespace: statefulset-9600, name: ss-0, uid: 7fa0ec2f-64f0-48ad-a419-85afcf3c7837, status phase: Failed. Waiting for statefulset controller to delete.
Dec 22 22:27:23.175: INFO: Observed stateful pod in namespace: statefulset-9600, name: ss-0, uid: 7fa0ec2f-64f0-48ad-a419-85afcf3c7837, status phase: Failed. Waiting for statefulset controller to delete.
Dec 22 22:27:23.177: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-9600
STEP: Removing pod with conflicting port in namespace statefulset-9600
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-9600 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Dec 22 22:27:27.199: INFO: Deleting all statefulset in ns statefulset-9600
Dec 22 22:27:27.201: INFO: Scaling statefulset ss to 0
Dec 22 22:27:37.210: INFO: Waiting for statefulset status.replicas updated to 0
Dec 22 22:27:37.212: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:27:37.222: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9600" for this suite.
Dec 22 22:27:43.232: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:27:43.301: INFO: namespace statefulset-9600 deletion completed in 6.075742113s

â€¢ [SLOW TEST:24.776 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:27:43.301: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-configmap-bbv7
STEP: Creating a pod to test atomic-volume-subpath
Dec 22 22:27:43.335: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-bbv7" in namespace "subpath-1835" to be "success or failure"
Dec 22 22:27:43.344: INFO: Pod "pod-subpath-test-configmap-bbv7": Phase="Pending", Reason="", readiness=false. Elapsed: 9.322938ms
Dec 22 22:27:45.350: INFO: Pod "pod-subpath-test-configmap-bbv7": Phase="Running", Reason="", readiness=true. Elapsed: 2.014797546s
Dec 22 22:27:47.353: INFO: Pod "pod-subpath-test-configmap-bbv7": Phase="Running", Reason="", readiness=true. Elapsed: 4.017601497s
Dec 22 22:27:49.355: INFO: Pod "pod-subpath-test-configmap-bbv7": Phase="Running", Reason="", readiness=true. Elapsed: 6.020117728s
Dec 22 22:27:51.358: INFO: Pod "pod-subpath-test-configmap-bbv7": Phase="Running", Reason="", readiness=true. Elapsed: 8.02288052s
Dec 22 22:27:53.368: INFO: Pod "pod-subpath-test-configmap-bbv7": Phase="Running", Reason="", readiness=true. Elapsed: 10.032549209s
Dec 22 22:27:55.370: INFO: Pod "pod-subpath-test-configmap-bbv7": Phase="Running", Reason="", readiness=true. Elapsed: 12.035385374s
Dec 22 22:27:57.374: INFO: Pod "pod-subpath-test-configmap-bbv7": Phase="Running", Reason="", readiness=true. Elapsed: 14.039200625s
Dec 22 22:27:59.378: INFO: Pod "pod-subpath-test-configmap-bbv7": Phase="Running", Reason="", readiness=true. Elapsed: 16.04312716s
Dec 22 22:28:01.381: INFO: Pod "pod-subpath-test-configmap-bbv7": Phase="Running", Reason="", readiness=true. Elapsed: 18.045753781s
Dec 22 22:28:03.385: INFO: Pod "pod-subpath-test-configmap-bbv7": Phase="Running", Reason="", readiness=true. Elapsed: 20.050100334s
Dec 22 22:28:05.388: INFO: Pod "pod-subpath-test-configmap-bbv7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.052639793s
STEP: Saw pod success
Dec 22 22:28:05.388: INFO: Pod "pod-subpath-test-configmap-bbv7" satisfied condition "success or failure"
Dec 22 22:28:05.390: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod pod-subpath-test-configmap-bbv7 container test-container-subpath-configmap-bbv7: <nil>
STEP: delete the pod
Dec 22 22:28:05.409: INFO: Waiting for pod pod-subpath-test-configmap-bbv7 to disappear
Dec 22 22:28:05.411: INFO: Pod pod-subpath-test-configmap-bbv7 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-bbv7
Dec 22 22:28:05.411: INFO: Deleting pod "pod-subpath-test-configmap-bbv7" in namespace "subpath-1835"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:28:05.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1835" for this suite.
Dec 22 22:28:11.427: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:28:11.490: INFO: namespace subpath-1835 deletion completed in 6.074673685s

â€¢ [SLOW TEST:28.189 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:28:11.490: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-upd-0066a254-1df4-42e9-971e-a6b46d559fc9
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:28:13.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6709" for this suite.
Dec 22 22:28:35.557: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:28:35.614: INFO: namespace configmap-6709 deletion completed in 22.065511412s

â€¢ [SLOW TEST:24.124 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:28:35.615: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override all
Dec 22 22:28:35.687: INFO: Waiting up to 5m0s for pod "client-containers-fc44b13f-f0d2-426a-9774-510c2d235e5b" in namespace "containers-9591" to be "success or failure"
Dec 22 22:28:35.689: INFO: Pod "client-containers-fc44b13f-f0d2-426a-9774-510c2d235e5b": Phase="Pending", Reason="", readiness=false. Elapsed: 1.844788ms
Dec 22 22:28:37.692: INFO: Pod "client-containers-fc44b13f-f0d2-426a-9774-510c2d235e5b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004660779s
STEP: Saw pod success
Dec 22 22:28:37.692: INFO: Pod "client-containers-fc44b13f-f0d2-426a-9774-510c2d235e5b" satisfied condition "success or failure"
Dec 22 22:28:37.694: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod client-containers-fc44b13f-f0d2-426a-9774-510c2d235e5b container test-container: <nil>
STEP: delete the pod
Dec 22 22:28:37.708: INFO: Waiting for pod client-containers-fc44b13f-f0d2-426a-9774-510c2d235e5b to disappear
Dec 22 22:28:37.711: INFO: Pod client-containers-fc44b13f-f0d2-426a-9774-510c2d235e5b no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:28:37.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-9591" for this suite.
Dec 22 22:28:43.726: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:28:43.782: INFO: namespace containers-9591 deletion completed in 6.062235848s

â€¢ [SLOW TEST:8.167 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:28:43.782: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Dec 22 22:28:43.799: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:28:47.617: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-390" for this suite.
Dec 22 22:28:53.629: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:28:53.704: INFO: namespace init-container-390 deletion completed in 6.082266488s

â€¢ [SLOW TEST:9.922 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:28:53.705: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap that has name configmap-test-emptyKey-370aefc8-a75b-4ffb-8655-661bfae2ad97
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:28:53.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9303" for this suite.
Dec 22 22:28:59.731: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:28:59.787: INFO: namespace configmap-9303 deletion completed in 6.062292618s

â€¢ [SLOW TEST:6.082 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:28:59.787: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-07135943-9be7-4873-a79b-12d32a34f136
STEP: Creating a pod to test consume configMaps
Dec 22 22:28:59.815: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ab923c31-e43a-46a5-bfde-f2f2b6594380" in namespace "projected-820" to be "success or failure"
Dec 22 22:28:59.817: INFO: Pod "pod-projected-configmaps-ab923c31-e43a-46a5-bfde-f2f2b6594380": Phase="Pending", Reason="", readiness=false. Elapsed: 1.778845ms
Dec 22 22:29:01.819: INFO: Pod "pod-projected-configmaps-ab923c31-e43a-46a5-bfde-f2f2b6594380": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004389201s
Dec 22 22:29:03.822: INFO: Pod "pod-projected-configmaps-ab923c31-e43a-46a5-bfde-f2f2b6594380": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007060498s
STEP: Saw pod success
Dec 22 22:29:03.822: INFO: Pod "pod-projected-configmaps-ab923c31-e43a-46a5-bfde-f2f2b6594380" satisfied condition "success or failure"
Dec 22 22:29:03.824: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod pod-projected-configmaps-ab923c31-e43a-46a5-bfde-f2f2b6594380 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 22 22:29:03.836: INFO: Waiting for pod pod-projected-configmaps-ab923c31-e43a-46a5-bfde-f2f2b6594380 to disappear
Dec 22 22:29:03.839: INFO: Pod pod-projected-configmaps-ab923c31-e43a-46a5-bfde-f2f2b6594380 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:29:03.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-820" for this suite.
Dec 22 22:29:09.861: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:29:09.924: INFO: namespace projected-820 deletion completed in 6.081827969s

â€¢ [SLOW TEST:10.136 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:29:09.924: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec 22 22:29:09.946: INFO: Waiting up to 5m0s for pod "pod-8884cf6b-3a05-42ce-b105-45210bad924e" in namespace "emptydir-1014" to be "success or failure"
Dec 22 22:29:09.949: INFO: Pod "pod-8884cf6b-3a05-42ce-b105-45210bad924e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.390817ms
Dec 22 22:29:11.952: INFO: Pod "pod-8884cf6b-3a05-42ce-b105-45210bad924e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006230435s
STEP: Saw pod success
Dec 22 22:29:11.952: INFO: Pod "pod-8884cf6b-3a05-42ce-b105-45210bad924e" satisfied condition "success or failure"
Dec 22 22:29:11.954: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod pod-8884cf6b-3a05-42ce-b105-45210bad924e container test-container: <nil>
STEP: delete the pod
Dec 22 22:29:11.970: INFO: Waiting for pod pod-8884cf6b-3a05-42ce-b105-45210bad924e to disappear
Dec 22 22:29:11.971: INFO: Pod pod-8884cf6b-3a05-42ce-b105-45210bad924e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:29:11.971: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1014" for this suite.
Dec 22 22:29:17.981: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:29:18.038: INFO: namespace emptydir-1014 deletion completed in 6.063370581s

â€¢ [SLOW TEST:8.114 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:29:18.038: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir volume type on node default medium
Dec 22 22:29:18.059: INFO: Waiting up to 5m0s for pod "pod-8bbbbf68-077b-41a0-a7fb-bd3b319f1d9f" in namespace "emptydir-7907" to be "success or failure"
Dec 22 22:29:18.061: INFO: Pod "pod-8bbbbf68-077b-41a0-a7fb-bd3b319f1d9f": Phase="Pending", Reason="", readiness=false. Elapsed: 1.56929ms
Dec 22 22:29:20.063: INFO: Pod "pod-8bbbbf68-077b-41a0-a7fb-bd3b319f1d9f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004024949s
STEP: Saw pod success
Dec 22 22:29:20.063: INFO: Pod "pod-8bbbbf68-077b-41a0-a7fb-bd3b319f1d9f" satisfied condition "success or failure"
Dec 22 22:29:20.065: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod pod-8bbbbf68-077b-41a0-a7fb-bd3b319f1d9f container test-container: <nil>
STEP: delete the pod
Dec 22 22:29:20.077: INFO: Waiting for pod pod-8bbbbf68-077b-41a0-a7fb-bd3b319f1d9f to disappear
Dec 22 22:29:20.079: INFO: Pod pod-8bbbbf68-077b-41a0-a7fb-bd3b319f1d9f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:29:20.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7907" for this suite.
Dec 22 22:29:26.091: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:29:26.201: INFO: namespace emptydir-7907 deletion completed in 6.117161391s

â€¢ [SLOW TEST:8.164 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:29:26.202: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-794e9865-97f4-4304-9d73-2eab1300195e
STEP: Creating a pod to test consume secrets
Dec 22 22:29:26.229: INFO: Waiting up to 5m0s for pod "pod-secrets-dc66dcf6-2643-4aa0-a34a-4a710ebda567" in namespace "secrets-4984" to be "success or failure"
Dec 22 22:29:26.235: INFO: Pod "pod-secrets-dc66dcf6-2643-4aa0-a34a-4a710ebda567": Phase="Pending", Reason="", readiness=false. Elapsed: 5.236621ms
Dec 22 22:29:28.237: INFO: Pod "pod-secrets-dc66dcf6-2643-4aa0-a34a-4a710ebda567": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008009365s
Dec 22 22:29:30.240: INFO: Pod "pod-secrets-dc66dcf6-2643-4aa0-a34a-4a710ebda567": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010919508s
STEP: Saw pod success
Dec 22 22:29:30.240: INFO: Pod "pod-secrets-dc66dcf6-2643-4aa0-a34a-4a710ebda567" satisfied condition "success or failure"
Dec 22 22:29:30.243: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod pod-secrets-dc66dcf6-2643-4aa0-a34a-4a710ebda567 container secret-volume-test: <nil>
STEP: delete the pod
Dec 22 22:29:30.263: INFO: Waiting for pod pod-secrets-dc66dcf6-2643-4aa0-a34a-4a710ebda567 to disappear
Dec 22 22:29:30.265: INFO: Pod pod-secrets-dc66dcf6-2643-4aa0-a34a-4a710ebda567 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:29:30.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4984" for this suite.
Dec 22 22:29:36.276: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:29:36.406: INFO: namespace secrets-4984 deletion completed in 6.138619992s

â€¢ [SLOW TEST:10.204 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:29:36.407: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec 22 22:29:36.427: INFO: Waiting up to 5m0s for pod "downwardapi-volume-95861edc-3262-47d4-b8e7-313205dc975c" in namespace "downward-api-5286" to be "success or failure"
Dec 22 22:29:36.429: INFO: Pod "downwardapi-volume-95861edc-3262-47d4-b8e7-313205dc975c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.126603ms
Dec 22 22:29:38.432: INFO: Pod "downwardapi-volume-95861edc-3262-47d4-b8e7-313205dc975c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004981078s
Dec 22 22:29:40.434: INFO: Pod "downwardapi-volume-95861edc-3262-47d4-b8e7-313205dc975c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007599009s
STEP: Saw pod success
Dec 22 22:29:40.434: INFO: Pod "downwardapi-volume-95861edc-3262-47d4-b8e7-313205dc975c" satisfied condition "success or failure"
Dec 22 22:29:40.436: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod downwardapi-volume-95861edc-3262-47d4-b8e7-313205dc975c container client-container: <nil>
STEP: delete the pod
Dec 22 22:29:40.450: INFO: Waiting for pod downwardapi-volume-95861edc-3262-47d4-b8e7-313205dc975c to disappear
Dec 22 22:29:40.453: INFO: Pod downwardapi-volume-95861edc-3262-47d4-b8e7-313205dc975c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:29:40.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5286" for this suite.
Dec 22 22:29:46.463: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:29:46.602: INFO: namespace downward-api-5286 deletion completed in 6.145558109s

â€¢ [SLOW TEST:10.195 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:29:46.602: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Dec 22 22:29:46.635: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-7598,SelfLink:/api/v1/namespaces/watch-7598/configmaps/e2e-watch-test-resource-version,UID:c3f2e018-e342-4104-a50c-88b9069eacc9,ResourceVersion:18838,Generation:0,CreationTimestamp:2019-12-22 22:29:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 22 22:29:46.635: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-7598,SelfLink:/api/v1/namespaces/watch-7598/configmaps/e2e-watch-test-resource-version,UID:c3f2e018-e342-4104-a50c-88b9069eacc9,ResourceVersion:18839,Generation:0,CreationTimestamp:2019-12-22 22:29:46 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:29:46.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7598" for this suite.
Dec 22 22:29:52.644: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:29:52.725: INFO: namespace watch-7598 deletion completed in 6.087158901s

â€¢ [SLOW TEST:6.123 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:29:52.725: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating replication controller my-hostname-basic-cf3f9390-1f89-4e39-8fcf-9be9f0553af7
Dec 22 22:29:52.805: INFO: Pod name my-hostname-basic-cf3f9390-1f89-4e39-8fcf-9be9f0553af7: Found 1 pods out of 1
Dec 22 22:29:52.805: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-cf3f9390-1f89-4e39-8fcf-9be9f0553af7" are running
Dec 22 22:29:54.839: INFO: Pod "my-hostname-basic-cf3f9390-1f89-4e39-8fcf-9be9f0553af7-74dcc" is running (conditions: [])
Dec 22 22:29:54.839: INFO: Trying to dial the pod
Dec 22 22:29:59.847: INFO: Controller my-hostname-basic-cf3f9390-1f89-4e39-8fcf-9be9f0553af7: Got expected result from replica 1 [my-hostname-basic-cf3f9390-1f89-4e39-8fcf-9be9f0553af7-74dcc]: "my-hostname-basic-cf3f9390-1f89-4e39-8fcf-9be9f0553af7-74dcc", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:29:59.847: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-8730" for this suite.
Dec 22 22:30:05.857: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:30:06.011: INFO: namespace replication-controller-8730 deletion completed in 6.160944953s

â€¢ [SLOW TEST:13.286 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:30:06.012: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-22ecf315-3260-46ab-9b08-406dcb9175b2
STEP: Creating a pod to test consume secrets
Dec 22 22:30:06.062: INFO: Waiting up to 5m0s for pod "pod-secrets-8b98158f-2ace-40a8-bf71-780c9ac8b1ed" in namespace "secrets-1157" to be "success or failure"
Dec 22 22:30:06.063: INFO: Pod "pod-secrets-8b98158f-2ace-40a8-bf71-780c9ac8b1ed": Phase="Pending", Reason="", readiness=false. Elapsed: 1.941298ms
Dec 22 22:30:08.066: INFO: Pod "pod-secrets-8b98158f-2ace-40a8-bf71-780c9ac8b1ed": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004423081s
STEP: Saw pod success
Dec 22 22:30:08.066: INFO: Pod "pod-secrets-8b98158f-2ace-40a8-bf71-780c9ac8b1ed" satisfied condition "success or failure"
Dec 22 22:30:08.068: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod pod-secrets-8b98158f-2ace-40a8-bf71-780c9ac8b1ed container secret-volume-test: <nil>
STEP: delete the pod
Dec 22 22:30:08.084: INFO: Waiting for pod pod-secrets-8b98158f-2ace-40a8-bf71-780c9ac8b1ed to disappear
Dec 22 22:30:08.086: INFO: Pod pod-secrets-8b98158f-2ace-40a8-bf71-780c9ac8b1ed no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:30:08.086: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1157" for this suite.
Dec 22 22:30:14.096: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:30:14.227: INFO: namespace secrets-1157 deletion completed in 6.138126537s
STEP: Destroying namespace "secret-namespace-3385" for this suite.
Dec 22 22:30:20.242: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:30:20.300: INFO: namespace secret-namespace-3385 deletion completed in 6.073648715s

â€¢ [SLOW TEST:14.289 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:30:20.301: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Starting the proxy
Dec 22 22:30:20.318: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-800494845 proxy --unix-socket=/tmp/kubectl-proxy-unix704497900/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:30:20.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7005" for this suite.
Dec 22 22:30:26.403: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:30:26.457: INFO: namespace kubectl-7005 deletion completed in 6.062689242s

â€¢ [SLOW TEST:6.156 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:30:26.458: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Dec 22 22:30:26.484: INFO: Pod name pod-release: Found 0 pods out of 1
Dec 22 22:30:31.486: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:30:31.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-7056" for this suite.
Dec 22 22:30:37.524: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:30:37.599: INFO: namespace replication-controller-7056 deletion completed in 6.095931652s

â€¢ [SLOW TEST:11.141 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:30:37.599: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-75a35a29-04bf-4783-b423-20ec79886a8f
STEP: Creating a pod to test consume secrets
Dec 22 22:30:37.622: INFO: Waiting up to 5m0s for pod "pod-secrets-01bfbf6e-864f-4879-a2a5-46d186bfab1b" in namespace "secrets-8943" to be "success or failure"
Dec 22 22:30:37.626: INFO: Pod "pod-secrets-01bfbf6e-864f-4879-a2a5-46d186bfab1b": Phase="Pending", Reason="", readiness=false. Elapsed: 3.861665ms
Dec 22 22:30:39.629: INFO: Pod "pod-secrets-01bfbf6e-864f-4879-a2a5-46d186bfab1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006664855s
STEP: Saw pod success
Dec 22 22:30:39.629: INFO: Pod "pod-secrets-01bfbf6e-864f-4879-a2a5-46d186bfab1b" satisfied condition "success or failure"
Dec 22 22:30:39.632: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod pod-secrets-01bfbf6e-864f-4879-a2a5-46d186bfab1b container secret-volume-test: <nil>
STEP: delete the pod
Dec 22 22:30:39.645: INFO: Waiting for pod pod-secrets-01bfbf6e-864f-4879-a2a5-46d186bfab1b to disappear
Dec 22 22:30:39.647: INFO: Pod pod-secrets-01bfbf6e-864f-4879-a2a5-46d186bfab1b no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:30:39.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8943" for this suite.
Dec 22 22:30:45.656: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:30:45.712: INFO: namespace secrets-8943 deletion completed in 6.062358307s

â€¢ [SLOW TEST:8.113 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:30:45.712: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-9005
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 22 22:30:45.729: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec 22 22:31:07.772: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.20.29.253 8081 | grep -v '^\s*$'] Namespace:pod-network-test-9005 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 22 22:31:07.772: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
Dec 22 22:31:08.920: INFO: Found all expected endpoints: [netserver-0]
Dec 22 22:31:08.923: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.20.27.39 8081 | grep -v '^\s*$'] Namespace:pod-network-test-9005 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 22 22:31:08.923: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
Dec 22 22:31:10.112: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:31:10.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-9005" for this suite.
Dec 22 22:31:32.125: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:31:32.245: INFO: namespace pod-network-test-9005 deletion completed in 22.128256893s

â€¢ [SLOW TEST:46.532 seconds]
[sig-network] Networking
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:31:32.246: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec 22 22:31:32.278: INFO: Waiting up to 5m0s for pod "pod-5baedd17-8701-42ee-aeac-335f59635702" in namespace "emptydir-7853" to be "success or failure"
Dec 22 22:31:32.282: INFO: Pod "pod-5baedd17-8701-42ee-aeac-335f59635702": Phase="Pending", Reason="", readiness=false. Elapsed: 3.420874ms
Dec 22 22:31:34.284: INFO: Pod "pod-5baedd17-8701-42ee-aeac-335f59635702": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005826233s
STEP: Saw pod success
Dec 22 22:31:34.284: INFO: Pod "pod-5baedd17-8701-42ee-aeac-335f59635702" satisfied condition "success or failure"
Dec 22 22:31:34.286: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod pod-5baedd17-8701-42ee-aeac-335f59635702 container test-container: <nil>
STEP: delete the pod
Dec 22 22:31:34.300: INFO: Waiting for pod pod-5baedd17-8701-42ee-aeac-335f59635702 to disappear
Dec 22 22:31:34.302: INFO: Pod pod-5baedd17-8701-42ee-aeac-335f59635702 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:31:34.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7853" for this suite.
Dec 22 22:31:40.315: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:31:40.376: INFO: namespace emptydir-7853 deletion completed in 6.067118374s

â€¢ [SLOW TEST:8.130 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:31:40.376: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-916
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating stateful set ss in namespace statefulset-916
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-916
Dec 22 22:31:40.410: INFO: Found 0 stateful pods, waiting for 1
Dec 22 22:31:50.419: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Dec 22 22:31:50.423: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-916 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 22 22:31:50.866: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Dec 22 22:31:50.866: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 22 22:31:50.866: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 22 22:31:50.869: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec 22 22:32:00.872: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 22 22:32:00.872: INFO: Waiting for statefulset status.replicas updated to 0
Dec 22 22:32:00.883: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
Dec 22 22:32:00.883: INFO: ss-0  ip-10-0-1-121.us-west-2.compute.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 22:31:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 22:31:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 22:31:51 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 22:31:40 +0000 UTC  }]
Dec 22 22:32:00.883: INFO: 
Dec 22 22:32:00.883: INFO: StatefulSet ss has not reached scale 3, at 1
Dec 22 22:32:01.887: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996602876s
Dec 22 22:32:02.893: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.992938522s
Dec 22 22:32:03.896: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.987104674s
Dec 22 22:32:04.899: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.983999907s
Dec 22 22:32:05.903: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.980682759s
Dec 22 22:32:06.906: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.976798945s
Dec 22 22:32:07.909: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.973705984s
Dec 22 22:32:08.912: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.970564817s
Dec 22 22:32:09.915: INFO: Verifying statefulset ss doesn't scale past 3 for another 967.392913ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-916
Dec 22 22:32:10.919: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-916 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 22 22:32:11.179: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Dec 22 22:32:11.179: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 22 22:32:11.179: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 22 22:32:11.179: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-916 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 22 22:32:11.392: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Dec 22 22:32:11.392: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 22 22:32:11.392: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 22 22:32:11.392: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-916 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 22 22:32:11.629: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Dec 22 22:32:11.629: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec 22 22:32:11.629: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec 22 22:32:11.633: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Dec 22 22:32:21.637: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 22 22:32:21.637: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 22 22:32:21.637: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Dec 22 22:32:21.641: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-916 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 22 22:32:21.905: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Dec 22 22:32:21.905: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 22 22:32:21.905: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 22 22:32:21.905: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-916 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 22 22:32:22.126: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Dec 22 22:32:22.126: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 22 22:32:22.126: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 22 22:32:22.126: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-916 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec 22 22:32:22.399: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Dec 22 22:32:22.399: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec 22 22:32:22.399: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec 22 22:32:22.399: INFO: Waiting for statefulset status.replicas updated to 0
Dec 22 22:32:22.402: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Dec 22 22:32:32.416: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 22 22:32:32.416: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec 22 22:32:32.416: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec 22 22:32:32.433: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
Dec 22 22:32:32.433: INFO: ss-0  ip-10-0-1-121.us-west-2.compute.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 22:31:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 22:32:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 22:32:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 22:31:40 +0000 UTC  }]
Dec 22 22:32:32.433: INFO: ss-1  ip-10-0-1-187.us-west-2.compute.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 22:32:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 22:32:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 22:32:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 22:32:00 +0000 UTC  }]
Dec 22 22:32:32.433: INFO: ss-2  ip-10-0-1-121.us-west-2.compute.internal  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 22:32:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 22:32:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 22:32:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 22:32:00 +0000 UTC  }]
Dec 22 22:32:32.433: INFO: 
Dec 22 22:32:32.433: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 22 22:32:33.437: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
Dec 22 22:32:33.437: INFO: ss-0  ip-10-0-1-121.us-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 22:31:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 22:32:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 22:32:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 22:31:40 +0000 UTC  }]
Dec 22 22:32:33.437: INFO: ss-1  ip-10-0-1-187.us-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 22:32:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 22:32:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 22:32:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 22:32:00 +0000 UTC  }]
Dec 22 22:32:33.437: INFO: ss-2  ip-10-0-1-121.us-west-2.compute.internal  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 22:32:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 22:32:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 22:32:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 22:32:00 +0000 UTC  }]
Dec 22 22:32:33.437: INFO: 
Dec 22 22:32:33.437: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 22 22:32:34.440: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
Dec 22 22:32:34.440: INFO: ss-1  ip-10-0-1-187.us-west-2.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 22:32:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 22:32:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 22:32:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 22:32:00 +0000 UTC  }]
Dec 22 22:32:34.440: INFO: 
Dec 22 22:32:34.440: INFO: StatefulSet ss has not reached scale 0, at 1
Dec 22 22:32:35.444: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
Dec 22 22:32:35.444: INFO: ss-1  ip-10-0-1-187.us-west-2.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 22:32:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 22:32:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 22:32:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 22:32:00 +0000 UTC  }]
Dec 22 22:32:35.444: INFO: 
Dec 22 22:32:35.444: INFO: StatefulSet ss has not reached scale 0, at 1
Dec 22 22:32:36.448: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
Dec 22 22:32:36.448: INFO: ss-1  ip-10-0-1-187.us-west-2.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 22:32:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 22:32:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 22:32:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 22:32:00 +0000 UTC  }]
Dec 22 22:32:36.449: INFO: 
Dec 22 22:32:36.449: INFO: StatefulSet ss has not reached scale 0, at 1
Dec 22 22:32:37.451: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
Dec 22 22:32:37.451: INFO: ss-1  ip-10-0-1-187.us-west-2.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 22:32:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 22:32:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 22:32:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 22:32:00 +0000 UTC  }]
Dec 22 22:32:37.451: INFO: 
Dec 22 22:32:37.451: INFO: StatefulSet ss has not reached scale 0, at 1
Dec 22 22:32:38.454: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
Dec 22 22:32:38.454: INFO: ss-1  ip-10-0-1-187.us-west-2.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 22:32:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 22:32:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 22:32:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 22:32:00 +0000 UTC  }]
Dec 22 22:32:38.454: INFO: 
Dec 22 22:32:38.454: INFO: StatefulSet ss has not reached scale 0, at 1
Dec 22 22:32:39.462: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
Dec 22 22:32:39.462: INFO: ss-1  ip-10-0-1-187.us-west-2.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 22:32:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 22:32:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 22:32:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 22:32:00 +0000 UTC  }]
Dec 22 22:32:39.462: INFO: 
Dec 22 22:32:39.462: INFO: StatefulSet ss has not reached scale 0, at 1
Dec 22 22:32:40.465: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
Dec 22 22:32:40.465: INFO: ss-1  ip-10-0-1-187.us-west-2.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 22:32:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 22:32:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 22:32:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 22:32:00 +0000 UTC  }]
Dec 22 22:32:40.465: INFO: 
Dec 22 22:32:40.465: INFO: StatefulSet ss has not reached scale 0, at 1
Dec 22 22:32:41.468: INFO: POD   NODE                                      PHASE    GRACE  CONDITIONS
Dec 22 22:32:41.468: INFO: ss-1  ip-10-0-1-187.us-west-2.compute.internal  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 22:32:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 22:32:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-22 22:32:22 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 22:32:00 +0000 UTC  }]
Dec 22 22:32:41.468: INFO: 
Dec 22 22:32:41.468: INFO: StatefulSet ss has not reached scale 0, at 1
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-916
Dec 22 22:32:42.472: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-916 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 22 22:32:42.576: INFO: rc: 1
Dec 22 22:32:42.576: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-916 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc003151dd0 exit status 1 <nil> <nil> true [0xc003bc2270 0xc003bc2288 0xc003bc22a0] [0xc003bc2270 0xc003bc2288 0xc003bc22a0] [0xc003bc2280 0xc003bc2298] [0xba6c10 0xba6c10] 0xc002c97f80 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1
Dec 22 22:32:52.576: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-916 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 22 22:32:52.655: INFO: rc: 1
Dec 22 22:32:52.655: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-916 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001ad21b0 exit status 1 <nil> <nil> true [0xc003bc22a8 0xc003bc22c0 0xc003bc22d8] [0xc003bc22a8 0xc003bc22c0 0xc003bc22d8] [0xc003bc22b8 0xc003bc22d0] [0xba6c10 0xba6c10] 0xc00125c300 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Dec 22 22:33:02.656: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-916 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 22 22:33:02.745: INFO: rc: 1
Dec 22 22:33:02.745: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-916 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001ad2570 exit status 1 <nil> <nil> true [0xc003bc22e0 0xc003bc2300 0xc003bc2318] [0xc003bc22e0 0xc003bc2300 0xc003bc2318] [0xc003bc22f0 0xc003bc2310] [0xba6c10 0xba6c10] 0xc00125c660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Dec 22 22:33:12.745: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-916 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 22 22:33:12.826: INFO: rc: 1
Dec 22 22:33:12.826: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-916 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001ad2960 exit status 1 <nil> <nil> true [0xc003bc2320 0xc003bc2338 0xc003bc2350] [0xc003bc2320 0xc003bc2338 0xc003bc2350] [0xc003bc2330 0xc003bc2348] [0xba6c10 0xba6c10] 0xc00125c9c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Dec 22 22:33:22.826: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-916 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 22 22:33:22.908: INFO: rc: 1
Dec 22 22:33:22.909: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-916 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc001ad2d20 exit status 1 <nil> <nil> true [0xc003bc2358 0xc003bc2370 0xc003bc2388] [0xc003bc2358 0xc003bc2370 0xc003bc2388] [0xc003bc2368 0xc003bc2380] [0xba6c10 0xba6c10] 0xc00125cd20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Dec 22 22:33:32.909: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-916 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 22 22:33:32.994: INFO: rc: 1
Dec 22 22:33:32.994: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-916 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002e79110 exit status 1 <nil> <nil> true [0xc0029ca500 0xc0029ca518 0xc0029ca530] [0xc0029ca500 0xc0029ca518 0xc0029ca530] [0xc0029ca510 0xc0029ca528] [0xba6c10 0xba6c10] 0xc002753d40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Dec 22 22:33:42.995: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-916 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 22 22:33:43.083: INFO: rc: 1
Dec 22 22:33:43.083: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-916 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002e794a0 exit status 1 <nil> <nil> true [0xc0029ca538 0xc0029ca550 0xc0029ca568] [0xc0029ca538 0xc0029ca550 0xc0029ca568] [0xc0029ca548 0xc0029ca560] [0xba6c10 0xba6c10] 0xc00337c0c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Dec 22 22:33:53.083: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-916 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 22 22:33:53.170: INFO: rc: 1
Dec 22 22:33:53.170: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-916 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002d0a3c0 exit status 1 <nil> <nil> true [0xc003bc2008 0xc003bc2020 0xc003bc2038] [0xc003bc2008 0xc003bc2020 0xc003bc2038] [0xc003bc2018 0xc003bc2030] [0xba6c10 0xba6c10] 0xc0027522a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Dec 22 22:34:03.171: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-916 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 22 22:34:03.273: INFO: rc: 1
Dec 22 22:34:03.273: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-916 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc003150360 exit status 1 <nil> <nil> true [0xc0029ca000 0xc0029ca018 0xc0029ca030] [0xc0029ca000 0xc0029ca018 0xc0029ca030] [0xc0029ca010 0xc0029ca028] [0xba6c10 0xba6c10] 0xc003bea2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Dec 22 22:34:13.274: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-916 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 22 22:34:13.362: INFO: rc: 1
Dec 22 22:34:13.362: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-916 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc003150720 exit status 1 <nil> <nil> true [0xc0029ca038 0xc0029ca050 0xc0029ca068] [0xc0029ca038 0xc0029ca050 0xc0029ca068] [0xc0029ca048 0xc0029ca060] [0xba6c10 0xba6c10] 0xc003bea600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Dec 22 22:34:23.362: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-916 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 22 22:34:23.442: INFO: rc: 1
Dec 22 22:34:23.442: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-916 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002d0a7b0 exit status 1 <nil> <nil> true [0xc003bc2040 0xc003bc2058 0xc003bc2070] [0xc003bc2040 0xc003bc2058 0xc003bc2070] [0xc003bc2050 0xc003bc2068] [0xba6c10 0xba6c10] 0xc002752600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Dec 22 22:34:33.442: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-916 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 22 22:34:33.527: INFO: rc: 1
Dec 22 22:34:33.527: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-916 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002d0ab40 exit status 1 <nil> <nil> true [0xc003bc2078 0xc003bc2090 0xc003bc20a8] [0xc003bc2078 0xc003bc2090 0xc003bc20a8] [0xc003bc2088 0xc003bc20a0] [0xba6c10 0xba6c10] 0xc002752960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Dec 22 22:34:43.527: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-916 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 22 22:34:43.596: INFO: rc: 1
Dec 22 22:34:43.596: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-916 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc003150b10 exit status 1 <nil> <nil> true [0xc0029ca070 0xc0029ca088 0xc0029ca0a0] [0xc0029ca070 0xc0029ca088 0xc0029ca0a0] [0xc0029ca080 0xc0029ca098] [0xba6c10 0xba6c10] 0xc003bea960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Dec 22 22:34:53.596: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-916 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 22 22:34:53.713: INFO: rc: 1
Dec 22 22:34:53.713: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-916 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc003150ed0 exit status 1 <nil> <nil> true [0xc0029ca0a8 0xc0029ca0c0 0xc0029ca0d8] [0xc0029ca0a8 0xc0029ca0c0 0xc0029ca0d8] [0xc0029ca0b8 0xc0029ca0d0] [0xba6c10 0xba6c10] 0xc003bead20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Dec 22 22:35:03.714: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-916 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 22 22:35:03.810: INFO: rc: 1
Dec 22 22:35:03.810: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-916 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002d0af00 exit status 1 <nil> <nil> true [0xc003bc20b0 0xc003bc20c8 0xc003bc20e0] [0xc003bc20b0 0xc003bc20c8 0xc003bc20e0] [0xc003bc20c0 0xc003bc20d8] [0xba6c10 0xba6c10] 0xc002752d80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Dec 22 22:35:13.810: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-916 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 22 22:35:13.895: INFO: rc: 1
Dec 22 22:35:13.895: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-916 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002d0b2c0 exit status 1 <nil> <nil> true [0xc003bc20e8 0xc003bc2100 0xc003bc2118] [0xc003bc20e8 0xc003bc2100 0xc003bc2118] [0xc003bc20f8 0xc003bc2110] [0xba6c10 0xba6c10] 0xc002753140 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Dec 22 22:35:23.895: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-916 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 22 22:35:23.968: INFO: rc: 1
Dec 22 22:35:23.969: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-916 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0031512c0 exit status 1 <nil> <nil> true [0xc0029ca0e0 0xc0029ca0f8 0xc0029ca110] [0xc0029ca0e0 0xc0029ca0f8 0xc0029ca110] [0xc0029ca0f0 0xc0029ca108] [0xba6c10 0xba6c10] 0xc003beb080 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Dec 22 22:35:33.969: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-916 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 22 22:35:34.091: INFO: rc: 1
Dec 22 22:35:34.091: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-916 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002d0b680 exit status 1 <nil> <nil> true [0xc003bc2120 0xc003bc2138 0xc003bc2150] [0xc003bc2120 0xc003bc2138 0xc003bc2150] [0xc003bc2130 0xc003bc2148] [0xba6c10 0xba6c10] 0xc0027534a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Dec 22 22:35:44.094: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-916 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 22 22:35:44.339: INFO: rc: 1
Dec 22 22:35:44.339: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-916 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc003151680 exit status 1 <nil> <nil> true [0xc0029ca118 0xc0029ca130 0xc0029ca148] [0xc0029ca118 0xc0029ca130 0xc0029ca148] [0xc0029ca128 0xc0029ca140] [0xba6c10 0xba6c10] 0xc003beb4a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Dec 22 22:35:54.339: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-916 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 22 22:35:54.407: INFO: rc: 1
Dec 22 22:35:54.407: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-916 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc003150390 exit status 1 <nil> <nil> true [0xc0029ca008 0xc0029ca020 0xc0029ca038] [0xc0029ca008 0xc0029ca020 0xc0029ca038] [0xc0029ca018 0xc0029ca030] [0xba6c10 0xba6c10] 0xc003bea2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Dec 22 22:36:04.408: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-916 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 22 22:36:04.485: INFO: rc: 1
Dec 22 22:36:04.485: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-916 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc003150750 exit status 1 <nil> <nil> true [0xc0029ca040 0xc0029ca058 0xc0029ca070] [0xc0029ca040 0xc0029ca058 0xc0029ca070] [0xc0029ca050 0xc0029ca068] [0xba6c10 0xba6c10] 0xc003bea600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Dec 22 22:36:14.485: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-916 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 22 22:36:14.563: INFO: rc: 1
Dec 22 22:36:14.563: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-916 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc003150b40 exit status 1 <nil> <nil> true [0xc0029ca078 0xc0029ca090 0xc0029ca0a8] [0xc0029ca078 0xc0029ca090 0xc0029ca0a8] [0xc0029ca088 0xc0029ca0a0] [0xba6c10 0xba6c10] 0xc003bea960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Dec 22 22:36:24.563: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-916 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 22 22:36:24.633: INFO: rc: 1
Dec 22 22:36:24.633: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-916 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002d0a450 exit status 1 <nil> <nil> true [0xc003bc2000 0xc003bc2018 0xc003bc2030] [0xc003bc2000 0xc003bc2018 0xc003bc2030] [0xc003bc2010 0xc003bc2028] [0xba6c10 0xba6c10] 0xc0027522a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Dec 22 22:36:34.633: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-916 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 22 22:36:34.706: INFO: rc: 1
Dec 22 22:36:34.706: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-916 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002d0a840 exit status 1 <nil> <nil> true [0xc003bc2038 0xc003bc2050 0xc003bc2068] [0xc003bc2038 0xc003bc2050 0xc003bc2068] [0xc003bc2048 0xc003bc2060] [0xba6c10 0xba6c10] 0xc002752600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Dec 22 22:36:44.706: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-916 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 22 22:36:44.783: INFO: rc: 1
Dec 22 22:36:44.783: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-916 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc003150f00 exit status 1 <nil> <nil> true [0xc0029ca0b0 0xc0029ca0c8 0xc0029ca0e0] [0xc0029ca0b0 0xc0029ca0c8 0xc0029ca0e0] [0xc0029ca0c0 0xc0029ca0d8] [0xba6c10 0xba6c10] 0xc003bead20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Dec 22 22:36:54.783: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-916 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 22 22:36:54.856: INFO: rc: 1
Dec 22 22:36:54.856: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-916 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002d0ac30 exit status 1 <nil> <nil> true [0xc003bc2070 0xc003bc2088 0xc003bc20a0] [0xc003bc2070 0xc003bc2088 0xc003bc20a0] [0xc003bc2080 0xc003bc2098] [0xba6c10 0xba6c10] 0xc002752960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Dec 22 22:37:04.856: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-916 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 22 22:37:04.935: INFO: rc: 1
Dec 22 22:37:04.936: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-916 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc003151320 exit status 1 <nil> <nil> true [0xc0029ca0e8 0xc0029ca100 0xc0029ca118] [0xc0029ca0e8 0xc0029ca100 0xc0029ca118] [0xc0029ca0f8 0xc0029ca110] [0xba6c10 0xba6c10] 0xc003beb080 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Dec 22 22:37:14.936: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-916 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 22 22:37:15.004: INFO: rc: 1
Dec 22 22:37:15.004: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-916 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002d0b020 exit status 1 <nil> <nil> true [0xc003bc20a8 0xc003bc20c0 0xc003bc20d8] [0xc003bc20a8 0xc003bc20c0 0xc003bc20d8] [0xc003bc20b8 0xc003bc20d0] [0xba6c10 0xba6c10] 0xc002752d80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Dec 22 22:37:25.005: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-916 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 22 22:37:25.108: INFO: rc: 1
Dec 22 22:37:25.108: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-916 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002d0b440 exit status 1 <nil> <nil> true [0xc003bc20e0 0xc003bc20f8 0xc003bc2110] [0xc003bc20e0 0xc003bc20f8 0xc003bc2110] [0xc003bc20f0 0xc003bc2108] [0xba6c10 0xba6c10] 0xc002753140 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Dec 22 22:37:35.108: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-916 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 22 22:37:35.186: INFO: rc: 1
Dec 22 22:37:35.186: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-916 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc003151740 exit status 1 <nil> <nil> true [0xc0029ca120 0xc0029ca138 0xc0029ca150] [0xc0029ca120 0xc0029ca138 0xc0029ca150] [0xc0029ca130 0xc0029ca148] [0xba6c10 0xba6c10] 0xc003beb4a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Dec 22 22:37:45.186: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 exec --namespace=statefulset-916 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec 22 22:37:45.260: INFO: rc: 1
Dec 22 22:37:45.260: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: 
Dec 22 22:37:45.260: INFO: Scaling statefulset ss to 0
Dec 22 22:37:45.267: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Dec 22 22:37:45.268: INFO: Deleting all statefulset in ns statefulset-916
Dec 22 22:37:45.270: INFO: Scaling statefulset ss to 0
Dec 22 22:37:45.276: INFO: Waiting for statefulset status.replicas updated to 0
Dec 22 22:37:45.278: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:37:45.284: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-916" for this suite.
Dec 22 22:37:51.295: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:37:51.351: INFO: namespace statefulset-916 deletion completed in 6.063402311s

â€¢ [SLOW TEST:370.975 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:37:51.352: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap configmap-5929/configmap-test-f6a5b8f0-7c81-4fd2-a940-33fd789eb341
STEP: Creating a pod to test consume configMaps
Dec 22 22:37:51.375: INFO: Waiting up to 5m0s for pod "pod-configmaps-389ce657-ce66-4876-a1cc-0e43dafcd328" in namespace "configmap-5929" to be "success or failure"
Dec 22 22:37:51.379: INFO: Pod "pod-configmaps-389ce657-ce66-4876-a1cc-0e43dafcd328": Phase="Pending", Reason="", readiness=false. Elapsed: 3.757962ms
Dec 22 22:37:53.382: INFO: Pod "pod-configmaps-389ce657-ce66-4876-a1cc-0e43dafcd328": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006926519s
Dec 22 22:37:55.385: INFO: Pod "pod-configmaps-389ce657-ce66-4876-a1cc-0e43dafcd328": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009720685s
STEP: Saw pod success
Dec 22 22:37:55.385: INFO: Pod "pod-configmaps-389ce657-ce66-4876-a1cc-0e43dafcd328" satisfied condition "success or failure"
Dec 22 22:37:55.387: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod pod-configmaps-389ce657-ce66-4876-a1cc-0e43dafcd328 container env-test: <nil>
STEP: delete the pod
Dec 22 22:37:55.400: INFO: Waiting for pod pod-configmaps-389ce657-ce66-4876-a1cc-0e43dafcd328 to disappear
Dec 22 22:37:55.402: INFO: Pod pod-configmaps-389ce657-ce66-4876-a1cc-0e43dafcd328 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:37:55.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5929" for this suite.
Dec 22 22:38:01.412: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:38:01.509: INFO: namespace configmap-5929 deletion completed in 6.10368839s

â€¢ [SLOW TEST:10.157 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:38:01.509: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:38:01.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6543" for this suite.
Dec 22 22:38:07.555: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:38:07.619: INFO: namespace kubelet-test-6543 deletion completed in 6.070116892s

â€¢ [SLOW TEST:6.110 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:38:07.619: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod busybox-f52b61bd-5328-4dad-a484-fe027064b469 in namespace container-probe-48
Dec 22 22:38:11.649: INFO: Started pod busybox-f52b61bd-5328-4dad-a484-fe027064b469 in namespace container-probe-48
STEP: checking the pod's current state and verifying that restartCount is present
Dec 22 22:38:11.652: INFO: Initial restart count of pod busybox-f52b61bd-5328-4dad-a484-fe027064b469 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:42:12.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-48" for this suite.
Dec 22 22:42:18.106: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:42:18.162: INFO: namespace container-probe-48 deletion completed in 6.063102993s

â€¢ [SLOW TEST:250.543 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:42:18.162: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4506.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-4506.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4506.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-4506.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 22 22:42:26.210: INFO: DNS probes using dns-test-fcd281e8-d700-49ff-ac23-2b7f8961b4fa succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4506.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-4506.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4506.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-4506.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 22 22:42:28.242: INFO: File wheezy_udp@dns-test-service-3.dns-4506.svc.cluster.local from pod  dns-4506/dns-test-8714384e-bad0-4ac0-aca9-e6db28e33db7 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 22 22:42:28.244: INFO: File jessie_udp@dns-test-service-3.dns-4506.svc.cluster.local from pod  dns-4506/dns-test-8714384e-bad0-4ac0-aca9-e6db28e33db7 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 22 22:42:28.244: INFO: Lookups using dns-4506/dns-test-8714384e-bad0-4ac0-aca9-e6db28e33db7 failed for: [wheezy_udp@dns-test-service-3.dns-4506.svc.cluster.local jessie_udp@dns-test-service-3.dns-4506.svc.cluster.local]

Dec 22 22:42:33.247: INFO: File wheezy_udp@dns-test-service-3.dns-4506.svc.cluster.local from pod  dns-4506/dns-test-8714384e-bad0-4ac0-aca9-e6db28e33db7 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 22 22:42:33.250: INFO: File jessie_udp@dns-test-service-3.dns-4506.svc.cluster.local from pod  dns-4506/dns-test-8714384e-bad0-4ac0-aca9-e6db28e33db7 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 22 22:42:33.250: INFO: Lookups using dns-4506/dns-test-8714384e-bad0-4ac0-aca9-e6db28e33db7 failed for: [wheezy_udp@dns-test-service-3.dns-4506.svc.cluster.local jessie_udp@dns-test-service-3.dns-4506.svc.cluster.local]

Dec 22 22:42:38.247: INFO: File wheezy_udp@dns-test-service-3.dns-4506.svc.cluster.local from pod  dns-4506/dns-test-8714384e-bad0-4ac0-aca9-e6db28e33db7 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 22 22:42:38.250: INFO: File jessie_udp@dns-test-service-3.dns-4506.svc.cluster.local from pod  dns-4506/dns-test-8714384e-bad0-4ac0-aca9-e6db28e33db7 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 22 22:42:38.250: INFO: Lookups using dns-4506/dns-test-8714384e-bad0-4ac0-aca9-e6db28e33db7 failed for: [wheezy_udp@dns-test-service-3.dns-4506.svc.cluster.local jessie_udp@dns-test-service-3.dns-4506.svc.cluster.local]

Dec 22 22:42:43.247: INFO: File wheezy_udp@dns-test-service-3.dns-4506.svc.cluster.local from pod  dns-4506/dns-test-8714384e-bad0-4ac0-aca9-e6db28e33db7 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 22 22:42:43.251: INFO: File jessie_udp@dns-test-service-3.dns-4506.svc.cluster.local from pod  dns-4506/dns-test-8714384e-bad0-4ac0-aca9-e6db28e33db7 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 22 22:42:43.251: INFO: Lookups using dns-4506/dns-test-8714384e-bad0-4ac0-aca9-e6db28e33db7 failed for: [wheezy_udp@dns-test-service-3.dns-4506.svc.cluster.local jessie_udp@dns-test-service-3.dns-4506.svc.cluster.local]

Dec 22 22:42:48.262: INFO: File wheezy_udp@dns-test-service-3.dns-4506.svc.cluster.local from pod  dns-4506/dns-test-8714384e-bad0-4ac0-aca9-e6db28e33db7 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 22 22:42:48.266: INFO: File jessie_udp@dns-test-service-3.dns-4506.svc.cluster.local from pod  dns-4506/dns-test-8714384e-bad0-4ac0-aca9-e6db28e33db7 contains '' instead of 'bar.example.com.'
Dec 22 22:42:48.266: INFO: Lookups using dns-4506/dns-test-8714384e-bad0-4ac0-aca9-e6db28e33db7 failed for: [wheezy_udp@dns-test-service-3.dns-4506.svc.cluster.local jessie_udp@dns-test-service-3.dns-4506.svc.cluster.local]

Dec 22 22:42:53.250: INFO: DNS probes using dns-test-8714384e-bad0-4ac0-aca9-e6db28e33db7 succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4506.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-4506.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4506.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-4506.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 22 22:42:57.298: INFO: DNS probes using dns-test-8a34d6bc-d2d9-4195-96a5-67dd2f30b0b4 succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:42:57.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4506" for this suite.
Dec 22 22:43:03.349: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:43:03.442: INFO: namespace dns-4506 deletion completed in 6.109229003s

â€¢ [SLOW TEST:45.280 seconds]
[sig-network] DNS
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:43:03.443: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-e65b6417-8153-4450-bcb3-f10c4ffb4d3c
STEP: Creating a pod to test consume configMaps
Dec 22 22:43:03.487: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-97e42596-4a54-4f68-9b15-7bf88a3e5d9d" in namespace "projected-7387" to be "success or failure"
Dec 22 22:43:03.501: INFO: Pod "pod-projected-configmaps-97e42596-4a54-4f68-9b15-7bf88a3e5d9d": Phase="Pending", Reason="", readiness=false. Elapsed: 14.665996ms
Dec 22 22:43:05.504: INFO: Pod "pod-projected-configmaps-97e42596-4a54-4f68-9b15-7bf88a3e5d9d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017425026s
STEP: Saw pod success
Dec 22 22:43:05.504: INFO: Pod "pod-projected-configmaps-97e42596-4a54-4f68-9b15-7bf88a3e5d9d" satisfied condition "success or failure"
Dec 22 22:43:05.527: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod pod-projected-configmaps-97e42596-4a54-4f68-9b15-7bf88a3e5d9d container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 22 22:43:05.594: INFO: Waiting for pod pod-projected-configmaps-97e42596-4a54-4f68-9b15-7bf88a3e5d9d to disappear
Dec 22 22:43:05.596: INFO: Pod pod-projected-configmaps-97e42596-4a54-4f68-9b15-7bf88a3e5d9d no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:43:05.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7387" for this suite.
Dec 22 22:43:11.633: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:43:11.692: INFO: namespace projected-7387 deletion completed in 6.06867893s

â€¢ [SLOW TEST:8.250 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:43:11.693: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Dec 22 22:43:11.712: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:43:15.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1594" for this suite.
Dec 22 22:43:37.611: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:43:37.714: INFO: namespace init-container-1594 deletion completed in 22.111631195s

â€¢ [SLOW TEST:26.022 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:43:37.715: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Dec 22 22:43:42.757: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:43:43.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-9046" for this suite.
Dec 22 22:44:05.781: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:44:05.913: INFO: namespace replicaset-9046 deletion completed in 22.138960228s

â€¢ [SLOW TEST:28.198 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:44:05.914: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Dec 22 22:44:05.943: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 22 22:44:05.948: INFO: Waiting for terminating namespaces to be deleted...
Dec 22 22:44:05.950: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-1-121.us-west-2.compute.internal before test
Dec 22 22:44:05.953: INFO: sonobuoy from sonobuoy started at 2019-12-22 21:18:58 +0000 UTC (1 container statuses recorded)
Dec 22 22:44:05.953: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 22 22:44:05.953: INFO: sonobuoy-systemd-logs-daemon-set-42c521be8b344bae-qnvsn from sonobuoy started at 2019-12-22 21:19:03 +0000 UTC (2 container statuses recorded)
Dec 22 22:44:05.953: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec 22 22:44:05.953: INFO: 	Container systemd-logs ready: true, restart count 1
Dec 22 22:44:05.953: INFO: calico-node-r5hns from kube-system started at 2019-12-22 21:13:22 +0000 UTC (1 container statuses recorded)
Dec 22 22:44:05.953: INFO: 	Container calico-node ready: true, restart count 0
Dec 22 22:44:05.953: INFO: 
Logging pods the kubelet thinks is on node ip-10-0-1-187.us-west-2.compute.internal before test
Dec 22 22:44:05.957: INFO: calico-node-bnxjf from kube-system started at 2019-12-22 21:13:27 +0000 UTC (1 container statuses recorded)
Dec 22 22:44:05.957: INFO: 	Container calico-node ready: true, restart count 0
Dec 22 22:44:05.957: INFO: sonobuoy-e2e-job-bfd4ea5b59194b8d from sonobuoy started at 2019-12-22 21:19:02 +0000 UTC (2 container statuses recorded)
Dec 22 22:44:05.957: INFO: 	Container e2e ready: true, restart count 0
Dec 22 22:44:05.957: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 22 22:44:05.957: INFO: sonobuoy-systemd-logs-daemon-set-42c521be8b344bae-95gp6 from sonobuoy started at 2019-12-22 21:19:03 +0000 UTC (2 container statuses recorded)
Dec 22 22:44:05.957: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec 22 22:44:05.957: INFO: 	Container systemd-logs ready: true, restart count 1
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-c86a9394-68cf-4398-8ef9-d4f90fa77db9 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-c86a9394-68cf-4398-8ef9-d4f90fa77db9 off the node ip-10-0-1-121.us-west-2.compute.internal
STEP: verifying the node doesn't have the label kubernetes.io/e2e-c86a9394-68cf-4398-8ef9-d4f90fa77db9
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:44:14.092: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-1610" for this suite.
Dec 22 22:44:42.103: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:44:42.216: INFO: namespace sched-pred-1610 deletion completed in 28.120576963s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

â€¢ [SLOW TEST:36.302 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:44:42.216: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec 22 22:44:48.284: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 22 22:44:48.286: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 22 22:44:50.287: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 22 22:44:50.290: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 22 22:44:52.287: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 22 22:44:52.289: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 22 22:44:54.287: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 22 22:44:54.289: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 22 22:44:56.287: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 22 22:44:56.289: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 22 22:44:58.287: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 22 22:44:58.290: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 22 22:45:00.287: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 22 22:45:00.290: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 22 22:45:02.287: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 22 22:45:02.290: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 22 22:45:04.287: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 22 22:45:04.289: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 22 22:45:06.287: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 22 22:45:06.289: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:45:06.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-3230" for this suite.
Dec 22 22:45:28.300: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:45:28.411: INFO: namespace container-lifecycle-hook-3230 deletion completed in 22.118327111s

â€¢ [SLOW TEST:46.195 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:45:28.411: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating all guestbook components
Dec 22 22:45:28.430: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Dec 22 22:45:28.430: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 create -f - --namespace=kubectl-2944'
Dec 22 22:45:28.801: INFO: stderr: ""
Dec 22 22:45:28.801: INFO: stdout: "service/redis-slave created\n"
Dec 22 22:45:28.802: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Dec 22 22:45:28.802: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 create -f - --namespace=kubectl-2944'
Dec 22 22:45:29.109: INFO: stderr: ""
Dec 22 22:45:29.109: INFO: stdout: "service/redis-master created\n"
Dec 22 22:45:29.109: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Dec 22 22:45:29.109: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 create -f - --namespace=kubectl-2944'
Dec 22 22:45:29.306: INFO: stderr: ""
Dec 22 22:45:29.306: INFO: stdout: "service/frontend created\n"
Dec 22 22:45:29.306: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Dec 22 22:45:29.306: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 create -f - --namespace=kubectl-2944'
Dec 22 22:45:29.505: INFO: stderr: ""
Dec 22 22:45:29.505: INFO: stdout: "deployment.apps/frontend created\n"
Dec 22 22:45:29.506: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Dec 22 22:45:29.506: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 create -f - --namespace=kubectl-2944'
Dec 22 22:45:29.657: INFO: stderr: ""
Dec 22 22:45:29.657: INFO: stdout: "deployment.apps/redis-master created\n"
Dec 22 22:45:29.657: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Dec 22 22:45:29.657: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 create -f - --namespace=kubectl-2944'
Dec 22 22:45:29.824: INFO: stderr: ""
Dec 22 22:45:29.824: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Dec 22 22:45:29.824: INFO: Waiting for all frontend pods to be Running.
Dec 22 22:45:44.875: INFO: Waiting for frontend to serve content.
Dec 22 22:45:49.898: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection timed out [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection time...', 110)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Stre in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Dec 22 22:45:54.907: INFO: Trying to add a new entry to the guestbook.
Dec 22 22:45:54.917: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Dec 22 22:45:54.924: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 delete --grace-period=0 --force -f - --namespace=kubectl-2944'
Dec 22 22:45:55.010: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 22 22:45:55.010: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Dec 22 22:45:55.010: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 delete --grace-period=0 --force -f - --namespace=kubectl-2944'
Dec 22 22:45:55.113: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 22 22:45:55.113: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Dec 22 22:45:55.113: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 delete --grace-period=0 --force -f - --namespace=kubectl-2944'
Dec 22 22:45:55.230: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 22 22:45:55.230: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec 22 22:45:55.230: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 delete --grace-period=0 --force -f - --namespace=kubectl-2944'
Dec 22 22:45:55.324: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 22 22:45:55.324: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec 22 22:45:55.325: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 delete --grace-period=0 --force -f - --namespace=kubectl-2944'
Dec 22 22:45:55.406: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 22 22:45:55.406: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Dec 22 22:45:55.406: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 delete --grace-period=0 --force -f - --namespace=kubectl-2944'
Dec 22 22:45:55.481: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 22 22:45:55.481: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:45:55.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2944" for this suite.
Dec 22 22:46:33.497: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:46:33.657: INFO: namespace kubectl-2944 deletion completed in 38.171872071s

â€¢ [SLOW TEST:65.246 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Guestbook application
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:46:33.657: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Dec 22 22:46:33.742: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:46:42.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6075" for this suite.
Dec 22 22:46:48.273: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:46:48.405: INFO: namespace pods-6075 deletion completed in 6.138131355s

â€¢ [SLOW TEST:14.748 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:46:48.405: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1420
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec 22 22:46:48.422: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-4685'
Dec 22 22:46:48.497: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec 22 22:46:48.497: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1426
Dec 22 22:46:50.507: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 delete deployment e2e-test-nginx-deployment --namespace=kubectl-4685'
Dec 22 22:46:50.594: INFO: stderr: ""
Dec 22 22:46:50.594: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:46:50.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4685" for this suite.
Dec 22 22:46:56.606: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:46:56.659: INFO: namespace kubectl-4685 deletion completed in 6.060632534s

â€¢ [SLOW TEST:8.254 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run default
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:46:56.659: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Dec 22 22:46:59.198: INFO: Successfully updated pod "labelsupdate2b0c9296-a1ca-4b1c-8d29-7549b3851165"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:47:03.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3038" for this suite.
Dec 22 22:47:25.234: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:47:25.325: INFO: namespace projected-3038 deletion completed in 22.097672197s

â€¢ [SLOW TEST:28.666 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:47:25.325: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-a0a64d59-1e33-4037-92d6-2bf8b3abd216
STEP: Creating a pod to test consume configMaps
Dec 22 22:47:25.356: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-de440c86-4232-4287-9957-eb5eb6023d5d" in namespace "projected-2830" to be "success or failure"
Dec 22 22:47:25.358: INFO: Pod "pod-projected-configmaps-de440c86-4232-4287-9957-eb5eb6023d5d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.205807ms
Dec 22 22:47:27.361: INFO: Pod "pod-projected-configmaps-de440c86-4232-4287-9957-eb5eb6023d5d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005197006s
STEP: Saw pod success
Dec 22 22:47:27.361: INFO: Pod "pod-projected-configmaps-de440c86-4232-4287-9957-eb5eb6023d5d" satisfied condition "success or failure"
Dec 22 22:47:27.364: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod pod-projected-configmaps-de440c86-4232-4287-9957-eb5eb6023d5d container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 22 22:47:27.377: INFO: Waiting for pod pod-projected-configmaps-de440c86-4232-4287-9957-eb5eb6023d5d to disappear
Dec 22 22:47:27.379: INFO: Pod pod-projected-configmaps-de440c86-4232-4287-9957-eb5eb6023d5d no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:47:27.379: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2830" for this suite.
Dec 22 22:47:33.389: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:47:33.540: INFO: namespace projected-2830 deletion completed in 6.157976548s

â€¢ [SLOW TEST:8.215 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:47:33.540: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:47:33.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3371" for this suite.
Dec 22 22:47:55.634: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:47:55.715: INFO: namespace pods-3371 deletion completed in 22.101008533s

â€¢ [SLOW TEST:22.175 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:47:55.716: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec 22 22:47:55.734: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Dec 22 22:47:57.769: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:47:58.780: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-962" for this suite.
Dec 22 22:48:04.791: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:48:04.850: INFO: namespace replication-controller-962 deletion completed in 6.066754659s

â€¢ [SLOW TEST:9.135 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:48:04.851: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: validating api versions
Dec 22 22:48:04.867: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 api-versions'
Dec 22 22:48:04.939: INFO: stderr: ""
Dec 22 22:48:04.939: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\ncrd.projectcalico.org/v1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1alpha1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:48:04.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-446" for this suite.
Dec 22 22:48:10.950: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:48:11.010: INFO: namespace kubectl-446 deletion completed in 6.06750777s

â€¢ [SLOW TEST:6.159 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:48:11.011: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec 22 22:48:13.051: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:48:13.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-7689" for this suite.
Dec 22 22:48:19.073: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:48:19.150: INFO: namespace container-runtime-7689 deletion completed in 6.083101377s

â€¢ [SLOW TEST:8.139 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:48:19.150: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Dec 22 22:48:21.728: INFO: Successfully updated pod "labelsupdate8c2bdaeb-4716-4809-84a4-f361a6132084"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:48:23.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7952" for this suite.
Dec 22 22:48:45.782: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:48:45.912: INFO: namespace downward-api-7952 deletion completed in 22.148453485s

â€¢ [SLOW TEST:26.762 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:48:45.913: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-87386e40-66ec-4d86-9d59-cccb18991116
STEP: Creating a pod to test consume secrets
Dec 22 22:48:45.934: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-fb816a3f-c586-43e4-8ab5-58eba579c1aa" in namespace "projected-1490" to be "success or failure"
Dec 22 22:48:45.937: INFO: Pod "pod-projected-secrets-fb816a3f-c586-43e4-8ab5-58eba579c1aa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.970228ms
Dec 22 22:48:47.940: INFO: Pod "pod-projected-secrets-fb816a3f-c586-43e4-8ab5-58eba579c1aa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005846036s
Dec 22 22:48:49.943: INFO: Pod "pod-projected-secrets-fb816a3f-c586-43e4-8ab5-58eba579c1aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008349373s
STEP: Saw pod success
Dec 22 22:48:49.943: INFO: Pod "pod-projected-secrets-fb816a3f-c586-43e4-8ab5-58eba579c1aa" satisfied condition "success or failure"
Dec 22 22:48:49.945: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod pod-projected-secrets-fb816a3f-c586-43e4-8ab5-58eba579c1aa container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 22 22:48:49.957: INFO: Waiting for pod pod-projected-secrets-fb816a3f-c586-43e4-8ab5-58eba579c1aa to disappear
Dec 22 22:48:49.960: INFO: Pod pod-projected-secrets-fb816a3f-c586-43e4-8ab5-58eba579c1aa no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:48:49.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1490" for this suite.
Dec 22 22:48:55.970: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:48:56.111: INFO: namespace projected-1490 deletion completed in 6.148294146s

â€¢ [SLOW TEST:10.199 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:48:56.113: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1222 22:49:02.177627      15 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec 22 22:49:02.177: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:49:02.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9299" for this suite.
Dec 22 22:49:08.200: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:49:08.306: INFO: namespace gc-9299 deletion completed in 6.121062852s

â€¢ [SLOW TEST:12.193 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:49:08.309: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec 22 22:49:10.367: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:49:10.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-750" for this suite.
Dec 22 22:49:16.425: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:49:16.488: INFO: namespace container-runtime-750 deletion completed in 6.084300429s

â€¢ [SLOW TEST:8.179 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:49:16.488: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap configmap-1980/configmap-test-58f76990-d23a-4c26-8b0f-85c8462a1e6c
STEP: Creating a pod to test consume configMaps
Dec 22 22:49:16.566: INFO: Waiting up to 5m0s for pod "pod-configmaps-32b6b0b5-cee0-49e7-b7d1-16ae5ea917a8" in namespace "configmap-1980" to be "success or failure"
Dec 22 22:49:16.568: INFO: Pod "pod-configmaps-32b6b0b5-cee0-49e7-b7d1-16ae5ea917a8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.472377ms
Dec 22 22:49:18.571: INFO: Pod "pod-configmaps-32b6b0b5-cee0-49e7-b7d1-16ae5ea917a8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005208752s
Dec 22 22:49:20.574: INFO: Pod "pod-configmaps-32b6b0b5-cee0-49e7-b7d1-16ae5ea917a8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008024887s
STEP: Saw pod success
Dec 22 22:49:20.574: INFO: Pod "pod-configmaps-32b6b0b5-cee0-49e7-b7d1-16ae5ea917a8" satisfied condition "success or failure"
Dec 22 22:49:20.576: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod pod-configmaps-32b6b0b5-cee0-49e7-b7d1-16ae5ea917a8 container env-test: <nil>
STEP: delete the pod
Dec 22 22:49:20.590: INFO: Waiting for pod pod-configmaps-32b6b0b5-cee0-49e7-b7d1-16ae5ea917a8 to disappear
Dec 22 22:49:20.591: INFO: Pod pod-configmaps-32b6b0b5-cee0-49e7-b7d1-16ae5ea917a8 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:49:20.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1980" for this suite.
Dec 22 22:49:26.603: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:49:26.717: INFO: namespace configmap-1980 deletion completed in 6.121237054s

â€¢ [SLOW TEST:10.228 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:49:26.717: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Dec 22 22:49:30.752: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-60ee56f5-e27d-4af5-bded-b793a60a46e0,GenerateName:,Namespace:events-4768,SelfLink:/api/v1/namespaces/events-4768/pods/send-events-60ee56f5-e27d-4af5-bded-b793a60a46e0,UID:d2b7a71c-3318-43b9-80f2-94ca194f35bb,ResourceVersion:22430,Generation:0,CreationTimestamp:2019-12-22 22:49:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 736800608,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.20.27.10/32,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sm2mg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sm2mg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-sm2mg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-121.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 22:49:26 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 22:49:28 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 22:49:28 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 22:49:26 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.121,PodIP:10.20.27.10,StartTime:2019-12-22 22:49:26 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-12-22 22:49:27 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://ee0ad2d8200ea69039d11ba2cf1d396cb92b698e34b633d2139955da219160eb}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Dec 22 22:49:32.755: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Dec 22 22:49:34.760: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:49:34.769: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-4768" for this suite.
Dec 22 22:50:12.784: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:50:12.913: INFO: namespace events-4768 deletion completed in 38.136890947s

â€¢ [SLOW TEST:46.195 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:50:12.913: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Dec 22 22:50:14.954: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-800494845 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Dec 22 22:50:20.039: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:50:20.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8783" for this suite.
Dec 22 22:50:26.057: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:50:26.124: INFO: namespace pods-8783 deletion completed in 6.079912996s

â€¢ [SLOW TEST:13.212 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be submitted and removed [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:50:26.125: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: getting the auto-created API token
Dec 22 22:50:26.709: INFO: created pod pod-service-account-defaultsa
Dec 22 22:50:26.709: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Dec 22 22:50:26.712: INFO: created pod pod-service-account-mountsa
Dec 22 22:50:26.712: INFO: pod pod-service-account-mountsa service account token volume mount: true
Dec 22 22:50:26.715: INFO: created pod pod-service-account-nomountsa
Dec 22 22:50:26.715: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Dec 22 22:50:26.736: INFO: created pod pod-service-account-defaultsa-mountspec
Dec 22 22:50:26.736: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Dec 22 22:50:26.760: INFO: created pod pod-service-account-mountsa-mountspec
Dec 22 22:50:26.760: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Dec 22 22:50:26.788: INFO: created pod pod-service-account-nomountsa-mountspec
Dec 22 22:50:26.788: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Dec 22 22:50:26.805: INFO: created pod pod-service-account-defaultsa-nomountspec
Dec 22 22:50:26.805: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Dec 22 22:50:26.816: INFO: created pod pod-service-account-mountsa-nomountspec
Dec 22 22:50:26.816: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Dec 22 22:50:26.828: INFO: created pod pod-service-account-nomountsa-nomountspec
Dec 22 22:50:26.828: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:50:26.828: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-8256" for this suite.
Dec 22 22:50:32.871: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:50:32.926: INFO: namespace svcaccounts-8256 deletion completed in 6.074082999s

â€¢ [SLOW TEST:6.802 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:50:32.927: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec 22 22:50:32.944: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Dec 22 22:50:32.949: INFO: Pod name sample-pod: Found 0 pods out of 1
Dec 22 22:50:37.952: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec 22 22:50:37.953: INFO: Creating deployment "test-rolling-update-deployment"
Dec 22 22:50:37.955: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Dec 22 22:50:37.960: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Dec 22 22:50:39.965: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Dec 22 22:50:39.967: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712651837, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712651837, loc:(*time.Location)(0x7ed0a00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712651838, loc:(*time.Location)(0x7ed0a00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712651837, loc:(*time.Location)(0x7ed0a00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-79f6b9d75c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 22 22:50:41.970: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Dec 22 22:50:41.983: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-8603,SelfLink:/apis/apps/v1/namespaces/deployment-8603/deployments/test-rolling-update-deployment,UID:4a68564d-8d45-4f28-b954-efa970d552ba,ResourceVersion:22779,Generation:1,CreationTimestamp:2019-12-22 22:50:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-12-22 22:50:37 +0000 UTC 2019-12-22 22:50:37 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-12-22 22:50:40 +0000 UTC 2019-12-22 22:50:37 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-79f6b9d75c" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Dec 22 22:50:41.988: INFO: New ReplicaSet "test-rolling-update-deployment-79f6b9d75c" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79f6b9d75c,GenerateName:,Namespace:deployment-8603,SelfLink:/apis/apps/v1/namespaces/deployment-8603/replicasets/test-rolling-update-deployment-79f6b9d75c,UID:c7a2d730-9d1f-4041-8ea1-043a343ca850,ResourceVersion:22768,Generation:1,CreationTimestamp:2019-12-22 22:50:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 4a68564d-8d45-4f28-b954-efa970d552ba 0xc002607297 0xc002607298}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Dec 22 22:50:41.988: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Dec 22 22:50:41.988: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-8603,SelfLink:/apis/apps/v1/namespaces/deployment-8603/replicasets/test-rolling-update-controller,UID:0030abe2-5502-4db2-bf20-5db0c96f59df,ResourceVersion:22778,Generation:2,CreationTimestamp:2019-12-22 22:50:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 4a68564d-8d45-4f28-b954-efa970d552ba 0xc0026071c7 0xc0026071c8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec 22 22:50:41.991: INFO: Pod "test-rolling-update-deployment-79f6b9d75c-t66d9" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79f6b9d75c-t66d9,GenerateName:test-rolling-update-deployment-79f6b9d75c-,Namespace:deployment-8603,SelfLink:/api/v1/namespaces/deployment-8603/pods/test-rolling-update-deployment-79f6b9d75c-t66d9,UID:9d313dad-bf15-41f3-8884-6d658b6e2cd2,ResourceVersion:22767,Generation:0,CreationTimestamp:2019-12-22 22:50:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{cni.projectcalico.org/podIP: 10.20.27.20/32,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-79f6b9d75c c7a2d730-9d1f-4041-8ea1-043a343ca850 0xc002607bb7 0xc002607bb8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-2t7m4 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2t7m4,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-2t7m4 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:ip-10-0-1-121.us-west-2.compute.internal,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 22:50:37 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 22:50:40 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 22:50:40 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-22 22:50:37 +0000 UTC  }],Message:,Reason:,HostIP:10.0.1.121,PodIP:10.20.27.20,StartTime:2019-12-22 22:50:37 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-12-22 22:50:39 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://b46dc02b999a85370b529e7047d69c5082af5e3508f2eb9065b80a88ef522647}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:50:41.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8603" for this suite.
Dec 22 22:50:48.002: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:50:48.072: INFO: namespace deployment-8603 deletion completed in 6.07797281s

â€¢ [SLOW TEST:15.146 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:50:48.073: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-6734
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a new StatefulSet
Dec 22 22:50:48.106: INFO: Found 0 stateful pods, waiting for 3
Dec 22 22:50:58.110: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 22 22:50:58.110: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 22 22:50:58.110: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Dec 22 22:50:58.134: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Dec 22 22:51:08.165: INFO: Updating stateful set ss2
Dec 22 22:51:08.172: INFO: Waiting for Pod statefulset-6734/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Restoring Pods to the correct revision when they are deleted
Dec 22 22:51:18.256: INFO: Found 1 stateful pods, waiting for 3
Dec 22 22:51:28.260: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 22 22:51:28.260: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 22 22:51:28.260: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Dec 22 22:51:28.282: INFO: Updating stateful set ss2
Dec 22 22:51:28.299: INFO: Waiting for Pod statefulset-6734/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Dec 22 22:51:38.320: INFO: Updating stateful set ss2
Dec 22 22:51:38.325: INFO: Waiting for StatefulSet statefulset-6734/ss2 to complete update
Dec 22 22:51:38.325: INFO: Waiting for Pod statefulset-6734/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Dec 22 22:51:48.331: INFO: Deleting all statefulset in ns statefulset-6734
Dec 22 22:51:48.333: INFO: Scaling statefulset ss2 to 0
Dec 22 22:52:18.345: INFO: Waiting for statefulset status.replicas updated to 0
Dec 22 22:52:18.348: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:52:18.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6734" for this suite.
Dec 22 22:52:24.372: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:52:24.507: INFO: namespace statefulset-6734 deletion completed in 6.143731121s

â€¢ [SLOW TEST:96.434 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:52:24.507: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec 22 22:52:26.551: INFO: Waiting up to 5m0s for pod "client-envvars-a19189aa-712d-4a1a-9da2-d8da1525fb44" in namespace "pods-5572" to be "success or failure"
Dec 22 22:52:26.556: INFO: Pod "client-envvars-a19189aa-712d-4a1a-9da2-d8da1525fb44": Phase="Pending", Reason="", readiness=false. Elapsed: 4.699843ms
Dec 22 22:52:28.559: INFO: Pod "client-envvars-a19189aa-712d-4a1a-9da2-d8da1525fb44": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008387062s
STEP: Saw pod success
Dec 22 22:52:28.559: INFO: Pod "client-envvars-a19189aa-712d-4a1a-9da2-d8da1525fb44" satisfied condition "success or failure"
Dec 22 22:52:28.562: INFO: Trying to get logs from node ip-10-0-1-121.us-west-2.compute.internal pod client-envvars-a19189aa-712d-4a1a-9da2-d8da1525fb44 container env3cont: <nil>
STEP: delete the pod
Dec 22 22:52:28.598: INFO: Waiting for pod client-envvars-a19189aa-712d-4a1a-9da2-d8da1525fb44 to disappear
Dec 22 22:52:28.601: INFO: Pod client-envvars-a19189aa-712d-4a1a-9da2-d8da1525fb44 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:52:28.601: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5572" for this suite.
Dec 22 22:53:12.613: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:53:12.713: INFO: namespace pods-5572 deletion completed in 44.10916625s

â€¢ [SLOW TEST:48.206 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:53:12.714: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name cm-test-opt-del-597af4e0-45a8-445f-8631-96ac1df656b3
STEP: Creating configMap with name cm-test-opt-upd-eef43e71-a7d0-4896-9c7c-325010407a12
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-597af4e0-45a8-445f-8631-96ac1df656b3
STEP: Updating configmap cm-test-opt-upd-eef43e71-a7d0-4896-9c7c-325010407a12
STEP: Creating configMap with name cm-test-opt-create-147dc882-69e7-4d93-86c4-20fa7365fbe3
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:53:16.875: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1551" for this suite.
Dec 22 22:53:38.886: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:53:38.944: INFO: namespace projected-1551 deletion completed in 22.065153179s

â€¢ [SLOW TEST:26.230 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:53:38.944: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:54:03.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-8213" for this suite.
Dec 22 22:54:09.086: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:54:09.239: INFO: namespace namespaces-8213 deletion completed in 6.160265755s
STEP: Destroying namespace "nsdeletetest-5979" for this suite.
Dec 22 22:54:09.240: INFO: Namespace nsdeletetest-5979 was already deleted
STEP: Destroying namespace "nsdeletetest-7423" for this suite.
Dec 22 22:54:15.249: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:54:15.322: INFO: namespace nsdeletetest-7423 deletion completed in 6.081168905s

â€¢ [SLOW TEST:36.377 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec 22 22:54:15.322: INFO: >>> kubeConfig: /tmp/kubeconfig-800494845
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1292
STEP: creating an rc
Dec 22 22:54:15.342: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 create -f - --namespace=kubectl-7123'
Dec 22 22:54:15.539: INFO: stderr: ""
Dec 22 22:54:15.539: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Waiting for Redis master to start.
Dec 22 22:54:16.542: INFO: Selector matched 1 pods for map[app:redis]
Dec 22 22:54:16.542: INFO: Found 0 / 1
Dec 22 22:54:17.545: INFO: Selector matched 1 pods for map[app:redis]
Dec 22 22:54:17.545: INFO: Found 1 / 1
Dec 22 22:54:17.545: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec 22 22:54:17.548: INFO: Selector matched 1 pods for map[app:redis]
Dec 22 22:54:17.548: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Dec 22 22:54:17.548: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 logs redis-master-n9s2j redis-master --namespace=kubectl-7123'
Dec 22 22:54:17.660: INFO: stderr: ""
Dec 22 22:54:17.661: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 22 Dec 22:54:16.671 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 22 Dec 22:54:16.671 # Server started, Redis version 3.2.12\n1:M 22 Dec 22:54:16.671 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 22 Dec 22:54:16.671 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Dec 22 22:54:17.661: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 logs redis-master-n9s2j redis-master --namespace=kubectl-7123 --tail=1'
Dec 22 22:54:17.756: INFO: stderr: ""
Dec 22 22:54:17.756: INFO: stdout: "1:M 22 Dec 22:54:16.671 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Dec 22 22:54:17.756: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 logs redis-master-n9s2j redis-master --namespace=kubectl-7123 --limit-bytes=1'
Dec 22 22:54:17.853: INFO: stderr: ""
Dec 22 22:54:17.853: INFO: stdout: " "
STEP: exposing timestamps
Dec 22 22:54:17.853: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 logs redis-master-n9s2j redis-master --namespace=kubectl-7123 --tail=1 --timestamps'
Dec 22 22:54:17.949: INFO: stderr: ""
Dec 22 22:54:17.949: INFO: stdout: "2019-12-22T22:54:16.673353995Z 1:M 22 Dec 22:54:16.671 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Dec 22 22:54:20.450: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 logs redis-master-n9s2j redis-master --namespace=kubectl-7123 --since=1s'
Dec 22 22:54:20.557: INFO: stderr: ""
Dec 22 22:54:20.558: INFO: stdout: ""
Dec 22 22:54:20.558: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 logs redis-master-n9s2j redis-master --namespace=kubectl-7123 --since=24h'
Dec 22 22:54:20.645: INFO: stderr: ""
Dec 22 22:54:20.645: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 22 Dec 22:54:16.671 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 22 Dec 22:54:16.671 # Server started, Redis version 3.2.12\n1:M 22 Dec 22:54:16.671 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 22 Dec 22:54:16.671 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
STEP: using delete to clean up resources
Dec 22 22:54:20.645: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 delete --grace-period=0 --force -f - --namespace=kubectl-7123'
Dec 22 22:54:20.793: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 22 22:54:20.793: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Dec 22 22:54:20.793: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 get rc,svc -l name=nginx --no-headers --namespace=kubectl-7123'
Dec 22 22:54:20.895: INFO: stderr: "No resources found.\n"
Dec 22 22:54:20.895: INFO: stdout: ""
Dec 22 22:54:20.895: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-800494845 get pods -l name=nginx --namespace=kubectl-7123 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 22 22:54:20.984: INFO: stderr: ""
Dec 22 22:54:20.984: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec 22 22:54:20.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7123" for this suite.
Dec 22 22:54:42.999: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 22 22:54:43.068: INFO: namespace kubectl-7123 deletion completed in 22.078423025s

â€¢ [SLOW TEST:27.746 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl logs
  /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.15.7-beta.0.34+76e131a00b86a9/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSDec 22 22:54:43.069: INFO: Running AfterSuite actions on all nodes
Dec 22 22:54:43.069: INFO: Running AfterSuite actions on node 1
Dec 22 22:54:43.069: INFO: Skipping dumping logs from cluster

Ran 215 of 4412 Specs in 5725.398 seconds
SUCCESS! -- 215 Passed | 0 Failed | 0 Pending | 4197 Skipped
PASS

Ginkgo ran 1 suite in 1h35m27.618008787s
Test Suite Passed
