Conformance test: not doing test setup.
I1203 14:35:51.778674    5066 e2e.go:243] Starting e2e run "ec88a771-0326-4e77-9674-12e2429f8350" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1575383749 - Will randomize all specs
Will run 215 of 4413 specs

Dec  3 14:36:42.307: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Deleting namespaces
I1203 14:36:42.367708    5066 e2e.go:98] Waiting for deletion of the following namespaces: []
STEP: Waiting for namespaces to vanish
Dec  3 14:36:44.379: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Dec  3 14:36:44.410: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Dec  3 14:36:44.488: INFO: 20 / 20 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Dec  3 14:36:44.488: INFO: expected 12 pod replicas in namespace 'kube-system', 12 are Running and Ready.
Dec  3 14:36:44.488: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Dec  3 14:36:44.504: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Dec  3 14:36:44.504: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Dec  3 14:36:44.504: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'node-exporter' (0 seconds elapsed)
Dec  3 14:36:44.504: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'node-problem-detector' (0 seconds elapsed)
Dec  3 14:36:44.504: INFO: e2e test version: v1.15.6
Dec  3 14:36:44.513: INFO: kube-apiserver version: v1.15.6
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:36:44.514: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
Dec  3 14:36:44.576: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Dec  3 14:36:44.610: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3489
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-4c682d5d-f772-4550-aa54-2fc6400c4397
STEP: Creating a pod to test consume configMaps
Dec  3 14:36:44.778: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-17cd7093-9a8f-4f7b-b6ab-63676a97e17f" in namespace "projected-3489" to be "success or failure"
Dec  3 14:36:44.788: INFO: Pod "pod-projected-configmaps-17cd7093-9a8f-4f7b-b6ab-63676a97e17f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.491199ms
Dec  3 14:36:46.799: INFO: Pod "pod-projected-configmaps-17cd7093-9a8f-4f7b-b6ab-63676a97e17f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021050962s
Dec  3 14:36:48.810: INFO: Pod "pod-projected-configmaps-17cd7093-9a8f-4f7b-b6ab-63676a97e17f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032657855s
STEP: Saw pod success
Dec  3 14:36:48.811: INFO: Pod "pod-projected-configmaps-17cd7093-9a8f-4f7b-b6ab-63676a97e17f" satisfied condition "success or failure"
Dec  3 14:36:48.821: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod pod-projected-configmaps-17cd7093-9a8f-4f7b-b6ab-63676a97e17f container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 14:36:48.990: INFO: Waiting for pod pod-projected-configmaps-17cd7093-9a8f-4f7b-b6ab-63676a97e17f to disappear
Dec  3 14:36:49.001: INFO: Pod pod-projected-configmaps-17cd7093-9a8f-4f7b-b6ab-63676a97e17f no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:36:49.001: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3489" for this suite.
Dec  3 14:36:55.054: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:36:55.480: INFO: namespace projected-3489 deletion completed in 6.460084517s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:36:55.481: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-9538
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-efd1241c-449f-41cb-8017-314d656bba82
STEP: Creating a pod to test consume secrets
Dec  3 14:36:55.695: INFO: Waiting up to 5m0s for pod "pod-secrets-480b0d21-a337-443f-90de-d4c2328f8cbd" in namespace "secrets-9538" to be "success or failure"
Dec  3 14:36:55.706: INFO: Pod "pod-secrets-480b0d21-a337-443f-90de-d4c2328f8cbd": Phase="Pending", Reason="", readiness=false. Elapsed: 10.575439ms
Dec  3 14:36:57.717: INFO: Pod "pod-secrets-480b0d21-a337-443f-90de-d4c2328f8cbd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021416696s
Dec  3 14:36:59.816: INFO: Pod "pod-secrets-480b0d21-a337-443f-90de-d4c2328f8cbd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.120380061s
STEP: Saw pod success
Dec  3 14:36:59.816: INFO: Pod "pod-secrets-480b0d21-a337-443f-90de-d4c2328f8cbd" satisfied condition "success or failure"
Dec  3 14:36:59.826: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod pod-secrets-480b0d21-a337-443f-90de-d4c2328f8cbd container secret-env-test: <nil>
STEP: delete the pod
Dec  3 14:36:59.858: INFO: Waiting for pod pod-secrets-480b0d21-a337-443f-90de-d4c2328f8cbd to disappear
Dec  3 14:36:59.868: INFO: Pod pod-secrets-480b0d21-a337-443f-90de-d4c2328f8cbd no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:36:59.868: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9538" for this suite.
Dec  3 14:37:05.920: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:37:06.355: INFO: namespace secrets-9538 deletion completed in 6.468150431s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:37:06.356: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3117
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating Redis RC
Dec  3 14:37:06.543: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-3117'
Dec  3 14:37:08.803: INFO: stderr: ""
Dec  3 14:37:08.803: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec  3 14:37:09.815: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 14:37:09.815: INFO: Found 0 / 1
Dec  3 14:37:10.814: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 14:37:10.814: INFO: Found 0 / 1
Dec  3 14:37:11.815: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 14:37:11.815: INFO: Found 1 / 1
Dec  3 14:37:11.815: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Dec  3 14:37:11.826: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 14:37:11.826: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec  3 14:37:11.826: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config patch pod redis-master-mnjzk --namespace=kubectl-3117 -p {"metadata":{"annotations":{"x":"y"}}}'
Dec  3 14:37:12.081: INFO: stderr: ""
Dec  3 14:37:12.081: INFO: stdout: "pod/redis-master-mnjzk patched\n"
STEP: checking annotations
Dec  3 14:37:12.092: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 14:37:12.092: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:37:12.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3117" for this suite.
Dec  3 14:37:34.144: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:37:34.544: INFO: namespace kubectl-3117 deletion completed in 22.433329493s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:37:34.545: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7290
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting the proxy server
Dec  3 14:37:34.729: INFO: Asynchronously running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:37:34.828: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7290" for this suite.
Dec  3 14:37:40.872: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:37:41.278: INFO: namespace kubectl-7290 deletion completed in 6.439111771s
•SSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:37:41.278: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-6168
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:37:43.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6168" for this suite.
Dec  3 14:38:25.576: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:38:25.970: INFO: namespace kubelet-test-6168 deletion completed in 42.425997812s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:38:25.970: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-2495
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-2495.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-2495.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2495.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-2495.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-2495.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2495.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec  3 14:38:40.759: INFO: DNS probes using dns-2495/dns-test-92dfa777-8c80-472d-b51e-1dcdde0f0fc9 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:38:40.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2495" for this suite.
Dec  3 14:38:46.827: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:38:47.265: INFO: namespace dns-2495 deletion completed in 6.470532417s
•SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:38:47.265: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-768
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Dec  3 14:38:50.059: INFO: Successfully updated pod "annotationupdatee327c36f-2777-4fdd-b5ee-587889b7e236"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:38:54.114: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-768" for this suite.
Dec  3 14:39:16.166: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:39:16.554: INFO: namespace projected-768 deletion completed in 22.421047997s
•SSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:39:16.555: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-5124
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec  3 14:39:16.823: INFO: Number of nodes with available pods: 0
Dec  3 14:39:16.823: INFO: Node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 is running more than one daemon pod
Dec  3 14:39:17.854: INFO: Number of nodes with available pods: 0
Dec  3 14:39:17.854: INFO: Node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 is running more than one daemon pod
Dec  3 14:39:18.853: INFO: Number of nodes with available pods: 0
Dec  3 14:39:18.853: INFO: Node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 is running more than one daemon pod
Dec  3 14:39:19.852: INFO: Number of nodes with available pods: 0
Dec  3 14:39:19.852: INFO: Node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 is running more than one daemon pod
Dec  3 14:39:20.853: INFO: Number of nodes with available pods: 0
Dec  3 14:39:21.135: INFO: Node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 is running more than one daemon pod
Dec  3 14:39:21.854: INFO: Number of nodes with available pods: 2
Dec  3 14:39:21.854: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Dec  3 14:39:21.910: INFO: Number of nodes with available pods: 1
Dec  3 14:39:21.910: INFO: Node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-r5glw is running more than one daemon pod
Dec  3 14:39:22.939: INFO: Number of nodes with available pods: 1
Dec  3 14:39:23.202: INFO: Node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-r5glw is running more than one daemon pod
Dec  3 14:39:23.939: INFO: Number of nodes with available pods: 2
Dec  3 14:39:23.939: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5124, will wait for the garbage collector to delete the pods
Dec  3 14:39:24.034: INFO: Deleting DaemonSet.extensions daemon-set took: 12.972551ms
Dec  3 14:39:24.434: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.392849ms
Dec  3 14:39:33.145: INFO: Number of nodes with available pods: 0
Dec  3 14:39:33.145: INFO: Number of running nodes: 0, number of available pods: 0
Dec  3 14:39:33.156: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-5124/daemonsets","resourceVersion":"3141"},"items":null}

Dec  3 14:39:33.167: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-5124/pods","resourceVersion":"3141"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:39:33.208: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5124" for this suite.
Dec  3 14:39:39.252: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:39:39.658: INFO: namespace daemonsets-5124 deletion completed in 6.438781743s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:39:39.659: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6005
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1456
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  3 14:39:39.842: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-6005'
Dec  3 14:39:39.985: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec  3 14:39:39.985: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Dec  3 14:39:40.005: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-z7wck]
Dec  3 14:39:40.005: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-z7wck" in namespace "kubectl-6005" to be "running and ready"
Dec  3 14:39:40.016: INFO: Pod "e2e-test-nginx-rc-z7wck": Phase="Pending", Reason="", readiness=false. Elapsed: 10.670299ms
Dec  3 14:39:42.027: INFO: Pod "e2e-test-nginx-rc-z7wck": Phase="Running", Reason="", readiness=true. Elapsed: 2.022023601s
Dec  3 14:39:42.027: INFO: Pod "e2e-test-nginx-rc-z7wck" satisfied condition "running and ready"
Dec  3 14:39:42.027: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-z7wck]
Dec  3 14:39:42.027: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs rc/e2e-test-nginx-rc --namespace=kubectl-6005'
Dec  3 14:39:42.328: INFO: stderr: ""
Dec  3 14:39:42.328: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1461
Dec  3 14:39:42.328: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete rc e2e-test-nginx-rc --namespace=kubectl-6005'
Dec  3 14:39:42.473: INFO: stderr: ""
Dec  3 14:39:42.473: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:39:42.473: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6005" for this suite.
Dec  3 14:39:48.524: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:39:48.918: INFO: namespace kubectl-6005 deletion completed in 6.426429685s
•S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:39:48.918: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-7844
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Dec  3 14:39:49.100: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec  3 14:39:49.121: INFO: Waiting for terminating namespaces to be deleted...
Dec  3 14:39:49.132: INFO: 
Logging pods the kubelet thinks is on node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 before test
Dec  3 14:39:49.156: INFO: calico-kube-controllers-5d785bc598-8q48p from kube-system started at 2019-12-03 14:26:43 +0000 UTC (1 container statuses recorded)
Dec  3 14:39:49.157: INFO: 	Container calico-kube-controllers ready: true, restart count 2
Dec  3 14:39:49.157: INFO: addons-nginx-ingress-controller-8468678b64-lvtp6 from kube-system started at 2019-12-03 14:26:43 +0000 UTC (1 container statuses recorded)
Dec  3 14:39:49.157: INFO: 	Container nginx-ingress-controller ready: true, restart count 1
Dec  3 14:39:49.157: INFO: node-problem-detector-c9sgc from kube-system started at 2019-12-03 14:26:23 +0000 UTC (1 container statuses recorded)
Dec  3 14:39:49.157: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec  3 14:39:49.157: INFO: calico-node-s9glf from kube-system started at 2019-12-03 14:26:23 +0000 UTC (1 container statuses recorded)
Dec  3 14:39:49.157: INFO: 	Container calico-node ready: true, restart count 0
Dec  3 14:39:49.157: INFO: kube-proxy-kst5c from kube-system started at 2019-12-03 14:26:23 +0000 UTC (1 container statuses recorded)
Dec  3 14:39:49.157: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  3 14:39:49.157: INFO: coredns-858b686868-btwxc from kube-system started at 2019-12-03 14:26:43 +0000 UTC (1 container statuses recorded)
Dec  3 14:39:49.157: INFO: 	Container coredns ready: true, restart count 0
Dec  3 14:39:49.157: INFO: node-exporter-42tbw from kube-system started at 2019-12-03 14:26:23 +0000 UTC (1 container statuses recorded)
Dec  3 14:39:49.157: INFO: 	Container node-exporter ready: true, restart count 0
Dec  3 14:39:49.157: INFO: metrics-server-5bd76bb595-8pxkg from kube-system started at 2019-12-03 14:26:43 +0000 UTC (1 container statuses recorded)
Dec  3 14:39:49.157: INFO: 	Container metrics-server ready: true, restart count 0
Dec  3 14:39:49.157: INFO: 
Logging pods the kubelet thinks is on node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-r5glw before test
Dec  3 14:39:49.211: INFO: calico-typha-vertical-autoscaler-656557779f-zz2kh from kube-system started at 2019-12-03 14:26:43 +0000 UTC (1 container statuses recorded)
Dec  3 14:39:49.211: INFO: 	Container autoscaler ready: true, restart count 4
Dec  3 14:39:49.211: INFO: coredns-858b686868-2fkln from kube-system started at 2019-12-03 14:26:43 +0000 UTC (1 container statuses recorded)
Dec  3 14:39:49.211: INFO: 	Container coredns ready: true, restart count 0
Dec  3 14:39:49.211: INFO: addons-kubernetes-dashboard-5c8d9945bc-6v6wm from kube-system started at 2019-12-03 14:26:43 +0000 UTC (1 container statuses recorded)
Dec  3 14:39:49.211: INFO: 	Container kubernetes-dashboard ready: true, restart count 1
Dec  3 14:39:49.211: INFO: kube-proxy-v4sb9 from kube-system started at 2019-12-03 14:26:21 +0000 UTC (1 container statuses recorded)
Dec  3 14:39:49.211: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  3 14:39:49.211: INFO: node-problem-detector-fbcm4 from kube-system started at 2019-12-03 14:26:21 +0000 UTC (1 container statuses recorded)
Dec  3 14:39:49.211: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec  3 14:39:49.211: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-88d6cff74-mp2kz from kube-system started at 2019-12-03 14:26:42 +0000 UTC (1 container statuses recorded)
Dec  3 14:39:49.211: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Dec  3 14:39:49.211: INFO: calico-typha-horizontal-autoscaler-554dfbfdd7-qwhfp from kube-system started at 2019-12-03 14:26:42 +0000 UTC (1 container statuses recorded)
Dec  3 14:39:49.211: INFO: 	Container autoscaler ready: true, restart count 0
Dec  3 14:39:49.211: INFO: vpn-shoot-5f48c598df-dqjlc from kube-system started at 2019-12-03 14:26:42 +0000 UTC (1 container statuses recorded)
Dec  3 14:39:49.211: INFO: 	Container vpn-shoot ready: true, restart count 0
Dec  3 14:39:49.211: INFO: calico-typha-deploy-5547c4cdc6-959hd from kube-system started at 2019-12-03 14:29:04 +0000 UTC (1 container statuses recorded)
Dec  3 14:39:49.211: INFO: 	Container calico-typha ready: true, restart count 0
Dec  3 14:39:49.211: INFO: calico-node-529d5 from kube-system started at 2019-12-03 14:26:21 +0000 UTC (1 container statuses recorded)
Dec  3 14:39:49.211: INFO: 	Container calico-node ready: true, restart count 0
Dec  3 14:39:49.211: INFO: blackbox-exporter-c87bdd467-v9ddq from kube-system started at 2019-12-03 14:26:21 +0000 UTC (1 container statuses recorded)
Dec  3 14:39:49.211: INFO: 	Container blackbox-exporter ready: true, restart count 0
Dec  3 14:39:49.211: INFO: node-exporter-6lmwr from kube-system started at 2019-12-03 14:26:21 +0000 UTC (1 container statuses recorded)
Dec  3 14:39:49.211: INFO: 	Container node-exporter ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15dce36438cffe05], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:39:50.276: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-7844" for this suite.
Dec  3 14:39:56.328: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:39:56.720: INFO: namespace sched-pred-7844 deletion completed in 6.424814787s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72
•SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:39:56.720: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-5966
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-projected-pmw4
STEP: Creating a pod to test atomic-volume-subpath
Dec  3 14:39:56.948: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-pmw4" in namespace "subpath-5966" to be "success or failure"
Dec  3 14:39:56.958: INFO: Pod "pod-subpath-test-projected-pmw4": Phase="Pending", Reason="", readiness=false. Elapsed: 10.256069ms
Dec  3 14:39:58.969: INFO: Pod "pod-subpath-test-projected-pmw4": Phase="Running", Reason="", readiness=true. Elapsed: 2.021133092s
Dec  3 14:40:00.980: INFO: Pod "pod-subpath-test-projected-pmw4": Phase="Running", Reason="", readiness=true. Elapsed: 4.03144979s
Dec  3 14:40:02.990: INFO: Pod "pod-subpath-test-projected-pmw4": Phase="Running", Reason="", readiness=true. Elapsed: 6.042199277s
Dec  3 14:40:05.001: INFO: Pod "pod-subpath-test-projected-pmw4": Phase="Running", Reason="", readiness=true. Elapsed: 8.052706316s
Dec  3 14:40:07.012: INFO: Pod "pod-subpath-test-projected-pmw4": Phase="Running", Reason="", readiness=true. Elapsed: 10.063548275s
Dec  3 14:40:09.023: INFO: Pod "pod-subpath-test-projected-pmw4": Phase="Running", Reason="", readiness=true. Elapsed: 12.074839461s
Dec  3 14:40:11.035: INFO: Pod "pod-subpath-test-projected-pmw4": Phase="Running", Reason="", readiness=true. Elapsed: 14.086699306s
Dec  3 14:40:13.051: INFO: Pod "pod-subpath-test-projected-pmw4": Phase="Running", Reason="", readiness=true. Elapsed: 16.102892123s
Dec  3 14:40:15.062: INFO: Pod "pod-subpath-test-projected-pmw4": Phase="Running", Reason="", readiness=true. Elapsed: 18.11409519s
Dec  3 14:40:17.074: INFO: Pod "pod-subpath-test-projected-pmw4": Phase="Running", Reason="", readiness=true. Elapsed: 20.12552611s
Dec  3 14:40:19.085: INFO: Pod "pod-subpath-test-projected-pmw4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.137007945s
STEP: Saw pod success
Dec  3 14:40:19.085: INFO: Pod "pod-subpath-test-projected-pmw4" satisfied condition "success or failure"
Dec  3 14:40:19.095: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod pod-subpath-test-projected-pmw4 container test-container-subpath-projected-pmw4: <nil>
STEP: delete the pod
Dec  3 14:40:19.169: INFO: Waiting for pod pod-subpath-test-projected-pmw4 to disappear
Dec  3 14:40:19.179: INFO: Pod pod-subpath-test-projected-pmw4 no longer exists
STEP: Deleting pod pod-subpath-test-projected-pmw4
Dec  3 14:40:19.179: INFO: Deleting pod "pod-subpath-test-projected-pmw4" in namespace "subpath-5966"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:40:19.189: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5966" for this suite.
Dec  3 14:40:25.239: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:40:25.628: INFO: namespace subpath-5966 deletion completed in 6.420449204s
•SSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:40:25.628: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8823
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-projected-all-test-volume-1eb6797c-0f98-4d6f-96ac-175a9d53d777
STEP: Creating secret with name secret-projected-all-test-volume-1848a01d-9736-448e-8c42-e15272ce672a
STEP: Creating a pod to test Check all projections for projected volume plugin
Dec  3 14:40:25.852: INFO: Waiting up to 5m0s for pod "projected-volume-55adf5e6-f653-4ae5-a25c-22f9549cd949" in namespace "projected-8823" to be "success or failure"
Dec  3 14:40:25.862: INFO: Pod "projected-volume-55adf5e6-f653-4ae5-a25c-22f9549cd949": Phase="Pending", Reason="", readiness=false. Elapsed: 10.029508ms
Dec  3 14:40:27.873: INFO: Pod "projected-volume-55adf5e6-f653-4ae5-a25c-22f9549cd949": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021048398s
Dec  3 14:40:29.884: INFO: Pod "projected-volume-55adf5e6-f653-4ae5-a25c-22f9549cd949": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031699447s
STEP: Saw pod success
Dec  3 14:40:29.884: INFO: Pod "projected-volume-55adf5e6-f653-4ae5-a25c-22f9549cd949" satisfied condition "success or failure"
Dec  3 14:40:29.895: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod projected-volume-55adf5e6-f653-4ae5-a25c-22f9549cd949 container projected-all-volume-test: <nil>
STEP: delete the pod
Dec  3 14:40:29.927: INFO: Waiting for pod projected-volume-55adf5e6-f653-4ae5-a25c-22f9549cd949 to disappear
Dec  3 14:40:29.937: INFO: Pod projected-volume-55adf5e6-f653-4ae5-a25c-22f9549cd949 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:40:29.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8823" for this suite.
Dec  3 14:40:35.998: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:40:36.400: INFO: namespace projected-8823 deletion completed in 6.441455534s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:40:36.400: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-4571
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec  3 14:40:36.635: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Dec  3 14:40:36.668: INFO: Number of nodes with available pods: 0
Dec  3 14:40:36.668: INFO: Node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 is running more than one daemon pod
Dec  3 14:40:37.698: INFO: Number of nodes with available pods: 0
Dec  3 14:40:37.698: INFO: Node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 is running more than one daemon pod
Dec  3 14:40:38.699: INFO: Number of nodes with available pods: 2
Dec  3 14:40:38.699: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Dec  3 14:40:38.778: INFO: Wrong image for pod: daemon-set-k9sms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec  3 14:40:38.778: INFO: Wrong image for pod: daemon-set-nqrg7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec  3 14:40:39.800: INFO: Wrong image for pod: daemon-set-k9sms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec  3 14:40:39.800: INFO: Wrong image for pod: daemon-set-nqrg7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec  3 14:40:40.800: INFO: Wrong image for pod: daemon-set-k9sms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec  3 14:40:40.801: INFO: Wrong image for pod: daemon-set-nqrg7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec  3 14:40:41.800: INFO: Wrong image for pod: daemon-set-k9sms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec  3 14:40:41.800: INFO: Pod daemon-set-k9sms is not available
Dec  3 14:40:41.800: INFO: Wrong image for pod: daemon-set-nqrg7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec  3 14:40:42.800: INFO: Wrong image for pod: daemon-set-k9sms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec  3 14:40:42.800: INFO: Pod daemon-set-k9sms is not available
Dec  3 14:40:42.800: INFO: Wrong image for pod: daemon-set-nqrg7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec  3 14:40:43.800: INFO: Wrong image for pod: daemon-set-k9sms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec  3 14:40:43.800: INFO: Pod daemon-set-k9sms is not available
Dec  3 14:40:43.800: INFO: Wrong image for pod: daemon-set-nqrg7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec  3 14:40:44.804: INFO: Wrong image for pod: daemon-set-k9sms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec  3 14:40:44.804: INFO: Pod daemon-set-k9sms is not available
Dec  3 14:40:44.804: INFO: Wrong image for pod: daemon-set-nqrg7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec  3 14:40:45.800: INFO: Wrong image for pod: daemon-set-k9sms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec  3 14:40:45.800: INFO: Pod daemon-set-k9sms is not available
Dec  3 14:40:45.800: INFO: Wrong image for pod: daemon-set-nqrg7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec  3 14:40:46.801: INFO: Wrong image for pod: daemon-set-k9sms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec  3 14:40:46.802: INFO: Pod daemon-set-k9sms is not available
Dec  3 14:40:46.802: INFO: Wrong image for pod: daemon-set-nqrg7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec  3 14:40:47.800: INFO: Wrong image for pod: daemon-set-k9sms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec  3 14:40:47.800: INFO: Pod daemon-set-k9sms is not available
Dec  3 14:40:47.800: INFO: Wrong image for pod: daemon-set-nqrg7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec  3 14:40:48.800: INFO: Wrong image for pod: daemon-set-k9sms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec  3 14:40:48.800: INFO: Pod daemon-set-k9sms is not available
Dec  3 14:40:48.800: INFO: Wrong image for pod: daemon-set-nqrg7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec  3 14:40:49.800: INFO: Wrong image for pod: daemon-set-k9sms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec  3 14:40:49.800: INFO: Pod daemon-set-k9sms is not available
Dec  3 14:40:49.800: INFO: Wrong image for pod: daemon-set-nqrg7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec  3 14:40:50.800: INFO: Wrong image for pod: daemon-set-k9sms. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec  3 14:40:50.800: INFO: Pod daemon-set-k9sms is not available
Dec  3 14:40:50.800: INFO: Wrong image for pod: daemon-set-nqrg7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec  3 14:40:51.800: INFO: Pod daemon-set-grfgh is not available
Dec  3 14:40:51.800: INFO: Wrong image for pod: daemon-set-nqrg7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec  3 14:40:52.799: INFO: Pod daemon-set-grfgh is not available
Dec  3 14:40:52.799: INFO: Wrong image for pod: daemon-set-nqrg7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec  3 14:40:53.800: INFO: Pod daemon-set-grfgh is not available
Dec  3 14:40:53.800: INFO: Wrong image for pod: daemon-set-nqrg7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec  3 14:40:54.800: INFO: Wrong image for pod: daemon-set-nqrg7. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Dec  3 14:40:54.800: INFO: Pod daemon-set-nqrg7 is not available
Dec  3 14:40:55.800: INFO: Pod daemon-set-czzmh is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Dec  3 14:40:55.892: INFO: Number of nodes with available pods: 1
Dec  3 14:40:55.892: INFO: Node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 is running more than one daemon pod
Dec  3 14:40:56.922: INFO: Number of nodes with available pods: 2
Dec  3 14:40:56.923: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4571, will wait for the garbage collector to delete the pods
Dec  3 14:40:57.094: INFO: Deleting DaemonSet.extensions daemon-set took: 12.910704ms
Dec  3 14:40:57.496: INFO: Terminating DaemonSet.extensions daemon-set pods took: 402.860981ms
Dec  3 14:41:11.011: INFO: Number of nodes with available pods: 0
Dec  3 14:41:11.011: INFO: Number of running nodes: 0, number of available pods: 0
Dec  3 14:41:11.022: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-4571/daemonsets","resourceVersion":"3517"},"items":null}

Dec  3 14:41:11.033: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-4571/pods","resourceVersion":"3517"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:41:11.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4571" for this suite.
Dec  3 14:41:17.116: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:41:17.509: INFO: namespace daemonsets-4571 deletion completed in 6.424347988s
•SSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:41:17.509: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-3344
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec  3 14:41:17.737: INFO: Creating ReplicaSet my-hostname-basic-1efe07e6-2923-4e54-b5bd-a42d42b395af
Dec  3 14:41:17.759: INFO: Pod name my-hostname-basic-1efe07e6-2923-4e54-b5bd-a42d42b395af: Found 1 pods out of 1
Dec  3 14:41:17.759: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-1efe07e6-2923-4e54-b5bd-a42d42b395af" is running
Dec  3 14:41:21.782: INFO: Pod "my-hostname-basic-1efe07e6-2923-4e54-b5bd-a42d42b395af-npj9s" is running (conditions: [{Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-03 14:41:17 +0000 UTC Reason: Message:}])
Dec  3 14:41:21.782: INFO: Trying to dial the pod
Dec  3 14:41:26.900: INFO: Controller my-hostname-basic-1efe07e6-2923-4e54-b5bd-a42d42b395af: Got expected result from replica 1 [my-hostname-basic-1efe07e6-2923-4e54-b5bd-a42d42b395af-npj9s]: "my-hostname-basic-1efe07e6-2923-4e54-b5bd-a42d42b395af-npj9s", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:41:26.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-3344" for this suite.
Dec  3 14:41:32.953: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:41:33.359: INFO: namespace replicaset-3344 deletion completed in 6.437576807s
•SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:41:33.360: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-1203
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec  3 14:41:35.597: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:41:35.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1203" for this suite.
Dec  3 14:41:41.672: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:41:42.064: INFO: namespace container-runtime-1203 deletion completed in 6.423886736s
•SSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:41:42.064: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-2888
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Dec  3 14:41:42.250: INFO: PodSpec: initContainers in spec.initContainers
Dec  3 14:42:27.823: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-ceda3507-ca91-4a64-bc08-536ce10f4c2d", GenerateName:"", Namespace:"init-container-2888", SelfLink:"/api/v1/namespaces/init-container-2888/pods/pod-init-ceda3507-ca91-4a64-bc08-536ce10f4c2d", UID:"8506bba3-6639-4f0f-9fa5-9ee773dfc92b", ResourceVersion:"3753", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63710980902, loc:(*time.Location)(0x7ed1a20)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"250014264"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"100.64.0.14/32", "kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-9nfqp", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001dfae00), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-9nfqp", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-9nfqp", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-9nfqp", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc002faae28), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-r5glw", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0024faf00), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002faaea0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002faaec0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc002faaec8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc002faaecc), PreemptionPolicy:(*v1.PreemptionPolicy)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710980902, loc:(*time.Location)(0x7ed1a20)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710980902, loc:(*time.Location)(0x7ed1a20)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710980902, loc:(*time.Location)(0x7ed1a20)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710980902, loc:(*time.Location)(0x7ed1a20)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.250.0.2", PodIP:"100.64.0.14", StartTime:(*v1.Time)(0xc00201f480), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002577e30)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002577ea0)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://53c794fb0e3fa354993130467b96437f1404ba18dfd1883aed3c077dae01bb7d"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00201f4c0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00201f4a0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:42:27.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-2888" for this suite.
Dec  3 14:42:49.881: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:42:50.284: INFO: namespace init-container-2888 deletion completed in 22.440776538s
•SSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:42:50.284: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2484
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-map-e4599c69-527a-4edc-aaa6-8bc41bd86981
STEP: Creating a pod to test consume secrets
Dec  3 14:42:50.494: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-63d7c1ee-7bfc-4007-b37c-d1b243a57153" in namespace "projected-2484" to be "success or failure"
Dec  3 14:42:50.504: INFO: Pod "pod-projected-secrets-63d7c1ee-7bfc-4007-b37c-d1b243a57153": Phase="Pending", Reason="", readiness=false. Elapsed: 10.577479ms
Dec  3 14:42:52.515: INFO: Pod "pod-projected-secrets-63d7c1ee-7bfc-4007-b37c-d1b243a57153": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021477586s
STEP: Saw pod success
Dec  3 14:42:52.515: INFO: Pod "pod-projected-secrets-63d7c1ee-7bfc-4007-b37c-d1b243a57153" satisfied condition "success or failure"
Dec  3 14:42:52.526: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod pod-projected-secrets-63d7c1ee-7bfc-4007-b37c-d1b243a57153 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  3 14:42:52.563: INFO: Waiting for pod pod-projected-secrets-63d7c1ee-7bfc-4007-b37c-d1b243a57153 to disappear
Dec  3 14:42:52.573: INFO: Pod pod-projected-secrets-63d7c1ee-7bfc-4007-b37c-d1b243a57153 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:42:52.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2484" for this suite.
Dec  3 14:42:58.625: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:42:59.022: INFO: namespace projected-2484 deletion completed in 6.429803308s
•SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:42:59.023: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in events-8636
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Dec  3 14:43:01.267: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-5a6744b9-da6e-4f46-b5a0-c9d12147d66c,GenerateName:,Namespace:events-8636,SelfLink:/api/v1/namespaces/events-8636/pods/send-events-5a6744b9-da6e-4f46-b5a0-c9d12147d66c,UID:0fc25621-e9f1-4c20-9364-fef981ba13ff,ResourceVersion:3866,Generation:0,CreationTimestamp:2019-12-03 14:42:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 213050520,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.64.1.22/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-gw52z {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-gw52z,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-gw52z true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0009b9e70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0009b9e90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:42:59 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:43:00 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:43:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:42:59 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.3,PodIP:100.64.1.22,StartTime:2019-12-03 14:42:59 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-12-03 14:43:00 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://7f3096fc6b8ab24cc24fa963b000be270b91d0907033f0b81ae13549108f6c5a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Dec  3 14:43:03.278: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Dec  3 14:43:05.290: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:43:05.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-8636" for this suite.
Dec  3 14:43:43.353: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:43:43.740: INFO: namespace events-8636 deletion completed in 38.420103165s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:43:43.741: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-6049
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Dec  3 14:43:52.027: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 14:43:52.037: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  3 14:43:54.038: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 14:43:54.048: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  3 14:43:56.038: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 14:43:56.049: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  3 14:43:58.038: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 14:43:58.048: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  3 14:44:00.038: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 14:44:00.048: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  3 14:44:02.038: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 14:44:02.053: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  3 14:44:04.038: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 14:44:04.048: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  3 14:44:06.038: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 14:44:06.049: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  3 14:44:08.038: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 14:44:08.048: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  3 14:44:10.038: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 14:44:10.049: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  3 14:44:12.038: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 14:44:12.049: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  3 14:44:14.038: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 14:44:14.048: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:44:14.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-6049" for this suite.
Dec  3 14:44:36.118: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:44:36.516: INFO: namespace container-lifecycle-hook-6049 deletion completed in 22.429857601s
•SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:44:36.516: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6029
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec  3 14:44:36.713: INFO: Waiting up to 5m0s for pod "downwardapi-volume-992010df-e5e1-40e7-901b-f491c23aea47" in namespace "projected-6029" to be "success or failure"
Dec  3 14:44:36.723: INFO: Pod "downwardapi-volume-992010df-e5e1-40e7-901b-f491c23aea47": Phase="Pending", Reason="", readiness=false. Elapsed: 9.874477ms
Dec  3 14:44:38.735: INFO: Pod "downwardapi-volume-992010df-e5e1-40e7-901b-f491c23aea47": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021491475s
Dec  3 14:44:40.746: INFO: Pod "downwardapi-volume-992010df-e5e1-40e7-901b-f491c23aea47": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032198651s
STEP: Saw pod success
Dec  3 14:44:40.746: INFO: Pod "downwardapi-volume-992010df-e5e1-40e7-901b-f491c23aea47" satisfied condition "success or failure"
Dec  3 14:44:40.756: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod downwardapi-volume-992010df-e5e1-40e7-901b-f491c23aea47 container client-container: <nil>
STEP: delete the pod
Dec  3 14:44:40.789: INFO: Waiting for pod downwardapi-volume-992010df-e5e1-40e7-901b-f491c23aea47 to disappear
Dec  3 14:44:40.799: INFO: Pod downwardapi-volume-992010df-e5e1-40e7-901b-f491c23aea47 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:44:40.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6029" for this suite.
Dec  3 14:44:46.849: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:44:47.247: INFO: namespace projected-6029 deletion completed in 6.428576385s
•S
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:44:47.247: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1877
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Dec  3 14:44:47.451: INFO: Waiting up to 5m0s for pod "downward-api-e7652c05-ad53-46e4-8a8a-d01c62c959aa" in namespace "downward-api-1877" to be "success or failure"
Dec  3 14:44:47.462: INFO: Pod "downward-api-e7652c05-ad53-46e4-8a8a-d01c62c959aa": Phase="Pending", Reason="", readiness=false. Elapsed: 10.380856ms
Dec  3 14:44:49.479: INFO: Pod "downward-api-e7652c05-ad53-46e4-8a8a-d01c62c959aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.027027588s
STEP: Saw pod success
Dec  3 14:44:49.479: INFO: Pod "downward-api-e7652c05-ad53-46e4-8a8a-d01c62c959aa" satisfied condition "success or failure"
Dec  3 14:44:49.489: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod downward-api-e7652c05-ad53-46e4-8a8a-d01c62c959aa container dapi-container: <nil>
STEP: delete the pod
Dec  3 14:44:49.522: INFO: Waiting for pod downward-api-e7652c05-ad53-46e4-8a8a-d01c62c959aa to disappear
Dec  3 14:44:49.532: INFO: Pod downward-api-e7652c05-ad53-46e4-8a8a-d01c62c959aa no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:44:49.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1877" for this suite.
Dec  3 14:44:55.583: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:44:55.976: INFO: namespace downward-api-1877 deletion completed in 6.425490758s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:44:55.977: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-4695
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod liveness-ec520c72-c76c-4122-9d69-53ea9c06000b in namespace container-probe-4695
Dec  3 14:45:00.199: INFO: Started pod liveness-ec520c72-c76c-4122-9d69-53ea9c06000b in namespace container-probe-4695
STEP: checking the pod's current state and verifying that restartCount is present
Dec  3 14:45:00.210: INFO: Initial restart count of pod liveness-ec520c72-c76c-4122-9d69-53ea9c06000b is 0
Dec  3 14:45:18.320: INFO: Restart count of pod container-probe-4695/liveness-ec520c72-c76c-4122-9d69-53ea9c06000b is now 1 (18.109931334s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:45:18.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4695" for this suite.
Dec  3 14:45:24.387: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:45:24.797: INFO: namespace container-probe-4695 deletion completed in 6.442847294s
•SSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:45:24.797: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5823
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1721
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  3 14:45:24.984: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=kubectl-5823'
Dec  3 14:45:25.117: INFO: stderr: ""
Dec  3 14:45:25.117: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Dec  3 14:45:30.167: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pod e2e-test-nginx-pod --namespace=kubectl-5823 -o json'
Dec  3 14:45:30.279: INFO: stderr: ""
Dec  3 14:45:30.279: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"100.64.1.28/32\",\n            \"kubernetes.io/psp\": \"e2e-test-privileged-psp\"\n        },\n        \"creationTimestamp\": \"2019-12-03T14:45:25Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"kubectl-5823\",\n        \"resourceVersion\": \"4306\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-5823/pods/e2e-test-nginx-pod\",\n        \"uid\": \"9d526798-6c08-40d2-a0c4-be801f5e0067\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-d7r5t\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-d7r5t\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-d7r5t\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-12-03T14:45:25Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-12-03T14:45:27Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-12-03T14:45:27Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-12-03T14:45:25Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://57e94f8968dff6a47e7034a736ccdd925a3b82a187bff009d59b0933a2129942\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-12-03T14:45:26Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.250.0.3\",\n        \"phase\": \"Running\",\n        \"podIP\": \"100.64.1.28\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-12-03T14:45:25Z\"\n    }\n}\n"
STEP: replace the image in the pod
Dec  3 14:45:30.280: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config replace -f - --namespace=kubectl-5823'
Dec  3 14:45:30.497: INFO: stderr: ""
Dec  3 14:45:30.497: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1726
Dec  3 14:45:30.508: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete pods e2e-test-nginx-pod --namespace=kubectl-5823'
Dec  3 14:45:43.058: INFO: stderr: ""
Dec  3 14:45:43.058: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:45:43.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5823" for this suite.
Dec  3 14:45:49.109: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:45:49.520: INFO: namespace kubectl-5823 deletion completed in 6.442846839s
•SSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:45:49.521: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-9662
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Dec  3 14:45:49.748: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-9662,SelfLink:/api/v1/namespaces/watch-9662/configmaps/e2e-watch-test-watch-closed,UID:9b0c2c1f-c477-487e-b227-09b2c26cf770,ResourceVersion:4374,Generation:0,CreationTimestamp:2019-12-03 14:45:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  3 14:45:49.748: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-9662,SelfLink:/api/v1/namespaces/watch-9662/configmaps/e2e-watch-test-watch-closed,UID:9b0c2c1f-c477-487e-b227-09b2c26cf770,ResourceVersion:4375,Generation:0,CreationTimestamp:2019-12-03 14:45:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Dec  3 14:45:49.791: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-9662,SelfLink:/api/v1/namespaces/watch-9662/configmaps/e2e-watch-test-watch-closed,UID:9b0c2c1f-c477-487e-b227-09b2c26cf770,ResourceVersion:4376,Generation:0,CreationTimestamp:2019-12-03 14:45:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  3 14:45:49.791: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-9662,SelfLink:/api/v1/namespaces/watch-9662/configmaps/e2e-watch-test-watch-closed,UID:9b0c2c1f-c477-487e-b227-09b2c26cf770,ResourceVersion:4377,Generation:0,CreationTimestamp:2019-12-03 14:45:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:45:49.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-9662" for this suite.
Dec  3 14:45:55.839: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:45:56.248: INFO: namespace watch-9662 deletion completed in 6.442683321s
•SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:45:56.249: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8105
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec  3 14:45:56.453: INFO: Waiting up to 5m0s for pod "downwardapi-volume-93661a3e-7be0-4eff-a80f-02b67f945e1d" in namespace "projected-8105" to be "success or failure"
Dec  3 14:45:56.464: INFO: Pod "downwardapi-volume-93661a3e-7be0-4eff-a80f-02b67f945e1d": Phase="Pending", Reason="", readiness=false. Elapsed: 10.418615ms
Dec  3 14:45:58.474: INFO: Pod "downwardapi-volume-93661a3e-7be0-4eff-a80f-02b67f945e1d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02114854s
STEP: Saw pod success
Dec  3 14:45:58.475: INFO: Pod "downwardapi-volume-93661a3e-7be0-4eff-a80f-02b67f945e1d" satisfied condition "success or failure"
Dec  3 14:45:58.485: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod downwardapi-volume-93661a3e-7be0-4eff-a80f-02b67f945e1d container client-container: <nil>
STEP: delete the pod
Dec  3 14:45:58.516: INFO: Waiting for pod downwardapi-volume-93661a3e-7be0-4eff-a80f-02b67f945e1d to disappear
Dec  3 14:45:58.527: INFO: Pod downwardapi-volume-93661a3e-7be0-4eff-a80f-02b67f945e1d no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:45:58.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8105" for this suite.
Dec  3 14:46:04.578: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:46:05.013: INFO: namespace projected-8105 deletion completed in 6.466674431s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:46:05.014: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-9965
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-efbae946-97c8-4171-92b4-dabf2e9bb167
STEP: Creating a pod to test consume secrets
Dec  3 14:46:05.223: INFO: Waiting up to 5m0s for pod "pod-secrets-cb5c70ea-eac8-435c-a90c-11d19182a11e" in namespace "secrets-9965" to be "success or failure"
Dec  3 14:46:05.233: INFO: Pod "pod-secrets-cb5c70ea-eac8-435c-a90c-11d19182a11e": Phase="Pending", Reason="", readiness=false. Elapsed: 9.900646ms
Dec  3 14:46:07.244: INFO: Pod "pod-secrets-cb5c70ea-eac8-435c-a90c-11d19182a11e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021481433s
STEP: Saw pod success
Dec  3 14:46:07.245: INFO: Pod "pod-secrets-cb5c70ea-eac8-435c-a90c-11d19182a11e" satisfied condition "success or failure"
Dec  3 14:46:07.262: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod pod-secrets-cb5c70ea-eac8-435c-a90c-11d19182a11e container secret-volume-test: <nil>
STEP: delete the pod
Dec  3 14:46:07.296: INFO: Waiting for pod pod-secrets-cb5c70ea-eac8-435c-a90c-11d19182a11e to disappear
Dec  3 14:46:07.306: INFO: Pod pod-secrets-cb5c70ea-eac8-435c-a90c-11d19182a11e no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:46:07.306: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9965" for this suite.
Dec  3 14:46:13.358: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:46:13.748: INFO: namespace secrets-9965 deletion completed in 6.423175684s
•S
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:46:13.748: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-5188
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec  3 14:46:18.511: INFO: Successfully updated pod "pod-update-08c54c30-c544-4b1d-bd69-c6170f403440"
STEP: verifying the updated pod is in kubernetes
Dec  3 14:46:18.533: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:46:18.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5188" for this suite.
Dec  3 14:46:36.588: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:46:37.015: INFO: namespace pods-5188 deletion completed in 18.460956139s
•SSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:46:37.083: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-945
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:46:39.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-945" for this suite.
Dec  3 14:47:25.428: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:47:25.831: INFO: namespace kubelet-test-945 deletion completed in 46.436590952s
•SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:47:25.832: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7780
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Dec  3 14:47:30.082: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec pod-sharedvolume-c221a731-1d2b-4272-8e73-1a14005a18b5 -c busybox-main-container --namespace=emptydir-7780 -- cat /usr/share/volumeshare/shareddata.txt'
Dec  3 14:47:31.090: INFO: stderr: ""
Dec  3 14:47:31.090: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:47:31.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7780" for this suite.
Dec  3 14:47:37.143: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:47:37.580: INFO: namespace emptydir-7780 deletion completed in 6.469825782s
•SSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:47:37.580: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-7647
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Dec  3 14:47:39.845: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:47:39.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-7647" for this suite.
Dec  3 14:48:01.930: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:48:02.331: INFO: namespace replicaset-7647 deletion completed in 22.432922042s
•SS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:48:02.331: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4814
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-e9b15bd1-9280-4027-b283-f04879eb539e
STEP: Creating a pod to test consume secrets
Dec  3 14:48:02.540: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-9cbdfa34-1a48-475a-9345-a98f3d2a9db5" in namespace "projected-4814" to be "success or failure"
Dec  3 14:48:02.551: INFO: Pod "pod-projected-secrets-9cbdfa34-1a48-475a-9345-a98f3d2a9db5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.334177ms
Dec  3 14:48:04.562: INFO: Pod "pod-projected-secrets-9cbdfa34-1a48-475a-9345-a98f3d2a9db5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021597594s
STEP: Saw pod success
Dec  3 14:48:04.562: INFO: Pod "pod-projected-secrets-9cbdfa34-1a48-475a-9345-a98f3d2a9db5" satisfied condition "success or failure"
Dec  3 14:48:04.572: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod pod-projected-secrets-9cbdfa34-1a48-475a-9345-a98f3d2a9db5 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  3 14:48:04.606: INFO: Waiting for pod pod-projected-secrets-9cbdfa34-1a48-475a-9345-a98f3d2a9db5 to disappear
Dec  3 14:48:04.616: INFO: Pod pod-projected-secrets-9cbdfa34-1a48-475a-9345-a98f3d2a9db5 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:48:04.616: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4814" for this suite.
Dec  3 14:48:10.667: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:48:11.065: INFO: namespace projected-4814 deletion completed in 6.429930134s
•SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:48:11.066: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-8170
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test use defaults
Dec  3 14:48:11.265: INFO: Waiting up to 5m0s for pod "client-containers-c3eb9d64-6335-4235-96e9-667f6f1c1015" in namespace "containers-8170" to be "success or failure"
Dec  3 14:48:11.275: INFO: Pod "client-containers-c3eb9d64-6335-4235-96e9-667f6f1c1015": Phase="Pending", Reason="", readiness=false. Elapsed: 10.244648ms
Dec  3 14:48:13.286: INFO: Pod "client-containers-c3eb9d64-6335-4235-96e9-667f6f1c1015": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020910599s
Dec  3 14:48:15.297: INFO: Pod "client-containers-c3eb9d64-6335-4235-96e9-667f6f1c1015": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03201308s
STEP: Saw pod success
Dec  3 14:48:15.309: INFO: Pod "client-containers-c3eb9d64-6335-4235-96e9-667f6f1c1015" satisfied condition "success or failure"
Dec  3 14:48:15.320: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod client-containers-c3eb9d64-6335-4235-96e9-667f6f1c1015 container test-container: <nil>
STEP: delete the pod
Dec  3 14:48:15.354: INFO: Waiting for pod client-containers-c3eb9d64-6335-4235-96e9-667f6f1c1015 to disappear
Dec  3 14:48:15.364: INFO: Pod client-containers-c3eb9d64-6335-4235-96e9-667f6f1c1015 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:48:15.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8170" for this suite.
Dec  3 14:48:21.420: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:48:21.822: INFO: namespace containers-8170 deletion completed in 6.43874243s
•SSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:48:21.895: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-7643
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-configmap-jvm9
STEP: Creating a pod to test atomic-volume-subpath
Dec  3 14:48:22.114: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-jvm9" in namespace "subpath-7643" to be "success or failure"
Dec  3 14:48:22.125: INFO: Pod "pod-subpath-test-configmap-jvm9": Phase="Pending", Reason="", readiness=false. Elapsed: 10.277633ms
Dec  3 14:48:24.136: INFO: Pod "pod-subpath-test-configmap-jvm9": Phase="Running", Reason="", readiness=true. Elapsed: 2.021408056s
Dec  3 14:48:26.149: INFO: Pod "pod-subpath-test-configmap-jvm9": Phase="Running", Reason="", readiness=true. Elapsed: 4.0350078s
Dec  3 14:48:28.160: INFO: Pod "pod-subpath-test-configmap-jvm9": Phase="Running", Reason="", readiness=true. Elapsed: 6.045850349s
Dec  3 14:48:30.171: INFO: Pod "pod-subpath-test-configmap-jvm9": Phase="Running", Reason="", readiness=true. Elapsed: 8.057050073s
Dec  3 14:48:32.182: INFO: Pod "pod-subpath-test-configmap-jvm9": Phase="Running", Reason="", readiness=true. Elapsed: 10.067970328s
Dec  3 14:48:34.193: INFO: Pod "pod-subpath-test-configmap-jvm9": Phase="Running", Reason="", readiness=true. Elapsed: 12.07843727s
Dec  3 14:48:36.204: INFO: Pod "pod-subpath-test-configmap-jvm9": Phase="Running", Reason="", readiness=true. Elapsed: 14.089204051s
Dec  3 14:48:38.216: INFO: Pod "pod-subpath-test-configmap-jvm9": Phase="Running", Reason="", readiness=true. Elapsed: 16.101421028s
Dec  3 14:48:40.227: INFO: Pod "pod-subpath-test-configmap-jvm9": Phase="Running", Reason="", readiness=true. Elapsed: 18.11299984s
Dec  3 14:48:42.239: INFO: Pod "pod-subpath-test-configmap-jvm9": Phase="Running", Reason="", readiness=true. Elapsed: 20.124132242s
Dec  3 14:48:44.249: INFO: Pod "pod-subpath-test-configmap-jvm9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.134980154s
STEP: Saw pod success
Dec  3 14:48:44.249: INFO: Pod "pod-subpath-test-configmap-jvm9" satisfied condition "success or failure"
Dec  3 14:48:44.260: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod pod-subpath-test-configmap-jvm9 container test-container-subpath-configmap-jvm9: <nil>
STEP: delete the pod
Dec  3 14:48:44.298: INFO: Waiting for pod pod-subpath-test-configmap-jvm9 to disappear
Dec  3 14:48:44.308: INFO: Pod pod-subpath-test-configmap-jvm9 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-jvm9
Dec  3 14:48:44.308: INFO: Deleting pod "pod-subpath-test-configmap-jvm9" in namespace "subpath-7643"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:48:44.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7643" for this suite.
Dec  3 14:48:50.373: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:48:50.780: INFO: namespace subpath-7643 deletion completed in 6.440078078s
•SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:48:50.780: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5040
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec  3 14:48:50.978: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0d501ce4-3cbb-4873-a9e6-17ff89355f9f" in namespace "projected-5040" to be "success or failure"
Dec  3 14:48:50.988: INFO: Pod "downwardapi-volume-0d501ce4-3cbb-4873-a9e6-17ff89355f9f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.194365ms
Dec  3 14:48:53.001: INFO: Pod "downwardapi-volume-0d501ce4-3cbb-4873-a9e6-17ff89355f9f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022457597s
STEP: Saw pod success
Dec  3 14:48:53.001: INFO: Pod "downwardapi-volume-0d501ce4-3cbb-4873-a9e6-17ff89355f9f" satisfied condition "success or failure"
Dec  3 14:48:53.011: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod downwardapi-volume-0d501ce4-3cbb-4873-a9e6-17ff89355f9f container client-container: <nil>
STEP: delete the pod
Dec  3 14:48:53.044: INFO: Waiting for pod downwardapi-volume-0d501ce4-3cbb-4873-a9e6-17ff89355f9f to disappear
Dec  3 14:48:53.055: INFO: Pod downwardapi-volume-0d501ce4-3cbb-4873-a9e6-17ff89355f9f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:48:53.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5040" for this suite.
Dec  3 14:48:59.108: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:48:59.552: INFO: namespace projected-5040 deletion completed in 6.477524193s
•SSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:48:59.552: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6762
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Dec  3 14:48:59.750: INFO: Waiting up to 5m0s for pod "downward-api-566b20e6-7144-46be-9f2f-04b497740067" in namespace "downward-api-6762" to be "success or failure"
Dec  3 14:48:59.760: INFO: Pod "downward-api-566b20e6-7144-46be-9f2f-04b497740067": Phase="Pending", Reason="", readiness=false. Elapsed: 10.079736ms
Dec  3 14:49:01.771: INFO: Pod "downward-api-566b20e6-7144-46be-9f2f-04b497740067": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02111701s
STEP: Saw pod success
Dec  3 14:49:01.771: INFO: Pod "downward-api-566b20e6-7144-46be-9f2f-04b497740067" satisfied condition "success or failure"
Dec  3 14:49:01.782: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod downward-api-566b20e6-7144-46be-9f2f-04b497740067 container dapi-container: <nil>
STEP: delete the pod
Dec  3 14:49:01.815: INFO: Waiting for pod downward-api-566b20e6-7144-46be-9f2f-04b497740067 to disappear
Dec  3 14:49:01.825: INFO: Pod downward-api-566b20e6-7144-46be-9f2f-04b497740067 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:49:01.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6762" for this suite.
Dec  3 14:49:07.879: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:49:08.318: INFO: namespace downward-api-6762 deletion completed in 6.474000729s
•SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:49:08.318: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5513
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1612
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  3 14:49:08.509: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-5513'
Dec  3 14:49:08.649: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec  3 14:49:08.649: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1617
Dec  3 14:49:08.660: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete jobs e2e-test-nginx-job --namespace=kubectl-5513'
Dec  3 14:49:08.793: INFO: stderr: ""
Dec  3 14:49:08.793: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:49:08.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5513" for this suite.
Dec  3 14:49:30.840: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:49:31.238: INFO: namespace kubectl-5513 deletion completed in 22.43304654s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:49:31.239: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-7519
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating replication controller my-hostname-basic-5f91f36f-5f45-443c-8ef6-4aac99eba76d
Dec  3 14:49:31.446: INFO: Pod name my-hostname-basic-5f91f36f-5f45-443c-8ef6-4aac99eba76d: Found 1 pods out of 1
Dec  3 14:49:31.446: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-5f91f36f-5f45-443c-8ef6-4aac99eba76d" are running
Dec  3 14:49:33.467: INFO: Pod "my-hostname-basic-5f91f36f-5f45-443c-8ef6-4aac99eba76d-xhzcz" is running (conditions: [{Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-03 14:49:31 +0000 UTC Reason: Message:}])
Dec  3 14:49:33.467: INFO: Trying to dial the pod
Dec  3 14:49:38.586: INFO: Controller my-hostname-basic-5f91f36f-5f45-443c-8ef6-4aac99eba76d: Got expected result from replica 1 [my-hostname-basic-5f91f36f-5f45-443c-8ef6-4aac99eba76d-xhzcz]: "my-hostname-basic-5f91f36f-5f45-443c-8ef6-4aac99eba76d-xhzcz", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:49:38.586: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-7519" for this suite.
Dec  3 14:49:44.640: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:49:45.066: INFO: namespace replication-controller-7519 deletion completed in 6.459007871s
•SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:49:45.066: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5204
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec  3 14:49:45.265: INFO: Waiting up to 5m0s for pod "pod-fd462a72-557e-45d1-bad6-7856aa1c19ed" in namespace "emptydir-5204" to be "success or failure"
Dec  3 14:49:45.275: INFO: Pod "pod-fd462a72-557e-45d1-bad6-7856aa1c19ed": Phase="Pending", Reason="", readiness=false. Elapsed: 10.189763ms
Dec  3 14:49:47.286: INFO: Pod "pod-fd462a72-557e-45d1-bad6-7856aa1c19ed": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021202373s
Dec  3 14:49:49.297: INFO: Pod "pod-fd462a72-557e-45d1-bad6-7856aa1c19ed": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032166396s
STEP: Saw pod success
Dec  3 14:49:49.297: INFO: Pod "pod-fd462a72-557e-45d1-bad6-7856aa1c19ed" satisfied condition "success or failure"
Dec  3 14:49:49.308: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod pod-fd462a72-557e-45d1-bad6-7856aa1c19ed container test-container: <nil>
STEP: delete the pod
Dec  3 14:49:49.340: INFO: Waiting for pod pod-fd462a72-557e-45d1-bad6-7856aa1c19ed to disappear
Dec  3 14:49:49.349: INFO: Pod pod-fd462a72-557e-45d1-bad6-7856aa1c19ed no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:49:49.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5204" for this suite.
Dec  3 14:49:55.403: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:49:55.851: INFO: namespace emptydir-5204 deletion completed in 6.482996963s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:49:55.852: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3939
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec  3 14:49:56.049: INFO: Waiting up to 5m0s for pod "pod-666f8c67-a4cf-4162-a188-6f8aa08a0537" in namespace "emptydir-3939" to be "success or failure"
Dec  3 14:49:56.060: INFO: Pod "pod-666f8c67-a4cf-4162-a188-6f8aa08a0537": Phase="Pending", Reason="", readiness=false. Elapsed: 10.24361ms
Dec  3 14:49:58.070: INFO: Pod "pod-666f8c67-a4cf-4162-a188-6f8aa08a0537": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020972443s
STEP: Saw pod success
Dec  3 14:49:58.071: INFO: Pod "pod-666f8c67-a4cf-4162-a188-6f8aa08a0537" satisfied condition "success or failure"
Dec  3 14:49:58.081: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod pod-666f8c67-a4cf-4162-a188-6f8aa08a0537 container test-container: <nil>
STEP: delete the pod
Dec  3 14:49:58.115: INFO: Waiting for pod pod-666f8c67-a4cf-4162-a188-6f8aa08a0537 to disappear
Dec  3 14:49:58.125: INFO: Pod pod-666f8c67-a4cf-4162-a188-6f8aa08a0537 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:49:58.125: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3939" for this suite.
Dec  3 14:50:04.175: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:50:04.596: INFO: namespace emptydir-3939 deletion completed in 6.451829418s
•SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:50:04.596: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4938
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec  3 14:50:04.791: INFO: Waiting up to 5m0s for pod "pod-9d292e1e-f157-431a-af49-0a0feda0f4a8" in namespace "emptydir-4938" to be "success or failure"
Dec  3 14:50:04.802: INFO: Pod "pod-9d292e1e-f157-431a-af49-0a0feda0f4a8": Phase="Pending", Reason="", readiness=false. Elapsed: 10.18162ms
Dec  3 14:50:06.813: INFO: Pod "pod-9d292e1e-f157-431a-af49-0a0feda0f4a8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021203868s
STEP: Saw pod success
Dec  3 14:50:06.813: INFO: Pod "pod-9d292e1e-f157-431a-af49-0a0feda0f4a8" satisfied condition "success or failure"
Dec  3 14:50:06.823: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod pod-9d292e1e-f157-431a-af49-0a0feda0f4a8 container test-container: <nil>
STEP: delete the pod
Dec  3 14:50:06.854: INFO: Waiting for pod pod-9d292e1e-f157-431a-af49-0a0feda0f4a8 to disappear
Dec  3 14:50:06.864: INFO: Pod pod-9d292e1e-f157-431a-af49-0a0feda0f4a8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:50:06.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4938" for this suite.
Dec  3 14:50:12.915: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:50:13.350: INFO: namespace emptydir-4938 deletion completed in 6.467803577s
•SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:50:13.350: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename aggregator
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in aggregator-5140
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:76
Dec  3 14:50:13.537: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Registering the sample API server.
Dec  3 14:50:14.290: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981414, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981414, loc:(*time.Location)(0x7ed1a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981414, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981414, loc:(*time.Location)(0x7ed1a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 14:50:16.301: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981414, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981414, loc:(*time.Location)(0x7ed1a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981414, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981414, loc:(*time.Location)(0x7ed1a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 14:50:18.302: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981414, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981414, loc:(*time.Location)(0x7ed1a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981414, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981414, loc:(*time.Location)(0x7ed1a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 14:50:20.302: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981414, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981414, loc:(*time.Location)(0x7ed1a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981414, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981414, loc:(*time.Location)(0x7ed1a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 14:50:22.302: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981414, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981414, loc:(*time.Location)(0x7ed1a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981414, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981414, loc:(*time.Location)(0x7ed1a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 14:50:24.301: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981414, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981414, loc:(*time.Location)(0x7ed1a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981414, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981414, loc:(*time.Location)(0x7ed1a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 14:50:29.107: INFO: Waited 2.79377602s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:67
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:50:29.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-5140" for this suite.
Dec  3 14:50:35.964: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:50:36.374: INFO: namespace aggregator-5140 deletion completed in 6.444029076s
•SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:50:36.375: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-4522
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: getting the auto-created API token
Dec  3 14:50:37.117: INFO: created pod pod-service-account-defaultsa
Dec  3 14:50:37.117: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Dec  3 14:50:37.128: INFO: created pod pod-service-account-mountsa
Dec  3 14:50:37.128: INFO: pod pod-service-account-mountsa service account token volume mount: true
Dec  3 14:50:37.139: INFO: created pod pod-service-account-nomountsa
Dec  3 14:50:37.139: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Dec  3 14:50:37.152: INFO: created pod pod-service-account-defaultsa-mountspec
Dec  3 14:50:37.152: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Dec  3 14:50:37.164: INFO: created pod pod-service-account-mountsa-mountspec
Dec  3 14:50:37.164: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Dec  3 14:50:37.176: INFO: created pod pod-service-account-nomountsa-mountspec
Dec  3 14:50:37.176: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Dec  3 14:50:37.187: INFO: created pod pod-service-account-defaultsa-nomountspec
Dec  3 14:50:37.187: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Dec  3 14:50:37.198: INFO: created pod pod-service-account-mountsa-nomountspec
Dec  3 14:50:37.198: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Dec  3 14:50:37.210: INFO: created pod pod-service-account-nomountsa-nomountspec
Dec  3 14:50:37.210: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:50:37.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-4522" for this suite.
Dec  3 14:50:43.262: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:50:43.663: INFO: namespace svcaccounts-4522 deletion completed in 6.434368861s
•SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:50:43.664: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9408
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Dec  3 14:50:43.862: INFO: Waiting up to 5m0s for pod "downward-api-f3948874-8851-4ae7-a240-b5f6eabc64e7" in namespace "downward-api-9408" to be "success or failure"
Dec  3 14:50:43.872: INFO: Pod "downward-api-f3948874-8851-4ae7-a240-b5f6eabc64e7": Phase="Pending", Reason="", readiness=false. Elapsed: 10.036748ms
Dec  3 14:50:45.883: INFO: Pod "downward-api-f3948874-8851-4ae7-a240-b5f6eabc64e7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021201086s
STEP: Saw pod success
Dec  3 14:50:45.883: INFO: Pod "downward-api-f3948874-8851-4ae7-a240-b5f6eabc64e7" satisfied condition "success or failure"
Dec  3 14:50:45.894: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod downward-api-f3948874-8851-4ae7-a240-b5f6eabc64e7 container dapi-container: <nil>
STEP: delete the pod
Dec  3 14:50:45.925: INFO: Waiting for pod downward-api-f3948874-8851-4ae7-a240-b5f6eabc64e7 to disappear
Dec  3 14:50:45.935: INFO: Pod downward-api-f3948874-8851-4ae7-a240-b5f6eabc64e7 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:50:45.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9408" for this suite.
Dec  3 14:50:51.987: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:50:52.394: INFO: namespace downward-api-9408 deletion completed in 6.439764711s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:50:52.394: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-5460
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec  3 14:50:52.612: INFO: (0) /api/v1/nodes/shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 14.619847ms)
Dec  3 14:50:52.655: INFO: (1) /api/v1/nodes/shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 43.033075ms)
Dec  3 14:50:52.668: INFO: (2) /api/v1/nodes/shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.95941ms)
Dec  3 14:50:52.680: INFO: (3) /api/v1/nodes/shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 11.747598ms)
Dec  3 14:50:52.692: INFO: (4) /api/v1/nodes/shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.026508ms)
Dec  3 14:50:52.704: INFO: (5) /api/v1/nodes/shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.193279ms)
Dec  3 14:50:52.717: INFO: (6) /api/v1/nodes/shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.561257ms)
Dec  3 14:50:52.729: INFO: (7) /api/v1/nodes/shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.424393ms)
Dec  3 14:50:52.742: INFO: (8) /api/v1/nodes/shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.195893ms)
Dec  3 14:50:52.755: INFO: (9) /api/v1/nodes/shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.89387ms)
Dec  3 14:50:52.767: INFO: (10) /api/v1/nodes/shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.315474ms)
Dec  3 14:50:52.780: INFO: (11) /api/v1/nodes/shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.512418ms)
Dec  3 14:50:52.792: INFO: (12) /api/v1/nodes/shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.817318ms)
Dec  3 14:50:52.805: INFO: (13) /api/v1/nodes/shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.89039ms)
Dec  3 14:50:52.818: INFO: (14) /api/v1/nodes/shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.594951ms)
Dec  3 14:50:52.831: INFO: (15) /api/v1/nodes/shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 13.170273ms)
Dec  3 14:50:52.844: INFO: (16) /api/v1/nodes/shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.661521ms)
Dec  3 14:50:52.857: INFO: (17) /api/v1/nodes/shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.922651ms)
Dec  3 14:50:52.870: INFO: (18) /api/v1/nodes/shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.973037ms)
Dec  3 14:50:52.884: INFO: (19) /api/v1/nodes/shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 14.262372ms)
[AfterEach] version v1
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:50:52.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-5460" for this suite.
Dec  3 14:50:58.928: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:50:59.341: INFO: namespace proxy-5460 deletion completed in 6.445743921s
•SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:50:59.342: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-4854
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-configmap-hzl6
STEP: Creating a pod to test atomic-volume-subpath
Dec  3 14:50:59.565: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-hzl6" in namespace "subpath-4854" to be "success or failure"
Dec  3 14:50:59.575: INFO: Pod "pod-subpath-test-configmap-hzl6": Phase="Pending", Reason="", readiness=false. Elapsed: 10.104483ms
Dec  3 14:51:01.586: INFO: Pod "pod-subpath-test-configmap-hzl6": Phase="Running", Reason="", readiness=true. Elapsed: 2.021075022s
Dec  3 14:51:03.597: INFO: Pod "pod-subpath-test-configmap-hzl6": Phase="Running", Reason="", readiness=true. Elapsed: 4.031637105s
Dec  3 14:51:05.608: INFO: Pod "pod-subpath-test-configmap-hzl6": Phase="Running", Reason="", readiness=true. Elapsed: 6.042880213s
Dec  3 14:51:07.619: INFO: Pod "pod-subpath-test-configmap-hzl6": Phase="Running", Reason="", readiness=true. Elapsed: 8.054164429s
Dec  3 14:51:09.630: INFO: Pod "pod-subpath-test-configmap-hzl6": Phase="Running", Reason="", readiness=true. Elapsed: 10.064792894s
Dec  3 14:51:11.641: INFO: Pod "pod-subpath-test-configmap-hzl6": Phase="Running", Reason="", readiness=true. Elapsed: 12.075921272s
Dec  3 14:51:13.652: INFO: Pod "pod-subpath-test-configmap-hzl6": Phase="Running", Reason="", readiness=true. Elapsed: 14.086590775s
Dec  3 14:51:15.662: INFO: Pod "pod-subpath-test-configmap-hzl6": Phase="Running", Reason="", readiness=true. Elapsed: 16.097138536s
Dec  3 14:51:17.673: INFO: Pod "pod-subpath-test-configmap-hzl6": Phase="Running", Reason="", readiness=true. Elapsed: 18.10810685s
Dec  3 14:51:19.684: INFO: Pod "pod-subpath-test-configmap-hzl6": Phase="Running", Reason="", readiness=true. Elapsed: 20.118841254s
Dec  3 14:51:21.694: INFO: Pod "pod-subpath-test-configmap-hzl6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.129383615s
STEP: Saw pod success
Dec  3 14:51:21.695: INFO: Pod "pod-subpath-test-configmap-hzl6" satisfied condition "success or failure"
Dec  3 14:51:21.705: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod pod-subpath-test-configmap-hzl6 container test-container-subpath-configmap-hzl6: <nil>
STEP: delete the pod
Dec  3 14:51:21.738: INFO: Waiting for pod pod-subpath-test-configmap-hzl6 to disappear
Dec  3 14:51:21.748: INFO: Pod pod-subpath-test-configmap-hzl6 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-hzl6
Dec  3 14:51:21.748: INFO: Deleting pod "pod-subpath-test-configmap-hzl6" in namespace "subpath-4854"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:51:21.758: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4854" for this suite.
Dec  3 14:51:27.809: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:51:28.199: INFO: namespace subpath-4854 deletion completed in 6.421955857s
•SS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:51:28.199: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5654
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Dec  3 14:51:28.397: INFO: Waiting up to 5m0s for pod "downward-api-90fd93c3-ccc0-485b-aa5c-f1f122707917" in namespace "downward-api-5654" to be "success or failure"
Dec  3 14:51:28.408: INFO: Pod "downward-api-90fd93c3-ccc0-485b-aa5c-f1f122707917": Phase="Pending", Reason="", readiness=false. Elapsed: 11.163648ms
Dec  3 14:51:30.420: INFO: Pod "downward-api-90fd93c3-ccc0-485b-aa5c-f1f122707917": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02264662s
STEP: Saw pod success
Dec  3 14:51:30.420: INFO: Pod "downward-api-90fd93c3-ccc0-485b-aa5c-f1f122707917" satisfied condition "success or failure"
Dec  3 14:51:30.430: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod downward-api-90fd93c3-ccc0-485b-aa5c-f1f122707917 container dapi-container: <nil>
STEP: delete the pod
Dec  3 14:51:30.466: INFO: Waiting for pod downward-api-90fd93c3-ccc0-485b-aa5c-f1f122707917 to disappear
Dec  3 14:51:30.477: INFO: Pod downward-api-90fd93c3-ccc0-485b-aa5c-f1f122707917 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:51:30.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5654" for this suite.
Dec  3 14:51:36.531: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:51:36.941: INFO: namespace downward-api-5654 deletion completed in 6.443934863s
•SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:51:36.941: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9377
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Dec  3 14:51:39.793: INFO: Successfully updated pod "annotationupdate5ab5eb5f-0439-420e-99d2-60abb728a0f4"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:51:43.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9377" for this suite.
Dec  3 14:52:05.906: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:52:06.325: INFO: namespace downward-api-9377 deletion completed in 22.456026697s
•SSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:52:06.326: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-4802
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-mr6ln in namespace proxy-4802
I1203 14:52:06.541016    5066 runners.go:180] Created replication controller with name: proxy-service-mr6ln, namespace: proxy-4802, replica count: 1
I1203 14:52:07.591652    5066 runners.go:180] proxy-service-mr6ln Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1203 14:52:08.591856    5066 runners.go:180] proxy-service-mr6ln Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1203 14:52:09.592136    5066 runners.go:180] proxy-service-mr6ln Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1203 14:52:10.592345    5066 runners.go:180] proxy-service-mr6ln Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1203 14:52:11.592549    5066 runners.go:180] proxy-service-mr6ln Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec  3 14:52:11.603: INFO: setup took 5.090669618s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Dec  3 14:52:11.623: INFO: (0) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:162/proxy/: bar (200; 19.163477ms)
Dec  3 14:52:11.623: INFO: (0) /api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:1080/proxy/rewriteme">... (200; 19.31228ms)
Dec  3 14:52:11.641: INFO: (0) /api/v1/namespaces/proxy-4802/services/proxy-service-mr6ln:portname2/proxy/: bar (200; 37.557534ms)
Dec  3 14:52:11.641: INFO: (0) /api/v1/namespaces/proxy-4802/services/http:proxy-service-mr6ln:portname2/proxy/: bar (200; 37.527858ms)
Dec  3 14:52:11.641: INFO: (0) /api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:162/proxy/: bar (200; 37.571628ms)
Dec  3 14:52:11.641: INFO: (0) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:1080/proxy/rewriteme">test<... (200; 37.596622ms)
Dec  3 14:52:11.641: INFO: (0) /api/v1/namespaces/proxy-4802/services/proxy-service-mr6ln:portname1/proxy/: foo (200; 37.581824ms)
Dec  3 14:52:11.641: INFO: (0) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:160/proxy/: foo (200; 38.045127ms)
Dec  3 14:52:11.641: INFO: (0) /api/v1/namespaces/proxy-4802/services/http:proxy-service-mr6ln:portname1/proxy/: foo (200; 37.950964ms)
Dec  3 14:52:11.641: INFO: (0) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7/proxy/rewriteme">test</a> (200; 38.008625ms)
Dec  3 14:52:11.641: INFO: (0) /api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:160/proxy/: foo (200; 38.065992ms)
Dec  3 14:52:11.649: INFO: (0) /api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:443/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:443/proxy/tlsrewritem... (200; 45.427506ms)
Dec  3 14:52:11.649: INFO: (0) /api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:460/proxy/: tls baz (200; 45.353469ms)
Dec  3 14:52:11.649: INFO: (0) /api/v1/namespaces/proxy-4802/services/https:proxy-service-mr6ln:tlsportname2/proxy/: tls qux (200; 45.370106ms)
Dec  3 14:52:11.649: INFO: (0) /api/v1/namespaces/proxy-4802/services/https:proxy-service-mr6ln:tlsportname1/proxy/: tls baz (200; 45.266082ms)
Dec  3 14:52:11.655: INFO: (0) /api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:462/proxy/: tls qux (200; 51.766591ms)
Dec  3 14:52:11.669: INFO: (1) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7/proxy/rewriteme">test</a> (200; 13.418497ms)
Dec  3 14:52:11.669: INFO: (1) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:162/proxy/: bar (200; 13.499547ms)
Dec  3 14:52:11.669: INFO: (1) /api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:1080/proxy/rewriteme">... (200; 13.638257ms)
Dec  3 14:52:11.669: INFO: (1) /api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:443/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:443/proxy/tlsrewritem... (200; 13.477658ms)
Dec  3 14:52:11.669: INFO: (1) /api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:160/proxy/: foo (200; 13.416369ms)
Dec  3 14:52:11.669: INFO: (1) /api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:162/proxy/: bar (200; 13.491357ms)
Dec  3 14:52:11.669: INFO: (1) /api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:460/proxy/: tls baz (200; 13.469316ms)
Dec  3 14:52:11.669: INFO: (1) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:1080/proxy/rewriteme">test<... (200; 13.447931ms)
Dec  3 14:52:11.669: INFO: (1) /api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:462/proxy/: tls qux (200; 13.572247ms)
Dec  3 14:52:11.669: INFO: (1) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:160/proxy/: foo (200; 13.542987ms)
Dec  3 14:52:11.669: INFO: (1) /api/v1/namespaces/proxy-4802/services/https:proxy-service-mr6ln:tlsportname2/proxy/: tls qux (200; 14.097901ms)
Dec  3 14:52:11.669: INFO: (1) /api/v1/namespaces/proxy-4802/services/https:proxy-service-mr6ln:tlsportname1/proxy/: tls baz (200; 13.890018ms)
Dec  3 14:52:11.670: INFO: (1) /api/v1/namespaces/proxy-4802/services/http:proxy-service-mr6ln:portname1/proxy/: foo (200; 14.574271ms)
Dec  3 14:52:11.670: INFO: (1) /api/v1/namespaces/proxy-4802/services/proxy-service-mr6ln:portname1/proxy/: foo (200; 14.573196ms)
Dec  3 14:52:11.670: INFO: (1) /api/v1/namespaces/proxy-4802/services/proxy-service-mr6ln:portname2/proxy/: bar (200; 14.506625ms)
Dec  3 14:52:11.670: INFO: (1) /api/v1/namespaces/proxy-4802/services/http:proxy-service-mr6ln:portname2/proxy/: bar (200; 14.555442ms)
Dec  3 14:52:11.683: INFO: (2) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:160/proxy/: foo (200; 12.925053ms)
Dec  3 14:52:11.683: INFO: (2) /api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:443/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:443/proxy/tlsrewritem... (200; 12.995454ms)
Dec  3 14:52:11.683: INFO: (2) /api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:460/proxy/: tls baz (200; 12.933186ms)
Dec  3 14:52:11.683: INFO: (2) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:162/proxy/: bar (200; 13.023216ms)
Dec  3 14:52:11.683: INFO: (2) /api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:160/proxy/: foo (200; 12.99329ms)
Dec  3 14:52:11.683: INFO: (2) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:1080/proxy/rewriteme">test<... (200; 13.065153ms)
Dec  3 14:52:11.683: INFO: (2) /api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:462/proxy/: tls qux (200; 12.995376ms)
Dec  3 14:52:11.683: INFO: (2) /api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:1080/proxy/rewriteme">... (200; 12.984335ms)
Dec  3 14:52:11.683: INFO: (2) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7/proxy/rewriteme">test</a> (200; 13.109207ms)
Dec  3 14:52:11.683: INFO: (2) /api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:162/proxy/: bar (200; 13.040022ms)
Dec  3 14:52:11.683: INFO: (2) /api/v1/namespaces/proxy-4802/services/https:proxy-service-mr6ln:tlsportname1/proxy/: tls baz (200; 13.404494ms)
Dec  3 14:52:11.684: INFO: (2) /api/v1/namespaces/proxy-4802/services/https:proxy-service-mr6ln:tlsportname2/proxy/: tls qux (200; 13.579839ms)
Dec  3 14:52:11.686: INFO: (2) /api/v1/namespaces/proxy-4802/services/proxy-service-mr6ln:portname2/proxy/: bar (200; 15.844145ms)
Dec  3 14:52:11.686: INFO: (2) /api/v1/namespaces/proxy-4802/services/http:proxy-service-mr6ln:portname2/proxy/: bar (200; 15.70036ms)
Dec  3 14:52:11.686: INFO: (2) /api/v1/namespaces/proxy-4802/services/proxy-service-mr6ln:portname1/proxy/: foo (200; 15.73643ms)
Dec  3 14:52:11.686: INFO: (2) /api/v1/namespaces/proxy-4802/services/http:proxy-service-mr6ln:portname1/proxy/: foo (200; 15.886711ms)
Dec  3 14:52:11.699: INFO: (3) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:160/proxy/: foo (200; 12.968059ms)
Dec  3 14:52:11.699: INFO: (3) /api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:162/proxy/: bar (200; 13.116462ms)
Dec  3 14:52:11.699: INFO: (3) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:162/proxy/: bar (200; 13.154945ms)
Dec  3 14:52:11.699: INFO: (3) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7/proxy/rewriteme">test</a> (200; 13.206024ms)
Dec  3 14:52:11.699: INFO: (3) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:1080/proxy/rewriteme">test<... (200; 13.246607ms)
Dec  3 14:52:11.699: INFO: (3) /api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:1080/proxy/rewriteme">... (200; 13.173759ms)
Dec  3 14:52:11.699: INFO: (3) /api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:443/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:443/proxy/tlsrewritem... (200; 13.259753ms)
Dec  3 14:52:11.700: INFO: (3) /api/v1/namespaces/proxy-4802/services/https:proxy-service-mr6ln:tlsportname2/proxy/: tls qux (200; 13.534424ms)
Dec  3 14:52:11.700: INFO: (3) /api/v1/namespaces/proxy-4802/services/https:proxy-service-mr6ln:tlsportname1/proxy/: tls baz (200; 13.552798ms)
Dec  3 14:52:11.700: INFO: (3) /api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:460/proxy/: tls baz (200; 13.548551ms)
Dec  3 14:52:11.700: INFO: (3) /api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:462/proxy/: tls qux (200; 13.513916ms)
Dec  3 14:52:11.700: INFO: (3) /api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:160/proxy/: foo (200; 13.533178ms)
Dec  3 14:52:11.700: INFO: (3) /api/v1/namespaces/proxy-4802/services/proxy-service-mr6ln:portname1/proxy/: foo (200; 14.271999ms)
Dec  3 14:52:11.700: INFO: (3) /api/v1/namespaces/proxy-4802/services/http:proxy-service-mr6ln:portname1/proxy/: foo (200; 14.401902ms)
Dec  3 14:52:11.700: INFO: (3) /api/v1/namespaces/proxy-4802/services/http:proxy-service-mr6ln:portname2/proxy/: bar (200; 14.43887ms)
Dec  3 14:52:11.701: INFO: (3) /api/v1/namespaces/proxy-4802/services/proxy-service-mr6ln:portname2/proxy/: bar (200; 14.865661ms)
Dec  3 14:52:11.714: INFO: (4) /api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:162/proxy/: bar (200; 13.202918ms)
Dec  3 14:52:11.714: INFO: (4) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7/proxy/rewriteme">test</a> (200; 13.266334ms)
Dec  3 14:52:11.714: INFO: (4) /api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:1080/proxy/rewriteme">... (200; 13.468158ms)
Dec  3 14:52:11.714: INFO: (4) /api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:160/proxy/: foo (200; 13.276994ms)
Dec  3 14:52:11.714: INFO: (4) /api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:460/proxy/: tls baz (200; 13.321657ms)
Dec  3 14:52:11.714: INFO: (4) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:160/proxy/: foo (200; 13.317791ms)
Dec  3 14:52:11.715: INFO: (4) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:1080/proxy/rewriteme">test<... (200; 13.331767ms)
Dec  3 14:52:11.715: INFO: (4) /api/v1/namespaces/proxy-4802/services/https:proxy-service-mr6ln:tlsportname1/proxy/: tls baz (200; 13.36603ms)
Dec  3 14:52:11.714: INFO: (4) /api/v1/namespaces/proxy-4802/services/https:proxy-service-mr6ln:tlsportname2/proxy/: tls qux (200; 13.408015ms)
Dec  3 14:52:11.715: INFO: (4) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:162/proxy/: bar (200; 13.275686ms)
Dec  3 14:52:11.715: INFO: (4) /api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:443/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:443/proxy/tlsrewritem... (200; 13.496589ms)
Dec  3 14:52:11.715: INFO: (4) /api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:462/proxy/: tls qux (200; 13.310658ms)
Dec  3 14:52:11.716: INFO: (4) /api/v1/namespaces/proxy-4802/services/http:proxy-service-mr6ln:portname2/proxy/: bar (200; 14.451083ms)
Dec  3 14:52:11.716: INFO: (4) /api/v1/namespaces/proxy-4802/services/http:proxy-service-mr6ln:portname1/proxy/: foo (200; 14.387246ms)
Dec  3 14:52:11.716: INFO: (4) /api/v1/namespaces/proxy-4802/services/proxy-service-mr6ln:portname2/proxy/: bar (200; 14.533155ms)
Dec  3 14:52:11.716: INFO: (4) /api/v1/namespaces/proxy-4802/services/proxy-service-mr6ln:portname1/proxy/: foo (200; 14.470993ms)
Dec  3 14:52:11.733: INFO: (5) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:162/proxy/: bar (200; 16.783868ms)
Dec  3 14:52:11.733: INFO: (5) /api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:1080/proxy/rewriteme">... (200; 16.783245ms)
Dec  3 14:52:11.733: INFO: (5) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:160/proxy/: foo (200; 16.803893ms)
Dec  3 14:52:11.733: INFO: (5) /api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:160/proxy/: foo (200; 16.793822ms)
Dec  3 14:52:11.733: INFO: (5) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:1080/proxy/rewriteme">test<... (200; 16.877322ms)
Dec  3 14:52:11.733: INFO: (5) /api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:462/proxy/: tls qux (200; 17.084335ms)
Dec  3 14:52:11.733: INFO: (5) /api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:162/proxy/: bar (200; 16.956807ms)
Dec  3 14:52:11.733: INFO: (5) /api/v1/namespaces/proxy-4802/services/https:proxy-service-mr6ln:tlsportname2/proxy/: tls qux (200; 16.916559ms)
Dec  3 14:52:11.733: INFO: (5) /api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:460/proxy/: tls baz (200; 17.507687ms)
Dec  3 14:52:11.733: INFO: (5) /api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:443/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:443/proxy/tlsrewritem... (200; 17.443411ms)
Dec  3 14:52:11.733: INFO: (5) /api/v1/namespaces/proxy-4802/services/https:proxy-service-mr6ln:tlsportname1/proxy/: tls baz (200; 17.455143ms)
Dec  3 14:52:11.733: INFO: (5) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7/proxy/rewriteme">test</a> (200; 17.492063ms)
Dec  3 14:52:11.733: INFO: (5) /api/v1/namespaces/proxy-4802/services/proxy-service-mr6ln:portname2/proxy/: bar (200; 17.370106ms)
Dec  3 14:52:11.734: INFO: (5) /api/v1/namespaces/proxy-4802/services/http:proxy-service-mr6ln:portname2/proxy/: bar (200; 17.671555ms)
Dec  3 14:52:11.734: INFO: (5) /api/v1/namespaces/proxy-4802/services/proxy-service-mr6ln:portname1/proxy/: foo (200; 17.680661ms)
Dec  3 14:52:11.734: INFO: (5) /api/v1/namespaces/proxy-4802/services/http:proxy-service-mr6ln:portname1/proxy/: foo (200; 17.901026ms)
Dec  3 14:52:11.747: INFO: (6) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:162/proxy/: bar (200; 13.553006ms)
Dec  3 14:52:11.747: INFO: (6) /api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:460/proxy/: tls baz (200; 13.655616ms)
Dec  3 14:52:11.747: INFO: (6) /api/v1/namespaces/proxy-4802/services/https:proxy-service-mr6ln:tlsportname1/proxy/: tls baz (200; 13.726598ms)
Dec  3 14:52:11.748: INFO: (6) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:160/proxy/: foo (200; 13.719915ms)
Dec  3 14:52:11.748: INFO: (6) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:1080/proxy/rewriteme">test<... (200; 13.773286ms)
Dec  3 14:52:11.748: INFO: (6) /api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:162/proxy/: bar (200; 13.781064ms)
Dec  3 14:52:11.748: INFO: (6) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7/proxy/rewriteme">test</a> (200; 13.923468ms)
Dec  3 14:52:11.748: INFO: (6) /api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:462/proxy/: tls qux (200; 13.780655ms)
Dec  3 14:52:11.748: INFO: (6) /api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:443/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:443/proxy/tlsrewritem... (200; 14.019005ms)
Dec  3 14:52:11.748: INFO: (6) /api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:160/proxy/: foo (200; 13.905048ms)
Dec  3 14:52:11.748: INFO: (6) /api/v1/namespaces/proxy-4802/services/https:proxy-service-mr6ln:tlsportname2/proxy/: tls qux (200; 13.93314ms)
Dec  3 14:52:11.748: INFO: (6) /api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:1080/proxy/rewriteme">... (200; 13.938592ms)
Dec  3 14:52:11.749: INFO: (6) /api/v1/namespaces/proxy-4802/services/proxy-service-mr6ln:portname2/proxy/: bar (200; 14.653328ms)
Dec  3 14:52:11.749: INFO: (6) /api/v1/namespaces/proxy-4802/services/http:proxy-service-mr6ln:portname2/proxy/: bar (200; 15.308515ms)
Dec  3 14:52:11.749: INFO: (6) /api/v1/namespaces/proxy-4802/services/http:proxy-service-mr6ln:portname1/proxy/: foo (200; 15.489827ms)
Dec  3 14:52:11.749: INFO: (6) /api/v1/namespaces/proxy-4802/services/proxy-service-mr6ln:portname1/proxy/: foo (200; 15.556972ms)
Dec  3 14:52:11.764: INFO: (7) /api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:1080/proxy/rewriteme">... (200; 14.469017ms)
Dec  3 14:52:11.764: INFO: (7) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:160/proxy/: foo (200; 14.480473ms)
Dec  3 14:52:11.764: INFO: (7) /api/v1/namespaces/proxy-4802/services/https:proxy-service-mr6ln:tlsportname2/proxy/: tls qux (200; 14.489104ms)
Dec  3 14:52:11.764: INFO: (7) /api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:460/proxy/: tls baz (200; 14.595599ms)
Dec  3 14:52:11.764: INFO: (7) /api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:160/proxy/: foo (200; 14.673938ms)
Dec  3 14:52:11.764: INFO: (7) /api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:462/proxy/: tls qux (200; 14.509656ms)
Dec  3 14:52:11.764: INFO: (7) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:1080/proxy/rewriteme">test<... (200; 14.553555ms)
Dec  3 14:52:11.764: INFO: (7) /api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:162/proxy/: bar (200; 14.533405ms)
Dec  3 14:52:11.764: INFO: (7) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:162/proxy/: bar (200; 14.654703ms)
Dec  3 14:52:11.764: INFO: (7) /api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:443/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:443/proxy/tlsrewritem... (200; 14.520306ms)
Dec  3 14:52:11.764: INFO: (7) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7/proxy/rewriteme">test</a> (200; 14.513589ms)
Dec  3 14:52:11.764: INFO: (7) /api/v1/namespaces/proxy-4802/services/https:proxy-service-mr6ln:tlsportname1/proxy/: tls baz (200; 14.493212ms)
Dec  3 14:52:11.764: INFO: (7) /api/v1/namespaces/proxy-4802/services/http:proxy-service-mr6ln:portname1/proxy/: foo (200; 14.844952ms)
Dec  3 14:52:11.765: INFO: (7) /api/v1/namespaces/proxy-4802/services/proxy-service-mr6ln:portname2/proxy/: bar (200; 15.537496ms)
Dec  3 14:52:11.765: INFO: (7) /api/v1/namespaces/proxy-4802/services/proxy-service-mr6ln:portname1/proxy/: foo (200; 15.417342ms)
Dec  3 14:52:11.765: INFO: (7) /api/v1/namespaces/proxy-4802/services/http:proxy-service-mr6ln:portname2/proxy/: bar (200; 15.579912ms)
Dec  3 14:52:11.780: INFO: (8) /api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:1080/proxy/rewriteme">... (200; 14.934716ms)
Dec  3 14:52:11.780: INFO: (8) /api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:162/proxy/: bar (200; 15.105813ms)
Dec  3 14:52:11.780: INFO: (8) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:162/proxy/: bar (200; 14.992681ms)
Dec  3 14:52:11.780: INFO: (8) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:160/proxy/: foo (200; 14.991813ms)
Dec  3 14:52:11.780: INFO: (8) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:1080/proxy/rewriteme">test<... (200; 15.01403ms)
Dec  3 14:52:11.780: INFO: (8) /api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:160/proxy/: foo (200; 14.968519ms)
Dec  3 14:52:11.780: INFO: (8) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7/proxy/rewriteme">test</a> (200; 15.029597ms)
Dec  3 14:52:11.780: INFO: (8) /api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:443/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:443/proxy/tlsrewritem... (200; 15.110723ms)
Dec  3 14:52:11.780: INFO: (8) /api/v1/namespaces/proxy-4802/services/https:proxy-service-mr6ln:tlsportname2/proxy/: tls qux (200; 15.204815ms)
Dec  3 14:52:11.780: INFO: (8) /api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:460/proxy/: tls baz (200; 15.276678ms)
Dec  3 14:52:11.780: INFO: (8) /api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:462/proxy/: tls qux (200; 15.176248ms)
Dec  3 14:52:11.781: INFO: (8) /api/v1/namespaces/proxy-4802/services/https:proxy-service-mr6ln:tlsportname1/proxy/: tls baz (200; 15.41822ms)
Dec  3 14:52:11.781: INFO: (8) /api/v1/namespaces/proxy-4802/services/http:proxy-service-mr6ln:portname1/proxy/: foo (200; 15.90478ms)
Dec  3 14:52:11.781: INFO: (8) /api/v1/namespaces/proxy-4802/services/http:proxy-service-mr6ln:portname2/proxy/: bar (200; 15.983467ms)
Dec  3 14:52:11.781: INFO: (8) /api/v1/namespaces/proxy-4802/services/proxy-service-mr6ln:portname1/proxy/: foo (200; 16.172822ms)
Dec  3 14:52:11.782: INFO: (8) /api/v1/namespaces/proxy-4802/services/proxy-service-mr6ln:portname2/proxy/: bar (200; 16.282538ms)
Dec  3 14:52:11.795: INFO: (9) /api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:1080/proxy/rewriteme">... (200; 13.2991ms)
Dec  3 14:52:11.795: INFO: (9) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:162/proxy/: bar (200; 13.358867ms)
Dec  3 14:52:11.795: INFO: (9) /api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:160/proxy/: foo (200; 13.416289ms)
Dec  3 14:52:11.795: INFO: (9) /api/v1/namespaces/proxy-4802/services/https:proxy-service-mr6ln:tlsportname1/proxy/: tls baz (200; 13.340101ms)
Dec  3 14:52:11.795: INFO: (9) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7/proxy/rewriteme">test</a> (200; 13.492871ms)
Dec  3 14:52:11.795: INFO: (9) /api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:443/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:443/proxy/tlsrewritem... (200; 13.434432ms)
Dec  3 14:52:11.795: INFO: (9) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:1080/proxy/rewriteme">test<... (200; 13.378345ms)
Dec  3 14:52:11.795: INFO: (9) /api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:460/proxy/: tls baz (200; 13.562427ms)
Dec  3 14:52:11.795: INFO: (9) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:160/proxy/: foo (200; 13.429336ms)
Dec  3 14:52:11.795: INFO: (9) /api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:162/proxy/: bar (200; 13.58155ms)
Dec  3 14:52:11.795: INFO: (9) /api/v1/namespaces/proxy-4802/services/https:proxy-service-mr6ln:tlsportname2/proxy/: tls qux (200; 13.508979ms)
Dec  3 14:52:11.795: INFO: (9) /api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:462/proxy/: tls qux (200; 13.468261ms)
Dec  3 14:52:11.796: INFO: (9) /api/v1/namespaces/proxy-4802/services/http:proxy-service-mr6ln:portname2/proxy/: bar (200; 14.096003ms)
Dec  3 14:52:11.837: INFO: (9) /api/v1/namespaces/proxy-4802/services/proxy-service-mr6ln:portname1/proxy/: foo (200; 55.385355ms)
Dec  3 14:52:11.837: INFO: (9) /api/v1/namespaces/proxy-4802/services/proxy-service-mr6ln:portname2/proxy/: bar (200; 55.454448ms)
Dec  3 14:52:11.837: INFO: (9) /api/v1/namespaces/proxy-4802/services/http:proxy-service-mr6ln:portname1/proxy/: foo (200; 55.529152ms)
Dec  3 14:52:11.850: INFO: (10) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:162/proxy/: bar (200; 12.875874ms)
Dec  3 14:52:11.850: INFO: (10) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7/proxy/rewriteme">test</a> (200; 12.921877ms)
Dec  3 14:52:11.850: INFO: (10) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:160/proxy/: foo (200; 12.919648ms)
Dec  3 14:52:11.850: INFO: (10) /api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:162/proxy/: bar (200; 12.989753ms)
Dec  3 14:52:11.850: INFO: (10) /api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:460/proxy/: tls baz (200; 12.928267ms)
Dec  3 14:52:11.850: INFO: (10) /api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:1080/proxy/rewriteme">... (200; 12.904609ms)
Dec  3 14:52:11.850: INFO: (10) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:1080/proxy/rewriteme">test<... (200; 13.041648ms)
Dec  3 14:52:11.851: INFO: (10) /api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:160/proxy/: foo (200; 13.288203ms)
Dec  3 14:52:11.851: INFO: (10) /api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:443/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:443/proxy/tlsrewritem... (200; 13.917179ms)
Dec  3 14:52:11.851: INFO: (10) /api/v1/namespaces/proxy-4802/services/https:proxy-service-mr6ln:tlsportname1/proxy/: tls baz (200; 13.930888ms)
Dec  3 14:52:11.852: INFO: (10) /api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:462/proxy/: tls qux (200; 14.415081ms)
Dec  3 14:52:11.893: INFO: (10) /api/v1/namespaces/proxy-4802/services/http:proxy-service-mr6ln:portname2/proxy/: bar (200; 55.211794ms)
Dec  3 14:52:11.893: INFO: (10) /api/v1/namespaces/proxy-4802/services/proxy-service-mr6ln:portname2/proxy/: bar (200; 55.259627ms)
Dec  3 14:52:11.893: INFO: (10) /api/v1/namespaces/proxy-4802/services/https:proxy-service-mr6ln:tlsportname2/proxy/: tls qux (200; 55.236011ms)
Dec  3 14:52:11.893: INFO: (10) /api/v1/namespaces/proxy-4802/services/http:proxy-service-mr6ln:portname1/proxy/: foo (200; 55.29681ms)
Dec  3 14:52:11.893: INFO: (10) /api/v1/namespaces/proxy-4802/services/proxy-service-mr6ln:portname1/proxy/: foo (200; 55.352047ms)
Dec  3 14:52:11.906: INFO: (11) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7/proxy/rewriteme">test</a> (200; 13.09485ms)
Dec  3 14:52:11.906: INFO: (11) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:162/proxy/: bar (200; 13.18442ms)
Dec  3 14:52:11.906: INFO: (11) /api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:462/proxy/: tls qux (200; 13.229879ms)
Dec  3 14:52:11.906: INFO: (11) /api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:460/proxy/: tls baz (200; 13.262983ms)
Dec  3 14:52:11.906: INFO: (11) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:160/proxy/: foo (200; 13.323341ms)
Dec  3 14:52:11.906: INFO: (11) /api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:162/proxy/: bar (200; 13.089786ms)
Dec  3 14:52:11.906: INFO: (11) /api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:1080/proxy/rewriteme">... (200; 13.267935ms)
Dec  3 14:52:11.906: INFO: (11) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:1080/proxy/rewriteme">test<... (200; 13.221524ms)
Dec  3 14:52:11.906: INFO: (11) /api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:443/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:443/proxy/tlsrewritem... (200; 13.367565ms)
Dec  3 14:52:11.906: INFO: (11) /api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:160/proxy/: foo (200; 13.492034ms)
Dec  3 14:52:11.907: INFO: (11) /api/v1/namespaces/proxy-4802/services/https:proxy-service-mr6ln:tlsportname2/proxy/: tls qux (200; 13.757559ms)
Dec  3 14:52:11.907: INFO: (11) /api/v1/namespaces/proxy-4802/services/https:proxy-service-mr6ln:tlsportname1/proxy/: tls baz (200; 13.896872ms)
Dec  3 14:52:11.908: INFO: (11) /api/v1/namespaces/proxy-4802/services/http:proxy-service-mr6ln:portname2/proxy/: bar (200; 14.934608ms)
Dec  3 14:52:11.909: INFO: (11) /api/v1/namespaces/proxy-4802/services/proxy-service-mr6ln:portname2/proxy/: bar (200; 15.651522ms)
Dec  3 14:52:11.909: INFO: (11) /api/v1/namespaces/proxy-4802/services/http:proxy-service-mr6ln:portname1/proxy/: foo (200; 15.586959ms)
Dec  3 14:52:11.909: INFO: (11) /api/v1/namespaces/proxy-4802/services/proxy-service-mr6ln:portname1/proxy/: foo (200; 15.69139ms)
Dec  3 14:52:11.922: INFO: (12) /api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:162/proxy/: bar (200; 13.370472ms)
Dec  3 14:52:11.922: INFO: (12) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7/proxy/rewriteme">test</a> (200; 13.404123ms)
Dec  3 14:52:11.922: INFO: (12) /api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:1080/proxy/rewriteme">... (200; 13.495234ms)
Dec  3 14:52:11.922: INFO: (12) /api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:160/proxy/: foo (200; 13.600811ms)
Dec  3 14:52:11.922: INFO: (12) /api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:462/proxy/: tls qux (200; 13.424436ms)
Dec  3 14:52:11.922: INFO: (12) /api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:443/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:443/proxy/tlsrewritem... (200; 13.680727ms)
Dec  3 14:52:11.922: INFO: (12) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:162/proxy/: bar (200; 13.501797ms)
Dec  3 14:52:11.922: INFO: (12) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:160/proxy/: foo (200; 13.523986ms)
Dec  3 14:52:11.922: INFO: (12) /api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:460/proxy/: tls baz (200; 13.526407ms)
Dec  3 14:52:11.922: INFO: (12) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:1080/proxy/rewriteme">test<... (200; 13.512981ms)
Dec  3 14:52:11.923: INFO: (12) /api/v1/namespaces/proxy-4802/services/https:proxy-service-mr6ln:tlsportname2/proxy/: tls qux (200; 14.475289ms)
Dec  3 14:52:11.924: INFO: (12) /api/v1/namespaces/proxy-4802/services/http:proxy-service-mr6ln:portname2/proxy/: bar (200; 14.938536ms)
Dec  3 14:52:11.924: INFO: (12) /api/v1/namespaces/proxy-4802/services/http:proxy-service-mr6ln:portname1/proxy/: foo (200; 15.009246ms)
Dec  3 14:52:11.924: INFO: (12) /api/v1/namespaces/proxy-4802/services/proxy-service-mr6ln:portname1/proxy/: foo (200; 15.453235ms)
Dec  3 14:52:11.924: INFO: (12) /api/v1/namespaces/proxy-4802/services/proxy-service-mr6ln:portname2/proxy/: bar (200; 15.582594ms)
Dec  3 14:52:11.924: INFO: (12) /api/v1/namespaces/proxy-4802/services/https:proxy-service-mr6ln:tlsportname1/proxy/: tls baz (200; 15.729267ms)
Dec  3 14:52:11.938: INFO: (13) /api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:460/proxy/: tls baz (200; 13.021696ms)
Dec  3 14:52:11.938: INFO: (13) /api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:160/proxy/: foo (200; 12.875465ms)
Dec  3 14:52:11.938: INFO: (13) /api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:462/proxy/: tls qux (200; 12.838139ms)
Dec  3 14:52:11.938: INFO: (13) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:162/proxy/: bar (200; 12.965848ms)
Dec  3 14:52:11.938: INFO: (13) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:160/proxy/: foo (200; 13.161346ms)
Dec  3 14:52:11.938: INFO: (13) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:1080/proxy/rewriteme">test<... (200; 13.07026ms)
Dec  3 14:52:11.938: INFO: (13) /api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:162/proxy/: bar (200; 13.431728ms)
Dec  3 14:52:11.938: INFO: (13) /api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:443/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:443/proxy/tlsrewritem... (200; 13.572381ms)
Dec  3 14:52:11.938: INFO: (13) /api/v1/namespaces/proxy-4802/services/proxy-service-mr6ln:portname2/proxy/: bar (200; 13.647404ms)
Dec  3 14:52:11.938: INFO: (13) /api/v1/namespaces/proxy-4802/services/https:proxy-service-mr6ln:tlsportname2/proxy/: tls qux (200; 13.643844ms)
Dec  3 14:52:11.938: INFO: (13) /api/v1/namespaces/proxy-4802/services/https:proxy-service-mr6ln:tlsportname1/proxy/: tls baz (200; 13.654602ms)
Dec  3 14:52:11.938: INFO: (13) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7/proxy/rewriteme">test</a> (200; 13.809133ms)
Dec  3 14:52:11.938: INFO: (13) /api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:1080/proxy/rewriteme">... (200; 13.754636ms)
Dec  3 14:52:11.939: INFO: (13) /api/v1/namespaces/proxy-4802/services/proxy-service-mr6ln:portname1/proxy/: foo (200; 14.046159ms)
Dec  3 14:52:11.939: INFO: (13) /api/v1/namespaces/proxy-4802/services/http:proxy-service-mr6ln:portname1/proxy/: foo (200; 14.114054ms)
Dec  3 14:52:11.940: INFO: (13) /api/v1/namespaces/proxy-4802/services/http:proxy-service-mr6ln:portname2/proxy/: bar (200; 15.472767ms)
Dec  3 14:52:11.954: INFO: (14) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:1080/proxy/rewriteme">test<... (200; 13.296533ms)
Dec  3 14:52:11.954: INFO: (14) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7/proxy/rewriteme">test</a> (200; 13.131364ms)
Dec  3 14:52:11.954: INFO: (14) /api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:443/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:443/proxy/tlsrewritem... (200; 13.375247ms)
Dec  3 14:52:11.954: INFO: (14) /api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:160/proxy/: foo (200; 13.237561ms)
Dec  3 14:52:11.954: INFO: (14) /api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:462/proxy/: tls qux (200; 13.224913ms)
Dec  3 14:52:11.954: INFO: (14) /api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:162/proxy/: bar (200; 13.335832ms)
Dec  3 14:52:11.954: INFO: (14) /api/v1/namespaces/proxy-4802/services/https:proxy-service-mr6ln:tlsportname2/proxy/: tls qux (200; 13.330346ms)
Dec  3 14:52:11.954: INFO: (14) /api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:1080/proxy/rewriteme">... (200; 13.359858ms)
Dec  3 14:52:11.954: INFO: (14) /api/v1/namespaces/proxy-4802/services/https:proxy-service-mr6ln:tlsportname1/proxy/: tls baz (200; 13.401535ms)
Dec  3 14:52:11.954: INFO: (14) /api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:460/proxy/: tls baz (200; 13.311098ms)
Dec  3 14:52:11.954: INFO: (14) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:160/proxy/: foo (200; 13.347134ms)
Dec  3 14:52:11.954: INFO: (14) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:162/proxy/: bar (200; 13.305193ms)
Dec  3 14:52:11.996: INFO: (14) /api/v1/namespaces/proxy-4802/services/http:proxy-service-mr6ln:portname1/proxy/: foo (200; 55.333099ms)
Dec  3 14:52:11.996: INFO: (14) /api/v1/namespaces/proxy-4802/services/proxy-service-mr6ln:portname1/proxy/: foo (200; 55.362179ms)
Dec  3 14:52:11.996: INFO: (14) /api/v1/namespaces/proxy-4802/services/http:proxy-service-mr6ln:portname2/proxy/: bar (200; 55.357426ms)
Dec  3 14:52:11.996: INFO: (14) /api/v1/namespaces/proxy-4802/services/proxy-service-mr6ln:portname2/proxy/: bar (200; 55.49509ms)
Dec  3 14:52:12.010: INFO: (15) /api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:462/proxy/: tls qux (200; 13.92529ms)
Dec  3 14:52:12.010: INFO: (15) /api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:1080/proxy/rewriteme">... (200; 13.949341ms)
Dec  3 14:52:12.010: INFO: (15) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:1080/proxy/rewriteme">test<... (200; 14.003961ms)
Dec  3 14:52:12.010: INFO: (15) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7/proxy/rewriteme">test</a> (200; 14.170973ms)
Dec  3 14:52:12.010: INFO: (15) /api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:460/proxy/: tls baz (200; 14.150203ms)
Dec  3 14:52:12.010: INFO: (15) /api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:443/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:443/proxy/tlsrewritem... (200; 14.33563ms)
Dec  3 14:52:12.010: INFO: (15) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:162/proxy/: bar (200; 14.505138ms)
Dec  3 14:52:12.011: INFO: (15) /api/v1/namespaces/proxy-4802/services/https:proxy-service-mr6ln:tlsportname2/proxy/: tls qux (200; 14.514819ms)
Dec  3 14:52:12.011: INFO: (15) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:160/proxy/: foo (200; 14.689206ms)
Dec  3 14:52:12.011: INFO: (15) /api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:162/proxy/: bar (200; 14.576797ms)
Dec  3 14:52:12.011: INFO: (15) /api/v1/namespaces/proxy-4802/services/https:proxy-service-mr6ln:tlsportname1/proxy/: tls baz (200; 14.6177ms)
Dec  3 14:52:12.011: INFO: (15) /api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:160/proxy/: foo (200; 14.660571ms)
Dec  3 14:52:12.012: INFO: (15) /api/v1/namespaces/proxy-4802/services/http:proxy-service-mr6ln:portname1/proxy/: foo (200; 16.143606ms)
Dec  3 14:52:12.013: INFO: (15) /api/v1/namespaces/proxy-4802/services/http:proxy-service-mr6ln:portname2/proxy/: bar (200; 16.549312ms)
Dec  3 14:52:12.013: INFO: (15) /api/v1/namespaces/proxy-4802/services/proxy-service-mr6ln:portname2/proxy/: bar (200; 16.51174ms)
Dec  3 14:52:12.013: INFO: (15) /api/v1/namespaces/proxy-4802/services/proxy-service-mr6ln:portname1/proxy/: foo (200; 16.942759ms)
Dec  3 14:52:12.034: INFO: (16) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:1080/proxy/rewriteme">test<... (200; 20.422182ms)
Dec  3 14:52:12.034: INFO: (16) /api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:160/proxy/: foo (200; 20.430141ms)
Dec  3 14:52:12.034: INFO: (16) /api/v1/namespaces/proxy-4802/services/https:proxy-service-mr6ln:tlsportname1/proxy/: tls baz (200; 20.542441ms)
Dec  3 14:52:12.034: INFO: (16) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:160/proxy/: foo (200; 20.419291ms)
Dec  3 14:52:12.034: INFO: (16) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:162/proxy/: bar (200; 20.503133ms)
Dec  3 14:52:12.034: INFO: (16) /api/v1/namespaces/proxy-4802/services/https:proxy-service-mr6ln:tlsportname2/proxy/: tls qux (200; 20.685787ms)
Dec  3 14:52:12.034: INFO: (16) /api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:443/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:443/proxy/tlsrewritem... (200; 20.411887ms)
Dec  3 14:52:12.034: INFO: (16) /api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:460/proxy/: tls baz (200; 20.445165ms)
Dec  3 14:52:12.034: INFO: (16) /api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:1080/proxy/rewriteme">... (200; 20.623618ms)
Dec  3 14:52:12.034: INFO: (16) /api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:162/proxy/: bar (200; 20.496642ms)
Dec  3 14:52:12.034: INFO: (16) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7/proxy/rewriteme">test</a> (200; 20.475394ms)
Dec  3 14:52:12.034: INFO: (16) /api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:462/proxy/: tls qux (200; 20.504071ms)
Dec  3 14:52:12.075: INFO: (16) /api/v1/namespaces/proxy-4802/services/proxy-service-mr6ln:portname1/proxy/: foo (200; 61.380735ms)
Dec  3 14:52:12.075: INFO: (16) /api/v1/namespaces/proxy-4802/services/http:proxy-service-mr6ln:portname2/proxy/: bar (200; 61.362427ms)
Dec  3 14:52:12.075: INFO: (16) /api/v1/namespaces/proxy-4802/services/proxy-service-mr6ln:portname2/proxy/: bar (200; 61.277161ms)
Dec  3 14:52:12.075: INFO: (16) /api/v1/namespaces/proxy-4802/services/http:proxy-service-mr6ln:portname1/proxy/: foo (200; 61.385287ms)
Dec  3 14:52:12.088: INFO: (17) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:160/proxy/: foo (200; 13.538975ms)
Dec  3 14:52:12.088: INFO: (17) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7/proxy/rewriteme">test</a> (200; 13.661438ms)
Dec  3 14:52:12.088: INFO: (17) /api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:460/proxy/: tls baz (200; 13.756377ms)
Dec  3 14:52:12.089: INFO: (17) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:162/proxy/: bar (200; 13.740222ms)
Dec  3 14:52:12.088: INFO: (17) /api/v1/namespaces/proxy-4802/services/https:proxy-service-mr6ln:tlsportname1/proxy/: tls baz (200; 13.575192ms)
Dec  3 14:52:12.088: INFO: (17) /api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:162/proxy/: bar (200; 13.608019ms)
Dec  3 14:52:12.088: INFO: (17) /api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:1080/proxy/rewriteme">... (200; 13.65781ms)
Dec  3 14:52:12.089: INFO: (17) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:1080/proxy/rewriteme">test<... (200; 13.682251ms)
Dec  3 14:52:12.089: INFO: (17) /api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:160/proxy/: foo (200; 13.634301ms)
Dec  3 14:52:12.089: INFO: (17) /api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:443/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:443/proxy/tlsrewritem... (200; 14.310552ms)
Dec  3 14:52:12.089: INFO: (17) /api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:462/proxy/: tls qux (200; 14.328931ms)
Dec  3 14:52:12.089: INFO: (17) /api/v1/namespaces/proxy-4802/services/https:proxy-service-mr6ln:tlsportname2/proxy/: tls qux (200; 14.463228ms)
Dec  3 14:52:12.131: INFO: (17) /api/v1/namespaces/proxy-4802/services/proxy-service-mr6ln:portname1/proxy/: foo (200; 56.332951ms)
Dec  3 14:52:12.131: INFO: (17) /api/v1/namespaces/proxy-4802/services/proxy-service-mr6ln:portname2/proxy/: bar (200; 56.349988ms)
Dec  3 14:52:12.131: INFO: (17) /api/v1/namespaces/proxy-4802/services/http:proxy-service-mr6ln:portname1/proxy/: foo (200; 56.520179ms)
Dec  3 14:52:12.131: INFO: (17) /api/v1/namespaces/proxy-4802/services/http:proxy-service-mr6ln:portname2/proxy/: bar (200; 56.381093ms)
Dec  3 14:52:12.150: INFO: (18) /api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:462/proxy/: tls qux (200; 18.370374ms)
Dec  3 14:52:12.150: INFO: (18) /api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:162/proxy/: bar (200; 18.232401ms)
Dec  3 14:52:12.150: INFO: (18) /api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:443/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:443/proxy/tlsrewritem... (200; 18.239205ms)
Dec  3 14:52:12.150: INFO: (18) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:160/proxy/: foo (200; 18.429492ms)
Dec  3 14:52:12.150: INFO: (18) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7/proxy/rewriteme">test</a> (200; 18.287084ms)
Dec  3 14:52:12.150: INFO: (18) /api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:160/proxy/: foo (200; 18.330395ms)
Dec  3 14:52:12.150: INFO: (18) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:162/proxy/: bar (200; 18.323559ms)
Dec  3 14:52:12.150: INFO: (18) /api/v1/namespaces/proxy-4802/services/https:proxy-service-mr6ln:tlsportname2/proxy/: tls qux (200; 18.220307ms)
Dec  3 14:52:12.150: INFO: (18) /api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:1080/proxy/rewriteme">... (200; 18.313687ms)
Dec  3 14:52:12.150: INFO: (18) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:1080/proxy/rewriteme">test<... (200; 18.256318ms)
Dec  3 14:52:12.150: INFO: (18) /api/v1/namespaces/proxy-4802/services/https:proxy-service-mr6ln:tlsportname1/proxy/: tls baz (200; 18.546605ms)
Dec  3 14:52:12.150: INFO: (18) /api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:460/proxy/: tls baz (200; 18.589512ms)
Dec  3 14:52:12.191: INFO: (18) /api/v1/namespaces/proxy-4802/services/proxy-service-mr6ln:portname1/proxy/: foo (200; 59.822868ms)
Dec  3 14:52:12.191: INFO: (18) /api/v1/namespaces/proxy-4802/services/http:proxy-service-mr6ln:portname2/proxy/: bar (200; 60.006151ms)
Dec  3 14:52:12.191: INFO: (18) /api/v1/namespaces/proxy-4802/services/proxy-service-mr6ln:portname2/proxy/: bar (200; 59.977418ms)
Dec  3 14:52:12.191: INFO: (18) /api/v1/namespaces/proxy-4802/services/http:proxy-service-mr6ln:portname1/proxy/: foo (200; 60.074886ms)
Dec  3 14:52:12.205: INFO: (19) /api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:1080/proxy/rewriteme">... (200; 13.154633ms)
Dec  3 14:52:12.205: INFO: (19) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:162/proxy/: bar (200; 13.155911ms)
Dec  3 14:52:12.205: INFO: (19) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:1080/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:1080/proxy/rewriteme">test<... (200; 13.199977ms)
Dec  3 14:52:12.205: INFO: (19) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7/proxy/rewriteme">test</a> (200; 13.249394ms)
Dec  3 14:52:12.205: INFO: (19) /api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:160/proxy/: foo (200; 13.429438ms)
Dec  3 14:52:12.205: INFO: (19) /api/v1/namespaces/proxy-4802/services/https:proxy-service-mr6ln:tlsportname1/proxy/: tls baz (200; 13.335351ms)
Dec  3 14:52:12.205: INFO: (19) /api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:462/proxy/: tls qux (200; 13.286948ms)
Dec  3 14:52:12.205: INFO: (19) /api/v1/namespaces/proxy-4802/pods/proxy-service-mr6ln-lqqh7:160/proxy/: foo (200; 13.377411ms)
Dec  3 14:52:12.205: INFO: (19) /api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:443/proxy/: <a href="/api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:443/proxy/tlsrewritem... (200; 13.382879ms)
Dec  3 14:52:12.205: INFO: (19) /api/v1/namespaces/proxy-4802/pods/https:proxy-service-mr6ln-lqqh7:460/proxy/: tls baz (200; 13.491372ms)
Dec  3 14:52:12.205: INFO: (19) /api/v1/namespaces/proxy-4802/services/https:proxy-service-mr6ln:tlsportname2/proxy/: tls qux (200; 13.369921ms)
Dec  3 14:52:12.205: INFO: (19) /api/v1/namespaces/proxy-4802/pods/http:proxy-service-mr6ln-lqqh7:162/proxy/: bar (200; 13.632197ms)
Dec  3 14:52:12.247: INFO: (19) /api/v1/namespaces/proxy-4802/services/proxy-service-mr6ln:portname1/proxy/: foo (200; 55.14434ms)
Dec  3 14:52:12.247: INFO: (19) /api/v1/namespaces/proxy-4802/services/proxy-service-mr6ln:portname2/proxy/: bar (200; 55.072479ms)
Dec  3 14:52:12.247: INFO: (19) /api/v1/namespaces/proxy-4802/services/http:proxy-service-mr6ln:portname2/proxy/: bar (200; 54.961509ms)
Dec  3 14:52:12.247: INFO: (19) /api/v1/namespaces/proxy-4802/services/http:proxy-service-mr6ln:portname1/proxy/: foo (200; 55.020778ms)
STEP: deleting ReplicationController proxy-service-mr6ln in namespace proxy-4802, will wait for the garbage collector to delete the pods
Dec  3 14:52:12.321: INFO: Deleting ReplicationController proxy-service-mr6ln took: 12.907456ms
Dec  3 14:52:12.421: INFO: Terminating ReplicationController proxy-service-mr6ln pods took: 100.321584ms
[AfterEach] version v1
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:52:23.121: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-4802" for this suite.
Dec  3 14:52:29.174: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:52:29.575: INFO: namespace proxy-4802 deletion completed in 6.434206575s
•SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:52:29.575: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-15
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-d3e4de39-16c6-4b31-8685-dad7f552be53
STEP: Creating a pod to test consume configMaps
Dec  3 14:52:29.787: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c359f340-1c77-4f4c-bd60-49c2aedd7992" in namespace "projected-15" to be "success or failure"
Dec  3 14:52:29.797: INFO: Pod "pod-projected-configmaps-c359f340-1c77-4f4c-bd60-49c2aedd7992": Phase="Pending", Reason="", readiness=false. Elapsed: 10.154165ms
Dec  3 14:52:31.808: INFO: Pod "pod-projected-configmaps-c359f340-1c77-4f4c-bd60-49c2aedd7992": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021007315s
STEP: Saw pod success
Dec  3 14:52:31.808: INFO: Pod "pod-projected-configmaps-c359f340-1c77-4f4c-bd60-49c2aedd7992" satisfied condition "success or failure"
Dec  3 14:52:31.818: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod pod-projected-configmaps-c359f340-1c77-4f4c-bd60-49c2aedd7992 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 14:52:31.853: INFO: Waiting for pod pod-projected-configmaps-c359f340-1c77-4f4c-bd60-49c2aedd7992 to disappear
Dec  3 14:52:31.863: INFO: Pod pod-projected-configmaps-c359f340-1c77-4f4c-bd60-49c2aedd7992 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:52:31.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-15" for this suite.
Dec  3 14:52:37.914: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:52:38.310: INFO: namespace projected-15 deletion completed in 6.428012883s
•SSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:52:38.311: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-522
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:52:40.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-522" for this suite.
Dec  3 14:53:18.618: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:53:19.033: INFO: namespace kubelet-test-522 deletion completed in 38.453701391s
•SSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:53:19.034: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-6120
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec  3 14:53:23.354: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  3 14:53:23.365: INFO: Pod pod-with-poststart-http-hook still exists
Dec  3 14:53:25.365: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  3 14:53:25.377: INFO: Pod pod-with-poststart-http-hook still exists
Dec  3 14:53:27.366: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  3 14:53:27.376: INFO: Pod pod-with-poststart-http-hook still exists
Dec  3 14:53:29.366: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  3 14:53:29.377: INFO: Pod pod-with-poststart-http-hook still exists
Dec  3 14:53:31.366: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  3 14:53:31.377: INFO: Pod pod-with-poststart-http-hook still exists
Dec  3 14:53:33.366: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  3 14:53:33.377: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:53:33.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-6120" for this suite.
Dec  3 14:53:55.435: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:53:55.839: INFO: namespace container-lifecycle-hook-6120 deletion completed in 22.442785148s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:53:55.840: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9073
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1420
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  3 14:53:56.027: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-9073'
Dec  3 14:53:56.155: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec  3 14:53:56.155: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1426
Dec  3 14:53:56.166: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete deployment e2e-test-nginx-deployment --namespace=kubectl-9073'
Dec  3 14:53:56.289: INFO: stderr: ""
Dec  3 14:53:56.289: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:53:56.290: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9073" for this suite.
Dec  3 14:54:02.335: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:54:02.726: INFO: namespace kubectl-9073 deletion completed in 6.424770361s
•SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:54:02.726: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2084
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec  3 14:54:02.922: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d9ed8ddf-871b-4ed4-9f1c-9ecf76f7cd23" in namespace "downward-api-2084" to be "success or failure"
Dec  3 14:54:02.933: INFO: Pod "downwardapi-volume-d9ed8ddf-871b-4ed4-9f1c-9ecf76f7cd23": Phase="Pending", Reason="", readiness=false. Elapsed: 10.522336ms
Dec  3 14:54:04.943: INFO: Pod "downwardapi-volume-d9ed8ddf-871b-4ed4-9f1c-9ecf76f7cd23": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021055105s
STEP: Saw pod success
Dec  3 14:54:04.943: INFO: Pod "downwardapi-volume-d9ed8ddf-871b-4ed4-9f1c-9ecf76f7cd23" satisfied condition "success or failure"
Dec  3 14:54:04.954: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod downwardapi-volume-d9ed8ddf-871b-4ed4-9f1c-9ecf76f7cd23 container client-container: <nil>
STEP: delete the pod
Dec  3 14:54:04.987: INFO: Waiting for pod downwardapi-volume-d9ed8ddf-871b-4ed4-9f1c-9ecf76f7cd23 to disappear
Dec  3 14:54:04.997: INFO: Pod downwardapi-volume-d9ed8ddf-871b-4ed4-9f1c-9ecf76f7cd23 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:54:04.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2084" for this suite.
Dec  3 14:54:11.050: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:54:11.485: INFO: namespace downward-api-2084 deletion completed in 6.469478884s
•S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:54:11.486: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-44
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec  3 14:54:11.688: INFO: Waiting up to 5m0s for pod "downwardapi-volume-89a923be-b24f-4098-88f4-c6c419c5004f" in namespace "projected-44" to be "success or failure"
Dec  3 14:54:11.699: INFO: Pod "downwardapi-volume-89a923be-b24f-4098-88f4-c6c419c5004f": Phase="Pending", Reason="", readiness=false. Elapsed: 11.373735ms
Dec  3 14:54:13.710: INFO: Pod "downwardapi-volume-89a923be-b24f-4098-88f4-c6c419c5004f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022412335s
STEP: Saw pod success
Dec  3 14:54:13.710: INFO: Pod "downwardapi-volume-89a923be-b24f-4098-88f4-c6c419c5004f" satisfied condition "success or failure"
Dec  3 14:54:13.721: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod downwardapi-volume-89a923be-b24f-4098-88f4-c6c419c5004f container client-container: <nil>
STEP: delete the pod
Dec  3 14:54:13.752: INFO: Waiting for pod downwardapi-volume-89a923be-b24f-4098-88f4-c6c419c5004f to disappear
Dec  3 14:54:13.762: INFO: Pod downwardapi-volume-89a923be-b24f-4098-88f4-c6c419c5004f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:54:13.762: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-44" for this suite.
Dec  3 14:54:19.816: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:54:20.226: INFO: namespace projected-44 deletion completed in 6.444632258s
•SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:54:20.226: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5986
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec  3 14:54:20.430: INFO: Waiting up to 5m0s for pod "pod-41062dc6-79d4-4f9f-acac-38d952b372bf" in namespace "emptydir-5986" to be "success or failure"
Dec  3 14:54:20.441: INFO: Pod "pod-41062dc6-79d4-4f9f-acac-38d952b372bf": Phase="Pending", Reason="", readiness=false. Elapsed: 10.446731ms
Dec  3 14:54:22.454: INFO: Pod "pod-41062dc6-79d4-4f9f-acac-38d952b372bf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023050619s
STEP: Saw pod success
Dec  3 14:54:22.454: INFO: Pod "pod-41062dc6-79d4-4f9f-acac-38d952b372bf" satisfied condition "success or failure"
Dec  3 14:54:22.464: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod pod-41062dc6-79d4-4f9f-acac-38d952b372bf container test-container: <nil>
STEP: delete the pod
Dec  3 14:54:22.500: INFO: Waiting for pod pod-41062dc6-79d4-4f9f-acac-38d952b372bf to disappear
Dec  3 14:54:22.510: INFO: Pod pod-41062dc6-79d4-4f9f-acac-38d952b372bf no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:54:22.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5986" for this suite.
Dec  3 14:54:28.563: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:54:28.972: INFO: namespace emptydir-5986 deletion completed in 6.442473077s
•SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:54:28.972: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6372
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a replication controller
Dec  3 14:54:29.162: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-6372'
Dec  3 14:54:29.524: INFO: stderr: ""
Dec  3 14:54:29.524: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  3 14:54:29.524: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6372'
Dec  3 14:54:29.678: INFO: stderr: ""
Dec  3 14:54:29.679: INFO: stdout: "update-demo-nautilus-28tsk update-demo-nautilus-qmbhp "
Dec  3 14:54:29.679: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-28tsk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6372'
Dec  3 14:54:29.793: INFO: stderr: ""
Dec  3 14:54:29.793: INFO: stdout: ""
Dec  3 14:54:29.793: INFO: update-demo-nautilus-28tsk is created but not running
Dec  3 14:54:34.793: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6372'
Dec  3 14:54:34.930: INFO: stderr: ""
Dec  3 14:54:34.930: INFO: stdout: "update-demo-nautilus-28tsk update-demo-nautilus-qmbhp "
Dec  3 14:54:34.930: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-28tsk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6372'
Dec  3 14:54:35.071: INFO: stderr: ""
Dec  3 14:54:35.071: INFO: stdout: "true"
Dec  3 14:54:35.071: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-28tsk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6372'
Dec  3 14:54:35.189: INFO: stderr: ""
Dec  3 14:54:35.189: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  3 14:54:35.189: INFO: validating pod update-demo-nautilus-28tsk
Dec  3 14:54:35.287: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 14:54:35.287: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 14:54:35.288: INFO: update-demo-nautilus-28tsk is verified up and running
Dec  3 14:54:35.288: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-qmbhp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6372'
Dec  3 14:54:35.422: INFO: stderr: ""
Dec  3 14:54:35.422: INFO: stdout: "true"
Dec  3 14:54:35.422: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-qmbhp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6372'
Dec  3 14:54:35.559: INFO: stderr: ""
Dec  3 14:54:35.559: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  3 14:54:35.559: INFO: validating pod update-demo-nautilus-qmbhp
Dec  3 14:54:35.654: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 14:54:35.654: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 14:54:35.654: INFO: update-demo-nautilus-qmbhp is verified up and running
STEP: scaling down the replication controller
Dec  3 14:54:35.657: INFO: scanned /root for discovery docs: <nil>
Dec  3 14:54:35.657: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-6372'
Dec  3 14:54:35.809: INFO: stderr: ""
Dec  3 14:54:35.809: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  3 14:54:35.809: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6372'
Dec  3 14:54:35.970: INFO: stderr: ""
Dec  3 14:54:35.970: INFO: stdout: "update-demo-nautilus-28tsk update-demo-nautilus-qmbhp "
STEP: Replicas for name=update-demo: expected=1 actual=2
Dec  3 14:54:40.971: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6372'
Dec  3 14:54:41.088: INFO: stderr: ""
Dec  3 14:54:41.088: INFO: stdout: "update-demo-nautilus-qmbhp "
Dec  3 14:54:41.088: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-qmbhp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6372'
Dec  3 14:54:41.236: INFO: stderr: ""
Dec  3 14:54:41.236: INFO: stdout: "true"
Dec  3 14:54:41.236: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-qmbhp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6372'
Dec  3 14:54:41.383: INFO: stderr: ""
Dec  3 14:54:41.383: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  3 14:54:41.383: INFO: validating pod update-demo-nautilus-qmbhp
Dec  3 14:54:41.395: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 14:54:41.395: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 14:54:41.395: INFO: update-demo-nautilus-qmbhp is verified up and running
STEP: scaling up the replication controller
Dec  3 14:54:41.397: INFO: scanned /root for discovery docs: <nil>
Dec  3 14:54:41.397: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-6372'
Dec  3 14:54:41.574: INFO: stderr: ""
Dec  3 14:54:41.574: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  3 14:54:41.574: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6372'
Dec  3 14:54:41.697: INFO: stderr: ""
Dec  3 14:54:41.697: INFO: stdout: "update-demo-nautilus-qmbhp update-demo-nautilus-zr4hf "
Dec  3 14:54:41.697: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-qmbhp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6372'
Dec  3 14:54:41.832: INFO: stderr: ""
Dec  3 14:54:41.832: INFO: stdout: "true"
Dec  3 14:54:41.832: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-qmbhp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6372'
Dec  3 14:54:41.967: INFO: stderr: ""
Dec  3 14:54:41.968: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  3 14:54:41.968: INFO: validating pod update-demo-nautilus-qmbhp
Dec  3 14:54:41.980: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 14:54:41.980: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 14:54:41.980: INFO: update-demo-nautilus-qmbhp is verified up and running
Dec  3 14:54:41.980: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-zr4hf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6372'
Dec  3 14:54:42.117: INFO: stderr: ""
Dec  3 14:54:42.117: INFO: stdout: ""
Dec  3 14:54:42.117: INFO: update-demo-nautilus-zr4hf is created but not running
Dec  3 14:54:47.117: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6372'
Dec  3 14:54:47.263: INFO: stderr: ""
Dec  3 14:54:47.263: INFO: stdout: "update-demo-nautilus-qmbhp update-demo-nautilus-zr4hf "
Dec  3 14:54:47.263: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-qmbhp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6372'
Dec  3 14:54:47.384: INFO: stderr: ""
Dec  3 14:54:47.384: INFO: stdout: "true"
Dec  3 14:54:47.384: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-qmbhp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6372'
Dec  3 14:54:47.509: INFO: stderr: ""
Dec  3 14:54:47.509: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  3 14:54:47.509: INFO: validating pod update-demo-nautilus-qmbhp
Dec  3 14:54:47.523: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 14:54:47.523: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 14:54:47.523: INFO: update-demo-nautilus-qmbhp is verified up and running
Dec  3 14:54:47.523: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-zr4hf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6372'
Dec  3 14:54:47.660: INFO: stderr: ""
Dec  3 14:54:47.660: INFO: stdout: "true"
Dec  3 14:54:47.660: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-zr4hf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6372'
Dec  3 14:54:47.776: INFO: stderr: ""
Dec  3 14:54:47.776: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  3 14:54:47.776: INFO: validating pod update-demo-nautilus-zr4hf
Dec  3 14:54:47.872: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 14:54:47.872: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 14:54:47.872: INFO: update-demo-nautilus-zr4hf is verified up and running
STEP: using delete to clean up resources
Dec  3 14:54:47.872: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-6372'
Dec  3 14:54:47.997: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 14:54:47.997: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec  3 14:54:47.997: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get rc,svc -l name=update-demo --no-headers --namespace=kubectl-6372'
Dec  3 14:54:48.135: INFO: stderr: "No resources found.\n"
Dec  3 14:54:48.135: INFO: stdout: ""
Dec  3 14:54:48.135: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -l name=update-demo --namespace=kubectl-6372 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  3 14:54:48.266: INFO: stderr: ""
Dec  3 14:54:48.267: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:54:48.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6372" for this suite.
Dec  3 14:54:54.321: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:54:54.725: INFO: namespace kubectl-6372 deletion completed in 6.438614016s
•SSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:54:54.725: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-3950
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec  3 14:54:54.910: INFO: Creating deployment "nginx-deployment"
Dec  3 14:54:54.921: INFO: Waiting for observed generation 1
Dec  3 14:54:56.943: INFO: Waiting for all required pods to come up
Dec  3 14:54:56.963: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Dec  3 14:54:58.992: INFO: Waiting for deployment "nginx-deployment" to complete
Dec  3 14:54:59.013: INFO: Updating deployment "nginx-deployment" with a non-existent image
Dec  3 14:54:59.035: INFO: Updating deployment nginx-deployment
Dec  3 14:54:59.035: INFO: Waiting for observed generation 2
Dec  3 14:55:01.057: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Dec  3 14:55:01.068: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Dec  3 14:55:01.078: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Dec  3 14:55:01.111: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Dec  3 14:55:01.111: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Dec  3 14:55:01.121: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Dec  3 14:55:01.142: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Dec  3 14:55:01.142: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Dec  3 14:55:01.164: INFO: Updating deployment nginx-deployment
Dec  3 14:55:01.164: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Dec  3 14:55:01.188: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Dec  3 14:55:01.199: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Dec  3 14:55:01.220: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-3950,SelfLink:/apis/apps/v1/namespaces/deployment-3950/deployments/nginx-deployment,UID:8774a100-94de-4398-89aa-3db73d754bec,ResourceVersion:6559,Generation:3,CreationTimestamp:2019-12-03 14:54:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Progressing True 2019-12-03 14:54:59 +0000 UTC 2019-12-03 14:54:54 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-55fb7cb77f" is progressing.} {Available False 2019-12-03 14:55:01 +0000 UTC 2019-12-03 14:55:01 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}],ReadyReplicas:8,CollisionCount:nil,},}

Dec  3 14:55:01.232: INFO: New ReplicaSet "nginx-deployment-55fb7cb77f" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f,GenerateName:,Namespace:deployment-3950,SelfLink:/apis/apps/v1/namespaces/deployment-3950/replicasets/nginx-deployment-55fb7cb77f,UID:840c76ed-a760-40b1-a6e5-d5bd9eff4584,ResourceVersion:6594,Generation:3,CreationTimestamp:2019-12-03 14:54:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 8774a100-94de-4398-89aa-3db73d754bec 0xc002e72c37 0xc002e72c38}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  3 14:55:01.232: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Dec  3 14:55:01.232: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498,GenerateName:,Namespace:deployment-3950,SelfLink:/apis/apps/v1/namespaces/deployment-3950/replicasets/nginx-deployment-7b8c6f4498,UID:28f88c1c-b1ca-4dd1-ac12-7c29d55df35b,ResourceVersion:6590,Generation:3,CreationTimestamp:2019-12-03 14:54:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 8774a100-94de-4398-89aa-3db73d754bec 0xc002e72d07 0xc002e72d08}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Dec  3 14:55:01.254: INFO: Pod "nginx-deployment-55fb7cb77f-9bc2b" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-9bc2b,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-3950,SelfLink:/api/v1/namespaces/deployment-3950/pods/nginx-deployment-55fb7cb77f-9bc2b,UID:c774345f-7e97-478a-b35b-c80a2a76aca2,ResourceVersion:6576,Generation:0,CreationTimestamp:2019-12-03 14:55:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 840c76ed-a760-40b1-a6e5-d5bd9eff4584 0xc002e73670 0xc002e73671}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sm8ws {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sm8ws,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-sm8ws true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-r5glw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e736f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e73710}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:55:01 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 14:55:01.254: INFO: Pod "nginx-deployment-55fb7cb77f-b2btd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-b2btd,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-3950,SelfLink:/api/v1/namespaces/deployment-3950/pods/nginx-deployment-55fb7cb77f-b2btd,UID:14ff4a31-9a40-46c0-a462-99cf50fa67d6,ResourceVersion:6582,Generation:0,CreationTimestamp:2019-12-03 14:55:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 840c76ed-a760-40b1-a6e5-d5bd9eff4584 0xc002e73790 0xc002e73791}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sm8ws {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sm8ws,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-sm8ws true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e73800} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e73820}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:55:01 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 14:55:01.254: INFO: Pod "nginx-deployment-55fb7cb77f-d7wlf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-d7wlf,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-3950,SelfLink:/api/v1/namespaces/deployment-3950/pods/nginx-deployment-55fb7cb77f-d7wlf,UID:b13a48fa-c51f-4fcf-bf34-ea907bf3947a,ResourceVersion:6568,Generation:0,CreationTimestamp:2019-12-03 14:55:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 840c76ed-a760-40b1-a6e5-d5bd9eff4584 0xc002e738a0 0xc002e738a1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sm8ws {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sm8ws,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-sm8ws true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e73910} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e73930}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:55:01 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 14:55:01.254: INFO: Pod "nginx-deployment-55fb7cb77f-j9w2j" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-j9w2j,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-3950,SelfLink:/api/v1/namespaces/deployment-3950/pods/nginx-deployment-55fb7cb77f-j9w2j,UID:48c42c2f-128e-41d0-96ea-24b2a8f1e276,ResourceVersion:6578,Generation:0,CreationTimestamp:2019-12-03 14:55:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 840c76ed-a760-40b1-a6e5-d5bd9eff4584 0xc002e739b0 0xc002e739b1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sm8ws {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sm8ws,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-sm8ws true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e73a20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e73a40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:55:01 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 14:55:01.254: INFO: Pod "nginx-deployment-55fb7cb77f-l8pgb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-l8pgb,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-3950,SelfLink:/api/v1/namespaces/deployment-3950/pods/nginx-deployment-55fb7cb77f-l8pgb,UID:e29a2195-9a90-4eb8-8431-b523727387a3,ResourceVersion:6545,Generation:0,CreationTimestamp:2019-12-03 14:54:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.64.1.76/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 840c76ed-a760-40b1-a6e5-d5bd9eff4584 0xc002e73ad0 0xc002e73ad1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sm8ws {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sm8ws,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-sm8ws true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e73b40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e73b60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:54:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:54:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:54:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:54:59 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.3,PodIP:,StartTime:2019-12-03 14:54:59 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 14:55:01.255: INFO: Pod "nginx-deployment-55fb7cb77f-m784g" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-m784g,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-3950,SelfLink:/api/v1/namespaces/deployment-3950/pods/nginx-deployment-55fb7cb77f-m784g,UID:cb7ae47a-1804-47e6-8fbb-fc0b834f3292,ResourceVersion:6544,Generation:0,CreationTimestamp:2019-12-03 14:54:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.64.1.75/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 840c76ed-a760-40b1-a6e5-d5bd9eff4584 0xc002e73c40 0xc002e73c41}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sm8ws {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sm8ws,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-sm8ws true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e73cc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e73ce0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:54:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:54:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:54:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:54:59 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.3,PodIP:,StartTime:2019-12-03 14:54:59 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 14:55:01.255: INFO: Pod "nginx-deployment-55fb7cb77f-mgcwj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-mgcwj,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-3950,SelfLink:/api/v1/namespaces/deployment-3950/pods/nginx-deployment-55fb7cb77f-mgcwj,UID:40c2af42-3b60-49de-9039-3b7704dbb7b9,ResourceVersion:6540,Generation:0,CreationTimestamp:2019-12-03 14:54:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.64.1.74/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 840c76ed-a760-40b1-a6e5-d5bd9eff4584 0xc002e73dc0 0xc002e73dc1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sm8ws {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sm8ws,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-sm8ws true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e73e30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e73e50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:54:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:54:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:54:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:54:59 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.3,PodIP:,StartTime:2019-12-03 14:54:59 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 14:55:01.255: INFO: Pod "nginx-deployment-55fb7cb77f-npsmv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-npsmv,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-3950,SelfLink:/api/v1/namespaces/deployment-3950/pods/nginx-deployment-55fb7cb77f-npsmv,UID:12fe1776-a9a7-4c21-83cd-c27dc0acc863,ResourceVersion:6555,Generation:0,CreationTimestamp:2019-12-03 14:55:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 840c76ed-a760-40b1-a6e5-d5bd9eff4584 0xc002e73f20 0xc002e73f21}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sm8ws {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sm8ws,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-sm8ws true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002e73f90} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002e73fb0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:55:01 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 14:55:01.255: INFO: Pod "nginx-deployment-55fb7cb77f-ptqtq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-ptqtq,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-3950,SelfLink:/api/v1/namespaces/deployment-3950/pods/nginx-deployment-55fb7cb77f-ptqtq,UID:02262fcf-dd42-42af-8763-e83efa5cd05c,ResourceVersion:6565,Generation:0,CreationTimestamp:2019-12-03 14:55:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 840c76ed-a760-40b1-a6e5-d5bd9eff4584 0xc0017d2030 0xc0017d2031}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sm8ws {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sm8ws,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-sm8ws true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-r5glw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0017d20d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0017d2100}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:55:01 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 14:55:01.255: INFO: Pod "nginx-deployment-55fb7cb77f-q9brv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-q9brv,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-3950,SelfLink:/api/v1/namespaces/deployment-3950/pods/nginx-deployment-55fb7cb77f-q9brv,UID:7a2efcae-0a1b-4965-89f0-3edaf232dfb0,ResourceVersion:6575,Generation:0,CreationTimestamp:2019-12-03 14:55:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 840c76ed-a760-40b1-a6e5-d5bd9eff4584 0xc0017d2820 0xc0017d2821}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sm8ws {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sm8ws,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-sm8ws true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-r5glw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0017d2890} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0017d28b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:55:01 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 14:55:01.255: INFO: Pod "nginx-deployment-55fb7cb77f-qkwz2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-qkwz2,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-3950,SelfLink:/api/v1/namespaces/deployment-3950/pods/nginx-deployment-55fb7cb77f-qkwz2,UID:8f0bcbb5-29a4-4b62-8f17-92332ec42ba8,ResourceVersion:6592,Generation:0,CreationTimestamp:2019-12-03 14:55:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 840c76ed-a760-40b1-a6e5-d5bd9eff4584 0xc0017d2a10 0xc0017d2a11}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sm8ws {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sm8ws,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-sm8ws true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-r5glw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0017d2a80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0017d2aa0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:55:01 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 14:55:01.256: INFO: Pod "nginx-deployment-55fb7cb77f-tlhpn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-tlhpn,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-3950,SelfLink:/api/v1/namespaces/deployment-3950/pods/nginx-deployment-55fb7cb77f-tlhpn,UID:7c2f40d8-4c1e-47e6-8456-a5958b87e60f,ResourceVersion:6539,Generation:0,CreationTimestamp:2019-12-03 14:54:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.64.0.24/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 840c76ed-a760-40b1-a6e5-d5bd9eff4584 0xc0017d2b30 0xc0017d2b31}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sm8ws {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sm8ws,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-sm8ws true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-r5glw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0017d2c30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0017d2c50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:54:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:54:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:54:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:54:59 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.2,PodIP:,StartTime:2019-12-03 14:54:59 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 14:55:01.256: INFO: Pod "nginx-deployment-55fb7cb77f-wt2cf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-wt2cf,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-3950,SelfLink:/api/v1/namespaces/deployment-3950/pods/nginx-deployment-55fb7cb77f-wt2cf,UID:a132ff40-d282-4016-92b8-60cf0413a1ac,ResourceVersion:6538,Generation:0,CreationTimestamp:2019-12-03 14:54:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.64.0.23/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 840c76ed-a760-40b1-a6e5-d5bd9eff4584 0xc0017d2d40 0xc0017d2d41}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sm8ws {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sm8ws,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-sm8ws true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-r5glw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0017d2db0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0017d2dd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:54:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:54:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:54:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:54:59 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.2,PodIP:,StartTime:2019-12-03 14:54:59 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 14:55:01.256: INFO: Pod "nginx-deployment-7b8c6f4498-2hvx5" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-2hvx5,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3950,SelfLink:/api/v1/namespaces/deployment-3950/pods/nginx-deployment-7b8c6f4498-2hvx5,UID:3ff4fa9d-9aba-42a4-a727-0055615d7b64,ResourceVersion:6589,Generation:0,CreationTimestamp:2019-12-03 14:55:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 28f88c1c-b1ca-4dd1-ac12-7c29d55df35b 0xc0017d2ea0 0xc0017d2ea1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sm8ws {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sm8ws,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sm8ws true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-r5glw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0017d2f00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0017d2f20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:55:01 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 14:55:01.256: INFO: Pod "nginx-deployment-7b8c6f4498-47jd5" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-47jd5,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3950,SelfLink:/api/v1/namespaces/deployment-3950/pods/nginx-deployment-7b8c6f4498-47jd5,UID:a0586eba-b2b0-4006-8aa9-090f61e7efa3,ResourceVersion:6492,Generation:0,CreationTimestamp:2019-12-03 14:54:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.64.1.71/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 28f88c1c-b1ca-4dd1-ac12-7c29d55df35b 0xc0017d2fb0 0xc0017d2fb1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sm8ws {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sm8ws,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sm8ws true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0017d3010} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0017d3030}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:54:54 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:54:58 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:54:58 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:54:54 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.3,PodIP:100.64.1.71,StartTime:2019-12-03 14:54:54 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-12-03 14:54:57 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://e88d701d7c09ceebb36bdaf4a436192bde527dca0d889d7083822932ba240f1f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 14:55:01.256: INFO: Pod "nginx-deployment-7b8c6f4498-4jmxh" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-4jmxh,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3950,SelfLink:/api/v1/namespaces/deployment-3950/pods/nginx-deployment-7b8c6f4498-4jmxh,UID:f8bf02f2-582d-4aae-9efa-e47bf30e6389,ResourceVersion:6572,Generation:0,CreationTimestamp:2019-12-03 14:55:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 28f88c1c-b1ca-4dd1-ac12-7c29d55df35b 0xc0017d3100 0xc0017d3101}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sm8ws {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sm8ws,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sm8ws true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0017d3160} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0017d3180}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:55:01 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 14:55:01.256: INFO: Pod "nginx-deployment-7b8c6f4498-66692" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-66692,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3950,SelfLink:/api/v1/namespaces/deployment-3950/pods/nginx-deployment-7b8c6f4498-66692,UID:c5a899b5-40ff-4fe3-917d-92c7afa73e45,ResourceVersion:6561,Generation:0,CreationTimestamp:2019-12-03 14:55:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 28f88c1c-b1ca-4dd1-ac12-7c29d55df35b 0xc0017d3200 0xc0017d3201}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sm8ws {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sm8ws,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sm8ws true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-r5glw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0017d3260} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0017d3280}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:55:01 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 14:55:01.257: INFO: Pod "nginx-deployment-7b8c6f4498-7js5f" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-7js5f,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3950,SelfLink:/api/v1/namespaces/deployment-3950/pods/nginx-deployment-7b8c6f4498-7js5f,UID:398673a8-52df-4542-8c2d-2b84e05e548c,ResourceVersion:6484,Generation:0,CreationTimestamp:2019-12-03 14:54:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.64.1.68/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 28f88c1c-b1ca-4dd1-ac12-7c29d55df35b 0xc0017d3310 0xc0017d3311}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sm8ws {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sm8ws,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sm8ws true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0017d3370} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0017d3390}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:54:54 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:54:57 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:54:57 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:54:54 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.3,PodIP:100.64.1.68,StartTime:2019-12-03 14:54:54 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-12-03 14:54:56 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://ce40639612c42261a47c3b6e0720d3048760bc047f51208c042ee6a61e7f59ef}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 14:55:01.257: INFO: Pod "nginx-deployment-7b8c6f4498-92tzv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-92tzv,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3950,SelfLink:/api/v1/namespaces/deployment-3950/pods/nginx-deployment-7b8c6f4498-92tzv,UID:e4c999d4-d0ff-4595-9148-85ac99e2f417,ResourceVersion:6552,Generation:0,CreationTimestamp:2019-12-03 14:55:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 28f88c1c-b1ca-4dd1-ac12-7c29d55df35b 0xc0017d3460 0xc0017d3461}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sm8ws {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sm8ws,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sm8ws true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0017d34c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0017d34f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:55:01 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 14:55:01.257: INFO: Pod "nginx-deployment-7b8c6f4498-b84vt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-b84vt,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3950,SelfLink:/api/v1/namespaces/deployment-3950/pods/nginx-deployment-7b8c6f4498-b84vt,UID:1e1d50cf-0899-452f-b301-fda7f3ffa955,ResourceVersion:6587,Generation:0,CreationTimestamp:2019-12-03 14:55:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 28f88c1c-b1ca-4dd1-ac12-7c29d55df35b 0xc0017d3570 0xc0017d3571}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sm8ws {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sm8ws,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sm8ws true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0017d35d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0017d35f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:55:01 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 14:55:01.257: INFO: Pod "nginx-deployment-7b8c6f4498-bd95d" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-bd95d,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3950,SelfLink:/api/v1/namespaces/deployment-3950/pods/nginx-deployment-7b8c6f4498-bd95d,UID:1703bf6a-dc5e-4399-928d-f82508feb0c5,ResourceVersion:6470,Generation:0,CreationTimestamp:2019-12-03 14:54:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.64.0.21/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 28f88c1c-b1ca-4dd1-ac12-7c29d55df35b 0xc0017d3680 0xc0017d3681}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sm8ws {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sm8ws,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sm8ws true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-r5glw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0017d36e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0017d3700}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:54:54 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:54:57 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:54:57 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:54:54 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.2,PodIP:100.64.0.21,StartTime:2019-12-03 14:54:54 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-12-03 14:54:56 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://353add9b9659926f99e2f33dbfdbbe687183b45d31bff4782b75fe9f0612384c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 14:55:01.257: INFO: Pod "nginx-deployment-7b8c6f4498-bmm7t" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-bmm7t,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3950,SelfLink:/api/v1/namespaces/deployment-3950/pods/nginx-deployment-7b8c6f4498-bmm7t,UID:67ad3244-7193-41a3-afe0-2167b44b552a,ResourceVersion:6586,Generation:0,CreationTimestamp:2019-12-03 14:55:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 28f88c1c-b1ca-4dd1-ac12-7c29d55df35b 0xc0017d37d0 0xc0017d37d1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sm8ws {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sm8ws,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sm8ws true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-r5glw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0017d3830} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0017d3850}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:55:01 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 14:55:01.257: INFO: Pod "nginx-deployment-7b8c6f4498-fjlxb" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-fjlxb,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3950,SelfLink:/api/v1/namespaces/deployment-3950/pods/nginx-deployment-7b8c6f4498-fjlxb,UID:c78ee132-6924-4340-86a8-cb018b4838c7,ResourceVersion:6480,Generation:0,CreationTimestamp:2019-12-03 14:54:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.64.0.20/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 28f88c1c-b1ca-4dd1-ac12-7c29d55df35b 0xc0017d38e0 0xc0017d38e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sm8ws {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sm8ws,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sm8ws true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-r5glw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0017d3940} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0017d3960}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:54:54 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:54:57 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:54:57 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:54:54 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.2,PodIP:100.64.0.20,StartTime:2019-12-03 14:54:54 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-12-03 14:54:56 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://c086f06ff89551e32af4bd4a46d1bf6f86d128842e4ab146bc8822e88a5c260f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 14:55:01.258: INFO: Pod "nginx-deployment-7b8c6f4498-gltdv" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-gltdv,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3950,SelfLink:/api/v1/namespaces/deployment-3950/pods/nginx-deployment-7b8c6f4498-gltdv,UID:37fdd942-3d26-4a53-af9a-db07cb90d049,ResourceVersion:6499,Generation:0,CreationTimestamp:2019-12-03 14:54:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.64.1.69/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 28f88c1c-b1ca-4dd1-ac12-7c29d55df35b 0xc0017d3a40 0xc0017d3a41}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sm8ws {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sm8ws,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sm8ws true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0017d3aa0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0017d3ac0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:54:54 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:54:58 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:54:58 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:54:54 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.3,PodIP:100.64.1.69,StartTime:2019-12-03 14:54:54 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-12-03 14:54:57 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://7e2e9f7915dcf37ff8d3290581c117201899a1ca458b8c362f9b2413875a21ed}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 14:55:01.258: INFO: Pod "nginx-deployment-7b8c6f4498-h5ds4" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-h5ds4,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3950,SelfLink:/api/v1/namespaces/deployment-3950/pods/nginx-deployment-7b8c6f4498-h5ds4,UID:81d4c27b-7060-406d-b468-cf885cd73e9a,ResourceVersion:6473,Generation:0,CreationTimestamp:2019-12-03 14:54:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.64.0.22/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 28f88c1c-b1ca-4dd1-ac12-7c29d55df35b 0xc0017d3ba0 0xc0017d3ba1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sm8ws {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sm8ws,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sm8ws true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-r5glw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0017d3c00} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0017d3c20}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:54:54 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:54:57 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:54:57 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:54:54 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.2,PodIP:100.64.0.22,StartTime:2019-12-03 14:54:54 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-12-03 14:54:56 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://0340677e2d13f2e8ec07da02a5c505db9ad9f95579dd41c991ff3d7561948655}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 14:55:01.258: INFO: Pod "nginx-deployment-7b8c6f4498-hpdmw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-hpdmw,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3950,SelfLink:/api/v1/namespaces/deployment-3950/pods/nginx-deployment-7b8c6f4498-hpdmw,UID:d86d26de-1c6c-4af3-97ca-78a20c413f38,ResourceVersion:6574,Generation:0,CreationTimestamp:2019-12-03 14:55:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 28f88c1c-b1ca-4dd1-ac12-7c29d55df35b 0xc0017d3cf0 0xc0017d3cf1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sm8ws {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sm8ws,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sm8ws true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-r5glw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0017d3d50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0017d3d70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:55:01 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 14:55:01.258: INFO: Pod "nginx-deployment-7b8c6f4498-jkpjt" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-jkpjt,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3950,SelfLink:/api/v1/namespaces/deployment-3950/pods/nginx-deployment-7b8c6f4498-jkpjt,UID:f9b31c72-66d3-4507-9bad-5f4a22b45901,ResourceVersion:6476,Generation:0,CreationTimestamp:2019-12-03 14:54:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.64.0.19/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 28f88c1c-b1ca-4dd1-ac12-7c29d55df35b 0xc0017d3e00 0xc0017d3e01}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sm8ws {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sm8ws,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sm8ws true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-r5glw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0017d3e60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0017d3e80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:54:54 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:54:57 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:54:57 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:54:54 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.2,PodIP:100.64.0.19,StartTime:2019-12-03 14:54:54 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-12-03 14:54:56 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://e9005518f0e7e38778e3131641692d3559bdfd10795cffeb9c387975d46cb652}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 14:55:01.258: INFO: Pod "nginx-deployment-7b8c6f4498-k6wzf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-k6wzf,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3950,SelfLink:/api/v1/namespaces/deployment-3950/pods/nginx-deployment-7b8c6f4498-k6wzf,UID:a8ef959c-34d3-4933-beea-cb9bff6d78b2,ResourceVersion:6593,Generation:0,CreationTimestamp:2019-12-03 14:55:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 28f88c1c-b1ca-4dd1-ac12-7c29d55df35b 0xc0017d3f50 0xc0017d3f51}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sm8ws {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sm8ws,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sm8ws true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-r5glw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0017d3fb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0017d3fd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:55:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:55:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:55:01 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:55:01 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.2,PodIP:,StartTime:2019-12-03 14:55:01 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 14:55:01.259: INFO: Pod "nginx-deployment-7b8c6f4498-nrnfq" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-nrnfq,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3950,SelfLink:/api/v1/namespaces/deployment-3950/pods/nginx-deployment-7b8c6f4498-nrnfq,UID:aebc3593-c5be-45de-8957-37fbf02b5da5,ResourceVersion:6495,Generation:0,CreationTimestamp:2019-12-03 14:54:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.64.1.72/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 28f88c1c-b1ca-4dd1-ac12-7c29d55df35b 0xc001536180 0xc001536181}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sm8ws {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sm8ws,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sm8ws true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0015361e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001536200}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:54:54 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:54:58 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:54:58 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:54:54 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.3,PodIP:100.64.1.72,StartTime:2019-12-03 14:54:54 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-12-03 14:54:57 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://666a5d64c10442a47f660818843f4f4d6aaa18f7ca9573527451888038c2b1a7}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 14:55:01.259: INFO: Pod "nginx-deployment-7b8c6f4498-ss6zf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-ss6zf,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3950,SelfLink:/api/v1/namespaces/deployment-3950/pods/nginx-deployment-7b8c6f4498-ss6zf,UID:f535fc8f-0925-4da0-b567-37492ffca41c,ResourceVersion:6573,Generation:0,CreationTimestamp:2019-12-03 14:55:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 28f88c1c-b1ca-4dd1-ac12-7c29d55df35b 0xc0015362d0 0xc0015362d1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sm8ws {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sm8ws,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sm8ws true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001536330} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001536350}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:55:01 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 14:55:01.259: INFO: Pod "nginx-deployment-7b8c6f4498-tx9qm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-tx9qm,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3950,SelfLink:/api/v1/namespaces/deployment-3950/pods/nginx-deployment-7b8c6f4498-tx9qm,UID:fabd42a9-3845-4dc0-837b-307765458034,ResourceVersion:6585,Generation:0,CreationTimestamp:2019-12-03 14:55:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 28f88c1c-b1ca-4dd1-ac12-7c29d55df35b 0xc0015364c0 0xc0015364c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sm8ws {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sm8ws,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sm8ws true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001536520} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001536540}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:55:01 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 14:55:01.259: INFO: Pod "nginx-deployment-7b8c6f4498-xbcrv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-xbcrv,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3950,SelfLink:/api/v1/namespaces/deployment-3950/pods/nginx-deployment-7b8c6f4498-xbcrv,UID:b89016e3-4572-45e5-98b3-fa4c44da76c1,ResourceVersion:6571,Generation:0,CreationTimestamp:2019-12-03 14:55:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 28f88c1c-b1ca-4dd1-ac12-7c29d55df35b 0xc0015365c0 0xc0015365c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sm8ws {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sm8ws,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sm8ws true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001536630} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001536650}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:55:01 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Dec  3 14:55:01.259: INFO: Pod "nginx-deployment-7b8c6f4498-zq48v" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-zq48v,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-3950,SelfLink:/api/v1/namespaces/deployment-3950/pods/nginx-deployment-7b8c6f4498-zq48v,UID:a5d71fae-cd43-465c-b36b-404e1dae1b63,ResourceVersion:6591,Generation:0,CreationTimestamp:2019-12-03 14:55:01 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 28f88c1c-b1ca-4dd1-ac12-7c29d55df35b 0xc0015366f0 0xc0015366f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sm8ws {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sm8ws,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-sm8ws true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001536750} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001536770}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:55:01 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:55:01.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3950" for this suite.
Dec  3 14:55:07.303: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:55:07.692: INFO: namespace deployment-3950 deletion completed in 6.421134131s
•SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:55:07.692: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3868
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec  3 14:55:07.892: INFO: Waiting up to 5m0s for pod "pod-61137bf6-89a0-4557-ae47-113503448f17" in namespace "emptydir-3868" to be "success or failure"
Dec  3 14:55:07.902: INFO: Pod "pod-61137bf6-89a0-4557-ae47-113503448f17": Phase="Pending", Reason="", readiness=false. Elapsed: 10.05903ms
Dec  3 14:55:09.913: INFO: Pod "pod-61137bf6-89a0-4557-ae47-113503448f17": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02070069s
Dec  3 14:55:11.924: INFO: Pod "pod-61137bf6-89a0-4557-ae47-113503448f17": Phase="Pending", Reason="", readiness=false. Elapsed: 4.031659706s
Dec  3 14:55:13.936: INFO: Pod "pod-61137bf6-89a0-4557-ae47-113503448f17": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.043336002s
STEP: Saw pod success
Dec  3 14:55:13.936: INFO: Pod "pod-61137bf6-89a0-4557-ae47-113503448f17" satisfied condition "success or failure"
Dec  3 14:55:13.946: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod pod-61137bf6-89a0-4557-ae47-113503448f17 container test-container: <nil>
STEP: delete the pod
Dec  3 14:55:13.978: INFO: Waiting for pod pod-61137bf6-89a0-4557-ae47-113503448f17 to disappear
Dec  3 14:55:13.988: INFO: Pod pod-61137bf6-89a0-4557-ae47-113503448f17 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:55:13.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3868" for this suite.
Dec  3 14:55:20.041: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:55:20.455: INFO: namespace emptydir-3868 deletion completed in 6.447673071s
•
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:55:20.455: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3440
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: executing a command with run --rm and attach with stdin
Dec  3 14:55:20.643: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-3440 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Dec  3 14:55:22.674: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Dec  3 14:55:22.674: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:55:24.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3440" for this suite.
Dec  3 14:55:30.748: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:55:31.161: INFO: namespace kubectl-3440 deletion completed in 6.44546179s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:55:31.161: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-9522
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9522.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-9522.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9522.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-9522.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec  3 14:55:33.589: INFO: DNS probes using dns-test-167dfe12-7fc3-44cd-8e91-21fb9123cf0e succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9522.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-9522.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9522.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-9522.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec  3 14:55:35.768: INFO: File wheezy_udp@dns-test-service-3.dns-9522.svc.cluster.local from pod  dns-9522/dns-test-8035dbce-9ac9-487a-b57b-79a267fd8cef contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec  3 14:55:35.851: INFO: Lookups using dns-9522/dns-test-8035dbce-9ac9-487a-b57b-79a267fd8cef failed for: [wheezy_udp@dns-test-service-3.dns-9522.svc.cluster.local]

Dec  3 14:55:40.949: INFO: DNS probes using dns-test-8035dbce-9ac9-487a-b57b-79a267fd8cef succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9522.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-9522.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9522.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-9522.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec  3 14:55:43.228: INFO: DNS probes using dns-test-4e7eeda2-e18d-41d2-b029-662168457e74 succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:55:43.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9522" for this suite.
Dec  3 14:55:49.314: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:55:49.713: INFO: namespace dns-9522 deletion completed in 6.432073613s
•SSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:55:49.713: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-6429
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod liveness-bae0e5b9-422d-4d49-bb86-dd48b27a5e43 in namespace container-probe-6429
Dec  3 14:55:51.936: INFO: Started pod liveness-bae0e5b9-422d-4d49-bb86-dd48b27a5e43 in namespace container-probe-6429
STEP: checking the pod's current state and verifying that restartCount is present
Dec  3 14:55:51.947: INFO: Initial restart count of pod liveness-bae0e5b9-422d-4d49-bb86-dd48b27a5e43 is 0
Dec  3 14:56:08.044: INFO: Restart count of pod container-probe-6429/liveness-bae0e5b9-422d-4d49-bb86-dd48b27a5e43 is now 1 (16.097052251s elapsed)
Dec  3 14:56:26.144: INFO: Restart count of pod container-probe-6429/liveness-bae0e5b9-422d-4d49-bb86-dd48b27a5e43 is now 2 (34.197110051s elapsed)
Dec  3 14:56:46.257: INFO: Restart count of pod container-probe-6429/liveness-bae0e5b9-422d-4d49-bb86-dd48b27a5e43 is now 3 (54.310142045s elapsed)
Dec  3 14:57:06.370: INFO: Restart count of pod container-probe-6429/liveness-bae0e5b9-422d-4d49-bb86-dd48b27a5e43 is now 4 (1m14.422372169s elapsed)
Dec  3 14:58:06.700: INFO: Restart count of pod container-probe-6429/liveness-bae0e5b9-422d-4d49-bb86-dd48b27a5e43 is now 5 (2m14.753011235s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:58:06.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6429" for this suite.
Dec  3 14:58:12.769: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:58:13.164: INFO: namespace container-probe-6429 deletion completed in 6.429492783s
•SSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:58:13.164: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-3586
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-3586
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec  3 14:58:13.352: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec  3 14:58:37.552: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 100.64.1.94 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3586 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 14:58:37.552: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 14:58:38.976: INFO: Found all expected endpoints: [netserver-0]
Dec  3 14:58:38.987: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 100.64.0.34 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3586 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 14:58:38.987: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 14:58:40.408: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 14:58:40.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3586" for this suite.
Dec  3 14:59:02.460: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:59:02.863: INFO: namespace pod-network-test-3586 deletion completed in 22.435361142s
•SSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 14:59:02.863: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7961
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name s-test-opt-del-6e2bb2fe-b17d-4f73-9223-891e00284c57
STEP: Creating secret with name s-test-opt-upd-963d2840-8ef9-46e7-8305-fdf613899e92
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-6e2bb2fe-b17d-4f73-9223-891e00284c57
STEP: Updating secret s-test-opt-upd-963d2840-8ef9-46e7-8305-fdf613899e92
STEP: Creating secret with name s-test-opt-create-e1d6fb37-2b3a-417d-8812-05e569ac3d34
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:00:30.297: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7961" for this suite.
Dec  3 15:00:52.342: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:00:52.753: INFO: namespace projected-7961 deletion completed in 22.443584538s
•SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:00:52.753: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-9207
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9207.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9207.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec  3 15:00:57.588: INFO: DNS probes using dns-9207/dns-test-9358ccbf-1d11-4d6d-b5c1-ff8dbacc5fb9 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:00:57.603: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9207" for this suite.
Dec  3 15:01:03.654: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:01:04.056: INFO: namespace dns-9207 deletion completed in 6.433423103s
•SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:01:04.056: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6463
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1210
STEP: creating the pod
Dec  3 15:01:04.248: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-6463'
Dec  3 15:01:04.728: INFO: stderr: ""
Dec  3 15:01:04.728: INFO: stdout: "pod/pause created\n"
Dec  3 15:01:04.728: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Dec  3 15:01:04.728: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-6463" to be "running and ready"
Dec  3 15:01:04.738: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 10.259818ms
Dec  3 15:01:06.750: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.021738645s
Dec  3 15:01:06.750: INFO: Pod "pause" satisfied condition "running and ready"
Dec  3 15:01:06.750: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: adding the label testing-label with value testing-label-value to a pod
Dec  3 15:01:06.750: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config label pods pause testing-label=testing-label-value --namespace=kubectl-6463'
Dec  3 15:01:06.868: INFO: stderr: ""
Dec  3 15:01:06.868: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Dec  3 15:01:06.868: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pod pause -L testing-label --namespace=kubectl-6463'
Dec  3 15:01:06.973: INFO: stderr: ""
Dec  3 15:01:06.973: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Dec  3 15:01:06.973: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config label pods pause testing-label- --namespace=kubectl-6463'
Dec  3 15:01:07.094: INFO: stderr: ""
Dec  3 15:01:07.094: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Dec  3 15:01:07.094: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pod pause -L testing-label --namespace=kubectl-6463'
Dec  3 15:01:07.204: INFO: stderr: ""
Dec  3 15:01:07.204: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1217
STEP: using delete to clean up resources
Dec  3 15:01:07.204: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-6463'
Dec  3 15:01:07.321: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 15:01:07.321: INFO: stdout: "pod \"pause\" force deleted\n"
Dec  3 15:01:07.321: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get rc,svc -l name=pause --no-headers --namespace=kubectl-6463'
Dec  3 15:01:07.449: INFO: stderr: "No resources found.\n"
Dec  3 15:01:07.449: INFO: stdout: ""
Dec  3 15:01:07.449: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -l name=pause --namespace=kubectl-6463 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  3 15:01:07.555: INFO: stderr: ""
Dec  3 15:01:07.555: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:01:07.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6463" for this suite.
Dec  3 15:01:13.606: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:01:14.005: INFO: namespace kubectl-6463 deletion completed in 6.431057921s
•SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:01:14.005: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-9280
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec  3 15:01:14.245: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Dec  3 15:01:14.266: INFO: Number of nodes with available pods: 0
Dec  3 15:01:14.266: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Dec  3 15:01:14.309: INFO: Number of nodes with available pods: 0
Dec  3 15:01:14.309: INFO: Node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 is running more than one daemon pod
Dec  3 15:01:15.320: INFO: Number of nodes with available pods: 0
Dec  3 15:01:15.320: INFO: Node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 is running more than one daemon pod
Dec  3 15:01:16.320: INFO: Number of nodes with available pods: 1
Dec  3 15:01:16.320: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Dec  3 15:01:16.362: INFO: Number of nodes with available pods: 0
Dec  3 15:01:16.362: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Dec  3 15:01:16.385: INFO: Number of nodes with available pods: 0
Dec  3 15:01:16.385: INFO: Node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 is running more than one daemon pod
Dec  3 15:01:17.396: INFO: Number of nodes with available pods: 0
Dec  3 15:01:17.396: INFO: Node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 is running more than one daemon pod
Dec  3 15:01:18.396: INFO: Number of nodes with available pods: 0
Dec  3 15:01:18.396: INFO: Node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 is running more than one daemon pod
Dec  3 15:01:19.396: INFO: Number of nodes with available pods: 0
Dec  3 15:01:19.396: INFO: Node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 is running more than one daemon pod
Dec  3 15:01:20.396: INFO: Number of nodes with available pods: 0
Dec  3 15:01:20.396: INFO: Node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 is running more than one daemon pod
Dec  3 15:01:21.395: INFO: Number of nodes with available pods: 0
Dec  3 15:01:21.395: INFO: Node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 is running more than one daemon pod
Dec  3 15:01:22.405: INFO: Number of nodes with available pods: 1
Dec  3 15:01:22.406: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9280, will wait for the garbage collector to delete the pods
Dec  3 15:01:22.500: INFO: Deleting DaemonSet.extensions daemon-set took: 12.221782ms
Dec  3 15:01:23.000: INFO: Terminating DaemonSet.extensions daemon-set pods took: 500.387468ms
Dec  3 15:01:33.111: INFO: Number of nodes with available pods: 0
Dec  3 15:01:33.111: INFO: Number of running nodes: 0, number of available pods: 0
Dec  3 15:01:33.121: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9280/daemonsets","resourceVersion":"7871"},"items":null}

Dec  3 15:01:33.131: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9280/pods","resourceVersion":"7871"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:01:33.186: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9280" for this suite.
Dec  3 15:01:39.231: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:01:39.652: INFO: namespace daemonsets-9280 deletion completed in 6.453975273s
•SSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:01:39.653: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svc-latency-769
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating replication controller svc-latency-rc in namespace svc-latency-769
I1203 15:01:39.856721    5066 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: svc-latency-769, replica count: 1
I1203 15:01:40.907270    5066 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1203 15:01:41.907607    5066 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec  3 15:01:42.024: INFO: Created: latency-svc-xpfqx
Dec  3 15:01:42.027: INFO: Got endpoints: latency-svc-xpfqx [19.811643ms]
Dec  3 15:01:42.044: INFO: Created: latency-svc-fp4jl
Dec  3 15:01:42.048: INFO: Created: latency-svc-p8l26
Dec  3 15:01:42.048: INFO: Got endpoints: latency-svc-fp4jl [21.000256ms]
Dec  3 15:01:42.054: INFO: Got endpoints: latency-svc-p8l26 [26.319219ms]
Dec  3 15:01:42.054: INFO: Created: latency-svc-mcr27
Dec  3 15:01:42.058: INFO: Got endpoints: latency-svc-mcr27 [30.551996ms]
Dec  3 15:01:42.058: INFO: Created: latency-svc-ls44q
Dec  3 15:01:42.060: INFO: Got endpoints: latency-svc-ls44q [32.931745ms]
Dec  3 15:01:42.064: INFO: Created: latency-svc-kftfp
Dec  3 15:01:42.069: INFO: Created: latency-svc-jsqvw
Dec  3 15:01:42.069: INFO: Got endpoints: latency-svc-kftfp [41.551553ms]
Dec  3 15:01:42.075: INFO: Got endpoints: latency-svc-jsqvw [47.079213ms]
Dec  3 15:01:42.075: INFO: Created: latency-svc-vdmkh
Dec  3 15:01:42.076: INFO: Got endpoints: latency-svc-vdmkh [48.727384ms]
Dec  3 15:01:42.079: INFO: Created: latency-svc-kz2ss
Dec  3 15:01:42.084: INFO: Got endpoints: latency-svc-kz2ss [56.330823ms]
Dec  3 15:01:42.084: INFO: Created: latency-svc-gffdb
Dec  3 15:01:42.088: INFO: Got endpoints: latency-svc-gffdb [60.866177ms]
Dec  3 15:01:42.089: INFO: Created: latency-svc-44lsn
Dec  3 15:01:42.091: INFO: Got endpoints: latency-svc-44lsn [63.096498ms]
Dec  3 15:01:42.098: INFO: Created: latency-svc-fwbfm
Dec  3 15:01:42.103: INFO: Got endpoints: latency-svc-fwbfm [74.931076ms]
Dec  3 15:01:42.103: INFO: Created: latency-svc-pw6n5
Dec  3 15:01:42.107: INFO: Created: latency-svc-5dsbw
Dec  3 15:01:42.108: INFO: Got endpoints: latency-svc-pw6n5 [79.968799ms]
Dec  3 15:01:42.112: INFO: Created: latency-svc-776qz
Dec  3 15:01:42.112: INFO: Got endpoints: latency-svc-5dsbw [84.304194ms]
Dec  3 15:01:42.117: INFO: Created: latency-svc-bjbld
Dec  3 15:01:42.117: INFO: Got endpoints: latency-svc-776qz [89.241471ms]
Dec  3 15:01:42.132: INFO: Created: latency-svc-255tr
Dec  3 15:01:42.132: INFO: Got endpoints: latency-svc-bjbld [104.339113ms]
Dec  3 15:01:42.136: INFO: Created: latency-svc-bvlwq
Dec  3 15:01:42.136: INFO: Got endpoints: latency-svc-255tr [87.577845ms]
Dec  3 15:01:42.141: INFO: Got endpoints: latency-svc-bvlwq [86.666108ms]
Dec  3 15:01:42.141: INFO: Created: latency-svc-t8zcx
Dec  3 15:01:42.145: INFO: Got endpoints: latency-svc-t8zcx [86.843395ms]
Dec  3 15:01:42.145: INFO: Created: latency-svc-jrkqf
Dec  3 15:01:42.150: INFO: Created: latency-svc-tltxr
Dec  3 15:01:42.150: INFO: Got endpoints: latency-svc-jrkqf [89.677998ms]
Dec  3 15:01:42.155: INFO: Got endpoints: latency-svc-tltxr [85.70804ms]
Dec  3 15:01:42.156: INFO: Created: latency-svc-j56tj
Dec  3 15:01:42.160: INFO: Got endpoints: latency-svc-j56tj [85.211601ms]
Dec  3 15:01:42.160: INFO: Created: latency-svc-kqfrf
Dec  3 15:01:42.164: INFO: Got endpoints: latency-svc-kqfrf [87.553665ms]
Dec  3 15:01:42.164: INFO: Created: latency-svc-h29mx
Dec  3 15:01:42.168: INFO: Got endpoints: latency-svc-h29mx [84.494897ms]
Dec  3 15:01:42.169: INFO: Created: latency-svc-954jb
Dec  3 15:01:42.173: INFO: Got endpoints: latency-svc-954jb [84.669084ms]
Dec  3 15:01:42.173: INFO: Created: latency-svc-5rbwz
Dec  3 15:01:42.178: INFO: Got endpoints: latency-svc-5rbwz [86.824802ms]
Dec  3 15:01:42.178: INFO: Created: latency-svc-6c7dw
Dec  3 15:01:42.183: INFO: Created: latency-svc-jnj59
Dec  3 15:01:42.183: INFO: Got endpoints: latency-svc-6c7dw [80.47297ms]
Dec  3 15:01:42.188: INFO: Created: latency-svc-zf46p
Dec  3 15:01:42.188: INFO: Got endpoints: latency-svc-jnj59 [80.601818ms]
Dec  3 15:01:42.193: INFO: Got endpoints: latency-svc-zf46p [81.124676ms]
Dec  3 15:01:42.194: INFO: Created: latency-svc-wx75g
Dec  3 15:01:42.198: INFO: Created: latency-svc-d7g88
Dec  3 15:01:42.198: INFO: Got endpoints: latency-svc-wx75g [81.457745ms]
Dec  3 15:01:42.203: INFO: Got endpoints: latency-svc-d7g88 [70.764003ms]
Dec  3 15:01:42.203: INFO: Created: latency-svc-6gvzc
Dec  3 15:01:42.208: INFO: Got endpoints: latency-svc-6gvzc [71.540768ms]
Dec  3 15:01:42.209: INFO: Created: latency-svc-j4b8d
Dec  3 15:01:42.213: INFO: Got endpoints: latency-svc-j4b8d [72.188347ms]
Dec  3 15:01:42.213: INFO: Created: latency-svc-c7vhp
Dec  3 15:01:42.217: INFO: Created: latency-svc-fh8m2
Dec  3 15:01:42.223: INFO: Created: latency-svc-kvgmt
Dec  3 15:01:42.237: INFO: Got endpoints: latency-svc-c7vhp [92.41956ms]
Dec  3 15:01:42.237: INFO: Created: latency-svc-5wrnp
Dec  3 15:01:42.242: INFO: Created: latency-svc-stcb5
Dec  3 15:01:42.246: INFO: Created: latency-svc-qn9cw
Dec  3 15:01:42.251: INFO: Created: latency-svc-q6ckp
Dec  3 15:01:42.256: INFO: Created: latency-svc-clq2z
Dec  3 15:01:42.260: INFO: Created: latency-svc-fk4pw
Dec  3 15:01:42.265: INFO: Created: latency-svc-l88c4
Dec  3 15:01:42.270: INFO: Created: latency-svc-7k8dl
Dec  3 15:01:42.275: INFO: Created: latency-svc-hlrsk
Dec  3 15:01:42.276: INFO: Got endpoints: latency-svc-fh8m2 [126.112441ms]
Dec  3 15:01:42.281: INFO: Created: latency-svc-xn62h
Dec  3 15:01:42.291: INFO: Created: latency-svc-8fs8b
Dec  3 15:01:42.295: INFO: Created: latency-svc-mf7zl
Dec  3 15:01:42.303: INFO: Created: latency-svc-p4jx6
Dec  3 15:01:42.308: INFO: Created: latency-svc-sd27s
Dec  3 15:01:42.383: INFO: Got endpoints: latency-svc-5wrnp [223.48777ms]
Dec  3 15:01:42.385: INFO: Got endpoints: latency-svc-kvgmt [229.894877ms]
Dec  3 15:01:42.401: INFO: Created: latency-svc-cqc9f
Dec  3 15:01:42.404: INFO: Created: latency-svc-dqjmm
Dec  3 15:01:42.427: INFO: Got endpoints: latency-svc-stcb5 [263.085811ms]
Dec  3 15:01:42.443: INFO: Created: latency-svc-lr8sv
Dec  3 15:01:42.477: INFO: Got endpoints: latency-svc-qn9cw [308.553386ms]
Dec  3 15:01:42.493: INFO: Created: latency-svc-fwch4
Dec  3 15:01:42.527: INFO: Got endpoints: latency-svc-q6ckp [353.776037ms]
Dec  3 15:01:42.543: INFO: Created: latency-svc-mjt7f
Dec  3 15:01:42.577: INFO: Got endpoints: latency-svc-clq2z [399.275388ms]
Dec  3 15:01:42.593: INFO: Created: latency-svc-dngsm
Dec  3 15:01:42.627: INFO: Got endpoints: latency-svc-fk4pw [444.114695ms]
Dec  3 15:01:42.644: INFO: Created: latency-svc-hrxxs
Dec  3 15:01:42.677: INFO: Got endpoints: latency-svc-l88c4 [488.990271ms]
Dec  3 15:01:42.695: INFO: Created: latency-svc-84jqs
Dec  3 15:01:42.727: INFO: Got endpoints: latency-svc-7k8dl [533.845438ms]
Dec  3 15:01:42.744: INFO: Created: latency-svc-kg9st
Dec  3 15:01:42.777: INFO: Got endpoints: latency-svc-hlrsk [579.039725ms]
Dec  3 15:01:42.794: INFO: Created: latency-svc-ltlps
Dec  3 15:01:42.827: INFO: Got endpoints: latency-svc-xn62h [624.333973ms]
Dec  3 15:01:42.843: INFO: Created: latency-svc-l2hxk
Dec  3 15:01:42.878: INFO: Got endpoints: latency-svc-8fs8b [669.805233ms]
Dec  3 15:01:42.893: INFO: Created: latency-svc-fjtgd
Dec  3 15:01:42.927: INFO: Got endpoints: latency-svc-mf7zl [714.508468ms]
Dec  3 15:01:42.943: INFO: Created: latency-svc-q95mt
Dec  3 15:01:42.977: INFO: Got endpoints: latency-svc-p4jx6 [739.59429ms]
Dec  3 15:01:42.993: INFO: Created: latency-svc-fntdw
Dec  3 15:01:43.027: INFO: Got endpoints: latency-svc-sd27s [750.549372ms]
Dec  3 15:01:43.043: INFO: Created: latency-svc-whmvg
Dec  3 15:01:43.078: INFO: Got endpoints: latency-svc-cqc9f [694.191677ms]
Dec  3 15:01:43.094: INFO: Created: latency-svc-5r26g
Dec  3 15:01:43.127: INFO: Got endpoints: latency-svc-dqjmm [741.967671ms]
Dec  3 15:01:43.143: INFO: Created: latency-svc-x2w56
Dec  3 15:01:43.177: INFO: Got endpoints: latency-svc-lr8sv [749.891993ms]
Dec  3 15:01:43.193: INFO: Created: latency-svc-b6869
Dec  3 15:01:43.227: INFO: Got endpoints: latency-svc-fwch4 [750.17401ms]
Dec  3 15:01:43.243: INFO: Created: latency-svc-g6xxb
Dec  3 15:01:43.277: INFO: Got endpoints: latency-svc-mjt7f [749.85187ms]
Dec  3 15:01:43.292: INFO: Created: latency-svc-7rml8
Dec  3 15:01:43.327: INFO: Got endpoints: latency-svc-dngsm [750.167077ms]
Dec  3 15:01:43.343: INFO: Created: latency-svc-sk5gl
Dec  3 15:01:43.377: INFO: Got endpoints: latency-svc-hrxxs [749.68396ms]
Dec  3 15:01:43.396: INFO: Created: latency-svc-qjw2w
Dec  3 15:01:43.427: INFO: Got endpoints: latency-svc-84jqs [749.681512ms]
Dec  3 15:01:43.442: INFO: Created: latency-svc-7wbv2
Dec  3 15:01:43.477: INFO: Got endpoints: latency-svc-kg9st [749.766321ms]
Dec  3 15:01:43.495: INFO: Created: latency-svc-9qn7w
Dec  3 15:01:43.527: INFO: Got endpoints: latency-svc-ltlps [749.387969ms]
Dec  3 15:01:43.542: INFO: Created: latency-svc-kjrlm
Dec  3 15:01:43.577: INFO: Got endpoints: latency-svc-l2hxk [749.590129ms]
Dec  3 15:01:43.592: INFO: Created: latency-svc-mrb4r
Dec  3 15:01:43.627: INFO: Got endpoints: latency-svc-fjtgd [749.480523ms]
Dec  3 15:01:43.643: INFO: Created: latency-svc-4hhqx
Dec  3 15:01:43.677: INFO: Got endpoints: latency-svc-q95mt [749.796996ms]
Dec  3 15:01:43.692: INFO: Created: latency-svc-jqt4l
Dec  3 15:01:43.727: INFO: Got endpoints: latency-svc-fntdw [750.149035ms]
Dec  3 15:01:43.743: INFO: Created: latency-svc-d6hhx
Dec  3 15:01:43.777: INFO: Got endpoints: latency-svc-whmvg [750.285109ms]
Dec  3 15:01:43.793: INFO: Created: latency-svc-5bws9
Dec  3 15:01:43.827: INFO: Got endpoints: latency-svc-5r26g [749.197353ms]
Dec  3 15:01:43.843: INFO: Created: latency-svc-459gk
Dec  3 15:01:43.877: INFO: Got endpoints: latency-svc-x2w56 [750.442262ms]
Dec  3 15:01:43.893: INFO: Created: latency-svc-ztjtn
Dec  3 15:01:43.928: INFO: Got endpoints: latency-svc-b6869 [750.480474ms]
Dec  3 15:01:43.943: INFO: Created: latency-svc-qmj4g
Dec  3 15:01:43.977: INFO: Got endpoints: latency-svc-g6xxb [749.668966ms]
Dec  3 15:01:43.995: INFO: Created: latency-svc-lfh67
Dec  3 15:01:44.028: INFO: Got endpoints: latency-svc-7rml8 [750.815929ms]
Dec  3 15:01:44.045: INFO: Created: latency-svc-zh2dh
Dec  3 15:01:44.077: INFO: Got endpoints: latency-svc-sk5gl [750.044613ms]
Dec  3 15:01:44.094: INFO: Created: latency-svc-679nl
Dec  3 15:01:44.127: INFO: Got endpoints: latency-svc-qjw2w [750.37616ms]
Dec  3 15:01:44.144: INFO: Created: latency-svc-4f6d7
Dec  3 15:01:44.177: INFO: Got endpoints: latency-svc-7wbv2 [750.092822ms]
Dec  3 15:01:44.193: INFO: Created: latency-svc-9knnv
Dec  3 15:01:44.228: INFO: Got endpoints: latency-svc-9qn7w [750.994664ms]
Dec  3 15:01:44.244: INFO: Created: latency-svc-bqrqx
Dec  3 15:01:44.277: INFO: Got endpoints: latency-svc-kjrlm [749.958806ms]
Dec  3 15:01:44.293: INFO: Created: latency-svc-jnphk
Dec  3 15:01:44.327: INFO: Got endpoints: latency-svc-mrb4r [750.343343ms]
Dec  3 15:01:44.343: INFO: Created: latency-svc-6qg8g
Dec  3 15:01:44.377: INFO: Got endpoints: latency-svc-4hhqx [750.005452ms]
Dec  3 15:01:44.393: INFO: Created: latency-svc-4mvrf
Dec  3 15:01:44.427: INFO: Got endpoints: latency-svc-jqt4l [749.891855ms]
Dec  3 15:01:44.443: INFO: Created: latency-svc-j6lz9
Dec  3 15:01:44.477: INFO: Got endpoints: latency-svc-d6hhx [749.886118ms]
Dec  3 15:01:44.494: INFO: Created: latency-svc-hm2nz
Dec  3 15:01:44.527: INFO: Got endpoints: latency-svc-5bws9 [749.962274ms]
Dec  3 15:01:44.548: INFO: Created: latency-svc-qr6pp
Dec  3 15:01:44.577: INFO: Got endpoints: latency-svc-459gk [750.234091ms]
Dec  3 15:01:44.593: INFO: Created: latency-svc-w8bpg
Dec  3 15:01:44.627: INFO: Got endpoints: latency-svc-ztjtn [750.028134ms]
Dec  3 15:01:44.647: INFO: Created: latency-svc-x7566
Dec  3 15:01:44.677: INFO: Got endpoints: latency-svc-qmj4g [749.313562ms]
Dec  3 15:01:44.693: INFO: Created: latency-svc-cl99w
Dec  3 15:01:44.727: INFO: Got endpoints: latency-svc-lfh67 [750.10878ms]
Dec  3 15:01:44.743: INFO: Created: latency-svc-qq97d
Dec  3 15:01:44.777: INFO: Got endpoints: latency-svc-zh2dh [749.149475ms]
Dec  3 15:01:44.794: INFO: Created: latency-svc-jltrv
Dec  3 15:01:44.827: INFO: Got endpoints: latency-svc-679nl [749.981874ms]
Dec  3 15:01:44.844: INFO: Created: latency-svc-6qfdh
Dec  3 15:01:44.877: INFO: Got endpoints: latency-svc-4f6d7 [749.585591ms]
Dec  3 15:01:44.894: INFO: Created: latency-svc-4mwnw
Dec  3 15:01:44.927: INFO: Got endpoints: latency-svc-9knnv [749.859281ms]
Dec  3 15:01:44.943: INFO: Created: latency-svc-fwsnq
Dec  3 15:01:44.977: INFO: Got endpoints: latency-svc-bqrqx [749.313724ms]
Dec  3 15:01:44.993: INFO: Created: latency-svc-vrpd8
Dec  3 15:01:45.027: INFO: Got endpoints: latency-svc-jnphk [750.224601ms]
Dec  3 15:01:45.044: INFO: Created: latency-svc-dl9sw
Dec  3 15:01:45.077: INFO: Got endpoints: latency-svc-6qg8g [749.653091ms]
Dec  3 15:01:45.093: INFO: Created: latency-svc-qkxsb
Dec  3 15:01:45.127: INFO: Got endpoints: latency-svc-4mvrf [749.713052ms]
Dec  3 15:01:45.143: INFO: Created: latency-svc-mgsng
Dec  3 15:01:45.177: INFO: Got endpoints: latency-svc-j6lz9 [749.79463ms]
Dec  3 15:01:45.193: INFO: Created: latency-svc-nm6tk
Dec  3 15:01:45.227: INFO: Got endpoints: latency-svc-hm2nz [749.99211ms]
Dec  3 15:01:45.244: INFO: Created: latency-svc-qp7vt
Dec  3 15:01:45.277: INFO: Got endpoints: latency-svc-qr6pp [749.801193ms]
Dec  3 15:01:45.293: INFO: Created: latency-svc-9f6qb
Dec  3 15:01:45.327: INFO: Got endpoints: latency-svc-w8bpg [749.827011ms]
Dec  3 15:01:45.344: INFO: Created: latency-svc-6q5qd
Dec  3 15:01:45.383: INFO: Got endpoints: latency-svc-x7566 [755.438253ms]
Dec  3 15:01:45.399: INFO: Created: latency-svc-8576d
Dec  3 15:01:45.428: INFO: Got endpoints: latency-svc-cl99w [750.496814ms]
Dec  3 15:01:45.444: INFO: Created: latency-svc-lwbkw
Dec  3 15:01:45.477: INFO: Got endpoints: latency-svc-qq97d [749.868296ms]
Dec  3 15:01:45.493: INFO: Created: latency-svc-dmgcz
Dec  3 15:01:45.527: INFO: Got endpoints: latency-svc-jltrv [750.165982ms]
Dec  3 15:01:45.543: INFO: Created: latency-svc-5vjkw
Dec  3 15:01:45.577: INFO: Got endpoints: latency-svc-6qfdh [749.71689ms]
Dec  3 15:01:45.595: INFO: Created: latency-svc-f6dtd
Dec  3 15:01:45.627: INFO: Got endpoints: latency-svc-4mwnw [750.177332ms]
Dec  3 15:01:45.644: INFO: Created: latency-svc-bgtwj
Dec  3 15:01:45.677: INFO: Got endpoints: latency-svc-fwsnq [750.288142ms]
Dec  3 15:01:45.700: INFO: Created: latency-svc-2gdp9
Dec  3 15:01:45.727: INFO: Got endpoints: latency-svc-vrpd8 [749.7555ms]
Dec  3 15:01:45.744: INFO: Created: latency-svc-rdm6l
Dec  3 15:01:45.778: INFO: Got endpoints: latency-svc-dl9sw [750.608051ms]
Dec  3 15:01:45.795: INFO: Created: latency-svc-lpjbl
Dec  3 15:01:45.827: INFO: Got endpoints: latency-svc-qkxsb [750.166224ms]
Dec  3 15:01:45.843: INFO: Created: latency-svc-4t9tl
Dec  3 15:01:45.877: INFO: Got endpoints: latency-svc-mgsng [749.996621ms]
Dec  3 15:01:45.895: INFO: Created: latency-svc-2n2ws
Dec  3 15:01:45.927: INFO: Got endpoints: latency-svc-nm6tk [750.34961ms]
Dec  3 15:01:45.943: INFO: Created: latency-svc-hdx4j
Dec  3 15:01:45.977: INFO: Got endpoints: latency-svc-qp7vt [749.819753ms]
Dec  3 15:01:45.993: INFO: Created: latency-svc-75tkz
Dec  3 15:01:46.027: INFO: Got endpoints: latency-svc-9f6qb [749.873296ms]
Dec  3 15:01:46.046: INFO: Created: latency-svc-2fftp
Dec  3 15:01:46.077: INFO: Got endpoints: latency-svc-6q5qd [749.280792ms]
Dec  3 15:01:46.092: INFO: Created: latency-svc-7swjj
Dec  3 15:01:46.128: INFO: Got endpoints: latency-svc-8576d [744.562885ms]
Dec  3 15:01:46.144: INFO: Created: latency-svc-9ll52
Dec  3 15:01:46.177: INFO: Got endpoints: latency-svc-lwbkw [749.293898ms]
Dec  3 15:01:46.193: INFO: Created: latency-svc-4ll9g
Dec  3 15:01:46.227: INFO: Got endpoints: latency-svc-dmgcz [749.817913ms]
Dec  3 15:01:46.243: INFO: Created: latency-svc-blkpx
Dec  3 15:01:46.277: INFO: Got endpoints: latency-svc-5vjkw [749.599303ms]
Dec  3 15:01:46.292: INFO: Created: latency-svc-zclw4
Dec  3 15:01:46.327: INFO: Got endpoints: latency-svc-f6dtd [749.717507ms]
Dec  3 15:01:46.343: INFO: Created: latency-svc-fnk5x
Dec  3 15:01:46.379: INFO: Got endpoints: latency-svc-bgtwj [751.569886ms]
Dec  3 15:01:46.395: INFO: Created: latency-svc-srdbd
Dec  3 15:01:46.429: INFO: Got endpoints: latency-svc-2gdp9 [751.643281ms]
Dec  3 15:01:46.445: INFO: Created: latency-svc-2ktdk
Dec  3 15:01:46.477: INFO: Got endpoints: latency-svc-rdm6l [749.488077ms]
Dec  3 15:01:46.494: INFO: Created: latency-svc-7tmds
Dec  3 15:01:46.528: INFO: Got endpoints: latency-svc-lpjbl [749.396156ms]
Dec  3 15:01:46.542: INFO: Created: latency-svc-88k95
Dec  3 15:01:46.577: INFO: Got endpoints: latency-svc-4t9tl [749.828363ms]
Dec  3 15:01:46.593: INFO: Created: latency-svc-bq8g8
Dec  3 15:01:46.627: INFO: Got endpoints: latency-svc-2n2ws [749.890732ms]
Dec  3 15:01:46.643: INFO: Created: latency-svc-znctr
Dec  3 15:01:46.677: INFO: Got endpoints: latency-svc-hdx4j [749.445068ms]
Dec  3 15:01:46.694: INFO: Created: latency-svc-mmn85
Dec  3 15:01:46.727: INFO: Got endpoints: latency-svc-75tkz [750.131744ms]
Dec  3 15:01:46.749: INFO: Created: latency-svc-rbknh
Dec  3 15:01:46.777: INFO: Got endpoints: latency-svc-2fftp [749.694036ms]
Dec  3 15:01:46.793: INFO: Created: latency-svc-x9c2l
Dec  3 15:01:46.827: INFO: Got endpoints: latency-svc-7swjj [750.47275ms]
Dec  3 15:01:46.849: INFO: Created: latency-svc-kl6kj
Dec  3 15:01:46.877: INFO: Got endpoints: latency-svc-9ll52 [749.330592ms]
Dec  3 15:01:46.892: INFO: Created: latency-svc-qkn92
Dec  3 15:01:46.927: INFO: Got endpoints: latency-svc-4ll9g [750.283834ms]
Dec  3 15:01:46.944: INFO: Created: latency-svc-tnpk4
Dec  3 15:01:46.977: INFO: Got endpoints: latency-svc-blkpx [749.809191ms]
Dec  3 15:01:46.993: INFO: Created: latency-svc-dkxbd
Dec  3 15:01:47.027: INFO: Got endpoints: latency-svc-zclw4 [750.090853ms]
Dec  3 15:01:47.045: INFO: Created: latency-svc-m7sft
Dec  3 15:01:47.078: INFO: Got endpoints: latency-svc-fnk5x [750.718865ms]
Dec  3 15:01:47.093: INFO: Created: latency-svc-srw9s
Dec  3 15:01:47.127: INFO: Got endpoints: latency-svc-srdbd [747.852976ms]
Dec  3 15:01:47.143: INFO: Created: latency-svc-qtwxr
Dec  3 15:01:47.177: INFO: Got endpoints: latency-svc-2ktdk [747.784903ms]
Dec  3 15:01:47.193: INFO: Created: latency-svc-wqftr
Dec  3 15:01:47.230: INFO: Got endpoints: latency-svc-7tmds [753.301873ms]
Dec  3 15:01:47.247: INFO: Created: latency-svc-7x8nh
Dec  3 15:01:47.277: INFO: Got endpoints: latency-svc-88k95 [749.568295ms]
Dec  3 15:01:47.293: INFO: Created: latency-svc-kfxhf
Dec  3 15:01:47.327: INFO: Got endpoints: latency-svc-bq8g8 [749.710235ms]
Dec  3 15:01:47.344: INFO: Created: latency-svc-mjw2n
Dec  3 15:01:47.377: INFO: Got endpoints: latency-svc-znctr [750.069097ms]
Dec  3 15:01:47.395: INFO: Created: latency-svc-hfnmg
Dec  3 15:01:47.427: INFO: Got endpoints: latency-svc-mmn85 [750.230454ms]
Dec  3 15:01:47.443: INFO: Created: latency-svc-b5zdb
Dec  3 15:01:47.477: INFO: Got endpoints: latency-svc-rbknh [749.65778ms]
Dec  3 15:01:47.494: INFO: Created: latency-svc-t4g8n
Dec  3 15:01:47.527: INFO: Got endpoints: latency-svc-x9c2l [750.031334ms]
Dec  3 15:01:47.543: INFO: Created: latency-svc-9bzbn
Dec  3 15:01:47.582: INFO: Got endpoints: latency-svc-kl6kj [754.727913ms]
Dec  3 15:01:47.599: INFO: Created: latency-svc-6zfmv
Dec  3 15:01:47.627: INFO: Got endpoints: latency-svc-qkn92 [749.772801ms]
Dec  3 15:01:47.643: INFO: Created: latency-svc-7kjkh
Dec  3 15:01:47.677: INFO: Got endpoints: latency-svc-tnpk4 [749.579248ms]
Dec  3 15:01:47.693: INFO: Created: latency-svc-xbf9t
Dec  3 15:01:47.727: INFO: Got endpoints: latency-svc-dkxbd [750.161145ms]
Dec  3 15:01:47.744: INFO: Created: latency-svc-8tjnj
Dec  3 15:01:47.777: INFO: Got endpoints: latency-svc-m7sft [749.743622ms]
Dec  3 15:01:47.798: INFO: Created: latency-svc-745xn
Dec  3 15:01:47.827: INFO: Got endpoints: latency-svc-srw9s [748.911685ms]
Dec  3 15:01:47.843: INFO: Created: latency-svc-6jnc2
Dec  3 15:01:47.877: INFO: Got endpoints: latency-svc-qtwxr [749.505847ms]
Dec  3 15:01:47.899: INFO: Created: latency-svc-n6tj2
Dec  3 15:01:47.927: INFO: Got endpoints: latency-svc-wqftr [749.92026ms]
Dec  3 15:01:47.944: INFO: Created: latency-svc-5dj2n
Dec  3 15:01:47.977: INFO: Got endpoints: latency-svc-7x8nh [746.917368ms]
Dec  3 15:01:47.993: INFO: Created: latency-svc-zlw6b
Dec  3 15:01:48.028: INFO: Got endpoints: latency-svc-kfxhf [750.711811ms]
Dec  3 15:01:48.044: INFO: Created: latency-svc-87b76
Dec  3 15:01:48.077: INFO: Got endpoints: latency-svc-mjw2n [749.876473ms]
Dec  3 15:01:48.107: INFO: Created: latency-svc-h85bz
Dec  3 15:01:48.127: INFO: Got endpoints: latency-svc-hfnmg [749.646242ms]
Dec  3 15:01:48.143: INFO: Created: latency-svc-5dgqq
Dec  3 15:01:48.177: INFO: Got endpoints: latency-svc-b5zdb [749.641199ms]
Dec  3 15:01:48.193: INFO: Created: latency-svc-8tbq4
Dec  3 15:01:48.227: INFO: Got endpoints: latency-svc-t4g8n [750.075648ms]
Dec  3 15:01:48.243: INFO: Created: latency-svc-4w7qc
Dec  3 15:01:48.277: INFO: Got endpoints: latency-svc-9bzbn [750.01729ms]
Dec  3 15:01:48.293: INFO: Created: latency-svc-kqb8k
Dec  3 15:01:48.327: INFO: Got endpoints: latency-svc-6zfmv [745.198483ms]
Dec  3 15:01:48.344: INFO: Created: latency-svc-gxkcj
Dec  3 15:01:48.377: INFO: Got endpoints: latency-svc-7kjkh [749.915253ms]
Dec  3 15:01:48.392: INFO: Created: latency-svc-jzlcl
Dec  3 15:01:48.427: INFO: Got endpoints: latency-svc-xbf9t [750.172765ms]
Dec  3 15:01:48.443: INFO: Created: latency-svc-xjhb2
Dec  3 15:01:48.477: INFO: Got endpoints: latency-svc-8tjnj [749.910957ms]
Dec  3 15:01:48.494: INFO: Created: latency-svc-zjgb2
Dec  3 15:01:48.527: INFO: Got endpoints: latency-svc-745xn [749.940183ms]
Dec  3 15:01:48.542: INFO: Created: latency-svc-4scbl
Dec  3 15:01:48.577: INFO: Got endpoints: latency-svc-6jnc2 [750.310848ms]
Dec  3 15:01:48.593: INFO: Created: latency-svc-85lwq
Dec  3 15:01:48.631: INFO: Got endpoints: latency-svc-n6tj2 [754.120035ms]
Dec  3 15:01:48.647: INFO: Created: latency-svc-2grjc
Dec  3 15:01:48.677: INFO: Got endpoints: latency-svc-5dj2n [749.73894ms]
Dec  3 15:01:48.693: INFO: Created: latency-svc-8h5wv
Dec  3 15:01:48.727: INFO: Got endpoints: latency-svc-zlw6b [749.748131ms]
Dec  3 15:01:48.744: INFO: Created: latency-svc-cczbq
Dec  3 15:01:48.777: INFO: Got endpoints: latency-svc-87b76 [749.091946ms]
Dec  3 15:01:48.793: INFO: Created: latency-svc-h6z5l
Dec  3 15:01:48.827: INFO: Got endpoints: latency-svc-h85bz [750.062988ms]
Dec  3 15:01:48.845: INFO: Created: latency-svc-wdngv
Dec  3 15:01:48.877: INFO: Got endpoints: latency-svc-5dgqq [749.854759ms]
Dec  3 15:01:48.893: INFO: Created: latency-svc-tgqpc
Dec  3 15:01:48.927: INFO: Got endpoints: latency-svc-8tbq4 [749.789735ms]
Dec  3 15:01:48.945: INFO: Created: latency-svc-jnn7x
Dec  3 15:01:48.977: INFO: Got endpoints: latency-svc-4w7qc [749.605235ms]
Dec  3 15:01:48.992: INFO: Created: latency-svc-f4n2h
Dec  3 15:01:49.027: INFO: Got endpoints: latency-svc-kqb8k [749.766474ms]
Dec  3 15:01:49.043: INFO: Created: latency-svc-xsjtb
Dec  3 15:01:49.077: INFO: Got endpoints: latency-svc-gxkcj [749.57739ms]
Dec  3 15:01:49.092: INFO: Created: latency-svc-rflzp
Dec  3 15:01:49.127: INFO: Got endpoints: latency-svc-jzlcl [750.014696ms]
Dec  3 15:01:49.143: INFO: Created: latency-svc-qn5bk
Dec  3 15:01:49.177: INFO: Got endpoints: latency-svc-xjhb2 [749.53956ms]
Dec  3 15:01:49.192: INFO: Created: latency-svc-tspk7
Dec  3 15:01:49.227: INFO: Got endpoints: latency-svc-zjgb2 [749.465407ms]
Dec  3 15:01:49.242: INFO: Created: latency-svc-d2mr5
Dec  3 15:01:49.277: INFO: Got endpoints: latency-svc-4scbl [749.964557ms]
Dec  3 15:01:49.294: INFO: Created: latency-svc-n7rzm
Dec  3 15:01:49.327: INFO: Got endpoints: latency-svc-85lwq [749.757035ms]
Dec  3 15:01:49.343: INFO: Created: latency-svc-59qqc
Dec  3 15:01:49.377: INFO: Got endpoints: latency-svc-2grjc [746.36452ms]
Dec  3 15:01:49.392: INFO: Created: latency-svc-96rr8
Dec  3 15:01:49.427: INFO: Got endpoints: latency-svc-8h5wv [750.112135ms]
Dec  3 15:01:49.443: INFO: Created: latency-svc-sqjc4
Dec  3 15:01:49.477: INFO: Got endpoints: latency-svc-cczbq [750.094135ms]
Dec  3 15:01:49.492: INFO: Created: latency-svc-q6p9w
Dec  3 15:01:49.527: INFO: Got endpoints: latency-svc-h6z5l [749.981842ms]
Dec  3 15:01:49.542: INFO: Created: latency-svc-96948
Dec  3 15:01:49.577: INFO: Got endpoints: latency-svc-wdngv [749.983557ms]
Dec  3 15:01:49.592: INFO: Created: latency-svc-5dq27
Dec  3 15:01:49.626: INFO: Got endpoints: latency-svc-tgqpc [749.46697ms]
Dec  3 15:01:49.643: INFO: Created: latency-svc-q8x5r
Dec  3 15:01:49.677: INFO: Got endpoints: latency-svc-jnn7x [750.181864ms]
Dec  3 15:01:49.694: INFO: Created: latency-svc-kh64s
Dec  3 15:01:49.727: INFO: Got endpoints: latency-svc-f4n2h [750.097599ms]
Dec  3 15:01:49.743: INFO: Created: latency-svc-x9p2z
Dec  3 15:01:49.777: INFO: Got endpoints: latency-svc-xsjtb [749.552336ms]
Dec  3 15:01:49.792: INFO: Created: latency-svc-jm8sf
Dec  3 15:01:49.827: INFO: Got endpoints: latency-svc-rflzp [749.883856ms]
Dec  3 15:01:49.843: INFO: Created: latency-svc-jffgn
Dec  3 15:01:49.877: INFO: Got endpoints: latency-svc-qn5bk [750.372617ms]
Dec  3 15:01:49.927: INFO: Got endpoints: latency-svc-tspk7 [749.986642ms]
Dec  3 15:01:49.977: INFO: Got endpoints: latency-svc-d2mr5 [750.231215ms]
Dec  3 15:01:50.027: INFO: Got endpoints: latency-svc-n7rzm [749.781129ms]
Dec  3 15:01:50.077: INFO: Got endpoints: latency-svc-59qqc [750.008546ms]
Dec  3 15:01:50.127: INFO: Got endpoints: latency-svc-96rr8 [749.779148ms]
Dec  3 15:01:50.178: INFO: Got endpoints: latency-svc-sqjc4 [750.478102ms]
Dec  3 15:01:50.227: INFO: Got endpoints: latency-svc-q6p9w [749.84934ms]
Dec  3 15:01:50.277: INFO: Got endpoints: latency-svc-96948 [750.0043ms]
Dec  3 15:01:50.327: INFO: Got endpoints: latency-svc-5dq27 [749.834325ms]
Dec  3 15:01:50.377: INFO: Got endpoints: latency-svc-q8x5r [750.68035ms]
Dec  3 15:01:50.427: INFO: Got endpoints: latency-svc-kh64s [749.958948ms]
Dec  3 15:01:50.477: INFO: Got endpoints: latency-svc-x9p2z [749.958309ms]
Dec  3 15:01:50.528: INFO: Got endpoints: latency-svc-jm8sf [750.962355ms]
Dec  3 15:01:50.578: INFO: Got endpoints: latency-svc-jffgn [750.484243ms]
Dec  3 15:01:50.578: INFO: Latencies: [21.000256ms 26.319219ms 30.551996ms 32.931745ms 41.551553ms 47.079213ms 48.727384ms 56.330823ms 60.866177ms 63.096498ms 70.764003ms 71.540768ms 72.188347ms 74.931076ms 79.968799ms 80.47297ms 80.601818ms 81.124676ms 81.457745ms 84.304194ms 84.494897ms 84.669084ms 85.211601ms 85.70804ms 86.666108ms 86.824802ms 86.843395ms 87.553665ms 87.577845ms 89.241471ms 89.677998ms 92.41956ms 104.339113ms 126.112441ms 223.48777ms 229.894877ms 263.085811ms 308.553386ms 353.776037ms 399.275388ms 444.114695ms 488.990271ms 533.845438ms 579.039725ms 624.333973ms 669.805233ms 694.191677ms 714.508468ms 739.59429ms 741.967671ms 744.562885ms 745.198483ms 746.36452ms 746.917368ms 747.784903ms 747.852976ms 748.911685ms 749.091946ms 749.149475ms 749.197353ms 749.280792ms 749.293898ms 749.313562ms 749.313724ms 749.330592ms 749.387969ms 749.396156ms 749.445068ms 749.465407ms 749.46697ms 749.480523ms 749.488077ms 749.505847ms 749.53956ms 749.552336ms 749.568295ms 749.57739ms 749.579248ms 749.585591ms 749.590129ms 749.599303ms 749.605235ms 749.641199ms 749.646242ms 749.653091ms 749.65778ms 749.668966ms 749.681512ms 749.68396ms 749.694036ms 749.710235ms 749.713052ms 749.71689ms 749.717507ms 749.73894ms 749.743622ms 749.748131ms 749.7555ms 749.757035ms 749.766321ms 749.766474ms 749.772801ms 749.779148ms 749.781129ms 749.789735ms 749.79463ms 749.796996ms 749.801193ms 749.809191ms 749.817913ms 749.819753ms 749.827011ms 749.828363ms 749.834325ms 749.84934ms 749.85187ms 749.854759ms 749.859281ms 749.868296ms 749.873296ms 749.876473ms 749.883856ms 749.886118ms 749.890732ms 749.891855ms 749.891993ms 749.910957ms 749.915253ms 749.92026ms 749.940183ms 749.958309ms 749.958806ms 749.958948ms 749.962274ms 749.964557ms 749.981842ms 749.981874ms 749.983557ms 749.986642ms 749.99211ms 749.996621ms 750.0043ms 750.005452ms 750.008546ms 750.014696ms 750.01729ms 750.028134ms 750.031334ms 750.044613ms 750.062988ms 750.069097ms 750.075648ms 750.090853ms 750.092822ms 750.094135ms 750.097599ms 750.10878ms 750.112135ms 750.131744ms 750.149035ms 750.161145ms 750.165982ms 750.166224ms 750.167077ms 750.172765ms 750.17401ms 750.177332ms 750.181864ms 750.224601ms 750.230454ms 750.231215ms 750.234091ms 750.283834ms 750.285109ms 750.288142ms 750.310848ms 750.343343ms 750.34961ms 750.372617ms 750.37616ms 750.442262ms 750.47275ms 750.478102ms 750.480474ms 750.484243ms 750.496814ms 750.549372ms 750.608051ms 750.68035ms 750.711811ms 750.718865ms 750.815929ms 750.962355ms 750.994664ms 751.569886ms 751.643281ms 753.301873ms 754.120035ms 754.727913ms 755.438253ms]
Dec  3 15:01:50.578: INFO: 50 %ile: 749.766474ms
Dec  3 15:01:50.578: INFO: 90 %ile: 750.442262ms
Dec  3 15:01:50.578: INFO: 99 %ile: 754.727913ms
Dec  3 15:01:50.578: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:01:50.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-769" for this suite.
Dec  3 15:02:06.623: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:02:07.023: INFO: namespace svc-latency-769 deletion completed in 16.433605543s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:02:07.024: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9377
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec  3 15:02:07.340: INFO: Waiting up to 5m0s for pod "pod-312b179d-7b5b-4589-a2f5-9e75af229abb" in namespace "emptydir-9377" to be "success or failure"
Dec  3 15:02:07.350: INFO: Pod "pod-312b179d-7b5b-4589-a2f5-9e75af229abb": Phase="Pending", Reason="", readiness=false. Elapsed: 9.919944ms
Dec  3 15:02:09.361: INFO: Pod "pod-312b179d-7b5b-4589-a2f5-9e75af229abb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021088565s
STEP: Saw pod success
Dec  3 15:02:09.361: INFO: Pod "pod-312b179d-7b5b-4589-a2f5-9e75af229abb" satisfied condition "success or failure"
Dec  3 15:02:09.372: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod pod-312b179d-7b5b-4589-a2f5-9e75af229abb container test-container: <nil>
STEP: delete the pod
Dec  3 15:02:09.409: INFO: Waiting for pod pod-312b179d-7b5b-4589-a2f5-9e75af229abb to disappear
Dec  3 15:02:09.419: INFO: Pod pod-312b179d-7b5b-4589-a2f5-9e75af229abb no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:02:09.419: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9377" for this suite.
Dec  3 15:02:15.472: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:02:15.918: INFO: namespace emptydir-9377 deletion completed in 6.47930458s
•SSSSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:02:15.918: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3791
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name secret-emptykey-test-c8fc1068-35e9-479b-a9ef-f2bba5acb36e
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:02:16.116: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3791" for this suite.
Dec  3 15:02:22.160: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:02:22.589: INFO: namespace secrets-3791 deletion completed in 6.462119526s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:02:22.590: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-1370
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec  3 15:02:25.848: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:02:25.874: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1370" for this suite.
Dec  3 15:02:31.928: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:02:32.331: INFO: namespace container-runtime-1370 deletion completed in 6.437416728s
•S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:02:32.332: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1270
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1557
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  3 15:02:32.517: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/apps.v1 --namespace=kubectl-1270'
Dec  3 15:02:32.643: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec  3 15:02:32.643: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1562
Dec  3 15:02:34.664: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete deployment e2e-test-nginx-deployment --namespace=kubectl-1270'
Dec  3 15:02:34.785: INFO: stderr: ""
Dec  3 15:02:34.785: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:02:34.785: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1270" for this suite.
Dec  3 15:02:56.837: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:02:57.228: INFO: namespace kubectl-1270 deletion completed in 22.423247291s
•SSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:02:57.228: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-2224
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Dec  3 15:03:03.515: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  3 15:03:03.526: INFO: Pod pod-with-prestop-http-hook still exists
Dec  3 15:03:05.526: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  3 15:03:05.537: INFO: Pod pod-with-prestop-http-hook still exists
Dec  3 15:03:07.526: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  3 15:03:07.538: INFO: Pod pod-with-prestop-http-hook still exists
Dec  3 15:03:09.526: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  3 15:03:09.537: INFO: Pod pod-with-prestop-http-hook still exists
Dec  3 15:03:11.526: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  3 15:03:11.538: INFO: Pod pod-with-prestop-http-hook still exists
Dec  3 15:03:13.526: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  3 15:03:13.537: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:03:13.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-2224" for this suite.
Dec  3 15:03:35.607: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:03:36.011: INFO: namespace container-lifecycle-hook-2224 deletion completed in 22.436119127s
•SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:03:36.011: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-626
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec  3 15:03:36.211: INFO: Waiting up to 5m0s for pod "pod-474fb4ef-5a65-4765-8465-bb878590f6f6" in namespace "emptydir-626" to be "success or failure"
Dec  3 15:03:36.222: INFO: Pod "pod-474fb4ef-5a65-4765-8465-bb878590f6f6": Phase="Pending", Reason="", readiness=false. Elapsed: 11.173852ms
Dec  3 15:03:38.233: INFO: Pod "pod-474fb4ef-5a65-4765-8465-bb878590f6f6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021962009s
Dec  3 15:03:40.244: INFO: Pod "pod-474fb4ef-5a65-4765-8465-bb878590f6f6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033276308s
STEP: Saw pod success
Dec  3 15:03:40.244: INFO: Pod "pod-474fb4ef-5a65-4765-8465-bb878590f6f6" satisfied condition "success or failure"
Dec  3 15:03:40.255: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod pod-474fb4ef-5a65-4765-8465-bb878590f6f6 container test-container: <nil>
STEP: delete the pod
Dec  3 15:03:40.288: INFO: Waiting for pod pod-474fb4ef-5a65-4765-8465-bb878590f6f6 to disappear
Dec  3 15:03:40.300: INFO: Pod pod-474fb4ef-5a65-4765-8465-bb878590f6f6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:03:40.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-626" for this suite.
Dec  3 15:03:46.352: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:03:46.752: INFO: namespace emptydir-626 deletion completed in 6.43251682s
•SSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:03:46.752: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-9295
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-8fb0d7df-586e-4e03-8dab-4546959d0b15
STEP: Creating a pod to test consume secrets
Dec  3 15:03:46.961: INFO: Waiting up to 5m0s for pod "pod-secrets-e06f321f-a275-4f9a-86c7-4e15f4ea3e04" in namespace "secrets-9295" to be "success or failure"
Dec  3 15:03:46.971: INFO: Pod "pod-secrets-e06f321f-a275-4f9a-86c7-4e15f4ea3e04": Phase="Pending", Reason="", readiness=false. Elapsed: 9.98852ms
Dec  3 15:03:48.983: INFO: Pod "pod-secrets-e06f321f-a275-4f9a-86c7-4e15f4ea3e04": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021846427s
STEP: Saw pod success
Dec  3 15:03:48.983: INFO: Pod "pod-secrets-e06f321f-a275-4f9a-86c7-4e15f4ea3e04" satisfied condition "success or failure"
Dec  3 15:03:48.994: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod pod-secrets-e06f321f-a275-4f9a-86c7-4e15f4ea3e04 container secret-volume-test: <nil>
STEP: delete the pod
Dec  3 15:03:49.027: INFO: Waiting for pod pod-secrets-e06f321f-a275-4f9a-86c7-4e15f4ea3e04 to disappear
Dec  3 15:03:49.038: INFO: Pod pod-secrets-e06f321f-a275-4f9a-86c7-4e15f4ea3e04 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:03:49.038: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9295" for this suite.
Dec  3 15:03:55.090: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:03:55.494: INFO: namespace secrets-9295 deletion completed in 6.436535197s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:03:55.494: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-188
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-f701b883-8949-4f97-9039-c1e2a7206be1
STEP: Creating a pod to test consume configMaps
Dec  3 15:03:55.719: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-9a5eb6fa-d7e8-4939-ac26-542150f1bac7" in namespace "projected-188" to be "success or failure"
Dec  3 15:03:55.730: INFO: Pod "pod-projected-configmaps-9a5eb6fa-d7e8-4939-ac26-542150f1bac7": Phase="Pending", Reason="", readiness=false. Elapsed: 10.403214ms
Dec  3 15:03:57.741: INFO: Pod "pod-projected-configmaps-9a5eb6fa-d7e8-4939-ac26-542150f1bac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02172892s
STEP: Saw pod success
Dec  3 15:03:57.741: INFO: Pod "pod-projected-configmaps-9a5eb6fa-d7e8-4939-ac26-542150f1bac7" satisfied condition "success or failure"
Dec  3 15:03:57.752: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod pod-projected-configmaps-9a5eb6fa-d7e8-4939-ac26-542150f1bac7 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 15:03:57.789: INFO: Waiting for pod pod-projected-configmaps-9a5eb6fa-d7e8-4939-ac26-542150f1bac7 to disappear
Dec  3 15:03:57.799: INFO: Pod pod-projected-configmaps-9a5eb6fa-d7e8-4939-ac26-542150f1bac7 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:03:57.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-188" for this suite.
Dec  3 15:04:03.849: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:04:04.281: INFO: namespace projected-188 deletion completed in 6.463790023s
•SSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:04:04.282: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-9701
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:04:08.501: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9701" for this suite.
Dec  3 15:04:14.553: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:04:14.953: INFO: namespace kubelet-test-9701 deletion completed in 6.43285605s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:04:14.953: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-9175
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-6657
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-3223
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:04:39.565: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-9175" for this suite.
Dec  3 15:04:45.619: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:04:46.019: INFO: namespace namespaces-9175 deletion completed in 6.434308194s
STEP: Destroying namespace "nsdeletetest-6657" for this suite.
Dec  3 15:04:46.029: INFO: Namespace nsdeletetest-6657 was already deleted
STEP: Destroying namespace "nsdeletetest-3223" for this suite.
Dec  3 15:04:52.063: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:04:52.477: INFO: namespace nsdeletetest-3223 deletion completed in 6.447842744s
•SSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:04:52.477: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1134
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap configmap-1134/configmap-test-c86bcba6-4e8c-4c13-b6dd-f12bc5bbd66d
STEP: Creating a pod to test consume configMaps
Dec  3 15:04:52.688: INFO: Waiting up to 5m0s for pod "pod-configmaps-7390deac-d5ba-488b-ba60-c8219521d327" in namespace "configmap-1134" to be "success or failure"
Dec  3 15:04:52.698: INFO: Pod "pod-configmaps-7390deac-d5ba-488b-ba60-c8219521d327": Phase="Pending", Reason="", readiness=false. Elapsed: 10.121363ms
Dec  3 15:04:54.710: INFO: Pod "pod-configmaps-7390deac-d5ba-488b-ba60-c8219521d327": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021425001s
STEP: Saw pod success
Dec  3 15:04:54.710: INFO: Pod "pod-configmaps-7390deac-d5ba-488b-ba60-c8219521d327" satisfied condition "success or failure"
Dec  3 15:04:54.721: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod pod-configmaps-7390deac-d5ba-488b-ba60-c8219521d327 container env-test: <nil>
STEP: delete the pod
Dec  3 15:04:54.757: INFO: Waiting for pod pod-configmaps-7390deac-d5ba-488b-ba60-c8219521d327 to disappear
Dec  3 15:04:54.768: INFO: Pod pod-configmaps-7390deac-d5ba-488b-ba60-c8219521d327 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:04:54.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1134" for this suite.
Dec  3 15:05:00.820: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:05:01.254: INFO: namespace configmap-1134 deletion completed in 6.466988381s
•SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:05:01.254: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9053
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the initial replication controller
Dec  3 15:05:01.440: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-9053'
Dec  3 15:05:01.727: INFO: stderr: ""
Dec  3 15:05:01.727: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  3 15:05:01.727: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9053'
Dec  3 15:05:01.837: INFO: stderr: ""
Dec  3 15:05:01.837: INFO: stdout: "update-demo-nautilus-56ttq update-demo-nautilus-qnhpj "
Dec  3 15:05:01.837: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-56ttq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9053'
Dec  3 15:05:01.975: INFO: stderr: ""
Dec  3 15:05:01.975: INFO: stdout: ""
Dec  3 15:05:01.975: INFO: update-demo-nautilus-56ttq is created but not running
Dec  3 15:05:06.975: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9053'
Dec  3 15:05:07.084: INFO: stderr: ""
Dec  3 15:05:07.085: INFO: stdout: "update-demo-nautilus-56ttq update-demo-nautilus-qnhpj "
Dec  3 15:05:07.085: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-56ttq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9053'
Dec  3 15:05:07.189: INFO: stderr: ""
Dec  3 15:05:07.189: INFO: stdout: "true"
Dec  3 15:05:07.189: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-56ttq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9053'
Dec  3 15:05:07.297: INFO: stderr: ""
Dec  3 15:05:07.297: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  3 15:05:07.297: INFO: validating pod update-demo-nautilus-56ttq
Dec  3 15:05:07.394: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 15:05:07.394: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 15:05:07.394: INFO: update-demo-nautilus-56ttq is verified up and running
Dec  3 15:05:07.394: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-qnhpj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9053'
Dec  3 15:05:07.504: INFO: stderr: ""
Dec  3 15:05:07.504: INFO: stdout: "true"
Dec  3 15:05:07.504: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-qnhpj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9053'
Dec  3 15:05:07.608: INFO: stderr: ""
Dec  3 15:05:07.608: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  3 15:05:07.608: INFO: validating pod update-demo-nautilus-qnhpj
Dec  3 15:05:07.704: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 15:05:07.704: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 15:05:07.704: INFO: update-demo-nautilus-qnhpj is verified up and running
STEP: rolling-update to new replication controller
Dec  3 15:05:07.707: INFO: scanned /root for discovery docs: <nil>
Dec  3 15:05:07.707: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-9053'
Dec  3 15:05:26.374: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Dec  3 15:05:26.374: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  3 15:05:26.374: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9053'
Dec  3 15:05:26.490: INFO: stderr: ""
Dec  3 15:05:26.490: INFO: stdout: "update-demo-kitten-mzdp7 update-demo-kitten-wzl6h update-demo-nautilus-qnhpj "
STEP: Replicas for name=update-demo: expected=2 actual=3
Dec  3 15:05:31.491: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9053'
Dec  3 15:05:31.606: INFO: stderr: ""
Dec  3 15:05:31.606: INFO: stdout: "update-demo-kitten-mzdp7 update-demo-kitten-wzl6h "
Dec  3 15:05:31.606: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-kitten-mzdp7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9053'
Dec  3 15:05:31.715: INFO: stderr: ""
Dec  3 15:05:31.715: INFO: stdout: "true"
Dec  3 15:05:31.715: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-kitten-mzdp7 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9053'
Dec  3 15:05:31.822: INFO: stderr: ""
Dec  3 15:05:31.822: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Dec  3 15:05:31.822: INFO: validating pod update-demo-kitten-mzdp7
Dec  3 15:05:31.918: INFO: got data: {
  "image": "kitten.jpg"
}

Dec  3 15:05:31.918: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Dec  3 15:05:31.918: INFO: update-demo-kitten-mzdp7 is verified up and running
Dec  3 15:05:31.919: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-kitten-wzl6h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9053'
Dec  3 15:05:32.024: INFO: stderr: ""
Dec  3 15:05:32.024: INFO: stdout: "true"
Dec  3 15:05:32.024: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-kitten-wzl6h -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9053'
Dec  3 15:05:32.131: INFO: stderr: ""
Dec  3 15:05:32.131: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Dec  3 15:05:32.131: INFO: validating pod update-demo-kitten-wzl6h
Dec  3 15:05:32.228: INFO: got data: {
  "image": "kitten.jpg"
}

Dec  3 15:05:32.228: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Dec  3 15:05:32.228: INFO: update-demo-kitten-wzl6h is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:05:32.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9053" for this suite.
Dec  3 15:05:54.285: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:05:54.692: INFO: namespace kubectl-9053 deletion completed in 22.444942099s
•S
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:05:54.692: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-2950
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec  3 15:05:54.881: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Dec  3 15:05:54.904: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec  3 15:05:58.925: INFO: Creating deployment "test-rolling-update-deployment"
Dec  3 15:05:58.937: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Dec  3 15:05:58.960: INFO: deployment "test-rolling-update-deployment" doesn't have the required revision set
Dec  3 15:06:00.983: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Dec  3 15:06:00.995: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Dec  3 15:06:01.028: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-2950,SelfLink:/apis/apps/v1/namespaces/deployment-2950/deployments/test-rolling-update-deployment,UID:8df11a9c-73c7-45af-8c25-2235c89600fa,ResourceVersion:10095,Generation:1,CreationTimestamp:2019-12-03 15:05:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-12-03 15:05:58 +0000 UTC 2019-12-03 15:05:58 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-12-03 15:06:00 +0000 UTC 2019-12-03 15:05:58 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-79f6b9d75c" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Dec  3 15:06:01.040: INFO: New ReplicaSet "test-rolling-update-deployment-79f6b9d75c" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79f6b9d75c,GenerateName:,Namespace:deployment-2950,SelfLink:/apis/apps/v1/namespaces/deployment-2950/replicasets/test-rolling-update-deployment-79f6b9d75c,UID:2b7ed6a4-9d0f-4455-9e2b-a199e6508fae,ResourceVersion:10088,Generation:1,CreationTimestamp:2019-12-03 15:05:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 8df11a9c-73c7-45af-8c25-2235c89600fa 0xc002d74667 0xc002d74668}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Dec  3 15:06:01.040: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Dec  3 15:06:01.040: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-2950,SelfLink:/apis/apps/v1/namespaces/deployment-2950/replicasets/test-rolling-update-controller,UID:af8d42e5-5de0-40af-af73-452c7fa9153a,ResourceVersion:10094,Generation:2,CreationTimestamp:2019-12-03 15:05:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment 8df11a9c-73c7-45af-8c25-2235c89600fa 0xc002d74597 0xc002d74598}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  3 15:06:01.051: INFO: Pod "test-rolling-update-deployment-79f6b9d75c-2vbwl" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79f6b9d75c-2vbwl,GenerateName:test-rolling-update-deployment-79f6b9d75c-,Namespace:deployment-2950,SelfLink:/api/v1/namespaces/deployment-2950/pods/test-rolling-update-deployment-79f6b9d75c-2vbwl,UID:96856f69-5c95-4252-b23c-7600228ba84b,ResourceVersion:10087,Generation:0,CreationTimestamp:2019-12-03 15:05:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.64.1.116/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-79f6b9d75c 2b7ed6a4-9d0f-4455-9e2b-a199e6508fae 0xc002d74f47 0xc002d74f48}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-ntg2p {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ntg2p,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-ntg2p true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002d74fb0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002d74fd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 15:05:58 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 15:05:59 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 15:05:59 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 15:05:58 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.3,PodIP:100.64.1.116,StartTime:2019-12-03 15:05:58 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-12-03 15:05:59 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://5522d7d5b44c9721cb526afab0196f7d162bde0a35969ff0f8b7017c0fdd3bbb}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:06:01.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2950" for this suite.
Dec  3 15:06:07.105: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:06:07.500: INFO: namespace deployment-2950 deletion completed in 6.42830903s
•SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:06:07.500: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-500
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec  3 15:06:07.685: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-500'
Dec  3 15:06:07.963: INFO: stderr: ""
Dec  3 15:06:07.963: INFO: stdout: "replicationcontroller/redis-master created\n"
Dec  3 15:06:07.963: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-500'
Dec  3 15:06:08.179: INFO: stderr: ""
Dec  3 15:06:08.179: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec  3 15:06:09.190: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 15:06:09.190: INFO: Found 1 / 1
Dec  3 15:06:09.190: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec  3 15:06:09.201: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 15:06:09.201: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec  3 15:06:09.201: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config describe pod redis-master-n8b75 --namespace=kubectl-500'
Dec  3 15:06:09.344: INFO: stderr: ""
Dec  3 15:06:09.344: INFO: stdout: "Name:           redis-master-n8b75\nNamespace:      kubectl-500\nPriority:       0\nNode:           shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9/10.250.0.3\nStart Time:     Tue, 03 Dec 2019 15:06:07 +0000\nLabels:         app=redis\n                role=master\nAnnotations:    cni.projectcalico.org/podIP: 100.64.1.117/32\n                kubernetes.io/psp: e2e-test-privileged-psp\nStatus:         Running\nIP:             100.64.1.117\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://cd805397fecd85d0ea59f9e1f815740fdc9b93c482ca30f6c966972cfdea7063\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 03 Dec 2019 15:06:08 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-lvv8v (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-lvv8v:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-lvv8v\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                                        Message\n  ----    ------     ----  ----                                                        -------\n  Normal  Scheduled  2s    default-scheduler                                           Successfully assigned kubectl-500/redis-master-n8b75 to shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9\n  Normal  Pulled     1s    kubelet, shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    1s    kubelet, shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9  Created container redis-master\n  Normal  Started    1s    kubelet, shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9  Started container redis-master\n"
Dec  3 15:06:09.344: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config describe rc redis-master --namespace=kubectl-500'
Dec  3 15:06:09.497: INFO: stderr: ""
Dec  3 15:06:09.497: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-500\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: redis-master-n8b75\n"
Dec  3 15:06:09.497: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config describe service redis-master --namespace=kubectl-500'
Dec  3 15:06:09.636: INFO: stderr: ""
Dec  3 15:06:09.636: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-500\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                100.111.20.185\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         100.64.1.117:6379\nSession Affinity:  None\nEvents:            <none>\n"
Dec  3 15:06:09.655: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config describe node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9'
Dec  3 15:06:09.827: INFO: stderr: ""
Dec  3 15:06:09.827: INFO: stdout: "Name:               shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=n1-standard-2\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=europe-west1\n                    failure-domain.beta.kubernetes.io/zone=europe-west1-b\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9\n                    kubernetes.io/os=linux\n                    node.kubernetes.io/role=node\n                    worker.garden.sapcloud.io/group=worker-1\n                    worker.gardener.cloud/pool=worker-1\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 10.250.0.3/32\n                    projectcalico.org/IPv4IPIPTunnelAddr: 100.64.1.1\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Tue, 03 Dec 2019 14:26:23 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type                          Status  LastHeartbeatTime                 LastTransitionTime                Reason                          Message\n  ----                          ------  -----------------                 ------------------                ------                          -------\n  ReadonlyFilesystem            False   Tue, 03 Dec 2019 15:05:32 +0000   Tue, 03 Dec 2019 14:27:10 +0000   FilesystemIsNotReadOnly         Filesystem is not read-only\n  FrequentUnregisterNetDevice   False   Tue, 03 Dec 2019 15:05:32 +0000   Tue, 03 Dec 2019 14:27:10 +0000   NoFrequentUnregisterNetDevice   node is functioning properly\n  CorruptDockerOverlay2         False   Tue, 03 Dec 2019 15:05:32 +0000   Tue, 03 Dec 2019 14:27:11 +0000   NoCorruptDockerOverlay2         docker overlay2 is functioning properly\n  FrequentKubeletRestart        False   Tue, 03 Dec 2019 15:05:32 +0000   Tue, 03 Dec 2019 14:27:10 +0000   NoFrequentKubeletRestart        kubelet is functioning properly\n  FrequentDockerRestart         False   Tue, 03 Dec 2019 15:05:32 +0000   Tue, 03 Dec 2019 14:27:10 +0000   NoFrequentDockerRestart         docker is functioning properly\n  FrequentContainerdRestart     False   Tue, 03 Dec 2019 15:05:32 +0000   Tue, 03 Dec 2019 14:27:10 +0000   NoFrequentContainerdRestart     containerd is functioning properly\n  KernelDeadlock                False   Tue, 03 Dec 2019 15:05:32 +0000   Tue, 03 Dec 2019 14:27:10 +0000   KernelHasNoDeadlock             kernel has no deadlock\n  NetworkUnavailable            False   Tue, 03 Dec 2019 14:26:44 +0000   Tue, 03 Dec 2019 14:26:44 +0000   CalicoIsUp                      Calico is running on this node\n  MemoryPressure                False   Tue, 03 Dec 2019 15:06:07 +0000   Tue, 03 Dec 2019 14:26:23 +0000   KubeletHasSufficientMemory      kubelet has sufficient memory available\n  DiskPressure                  False   Tue, 03 Dec 2019 15:06:07 +0000   Tue, 03 Dec 2019 14:26:23 +0000   KubeletHasNoDiskPressure        kubelet has no disk pressure\n  PIDPressure                   False   Tue, 03 Dec 2019 15:06:07 +0000   Tue, 03 Dec 2019 14:26:23 +0000   KubeletHasSufficientPID         kubelet has sufficient PID available\n  Ready                         True    Tue, 03 Dec 2019 15:06:07 +0000   Tue, 03 Dec 2019 14:26:43 +0000   KubeletReady                    kubelet is posting ready status\nAddresses:\n  InternalIP:   10.250.0.3\n  ExternalIP:   \n  InternalDNS:  shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9.c.sap-gcp-k8s-canary-custom.internal\n  Hostname:     shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9.c.sap-gcp-k8s-canary-custom.internal\nCapacity:\n attachable-volumes-gce-pd:  127\n cpu:                        2\n ephemeral-storage:          28056816Ki\n hugepages-1Gi:              0\n hugepages-2Mi:              0\n memory:                     7652420Ki\n pods:                       110\nAllocatable:\n attachable-volumes-gce-pd:  127\n cpu:                        1920m\n ephemeral-storage:          27293670584\n hugepages-1Gi:              0\n hugepages-2Mi:              0\n memory:                     6370532347\n pods:                       110\nSystem Info:\n Machine ID:                 0127e60d16ae7c50991cf9d50cba093e\n System UUID:                0127e60d-16ae-7c50-991c-f9d50cba093e\n Boot ID:                    0ecc5213-9a23-4060-99b0-924a64215ef1\n Kernel Version:             4.19.56-coreos-r1\n OS Image:                   Container Linux by CoreOS 2135.6.0 (Rhyolite)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.6.3\n Kubelet Version:            v1.15.6\n Kube-Proxy Version:         v1.15.6\nPodCIDR:                     100.64.1.0/24\nProviderID:                  gce://sap-gcp-k8s-canary-custom/europe-west1-b/shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9\nNon-terminated Pods:         (9 in total)\n  Namespace                  Name                                                CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                ------------  ----------  ---------------  -------------  ---\n  kube-system                addons-nginx-ingress-controller-8468678b64-lvtp6    100m (5%)     2 (104%)    100Mi (1%)       1Gi (16%)      41m\n  kube-system                calico-kube-controllers-5d785bc598-8q48p            0 (0%)        0 (0%)      0 (0%)           0 (0%)         41m\n  kube-system                calico-node-s9glf                                   100m (5%)     500m (26%)  100Mi (1%)       700Mi (11%)    39m\n  kube-system                coredns-858b686868-btwxc                            50m (2%)      100m (5%)   15Mi (0%)        100Mi (1%)     41m\n  kube-system                kube-proxy-kst5c                                    20m (1%)      0 (0%)      64Mi (1%)        0 (0%)         39m\n  kube-system                metrics-server-5bd76bb595-8pxkg                     20m (1%)      80m (4%)    100Mi (1%)       400Mi (6%)     41m\n  kube-system                node-exporter-42tbw                                 5m (0%)       25m (1%)    10Mi (0%)        100Mi (1%)     39m\n  kube-system                node-problem-detector-c9sgc                         20m (1%)      200m (10%)  20Mi (0%)        100Mi (1%)     39m\n  kubectl-500                redis-master-n8b75                                  0 (0%)        0 (0%)      0 (0%)           0 (0%)         2s\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource                   Requests    Limits\n  --------                   --------    ------\n  cpu                        315m (16%)  2905m (151%)\n  memory                     409Mi (6%)  2424Mi (39%)\n  ephemeral-storage          0 (0%)      0 (0%)\n  attachable-volumes-gce-pd  0           0\nEvents:\n  Type     Reason                   Age                From                                                                Message\n  ----     ------                   ----               ----                                                                -------\n  Normal   Starting                 39m                kubelet, shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9          Starting kubelet.\n  Normal   NodeHasSufficientMemory  39m                kubelet, shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9          Node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 status is now: NodeHasSufficientMemory\n  Normal   NodeHasNoDiskPressure    39m                kubelet, shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9          Node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientPID     39m                kubelet, shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9          Node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 status is now: NodeHasSufficientPID\n  Normal   NodeAllocatableEnforced  39m                kubelet, shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9          Updated Node Allocatable limit across pods\n  Normal   Starting                 39m                kube-proxy, shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9       Starting kube-proxy.\n  Normal   NodeReady                39m                kubelet, shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9          Node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 status is now: NodeReady\n  Warning  DockerStart              38m (x3 over 38m)  systemd-monitor, shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9  Starting Docker Application Container Engine...\n"
Dec  3 15:06:09.828: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config describe namespace kubectl-500'
Dec  3 15:06:09.969: INFO: stderr: ""
Dec  3 15:06:09.969: INFO: stdout: "Name:         kubectl-500\nLabels:       e2e-framework=kubectl\n              e2e-run=ec88a771-0326-4e77-9674-12e2429f8350\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:06:09.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-500" for this suite.
Dec  3 15:06:32.021: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:06:32.425: INFO: namespace kubectl-500 deletion completed in 22.436262041s
•SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:06:32.425: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-111
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec  3 15:06:36.685: INFO: Waiting up to 5m0s for pod "client-envvars-dbc6da8e-67f6-4878-b2f1-e7d813e8237a" in namespace "pods-111" to be "success or failure"
Dec  3 15:06:36.695: INFO: Pod "client-envvars-dbc6da8e-67f6-4878-b2f1-e7d813e8237a": Phase="Pending", Reason="", readiness=false. Elapsed: 10.247796ms
Dec  3 15:06:38.706: INFO: Pod "client-envvars-dbc6da8e-67f6-4878-b2f1-e7d813e8237a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021287423s
STEP: Saw pod success
Dec  3 15:06:38.706: INFO: Pod "client-envvars-dbc6da8e-67f6-4878-b2f1-e7d813e8237a" satisfied condition "success or failure"
Dec  3 15:06:38.717: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod client-envvars-dbc6da8e-67f6-4878-b2f1-e7d813e8237a container env3cont: <nil>
STEP: delete the pod
Dec  3 15:06:38.749: INFO: Waiting for pod client-envvars-dbc6da8e-67f6-4878-b2f1-e7d813e8237a to disappear
Dec  3 15:06:38.760: INFO: Pod client-envvars-dbc6da8e-67f6-4878-b2f1-e7d813e8237a no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:06:38.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-111" for this suite.
Dec  3 15:07:28.812: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:07:29.215: INFO: namespace pods-111 deletion completed in 50.435409879s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:07:29.216: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9240
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: validating api versions
Dec  3 15:07:29.401: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config api-versions'
Dec  3 15:07:29.525: INFO: stderr: ""
Dec  3 15:07:29.525: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncert.gardener.cloud/v1alpha1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\ncrd.projectcalico.org/v1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:07:29.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9240" for this suite.
Dec  3 15:07:35.568: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:07:35.960: INFO: namespace kubectl-9240 deletion completed in 6.424277328s
•SSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:07:35.961: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-7460
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec  3 15:07:36.144: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Dec  3 15:07:37.221: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:07:37.232: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-7460" for this suite.
Dec  3 15:07:43.282: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:07:43.676: INFO: namespace replication-controller-7460 deletion completed in 6.425635659s
•SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:07:43.676: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9922
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-252a2c72-5c7f-46e2-823c-7a6af794570c
STEP: Creating a pod to test consume configMaps
Dec  3 15:07:43.883: INFO: Waiting up to 5m0s for pod "pod-configmaps-470c2b1f-999f-40bd-9735-a4351401c417" in namespace "configmap-9922" to be "success or failure"
Dec  3 15:07:43.894: INFO: Pod "pod-configmaps-470c2b1f-999f-40bd-9735-a4351401c417": Phase="Pending", Reason="", readiness=false. Elapsed: 10.595532ms
Dec  3 15:07:45.904: INFO: Pod "pod-configmaps-470c2b1f-999f-40bd-9735-a4351401c417": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021146541s
STEP: Saw pod success
Dec  3 15:07:45.905: INFO: Pod "pod-configmaps-470c2b1f-999f-40bd-9735-a4351401c417" satisfied condition "success or failure"
Dec  3 15:07:45.915: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod pod-configmaps-470c2b1f-999f-40bd-9735-a4351401c417 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 15:07:45.948: INFO: Waiting for pod pod-configmaps-470c2b1f-999f-40bd-9735-a4351401c417 to disappear
Dec  3 15:07:45.958: INFO: Pod pod-configmaps-470c2b1f-999f-40bd-9735-a4351401c417 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:07:45.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9922" for this suite.
Dec  3 15:07:52.008: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:07:52.449: INFO: namespace configmap-9922 deletion completed in 6.47282418s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:07:52.450: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7232
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating secret secrets-7232/secret-test-4c61bad1-6550-44ec-a0a6-217373a9dfb8
STEP: Creating a pod to test consume secrets
Dec  3 15:07:52.663: INFO: Waiting up to 5m0s for pod "pod-configmaps-54ca132e-7a06-475c-8618-7e6ae1670fe1" in namespace "secrets-7232" to be "success or failure"
Dec  3 15:07:52.673: INFO: Pod "pod-configmaps-54ca132e-7a06-475c-8618-7e6ae1670fe1": Phase="Pending", Reason="", readiness=false. Elapsed: 10.320562ms
Dec  3 15:07:54.684: INFO: Pod "pod-configmaps-54ca132e-7a06-475c-8618-7e6ae1670fe1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02136798s
STEP: Saw pod success
Dec  3 15:07:54.685: INFO: Pod "pod-configmaps-54ca132e-7a06-475c-8618-7e6ae1670fe1" satisfied condition "success or failure"
Dec  3 15:07:54.695: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod pod-configmaps-54ca132e-7a06-475c-8618-7e6ae1670fe1 container env-test: <nil>
STEP: delete the pod
Dec  3 15:07:54.727: INFO: Waiting for pod pod-configmaps-54ca132e-7a06-475c-8618-7e6ae1670fe1 to disappear
Dec  3 15:07:54.737: INFO: Pod pod-configmaps-54ca132e-7a06-475c-8618-7e6ae1670fe1 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:07:54.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7232" for this suite.
Dec  3 15:08:00.789: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:08:01.186: INFO: namespace secrets-7232 deletion completed in 6.429474488s
•SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:08:01.186: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-516
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec  3 15:08:01.397: INFO: (0) /api/v1/nodes/shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 15.242922ms)
Dec  3 15:08:01.440: INFO: (1) /api/v1/nodes/shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 42.87127ms)
Dec  3 15:08:01.454: INFO: (2) /api/v1/nodes/shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 13.035803ms)
Dec  3 15:08:01.467: INFO: (3) /api/v1/nodes/shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 13.202999ms)
Dec  3 15:08:01.480: INFO: (4) /api/v1/nodes/shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 13.350858ms)
Dec  3 15:08:01.493: INFO: (5) /api/v1/nodes/shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.609529ms)
Dec  3 15:08:01.506: INFO: (6) /api/v1/nodes/shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.650123ms)
Dec  3 15:08:01.519: INFO: (7) /api/v1/nodes/shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 13.099217ms)
Dec  3 15:08:01.532: INFO: (8) /api/v1/nodes/shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 13.082711ms)
Dec  3 15:08:01.545: INFO: (9) /api/v1/nodes/shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.850938ms)
Dec  3 15:08:01.558: INFO: (10) /api/v1/nodes/shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.555368ms)
Dec  3 15:08:01.570: INFO: (11) /api/v1/nodes/shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.768685ms)
Dec  3 15:08:01.583: INFO: (12) /api/v1/nodes/shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.71534ms)
Dec  3 15:08:01.596: INFO: (13) /api/v1/nodes/shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 13.007249ms)
Dec  3 15:08:01.609: INFO: (14) /api/v1/nodes/shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.729502ms)
Dec  3 15:08:01.622: INFO: (15) /api/v1/nodes/shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 13.319217ms)
Dec  3 15:08:01.636: INFO: (16) /api/v1/nodes/shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 13.386229ms)
Dec  3 15:08:01.649: INFO: (17) /api/v1/nodes/shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.617728ms)
Dec  3 15:08:01.663: INFO: (18) /api/v1/nodes/shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 14.232845ms)
Dec  3 15:08:01.677: INFO: (19) /api/v1/nodes/shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 13.886672ms)
[AfterEach] version v1
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:08:01.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-516" for this suite.
Dec  3 15:08:07.721: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:08:08.141: INFO: namespace proxy-516 deletion completed in 6.452180457s
•SSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:08:08.141: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-809
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Dec  3 15:08:08.328: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:08:11.194: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-809" for this suite.
Dec  3 15:08:17.246: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:08:17.668: INFO: namespace init-container-809 deletion completed in 6.454601373s
•SSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:08:17.668: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-6275
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-6275
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec  3 15:08:17.859: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec  3 15:08:42.072: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.64.1.125:8080/dial?request=hostName&protocol=udp&host=100.64.0.38&port=8081&tries=1'] Namespace:pod-network-test-6275 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:08:42.072: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:08:42.604: INFO: Waiting for endpoints: map[]
Dec  3 15:08:42.614: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.64.1.125:8080/dial?request=hostName&protocol=udp&host=100.64.1.124&port=8081&tries=1'] Namespace:pod-network-test-6275 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:08:42.614: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:08:43.076: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:08:43.077: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-6275" for this suite.
Dec  3 15:09:05.129: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:09:05.531: INFO: namespace pod-network-test-6275 deletion completed in 22.434475621s
•SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:09:05.532: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-864
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: getting the auto-created API token
STEP: reading a file in the container
Dec  3 15:09:08.287: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl exec --namespace=svcaccounts-864 pod-service-account-1fa10848-ef6d-40ae-8af9-1f8af3bd459b -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Dec  3 15:09:08.864: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl exec --namespace=svcaccounts-864 pod-service-account-1fa10848-ef6d-40ae-8af9-1f8af3bd459b -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Dec  3 15:09:09.418: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl exec --namespace=svcaccounts-864 pod-service-account-1fa10848-ef6d-40ae-8af9-1f8af3bd459b -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:09:10.000: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-864" for this suite.
Dec  3 15:09:16.051: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:09:16.453: INFO: namespace svcaccounts-864 deletion completed in 6.433911782s
•SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:09:16.453: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9883
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1685
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  3 15:09:16.636: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-9883'
Dec  3 15:09:16.757: INFO: stderr: ""
Dec  3 15:09:16.758: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1690
Dec  3 15:09:16.768: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete pods e2e-test-nginx-pod --namespace=kubectl-9883'
Dec  3 15:09:19.987: INFO: stderr: ""
Dec  3 15:09:19.987: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:09:19.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9883" for this suite.
Dec  3 15:09:26.039: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:09:26.447: INFO: namespace kubectl-9883 deletion completed in 6.441126712s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:09:26.447: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6496
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec  3 15:09:26.632: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config version'
Dec  3 15:09:26.737: INFO: stderr: ""
Dec  3 15:09:26.737: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.6\", GitCommit:\"7015f71e75f670eb9e7ebd4b5749639d42e20079\", GitTreeState:\"clean\", BuildDate:\"2019-11-13T11:20:18Z\", GoVersion:\"go1.12.12\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.6\", GitCommit:\"7015f71e75f670eb9e7ebd4b5749639d42e20079\", GitTreeState:\"clean\", BuildDate:\"2019-11-13T11:11:50Z\", GoVersion:\"go1.12.12\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:09:26.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6496" for this suite.
Dec  3 15:09:32.781: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:09:33.186: INFO: namespace kubectl-6496 deletion completed in 6.437936328s
•SSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:09:33.186: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-7400
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec  3 15:09:35.952: INFO: Successfully updated pod "pod-update-activedeadlineseconds-5ce3e376-a8d3-42c9-adff-79ca3b5357f5"
Dec  3 15:09:35.952: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-5ce3e376-a8d3-42c9-adff-79ca3b5357f5" in namespace "pods-7400" to be "terminated due to deadline exceeded"
Dec  3 15:09:35.962: INFO: Pod "pod-update-activedeadlineseconds-5ce3e376-a8d3-42c9-adff-79ca3b5357f5": Phase="Running", Reason="", readiness=true. Elapsed: 10.566704ms
Dec  3 15:09:37.973: INFO: Pod "pod-update-activedeadlineseconds-5ce3e376-a8d3-42c9-adff-79ca3b5357f5": Phase="Running", Reason="", readiness=true. Elapsed: 2.021173547s
Dec  3 15:09:39.984: INFO: Pod "pod-update-activedeadlineseconds-5ce3e376-a8d3-42c9-adff-79ca3b5357f5": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.031869088s
Dec  3 15:09:39.984: INFO: Pod "pod-update-activedeadlineseconds-5ce3e376-a8d3-42c9-adff-79ca3b5357f5" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:09:39.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7400" for this suite.
Dec  3 15:09:46.035: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:09:46.424: INFO: namespace pods-7400 deletion completed in 6.421231075s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:09:46.425: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-8979
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod busybox-2e3d4bca-29d7-4f12-a9b4-a22ef0323d8b in namespace container-probe-8979
Dec  3 15:09:48.641: INFO: Started pod busybox-2e3d4bca-29d7-4f12-a9b4-a22ef0323d8b in namespace container-probe-8979
STEP: checking the pod's current state and verifying that restartCount is present
Dec  3 15:09:48.652: INFO: Initial restart count of pod busybox-2e3d4bca-29d7-4f12-a9b4-a22ef0323d8b is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:13:50.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8979" for this suite.
Dec  3 15:13:56.265: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:13:56.663: INFO: namespace container-probe-8979 deletion completed in 6.430817546s
•SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:13:56.663: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-2461
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-2461
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a new StatefulSet
Dec  3 15:13:56.880: INFO: Found 1 stateful pods, waiting for 3
Dec  3 15:14:06.892: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 15:14:06.892: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 15:14:06.892: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Dec  3 15:14:06.957: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Dec  3 15:14:07.009: INFO: Updating stateful set ss2
Dec  3 15:14:07.032: INFO: Waiting for Pod statefulset-2461/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Restoring Pods to the correct revision when they are deleted
Dec  3 15:14:17.097: INFO: Found 2 stateful pods, waiting for 3
Dec  3 15:14:27.109: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 15:14:27.109: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 15:14:27.109: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Dec  3 15:14:27.164: INFO: Updating stateful set ss2
Dec  3 15:14:27.185: INFO: Waiting for Pod statefulset-2461/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Dec  3 15:14:37.241: INFO: Updating stateful set ss2
Dec  3 15:14:37.262: INFO: Waiting for StatefulSet statefulset-2461/ss2 to complete update
Dec  3 15:14:37.262: INFO: Waiting for Pod statefulset-2461/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Dec  3 15:14:47.284: INFO: Deleting all statefulset in ns statefulset-2461
Dec  3 15:14:47.295: INFO: Scaling statefulset ss2 to 0
Dec  3 15:14:57.339: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 15:14:57.350: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:14:57.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2461" for this suite.
Dec  3 15:15:03.433: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:15:03.842: INFO: namespace statefulset-2461 deletion completed in 6.440624941s
•SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:15:03.842: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-46
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Dec  3 15:15:06.622: INFO: Successfully updated pod "labelsupdate6f4b2773-2c0d-446e-8306-3e693739d6e3"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:15:10.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-46" for this suite.
Dec  3 15:15:32.733: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:15:33.136: INFO: namespace downward-api-46 deletion completed in 22.436068712s
•SSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:15:33.136: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-8238
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Dec  3 15:15:33.396: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-8238,SelfLink:/api/v1/namespaces/watch-8238/configmaps/e2e-watch-test-resource-version,UID:9c2539f0-f4d9-4de5-95a3-3f33a9cea806,ResourceVersion:11915,Generation:0,CreationTimestamp:2019-12-03 15:15:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  3 15:15:33.396: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-8238,SelfLink:/api/v1/namespaces/watch-8238/configmaps/e2e-watch-test-resource-version,UID:9c2539f0-f4d9-4de5-95a3-3f33a9cea806,ResourceVersion:11916,Generation:0,CreationTimestamp:2019-12-03 15:15:33 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:15:33.396: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8238" for this suite.
Dec  3 15:15:39.442: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:15:39.836: INFO: namespace watch-8238 deletion completed in 6.427947943s
•SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:15:39.836: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-2547
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Dec  3 15:16:20.181: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1203 15:16:20.181157    5066 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:16:20.181: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2547" for this suite.
Dec  3 15:16:26.224: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:16:26.608: INFO: namespace gc-2547 deletion completed in 6.416338875s
•S
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:16:26.609: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8065
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec  3 15:16:26.800: INFO: Waiting up to 5m0s for pod "downwardapi-volume-94ae96b8-30b3-4d9e-80ba-45d2996969c6" in namespace "downward-api-8065" to be "success or failure"
Dec  3 15:16:26.810: INFO: Pod "downwardapi-volume-94ae96b8-30b3-4d9e-80ba-45d2996969c6": Phase="Pending", Reason="", readiness=false. Elapsed: 10.098554ms
Dec  3 15:16:28.821: INFO: Pod "downwardapi-volume-94ae96b8-30b3-4d9e-80ba-45d2996969c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020636612s
Dec  3 15:16:30.831: INFO: Pod "downwardapi-volume-94ae96b8-30b3-4d9e-80ba-45d2996969c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031311737s
STEP: Saw pod success
Dec  3 15:16:30.832: INFO: Pod "downwardapi-volume-94ae96b8-30b3-4d9e-80ba-45d2996969c6" satisfied condition "success or failure"
Dec  3 15:16:30.842: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod downwardapi-volume-94ae96b8-30b3-4d9e-80ba-45d2996969c6 container client-container: <nil>
STEP: delete the pod
Dec  3 15:16:30.877: INFO: Waiting for pod downwardapi-volume-94ae96b8-30b3-4d9e-80ba-45d2996969c6 to disappear
Dec  3 15:16:30.887: INFO: Pod downwardapi-volume-94ae96b8-30b3-4d9e-80ba-45d2996969c6 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:16:30.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8065" for this suite.
Dec  3 15:16:36.938: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:16:37.325: INFO: namespace downward-api-8065 deletion completed in 6.419873562s
•SSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:16:37.326: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-4936
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4936.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-4936.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4936.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-4936.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4936.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-4936.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4936.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-4936.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4936.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-4936.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4936.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-4936.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4936.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 221.73.104.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.104.73.221_udp@PTR;check="$$(dig +tcp +noall +answer +search 221.73.104.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.104.73.221_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4936.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-4936.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4936.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-4936.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4936.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-4936.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4936.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-4936.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4936.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-4936.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4936.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-4936.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4936.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 221.73.104.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.104.73.221_udp@PTR;check="$$(dig +tcp +noall +answer +search 221.73.104.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.104.73.221_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec  3 15:16:39.673: INFO: Unable to read wheezy_udp@dns-test-service.dns-4936.svc.cluster.local from pod dns-4936/dns-test-3f3990db-5b37-4490-b247-60215e7a9f2a: the server could not find the requested resource (get pods dns-test-3f3990db-5b37-4490-b247-60215e7a9f2a)
Dec  3 15:16:39.716: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4936.svc.cluster.local from pod dns-4936/dns-test-3f3990db-5b37-4490-b247-60215e7a9f2a: the server could not find the requested resource (get pods dns-test-3f3990db-5b37-4490-b247-60215e7a9f2a)
Dec  3 15:16:39.728: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4936.svc.cluster.local from pod dns-4936/dns-test-3f3990db-5b37-4490-b247-60215e7a9f2a: the server could not find the requested resource (get pods dns-test-3f3990db-5b37-4490-b247-60215e7a9f2a)
Dec  3 15:16:39.741: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4936.svc.cluster.local from pod dns-4936/dns-test-3f3990db-5b37-4490-b247-60215e7a9f2a: the server could not find the requested resource (get pods dns-test-3f3990db-5b37-4490-b247-60215e7a9f2a)
Dec  3 15:16:40.175: INFO: Unable to read jessie_udp@dns-test-service.dns-4936.svc.cluster.local from pod dns-4936/dns-test-3f3990db-5b37-4490-b247-60215e7a9f2a: the server could not find the requested resource (get pods dns-test-3f3990db-5b37-4490-b247-60215e7a9f2a)
Dec  3 15:16:40.187: INFO: Unable to read jessie_tcp@dns-test-service.dns-4936.svc.cluster.local from pod dns-4936/dns-test-3f3990db-5b37-4490-b247-60215e7a9f2a: the server could not find the requested resource (get pods dns-test-3f3990db-5b37-4490-b247-60215e7a9f2a)
Dec  3 15:16:40.199: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4936.svc.cluster.local from pod dns-4936/dns-test-3f3990db-5b37-4490-b247-60215e7a9f2a: the server could not find the requested resource (get pods dns-test-3f3990db-5b37-4490-b247-60215e7a9f2a)
Dec  3 15:16:40.211: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4936.svc.cluster.local from pod dns-4936/dns-test-3f3990db-5b37-4490-b247-60215e7a9f2a: the server could not find the requested resource (get pods dns-test-3f3990db-5b37-4490-b247-60215e7a9f2a)
Dec  3 15:16:40.605: INFO: Lookups using dns-4936/dns-test-3f3990db-5b37-4490-b247-60215e7a9f2a failed for: [wheezy_udp@dns-test-service.dns-4936.svc.cluster.local wheezy_tcp@dns-test-service.dns-4936.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4936.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4936.svc.cluster.local jessie_udp@dns-test-service.dns-4936.svc.cluster.local jessie_tcp@dns-test-service.dns-4936.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4936.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4936.svc.cluster.local]

Dec  3 15:16:45.704: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4936.svc.cluster.local from pod dns-4936/dns-test-3f3990db-5b37-4490-b247-60215e7a9f2a: the server could not find the requested resource (get pods dns-test-3f3990db-5b37-4490-b247-60215e7a9f2a)
Dec  3 15:16:45.716: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4936.svc.cluster.local from pod dns-4936/dns-test-3f3990db-5b37-4490-b247-60215e7a9f2a: the server could not find the requested resource (get pods dns-test-3f3990db-5b37-4490-b247-60215e7a9f2a)
Dec  3 15:16:46.275: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4936.svc.cluster.local from pod dns-4936/dns-test-3f3990db-5b37-4490-b247-60215e7a9f2a: the server could not find the requested resource (get pods dns-test-3f3990db-5b37-4490-b247-60215e7a9f2a)
Dec  3 15:16:46.290: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4936.svc.cluster.local from pod dns-4936/dns-test-3f3990db-5b37-4490-b247-60215e7a9f2a: the server could not find the requested resource (get pods dns-test-3f3990db-5b37-4490-b247-60215e7a9f2a)
Dec  3 15:16:46.679: INFO: Lookups using dns-4936/dns-test-3f3990db-5b37-4490-b247-60215e7a9f2a failed for: [wheezy_udp@_http._tcp.dns-test-service.dns-4936.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4936.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4936.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4936.svc.cluster.local]

Dec  3 15:16:50.703: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4936.svc.cluster.local from pod dns-4936/dns-test-3f3990db-5b37-4490-b247-60215e7a9f2a: the server could not find the requested resource (get pods dns-test-3f3990db-5b37-4490-b247-60215e7a9f2a)
Dec  3 15:16:50.715: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4936.svc.cluster.local from pod dns-4936/dns-test-3f3990db-5b37-4490-b247-60215e7a9f2a: the server could not find the requested resource (get pods dns-test-3f3990db-5b37-4490-b247-60215e7a9f2a)
Dec  3 15:16:51.276: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4936.svc.cluster.local from pod dns-4936/dns-test-3f3990db-5b37-4490-b247-60215e7a9f2a: the server could not find the requested resource (get pods dns-test-3f3990db-5b37-4490-b247-60215e7a9f2a)
Dec  3 15:16:51.289: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4936.svc.cluster.local from pod dns-4936/dns-test-3f3990db-5b37-4490-b247-60215e7a9f2a: the server could not find the requested resource (get pods dns-test-3f3990db-5b37-4490-b247-60215e7a9f2a)
Dec  3 15:16:51.680: INFO: Lookups using dns-4936/dns-test-3f3990db-5b37-4490-b247-60215e7a9f2a failed for: [wheezy_udp@_http._tcp.dns-test-service.dns-4936.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4936.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4936.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4936.svc.cluster.local]

Dec  3 15:16:55.744: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4936.svc.cluster.local from pod dns-4936/dns-test-3f3990db-5b37-4490-b247-60215e7a9f2a: the server could not find the requested resource (get pods dns-test-3f3990db-5b37-4490-b247-60215e7a9f2a)
Dec  3 15:16:55.756: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4936.svc.cluster.local from pod dns-4936/dns-test-3f3990db-5b37-4490-b247-60215e7a9f2a: the server could not find the requested resource (get pods dns-test-3f3990db-5b37-4490-b247-60215e7a9f2a)
Dec  3 15:16:56.313: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4936.svc.cluster.local from pod dns-4936/dns-test-3f3990db-5b37-4490-b247-60215e7a9f2a: the server could not find the requested resource (get pods dns-test-3f3990db-5b37-4490-b247-60215e7a9f2a)
Dec  3 15:16:56.325: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4936.svc.cluster.local from pod dns-4936/dns-test-3f3990db-5b37-4490-b247-60215e7a9f2a: the server could not find the requested resource (get pods dns-test-3f3990db-5b37-4490-b247-60215e7a9f2a)
Dec  3 15:16:56.714: INFO: Lookups using dns-4936/dns-test-3f3990db-5b37-4490-b247-60215e7a9f2a failed for: [wheezy_udp@_http._tcp.dns-test-service.dns-4936.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4936.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4936.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4936.svc.cluster.local]

Dec  3 15:17:00.703: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4936.svc.cluster.local from pod dns-4936/dns-test-3f3990db-5b37-4490-b247-60215e7a9f2a: the server could not find the requested resource (get pods dns-test-3f3990db-5b37-4490-b247-60215e7a9f2a)
Dec  3 15:17:00.715: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4936.svc.cluster.local from pod dns-4936/dns-test-3f3990db-5b37-4490-b247-60215e7a9f2a: the server could not find the requested resource (get pods dns-test-3f3990db-5b37-4490-b247-60215e7a9f2a)
Dec  3 15:17:01.272: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4936.svc.cluster.local from pod dns-4936/dns-test-3f3990db-5b37-4490-b247-60215e7a9f2a: the server could not find the requested resource (get pods dns-test-3f3990db-5b37-4490-b247-60215e7a9f2a)
Dec  3 15:17:01.285: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4936.svc.cluster.local from pod dns-4936/dns-test-3f3990db-5b37-4490-b247-60215e7a9f2a: the server could not find the requested resource (get pods dns-test-3f3990db-5b37-4490-b247-60215e7a9f2a)
Dec  3 15:17:01.675: INFO: Lookups using dns-4936/dns-test-3f3990db-5b37-4490-b247-60215e7a9f2a failed for: [wheezy_udp@_http._tcp.dns-test-service.dns-4936.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4936.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4936.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4936.svc.cluster.local]

Dec  3 15:17:05.704: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4936.svc.cluster.local from pod dns-4936/dns-test-3f3990db-5b37-4490-b247-60215e7a9f2a: the server could not find the requested resource (get pods dns-test-3f3990db-5b37-4490-b247-60215e7a9f2a)
Dec  3 15:17:05.716: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4936.svc.cluster.local from pod dns-4936/dns-test-3f3990db-5b37-4490-b247-60215e7a9f2a: the server could not find the requested resource (get pods dns-test-3f3990db-5b37-4490-b247-60215e7a9f2a)
Dec  3 15:17:06.275: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4936.svc.cluster.local from pod dns-4936/dns-test-3f3990db-5b37-4490-b247-60215e7a9f2a: the server could not find the requested resource (get pods dns-test-3f3990db-5b37-4490-b247-60215e7a9f2a)
Dec  3 15:17:06.287: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4936.svc.cluster.local from pod dns-4936/dns-test-3f3990db-5b37-4490-b247-60215e7a9f2a: the server could not find the requested resource (get pods dns-test-3f3990db-5b37-4490-b247-60215e7a9f2a)
Dec  3 15:17:06.634: INFO: Lookups using dns-4936/dns-test-3f3990db-5b37-4490-b247-60215e7a9f2a failed for: [wheezy_udp@_http._tcp.dns-test-service.dns-4936.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4936.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4936.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4936.svc.cluster.local]

Dec  3 15:17:11.840: INFO: DNS probes using dns-4936/dns-test-3f3990db-5b37-4490-b247-60215e7a9f2a succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:17:11.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4936" for this suite.
Dec  3 15:17:17.930: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:17:18.319: INFO: namespace dns-4936 deletion completed in 6.420791522s
•SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:17:18.320: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3692
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name cm-test-opt-del-c71db116-e50e-4d04-86a2-196e3387c417
STEP: Creating configMap with name cm-test-opt-upd-d4d05014-c08b-4bc8-8655-010f2a50e0a9
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-c71db116-e50e-4d04-86a2-196e3387c417
STEP: Updating configmap cm-test-opt-upd-d4d05014-c08b-4bc8-8655-010f2a50e0a9
STEP: Creating configMap with name cm-test-opt-create-def59a51-bd39-4826-bdb5-771e2c6fd75c
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:18:35.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3692" for this suite.
Dec  3 15:18:57.768: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:18:58.160: INFO: namespace projected-3692 deletion completed in 22.424366367s
•SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:18:58.160: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-2170
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:19:00.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-2170" for this suite.
Dec  3 15:19:06.496: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:19:06.877: INFO: namespace emptydir-wrapper-2170 deletion completed in 6.411984686s
•SSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:19:06.877: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7081
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap configmap-7081/configmap-test-c80cf5b3-ddf9-4653-b450-1bf79d8ca241
STEP: Creating a pod to test consume configMaps
Dec  3 15:19:07.084: INFO: Waiting up to 5m0s for pod "pod-configmaps-2e083510-b19b-406c-9ade-41b9ed02906a" in namespace "configmap-7081" to be "success or failure"
Dec  3 15:19:07.094: INFO: Pod "pod-configmaps-2e083510-b19b-406c-9ade-41b9ed02906a": Phase="Pending", Reason="", readiness=false. Elapsed: 9.691206ms
Dec  3 15:19:09.105: INFO: Pod "pod-configmaps-2e083510-b19b-406c-9ade-41b9ed02906a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021012217s
STEP: Saw pod success
Dec  3 15:19:09.105: INFO: Pod "pod-configmaps-2e083510-b19b-406c-9ade-41b9ed02906a" satisfied condition "success or failure"
Dec  3 15:19:09.115: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod pod-configmaps-2e083510-b19b-406c-9ade-41b9ed02906a container env-test: <nil>
STEP: delete the pod
Dec  3 15:19:09.148: INFO: Waiting for pod pod-configmaps-2e083510-b19b-406c-9ade-41b9ed02906a to disappear
Dec  3 15:19:09.157: INFO: Pod pod-configmaps-2e083510-b19b-406c-9ade-41b9ed02906a no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:19:09.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7081" for this suite.
Dec  3 15:19:15.208: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:19:15.633: INFO: namespace configmap-7081 deletion completed in 6.457253747s
•SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:19:15.633: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8043
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Starting the proxy
Dec  3 15:19:15.817: INFO: Asynchronously running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config proxy --unix-socket=/tmp/kubectl-proxy-unix926904690/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:19:15.873: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8043" for this suite.
Dec  3 15:19:21.916: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:19:22.298: INFO: namespace kubectl-8043 deletion completed in 6.413902428s
•SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:19:22.298: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2120
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with configMap that has name projected-configmap-test-upd-083a98bb-b288-4aa9-b13c-d88c4a26d279
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-083a98bb-b288-4aa9-b13c-d88c4a26d279
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:19:26.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2120" for this suite.
Dec  3 15:19:48.718: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:19:49.110: INFO: namespace projected-2120 deletion completed in 22.423848453s
•SSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:19:49.110: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5524
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-map-376481a8-cb70-4e9f-ab21-3dc83410f881
STEP: Creating a pod to test consume secrets
Dec  3 15:19:49.314: INFO: Waiting up to 5m0s for pod "pod-secrets-0b5867c2-a243-4379-a462-f9c02602b3e9" in namespace "secrets-5524" to be "success or failure"
Dec  3 15:19:49.323: INFO: Pod "pod-secrets-0b5867c2-a243-4379-a462-f9c02602b3e9": Phase="Pending", Reason="", readiness=false. Elapsed: 9.785835ms
Dec  3 15:19:51.335: INFO: Pod "pod-secrets-0b5867c2-a243-4379-a462-f9c02602b3e9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020996872s
STEP: Saw pod success
Dec  3 15:19:51.335: INFO: Pod "pod-secrets-0b5867c2-a243-4379-a462-f9c02602b3e9" satisfied condition "success or failure"
Dec  3 15:19:51.345: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod pod-secrets-0b5867c2-a243-4379-a462-f9c02602b3e9 container secret-volume-test: <nil>
STEP: delete the pod
Dec  3 15:19:51.376: INFO: Waiting for pod pod-secrets-0b5867c2-a243-4379-a462-f9c02602b3e9 to disappear
Dec  3 15:19:51.386: INFO: Pod pod-secrets-0b5867c2-a243-4379-a462-f9c02602b3e9 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:19:51.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5524" for this suite.
Dec  3 15:19:57.436: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:19:57.817: INFO: namespace secrets-5524 deletion completed in 6.411839738s
•SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:19:57.817: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-2148
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Dec  3 15:20:28.092: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1203 15:20:28.092867    5066 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:20:28.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2148" for this suite.
Dec  3 15:20:34.135: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:20:34.522: INFO: namespace gc-2148 deletion completed in 6.418418848s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:20:34.525: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-614
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: validating cluster-info
Dec  3 15:20:34.706: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config cluster-info'
Dec  3 15:20:35.044: INFO: stderr: ""
Dec  3 15:20:35.044: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://api.tml9e-anp.it.internal.staging.k8s.ondemand.com\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://api.tml9e-anp.it.internal.staging.k8s.ondemand.com/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mkubernetes-dashboard\x1b[0m is running at \x1b[0;33mhttps://api.tml9e-anp.it.internal.staging.k8s.ondemand.com/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:20:35.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-614" for this suite.
Dec  3 15:20:41.086: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:20:41.478: INFO: namespace kubectl-614 deletion completed in 6.423294356s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:20:41.478: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in hostpath-3051
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test hostPath mode
Dec  3 15:20:41.674: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-3051" to be "success or failure"
Dec  3 15:20:41.684: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 10.103944ms
Dec  3 15:20:43.694: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020452636s
STEP: Saw pod success
Dec  3 15:20:43.694: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Dec  3 15:20:43.705: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Dec  3 15:20:43.740: INFO: Waiting for pod pod-host-path-test to disappear
Dec  3 15:20:43.749: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:20:43.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-3051" for this suite.
Dec  3 15:20:49.799: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:20:50.217: INFO: namespace hostpath-3051 deletion completed in 6.449282376s
•SSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:20:50.217: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-4641
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod busybox-6aa920b6-3fb7-4861-b2f9-365ecff0cbbe in namespace container-probe-4641
Dec  3 15:20:52.433: INFO: Started pod busybox-6aa920b6-3fb7-4861-b2f9-365ecff0cbbe in namespace container-probe-4641
STEP: checking the pod's current state and verifying that restartCount is present
Dec  3 15:20:52.443: INFO: Initial restart count of pod busybox-6aa920b6-3fb7-4861-b2f9-365ecff0cbbe is 0
Dec  3 15:21:38.704: INFO: Restart count of pod container-probe-4641/busybox-6aa920b6-3fb7-4861-b2f9-365ecff0cbbe is now 1 (46.261089889s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:21:38.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4641" for this suite.
Dec  3 15:21:44.768: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:21:45.156: INFO: namespace container-probe-4641 deletion completed in 6.419151758s
•SSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:21:45.156: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2274
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-761c18f7-008d-429f-bdf7-b83f5afd36ce
STEP: Creating a pod to test consume configMaps
Dec  3 15:21:45.365: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4064abb1-3181-4b92-b462-87d3219e0bd3" in namespace "projected-2274" to be "success or failure"
Dec  3 15:21:45.375: INFO: Pod "pod-projected-configmaps-4064abb1-3181-4b92-b462-87d3219e0bd3": Phase="Pending", Reason="", readiness=false. Elapsed: 9.872857ms
Dec  3 15:21:47.386: INFO: Pod "pod-projected-configmaps-4064abb1-3181-4b92-b462-87d3219e0bd3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021041393s
Dec  3 15:21:49.397: INFO: Pod "pod-projected-configmaps-4064abb1-3181-4b92-b462-87d3219e0bd3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031981046s
STEP: Saw pod success
Dec  3 15:21:49.397: INFO: Pod "pod-projected-configmaps-4064abb1-3181-4b92-b462-87d3219e0bd3" satisfied condition "success or failure"
Dec  3 15:21:49.407: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod pod-projected-configmaps-4064abb1-3181-4b92-b462-87d3219e0bd3 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 15:21:49.439: INFO: Waiting for pod pod-projected-configmaps-4064abb1-3181-4b92-b462-87d3219e0bd3 to disappear
Dec  3 15:21:49.448: INFO: Pod pod-projected-configmaps-4064abb1-3181-4b92-b462-87d3219e0bd3 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:21:49.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2274" for this suite.
Dec  3 15:21:55.500: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:21:55.887: INFO: namespace projected-2274 deletion completed in 6.420181056s
•SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:21:55.888: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2523
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1292
STEP: creating an rc
Dec  3 15:21:56.071: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-2523'
Dec  3 15:21:56.345: INFO: stderr: ""
Dec  3 15:21:56.345: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Waiting for Redis master to start.
Dec  3 15:21:57.356: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 15:21:57.356: INFO: Found 0 / 1
Dec  3 15:21:58.356: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 15:21:58.356: INFO: Found 1 / 1
Dec  3 15:21:58.356: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec  3 15:21:58.366: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 15:21:58.366: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Dec  3 15:21:58.366: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs redis-master-jq5hh redis-master --namespace=kubectl-2523'
Dec  3 15:21:58.588: INFO: stderr: ""
Dec  3 15:21:58.588: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 03 Dec 15:21:57.229 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 03 Dec 15:21:57.229 # Server started, Redis version 3.2.12\n1:M 03 Dec 15:21:57.229 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 03 Dec 15:21:57.229 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Dec  3 15:21:58.588: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs redis-master-jq5hh redis-master --namespace=kubectl-2523 --tail=1'
Dec  3 15:21:58.842: INFO: stderr: ""
Dec  3 15:21:58.842: INFO: stdout: "1:M 03 Dec 15:21:57.229 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Dec  3 15:21:58.842: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs redis-master-jq5hh redis-master --namespace=kubectl-2523 --limit-bytes=1'
Dec  3 15:21:59.111: INFO: stderr: ""
Dec  3 15:21:59.111: INFO: stdout: " "
STEP: exposing timestamps
Dec  3 15:21:59.111: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs redis-master-jq5hh redis-master --namespace=kubectl-2523 --tail=1 --timestamps'
Dec  3 15:21:59.279: INFO: stderr: ""
Dec  3 15:21:59.279: INFO: stdout: "2019-12-03T15:21:57.229832315Z 1:M 03 Dec 15:21:57.229 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Dec  3 15:22:01.780: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs redis-master-jq5hh redis-master --namespace=kubectl-2523 --since=1s'
Dec  3 15:22:01.912: INFO: stderr: ""
Dec  3 15:22:01.912: INFO: stdout: ""
Dec  3 15:22:01.912: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs redis-master-jq5hh redis-master --namespace=kubectl-2523 --since=24h'
Dec  3 15:22:02.044: INFO: stderr: ""
Dec  3 15:22:02.044: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 03 Dec 15:21:57.229 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 03 Dec 15:21:57.229 # Server started, Redis version 3.2.12\n1:M 03 Dec 15:21:57.229 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 03 Dec 15:21:57.229 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1298
STEP: using delete to clean up resources
Dec  3 15:22:02.044: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-2523'
Dec  3 15:22:02.171: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 15:22:02.171: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Dec  3 15:22:02.171: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get rc,svc -l name=nginx --no-headers --namespace=kubectl-2523'
Dec  3 15:22:02.289: INFO: stderr: "No resources found.\n"
Dec  3 15:22:02.289: INFO: stdout: ""
Dec  3 15:22:02.290: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -l name=nginx --namespace=kubectl-2523 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  3 15:22:02.396: INFO: stderr: ""
Dec  3 15:22:02.396: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:22:02.396: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2523" for this suite.
Dec  3 15:22:24.447: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:22:24.829: INFO: namespace kubectl-2523 deletion completed in 22.414006117s
•SS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:22:24.829: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-6968
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec  3 15:22:25.013: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:22:27.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6968" for this suite.
Dec  3 15:23:17.368: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:23:17.758: INFO: namespace pods-6968 deletion completed in 50.422298947s
•SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:23:17.759: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6436
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec  3 15:23:17.955: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0e159fe8-7844-4e56-b62e-1f2a577b69fe" in namespace "downward-api-6436" to be "success or failure"
Dec  3 15:23:17.964: INFO: Pod "downwardapi-volume-0e159fe8-7844-4e56-b62e-1f2a577b69fe": Phase="Pending", Reason="", readiness=false. Elapsed: 9.333489ms
Dec  3 15:23:19.975: INFO: Pod "downwardapi-volume-0e159fe8-7844-4e56-b62e-1f2a577b69fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019909942s
STEP: Saw pod success
Dec  3 15:23:19.975: INFO: Pod "downwardapi-volume-0e159fe8-7844-4e56-b62e-1f2a577b69fe" satisfied condition "success or failure"
Dec  3 15:23:19.985: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod downwardapi-volume-0e159fe8-7844-4e56-b62e-1f2a577b69fe container client-container: <nil>
STEP: delete the pod
Dec  3 15:23:20.019: INFO: Waiting for pod downwardapi-volume-0e159fe8-7844-4e56-b62e-1f2a577b69fe to disappear
Dec  3 15:23:20.029: INFO: Pod downwardapi-volume-0e159fe8-7844-4e56-b62e-1f2a577b69fe no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:23:20.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6436" for this suite.
Dec  3 15:23:26.084: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:23:26.477: INFO: namespace downward-api-6436 deletion completed in 6.425437379s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:23:26.477: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-246
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Dec  3 15:23:29.247: INFO: Successfully updated pod "labelsupdate43d082d6-9ae8-4e3e-8ca5-4f96815e3355"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:23:33.303: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-246" for this suite.
Dec  3 15:23:55.355: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:23:55.738: INFO: namespace projected-246 deletion completed in 22.416142756s
•SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:23:55.738: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-972
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec  3 15:23:55.934: INFO: Waiting up to 5m0s for pod "downwardapi-volume-151c280e-6ed7-47e0-9973-a7687e34e513" in namespace "downward-api-972" to be "success or failure"
Dec  3 15:23:55.943: INFO: Pod "downwardapi-volume-151c280e-6ed7-47e0-9973-a7687e34e513": Phase="Pending", Reason="", readiness=false. Elapsed: 9.690585ms
Dec  3 15:23:57.954: INFO: Pod "downwardapi-volume-151c280e-6ed7-47e0-9973-a7687e34e513": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019922115s
STEP: Saw pod success
Dec  3 15:23:57.954: INFO: Pod "downwardapi-volume-151c280e-6ed7-47e0-9973-a7687e34e513" satisfied condition "success or failure"
Dec  3 15:23:57.964: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod downwardapi-volume-151c280e-6ed7-47e0-9973-a7687e34e513 container client-container: <nil>
STEP: delete the pod
Dec  3 15:23:57.995: INFO: Waiting for pod downwardapi-volume-151c280e-6ed7-47e0-9973-a7687e34e513 to disappear
Dec  3 15:23:58.005: INFO: Pod downwardapi-volume-151c280e-6ed7-47e0-9973-a7687e34e513 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:23:58.005: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-972" for this suite.
Dec  3 15:24:04.054: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:24:04.437: INFO: namespace downward-api-972 deletion completed in 6.414423569s
•SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:24:04.437: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5696
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec  3 15:24:04.632: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f12d612e-6448-4a74-bdfa-33b7f6b35ecb" in namespace "projected-5696" to be "success or failure"
Dec  3 15:24:04.641: INFO: Pod "downwardapi-volume-f12d612e-6448-4a74-bdfa-33b7f6b35ecb": Phase="Pending", Reason="", readiness=false. Elapsed: 9.450369ms
Dec  3 15:24:06.652: INFO: Pod "downwardapi-volume-f12d612e-6448-4a74-bdfa-33b7f6b35ecb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020271847s
STEP: Saw pod success
Dec  3 15:24:06.652: INFO: Pod "downwardapi-volume-f12d612e-6448-4a74-bdfa-33b7f6b35ecb" satisfied condition "success or failure"
Dec  3 15:24:06.662: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod downwardapi-volume-f12d612e-6448-4a74-bdfa-33b7f6b35ecb container client-container: <nil>
STEP: delete the pod
Dec  3 15:24:06.696: INFO: Waiting for pod downwardapi-volume-f12d612e-6448-4a74-bdfa-33b7f6b35ecb to disappear
Dec  3 15:24:06.706: INFO: Pod downwardapi-volume-f12d612e-6448-4a74-bdfa-33b7f6b35ecb no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:24:06.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5696" for this suite.
Dec  3 15:24:12.755: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:24:13.179: INFO: namespace projected-5696 deletion completed in 6.454456374s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:24:13.179: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-7377
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-7377
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a new StatefulSet
Dec  3 15:24:13.394: INFO: Found 1 stateful pods, waiting for 3
Dec  3 15:24:23.406: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 15:24:23.406: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 15:24:23.406: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 15:24:23.437: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7377 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  3 15:24:24.036: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Dec  3 15:24:24.036: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  3 15:24:24.036: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Dec  3 15:24:34.110: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Dec  3 15:24:34.140: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7377 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 15:24:34.681: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Dec  3 15:24:34.681: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  3 15:24:34.681: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  3 15:24:44.745: INFO: Waiting for StatefulSet statefulset-7377/ss2 to complete update
Dec  3 15:24:44.745: INFO: Waiting for Pod statefulset-7377/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Dec  3 15:24:44.745: INFO: Waiting for Pod statefulset-7377/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Dec  3 15:24:54.767: INFO: Waiting for StatefulSet statefulset-7377/ss2 to complete update
Dec  3 15:24:54.767: INFO: Waiting for Pod statefulset-7377/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Dec  3 15:25:04.766: INFO: Waiting for StatefulSet statefulset-7377/ss2 to complete update
STEP: Rolling back to a previous revision
Dec  3 15:25:14.767: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7377 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  3 15:25:15.326: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Dec  3 15:25:15.326: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  3 15:25:15.326: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  3 15:25:25.400: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Dec  3 15:25:25.431: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7377 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 15:25:26.052: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Dec  3 15:25:26.052: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  3 15:25:26.052: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  3 15:25:46.116: INFO: Waiting for StatefulSet statefulset-7377/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Dec  3 15:25:56.137: INFO: Deleting all statefulset in ns statefulset-7377
Dec  3 15:25:56.148: INFO: Scaling statefulset ss2 to 0
Dec  3 15:26:16.190: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 15:26:16.201: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:26:16.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7377" for this suite.
Dec  3 15:26:22.283: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:26:22.668: INFO: namespace statefulset-7377 deletion completed in 6.416464037s
•SS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:26:22.668: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-4817
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-secret-chwh
STEP: Creating a pod to test atomic-volume-subpath
Dec  3 15:26:22.884: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-chwh" in namespace "subpath-4817" to be "success or failure"
Dec  3 15:26:22.894: INFO: Pod "pod-subpath-test-secret-chwh": Phase="Pending", Reason="", readiness=false. Elapsed: 9.61507ms
Dec  3 15:26:24.904: INFO: Pod "pod-subpath-test-secret-chwh": Phase="Running", Reason="", readiness=true. Elapsed: 2.019940396s
Dec  3 15:26:26.914: INFO: Pod "pod-subpath-test-secret-chwh": Phase="Running", Reason="", readiness=true. Elapsed: 4.030171019s
Dec  3 15:26:28.926: INFO: Pod "pod-subpath-test-secret-chwh": Phase="Running", Reason="", readiness=true. Elapsed: 6.041348038s
Dec  3 15:26:30.936: INFO: Pod "pod-subpath-test-secret-chwh": Phase="Running", Reason="", readiness=true. Elapsed: 8.052261236s
Dec  3 15:26:32.947: INFO: Pod "pod-subpath-test-secret-chwh": Phase="Running", Reason="", readiness=true. Elapsed: 10.063266178s
Dec  3 15:26:34.958: INFO: Pod "pod-subpath-test-secret-chwh": Phase="Running", Reason="", readiness=true. Elapsed: 12.07410978s
Dec  3 15:26:36.969: INFO: Pod "pod-subpath-test-secret-chwh": Phase="Running", Reason="", readiness=true. Elapsed: 14.08472961s
Dec  3 15:26:38.979: INFO: Pod "pod-subpath-test-secret-chwh": Phase="Running", Reason="", readiness=true. Elapsed: 16.095237272s
Dec  3 15:26:40.991: INFO: Pod "pod-subpath-test-secret-chwh": Phase="Running", Reason="", readiness=true. Elapsed: 18.106360892s
Dec  3 15:26:43.003: INFO: Pod "pod-subpath-test-secret-chwh": Phase="Running", Reason="", readiness=true. Elapsed: 20.118399894s
Dec  3 15:26:45.013: INFO: Pod "pod-subpath-test-secret-chwh": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.128812973s
STEP: Saw pod success
Dec  3 15:26:45.013: INFO: Pod "pod-subpath-test-secret-chwh" satisfied condition "success or failure"
Dec  3 15:26:45.023: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod pod-subpath-test-secret-chwh container test-container-subpath-secret-chwh: <nil>
STEP: delete the pod
Dec  3 15:26:45.059: INFO: Waiting for pod pod-subpath-test-secret-chwh to disappear
Dec  3 15:26:45.069: INFO: Pod pod-subpath-test-secret-chwh no longer exists
STEP: Deleting pod pod-subpath-test-secret-chwh
Dec  3 15:26:45.069: INFO: Deleting pod "pod-subpath-test-secret-chwh" in namespace "subpath-4817"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:26:45.079: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4817" for this suite.
Dec  3 15:26:51.129: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:26:51.546: INFO: namespace subpath-4817 deletion completed in 6.448944999s
•SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:26:51.547: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8254
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec  3 15:26:51.742: INFO: Waiting up to 5m0s for pod "pod-5020ed8b-34c8-4b59-a860-b8aedc589dd8" in namespace "emptydir-8254" to be "success or failure"
Dec  3 15:26:51.752: INFO: Pod "pod-5020ed8b-34c8-4b59-a860-b8aedc589dd8": Phase="Pending", Reason="", readiness=false. Elapsed: 9.63859ms
Dec  3 15:26:53.763: INFO: Pod "pod-5020ed8b-34c8-4b59-a860-b8aedc589dd8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020158646s
STEP: Saw pod success
Dec  3 15:26:53.763: INFO: Pod "pod-5020ed8b-34c8-4b59-a860-b8aedc589dd8" satisfied condition "success or failure"
Dec  3 15:26:53.773: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod pod-5020ed8b-34c8-4b59-a860-b8aedc589dd8 container test-container: <nil>
STEP: delete the pod
Dec  3 15:26:53.807: INFO: Waiting for pod pod-5020ed8b-34c8-4b59-a860-b8aedc589dd8 to disappear
Dec  3 15:26:53.816: INFO: Pod pod-5020ed8b-34c8-4b59-a860-b8aedc589dd8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:26:53.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8254" for this suite.
Dec  3 15:26:59.866: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:27:00.237: INFO: namespace emptydir-8254 deletion completed in 6.402129508s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:27:00.238: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-7236
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec  3 15:27:00.419: INFO: Creating deployment "test-recreate-deployment"
Dec  3 15:27:00.430: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Dec  3 15:27:00.449: INFO: Waiting deployment "test-recreate-deployment" to complete
Dec  3 15:27:00.459: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983620, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983620, loc:(*time.Location)(0x7ed1a20)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983620, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983620, loc:(*time.Location)(0x7ed1a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-6df85df6b9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 15:27:02.470: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Dec  3 15:27:02.491: INFO: Updating deployment test-recreate-deployment
Dec  3 15:27:02.491: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Dec  3 15:27:02.531: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-7236,SelfLink:/apis/apps/v1/namespaces/deployment-7236/deployments/test-recreate-deployment,UID:383e147d-e6ad-4c8c-85f1-fdf1c1ea1c71,ResourceVersion:14413,Generation:2,CreationTimestamp:2019-12-03 15:27:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-12-03 15:27:02 +0000 UTC 2019-12-03 15:27:02 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-12-03 15:27:02 +0000 UTC 2019-12-03 15:27:00 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-5c8c9cc69d" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Dec  3 15:27:02.542: INFO: New ReplicaSet "test-recreate-deployment-5c8c9cc69d" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5c8c9cc69d,GenerateName:,Namespace:deployment-7236,SelfLink:/apis/apps/v1/namespaces/deployment-7236/replicasets/test-recreate-deployment-5c8c9cc69d,UID:9775ef02-7590-4eed-bbbf-c8d805343d02,ResourceVersion:14412,Generation:1,CreationTimestamp:2019-12-03 15:27:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 383e147d-e6ad-4c8c-85f1-fdf1c1ea1c71 0xc001a0fb77 0xc001a0fb78}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  3 15:27:02.542: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Dec  3 15:27:02.542: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-6df85df6b9,GenerateName:,Namespace:deployment-7236,SelfLink:/apis/apps/v1/namespaces/deployment-7236/replicasets/test-recreate-deployment-6df85df6b9,UID:1a5d3ea7-bd41-4b12-8e15-347a6b73c2d0,ResourceVersion:14405,Generation:2,CreationTimestamp:2019-12-03 15:27:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 383e147d-e6ad-4c8c-85f1-fdf1c1ea1c71 0xc001a0fc47 0xc001a0fc48}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  3 15:27:02.552: INFO: Pod "test-recreate-deployment-5c8c9cc69d-8mqkw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5c8c9cc69d-8mqkw,GenerateName:test-recreate-deployment-5c8c9cc69d-,Namespace:deployment-7236,SelfLink:/api/v1/namespaces/deployment-7236/pods/test-recreate-deployment-5c8c9cc69d-8mqkw,UID:53e2b0a0-4a23-4431-96ca-39004b48b258,ResourceVersion:14414,Generation:0,CreationTimestamp:2019-12-03 15:27:02 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-5c8c9cc69d 9775ef02-7590-4eed-bbbf-c8d805343d02 0xc0031c2527 0xc0031c2528}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-llw2f {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-llw2f,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-llw2f true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0031c2590} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0031c25b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 15:27:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 15:27:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 15:27:02 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 15:27:02 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.3,PodIP:,StartTime:2019-12-03 15:27:02 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:27:02.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7236" for this suite.
Dec  3 15:27:08.602: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:27:08.990: INFO: namespace deployment-7236 deletion completed in 6.418627086s
•
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:27:08.990: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4240
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-803225e7-fbeb-4cf5-be6e-284a71cc9fd1
STEP: Creating a pod to test consume configMaps
Dec  3 15:27:09.196: INFO: Waiting up to 5m0s for pod "pod-configmaps-a60153eb-e0c9-4c4d-ad48-41890da96199" in namespace "configmap-4240" to be "success or failure"
Dec  3 15:27:09.205: INFO: Pod "pod-configmaps-a60153eb-e0c9-4c4d-ad48-41890da96199": Phase="Pending", Reason="", readiness=false. Elapsed: 9.332078ms
Dec  3 15:27:11.216: INFO: Pod "pod-configmaps-a60153eb-e0c9-4c4d-ad48-41890da96199": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020084581s
STEP: Saw pod success
Dec  3 15:27:11.216: INFO: Pod "pod-configmaps-a60153eb-e0c9-4c4d-ad48-41890da96199" satisfied condition "success or failure"
Dec  3 15:27:11.226: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod pod-configmaps-a60153eb-e0c9-4c4d-ad48-41890da96199 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 15:27:11.268: INFO: Waiting for pod pod-configmaps-a60153eb-e0c9-4c4d-ad48-41890da96199 to disappear
Dec  3 15:27:11.278: INFO: Pod pod-configmaps-a60153eb-e0c9-4c4d-ad48-41890da96199 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:27:11.278: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4240" for this suite.
Dec  3 15:27:17.327: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:27:17.743: INFO: namespace configmap-4240 deletion completed in 6.447917454s
•SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:27:17.744: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-8752
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Dec  3 15:27:28.090: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:27:28.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W1203 15:27:28.090643    5066 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-8752" for this suite.
Dec  3 15:27:34.131: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:27:34.512: INFO: namespace gc-8752 deletion completed in 6.411643794s
•SSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:27:34.513: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-8826
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-8826
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-8826
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-8826
Dec  3 15:27:34.735: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
Dec  3 15:27:44.747: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Dec  3 15:27:44.758: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8826 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  3 15:27:45.356: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Dec  3 15:27:45.356: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  3 15:27:45.356: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  3 15:27:45.366: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec  3 15:27:55.378: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  3 15:27:55.378: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 15:27:55.420: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999641s
Dec  3 15:27:56.431: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.989099181s
Dec  3 15:27:57.441: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.978237365s
Dec  3 15:27:58.452: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.967734601s
Dec  3 15:27:59.463: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.957095589s
Dec  3 15:28:00.474: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.945876566s
Dec  3 15:28:01.485: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.934944327s
Dec  3 15:28:02.497: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.924200149s
Dec  3 15:28:03.507: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.912660184s
Dec  3 15:28:04.518: INFO: Verifying statefulset ss doesn't scale past 1 for another 901.930037ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-8826
Dec  3 15:28:05.530: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8826 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 15:28:06.080: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Dec  3 15:28:06.080: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  3 15:28:06.080: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  3 15:28:06.091: INFO: Found 1 stateful pods, waiting for 3
Dec  3 15:28:16.102: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 15:28:16.102: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 15:28:16.102: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Dec  3 15:28:16.121: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8826 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  3 15:28:16.692: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Dec  3 15:28:16.692: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  3 15:28:16.692: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  3 15:28:16.692: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8826 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  3 15:28:17.278: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Dec  3 15:28:17.278: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  3 15:28:17.278: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  3 15:28:17.278: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8826 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  3 15:28:17.877: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Dec  3 15:28:17.877: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  3 15:28:17.877: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  3 15:28:17.877: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 15:28:17.887: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Dec  3 15:28:27.909: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  3 15:28:27.909: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec  3 15:28:27.909: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec  3 15:28:27.940: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999591s
Dec  3 15:28:28.951: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.989639073s
Dec  3 15:28:29.962: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.978604936s
Dec  3 15:28:30.973: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.967866048s
Dec  3 15:28:31.985: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.956705671s
Dec  3 15:28:32.996: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.945272204s
Dec  3 15:28:34.007: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.934352033s
Dec  3 15:28:35.019: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.922759946s
Dec  3 15:28:36.030: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.91137255s
Dec  3 15:28:37.042: INFO: Verifying statefulset ss doesn't scale past 3 for another 899.99403ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-8826
Dec  3 15:28:38.054: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8826 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 15:28:38.610: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Dec  3 15:28:38.610: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  3 15:28:38.610: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  3 15:28:38.610: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8826 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 15:28:39.215: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Dec  3 15:28:39.215: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  3 15:28:39.215: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  3 15:28:39.215: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8826 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 15:28:39.784: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Dec  3 15:28:39.784: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  3 15:28:39.784: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  3 15:28:39.784: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Dec  3 15:29:09.827: INFO: Deleting all statefulset in ns statefulset-8826
Dec  3 15:29:09.837: INFO: Scaling statefulset ss to 0
Dec  3 15:29:09.867: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 15:29:09.877: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:29:09.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8826" for this suite.
Dec  3 15:29:15.958: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:29:16.332: INFO: namespace statefulset-8826 deletion completed in 6.405863057s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:29:16.333: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-6495
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec  3 15:29:38.557: INFO: Container started at 2019-12-03 15:29:17 +0000 UTC, pod became ready at 2019-12-03 15:29:37 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:29:38.557: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6495" for this suite.
Dec  3 15:30:00.608: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:30:01.000: INFO: namespace container-probe-6495 deletion completed in 22.423965162s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:30:01.001: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2456
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a replication controller
Dec  3 15:30:01.183: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-2456'
Dec  3 15:30:01.398: INFO: stderr: ""
Dec  3 15:30:01.398: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  3 15:30:01.398: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2456'
Dec  3 15:30:01.508: INFO: stderr: ""
Dec  3 15:30:01.508: INFO: stdout: "update-demo-nautilus-687fw update-demo-nautilus-vblwn "
Dec  3 15:30:01.508: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-687fw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2456'
Dec  3 15:30:01.612: INFO: stderr: ""
Dec  3 15:30:01.612: INFO: stdout: ""
Dec  3 15:30:01.612: INFO: update-demo-nautilus-687fw is created but not running
Dec  3 15:30:06.612: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2456'
Dec  3 15:30:06.721: INFO: stderr: ""
Dec  3 15:30:06.721: INFO: stdout: "update-demo-nautilus-687fw update-demo-nautilus-vblwn "
Dec  3 15:30:06.722: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-687fw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2456'
Dec  3 15:30:06.823: INFO: stderr: ""
Dec  3 15:30:06.823: INFO: stdout: "true"
Dec  3 15:30:06.823: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-687fw -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2456'
Dec  3 15:30:06.928: INFO: stderr: ""
Dec  3 15:30:06.928: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  3 15:30:06.928: INFO: validating pod update-demo-nautilus-687fw
Dec  3 15:30:07.025: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 15:30:07.025: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 15:30:07.025: INFO: update-demo-nautilus-687fw is verified up and running
Dec  3 15:30:07.025: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-vblwn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2456'
Dec  3 15:30:07.132: INFO: stderr: ""
Dec  3 15:30:07.132: INFO: stdout: "true"
Dec  3 15:30:07.132: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-vblwn -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2456'
Dec  3 15:30:07.241: INFO: stderr: ""
Dec  3 15:30:07.241: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  3 15:30:07.241: INFO: validating pod update-demo-nautilus-vblwn
Dec  3 15:30:07.338: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 15:30:07.338: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 15:30:07.338: INFO: update-demo-nautilus-vblwn is verified up and running
STEP: using delete to clean up resources
Dec  3 15:30:07.339: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-2456'
Dec  3 15:30:07.461: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 15:30:07.461: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec  3 15:30:07.461: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get rc,svc -l name=update-demo --no-headers --namespace=kubectl-2456'
Dec  3 15:30:07.577: INFO: stderr: "No resources found.\n"
Dec  3 15:30:07.577: INFO: stdout: ""
Dec  3 15:30:07.577: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -l name=update-demo --namespace=kubectl-2456 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  3 15:30:07.681: INFO: stderr: ""
Dec  3 15:30:07.681: INFO: stdout: "update-demo-nautilus-687fw\nupdate-demo-nautilus-vblwn\n"
Dec  3 15:30:08.181: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get rc,svc -l name=update-demo --no-headers --namespace=kubectl-2456'
Dec  3 15:30:08.297: INFO: stderr: "No resources found.\n"
Dec  3 15:30:08.297: INFO: stdout: ""
Dec  3 15:30:08.297: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -l name=update-demo --namespace=kubectl-2456 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  3 15:30:08.411: INFO: stderr: ""
Dec  3 15:30:08.411: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:30:08.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2456" for this suite.
Dec  3 15:30:14.462: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:30:14.833: INFO: namespace kubectl-2456 deletion completed in 6.403697361s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:30:14.834: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-2812
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec  3 15:30:15.016: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:30:17.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2812" for this suite.
Dec  3 15:30:55.162: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:30:55.546: INFO: namespace pods-2812 deletion completed in 38.417933106s
•SSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:30:55.546: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-1069
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name s-test-opt-del-c70dd452-f7b3-4b86-9ec0-79f8007495b0
STEP: Creating secret with name s-test-opt-upd-99ca3f86-ef08-4d61-8d82-92df1d76e1c9
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-c70dd452-f7b3-4b86-9ec0-79f8007495b0
STEP: Updating secret s-test-opt-upd-99ca3f86-ef08-4d61-8d82-92df1d76e1c9
STEP: Creating secret with name s-test-opt-create-d1507ce0-d57f-4e04-97db-7194c07807a2
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:32:33.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1069" for this suite.
Dec  3 15:32:55.064: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:32:55.458: INFO: namespace secrets-1069 deletion completed in 22.425141151s
•SSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:32:55.458: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-1292
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Dec  3 15:32:56.189: INFO: Pod name wrapped-volume-race-94f427dd-8491-436f-ad27-52db01a52560: Found 1 pods out of 5
Dec  3 15:33:01.212: INFO: Pod name wrapped-volume-race-94f427dd-8491-436f-ad27-52db01a52560: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-94f427dd-8491-436f-ad27-52db01a52560 in namespace emptydir-wrapper-1292, will wait for the garbage collector to delete the pods
Dec  3 15:33:01.338: INFO: Deleting ReplicationController wrapped-volume-race-94f427dd-8491-436f-ad27-52db01a52560 took: 13.358516ms
Dec  3 15:33:01.839: INFO: Terminating ReplicationController wrapped-volume-race-94f427dd-8491-436f-ad27-52db01a52560 pods took: 500.330695ms
STEP: Creating RC which spawns configmap-volume pods
Dec  3 15:33:43.275: INFO: Pod name wrapped-volume-race-d9d1fbf7-ed63-4f05-a9e0-672caf0cbc52: Found 0 pods out of 5
Dec  3 15:33:48.296: INFO: Pod name wrapped-volume-race-d9d1fbf7-ed63-4f05-a9e0-672caf0cbc52: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-d9d1fbf7-ed63-4f05-a9e0-672caf0cbc52 in namespace emptydir-wrapper-1292, will wait for the garbage collector to delete the pods
Dec  3 15:33:48.426: INFO: Deleting ReplicationController wrapped-volume-race-d9d1fbf7-ed63-4f05-a9e0-672caf0cbc52 took: 15.398017ms
Dec  3 15:33:50.726: INFO: Terminating ReplicationController wrapped-volume-race-d9d1fbf7-ed63-4f05-a9e0-672caf0cbc52 pods took: 2.300307049s
STEP: Creating RC which spawns configmap-volume pods
Dec  3 15:34:33.264: INFO: Pod name wrapped-volume-race-f6107ee9-1572-4e00-b4bc-3ee026486264: Found 0 pods out of 5
Dec  3 15:34:38.284: INFO: Pod name wrapped-volume-race-f6107ee9-1572-4e00-b4bc-3ee026486264: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-f6107ee9-1572-4e00-b4bc-3ee026486264 in namespace emptydir-wrapper-1292, will wait for the garbage collector to delete the pods
Dec  3 15:34:38.413: INFO: Deleting ReplicationController wrapped-volume-race-f6107ee9-1572-4e00-b4bc-3ee026486264 took: 15.580795ms
Dec  3 15:34:38.513: INFO: Terminating ReplicationController wrapped-volume-race-f6107ee9-1572-4e00-b4bc-3ee026486264 pods took: 100.291675ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:35:23.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-1292" for this suite.
Dec  3 15:35:29.763: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:35:30.148: INFO: namespace emptydir-wrapper-1292 deletion completed in 6.417262876s
•SSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:35:30.149: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-5792
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:35:32.398: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-5792" for this suite.
Dec  3 15:35:54.448: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:35:54.835: INFO: namespace replication-controller-5792 deletion completed in 22.418959335s
•
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:35:54.835: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4990
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name cm-test-opt-del-96efcff5-28dc-444c-94bc-40e6831744ac
STEP: Creating configMap with name cm-test-opt-upd-ced76b1c-4322-45ee-92d6-37cdc16ee390
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-96efcff5-28dc-444c-94bc-40e6831744ac
STEP: Updating configmap cm-test-opt-upd-ced76b1c-4322-45ee-92d6-37cdc16ee390
STEP: Creating configMap with name cm-test-opt-create-7c8ccfd3-2afe-4602-8b2a-f9a9c2e7f851
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:35:59.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4990" for this suite.
Dec  3 15:36:21.493: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:36:21.909: INFO: namespace configmap-4990 deletion completed in 22.446520674s
•SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:36:21.909: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-174
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec  3 15:36:22.109: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c0602ca9-e52d-4dbd-9053-b3c07422332c" in namespace "downward-api-174" to be "success or failure"
Dec  3 15:36:22.119: INFO: Pod "downwardapi-volume-c0602ca9-e52d-4dbd-9053-b3c07422332c": Phase="Pending", Reason="", readiness=false. Elapsed: 9.855215ms
Dec  3 15:36:24.130: INFO: Pod "downwardapi-volume-c0602ca9-e52d-4dbd-9053-b3c07422332c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021218382s
STEP: Saw pod success
Dec  3 15:36:24.131: INFO: Pod "downwardapi-volume-c0602ca9-e52d-4dbd-9053-b3c07422332c" satisfied condition "success or failure"
Dec  3 15:36:24.141: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod downwardapi-volume-c0602ca9-e52d-4dbd-9053-b3c07422332c container client-container: <nil>
STEP: delete the pod
Dec  3 15:36:24.173: INFO: Waiting for pod downwardapi-volume-c0602ca9-e52d-4dbd-9053-b3c07422332c to disappear
Dec  3 15:36:24.183: INFO: Pod downwardapi-volume-c0602ca9-e52d-4dbd-9053-b3c07422332c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:36:24.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-174" for this suite.
Dec  3 15:36:30.233: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:36:30.621: INFO: namespace downward-api-174 deletion completed in 6.419108334s
•SSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:36:30.621: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4495
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-5b89fc13-f5f3-4599-90df-5d0391662155
STEP: Creating a pod to test consume secrets
Dec  3 15:36:30.826: INFO: Waiting up to 5m0s for pod "pod-secrets-2085a642-4af7-47e2-b454-0aa53b19161b" in namespace "secrets-4495" to be "success or failure"
Dec  3 15:36:30.836: INFO: Pod "pod-secrets-2085a642-4af7-47e2-b454-0aa53b19161b": Phase="Pending", Reason="", readiness=false. Elapsed: 9.398158ms
Dec  3 15:36:32.851: INFO: Pod "pod-secrets-2085a642-4af7-47e2-b454-0aa53b19161b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.024772691s
STEP: Saw pod success
Dec  3 15:36:32.851: INFO: Pod "pod-secrets-2085a642-4af7-47e2-b454-0aa53b19161b" satisfied condition "success or failure"
Dec  3 15:36:32.862: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod pod-secrets-2085a642-4af7-47e2-b454-0aa53b19161b container secret-volume-test: <nil>
STEP: delete the pod
Dec  3 15:36:32.894: INFO: Waiting for pod pod-secrets-2085a642-4af7-47e2-b454-0aa53b19161b to disappear
Dec  3 15:36:32.904: INFO: Pod pod-secrets-2085a642-4af7-47e2-b454-0aa53b19161b no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:36:32.904: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4495" for this suite.
Dec  3 15:36:38.953: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:36:39.383: INFO: namespace secrets-4495 deletion completed in 6.460918976s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:36:39.384: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-9397
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: Gathering metrics
Dec  3 15:36:39.641: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
W1203 15:36:39.641316    5066 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  3 15:36:39.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9397" for this suite.
Dec  3 15:36:45.683: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:36:46.106: INFO: namespace gc-9397 deletion completed in 6.454583549s
•SSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:36:46.106: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-9262
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-9262, will wait for the garbage collector to delete the pods
Dec  3 15:36:48.385: INFO: Deleting Job.batch foo took: 13.290804ms
Dec  3 15:36:48.485: INFO: Terminating Job.batch foo pods took: 100.274659ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:37:33.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-9262" for this suite.
Dec  3 15:37:39.147: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:37:39.536: INFO: namespace job-9262 deletion completed in 6.421886086s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:37:39.536: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-2120
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec  3 15:37:39.789: INFO: Create a RollingUpdate DaemonSet
Dec  3 15:37:39.800: INFO: Check that daemon pods launch on every node of the cluster
Dec  3 15:37:39.821: INFO: Number of nodes with available pods: 0
Dec  3 15:37:39.821: INFO: Node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 is running more than one daemon pod
Dec  3 15:37:40.864: INFO: Number of nodes with available pods: 0
Dec  3 15:37:40.864: INFO: Node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 is running more than one daemon pod
Dec  3 15:37:41.853: INFO: Number of nodes with available pods: 2
Dec  3 15:37:41.853: INFO: Number of running nodes: 2, number of available pods: 2
Dec  3 15:37:41.853: INFO: Update the DaemonSet to trigger a rollout
Dec  3 15:37:41.873: INFO: Updating DaemonSet daemon-set
Dec  3 15:37:46.926: INFO: Roll back the DaemonSet before rollout is complete
Dec  3 15:37:46.947: INFO: Updating DaemonSet daemon-set
Dec  3 15:37:46.947: INFO: Make sure DaemonSet rollback is complete
Dec  3 15:37:46.957: INFO: Wrong image for pod: daemon-set-cwtwh. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Dec  3 15:37:46.957: INFO: Pod daemon-set-cwtwh is not available
Dec  3 15:37:47.978: INFO: Wrong image for pod: daemon-set-cwtwh. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Dec  3 15:37:47.978: INFO: Pod daemon-set-cwtwh is not available
Dec  3 15:37:48.979: INFO: Wrong image for pod: daemon-set-cwtwh. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Dec  3 15:37:48.979: INFO: Pod daemon-set-cwtwh is not available
Dec  3 15:37:49.981: INFO: Wrong image for pod: daemon-set-cwtwh. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Dec  3 15:37:49.981: INFO: Pod daemon-set-cwtwh is not available
Dec  3 15:37:50.979: INFO: Wrong image for pod: daemon-set-cwtwh. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Dec  3 15:37:50.979: INFO: Pod daemon-set-cwtwh is not available
Dec  3 15:37:51.980: INFO: Pod daemon-set-thpwf is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2120, will wait for the garbage collector to delete the pods
Dec  3 15:37:52.093: INFO: Deleting DaemonSet.extensions daemon-set took: 12.711847ms
Dec  3 15:37:52.193: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.42674ms
Dec  3 15:39:01.104: INFO: Number of nodes with available pods: 0
Dec  3 15:39:01.104: INFO: Number of running nodes: 0, number of available pods: 0
Dec  3 15:39:01.114: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-2120/daemonsets","resourceVersion":"17033"},"items":null}

Dec  3 15:39:01.125: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-2120/pods","resourceVersion":"17033"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:39:01.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2120" for this suite.
Dec  3 15:39:07.209: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:39:07.601: INFO: namespace daemonsets-2120 deletion completed in 6.424214491s
•SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:39:07.602: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-8380
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Dec  3 15:39:07.804: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:39:08.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-8380" for this suite.
Dec  3 15:39:14.907: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:39:15.290: INFO: namespace replication-controller-8380 deletion completed in 6.414370728s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:39:15.291: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-2838
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test substitution in container's args
Dec  3 15:39:15.632: INFO: Waiting up to 5m0s for pod "var-expansion-13ac5110-87fb-400f-b208-127ab47bebee" in namespace "var-expansion-2838" to be "success or failure"
Dec  3 15:39:15.642: INFO: Pod "var-expansion-13ac5110-87fb-400f-b208-127ab47bebee": Phase="Pending", Reason="", readiness=false. Elapsed: 9.494242ms
Dec  3 15:39:17.652: INFO: Pod "var-expansion-13ac5110-87fb-400f-b208-127ab47bebee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0201416s
STEP: Saw pod success
Dec  3 15:39:17.652: INFO: Pod "var-expansion-13ac5110-87fb-400f-b208-127ab47bebee" satisfied condition "success or failure"
Dec  3 15:39:17.662: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod var-expansion-13ac5110-87fb-400f-b208-127ab47bebee container dapi-container: <nil>
STEP: delete the pod
Dec  3 15:39:17.697: INFO: Waiting for pod var-expansion-13ac5110-87fb-400f-b208-127ab47bebee to disappear
Dec  3 15:39:17.706: INFO: Pod var-expansion-13ac5110-87fb-400f-b208-127ab47bebee no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:39:17.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2838" for this suite.
Dec  3 15:39:23.755: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:39:24.143: INFO: namespace var-expansion-2838 deletion completed in 6.419396141s
•SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:39:24.144: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3620
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-73d697b7-d986-4e0b-b609-6ae97bb4fa61
STEP: Creating a pod to test consume configMaps
Dec  3 15:39:24.349: INFO: Waiting up to 5m0s for pod "pod-configmaps-135442c9-4c49-4ff9-b7bf-6e7f1223938a" in namespace "configmap-3620" to be "success or failure"
Dec  3 15:39:24.359: INFO: Pod "pod-configmaps-135442c9-4c49-4ff9-b7bf-6e7f1223938a": Phase="Pending", Reason="", readiness=false. Elapsed: 9.662857ms
Dec  3 15:39:26.370: INFO: Pod "pod-configmaps-135442c9-4c49-4ff9-b7bf-6e7f1223938a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020749899s
STEP: Saw pod success
Dec  3 15:39:26.370: INFO: Pod "pod-configmaps-135442c9-4c49-4ff9-b7bf-6e7f1223938a" satisfied condition "success or failure"
Dec  3 15:39:26.380: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod pod-configmaps-135442c9-4c49-4ff9-b7bf-6e7f1223938a container configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 15:39:26.412: INFO: Waiting for pod pod-configmaps-135442c9-4c49-4ff9-b7bf-6e7f1223938a to disappear
Dec  3 15:39:26.421: INFO: Pod pod-configmaps-135442c9-4c49-4ff9-b7bf-6e7f1223938a no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:39:26.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3620" for this suite.
Dec  3 15:39:32.471: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:39:32.853: INFO: namespace configmap-3620 deletion completed in 6.412413166s
•SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:39:32.853: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5913
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec  3 15:39:33.049: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e0650a4b-9836-4013-981d-f4c082fc783a" in namespace "projected-5913" to be "success or failure"
Dec  3 15:39:33.059: INFO: Pod "downwardapi-volume-e0650a4b-9836-4013-981d-f4c082fc783a": Phase="Pending", Reason="", readiness=false. Elapsed: 9.833777ms
Dec  3 15:39:35.070: INFO: Pod "downwardapi-volume-e0650a4b-9836-4013-981d-f4c082fc783a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020888948s
STEP: Saw pod success
Dec  3 15:39:35.070: INFO: Pod "downwardapi-volume-e0650a4b-9836-4013-981d-f4c082fc783a" satisfied condition "success or failure"
Dec  3 15:39:35.080: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod downwardapi-volume-e0650a4b-9836-4013-981d-f4c082fc783a container client-container: <nil>
STEP: delete the pod
Dec  3 15:39:35.112: INFO: Waiting for pod downwardapi-volume-e0650a4b-9836-4013-981d-f4c082fc783a to disappear
Dec  3 15:39:35.122: INFO: Pod downwardapi-volume-e0650a4b-9836-4013-981d-f4c082fc783a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:39:35.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5913" for this suite.
Dec  3 15:39:41.171: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:39:41.594: INFO: namespace projected-5913 deletion completed in 6.45392864s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:39:41.594: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-3191
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Dec  3 15:39:41.778: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec  3 15:39:41.799: INFO: Waiting for terminating namespaces to be deleted...
Dec  3 15:39:41.809: INFO: 
Logging pods the kubelet thinks is on node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 before test
Dec  3 15:39:41.833: INFO: metrics-server-5bd76bb595-8pxkg from kube-system started at 2019-12-03 14:26:43 +0000 UTC (1 container statuses recorded)
Dec  3 15:39:41.833: INFO: 	Container metrics-server ready: true, restart count 0
Dec  3 15:39:41.833: INFO: calico-kube-controllers-5d785bc598-8q48p from kube-system started at 2019-12-03 14:26:43 +0000 UTC (1 container statuses recorded)
Dec  3 15:39:41.833: INFO: 	Container calico-kube-controllers ready: true, restart count 2
Dec  3 15:39:41.833: INFO: addons-nginx-ingress-controller-8468678b64-lvtp6 from kube-system started at 2019-12-03 14:26:43 +0000 UTC (1 container statuses recorded)
Dec  3 15:39:41.833: INFO: 	Container nginx-ingress-controller ready: true, restart count 1
Dec  3 15:39:41.833: INFO: node-exporter-42tbw from kube-system started at 2019-12-03 14:26:23 +0000 UTC (1 container statuses recorded)
Dec  3 15:39:41.833: INFO: 	Container node-exporter ready: true, restart count 0
Dec  3 15:39:41.833: INFO: kube-proxy-kst5c from kube-system started at 2019-12-03 14:26:23 +0000 UTC (1 container statuses recorded)
Dec  3 15:39:41.833: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  3 15:39:41.833: INFO: coredns-858b686868-btwxc from kube-system started at 2019-12-03 14:26:43 +0000 UTC (1 container statuses recorded)
Dec  3 15:39:41.833: INFO: 	Container coredns ready: true, restart count 0
Dec  3 15:39:41.833: INFO: node-problem-detector-c9sgc from kube-system started at 2019-12-03 14:26:23 +0000 UTC (1 container statuses recorded)
Dec  3 15:39:41.833: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec  3 15:39:41.833: INFO: calico-node-s9glf from kube-system started at 2019-12-03 14:26:23 +0000 UTC (1 container statuses recorded)
Dec  3 15:39:41.833: INFO: 	Container calico-node ready: true, restart count 0
Dec  3 15:39:41.833: INFO: 
Logging pods the kubelet thinks is on node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-r5glw before test
Dec  3 15:39:41.886: INFO: blackbox-exporter-c87bdd467-v9ddq from kube-system started at 2019-12-03 14:26:21 +0000 UTC (1 container statuses recorded)
Dec  3 15:39:41.886: INFO: 	Container blackbox-exporter ready: true, restart count 0
Dec  3 15:39:41.886: INFO: vpn-shoot-5f48c598df-dqjlc from kube-system started at 2019-12-03 14:26:42 +0000 UTC (1 container statuses recorded)
Dec  3 15:39:41.886: INFO: 	Container vpn-shoot ready: true, restart count 0
Dec  3 15:39:41.887: INFO: node-problem-detector-fbcm4 from kube-system started at 2019-12-03 14:26:21 +0000 UTC (1 container statuses recorded)
Dec  3 15:39:41.887: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec  3 15:39:41.887: INFO: coredns-858b686868-2fkln from kube-system started at 2019-12-03 14:26:43 +0000 UTC (1 container statuses recorded)
Dec  3 15:39:41.887: INFO: 	Container coredns ready: true, restart count 0
Dec  3 15:39:41.887: INFO: calico-node-529d5 from kube-system started at 2019-12-03 14:26:21 +0000 UTC (1 container statuses recorded)
Dec  3 15:39:41.887: INFO: 	Container calico-node ready: true, restart count 0
Dec  3 15:39:41.887: INFO: calico-typha-horizontal-autoscaler-554dfbfdd7-qwhfp from kube-system started at 2019-12-03 14:26:42 +0000 UTC (1 container statuses recorded)
Dec  3 15:39:41.887: INFO: 	Container autoscaler ready: true, restart count 0
Dec  3 15:39:41.887: INFO: calico-typha-deploy-5547c4cdc6-959hd from kube-system started at 2019-12-03 14:29:04 +0000 UTC (1 container statuses recorded)
Dec  3 15:39:41.887: INFO: 	Container calico-typha ready: true, restart count 0
Dec  3 15:39:41.887: INFO: calico-typha-vertical-autoscaler-656557779f-zz2kh from kube-system started at 2019-12-03 14:26:43 +0000 UTC (1 container statuses recorded)
Dec  3 15:39:41.887: INFO: 	Container autoscaler ready: true, restart count 4
Dec  3 15:39:41.887: INFO: addons-kubernetes-dashboard-5c8d9945bc-6v6wm from kube-system started at 2019-12-03 14:26:43 +0000 UTC (1 container statuses recorded)
Dec  3 15:39:41.887: INFO: 	Container kubernetes-dashboard ready: true, restart count 1
Dec  3 15:39:41.887: INFO: node-exporter-6lmwr from kube-system started at 2019-12-03 14:26:21 +0000 UTC (1 container statuses recorded)
Dec  3 15:39:41.887: INFO: 	Container node-exporter ready: true, restart count 0
Dec  3 15:39:41.887: INFO: kube-proxy-v4sb9 from kube-system started at 2019-12-03 14:26:21 +0000 UTC (1 container statuses recorded)
Dec  3 15:39:41.887: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  3 15:39:41.887: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-88d6cff74-mp2kz from kube-system started at 2019-12-03 14:26:42 +0000 UTC (1 container statuses recorded)
Dec  3 15:39:41.887: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-acb56fdf-0e20-4715-ba2d-d02c6a30442a 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-acb56fdf-0e20-4715-ba2d-d02c6a30442a off the node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9
STEP: verifying the node doesn't have the label kubernetes.io/e2e-acb56fdf-0e20-4715-ba2d-d02c6a30442a
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:39:46.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-3191" for this suite.
Dec  3 15:40:04.081: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:40:04.464: INFO: namespace sched-pred-3191 deletion completed in 18.413756378s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72
•SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:40:04.464: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in prestop-6623
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating server pod server in namespace prestop-6623
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-6623
STEP: Deleting pre-stop pod
Dec  3 15:40:15.836: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:40:15.848: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-6623" for this suite.
Dec  3 15:40:53.897: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:40:54.284: INFO: namespace prestop-6623 deletion completed in 38.419004779s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:40:54.285: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-2570
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating pod
Dec  3 15:40:56.519: INFO: Pod pod-hostip-6da6466d-d3ac-4a9e-b864-b1e8b1d56bf1 has hostIP: 10.250.0.3
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:40:56.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2570" for this suite.
Dec  3 15:41:18.575: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:41:18.960: INFO: namespace pods-2570 deletion completed in 22.420062274s
•SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:41:18.961: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2166
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir volume type on tmpfs
Dec  3 15:41:19.159: INFO: Waiting up to 5m0s for pod "pod-0ffabda5-0290-450a-8938-fb160ac57805" in namespace "emptydir-2166" to be "success or failure"
Dec  3 15:41:19.168: INFO: Pod "pod-0ffabda5-0290-450a-8938-fb160ac57805": Phase="Pending", Reason="", readiness=false. Elapsed: 9.401395ms
Dec  3 15:41:21.179: INFO: Pod "pod-0ffabda5-0290-450a-8938-fb160ac57805": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019969787s
STEP: Saw pod success
Dec  3 15:41:21.179: INFO: Pod "pod-0ffabda5-0290-450a-8938-fb160ac57805" satisfied condition "success or failure"
Dec  3 15:41:21.189: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod pod-0ffabda5-0290-450a-8938-fb160ac57805 container test-container: <nil>
STEP: delete the pod
Dec  3 15:41:21.223: INFO: Waiting for pod pod-0ffabda5-0290-450a-8938-fb160ac57805 to disappear
Dec  3 15:41:21.233: INFO: Pod pod-0ffabda5-0290-450a-8938-fb160ac57805 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:41:21.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2166" for this suite.
Dec  3 15:41:27.283: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:41:27.703: INFO: namespace emptydir-2166 deletion completed in 6.451956895s
•SSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:41:27.704: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-2473
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating service multi-endpoint-test in namespace services-2473
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2473 to expose endpoints map[]
Dec  3 15:41:27.910: INFO: successfully validated that service multi-endpoint-test in namespace services-2473 exposes endpoints map[] (9.443584ms elapsed)
STEP: Creating pod pod1 in namespace services-2473
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2473 to expose endpoints map[pod1:[100]]
Dec  3 15:41:29.984: INFO: successfully validated that service multi-endpoint-test in namespace services-2473 exposes endpoints map[pod1:[100]] (2.060778306s elapsed)
STEP: Creating pod pod2 in namespace services-2473
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2473 to expose endpoints map[pod1:[100] pod2:[101]]
Dec  3 15:41:33.117: INFO: successfully validated that service multi-endpoint-test in namespace services-2473 exposes endpoints map[pod1:[100] pod2:[101]] (3.121727737s elapsed)
STEP: Deleting pod pod1 in namespace services-2473
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2473 to expose endpoints map[pod2:[101]]
Dec  3 15:41:33.148: INFO: successfully validated that service multi-endpoint-test in namespace services-2473 exposes endpoints map[pod2:[101]] (19.722763ms elapsed)
STEP: Deleting pod pod2 in namespace services-2473
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2473 to expose endpoints map[]
Dec  3 15:41:33.169: INFO: successfully validated that service multi-endpoint-test in namespace services-2473 exposes endpoints map[] (9.627166ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:41:33.189: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2473" for this suite.
Dec  3 15:41:55.240: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:41:55.630: INFO: namespace services-2473 deletion completed in 22.421854057s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92
•SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:41:55.630: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8693
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating Redis RC
Dec  3 15:41:55.816: INFO: namespace kubectl-8693
Dec  3 15:41:55.816: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-8693'
Dec  3 15:41:56.268: INFO: stderr: ""
Dec  3 15:41:56.268: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec  3 15:41:57.279: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 15:41:57.279: INFO: Found 0 / 1
Dec  3 15:41:58.279: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 15:41:58.279: INFO: Found 1 / 1
Dec  3 15:41:58.279: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec  3 15:41:58.289: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 15:41:58.289: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec  3 15:41:58.289: INFO: wait on redis-master startup in kubectl-8693 
Dec  3 15:41:58.289: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs redis-master-nvwd8 redis-master --namespace=kubectl-8693'
Dec  3 15:41:58.420: INFO: stderr: ""
Dec  3 15:41:58.420: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 03 Dec 15:41:57.235 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 03 Dec 15:41:57.235 # Server started, Redis version 3.2.12\n1:M 03 Dec 15:41:57.235 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 03 Dec 15:41:57.235 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Dec  3 15:41:58.420: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-8693'
Dec  3 15:41:58.551: INFO: stderr: ""
Dec  3 15:41:58.551: INFO: stdout: "service/rm2 exposed\n"
Dec  3 15:41:58.561: INFO: Service rm2 in namespace kubectl-8693 found.
STEP: exposing service
Dec  3 15:42:00.582: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-8693'
Dec  3 15:42:00.702: INFO: stderr: ""
Dec  3 15:42:00.702: INFO: stdout: "service/rm3 exposed\n"
Dec  3 15:42:00.711: INFO: Service rm3 in namespace kubectl-8693 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:42:02.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8693" for this suite.
Dec  3 15:42:24.783: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:42:25.164: INFO: namespace kubectl-8693 deletion completed in 22.412323362s
•SS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:42:25.164: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-1493
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Dec  3 15:42:25.347: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:42:29.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1493" for this suite.
Dec  3 15:42:51.497: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:42:51.881: INFO: namespace init-container-1493 deletion completed in 22.416465279s
•SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:42:51.881: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-392
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Dec  3 15:43:02.139: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1203 15:43:02.139076    5066 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:43:02.139: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-392" for this suite.
Dec  3 15:43:08.181: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:43:08.570: INFO: namespace gc-392 deletion completed in 6.419997316s
•SSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:43:08.570: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9033
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-566af18d-6791-413e-a6c2-0f6e7a8781cd
STEP: Creating a pod to test consume configMaps
Dec  3 15:43:08.781: INFO: Waiting up to 5m0s for pod "pod-configmaps-55be6434-bcd2-4d56-b83b-315b92637cae" in namespace "configmap-9033" to be "success or failure"
Dec  3 15:43:08.791: INFO: Pod "pod-configmaps-55be6434-bcd2-4d56-b83b-315b92637cae": Phase="Pending", Reason="", readiness=false. Elapsed: 10.172533ms
Dec  3 15:43:10.802: INFO: Pod "pod-configmaps-55be6434-bcd2-4d56-b83b-315b92637cae": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020880112s
STEP: Saw pod success
Dec  3 15:43:10.802: INFO: Pod "pod-configmaps-55be6434-bcd2-4d56-b83b-315b92637cae" satisfied condition "success or failure"
Dec  3 15:43:10.812: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod pod-configmaps-55be6434-bcd2-4d56-b83b-315b92637cae container configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 15:43:10.844: INFO: Waiting for pod pod-configmaps-55be6434-bcd2-4d56-b83b-315b92637cae to disappear
Dec  3 15:43:10.854: INFO: Pod pod-configmaps-55be6434-bcd2-4d56-b83b-315b92637cae no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:43:10.854: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9033" for this suite.
Dec  3 15:43:16.904: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:43:17.287: INFO: namespace configmap-9033 deletion completed in 6.41481191s
•SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:43:17.287: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-4279
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:43:22.961: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-4279" for this suite.
Dec  3 15:43:29.121: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:43:29.507: INFO: namespace watch-4279 deletion completed in 6.495172257s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:43:29.507: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3325
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-upd-6da7ede5-dc7e-44b4-a2f7-a4b87f690d37
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-6da7ede5-dc7e-44b4-a2f7-a4b87f690d37
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:43:33.873: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3325" for this suite.
Dec  3 15:43:55.922: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:43:56.304: INFO: namespace configmap-3325 deletion completed in 22.412702927s
•SSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:43:56.304: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-389
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Dec  3 15:43:56.488: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec  3 15:43:56.509: INFO: Waiting for terminating namespaces to be deleted...
Dec  3 15:43:56.519: INFO: 
Logging pods the kubelet thinks is on node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 before test
Dec  3 15:43:56.536: INFO: calico-kube-controllers-5d785bc598-8q48p from kube-system started at 2019-12-03 14:26:43 +0000 UTC (1 container statuses recorded)
Dec  3 15:43:56.536: INFO: 	Container calico-kube-controllers ready: true, restart count 2
Dec  3 15:43:56.536: INFO: addons-nginx-ingress-controller-8468678b64-lvtp6 from kube-system started at 2019-12-03 14:26:43 +0000 UTC (1 container statuses recorded)
Dec  3 15:43:56.536: INFO: 	Container nginx-ingress-controller ready: true, restart count 1
Dec  3 15:43:56.536: INFO: node-exporter-42tbw from kube-system started at 2019-12-03 14:26:23 +0000 UTC (1 container statuses recorded)
Dec  3 15:43:56.536: INFO: 	Container node-exporter ready: true, restart count 0
Dec  3 15:43:56.536: INFO: node-problem-detector-c9sgc from kube-system started at 2019-12-03 14:26:23 +0000 UTC (1 container statuses recorded)
Dec  3 15:43:56.536: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec  3 15:43:56.536: INFO: calico-node-s9glf from kube-system started at 2019-12-03 14:26:23 +0000 UTC (1 container statuses recorded)
Dec  3 15:43:56.536: INFO: 	Container calico-node ready: true, restart count 0
Dec  3 15:43:56.536: INFO: kube-proxy-kst5c from kube-system started at 2019-12-03 14:26:23 +0000 UTC (1 container statuses recorded)
Dec  3 15:43:56.536: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  3 15:43:56.536: INFO: coredns-858b686868-btwxc from kube-system started at 2019-12-03 14:26:43 +0000 UTC (1 container statuses recorded)
Dec  3 15:43:56.536: INFO: 	Container coredns ready: true, restart count 0
Dec  3 15:43:56.536: INFO: metrics-server-5bd76bb595-8pxkg from kube-system started at 2019-12-03 14:26:43 +0000 UTC (1 container statuses recorded)
Dec  3 15:43:56.536: INFO: 	Container metrics-server ready: true, restart count 0
Dec  3 15:43:56.536: INFO: 
Logging pods the kubelet thinks is on node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-r5glw before test
Dec  3 15:43:56.584: INFO: node-exporter-6lmwr from kube-system started at 2019-12-03 14:26:21 +0000 UTC (1 container statuses recorded)
Dec  3 15:43:56.584: INFO: 	Container node-exporter ready: true, restart count 0
Dec  3 15:43:56.584: INFO: kube-proxy-v4sb9 from kube-system started at 2019-12-03 14:26:21 +0000 UTC (1 container statuses recorded)
Dec  3 15:43:56.584: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  3 15:43:56.584: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-88d6cff74-mp2kz from kube-system started at 2019-12-03 14:26:42 +0000 UTC (1 container statuses recorded)
Dec  3 15:43:56.584: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Dec  3 15:43:56.584: INFO: vpn-shoot-5f48c598df-dqjlc from kube-system started at 2019-12-03 14:26:42 +0000 UTC (1 container statuses recorded)
Dec  3 15:43:56.584: INFO: 	Container vpn-shoot ready: true, restart count 0
Dec  3 15:43:56.584: INFO: blackbox-exporter-c87bdd467-v9ddq from kube-system started at 2019-12-03 14:26:21 +0000 UTC (1 container statuses recorded)
Dec  3 15:43:56.584: INFO: 	Container blackbox-exporter ready: true, restart count 0
Dec  3 15:43:56.584: INFO: coredns-858b686868-2fkln from kube-system started at 2019-12-03 14:26:43 +0000 UTC (1 container statuses recorded)
Dec  3 15:43:56.584: INFO: 	Container coredns ready: true, restart count 0
Dec  3 15:43:56.584: INFO: node-problem-detector-fbcm4 from kube-system started at 2019-12-03 14:26:21 +0000 UTC (1 container statuses recorded)
Dec  3 15:43:56.584: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec  3 15:43:56.584: INFO: calico-typha-horizontal-autoscaler-554dfbfdd7-qwhfp from kube-system started at 2019-12-03 14:26:42 +0000 UTC (1 container statuses recorded)
Dec  3 15:43:56.584: INFO: 	Container autoscaler ready: true, restart count 0
Dec  3 15:43:56.584: INFO: calico-typha-deploy-5547c4cdc6-959hd from kube-system started at 2019-12-03 14:29:04 +0000 UTC (1 container statuses recorded)
Dec  3 15:43:56.584: INFO: 	Container calico-typha ready: true, restart count 0
Dec  3 15:43:56.584: INFO: calico-node-529d5 from kube-system started at 2019-12-03 14:26:21 +0000 UTC (1 container statuses recorded)
Dec  3 15:43:56.584: INFO: 	Container calico-node ready: true, restart count 0
Dec  3 15:43:56.584: INFO: addons-kubernetes-dashboard-5c8d9945bc-6v6wm from kube-system started at 2019-12-03 14:26:43 +0000 UTC (1 container statuses recorded)
Dec  3 15:43:56.584: INFO: 	Container kubernetes-dashboard ready: true, restart count 1
Dec  3 15:43:56.584: INFO: calico-typha-vertical-autoscaler-656557779f-zz2kh from kube-system started at 2019-12-03 14:26:43 +0000 UTC (1 container statuses recorded)
Dec  3 15:43:56.584: INFO: 	Container autoscaler ready: true, restart count 4
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: verifying the node has the label node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9
STEP: verifying the node has the label node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-r5glw
Dec  3 15:43:56.656: INFO: Pod addons-kubernetes-dashboard-5c8d9945bc-6v6wm requesting resource cpu=50m on Node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-r5glw
Dec  3 15:43:56.656: INFO: Pod addons-nginx-ingress-controller-8468678b64-lvtp6 requesting resource cpu=100m on Node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9
Dec  3 15:43:56.656: INFO: Pod addons-nginx-ingress-nginx-ingress-k8s-backend-88d6cff74-mp2kz requesting resource cpu=0m on Node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-r5glw
Dec  3 15:43:56.656: INFO: Pod blackbox-exporter-c87bdd467-v9ddq requesting resource cpu=5m on Node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-r5glw
Dec  3 15:43:56.656: INFO: Pod calico-kube-controllers-5d785bc598-8q48p requesting resource cpu=0m on Node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9
Dec  3 15:43:56.656: INFO: Pod calico-node-529d5 requesting resource cpu=100m on Node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-r5glw
Dec  3 15:43:56.656: INFO: Pod calico-node-s9glf requesting resource cpu=100m on Node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9
Dec  3 15:43:56.656: INFO: Pod calico-typha-deploy-5547c4cdc6-959hd requesting resource cpu=0m on Node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-r5glw
Dec  3 15:43:56.656: INFO: Pod calico-typha-horizontal-autoscaler-554dfbfdd7-qwhfp requesting resource cpu=10m on Node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-r5glw
Dec  3 15:43:56.656: INFO: Pod calico-typha-vertical-autoscaler-656557779f-zz2kh requesting resource cpu=0m on Node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-r5glw
Dec  3 15:43:56.656: INFO: Pod coredns-858b686868-2fkln requesting resource cpu=50m on Node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-r5glw
Dec  3 15:43:56.656: INFO: Pod coredns-858b686868-btwxc requesting resource cpu=50m on Node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9
Dec  3 15:43:56.656: INFO: Pod kube-proxy-kst5c requesting resource cpu=20m on Node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9
Dec  3 15:43:56.656: INFO: Pod kube-proxy-v4sb9 requesting resource cpu=20m on Node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-r5glw
Dec  3 15:43:56.656: INFO: Pod metrics-server-5bd76bb595-8pxkg requesting resource cpu=20m on Node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9
Dec  3 15:43:56.656: INFO: Pod node-exporter-42tbw requesting resource cpu=5m on Node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9
Dec  3 15:43:56.656: INFO: Pod node-exporter-6lmwr requesting resource cpu=5m on Node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-r5glw
Dec  3 15:43:56.656: INFO: Pod node-problem-detector-c9sgc requesting resource cpu=20m on Node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9
Dec  3 15:43:56.656: INFO: Pod node-problem-detector-fbcm4 requesting resource cpu=20m on Node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-r5glw
Dec  3 15:43:56.656: INFO: Pod vpn-shoot-5f48c598df-dqjlc requesting resource cpu=100m on Node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-r5glw
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-12eb7b5e-20fa-477e-8236-32f420feb846.15dce6e404256631], Reason = [Scheduled], Message = [Successfully assigned sched-pred-389/filler-pod-12eb7b5e-20fa-477e-8236-32f420feb846 to shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-r5glw]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-12eb7b5e-20fa-477e-8236-32f420feb846.15dce6e430009338], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-12eb7b5e-20fa-477e-8236-32f420feb846.15dce6e4325e45b2], Reason = [Created], Message = [Created container filler-pod-12eb7b5e-20fa-477e-8236-32f420feb846]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-12eb7b5e-20fa-477e-8236-32f420feb846.15dce6e4391bcd08], Reason = [Started], Message = [Started container filler-pod-12eb7b5e-20fa-477e-8236-32f420feb846]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2feae30d-4087-4f36-8b91-2b8d54920191.15dce6e404c0fba9], Reason = [Scheduled], Message = [Successfully assigned sched-pred-389/filler-pod-2feae30d-4087-4f36-8b91-2b8d54920191 to shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2feae30d-4087-4f36-8b91-2b8d54920191.15dce6e4326a169b], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2feae30d-4087-4f36-8b91-2b8d54920191.15dce6e43515cc8f], Reason = [Created], Message = [Created container filler-pod-2feae30d-4087-4f36-8b91-2b8d54920191]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2feae30d-4087-4f36-8b91-2b8d54920191.15dce6e43da95f41], Reason = [Started], Message = [Started container filler-pod-2feae30d-4087-4f36-8b91-2b8d54920191]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15dce6e47f686c6a], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 Insufficient cpu.]
STEP: removing the label node off the node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-r5glw
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:43:59.814: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-389" for this suite.
Dec  3 15:44:05.857: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:44:06.236: INFO: namespace sched-pred-389 deletion completed in 6.412154859s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72
•SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:44:06.237: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5885
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-171910a0-dbe2-4c16-b5ba-3883a7c63258
STEP: Creating a pod to test consume configMaps
Dec  3 15:44:06.443: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b108242d-645f-40c3-9bf2-aeb0d72227de" in namespace "projected-5885" to be "success or failure"
Dec  3 15:44:06.453: INFO: Pod "pod-projected-configmaps-b108242d-645f-40c3-9bf2-aeb0d72227de": Phase="Pending", Reason="", readiness=false. Elapsed: 9.627688ms
Dec  3 15:44:08.464: INFO: Pod "pod-projected-configmaps-b108242d-645f-40c3-9bf2-aeb0d72227de": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020547773s
STEP: Saw pod success
Dec  3 15:44:08.464: INFO: Pod "pod-projected-configmaps-b108242d-645f-40c3-9bf2-aeb0d72227de" satisfied condition "success or failure"
Dec  3 15:44:08.474: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod pod-projected-configmaps-b108242d-645f-40c3-9bf2-aeb0d72227de container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 15:44:08.507: INFO: Waiting for pod pod-projected-configmaps-b108242d-645f-40c3-9bf2-aeb0d72227de to disappear
Dec  3 15:44:08.519: INFO: Pod pod-projected-configmaps-b108242d-645f-40c3-9bf2-aeb0d72227de no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:44:08.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5885" for this suite.
Dec  3 15:44:14.569: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:44:14.988: INFO: namespace projected-5885 deletion completed in 6.450618388s
•SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:44:14.988: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7395
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec  3 15:44:15.187: INFO: Waiting up to 5m0s for pod "pod-34c19755-aa7a-4444-9140-863d2df540ff" in namespace "emptydir-7395" to be "success or failure"
Dec  3 15:44:15.197: INFO: Pod "pod-34c19755-aa7a-4444-9140-863d2df540ff": Phase="Pending", Reason="", readiness=false. Elapsed: 9.566202ms
Dec  3 15:44:17.207: INFO: Pod "pod-34c19755-aa7a-4444-9140-863d2df540ff": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020478689s
STEP: Saw pod success
Dec  3 15:44:17.208: INFO: Pod "pod-34c19755-aa7a-4444-9140-863d2df540ff" satisfied condition "success or failure"
Dec  3 15:44:17.218: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod pod-34c19755-aa7a-4444-9140-863d2df540ff container test-container: <nil>
STEP: delete the pod
Dec  3 15:44:17.251: INFO: Waiting for pod pod-34c19755-aa7a-4444-9140-863d2df540ff to disappear
Dec  3 15:44:17.260: INFO: Pod pod-34c19755-aa7a-4444-9140-863d2df540ff no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:44:17.260: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7395" for this suite.
Dec  3 15:44:23.311: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:44:23.739: INFO: namespace emptydir-7395 deletion completed in 6.460256065s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:44:23.740: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-5825
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec  3 15:44:25.976: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:44:26.001: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5825" for this suite.
Dec  3 15:44:32.051: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:44:32.438: INFO: namespace container-runtime-5825 deletion completed in 6.419456596s
•SSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:44:32.439: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6226
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-e29e63be-0268-49fc-be28-85a1b0cc8e6f
STEP: Creating a pod to test consume secrets
Dec  3 15:44:32.648: INFO: Waiting up to 5m0s for pod "pod-secrets-5e1e7bae-c65b-4903-8061-12cd3483f193" in namespace "secrets-6226" to be "success or failure"
Dec  3 15:44:32.657: INFO: Pod "pod-secrets-5e1e7bae-c65b-4903-8061-12cd3483f193": Phase="Pending", Reason="", readiness=false. Elapsed: 9.647682ms
Dec  3 15:44:34.668: INFO: Pod "pod-secrets-5e1e7bae-c65b-4903-8061-12cd3483f193": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019975644s
STEP: Saw pod success
Dec  3 15:44:34.668: INFO: Pod "pod-secrets-5e1e7bae-c65b-4903-8061-12cd3483f193" satisfied condition "success or failure"
Dec  3 15:44:34.677: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod pod-secrets-5e1e7bae-c65b-4903-8061-12cd3483f193 container secret-volume-test: <nil>
STEP: delete the pod
Dec  3 15:44:34.710: INFO: Waiting for pod pod-secrets-5e1e7bae-c65b-4903-8061-12cd3483f193 to disappear
Dec  3 15:44:34.725: INFO: Pod pod-secrets-5e1e7bae-c65b-4903-8061-12cd3483f193 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:44:34.725: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6226" for this suite.
Dec  3 15:44:40.776: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:44:41.200: INFO: namespace secrets-6226 deletion completed in 6.456371233s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:44:41.201: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-808
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec  3 15:44:41.398: INFO: Waiting up to 5m0s for pod "downwardapi-volume-389bbaf2-fb04-4ab7-9e7f-6ded0867ede8" in namespace "projected-808" to be "success or failure"
Dec  3 15:44:41.408: INFO: Pod "downwardapi-volume-389bbaf2-fb04-4ab7-9e7f-6ded0867ede8": Phase="Pending", Reason="", readiness=false. Elapsed: 9.38945ms
Dec  3 15:44:43.418: INFO: Pod "downwardapi-volume-389bbaf2-fb04-4ab7-9e7f-6ded0867ede8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020063952s
STEP: Saw pod success
Dec  3 15:44:43.418: INFO: Pod "downwardapi-volume-389bbaf2-fb04-4ab7-9e7f-6ded0867ede8" satisfied condition "success or failure"
Dec  3 15:44:43.429: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod downwardapi-volume-389bbaf2-fb04-4ab7-9e7f-6ded0867ede8 container client-container: <nil>
STEP: delete the pod
Dec  3 15:44:43.460: INFO: Waiting for pod downwardapi-volume-389bbaf2-fb04-4ab7-9e7f-6ded0867ede8 to disappear
Dec  3 15:44:43.469: INFO: Pod downwardapi-volume-389bbaf2-fb04-4ab7-9e7f-6ded0867ede8 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:44:43.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-808" for this suite.
Dec  3 15:44:49.518: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:44:49.935: INFO: namespace projected-808 deletion completed in 6.447304185s
•SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:44:49.935: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-6804
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Dec  3 15:44:50.177: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-6804,SelfLink:/api/v1/namespaces/watch-6804/configmaps/e2e-watch-test-label-changed,UID:9400c9b2-64e6-49ee-b996-2098d109d3f3,ResourceVersion:18509,Generation:0,CreationTimestamp:2019-12-03 15:44:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  3 15:44:50.177: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-6804,SelfLink:/api/v1/namespaces/watch-6804/configmaps/e2e-watch-test-label-changed,UID:9400c9b2-64e6-49ee-b996-2098d109d3f3,ResourceVersion:18510,Generation:0,CreationTimestamp:2019-12-03 15:44:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Dec  3 15:44:50.177: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-6804,SelfLink:/api/v1/namespaces/watch-6804/configmaps/e2e-watch-test-label-changed,UID:9400c9b2-64e6-49ee-b996-2098d109d3f3,ResourceVersion:18511,Generation:0,CreationTimestamp:2019-12-03 15:44:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Dec  3 15:45:00.251: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-6804,SelfLink:/api/v1/namespaces/watch-6804/configmaps/e2e-watch-test-label-changed,UID:9400c9b2-64e6-49ee-b996-2098d109d3f3,ResourceVersion:18540,Generation:0,CreationTimestamp:2019-12-03 15:44:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  3 15:45:00.251: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-6804,SelfLink:/api/v1/namespaces/watch-6804/configmaps/e2e-watch-test-label-changed,UID:9400c9b2-64e6-49ee-b996-2098d109d3f3,ResourceVersion:18541,Generation:0,CreationTimestamp:2019-12-03 15:44:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Dec  3 15:45:00.251: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-6804,SelfLink:/api/v1/namespaces/watch-6804/configmaps/e2e-watch-test-label-changed,UID:9400c9b2-64e6-49ee-b996-2098d109d3f3,ResourceVersion:18542,Generation:0,CreationTimestamp:2019-12-03 15:44:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:45:00.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6804" for this suite.
Dec  3 15:45:06.315: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:45:06.701: INFO: namespace watch-6804 deletion completed in 6.431406784s
•SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:45:06.701: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8260
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec  3 15:45:06.898: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4b11ca7a-51eb-49ce-af1e-1d312ccbd5b7" in namespace "downward-api-8260" to be "success or failure"
Dec  3 15:45:06.907: INFO: Pod "downwardapi-volume-4b11ca7a-51eb-49ce-af1e-1d312ccbd5b7": Phase="Pending", Reason="", readiness=false. Elapsed: 9.654266ms
Dec  3 15:45:08.918: INFO: Pod "downwardapi-volume-4b11ca7a-51eb-49ce-af1e-1d312ccbd5b7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020362878s
STEP: Saw pod success
Dec  3 15:45:08.918: INFO: Pod "downwardapi-volume-4b11ca7a-51eb-49ce-af1e-1d312ccbd5b7" satisfied condition "success or failure"
Dec  3 15:45:08.928: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod downwardapi-volume-4b11ca7a-51eb-49ce-af1e-1d312ccbd5b7 container client-container: <nil>
STEP: delete the pod
Dec  3 15:45:08.961: INFO: Waiting for pod downwardapi-volume-4b11ca7a-51eb-49ce-af1e-1d312ccbd5b7 to disappear
Dec  3 15:45:08.970: INFO: Pod downwardapi-volume-4b11ca7a-51eb-49ce-af1e-1d312ccbd5b7 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:45:08.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8260" for this suite.
Dec  3 15:45:15.020: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:45:15.411: INFO: namespace downward-api-8260 deletion completed in 6.422447626s
•SSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:45:15.411: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-3353
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Dec  3 15:45:15.613: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:45:23.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3353" for this suite.
Dec  3 15:45:29.117: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:45:29.501: INFO: namespace pods-3353 deletion completed in 6.414822636s
•SSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:45:29.501: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4169
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec  3 15:45:29.699: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cfedb85e-d719-4eb2-a9fd-81e2e6e27ea3" in namespace "downward-api-4169" to be "success or failure"
Dec  3 15:45:29.709: INFO: Pod "downwardapi-volume-cfedb85e-d719-4eb2-a9fd-81e2e6e27ea3": Phase="Pending", Reason="", readiness=false. Elapsed: 9.868218ms
Dec  3 15:45:31.720: INFO: Pod "downwardapi-volume-cfedb85e-d719-4eb2-a9fd-81e2e6e27ea3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020242903s
STEP: Saw pod success
Dec  3 15:45:31.720: INFO: Pod "downwardapi-volume-cfedb85e-d719-4eb2-a9fd-81e2e6e27ea3" satisfied condition "success or failure"
Dec  3 15:45:31.730: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod downwardapi-volume-cfedb85e-d719-4eb2-a9fd-81e2e6e27ea3 container client-container: <nil>
STEP: delete the pod
Dec  3 15:45:31.763: INFO: Waiting for pod downwardapi-volume-cfedb85e-d719-4eb2-a9fd-81e2e6e27ea3 to disappear
Dec  3 15:45:31.773: INFO: Pod downwardapi-volume-cfedb85e-d719-4eb2-a9fd-81e2e6e27ea3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:45:31.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4169" for this suite.
Dec  3 15:45:37.824: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:45:38.208: INFO: namespace downward-api-4169 deletion completed in 6.416252376s
•SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:45:38.209: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1892
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec  3 15:45:38.407: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3be65205-867f-4228-b50c-cc9b29b7afbe" in namespace "projected-1892" to be "success or failure"
Dec  3 15:45:38.417: INFO: Pod "downwardapi-volume-3be65205-867f-4228-b50c-cc9b29b7afbe": Phase="Pending", Reason="", readiness=false. Elapsed: 9.674064ms
Dec  3 15:45:40.427: INFO: Pod "downwardapi-volume-3be65205-867f-4228-b50c-cc9b29b7afbe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020058731s
STEP: Saw pod success
Dec  3 15:45:40.427: INFO: Pod "downwardapi-volume-3be65205-867f-4228-b50c-cc9b29b7afbe" satisfied condition "success or failure"
Dec  3 15:45:40.437: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod downwardapi-volume-3be65205-867f-4228-b50c-cc9b29b7afbe container client-container: <nil>
STEP: delete the pod
Dec  3 15:45:40.474: INFO: Waiting for pod downwardapi-volume-3be65205-867f-4228-b50c-cc9b29b7afbe to disappear
Dec  3 15:45:40.484: INFO: Pod downwardapi-volume-3be65205-867f-4228-b50c-cc9b29b7afbe no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:45:40.484: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1892" for this suite.
Dec  3 15:45:46.534: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:45:46.950: INFO: namespace projected-1892 deletion completed in 6.447993793s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:45:46.951: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-5282
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec  3 15:45:47.159: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec  3 15:45:49.180: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Dec  3 15:45:51.269: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-5282,SelfLink:/apis/apps/v1/namespaces/deployment-5282/deployments/test-cleanup-deployment,UID:6dcdba9f-f74a-4e8a-b89e-e047b33279c9,ResourceVersion:18779,Generation:1,CreationTimestamp:2019-12-03 15:45:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 1,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-12-03 15:45:49 +0000 UTC 2019-12-03 15:45:49 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-12-03 15:45:50 +0000 UTC 2019-12-03 15:45:49 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-cleanup-deployment-55bbcbc84c" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Dec  3 15:45:51.279: INFO: New ReplicaSet "test-cleanup-deployment-55bbcbc84c" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55bbcbc84c,GenerateName:,Namespace:deployment-5282,SelfLink:/apis/apps/v1/namespaces/deployment-5282/replicasets/test-cleanup-deployment-55bbcbc84c,UID:01026b35-15dd-4f8d-837f-062759dd9041,ResourceVersion:18772,Generation:1,CreationTimestamp:2019-12-03 15:45:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 6dcdba9f-f74a-4e8a-b89e-e047b33279c9 0xc003b20667 0xc003b20668}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Dec  3 15:45:51.290: INFO: Pod "test-cleanup-deployment-55bbcbc84c-6qddv" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55bbcbc84c-6qddv,GenerateName:test-cleanup-deployment-55bbcbc84c-,Namespace:deployment-5282,SelfLink:/api/v1/namespaces/deployment-5282/pods/test-cleanup-deployment-55bbcbc84c-6qddv,UID:2f0c6819-6b3d-4d0c-8d27-17db022f2675,ResourceVersion:18771,Generation:0,CreationTimestamp:2019-12-03 15:45:49 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.64.1.232/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-55bbcbc84c 01026b35-15dd-4f8d-837f-062759dd9041 0xc003b20c77 0xc003b20c78}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-g8sjz {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-g8sjz,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-g8sjz true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003b20ce0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003b20d00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 15:45:49 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 15:45:50 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 15:45:50 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 15:45:49 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.3,PodIP:100.64.1.232,StartTime:2019-12-03 15:45:49 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-12-03 15:45:50 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://8aec163c93b548363cdfe39736f18968da12c46f1ebad4fc67d901a74ab7c12f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:45:51.290: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5282" for this suite.
Dec  3 15:45:57.341: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:45:57.714: INFO: namespace deployment-5282 deletion completed in 6.405322237s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:45:57.715: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7298
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec  3 15:45:57.910: INFO: Waiting up to 5m0s for pod "pod-9110dfd5-45b6-410d-90df-92f17092520b" in namespace "emptydir-7298" to be "success or failure"
Dec  3 15:45:57.919: INFO: Pod "pod-9110dfd5-45b6-410d-90df-92f17092520b": Phase="Pending", Reason="", readiness=false. Elapsed: 9.432051ms
Dec  3 15:45:59.930: INFO: Pod "pod-9110dfd5-45b6-410d-90df-92f17092520b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01971608s
STEP: Saw pod success
Dec  3 15:45:59.930: INFO: Pod "pod-9110dfd5-45b6-410d-90df-92f17092520b" satisfied condition "success or failure"
Dec  3 15:45:59.940: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod pod-9110dfd5-45b6-410d-90df-92f17092520b container test-container: <nil>
STEP: delete the pod
Dec  3 15:45:59.975: INFO: Waiting for pod pod-9110dfd5-45b6-410d-90df-92f17092520b to disappear
Dec  3 15:45:59.985: INFO: Pod pod-9110dfd5-45b6-410d-90df-92f17092520b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:45:59.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7298" for this suite.
Dec  3 15:46:06.041: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:46:06.423: INFO: namespace emptydir-7298 deletion completed in 6.418640768s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:46:06.423: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-239
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec  3 15:46:08.659: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:46:08.683: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-239" for this suite.
Dec  3 15:46:14.733: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:46:15.160: INFO: namespace container-runtime-239 deletion completed in 6.458497673s
•SSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:46:15.160: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-697
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-db74b187-da6d-44f1-b87d-826870e6d3dc
STEP: Creating a pod to test consume configMaps
Dec  3 15:46:15.368: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d3bff45a-a388-419c-a547-011058e26cf6" in namespace "projected-697" to be "success or failure"
Dec  3 15:46:15.378: INFO: Pod "pod-projected-configmaps-d3bff45a-a388-419c-a547-011058e26cf6": Phase="Pending", Reason="", readiness=false. Elapsed: 10.373197ms
Dec  3 15:46:17.389: INFO: Pod "pod-projected-configmaps-d3bff45a-a388-419c-a547-011058e26cf6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021802434s
STEP: Saw pod success
Dec  3 15:46:17.390: INFO: Pod "pod-projected-configmaps-d3bff45a-a388-419c-a547-011058e26cf6" satisfied condition "success or failure"
Dec  3 15:46:17.400: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod pod-projected-configmaps-d3bff45a-a388-419c-a547-011058e26cf6 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 15:46:17.434: INFO: Waiting for pod pod-projected-configmaps-d3bff45a-a388-419c-a547-011058e26cf6 to disappear
Dec  3 15:46:17.443: INFO: Pod pod-projected-configmaps-d3bff45a-a388-419c-a547-011058e26cf6 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:46:17.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-697" for this suite.
Dec  3 15:46:23.496: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:46:23.881: INFO: namespace projected-697 deletion completed in 6.419613971s
•SSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:46:23.882: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-1167
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:46:24.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1167" for this suite.
Dec  3 15:46:36.133: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:46:36.521: INFO: namespace pods-1167 deletion completed in 12.41957444s
•SSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:46:36.522: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4521
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Dec  3 15:46:36.725: INFO: Waiting up to 5m0s for pod "downward-api-da1df3f4-9241-4e54-9c09-37ef08a1d4a5" in namespace "downward-api-4521" to be "success or failure"
Dec  3 15:46:36.734: INFO: Pod "downward-api-da1df3f4-9241-4e54-9c09-37ef08a1d4a5": Phase="Pending", Reason="", readiness=false. Elapsed: 9.801118ms
Dec  3 15:46:38.745: INFO: Pod "downward-api-da1df3f4-9241-4e54-9c09-37ef08a1d4a5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020912473s
STEP: Saw pod success
Dec  3 15:46:38.746: INFO: Pod "downward-api-da1df3f4-9241-4e54-9c09-37ef08a1d4a5" satisfied condition "success or failure"
Dec  3 15:46:38.756: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod downward-api-da1df3f4-9241-4e54-9c09-37ef08a1d4a5 container dapi-container: <nil>
STEP: delete the pod
Dec  3 15:46:38.791: INFO: Waiting for pod downward-api-da1df3f4-9241-4e54-9c09-37ef08a1d4a5 to disappear
Dec  3 15:46:38.801: INFO: Pod downward-api-da1df3f4-9241-4e54-9c09-37ef08a1d4a5 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:46:38.801: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4521" for this suite.
Dec  3 15:46:44.851: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:46:45.275: INFO: namespace downward-api-4521 deletion completed in 6.455676139s
•SSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:46:45.275: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-5556
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test env composition
Dec  3 15:46:45.470: INFO: Waiting up to 5m0s for pod "var-expansion-4232c4ac-f047-4f4c-8e54-a2a8b42993d4" in namespace "var-expansion-5556" to be "success or failure"
Dec  3 15:46:45.480: INFO: Pod "var-expansion-4232c4ac-f047-4f4c-8e54-a2a8b42993d4": Phase="Pending", Reason="", readiness=false. Elapsed: 9.485566ms
Dec  3 15:46:47.490: INFO: Pod "var-expansion-4232c4ac-f047-4f4c-8e54-a2a8b42993d4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02001549s
STEP: Saw pod success
Dec  3 15:46:47.490: INFO: Pod "var-expansion-4232c4ac-f047-4f4c-8e54-a2a8b42993d4" satisfied condition "success or failure"
Dec  3 15:46:47.501: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod var-expansion-4232c4ac-f047-4f4c-8e54-a2a8b42993d4 container dapi-container: <nil>
STEP: delete the pod
Dec  3 15:46:47.534: INFO: Waiting for pod var-expansion-4232c4ac-f047-4f4c-8e54-a2a8b42993d4 to disappear
Dec  3 15:46:47.543: INFO: Pod var-expansion-4232c4ac-f047-4f4c-8e54-a2a8b42993d4 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:46:47.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-5556" for this suite.
Dec  3 15:46:53.593: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:46:53.998: INFO: namespace var-expansion-5556 deletion completed in 6.436766904s
•SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:46:53.999: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9229
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec  3 15:46:54.194: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3767358e-3f07-4430-bc9a-c4e741c68dbd" in namespace "downward-api-9229" to be "success or failure"
Dec  3 15:46:54.204: INFO: Pod "downwardapi-volume-3767358e-3f07-4430-bc9a-c4e741c68dbd": Phase="Pending", Reason="", readiness=false. Elapsed: 9.926116ms
Dec  3 15:46:56.214: INFO: Pod "downwardapi-volume-3767358e-3f07-4430-bc9a-c4e741c68dbd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020287739s
STEP: Saw pod success
Dec  3 15:46:56.215: INFO: Pod "downwardapi-volume-3767358e-3f07-4430-bc9a-c4e741c68dbd" satisfied condition "success or failure"
Dec  3 15:46:56.225: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod downwardapi-volume-3767358e-3f07-4430-bc9a-c4e741c68dbd container client-container: <nil>
STEP: delete the pod
Dec  3 15:46:56.256: INFO: Waiting for pod downwardapi-volume-3767358e-3f07-4430-bc9a-c4e741c68dbd to disappear
Dec  3 15:46:56.265: INFO: Pod downwardapi-volume-3767358e-3f07-4430-bc9a-c4e741c68dbd no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:46:56.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9229" for this suite.
Dec  3 15:47:02.316: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:47:02.708: INFO: namespace downward-api-9229 deletion completed in 6.424210383s
•SSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:47:02.708: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-3677
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-3677
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec  3 15:47:02.890: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec  3 15:47:21.090: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.64.1.240:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3677 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:47:21.090: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:47:21.544: INFO: Found all expected endpoints: [netserver-0]
Dec  3 15:47:21.554: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.64.0.62:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3677 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:47:21.554: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:47:22.007: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:47:22.007: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3677" for this suite.
Dec  3 15:47:44.058: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:47:44.441: INFO: namespace pod-network-test-3677 deletion completed in 22.415196222s
•S
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:47:44.441: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-5305
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override all
Dec  3 15:47:44.639: INFO: Waiting up to 5m0s for pod "client-containers-30f83831-4e73-4bf9-89c9-d08742940044" in namespace "containers-5305" to be "success or failure"
Dec  3 15:47:44.648: INFO: Pod "client-containers-30f83831-4e73-4bf9-89c9-d08742940044": Phase="Pending", Reason="", readiness=false. Elapsed: 9.597682ms
Dec  3 15:47:46.659: INFO: Pod "client-containers-30f83831-4e73-4bf9-89c9-d08742940044": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020407801s
STEP: Saw pod success
Dec  3 15:47:46.659: INFO: Pod "client-containers-30f83831-4e73-4bf9-89c9-d08742940044" satisfied condition "success or failure"
Dec  3 15:47:46.669: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod client-containers-30f83831-4e73-4bf9-89c9-d08742940044 container test-container: <nil>
STEP: delete the pod
Dec  3 15:47:46.703: INFO: Waiting for pod client-containers-30f83831-4e73-4bf9-89c9-d08742940044 to disappear
Dec  3 15:47:46.712: INFO: Pod client-containers-30f83831-4e73-4bf9-89c9-d08742940044 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:47:46.712: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-5305" for this suite.
Dec  3 15:47:52.762: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:47:53.141: INFO: namespace containers-5305 deletion completed in 6.410373703s
•SSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:47:53.142: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-2437
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:48:15.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-2437" for this suite.
Dec  3 15:48:21.874: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:48:22.260: INFO: namespace container-runtime-2437 deletion completed in 6.416359469s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:48:22.260: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-4911
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override arguments
Dec  3 15:48:22.460: INFO: Waiting up to 5m0s for pod "client-containers-ded7d7f2-07c8-48d9-a3f7-a9dde4f79c8d" in namespace "containers-4911" to be "success or failure"
Dec  3 15:48:22.470: INFO: Pod "client-containers-ded7d7f2-07c8-48d9-a3f7-a9dde4f79c8d": Phase="Pending", Reason="", readiness=false. Elapsed: 9.764231ms
Dec  3 15:48:24.481: INFO: Pod "client-containers-ded7d7f2-07c8-48d9-a3f7-a9dde4f79c8d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020400844s
STEP: Saw pod success
Dec  3 15:48:24.481: INFO: Pod "client-containers-ded7d7f2-07c8-48d9-a3f7-a9dde4f79c8d" satisfied condition "success or failure"
Dec  3 15:48:24.491: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod client-containers-ded7d7f2-07c8-48d9-a3f7-a9dde4f79c8d container test-container: <nil>
STEP: delete the pod
Dec  3 15:48:24.525: INFO: Waiting for pod client-containers-ded7d7f2-07c8-48d9-a3f7-a9dde4f79c8d to disappear
Dec  3 15:48:24.534: INFO: Pod client-containers-ded7d7f2-07c8-48d9-a3f7-a9dde4f79c8d no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:48:24.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-4911" for this suite.
Dec  3 15:48:30.584: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:48:30.970: INFO: namespace containers-4911 deletion completed in 6.417473646s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:48:30.971: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9739
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating all guestbook components
Dec  3 15:48:31.154: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Dec  3 15:48:31.154: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-9739'
Dec  3 15:48:31.443: INFO: stderr: ""
Dec  3 15:48:31.443: INFO: stdout: "service/redis-slave created\n"
Dec  3 15:48:31.444: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Dec  3 15:48:31.444: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-9739'
Dec  3 15:48:31.704: INFO: stderr: ""
Dec  3 15:48:31.704: INFO: stdout: "service/redis-master created\n"
Dec  3 15:48:31.704: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Dec  3 15:48:31.704: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-9739'
Dec  3 15:48:31.950: INFO: stderr: ""
Dec  3 15:48:31.950: INFO: stdout: "service/frontend created\n"
Dec  3 15:48:31.950: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Dec  3 15:48:31.950: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-9739'
Dec  3 15:48:32.201: INFO: stderr: ""
Dec  3 15:48:32.201: INFO: stdout: "deployment.apps/frontend created\n"
Dec  3 15:48:32.201: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Dec  3 15:48:32.201: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-9739'
Dec  3 15:48:32.473: INFO: stderr: ""
Dec  3 15:48:32.473: INFO: stdout: "deployment.apps/redis-master created\n"
Dec  3 15:48:32.473: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Dec  3 15:48:32.473: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-9739'
Dec  3 15:48:32.739: INFO: stderr: ""
Dec  3 15:48:32.739: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Dec  3 15:48:32.739: INFO: Waiting for all frontend pods to be Running.
Dec  3 15:48:52.791: INFO: Waiting for frontend to serve content.
Dec  3 15:48:52.896: INFO: Trying to add a new entry to the guestbook.
Dec  3 15:48:52.996: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Dec  3 15:48:53.123: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-9739'
Dec  3 15:48:53.248: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 15:48:53.248: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Dec  3 15:48:53.249: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-9739'
Dec  3 15:48:53.372: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 15:48:53.372: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Dec  3 15:48:53.372: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-9739'
Dec  3 15:48:53.500: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 15:48:53.500: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec  3 15:48:53.501: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-9739'
Dec  3 15:48:53.623: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 15:48:53.623: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec  3 15:48:53.623: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-9739'
Dec  3 15:48:53.746: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 15:48:53.746: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Dec  3 15:48:53.746: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-9739'
Dec  3 15:48:53.862: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 15:48:53.863: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:48:53.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9739" for this suite.
Dec  3 15:49:31.913: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:49:32.306: INFO: namespace kubectl-9739 deletion completed in 38.424788559s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:49:32.307: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3187
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-53905f34-9877-4c38-825a-207998e07578
STEP: Creating a pod to test consume configMaps
Dec  3 15:49:32.516: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-10cd8a53-9030-4904-ab25-b4f0aa8d01a5" in namespace "projected-3187" to be "success or failure"
Dec  3 15:49:32.526: INFO: Pod "pod-projected-configmaps-10cd8a53-9030-4904-ab25-b4f0aa8d01a5": Phase="Pending", Reason="", readiness=false. Elapsed: 9.798566ms
Dec  3 15:49:34.537: INFO: Pod "pod-projected-configmaps-10cd8a53-9030-4904-ab25-b4f0aa8d01a5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020530634s
STEP: Saw pod success
Dec  3 15:49:34.537: INFO: Pod "pod-projected-configmaps-10cd8a53-9030-4904-ab25-b4f0aa8d01a5" satisfied condition "success or failure"
Dec  3 15:49:34.547: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod pod-projected-configmaps-10cd8a53-9030-4904-ab25-b4f0aa8d01a5 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 15:49:34.579: INFO: Waiting for pod pod-projected-configmaps-10cd8a53-9030-4904-ab25-b4f0aa8d01a5 to disappear
Dec  3 15:49:34.589: INFO: Pod pod-projected-configmaps-10cd8a53-9030-4904-ab25-b4f0aa8d01a5 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:49:34.589: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3187" for this suite.
Dec  3 15:49:40.639: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:49:41.043: INFO: namespace projected-3187 deletion completed in 6.435465652s
•SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:49:41.044: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5382
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-map-efd62f6f-a665-43e0-96d2-0bb160dfd3f3
STEP: Creating a pod to test consume secrets
Dec  3 15:49:41.251: INFO: Waiting up to 5m0s for pod "pod-secrets-e9c72927-df61-41d1-a9d1-383fd5d50aa9" in namespace "secrets-5382" to be "success or failure"
Dec  3 15:49:41.261: INFO: Pod "pod-secrets-e9c72927-df61-41d1-a9d1-383fd5d50aa9": Phase="Pending", Reason="", readiness=false. Elapsed: 9.845276ms
Dec  3 15:49:43.272: INFO: Pod "pod-secrets-e9c72927-df61-41d1-a9d1-383fd5d50aa9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020501604s
STEP: Saw pod success
Dec  3 15:49:43.272: INFO: Pod "pod-secrets-e9c72927-df61-41d1-a9d1-383fd5d50aa9" satisfied condition "success or failure"
Dec  3 15:49:43.282: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod pod-secrets-e9c72927-df61-41d1-a9d1-383fd5d50aa9 container secret-volume-test: <nil>
STEP: delete the pod
Dec  3 15:49:43.315: INFO: Waiting for pod pod-secrets-e9c72927-df61-41d1-a9d1-383fd5d50aa9 to disappear
Dec  3 15:49:43.325: INFO: Pod pod-secrets-e9c72927-df61-41d1-a9d1-383fd5d50aa9 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:49:43.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5382" for this suite.
Dec  3 15:49:49.379: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:49:49.807: INFO: namespace secrets-5382 deletion completed in 6.463457341s
•SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:49:49.807: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1555
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec  3 15:49:50.003: INFO: Waiting up to 5m0s for pod "downwardapi-volume-878a9389-d445-4698-bf0a-349272799014" in namespace "downward-api-1555" to be "success or failure"
Dec  3 15:49:50.012: INFO: Pod "downwardapi-volume-878a9389-d445-4698-bf0a-349272799014": Phase="Pending", Reason="", readiness=false. Elapsed: 9.646086ms
Dec  3 15:49:52.023: INFO: Pod "downwardapi-volume-878a9389-d445-4698-bf0a-349272799014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020451881s
STEP: Saw pod success
Dec  3 15:49:52.023: INFO: Pod "downwardapi-volume-878a9389-d445-4698-bf0a-349272799014" satisfied condition "success or failure"
Dec  3 15:49:52.033: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod downwardapi-volume-878a9389-d445-4698-bf0a-349272799014 container client-container: <nil>
STEP: delete the pod
Dec  3 15:49:52.066: INFO: Waiting for pod downwardapi-volume-878a9389-d445-4698-bf0a-349272799014 to disappear
Dec  3 15:49:52.076: INFO: Pod downwardapi-volume-878a9389-d445-4698-bf0a-349272799014 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:49:52.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1555" for this suite.
Dec  3 15:49:58.125: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:49:58.497: INFO: namespace downward-api-1555 deletion completed in 6.402186915s
•SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:49:58.497: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-9783
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Dec  3 15:50:04.760: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
W1203 15:50:04.760490    5066 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  3 15:50:04.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9783" for this suite.
Dec  3 15:50:10.801: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:50:11.184: INFO: namespace gc-9783 deletion completed in 6.413633196s
•SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:50:11.185: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3042
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-61ddf9f8-13e8-40df-a0f8-e9db8d24c2d2
STEP: Creating a pod to test consume configMaps
Dec  3 15:50:11.391: INFO: Waiting up to 5m0s for pod "pod-configmaps-5a428562-dba5-4fb0-b62a-b224e9c369f2" in namespace "configmap-3042" to be "success or failure"
Dec  3 15:50:11.401: INFO: Pod "pod-configmaps-5a428562-dba5-4fb0-b62a-b224e9c369f2": Phase="Pending", Reason="", readiness=false. Elapsed: 9.659862ms
Dec  3 15:50:13.412: INFO: Pod "pod-configmaps-5a428562-dba5-4fb0-b62a-b224e9c369f2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020559837s
STEP: Saw pod success
Dec  3 15:50:13.412: INFO: Pod "pod-configmaps-5a428562-dba5-4fb0-b62a-b224e9c369f2" satisfied condition "success or failure"
Dec  3 15:50:13.422: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod pod-configmaps-5a428562-dba5-4fb0-b62a-b224e9c369f2 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 15:50:13.454: INFO: Waiting for pod pod-configmaps-5a428562-dba5-4fb0-b62a-b224e9c369f2 to disappear
Dec  3 15:50:13.464: INFO: Pod pod-configmaps-5a428562-dba5-4fb0-b62a-b224e9c369f2 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:50:13.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3042" for this suite.
Dec  3 15:50:19.519: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:50:19.935: INFO: namespace configmap-3042 deletion completed in 6.452386952s
•SSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:50:19.935: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-7014
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:51:20.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7014" for this suite.
Dec  3 15:51:36.195: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:51:36.580: INFO: namespace container-probe-7014 deletion completed in 16.416025658s
•SSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:51:36.581: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5966
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-2bd24634-049f-4dc0-ae59-cbd8710c0f44
STEP: Creating a pod to test consume configMaps
Dec  3 15:51:36.787: INFO: Waiting up to 5m0s for pod "pod-configmaps-a7104073-381d-499b-8311-3b893fcd9063" in namespace "configmap-5966" to be "success or failure"
Dec  3 15:51:36.797: INFO: Pod "pod-configmaps-a7104073-381d-499b-8311-3b893fcd9063": Phase="Pending", Reason="", readiness=false. Elapsed: 9.860715ms
Dec  3 15:51:38.807: INFO: Pod "pod-configmaps-a7104073-381d-499b-8311-3b893fcd9063": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02019659s
STEP: Saw pod success
Dec  3 15:51:38.807: INFO: Pod "pod-configmaps-a7104073-381d-499b-8311-3b893fcd9063" satisfied condition "success or failure"
Dec  3 15:51:38.818: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod pod-configmaps-a7104073-381d-499b-8311-3b893fcd9063 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 15:51:38.851: INFO: Waiting for pod pod-configmaps-a7104073-381d-499b-8311-3b893fcd9063 to disappear
Dec  3 15:51:38.861: INFO: Pod pod-configmaps-a7104073-381d-499b-8311-3b893fcd9063 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:51:38.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5966" for this suite.
Dec  3 15:51:44.913: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:51:45.300: INFO: namespace configmap-5966 deletion completed in 6.420717413s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:51:45.300: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2385
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Dec  3 15:51:45.496: INFO: Waiting up to 5m0s for pod "downwardapi-volume-098bcf0a-48e5-4013-84ba-d539f09b300e" in namespace "projected-2385" to be "success or failure"
Dec  3 15:51:45.506: INFO: Pod "downwardapi-volume-098bcf0a-48e5-4013-84ba-d539f09b300e": Phase="Pending", Reason="", readiness=false. Elapsed: 9.373211ms
Dec  3 15:51:47.516: INFO: Pod "downwardapi-volume-098bcf0a-48e5-4013-84ba-d539f09b300e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020259989s
STEP: Saw pod success
Dec  3 15:51:47.516: INFO: Pod "downwardapi-volume-098bcf0a-48e5-4013-84ba-d539f09b300e" satisfied condition "success or failure"
Dec  3 15:51:47.526: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod downwardapi-volume-098bcf0a-48e5-4013-84ba-d539f09b300e container client-container: <nil>
STEP: delete the pod
Dec  3 15:51:47.558: INFO: Waiting for pod downwardapi-volume-098bcf0a-48e5-4013-84ba-d539f09b300e to disappear
Dec  3 15:51:47.568: INFO: Pod downwardapi-volume-098bcf0a-48e5-4013-84ba-d539f09b300e no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:51:47.568: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2385" for this suite.
Dec  3 15:51:53.617: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:51:54.013: INFO: namespace projected-2385 deletion completed in 6.427327344s
•SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:51:54.014: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-1818
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:51:54.222: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1818" for this suite.
Dec  3 15:52:16.264: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:52:16.644: INFO: namespace kubelet-test-1818 deletion completed in 22.411738638s
•SS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:52:16.644: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7661
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-map-85757e66-2eb4-4b01-ad8b-4a82d0254288
STEP: Creating a pod to test consume secrets
Dec  3 15:52:16.855: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-5f5047cc-b947-4617-97e1-608d32be17d6" in namespace "projected-7661" to be "success or failure"
Dec  3 15:52:16.865: INFO: Pod "pod-projected-secrets-5f5047cc-b947-4617-97e1-608d32be17d6": Phase="Pending", Reason="", readiness=false. Elapsed: 9.584643ms
Dec  3 15:52:18.875: INFO: Pod "pod-projected-secrets-5f5047cc-b947-4617-97e1-608d32be17d6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01996607s
STEP: Saw pod success
Dec  3 15:52:18.875: INFO: Pod "pod-projected-secrets-5f5047cc-b947-4617-97e1-608d32be17d6" satisfied condition "success or failure"
Dec  3 15:52:18.885: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod pod-projected-secrets-5f5047cc-b947-4617-97e1-608d32be17d6 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  3 15:52:18.917: INFO: Waiting for pod pod-projected-secrets-5f5047cc-b947-4617-97e1-608d32be17d6 to disappear
Dec  3 15:52:18.927: INFO: Pod pod-projected-secrets-5f5047cc-b947-4617-97e1-608d32be17d6 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:52:18.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7661" for this suite.
Dec  3 15:52:24.980: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:52:25.366: INFO: namespace projected-7661 deletion completed in 6.416911607s
•SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:52:25.366: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2793
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec  3 15:52:25.561: INFO: Waiting up to 5m0s for pod "pod-7f0e2d4e-9af6-49fc-8d30-6d2226a847c0" in namespace "emptydir-2793" to be "success or failure"
Dec  3 15:52:25.571: INFO: Pod "pod-7f0e2d4e-9af6-49fc-8d30-6d2226a847c0": Phase="Pending", Reason="", readiness=false. Elapsed: 9.900564ms
Dec  3 15:52:27.581: INFO: Pod "pod-7f0e2d4e-9af6-49fc-8d30-6d2226a847c0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020700252s
STEP: Saw pod success
Dec  3 15:52:27.582: INFO: Pod "pod-7f0e2d4e-9af6-49fc-8d30-6d2226a847c0" satisfied condition "success or failure"
Dec  3 15:52:27.592: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod pod-7f0e2d4e-9af6-49fc-8d30-6d2226a847c0 container test-container: <nil>
STEP: delete the pod
Dec  3 15:52:27.624: INFO: Waiting for pod pod-7f0e2d4e-9af6-49fc-8d30-6d2226a847c0 to disappear
Dec  3 15:52:27.634: INFO: Pod pod-7f0e2d4e-9af6-49fc-8d30-6d2226a847c0 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:52:27.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2793" for this suite.
Dec  3 15:52:33.686: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:52:34.075: INFO: namespace emptydir-2793 deletion completed in 6.422400165s
•SSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:52:34.076: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-880
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap that has name configmap-test-emptyKey-804779b1-02af-4b57-9496-0639eb1dced0
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:52:34.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-880" for this suite.
Dec  3 15:52:40.311: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:52:40.732: INFO: namespace configmap-880 deletion completed in 6.453008413s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:52:40.732: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-kubelet-etc-hosts-8370
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Dec  3 15:52:47.007: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8370 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:52:47.007: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:52:47.444: INFO: Exec stderr: ""
Dec  3 15:52:47.444: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8370 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:52:47.444: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:52:47.885: INFO: Exec stderr: ""
Dec  3 15:52:47.885: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8370 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:52:47.885: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:52:48.404: INFO: Exec stderr: ""
Dec  3 15:52:48.404: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8370 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:52:48.404: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:52:48.841: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Dec  3 15:52:48.841: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8370 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:52:48.841: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:52:49.301: INFO: Exec stderr: ""
Dec  3 15:52:49.302: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8370 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:52:49.302: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:52:49.782: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Dec  3 15:52:49.782: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8370 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:52:49.782: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:52:50.267: INFO: Exec stderr: ""
Dec  3 15:52:50.267: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8370 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:52:50.267: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:52:50.703: INFO: Exec stderr: ""
Dec  3 15:52:50.709: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-8370 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:52:50.709: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:52:51.179: INFO: Exec stderr: ""
Dec  3 15:52:51.179: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-8370 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:52:51.179: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:52:51.643: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:52:51.643: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-8370" for this suite.
Dec  3 15:53:33.781: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:53:34.162: INFO: namespace e2e-kubelet-etc-hosts-8370 deletion completed in 42.412930409s
•SSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:53:34.177: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-1171
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Dec  3 15:53:36.421: INFO: Asynchronously running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Dec  3 15:53:41.563: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:53:41.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1171" for this suite.
Dec  3 15:53:47.616: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:53:47.999: INFO: namespace pods-1171 deletion completed in 6.414730618s
•SSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:53:47.999: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-3569
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test substitution in container's command
Dec  3 15:53:48.198: INFO: Waiting up to 5m0s for pod "var-expansion-65e89e27-94f9-4a39-8788-ce6b0b3e557c" in namespace "var-expansion-3569" to be "success or failure"
Dec  3 15:53:48.208: INFO: Pod "var-expansion-65e89e27-94f9-4a39-8788-ce6b0b3e557c": Phase="Pending", Reason="", readiness=false. Elapsed: 9.580914ms
Dec  3 15:53:50.218: INFO: Pod "var-expansion-65e89e27-94f9-4a39-8788-ce6b0b3e557c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020231238s
STEP: Saw pod success
Dec  3 15:53:50.218: INFO: Pod "var-expansion-65e89e27-94f9-4a39-8788-ce6b0b3e557c" satisfied condition "success or failure"
Dec  3 15:53:50.228: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod var-expansion-65e89e27-94f9-4a39-8788-ce6b0b3e557c container dapi-container: <nil>
STEP: delete the pod
Dec  3 15:53:50.259: INFO: Waiting for pod var-expansion-65e89e27-94f9-4a39-8788-ce6b0b3e557c to disappear
Dec  3 15:53:50.268: INFO: Pod var-expansion-65e89e27-94f9-4a39-8788-ce6b0b3e557c no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:53:50.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-3569" for this suite.
Dec  3 15:53:56.319: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:53:56.718: INFO: namespace var-expansion-3569 deletion completed in 6.430592158s
•SSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:53:56.718: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-2835
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-downwardapi-5w6r
STEP: Creating a pod to test atomic-volume-subpath
Dec  3 15:53:56.932: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-5w6r" in namespace "subpath-2835" to be "success or failure"
Dec  3 15:53:56.942: INFO: Pod "pod-subpath-test-downwardapi-5w6r": Phase="Pending", Reason="", readiness=false. Elapsed: 9.434254ms
Dec  3 15:53:58.952: INFO: Pod "pod-subpath-test-downwardapi-5w6r": Phase="Running", Reason="", readiness=true. Elapsed: 2.019741374s
Dec  3 15:54:00.963: INFO: Pod "pod-subpath-test-downwardapi-5w6r": Phase="Running", Reason="", readiness=true. Elapsed: 4.030490551s
Dec  3 15:54:02.974: INFO: Pod "pod-subpath-test-downwardapi-5w6r": Phase="Running", Reason="", readiness=true. Elapsed: 6.041139123s
Dec  3 15:54:04.984: INFO: Pod "pod-subpath-test-downwardapi-5w6r": Phase="Running", Reason="", readiness=true. Elapsed: 8.051324895s
Dec  3 15:54:06.994: INFO: Pod "pod-subpath-test-downwardapi-5w6r": Phase="Running", Reason="", readiness=true. Elapsed: 10.061649259s
Dec  3 15:54:09.005: INFO: Pod "pod-subpath-test-downwardapi-5w6r": Phase="Running", Reason="", readiness=true. Elapsed: 12.072158458s
Dec  3 15:54:11.015: INFO: Pod "pod-subpath-test-downwardapi-5w6r": Phase="Running", Reason="", readiness=true. Elapsed: 14.082609437s
Dec  3 15:54:13.026: INFO: Pod "pod-subpath-test-downwardapi-5w6r": Phase="Running", Reason="", readiness=true. Elapsed: 16.09334434s
Dec  3 15:54:15.036: INFO: Pod "pod-subpath-test-downwardapi-5w6r": Phase="Running", Reason="", readiness=true. Elapsed: 18.103745255s
Dec  3 15:54:17.047: INFO: Pod "pod-subpath-test-downwardapi-5w6r": Phase="Running", Reason="", readiness=true. Elapsed: 20.114241706s
Dec  3 15:54:19.057: INFO: Pod "pod-subpath-test-downwardapi-5w6r": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.124812766s
STEP: Saw pod success
Dec  3 15:54:19.057: INFO: Pod "pod-subpath-test-downwardapi-5w6r" satisfied condition "success or failure"
Dec  3 15:54:19.067: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod pod-subpath-test-downwardapi-5w6r container test-container-subpath-downwardapi-5w6r: <nil>
STEP: delete the pod
Dec  3 15:54:19.100: INFO: Waiting for pod pod-subpath-test-downwardapi-5w6r to disappear
Dec  3 15:54:19.109: INFO: Pod pod-subpath-test-downwardapi-5w6r no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-5w6r
Dec  3 15:54:19.109: INFO: Deleting pod "pod-subpath-test-downwardapi-5w6r" in namespace "subpath-2835"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:54:19.119: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2835" for this suite.
Dec  3 15:54:25.168: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:54:25.552: INFO: namespace subpath-2835 deletion completed in 6.414616551s
•SSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:54:25.553: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6661
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-c4a98361-eabc-4dff-aa4f-36e49a28b49b
STEP: Creating a pod to test consume secrets
Dec  3 15:54:25.759: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-7d483958-3e15-4c3b-be69-54fad55f381a" in namespace "projected-6661" to be "success or failure"
Dec  3 15:54:25.769: INFO: Pod "pod-projected-secrets-7d483958-3e15-4c3b-be69-54fad55f381a": Phase="Pending", Reason="", readiness=false. Elapsed: 9.939584ms
Dec  3 15:54:27.780: INFO: Pod "pod-projected-secrets-7d483958-3e15-4c3b-be69-54fad55f381a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020433198s
STEP: Saw pod success
Dec  3 15:54:27.780: INFO: Pod "pod-projected-secrets-7d483958-3e15-4c3b-be69-54fad55f381a" satisfied condition "success or failure"
Dec  3 15:54:27.790: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod pod-projected-secrets-7d483958-3e15-4c3b-be69-54fad55f381a container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  3 15:54:27.823: INFO: Waiting for pod pod-projected-secrets-7d483958-3e15-4c3b-be69-54fad55f381a to disappear
Dec  3 15:54:27.833: INFO: Pod pod-projected-secrets-7d483958-3e15-4c3b-be69-54fad55f381a no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:54:27.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6661" for this suite.
Dec  3 15:54:33.883: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:54:34.309: INFO: namespace projected-6661 deletion completed in 6.457498255s
•SSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:54:34.309: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-1929
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec  3 15:54:40.609: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 15:54:40.620: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  3 15:54:42.620: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 15:54:42.631: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  3 15:54:44.620: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 15:54:44.632: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  3 15:54:46.620: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 15:54:46.631: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  3 15:54:48.620: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 15:54:48.631: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  3 15:54:50.620: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 15:54:50.631: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  3 15:54:52.620: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 15:54:52.633: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  3 15:54:54.620: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 15:54:54.631: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  3 15:54:56.620: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 15:54:56.631: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  3 15:54:58.620: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 15:54:58.631: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:54:58.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-1929" for this suite.
Dec  3 15:55:20.680: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:55:21.067: INFO: namespace container-lifecycle-hook-1929 deletion completed in 22.417957996s
•SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:55:21.068: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7573
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1516
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Dec  3 15:55:21.251: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-7573'
Dec  3 15:55:21.629: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec  3 15:55:21.629: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: rolling-update to same image controller
Dec  3 15:55:21.650: INFO: scanned /root for discovery docs: <nil>
Dec  3 15:55:21.651: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-7573'
Dec  3 15:55:32.725: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Dec  3 15:55:32.725: INFO: stdout: "Created e2e-test-nginx-rc-2cfaa3d98916388e818a1070822ace0e\nScaling up e2e-test-nginx-rc-2cfaa3d98916388e818a1070822ace0e from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-2cfaa3d98916388e818a1070822ace0e up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-2cfaa3d98916388e818a1070822ace0e to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Dec  3 15:55:32.725: INFO: stdout: "Created e2e-test-nginx-rc-2cfaa3d98916388e818a1070822ace0e\nScaling up e2e-test-nginx-rc-2cfaa3d98916388e818a1070822ace0e from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-2cfaa3d98916388e818a1070822ace0e up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-2cfaa3d98916388e818a1070822ace0e to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Dec  3 15:55:32.725: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-7573'
Dec  3 15:55:32.852: INFO: stderr: ""
Dec  3 15:55:32.852: INFO: stdout: "e2e-test-nginx-rc-2cfaa3d98916388e818a1070822ace0e-j5hcq "
Dec  3 15:55:32.852: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods e2e-test-nginx-rc-2cfaa3d98916388e818a1070822ace0e-j5hcq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7573'
Dec  3 15:55:32.966: INFO: stderr: ""
Dec  3 15:55:32.966: INFO: stdout: "true"
Dec  3 15:55:32.966: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods e2e-test-nginx-rc-2cfaa3d98916388e818a1070822ace0e-j5hcq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7573'
Dec  3 15:55:33.080: INFO: stderr: ""
Dec  3 15:55:33.080: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Dec  3 15:55:33.080: INFO: e2e-test-nginx-rc-2cfaa3d98916388e818a1070822ace0e-j5hcq is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1522
Dec  3 15:55:33.080: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete rc e2e-test-nginx-rc --namespace=kubectl-7573'
Dec  3 15:55:33.207: INFO: stderr: ""
Dec  3 15:55:33.207: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:55:33.207: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7573" for this suite.
Dec  3 15:55:39.261: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:55:39.643: INFO: namespace kubectl-7573 deletion completed in 6.417366703s
•SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:55:39.643: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8009
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-08f77f8a-109f-4f57-9ab3-170c7c9c19bc
STEP: Creating a pod to test consume configMaps
Dec  3 15:55:39.849: INFO: Waiting up to 5m0s for pod "pod-configmaps-0aa431a2-641c-4ce6-8845-1bb5134329fd" in namespace "configmap-8009" to be "success or failure"
Dec  3 15:55:39.859: INFO: Pod "pod-configmaps-0aa431a2-641c-4ce6-8845-1bb5134329fd": Phase="Pending", Reason="", readiness=false. Elapsed: 9.518969ms
Dec  3 15:55:41.869: INFO: Pod "pod-configmaps-0aa431a2-641c-4ce6-8845-1bb5134329fd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020174461s
STEP: Saw pod success
Dec  3 15:55:41.869: INFO: Pod "pod-configmaps-0aa431a2-641c-4ce6-8845-1bb5134329fd" satisfied condition "success or failure"
Dec  3 15:55:41.879: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod pod-configmaps-0aa431a2-641c-4ce6-8845-1bb5134329fd container configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 15:55:41.911: INFO: Waiting for pod pod-configmaps-0aa431a2-641c-4ce6-8845-1bb5134329fd to disappear
Dec  3 15:55:41.921: INFO: Pod pod-configmaps-0aa431a2-641c-4ce6-8845-1bb5134329fd no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:55:41.921: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8009" for this suite.
Dec  3 15:55:47.971: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:55:48.391: INFO: namespace configmap-8009 deletion completed in 6.451810155s
•SSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:55:48.391: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-6372
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-6372
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-6372
STEP: Creating statefulset with conflicting port in namespace statefulset-6372
STEP: Waiting until pod test-pod will start running in namespace statefulset-6372
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-6372
Dec  3 15:55:50.647: INFO: Observed stateful pod in namespace: statefulset-6372, name: ss-0, uid: ed80bfe8-fe65-4285-98b8-1b02600d7a0a, status phase: Failed. Waiting for statefulset controller to delete.
Dec  3 15:55:50.672: INFO: Observed stateful pod in namespace: statefulset-6372, name: ss-0, uid: ed80bfe8-fe65-4285-98b8-1b02600d7a0a, status phase: Failed. Waiting for statefulset controller to delete.
Dec  3 15:55:50.674: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-6372
STEP: Removing pod with conflicting port in namespace statefulset-6372
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-6372 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Dec  3 15:55:52.708: INFO: Deleting all statefulset in ns statefulset-6372
Dec  3 15:55:52.718: INFO: Scaling statefulset ss to 0
Dec  3 15:56:12.761: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 15:56:12.771: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:56:12.803: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6372" for this suite.
Dec  3 15:56:18.853: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:56:19.233: INFO: namespace statefulset-6372 deletion completed in 6.411655333s
•SSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:56:19.233: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-3775
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Dec  3 15:56:19.455: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3775,SelfLink:/api/v1/namespaces/watch-3775/configmaps/e2e-watch-test-configmap-a,UID:d2d72666-384f-447b-8879-7edbdd11fa27,ResourceVersion:21370,Generation:0,CreationTimestamp:2019-12-03 15:56:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  3 15:56:19.455: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3775,SelfLink:/api/v1/namespaces/watch-3775/configmaps/e2e-watch-test-configmap-a,UID:d2d72666-384f-447b-8879-7edbdd11fa27,ResourceVersion:21370,Generation:0,CreationTimestamp:2019-12-03 15:56:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Dec  3 15:56:29.477: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3775,SelfLink:/api/v1/namespaces/watch-3775/configmaps/e2e-watch-test-configmap-a,UID:d2d72666-384f-447b-8879-7edbdd11fa27,ResourceVersion:21396,Generation:0,CreationTimestamp:2019-12-03 15:56:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Dec  3 15:56:29.477: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3775,SelfLink:/api/v1/namespaces/watch-3775/configmaps/e2e-watch-test-configmap-a,UID:d2d72666-384f-447b-8879-7edbdd11fa27,ResourceVersion:21396,Generation:0,CreationTimestamp:2019-12-03 15:56:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Dec  3 15:56:39.500: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3775,SelfLink:/api/v1/namespaces/watch-3775/configmaps/e2e-watch-test-configmap-a,UID:d2d72666-384f-447b-8879-7edbdd11fa27,ResourceVersion:21422,Generation:0,CreationTimestamp:2019-12-03 15:56:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  3 15:56:39.500: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3775,SelfLink:/api/v1/namespaces/watch-3775/configmaps/e2e-watch-test-configmap-a,UID:d2d72666-384f-447b-8879-7edbdd11fa27,ResourceVersion:21422,Generation:0,CreationTimestamp:2019-12-03 15:56:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Dec  3 15:56:49.515: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3775,SelfLink:/api/v1/namespaces/watch-3775/configmaps/e2e-watch-test-configmap-a,UID:d2d72666-384f-447b-8879-7edbdd11fa27,ResourceVersion:21447,Generation:0,CreationTimestamp:2019-12-03 15:56:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  3 15:56:49.515: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3775,SelfLink:/api/v1/namespaces/watch-3775/configmaps/e2e-watch-test-configmap-a,UID:d2d72666-384f-447b-8879-7edbdd11fa27,ResourceVersion:21447,Generation:0,CreationTimestamp:2019-12-03 15:56:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Dec  3 15:56:59.529: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-3775,SelfLink:/api/v1/namespaces/watch-3775/configmaps/e2e-watch-test-configmap-b,UID:fb6d681c-aded-4d42-b5dc-2b1c2c4bd81c,ResourceVersion:21472,Generation:0,CreationTimestamp:2019-12-03 15:56:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  3 15:56:59.529: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-3775,SelfLink:/api/v1/namespaces/watch-3775/configmaps/e2e-watch-test-configmap-b,UID:fb6d681c-aded-4d42-b5dc-2b1c2c4bd81c,ResourceVersion:21472,Generation:0,CreationTimestamp:2019-12-03 15:56:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Dec  3 15:57:09.542: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-3775,SelfLink:/api/v1/namespaces/watch-3775/configmaps/e2e-watch-test-configmap-b,UID:fb6d681c-aded-4d42-b5dc-2b1c2c4bd81c,ResourceVersion:21499,Generation:0,CreationTimestamp:2019-12-03 15:56:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  3 15:57:09.542: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-3775,SelfLink:/api/v1/namespaces/watch-3775/configmaps/e2e-watch-test-configmap-b,UID:fb6d681c-aded-4d42-b5dc-2b1c2c4bd81c,ResourceVersion:21499,Generation:0,CreationTimestamp:2019-12-03 15:56:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:57:19.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3775" for this suite.
Dec  3 15:57:25.594: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:57:25.973: INFO: namespace watch-3775 deletion completed in 6.410556288s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:57:25.974: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-1538
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec  3 15:57:26.178: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec  3 15:57:28.199: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Dec  3 15:57:30.210: INFO: Creating deployment "test-rollover-deployment"
Dec  3 15:57:30.231: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Dec  3 15:57:32.251: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Dec  3 15:57:32.272: INFO: Ensure that both replica sets have 1 created replica
Dec  3 15:57:32.293: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Dec  3 15:57:32.315: INFO: Updating deployment test-rollover-deployment
Dec  3 15:57:32.315: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Dec  3 15:57:34.335: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Dec  3 15:57:34.355: INFO: Make sure deployment "test-rollover-deployment" is complete
Dec  3 15:57:34.376: INFO: all replica sets need to contain the pod-template-hash label
Dec  3 15:57:34.376: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985450, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985450, loc:(*time.Location)(0x7ed1a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985453, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985450, loc:(*time.Location)(0x7ed1a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 15:57:36.400: INFO: all replica sets need to contain the pod-template-hash label
Dec  3 15:57:36.400: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985450, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985450, loc:(*time.Location)(0x7ed1a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985453, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985450, loc:(*time.Location)(0x7ed1a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 15:57:38.398: INFO: all replica sets need to contain the pod-template-hash label
Dec  3 15:57:38.398: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985450, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985450, loc:(*time.Location)(0x7ed1a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985453, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985450, loc:(*time.Location)(0x7ed1a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 15:57:40.397: INFO: all replica sets need to contain the pod-template-hash label
Dec  3 15:57:40.397: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985450, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985450, loc:(*time.Location)(0x7ed1a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985453, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985450, loc:(*time.Location)(0x7ed1a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 15:57:42.397: INFO: all replica sets need to contain the pod-template-hash label
Dec  3 15:57:42.397: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985450, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985450, loc:(*time.Location)(0x7ed1a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985453, loc:(*time.Location)(0x7ed1a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985450, loc:(*time.Location)(0x7ed1a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 15:57:44.397: INFO: 
Dec  3 15:57:44.397: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Dec  3 15:57:44.428: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-1538,SelfLink:/apis/apps/v1/namespaces/deployment-1538/deployments/test-rollover-deployment,UID:b174e21d-9114-4e8a-93f6-b4d69528ba5e,ResourceVersion:21645,Generation:2,CreationTimestamp:2019-12-03 15:57:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-12-03 15:57:30 +0000 UTC 2019-12-03 15:57:30 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-12-03 15:57:43 +0000 UTC 2019-12-03 15:57:30 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-854595fc44" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Dec  3 15:57:44.439: INFO: New ReplicaSet "test-rollover-deployment-854595fc44" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-854595fc44,GenerateName:,Namespace:deployment-1538,SelfLink:/apis/apps/v1/namespaces/deployment-1538/replicasets/test-rollover-deployment-854595fc44,UID:ae4f7291-7430-4f73-887d-2233c0d466e3,ResourceVersion:21638,Generation:2,CreationTimestamp:2019-12-03 15:57:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment b174e21d-9114-4e8a-93f6-b4d69528ba5e 0xc0031c33c7 0xc0031c33c8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Dec  3 15:57:44.439: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Dec  3 15:57:44.439: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-1538,SelfLink:/apis/apps/v1/namespaces/deployment-1538/replicasets/test-rollover-controller,UID:bdcaa9a2-0868-4d2d-a252-85a48145124a,ResourceVersion:21644,Generation:2,CreationTimestamp:2019-12-03 15:57:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment b174e21d-9114-4e8a-93f6-b4d69528ba5e 0xc0031c32f7 0xc0031c32f8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  3 15:57:44.439: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-9b8b997cf,GenerateName:,Namespace:deployment-1538,SelfLink:/apis/apps/v1/namespaces/deployment-1538/replicasets/test-rollover-deployment-9b8b997cf,UID:12510ff0-5000-49a8-bf51-2a820991dd04,ResourceVersion:21601,Generation:2,CreationTimestamp:2019-12-03 15:57:30 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment b174e21d-9114-4e8a-93f6-b4d69528ba5e 0xc0031c3490 0xc0031c3491}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Dec  3 15:57:44.450: INFO: Pod "test-rollover-deployment-854595fc44-mk8xn" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-854595fc44-mk8xn,GenerateName:test-rollover-deployment-854595fc44-,Namespace:deployment-1538,SelfLink:/api/v1/namespaces/deployment-1538/pods/test-rollover-deployment-854595fc44-mk8xn,UID:8b5f524a-458f-46d4-8bad-f154d3f90cf2,ResourceVersion:21611,Generation:0,CreationTimestamp:2019-12-03 15:57:32 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{cni.projectcalico.org/podIP: 100.64.1.32/32,kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-854595fc44 ae4f7291-7430-4f73-887d-2233c0d466e3 0xc00308c0c7 0xc00308c0c8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-257fp {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-257fp,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-257fp true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00308c130} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00308c150}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 15:57:32 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 15:57:33 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 15:57:33 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 15:57:32 +0000 UTC  }],Message:,Reason:,HostIP:10.250.0.3,PodIP:100.64.1.32,StartTime:2019-12-03 15:57:32 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-12-03 15:57:33 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://a3cd18ee3dbc6373c40a8d39997b05bc4758b81bad666df0826ab17e2cead969}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:57:44.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1538" for this suite.
Dec  3 15:57:50.509: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:57:50.912: INFO: namespace deployment-1538 deletion completed in 6.442828224s
•SSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:57:50.912: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-902
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name projected-secret-test-c12ddaa0-5194-4c6a-b2fd-77f85a7d6fd3
STEP: Creating a pod to test consume secrets
Dec  3 15:57:51.123: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-787bceab-d114-458b-b579-d418ad8402b7" in namespace "projected-902" to be "success or failure"
Dec  3 15:57:51.133: INFO: Pod "pod-projected-secrets-787bceab-d114-458b-b579-d418ad8402b7": Phase="Pending", Reason="", readiness=false. Elapsed: 10.289851ms
Dec  3 15:57:53.144: INFO: Pod "pod-projected-secrets-787bceab-d114-458b-b579-d418ad8402b7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021172532s
STEP: Saw pod success
Dec  3 15:57:53.144: INFO: Pod "pod-projected-secrets-787bceab-d114-458b-b579-d418ad8402b7" satisfied condition "success or failure"
Dec  3 15:57:53.154: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod pod-projected-secrets-787bceab-d114-458b-b579-d418ad8402b7 container secret-volume-test: <nil>
STEP: delete the pod
Dec  3 15:57:53.189: INFO: Waiting for pod pod-projected-secrets-787bceab-d114-458b-b579-d418ad8402b7 to disappear
Dec  3 15:57:53.199: INFO: Pod pod-projected-secrets-787bceab-d114-458b-b579-d418ad8402b7 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:57:53.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-902" for this suite.
Dec  3 15:57:59.249: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:57:59.636: INFO: namespace projected-902 deletion completed in 6.417895749s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:57:59.636: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5265
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir volume type on node default medium
Dec  3 15:57:59.834: INFO: Waiting up to 5m0s for pod "pod-80ff8164-316b-4d90-94e7-49f085d22f7e" in namespace "emptydir-5265" to be "success or failure"
Dec  3 15:57:59.843: INFO: Pod "pod-80ff8164-316b-4d90-94e7-49f085d22f7e": Phase="Pending", Reason="", readiness=false. Elapsed: 9.561327ms
Dec  3 15:58:01.854: INFO: Pod "pod-80ff8164-316b-4d90-94e7-49f085d22f7e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020090154s
STEP: Saw pod success
Dec  3 15:58:01.854: INFO: Pod "pod-80ff8164-316b-4d90-94e7-49f085d22f7e" satisfied condition "success or failure"
Dec  3 15:58:01.864: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod pod-80ff8164-316b-4d90-94e7-49f085d22f7e container test-container: <nil>
STEP: delete the pod
Dec  3 15:58:01.897: INFO: Waiting for pod pod-80ff8164-316b-4d90-94e7-49f085d22f7e to disappear
Dec  3 15:58:01.908: INFO: Pod pod-80ff8164-316b-4d90-94e7-49f085d22f7e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:58:01.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5265" for this suite.
Dec  3 15:58:07.957: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:58:08.354: INFO: namespace emptydir-5265 deletion completed in 6.427563733s
•SSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:58:08.354: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-3955
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-3955
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec  3 15:58:08.537: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec  3 15:58:28.714: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.64.1.36:8080/dial?request=hostName&protocol=http&host=100.64.1.35&port=8080&tries=1'] Namespace:pod-network-test-3955 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:58:28.714: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:58:29.246: INFO: Waiting for endpoints: map[]
Dec  3 15:58:29.257: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.64.1.36:8080/dial?request=hostName&protocol=http&host=100.64.0.69&port=8080&tries=1'] Namespace:pod-network-test-3955 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:58:29.257: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:58:29.692: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:58:29.692: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3955" for this suite.
Dec  3 15:58:51.744: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:58:52.127: INFO: namespace pod-network-test-3955 deletion completed in 22.414630752s
•S
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:58:52.127: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-2109
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-3307
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-7498
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:58:58.712: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-2109" for this suite.
Dec  3 15:59:04.760: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:59:05.144: INFO: namespace namespaces-2109 deletion completed in 6.414130835s
STEP: Destroying namespace "nsdeletetest-3307" for this suite.
Dec  3 15:59:05.154: INFO: Namespace nsdeletetest-3307 was already deleted
STEP: Destroying namespace "nsdeletetest-7498" for this suite.
Dec  3 15:59:11.186: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:59:11.568: INFO: namespace nsdeletetest-7498 deletion completed in 6.413452785s
•SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:59:11.568: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-6416
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Dec  3 15:59:11.751: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:59:15.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6416" for this suite.
Dec  3 15:59:21.530: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:59:21.914: INFO: namespace init-container-6416 deletion completed in 6.414696516s
•SSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:59:21.914: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-9175
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec  3 15:59:22.096: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:59:22.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-9175" for this suite.
Dec  3 15:59:28.750: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:59:29.131: INFO: namespace custom-resource-definition-9175 deletion completed in 6.420508532s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:59:29.132: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6751
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-upd-cc3c4fab-f8cc-4fe1-8eda-c8c5d27f176c
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:59:31.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6751" for this suite.
Dec  3 15:59:53.536: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:59:53.958: INFO: namespace configmap-6751 deletion completed in 22.452713067s
•SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 15:59:53.958: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5941
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec  3 15:59:54.154: INFO: Waiting up to 5m0s for pod "pod-83e72edd-de7a-402e-a99e-07b2ee143dd6" in namespace "emptydir-5941" to be "success or failure"
Dec  3 15:59:54.164: INFO: Pod "pod-83e72edd-de7a-402e-a99e-07b2ee143dd6": Phase="Pending", Reason="", readiness=false. Elapsed: 9.419699ms
Dec  3 15:59:56.174: INFO: Pod "pod-83e72edd-de7a-402e-a99e-07b2ee143dd6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019841657s
STEP: Saw pod success
Dec  3 15:59:56.174: INFO: Pod "pod-83e72edd-de7a-402e-a99e-07b2ee143dd6" satisfied condition "success or failure"
Dec  3 15:59:56.184: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod pod-83e72edd-de7a-402e-a99e-07b2ee143dd6 container test-container: <nil>
STEP: delete the pod
Dec  3 15:59:56.220: INFO: Waiting for pod pod-83e72edd-de7a-402e-a99e-07b2ee143dd6 to disappear
Dec  3 15:59:56.229: INFO: Pod pod-83e72edd-de7a-402e-a99e-07b2ee143dd6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 15:59:56.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5941" for this suite.
Dec  3 16:00:02.279: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:00:02.666: INFO: namespace emptydir-5941 deletion completed in 6.418132063s
•SSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 16:00:02.667: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-6149
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 16:00:02.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6149" for this suite.
Dec  3 16:00:08.905: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:00:09.319: INFO: namespace services-6149 deletion completed in 6.445877125s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 16:00:09.319: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-5176
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Dec  3 16:00:09.543: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"9299fbfa-98bc-42c0-aa85-f681a6496456", Controller:(*bool)(0xc002512e1a), BlockOwnerDeletion:(*bool)(0xc002512e1b)}}
Dec  3 16:00:09.554: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"f42506bc-0350-4d87-a4f8-acf9f3a8aff2", Controller:(*bool)(0xc0032a6356), BlockOwnerDeletion:(*bool)(0xc0032a6357)}}
Dec  3 16:00:09.565: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"a412ad46-c3a9-488c-a956-c45f26163b4f", Controller:(*bool)(0xc002eceb06), BlockOwnerDeletion:(*bool)(0xc002eceb07)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 16:00:14.587: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5176" for this suite.
Dec  3 16:00:20.641: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:00:21.018: INFO: namespace gc-5176 deletion completed in 6.409653116s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 16:00:21.019: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-224
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod test-webserver-4c51d4fa-1c4d-4859-827d-ae0071720c71 in namespace container-probe-224
Dec  3 16:00:23.234: INFO: Started pod test-webserver-4c51d4fa-1c4d-4859-827d-ae0071720c71 in namespace container-probe-224
STEP: checking the pod's current state and verifying that restartCount is present
Dec  3 16:00:23.245: INFO: Initial restart count of pod test-webserver-4c51d4fa-1c4d-4859-827d-ae0071720c71 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 16:04:24.529: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-224" for this suite.
Dec  3 16:04:30.579: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:04:30.962: INFO: namespace container-probe-224 deletion completed in 6.414616752s
•SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 16:04:30.963: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5987
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secret-namespace-7257
STEP: Creating secret with name secret-test-a6ffd9ba-a634-4895-9254-0d1641790d6b
STEP: Creating a pod to test consume secrets
Dec  3 16:04:31.351: INFO: Waiting up to 5m0s for pod "pod-secrets-35fff53d-2829-4c9e-91df-04262061c7d2" in namespace "secrets-5987" to be "success or failure"
Dec  3 16:04:31.360: INFO: Pod "pod-secrets-35fff53d-2829-4c9e-91df-04262061c7d2": Phase="Pending", Reason="", readiness=false. Elapsed: 9.580418ms
Dec  3 16:04:33.371: INFO: Pod "pod-secrets-35fff53d-2829-4c9e-91df-04262061c7d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020065212s
STEP: Saw pod success
Dec  3 16:04:33.371: INFO: Pod "pod-secrets-35fff53d-2829-4c9e-91df-04262061c7d2" satisfied condition "success or failure"
Dec  3 16:04:33.381: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod pod-secrets-35fff53d-2829-4c9e-91df-04262061c7d2 container secret-volume-test: <nil>
STEP: delete the pod
Dec  3 16:04:33.417: INFO: Waiting for pod pod-secrets-35fff53d-2829-4c9e-91df-04262061c7d2 to disappear
Dec  3 16:04:33.427: INFO: Pod pod-secrets-35fff53d-2829-4c9e-91df-04262061c7d2 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 16:04:33.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5987" for this suite.
Dec  3 16:04:39.477: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:04:39.878: INFO: namespace secrets-5987 deletion completed in 6.432697346s
STEP: Destroying namespace "secret-namespace-7257" for this suite.
Dec  3 16:04:45.909: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:04:46.290: INFO: namespace secret-namespace-7257 deletion completed in 6.412271519s
•SSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 16:04:46.290: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8581
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-165a76f9-7add-4215-b71b-0e9beb8bcffd
STEP: Creating a pod to test consume secrets
Dec  3 16:04:46.494: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ff039ead-2726-4f1c-b72d-9b28a5a83c66" in namespace "projected-8581" to be "success or failure"
Dec  3 16:04:46.504: INFO: Pod "pod-projected-secrets-ff039ead-2726-4f1c-b72d-9b28a5a83c66": Phase="Pending", Reason="", readiness=false. Elapsed: 9.440956ms
Dec  3 16:04:48.515: INFO: Pod "pod-projected-secrets-ff039ead-2726-4f1c-b72d-9b28a5a83c66": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020321279s
STEP: Saw pod success
Dec  3 16:04:48.515: INFO: Pod "pod-projected-secrets-ff039ead-2726-4f1c-b72d-9b28a5a83c66" satisfied condition "success or failure"
Dec  3 16:04:48.525: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod pod-projected-secrets-ff039ead-2726-4f1c-b72d-9b28a5a83c66 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  3 16:04:48.557: INFO: Waiting for pod pod-projected-secrets-ff039ead-2726-4f1c-b72d-9b28a5a83c66 to disappear
Dec  3 16:04:48.567: INFO: Pod pod-projected-secrets-ff039ead-2726-4f1c-b72d-9b28a5a83c66 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 16:04:48.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8581" for this suite.
Dec  3 16:04:54.616: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:04:55.014: INFO: namespace projected-8581 deletion completed in 6.428114331s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 16:04:55.015: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-3971
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating service endpoint-test2 in namespace services-3971
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3971 to expose endpoints map[]
Dec  3 16:04:55.224: INFO: successfully validated that service endpoint-test2 in namespace services-3971 exposes endpoints map[] (9.669022ms elapsed)
STEP: Creating pod pod1 in namespace services-3971
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3971 to expose endpoints map[pod1:[80]]
Dec  3 16:04:57.301: INFO: successfully validated that service endpoint-test2 in namespace services-3971 exposes endpoints map[pod1:[80]] (2.063447637s elapsed)
STEP: Creating pod pod2 in namespace services-3971
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3971 to expose endpoints map[pod1:[80] pod2:[80]]
Dec  3 16:04:59.404: INFO: successfully validated that service endpoint-test2 in namespace services-3971 exposes endpoints map[pod1:[80] pod2:[80]] (2.091627544s elapsed)
STEP: Deleting pod pod1 in namespace services-3971
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3971 to expose endpoints map[pod2:[80]]
Dec  3 16:04:59.436: INFO: successfully validated that service endpoint-test2 in namespace services-3971 exposes endpoints map[pod2:[80]] (20.35047ms elapsed)
STEP: Deleting pod pod2 in namespace services-3971
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3971 to expose endpoints map[]
Dec  3 16:04:59.458: INFO: successfully validated that service endpoint-test2 in namespace services-3971 exposes endpoints map[] (9.646794ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 16:04:59.478: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3971" for this suite.
Dec  3 16:05:21.528: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:05:21.920: INFO: namespace services-3971 deletion completed in 22.4226088s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92
•SSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 16:05:21.920: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-9696
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override command
Dec  3 16:05:22.117: INFO: Waiting up to 5m0s for pod "client-containers-57833016-8dce-4926-b6ca-00913be14d57" in namespace "containers-9696" to be "success or failure"
Dec  3 16:05:22.128: INFO: Pod "client-containers-57833016-8dce-4926-b6ca-00913be14d57": Phase="Pending", Reason="", readiness=false. Elapsed: 10.100516ms
Dec  3 16:05:24.139: INFO: Pod "client-containers-57833016-8dce-4926-b6ca-00913be14d57": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021102516s
STEP: Saw pod success
Dec  3 16:05:24.139: INFO: Pod "client-containers-57833016-8dce-4926-b6ca-00913be14d57" satisfied condition "success or failure"
Dec  3 16:05:24.149: INFO: Trying to get logs from node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 pod client-containers-57833016-8dce-4926-b6ca-00913be14d57 container test-container: <nil>
STEP: delete the pod
Dec  3 16:05:24.182: INFO: Waiting for pod client-containers-57833016-8dce-4926-b6ca-00913be14d57 to disappear
Dec  3 16:05:24.191: INFO: Pod client-containers-57833016-8dce-4926-b6ca-00913be14d57 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 16:05:24.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-9696" for this suite.
Dec  3 16:05:30.242: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:05:30.662: INFO: namespace containers-9696 deletion completed in 6.45152678s
•SSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 16:05:30.662: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-6732
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec  3 16:05:30.926: INFO: Number of nodes with available pods: 0
Dec  3 16:05:30.926: INFO: Node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 is running more than one daemon pod
Dec  3 16:05:31.955: INFO: Number of nodes with available pods: 0
Dec  3 16:05:31.955: INFO: Node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 is running more than one daemon pod
Dec  3 16:05:32.956: INFO: Number of nodes with available pods: 2
Dec  3 16:05:32.956: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Dec  3 16:05:33.010: INFO: Number of nodes with available pods: 1
Dec  3 16:05:33.010: INFO: Node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 is running more than one daemon pod
Dec  3 16:05:34.038: INFO: Number of nodes with available pods: 1
Dec  3 16:05:34.038: INFO: Node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 is running more than one daemon pod
Dec  3 16:05:35.039: INFO: Number of nodes with available pods: 1
Dec  3 16:05:35.039: INFO: Node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 is running more than one daemon pod
Dec  3 16:05:36.039: INFO: Number of nodes with available pods: 1
Dec  3 16:05:36.039: INFO: Node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 is running more than one daemon pod
Dec  3 16:05:37.039: INFO: Number of nodes with available pods: 1
Dec  3 16:05:37.039: INFO: Node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 is running more than one daemon pod
Dec  3 16:05:38.039: INFO: Number of nodes with available pods: 1
Dec  3 16:05:38.039: INFO: Node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 is running more than one daemon pod
Dec  3 16:05:39.040: INFO: Number of nodes with available pods: 1
Dec  3 16:05:39.040: INFO: Node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 is running more than one daemon pod
Dec  3 16:05:40.039: INFO: Number of nodes with available pods: 1
Dec  3 16:05:40.040: INFO: Node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 is running more than one daemon pod
Dec  3 16:05:41.039: INFO: Number of nodes with available pods: 1
Dec  3 16:05:41.039: INFO: Node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 is running more than one daemon pod
Dec  3 16:05:42.039: INFO: Number of nodes with available pods: 1
Dec  3 16:05:42.039: INFO: Node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 is running more than one daemon pod
Dec  3 16:05:43.039: INFO: Number of nodes with available pods: 1
Dec  3 16:05:43.039: INFO: Node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 is running more than one daemon pod
Dec  3 16:05:44.039: INFO: Number of nodes with available pods: 1
Dec  3 16:05:44.039: INFO: Node shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9 is running more than one daemon pod
Dec  3 16:05:45.039: INFO: Number of nodes with available pods: 2
Dec  3 16:05:45.039: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6732, will wait for the garbage collector to delete the pods
Dec  3 16:05:45.121: INFO: Deleting DaemonSet.extensions daemon-set took: 12.32862ms
Dec  3 16:05:45.221: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.236187ms
Dec  3 16:05:53.132: INFO: Number of nodes with available pods: 0
Dec  3 16:05:53.132: INFO: Number of running nodes: 0, number of available pods: 0
Dec  3 16:05:53.142: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-6732/daemonsets","resourceVersion":"23276"},"items":null}

Dec  3 16:05:53.152: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-6732/pods","resourceVersion":"23276"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 16:05:53.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6732" for this suite.
Dec  3 16:05:59.234: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:05:59.635: INFO: namespace daemonsets-6732 deletion completed in 6.432632446s
•SSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Dec  3 16:05:59.635: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-7448
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-7448
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating stateful set ss in namespace statefulset-7448
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-7448
Dec  3 16:05:59.852: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
Dec  3 16:06:09.864: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Dec  3 16:06:09.874: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7448 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  3 16:06:18.735: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Dec  3 16:06:18.735: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  3 16:06:18.735: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  3 16:06:18.747: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec  3 16:06:28.760: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  3 16:06:28.760: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 16:06:28.801: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999572s
Dec  3 16:06:29.811: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.98956285s
Dec  3 16:06:30.822: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.978918312s
Dec  3 16:06:31.833: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.968296166s
Dec  3 16:06:32.845: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.957270902s
Dec  3 16:06:33.856: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.945743844s
Dec  3 16:06:34.867: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.934509324s
Dec  3 16:06:35.877: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.92364526s
Dec  3 16:06:36.889: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.913055718s
Dec  3 16:06:37.900: INFO: Verifying statefulset ss doesn't scale past 3 for another 901.118405ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-7448
Dec  3 16:06:38.911: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7448 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 16:06:39.520: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Dec  3 16:06:39.520: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  3 16:06:39.520: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  3 16:06:39.520: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7448 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 16:06:40.114: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Dec  3 16:06:40.114: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  3 16:06:40.114: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  3 16:06:40.114: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7448 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 16:06:40.711: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Dec  3 16:06:40.711: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Dec  3 16:06:40.711: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Dec  3 16:06:40.723: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 16:06:40.723: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 16:06:40.723: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Dec  3 16:06:40.733: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7448 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  3 16:06:41.318: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Dec  3 16:06:41.318: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  3 16:06:41.318: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  3 16:06:41.318: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7448 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  3 16:06:41.916: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Dec  3 16:06:41.916: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  3 16:06:41.916: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  3 16:06:41.916: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7448 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Dec  3 16:06:42.651: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Dec  3 16:06:42.651: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Dec  3 16:06:42.651: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Dec  3 16:06:42.651: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 16:06:42.662: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Dec  3 16:06:52.685: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  3 16:06:52.685: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec  3 16:06:52.685: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec  3 16:06:52.720: INFO: POD   NODE                                               PHASE    GRACE  CONDITIONS
Dec  3 16:06:52.720: INFO: ss-0  shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:05:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:06:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:06:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:05:59 +0000 UTC  }]
Dec  3 16:06:52.720: INFO: ss-1  shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-r5glw  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:06:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:06:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:06:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:06:28 +0000 UTC  }]
Dec  3 16:06:52.720: INFO: ss-2  shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:06:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:06:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:06:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:06:28 +0000 UTC  }]
Dec  3 16:06:52.720: INFO: 
Dec  3 16:06:52.720: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  3 16:06:53.731: INFO: POD   NODE                                               PHASE    GRACE  CONDITIONS
Dec  3 16:06:53.731: INFO: ss-0  shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:05:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:06:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:06:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:05:59 +0000 UTC  }]
Dec  3 16:06:53.731: INFO: ss-1  shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-r5glw  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:06:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:06:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:06:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:06:28 +0000 UTC  }]
Dec  3 16:06:53.731: INFO: ss-2  shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:06:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:06:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:06:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:06:28 +0000 UTC  }]
Dec  3 16:06:53.731: INFO: 
Dec  3 16:06:53.731: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  3 16:06:54.742: INFO: POD   NODE                                               PHASE    GRACE  CONDITIONS
Dec  3 16:06:54.742: INFO: ss-0  shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:05:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:06:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:06:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:05:59 +0000 UTC  }]
Dec  3 16:06:54.742: INFO: ss-1  shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-r5glw  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:06:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:06:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:06:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:06:28 +0000 UTC  }]
Dec  3 16:06:54.742: INFO: ss-2  shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:06:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:06:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:06:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:06:28 +0000 UTC  }]
Dec  3 16:06:54.742: INFO: 
Dec  3 16:06:54.742: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  3 16:06:55.753: INFO: POD   NODE                                               PHASE    GRACE  CONDITIONS
Dec  3 16:06:55.753: INFO: ss-0  shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:05:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:06:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:06:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:05:59 +0000 UTC  }]
Dec  3 16:06:55.753: INFO: ss-1  shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-r5glw  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:06:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:06:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:06:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:06:28 +0000 UTC  }]
Dec  3 16:06:55.753: INFO: 
Dec  3 16:06:55.753: INFO: StatefulSet ss has not reached scale 0, at 2
Dec  3 16:06:56.764: INFO: POD   NODE                                               PHASE    GRACE  CONDITIONS
Dec  3 16:06:56.764: INFO: ss-0  shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:05:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:06:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:06:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:05:59 +0000 UTC  }]
Dec  3 16:06:56.764: INFO: ss-1  shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-r5glw  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:06:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:06:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:06:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:06:28 +0000 UTC  }]
Dec  3 16:06:56.764: INFO: 
Dec  3 16:06:56.764: INFO: StatefulSet ss has not reached scale 0, at 2
Dec  3 16:06:57.775: INFO: POD   NODE                                               PHASE    GRACE  CONDITIONS
Dec  3 16:06:57.775: INFO: ss-0  shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:05:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:06:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:06:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:05:59 +0000 UTC  }]
Dec  3 16:06:57.775: INFO: ss-1  shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-r5glw  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:06:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:06:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:06:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:06:28 +0000 UTC  }]
Dec  3 16:06:57.775: INFO: 
Dec  3 16:06:57.775: INFO: StatefulSet ss has not reached scale 0, at 2
Dec  3 16:06:58.786: INFO: POD   NODE                                               PHASE    GRACE  CONDITIONS
Dec  3 16:06:58.786: INFO: ss-0  shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:05:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:06:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:06:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:05:59 +0000 UTC  }]
Dec  3 16:06:58.786: INFO: ss-1  shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-r5glw  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:06:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:06:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:06:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:06:28 +0000 UTC  }]
Dec  3 16:06:58.786: INFO: 
Dec  3 16:06:58.786: INFO: StatefulSet ss has not reached scale 0, at 2
Dec  3 16:06:59.797: INFO: POD   NODE                                               PHASE    GRACE  CONDITIONS
Dec  3 16:06:59.797: INFO: ss-0  shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:05:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:06:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:06:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:05:59 +0000 UTC  }]
Dec  3 16:06:59.797: INFO: ss-1  shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-r5glw  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:06:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:06:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:06:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:06:28 +0000 UTC  }]
Dec  3 16:06:59.797: INFO: 
Dec  3 16:06:59.797: INFO: StatefulSet ss has not reached scale 0, at 2
Dec  3 16:07:00.808: INFO: POD   NODE                                               PHASE    GRACE  CONDITIONS
Dec  3 16:07:00.808: INFO: ss-0  shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:05:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:06:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:06:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:05:59 +0000 UTC  }]
Dec  3 16:07:00.808: INFO: ss-1  shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-r5glw  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:06:28 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:06:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:06:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:06:28 +0000 UTC  }]
Dec  3 16:07:00.808: INFO: 
Dec  3 16:07:00.808: INFO: StatefulSet ss has not reached scale 0, at 2
Dec  3 16:07:01.819: INFO: POD   NODE                                               PHASE    GRACE  CONDITIONS
Dec  3 16:07:01.819: INFO: ss-0  shoot--it--tml9e-anp-worker-1-z1-7c98d6d78c-7mvh9  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:05:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:06:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:06:42 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:05:59 +0000 UTC  }]
Dec  3 16:07:01.819: INFO: 
Dec  3 16:07:01.819: INFO: StatefulSet ss has not reached scale 0, at 1
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-7448
Dec  3 16:07:02.831: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7448 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 16:07:03.113: INFO: rc: 1
Dec  3 16:07:03.113: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7448 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: pod does not exist
 [] <nil> 0xc001440810 exit status 1 <nil> <nil> true [0xc000331fd0 0xc001024c28 0xc0010250f0] [0xc000331fd0 0xc001024c28 0xc0010250f0] [0xc001024b08 0xc001025030] [0xba6c10 0xba6c10] 0xc0032fbec0 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: pod does not exist

error:
exit status 1
Dec  3 16:07:13.114: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7448 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 16:07:13.267: INFO: rc: 1
Dec  3 16:07:13.267: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7448 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0037ab5f0 exit status 1 <nil> <nil> true [0xc0017a21d0 0xc0017a21e8 0xc0017a2200] [0xc0017a21d0 0xc0017a21e8 0xc0017a2200] [0xc0017a21e0 0xc0017a21f8] [0xba6c10 0xba6c10] 0xc002a7dce0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec  3 16:07:23.267: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7448 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 16:07:23.399: INFO: rc: 1
Dec  3 16:07:23.399: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7448 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00194a840 exit status 1 <nil> <nil> true [0xc002284190 0xc0022841d8 0xc002284220] [0xc002284190 0xc0022841d8 0xc002284220] [0xc0022841b8 0xc002284208] [0xba6c10 0xba6c10] 0xc0035fee40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec  3 16:07:33.399: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7448 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 16:07:33.540: INFO: rc: 1
Dec  3 16:07:33.540: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7448 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc003435dd0 exit status 1 <nil> <nil> true [0xc0000119c8 0xc000011a98 0xc000011b08] [0xc0000119c8 0xc000011a98 0xc000011b08] [0xc000011a78 0xc000011af8] [0xba6c10 0xba6c10] 0xc001b9b560 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec  3 16:07:43.541: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7448 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 16:07:43.708: INFO: rc: 1
Dec  3 16:07:43.708: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7448 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001440de0 exit status 1 <nil> <nil> true [0xc0010253d0 0xc001025868 0xc0010259c0] [0xc0010253d0 0xc001025868 0xc0010259c0] [0xc001025620 0xc001025938] [0xba6c10 0xba6c10] 0xc002968240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec  3 16:07:53.709: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7448 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 16:07:53.837: INFO: rc: 1
Dec  3 16:07:53.837: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7448 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0037abc20 exit status 1 <nil> <nil> true [0xc0017a2208 0xc0017a2220 0xc0017a2238] [0xc0017a2208 0xc0017a2220 0xc0017a2238] [0xc0017a2218 0xc0017a2230] [0xba6c10 0xba6c10] 0xc002b06000 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec  3 16:08:03.837: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7448 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 16:08:03.990: INFO: rc: 1
Dec  3 16:08:03.990: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7448 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002f3e5a0 exit status 1 <nil> <nil> true [0xc000330988 0xc0003309d8 0xc000330a90] [0xc000330988 0xc0003309d8 0xc000330a90] [0xc0003309c8 0xc000330a60] [0xba6c10 0xba6c10] 0xc0032fa240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec  3 16:08:13.990: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7448 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 16:08:14.142: INFO: rc: 1
Dec  3 16:08:14.142: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7448 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000b96600 exit status 1 <nil> <nil> true [0xc002284010 0xc002284028 0xc002284040] [0xc002284010 0xc002284028 0xc002284040] [0xc002284020 0xc002284038] [0xba6c10 0xba6c10] 0xc001de0240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec  3 16:08:24.142: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7448 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 16:08:24.287: INFO: rc: 1
Dec  3 16:08:24.287: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7448 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000b96bd0 exit status 1 <nil> <nil> true [0xc002284048 0xc002284060 0xc002284078] [0xc002284048 0xc002284060 0xc002284078] [0xc002284058 0xc002284070] [0xba6c10 0xba6c10] 0xc001de07e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec  3 16:08:34.287: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7448 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 16:08:34.431: INFO: rc: 1
Dec  3 16:08:34.431: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7448 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000b971a0 exit status 1 <nil> <nil> true [0xc002284080 0xc002284098 0xc0022840b0] [0xc002284080 0xc002284098 0xc0022840b0] [0xc002284090 0xc0022840a8] [0xba6c10 0xba6c10] 0xc001de0b40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec  3 16:08:44.431: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7448 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 16:08:44.593: INFO: rc: 1
Dec  3 16:08:44.593: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7448 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002e5e5d0 exit status 1 <nil> <nil> true [0xc0010247c0 0xc001024ff8 0xc0010253d0] [0xc0010247c0 0xc001024ff8 0xc0010253d0] [0xc001024c28 0xc0010250f0] [0xba6c10 0xba6c10] 0xc002a7c2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec  3 16:08:54.593: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7448 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 16:08:54.780: INFO: rc: 1
Dec  3 16:08:54.780: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7448 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000b97770 exit status 1 <nil> <nil> true [0xc0022840b8 0xc0022840d0 0xc002284110] [0xc0022840b8 0xc0022840d0 0xc002284110] [0xc0022840c8 0xc0022840f8] [0xba6c10 0xba6c10] 0xc001de1080 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec  3 16:09:04.781: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7448 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 16:09:04.904: INFO: rc: 1
Dec  3 16:09:04.904: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7448 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002e5ebd0 exit status 1 <nil> <nil> true [0xc001025518 0xc001025898 0xc001025cd8] [0xc001025518 0xc001025898 0xc001025cd8] [0xc001025868 0xc0010259c0] [0xba6c10 0xba6c10] 0xc002a7c7e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec  3 16:09:14.904: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7448 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 16:09:15.054: INFO: rc: 1
Dec  3 16:09:15.054: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7448 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0036d2600 exit status 1 <nil> <nil> true [0xc0017a2000 0xc0017a2018 0xc0017a2030] [0xc0017a2000 0xc0017a2018 0xc0017a2030] [0xc0017a2010 0xc0017a2028] [0xba6c10 0xba6c10] 0xc0035fe240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec  3 16:09:25.055: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7448 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 16:09:25.184: INFO: rc: 1
Dec  3 16:09:25.184: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7448 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002f3ec00 exit status 1 <nil> <nil> true [0xc000330b00 0xc000330b78 0xc000330ca8] [0xc000330b00 0xc000330b78 0xc000330ca8] [0xc000330b68 0xc000330c58] [0xba6c10 0xba6c10] 0xc0032fa540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec  3 16:09:35.184: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7448 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 16:09:35.378: INFO: rc: 1
Dec  3 16:09:35.378: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7448 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0036d2bd0 exit status 1 <nil> <nil> true [0xc0017a2038 0xc0017a2050 0xc0017a2068] [0xc0017a2038 0xc0017a2050 0xc0017a2068] [0xc0017a2048 0xc0017a2060] [0xba6c10 0xba6c10] 0xc0035fe540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec  3 16:09:45.379: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7448 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 16:09:45.566: INFO: rc: 1
Dec  3 16:09:45.566: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7448 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002e5f230 exit status 1 <nil> <nil> true [0xc001025e90 0xc000010840 0xc0000108f0] [0xc001025e90 0xc000010840 0xc0000108f0] [0xc000010328 0xc0000108d0] [0xba6c10 0xba6c10] 0xc002a7cae0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec  3 16:09:55.568: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7448 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 16:09:55.697: INFO: rc: 1
Dec  3 16:09:55.697: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7448 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002f3f1d0 exit status 1 <nil> <nil> true [0xc000330cc8 0xc000330d48 0xc000330d90] [0xc000330cc8 0xc000330d48 0xc000330d90] [0xc000330d30 0xc000330d68] [0xba6c10 0xba6c10] 0xc0032fa840 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec  3 16:10:05.697: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7448 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 16:10:05.848: INFO: rc: 1
Dec  3 16:10:05.848: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7448 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002f3e5d0 exit status 1 <nil> <nil> true [0xc001024b08 0xc001025030 0xc001025518] [0xc001024b08 0xc001025030 0xc001025518] [0xc001024ff8 0xc0010253d0] [0xba6c10 0xba6c10] 0xc0032fa240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec  3 16:10:15.848: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7448 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 16:10:16.081: INFO: rc: 1
Dec  3 16:10:16.081: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7448 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002f3ebd0 exit status 1 <nil> <nil> true [0xc001025620 0xc001025938 0xc001025e90] [0xc001025620 0xc001025938 0xc001025e90] [0xc001025898 0xc001025cd8] [0xba6c10 0xba6c10] 0xc0032fa540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec  3 16:10:26.081: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7448 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 16:10:26.275: INFO: rc: 1
Dec  3 16:10:26.275: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7448 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002e5e5a0 exit status 1 <nil> <nil> true [0xc0003308f8 0xc0003309c8 0xc000330a60] [0xc0003308f8 0xc0003309c8 0xc000330a60] [0xc0003309a8 0xc0003309f8] [0xba6c10 0xba6c10] 0xc002a7c2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec  3 16:10:36.276: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7448 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 16:10:36.411: INFO: rc: 1
Dec  3 16:10:36.411: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7448 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002e5eba0 exit status 1 <nil> <nil> true [0xc000330a90 0xc000330b68 0xc000330c58] [0xc000330a90 0xc000330b68 0xc000330c58] [0xc000330b50 0xc000330be0] [0xba6c10 0xba6c10] 0xc002a7c7e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec  3 16:10:46.411: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7448 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 16:10:46.566: INFO: rc: 1
Dec  3 16:10:46.566: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7448 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000b96630 exit status 1 <nil> <nil> true [0xc000010328 0xc0000108d0 0xc000010930] [0xc000010328 0xc0000108d0 0xc000010930] [0xc000010888 0xc000010918] [0xba6c10 0xba6c10] 0xc0035fe240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec  3 16:10:56.566: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7448 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 16:10:56.693: INFO: rc: 1
Dec  3 16:10:56.693: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7448 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002e5f1d0 exit status 1 <nil> <nil> true [0xc000330ca8 0xc000330d30 0xc000330d68] [0xc000330ca8 0xc000330d30 0xc000330d68] [0xc000330cf0 0xc000330d58] [0xba6c10 0xba6c10] 0xc002a7cae0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec  3 16:11:06.693: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7448 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 16:11:06.833: INFO: rc: 1
Dec  3 16:11:06.833: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7448 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0036d2630 exit status 1 <nil> <nil> true [0xc0017a2000 0xc0017a2018 0xc0017a2030] [0xc0017a2000 0xc0017a2018 0xc0017a2030] [0xc0017a2010 0xc0017a2028] [0xba6c10 0xba6c10] 0xc001de0240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec  3 16:11:16.833: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7448 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 16:11:16.987: INFO: rc: 1
Dec  3 16:11:16.987: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7448 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002e5f800 exit status 1 <nil> <nil> true [0xc000330d90 0xc000330f20 0xc000331090] [0xc000330d90 0xc000330f20 0xc000331090] [0xc000330ed0 0xc000331080] [0xba6c10 0xba6c10] 0xc002a7cde0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec  3 16:11:26.987: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7448 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 16:11:27.157: INFO: rc: 1
Dec  3 16:11:27.157: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7448 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc000b96cc0 exit status 1 <nil> <nil> true [0xc000010938 0xc0000111e0 0xc000011358] [0xc000010938 0xc0000111e0 0xc000011358] [0xc0000110c0 0xc000011310] [0xba6c10 0xba6c10] 0xc0035fe540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec  3 16:11:37.157: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7448 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 16:11:37.299: INFO: rc: 1
Dec  3 16:11:37.299: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7448 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0036d2c60 exit status 1 <nil> <nil> true [0xc0017a2038 0xc0017a2050 0xc0017a2068] [0xc0017a2038 0xc0017a2050 0xc0017a2068] [0xc0017a2048 0xc0017a2060] [0xba6c10 0xba6c10] 0xc001de07e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec  3 16:11:47.300: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7448 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 16:11:47.441: INFO: rc: 1
Dec  3 16:11:47.441: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7448 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0036d3230 exit status 1 <nil> <nil> true [0xc0017a2070 0xc0017a2088 0xc0017a20a0] [0xc0017a2070 0xc0017a2088 0xc0017a20a0] [0xc0017a2080 0xc0017a2098] [0xba6c10 0xba6c10] 0xc001de0b40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec  3 16:11:57.441: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7448 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 16:11:57.597: INFO: rc: 1
Dec  3 16:11:57.597: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7448 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0036d3860 exit status 1 <nil> <nil> true [0xc0017a20a8 0xc0017a20c8 0xc0017a20e0] [0xc0017a20a8 0xc0017a20c8 0xc0017a20e0] [0xc0017a20c0 0xc0017a20d8] [0xba6c10 0xba6c10] 0xc001de1080 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec  3 16:12:07.598: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tml9e-anp.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7448 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Dec  3 16:12:07.733: INFO: rc: 1
Dec  3 16:12:07.733: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: 
Dec  3 16:12:07.733: INFO: Scaling statefulset ss to 0
Dec  3 16:12:07.768: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Dec  3 16:12:07.779: INFO: Deleting all statefulset in ns statefulset-7448
Dec  3 16:12:07.789: INFO: Scaling statefulset ss to 0
Dec  3 16:12:07.819: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 16:12:07.829: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Dec  3 16:12:07.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7448" for this suite.
Dec  3 16:12:27.911: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:12:28.303: INFO: namespace statefulset-7448 deletion completed in 20.422659691s

• [SLOW TEST:388.668 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.15.6-beta.0.38+7015f71e75f670/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSDec  3 16:12:28.304: INFO: Running AfterSuite actions on all nodes
Dec  3 16:12:28.304: INFO: Running AfterSuite actions on node 1
Dec  3 16:12:28.304: INFO: Skipping dumping logs from cluster

Ran 215 of 4413 Specs in 5746.003 seconds
SUCCESS! -- 215 Passed | 0 Failed | 0 Flaked | 0 Pending | 4198 Skipped
PASS

Ginkgo ran 1 suite in 1h36m38.745766954s
Test Suite Passed
