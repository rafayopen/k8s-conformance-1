I0809 13:02:12.784556      19 test_context.go:406] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-400702193
I0809 13:02:12.784874      19 e2e.go:241] Starting e2e run "11f8fffa-f849-4f57-adcb-7f713fa15a16" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1565355729 - Will randomize all specs
Will run 215 of 4413 specs

Aug  9 13:02:13.244: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
Aug  9 13:02:13.248: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Aug  9 13:02:13.290: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Aug  9 13:02:13.374: INFO: 17 / 17 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Aug  9 13:02:13.374: INFO: expected 2 pod replicas in namespace 'kube-system', 2 are Running and Ready.
Aug  9 13:02:13.374: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Aug  9 13:02:13.400: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'csi-node' (0 seconds elapsed)
Aug  9 13:02:13.400: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'flannel' (0 seconds elapsed)
Aug  9 13:02:13.400: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'ingress-traefik' (0 seconds elapsed)
Aug  9 13:02:13.400: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Aug  9 13:02:13.400: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'node-problem-detector' (0 seconds elapsed)
Aug  9 13:02:13.400: INFO: e2e test version: v1.15.2
Aug  9 13:02:13.406: INFO: kube-apiserver version: v1.15.2
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:02:13.406: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename container-probe
Aug  9 13:02:13.567: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Aug  9 13:02:13.611: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-8819
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod test-webserver-9ca02d69-3861-4197-b286-ecba7deb280a in namespace container-probe-8819
Aug  9 13:02:21.813: INFO: Started pod test-webserver-9ca02d69-3861-4197-b286-ecba7deb280a in namespace container-probe-8819
STEP: checking the pod's current state and verifying that restartCount is present
Aug  9 13:02:21.823: INFO: Initial restart count of pod test-webserver-9ca02d69-3861-4197-b286-ecba7deb280a is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:06:23.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8819" for this suite.
Aug  9 13:06:29.642: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:06:30.007: INFO: namespace container-probe-8819 deletion completed in 6.410761018s

• [SLOW TEST:256.600 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:06:30.010: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-7445
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test substitution in container's args
Aug  9 13:06:30.289: INFO: Waiting up to 5m0s for pod "var-expansion-a5bbadc8-ce50-4a82-ae86-29a6daeb2a4e" in namespace "var-expansion-7445" to be "success or failure"
Aug  9 13:06:30.301: INFO: Pod "var-expansion-a5bbadc8-ce50-4a82-ae86-29a6daeb2a4e": Phase="Pending", Reason="", readiness=false. Elapsed: 11.385297ms
Aug  9 13:06:32.311: INFO: Pod "var-expansion-a5bbadc8-ce50-4a82-ae86-29a6daeb2a4e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021959981s
Aug  9 13:06:34.326: INFO: Pod "var-expansion-a5bbadc8-ce50-4a82-ae86-29a6daeb2a4e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.036251012s
Aug  9 13:06:36.339: INFO: Pod "var-expansion-a5bbadc8-ce50-4a82-ae86-29a6daeb2a4e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.049227144s
STEP: Saw pod success
Aug  9 13:06:36.339: INFO: Pod "var-expansion-a5bbadc8-ce50-4a82-ae86-29a6daeb2a4e" satisfied condition "success or failure"
Aug  9 13:06:36.346: INFO: Trying to get logs from node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d pod var-expansion-a5bbadc8-ce50-4a82-ae86-29a6daeb2a4e container dapi-container: <nil>
STEP: delete the pod
Aug  9 13:06:36.457: INFO: Waiting for pod var-expansion-a5bbadc8-ce50-4a82-ae86-29a6daeb2a4e to disappear
Aug  9 13:06:36.471: INFO: Pod var-expansion-a5bbadc8-ce50-4a82-ae86-29a6daeb2a4e no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:06:36.471: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7445" for this suite.
Aug  9 13:06:42.532: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:06:42.963: INFO: namespace var-expansion-7445 deletion completed in 6.475626932s

• [SLOW TEST:12.953 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:06:42.967: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-4535
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Aug  9 13:06:53.371: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:06:53.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W0809 13:06:53.371187      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-4535" for this suite.
Aug  9 13:06:59.427: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:06:59.749: INFO: namespace gc-4535 deletion completed in 6.36269379s

• [SLOW TEST:16.781 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:06:59.756: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-4978
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-configmap-j5xv
STEP: Creating a pod to test atomic-volume-subpath
Aug  9 13:07:00.043: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-j5xv" in namespace "subpath-4978" to be "success or failure"
Aug  9 13:07:00.051: INFO: Pod "pod-subpath-test-configmap-j5xv": Phase="Pending", Reason="", readiness=false. Elapsed: 8.605898ms
Aug  9 13:07:02.064: INFO: Pod "pod-subpath-test-configmap-j5xv": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021270365s
Aug  9 13:07:04.078: INFO: Pod "pod-subpath-test-configmap-j5xv": Phase="Running", Reason="", readiness=true. Elapsed: 4.034943574s
Aug  9 13:07:06.091: INFO: Pod "pod-subpath-test-configmap-j5xv": Phase="Running", Reason="", readiness=true. Elapsed: 6.048342874s
Aug  9 13:07:08.101: INFO: Pod "pod-subpath-test-configmap-j5xv": Phase="Running", Reason="", readiness=true. Elapsed: 8.058494761s
Aug  9 13:07:10.200: INFO: Pod "pod-subpath-test-configmap-j5xv": Phase="Running", Reason="", readiness=true. Elapsed: 10.157804633s
Aug  9 13:07:12.213: INFO: Pod "pod-subpath-test-configmap-j5xv": Phase="Running", Reason="", readiness=true. Elapsed: 12.170071914s
Aug  9 13:07:14.223: INFO: Pod "pod-subpath-test-configmap-j5xv": Phase="Running", Reason="", readiness=true. Elapsed: 14.179879808s
Aug  9 13:07:16.232: INFO: Pod "pod-subpath-test-configmap-j5xv": Phase="Running", Reason="", readiness=true. Elapsed: 16.189460593s
Aug  9 13:07:18.254: INFO: Pod "pod-subpath-test-configmap-j5xv": Phase="Running", Reason="", readiness=true. Elapsed: 18.211006461s
Aug  9 13:07:20.266: INFO: Pod "pod-subpath-test-configmap-j5xv": Phase="Running", Reason="", readiness=true. Elapsed: 20.223353892s
Aug  9 13:07:22.283: INFO: Pod "pod-subpath-test-configmap-j5xv": Phase="Running", Reason="", readiness=true. Elapsed: 22.240543986s
Aug  9 13:07:24.294: INFO: Pod "pod-subpath-test-configmap-j5xv": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.251550415s
STEP: Saw pod success
Aug  9 13:07:24.294: INFO: Pod "pod-subpath-test-configmap-j5xv" satisfied condition "success or failure"
Aug  9 13:07:24.304: INFO: Trying to get logs from node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d pod pod-subpath-test-configmap-j5xv container test-container-subpath-configmap-j5xv: <nil>
STEP: delete the pod
Aug  9 13:07:24.371: INFO: Waiting for pod pod-subpath-test-configmap-j5xv to disappear
Aug  9 13:07:24.380: INFO: Pod pod-subpath-test-configmap-j5xv no longer exists
STEP: Deleting pod pod-subpath-test-configmap-j5xv
Aug  9 13:07:24.381: INFO: Deleting pod "pod-subpath-test-configmap-j5xv" in namespace "subpath-4978"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:07:24.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4978" for this suite.
Aug  9 13:07:30.448: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:07:30.832: INFO: namespace subpath-4978 deletion completed in 6.425267295s

• [SLOW TEST:31.077 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:07:30.834: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-5287
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-5287.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-5287.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5287.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-5287.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-5287.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5287.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug  9 13:07:57.842: INFO: DNS probes using dns-5287/dns-test-dd7d9d18-ac30-40ae-a56a-68afb4fbe2be succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:07:57.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5287" for this suite.
Aug  9 13:08:03.942: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:08:04.298: INFO: namespace dns-5287 deletion completed in 6.399885167s

• [SLOW TEST:33.464 seconds]
[sig-network] DNS
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:08:04.298: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3618
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-upd-57de1673-fdb1-445a-b897-5b7035d427ff
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-57de1673-fdb1-445a-b897-5b7035d427ff
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:08:12.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3618" for this suite.
Aug  9 13:08:36.890: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:08:37.240: INFO: namespace configmap-3618 deletion completed in 24.388755603s

• [SLOW TEST:32.943 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:08:37.242: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7281
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug  9 13:08:37.488: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d9309271-70ec-4315-a71b-4fc5125107b4" in namespace "downward-api-7281" to be "success or failure"
Aug  9 13:08:37.498: INFO: Pod "downwardapi-volume-d9309271-70ec-4315-a71b-4fc5125107b4": Phase="Pending", Reason="", readiness=false. Elapsed: 9.597084ms
Aug  9 13:08:39.509: INFO: Pod "downwardapi-volume-d9309271-70ec-4315-a71b-4fc5125107b4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020376436s
Aug  9 13:08:41.524: INFO: Pod "downwardapi-volume-d9309271-70ec-4315-a71b-4fc5125107b4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.035195421s
Aug  9 13:08:43.538: INFO: Pod "downwardapi-volume-d9309271-70ec-4315-a71b-4fc5125107b4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.049503903s
STEP: Saw pod success
Aug  9 13:08:43.538: INFO: Pod "downwardapi-volume-d9309271-70ec-4315-a71b-4fc5125107b4" satisfied condition "success or failure"
Aug  9 13:08:43.549: INFO: Trying to get logs from node scw-flan15-default-fbc750a75c7f4c499b691cc5ccd pod downwardapi-volume-d9309271-70ec-4315-a71b-4fc5125107b4 container client-container: <nil>
STEP: delete the pod
Aug  9 13:08:43.630: INFO: Waiting for pod downwardapi-volume-d9309271-70ec-4315-a71b-4fc5125107b4 to disappear
Aug  9 13:08:43.639: INFO: Pod downwardapi-volume-d9309271-70ec-4315-a71b-4fc5125107b4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:08:43.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7281" for this suite.
Aug  9 13:08:49.701: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:08:50.040: INFO: namespace downward-api-7281 deletion completed in 6.376454655s

• [SLOW TEST:12.799 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:08:50.044: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7794
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug  9 13:08:50.298: INFO: Waiting up to 5m0s for pod "downwardapi-volume-23a59b1d-01fc-44d5-b854-a702a023b86e" in namespace "downward-api-7794" to be "success or failure"
Aug  9 13:08:50.317: INFO: Pod "downwardapi-volume-23a59b1d-01fc-44d5-b854-a702a023b86e": Phase="Pending", Reason="", readiness=false. Elapsed: 19.013388ms
Aug  9 13:08:52.329: INFO: Pod "downwardapi-volume-23a59b1d-01fc-44d5-b854-a702a023b86e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031846756s
Aug  9 13:08:54.341: INFO: Pod "downwardapi-volume-23a59b1d-01fc-44d5-b854-a702a023b86e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.043262783s
STEP: Saw pod success
Aug  9 13:08:54.341: INFO: Pod "downwardapi-volume-23a59b1d-01fc-44d5-b854-a702a023b86e" satisfied condition "success or failure"
Aug  9 13:08:54.350: INFO: Trying to get logs from node scw-flan15-default-fbc750a75c7f4c499b691cc5ccd pod downwardapi-volume-23a59b1d-01fc-44d5-b854-a702a023b86e container client-container: <nil>
STEP: delete the pod
Aug  9 13:08:54.408: INFO: Waiting for pod downwardapi-volume-23a59b1d-01fc-44d5-b854-a702a023b86e to disappear
Aug  9 13:08:54.417: INFO: Pod downwardapi-volume-23a59b1d-01fc-44d5-b854-a702a023b86e no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:08:54.417: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7794" for this suite.
Aug  9 13:09:00.471: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:09:00.840: INFO: namespace downward-api-7794 deletion completed in 6.408982278s

• [SLOW TEST:10.796 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:09:00.840: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-7177
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug  9 13:09:01.143: INFO: Create a RollingUpdate DaemonSet
Aug  9 13:09:01.160: INFO: Check that daemon pods launch on every node of the cluster
Aug  9 13:09:01.191: INFO: Number of nodes with available pods: 0
Aug  9 13:09:01.191: INFO: Node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d is running more than one daemon pod
Aug  9 13:09:02.226: INFO: Number of nodes with available pods: 0
Aug  9 13:09:02.226: INFO: Node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d is running more than one daemon pod
Aug  9 13:09:03.232: INFO: Number of nodes with available pods: 0
Aug  9 13:09:03.232: INFO: Node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d is running more than one daemon pod
Aug  9 13:09:04.213: INFO: Number of nodes with available pods: 2
Aug  9 13:09:04.213: INFO: Node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d is running more than one daemon pod
Aug  9 13:09:05.223: INFO: Number of nodes with available pods: 2
Aug  9 13:09:05.223: INFO: Node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d is running more than one daemon pod
Aug  9 13:09:06.222: INFO: Number of nodes with available pods: 2
Aug  9 13:09:06.222: INFO: Node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d is running more than one daemon pod
Aug  9 13:09:07.220: INFO: Number of nodes with available pods: 2
Aug  9 13:09:07.220: INFO: Node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d is running more than one daemon pod
Aug  9 13:09:08.273: INFO: Number of nodes with available pods: 3
Aug  9 13:09:08.273: INFO: Number of running nodes: 3, number of available pods: 3
Aug  9 13:09:08.274: INFO: Update the DaemonSet to trigger a rollout
Aug  9 13:09:08.299: INFO: Updating DaemonSet daemon-set
Aug  9 13:09:11.359: INFO: Roll back the DaemonSet before rollout is complete
Aug  9 13:09:11.383: INFO: Updating DaemonSet daemon-set
Aug  9 13:09:11.383: INFO: Make sure DaemonSet rollback is complete
Aug  9 13:09:11.395: INFO: Wrong image for pod: daemon-set-7dbhc. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Aug  9 13:09:11.395: INFO: Pod daemon-set-7dbhc is not available
Aug  9 13:09:12.424: INFO: Wrong image for pod: daemon-set-7dbhc. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Aug  9 13:09:12.424: INFO: Pod daemon-set-7dbhc is not available
Aug  9 13:09:13.425: INFO: Wrong image for pod: daemon-set-7dbhc. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Aug  9 13:09:13.425: INFO: Pod daemon-set-7dbhc is not available
Aug  9 13:09:14.446: INFO: Wrong image for pod: daemon-set-7dbhc. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Aug  9 13:09:14.446: INFO: Pod daemon-set-7dbhc is not available
Aug  9 13:09:15.424: INFO: Pod daemon-set-cft6c is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7177, will wait for the garbage collector to delete the pods
Aug  9 13:09:15.543: INFO: Deleting DaemonSet.extensions daemon-set took: 26.40867ms
Aug  9 13:09:15.844: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.400048ms
Aug  9 13:09:27.957: INFO: Number of nodes with available pods: 0
Aug  9 13:09:27.957: INFO: Number of running nodes: 0, number of available pods: 0
Aug  9 13:09:27.970: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7177/daemonsets","resourceVersion":"124613005"},"items":null}

Aug  9 13:09:27.982: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7177/pods","resourceVersion":"124613005"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:09:28.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7177" for this suite.
Aug  9 13:09:36.080: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:09:36.405: INFO: namespace daemonsets-7177 deletion completed in 8.361709451s

• [SLOW TEST:35.564 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:09:36.405: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-7403
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:09:36.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7403" for this suite.
Aug  9 13:09:42.685: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:09:43.047: INFO: namespace services-7403 deletion completed in 6.398838324s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:6.642 seconds]
[sig-network] Services
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide secure master service  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:09:43.050: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-7362
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-secret-2j9t
STEP: Creating a pod to test atomic-volume-subpath
Aug  9 13:09:43.439: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-2j9t" in namespace "subpath-7362" to be "success or failure"
Aug  9 13:09:43.448: INFO: Pod "pod-subpath-test-secret-2j9t": Phase="Pending", Reason="", readiness=false. Elapsed: 8.379038ms
Aug  9 13:09:45.458: INFO: Pod "pod-subpath-test-secret-2j9t": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018914577s
Aug  9 13:09:47.479: INFO: Pod "pod-subpath-test-secret-2j9t": Phase="Running", Reason="", readiness=true. Elapsed: 4.03925753s
Aug  9 13:09:49.499: INFO: Pod "pod-subpath-test-secret-2j9t": Phase="Running", Reason="", readiness=true. Elapsed: 6.059444111s
Aug  9 13:09:51.509: INFO: Pod "pod-subpath-test-secret-2j9t": Phase="Running", Reason="", readiness=true. Elapsed: 8.069144533s
Aug  9 13:09:53.522: INFO: Pod "pod-subpath-test-secret-2j9t": Phase="Running", Reason="", readiness=true. Elapsed: 10.082182885s
Aug  9 13:09:55.533: INFO: Pod "pod-subpath-test-secret-2j9t": Phase="Running", Reason="", readiness=true. Elapsed: 12.093069159s
Aug  9 13:09:57.542: INFO: Pod "pod-subpath-test-secret-2j9t": Phase="Running", Reason="", readiness=true. Elapsed: 14.102569022s
Aug  9 13:09:59.554: INFO: Pod "pod-subpath-test-secret-2j9t": Phase="Running", Reason="", readiness=true. Elapsed: 16.114051401s
Aug  9 13:10:01.564: INFO: Pod "pod-subpath-test-secret-2j9t": Phase="Running", Reason="", readiness=true. Elapsed: 18.124505531s
Aug  9 13:10:03.574: INFO: Pod "pod-subpath-test-secret-2j9t": Phase="Running", Reason="", readiness=true. Elapsed: 20.134742237s
Aug  9 13:10:05.584: INFO: Pod "pod-subpath-test-secret-2j9t": Phase="Running", Reason="", readiness=true. Elapsed: 22.14493824s
Aug  9 13:10:07.596: INFO: Pod "pod-subpath-test-secret-2j9t": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.156453924s
STEP: Saw pod success
Aug  9 13:10:07.596: INFO: Pod "pod-subpath-test-secret-2j9t" satisfied condition "success or failure"
Aug  9 13:10:07.607: INFO: Trying to get logs from node scw-flan15-default-f07a9b7e282146a6b5427e9aba2 pod pod-subpath-test-secret-2j9t container test-container-subpath-secret-2j9t: <nil>
STEP: delete the pod
Aug  9 13:10:07.671: INFO: Waiting for pod pod-subpath-test-secret-2j9t to disappear
Aug  9 13:10:07.680: INFO: Pod pod-subpath-test-secret-2j9t no longer exists
STEP: Deleting pod pod-subpath-test-secret-2j9t
Aug  9 13:10:07.680: INFO: Deleting pod "pod-subpath-test-secret-2j9t" in namespace "subpath-7362"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:10:07.688: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7362" for this suite.
Aug  9 13:10:13.736: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:10:14.109: INFO: namespace subpath-7362 deletion completed in 6.408638929s

• [SLOW TEST:31.059 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:10:14.109: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-9529
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Aug  9 13:10:19.014: INFO: Successfully updated pod "pod-update-bf273068-c889-40f7-ba62-c15ad686c8d4"
STEP: verifying the updated pod is in kubernetes
Aug  9 13:10:19.037: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:10:19.037: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9529" for this suite.
Aug  9 13:10:43.086: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:10:43.855: INFO: namespace pods-9529 deletion completed in 24.806988418s

• [SLOW TEST:29.746 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:10:43.858: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-2817
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Aug  9 13:10:44.127: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:10:49.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-2817" for this suite.
Aug  9 13:10:55.654: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:10:55.989: INFO: namespace init-container-2817 deletion completed in 6.390178965s

• [SLOW TEST:12.132 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:10:55.990: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8824
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-68508d5d-49b0-4c9a-a453-4052985a9814
STEP: Creating a pod to test consume configMaps
Aug  9 13:10:56.245: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5e6203bf-1f23-4b63-b631-266a294fd1c2" in namespace "projected-8824" to be "success or failure"
Aug  9 13:10:56.258: INFO: Pod "pod-projected-configmaps-5e6203bf-1f23-4b63-b631-266a294fd1c2": Phase="Pending", Reason="", readiness=false. Elapsed: 12.821275ms
Aug  9 13:10:58.287: INFO: Pod "pod-projected-configmaps-5e6203bf-1f23-4b63-b631-266a294fd1c2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041356665s
Aug  9 13:11:00.297: INFO: Pod "pod-projected-configmaps-5e6203bf-1f23-4b63-b631-266a294fd1c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.051423154s
STEP: Saw pod success
Aug  9 13:11:00.297: INFO: Pod "pod-projected-configmaps-5e6203bf-1f23-4b63-b631-266a294fd1c2" satisfied condition "success or failure"
Aug  9 13:11:00.307: INFO: Trying to get logs from node scw-flan15-default-f07a9b7e282146a6b5427e9aba2 pod pod-projected-configmaps-5e6203bf-1f23-4b63-b631-266a294fd1c2 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug  9 13:11:00.383: INFO: Waiting for pod pod-projected-configmaps-5e6203bf-1f23-4b63-b631-266a294fd1c2 to disappear
Aug  9 13:11:00.395: INFO: Pod pod-projected-configmaps-5e6203bf-1f23-4b63-b631-266a294fd1c2 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:11:00.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8824" for this suite.
Aug  9 13:11:06.464: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:11:06.908: INFO: namespace projected-8824 deletion completed in 6.487210864s

• [SLOW TEST:10.918 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:11:06.910: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8189
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-d40fc906-ec9e-46bc-a7b6-bd749f8de2e4
STEP: Creating a pod to test consume configMaps
Aug  9 13:11:07.203: INFO: Waiting up to 5m0s for pod "pod-configmaps-5a7ae51b-e360-49d2-9750-f616a4ebf218" in namespace "configmap-8189" to be "success or failure"
Aug  9 13:11:07.211: INFO: Pod "pod-configmaps-5a7ae51b-e360-49d2-9750-f616a4ebf218": Phase="Pending", Reason="", readiness=false. Elapsed: 8.178116ms
Aug  9 13:11:09.227: INFO: Pod "pod-configmaps-5a7ae51b-e360-49d2-9750-f616a4ebf218": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023800084s
Aug  9 13:11:11.239: INFO: Pod "pod-configmaps-5a7ae51b-e360-49d2-9750-f616a4ebf218": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036357906s
STEP: Saw pod success
Aug  9 13:11:11.239: INFO: Pod "pod-configmaps-5a7ae51b-e360-49d2-9750-f616a4ebf218" satisfied condition "success or failure"
Aug  9 13:11:11.275: INFO: Trying to get logs from node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d pod pod-configmaps-5a7ae51b-e360-49d2-9750-f616a4ebf218 container configmap-volume-test: <nil>
STEP: delete the pod
Aug  9 13:11:11.362: INFO: Waiting for pod pod-configmaps-5a7ae51b-e360-49d2-9750-f616a4ebf218 to disappear
Aug  9 13:11:11.372: INFO: Pod pod-configmaps-5a7ae51b-e360-49d2-9750-f616a4ebf218 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:11:11.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8189" for this suite.
Aug  9 13:11:17.435: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:11:17.925: INFO: namespace configmap-8189 deletion completed in 6.540543165s

• [SLOW TEST:11.015 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:11:17.926: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4155
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-map-8f91fe2f-c9b4-41cf-8d73-8f1304b4b87f
STEP: Creating a pod to test consume secrets
Aug  9 13:11:18.212: INFO: Waiting up to 5m0s for pod "pod-secrets-f1874237-5a1b-4a92-a038-f0c281ec1566" in namespace "secrets-4155" to be "success or failure"
Aug  9 13:11:18.233: INFO: Pod "pod-secrets-f1874237-5a1b-4a92-a038-f0c281ec1566": Phase="Pending", Reason="", readiness=false. Elapsed: 20.950601ms
Aug  9 13:11:20.300: INFO: Pod "pod-secrets-f1874237-5a1b-4a92-a038-f0c281ec1566": Phase="Pending", Reason="", readiness=false. Elapsed: 2.088371022s
Aug  9 13:11:22.310: INFO: Pod "pod-secrets-f1874237-5a1b-4a92-a038-f0c281ec1566": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.098037941s
STEP: Saw pod success
Aug  9 13:11:22.310: INFO: Pod "pod-secrets-f1874237-5a1b-4a92-a038-f0c281ec1566" satisfied condition "success or failure"
Aug  9 13:11:22.319: INFO: Trying to get logs from node scw-flan15-default-fbc750a75c7f4c499b691cc5ccd pod pod-secrets-f1874237-5a1b-4a92-a038-f0c281ec1566 container secret-volume-test: <nil>
STEP: delete the pod
Aug  9 13:11:22.466: INFO: Waiting for pod pod-secrets-f1874237-5a1b-4a92-a038-f0c281ec1566 to disappear
Aug  9 13:11:22.476: INFO: Pod pod-secrets-f1874237-5a1b-4a92-a038-f0c281ec1566 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:11:22.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4155" for this suite.
Aug  9 13:11:28.526: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:11:28.852: INFO: namespace secrets-4155 deletion completed in 6.36141943s

• [SLOW TEST:10.927 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:11:28.853: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-1122
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-6e9e4115-32b1-4dc1-a594-f9855863a616
STEP: Creating a pod to test consume secrets
Aug  9 13:11:29.154: INFO: Waiting up to 5m0s for pod "pod-secrets-766f370c-fccd-4a07-9b4c-7dd7414b650f" in namespace "secrets-1122" to be "success or failure"
Aug  9 13:11:29.162: INFO: Pod "pod-secrets-766f370c-fccd-4a07-9b4c-7dd7414b650f": Phase="Pending", Reason="", readiness=false. Elapsed: 8.365967ms
Aug  9 13:11:31.172: INFO: Pod "pod-secrets-766f370c-fccd-4a07-9b4c-7dd7414b650f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018801448s
Aug  9 13:11:33.188: INFO: Pod "pod-secrets-766f370c-fccd-4a07-9b4c-7dd7414b650f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03392425s
STEP: Saw pod success
Aug  9 13:11:33.188: INFO: Pod "pod-secrets-766f370c-fccd-4a07-9b4c-7dd7414b650f" satisfied condition "success or failure"
Aug  9 13:11:33.199: INFO: Trying to get logs from node scw-flan15-default-f07a9b7e282146a6b5427e9aba2 pod pod-secrets-766f370c-fccd-4a07-9b4c-7dd7414b650f container secret-env-test: <nil>
STEP: delete the pod
Aug  9 13:11:33.261: INFO: Waiting for pod pod-secrets-766f370c-fccd-4a07-9b4c-7dd7414b650f to disappear
Aug  9 13:11:33.271: INFO: Pod pod-secrets-766f370c-fccd-4a07-9b4c-7dd7414b650f no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:11:33.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1122" for this suite.
Aug  9 13:11:39.326: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:11:39.690: INFO: namespace secrets-1122 deletion completed in 6.403947073s

• [SLOW TEST:10.837 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:11:39.691: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-664
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Aug  9 13:11:39.935: INFO: Waiting up to 5m0s for pod "downward-api-62d20782-90d1-4492-8fe2-2305d62845f7" in namespace "downward-api-664" to be "success or failure"
Aug  9 13:11:39.962: INFO: Pod "downward-api-62d20782-90d1-4492-8fe2-2305d62845f7": Phase="Pending", Reason="", readiness=false. Elapsed: 27.256705ms
Aug  9 13:11:41.974: INFO: Pod "downward-api-62d20782-90d1-4492-8fe2-2305d62845f7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038723285s
Aug  9 13:11:43.985: INFO: Pod "downward-api-62d20782-90d1-4492-8fe2-2305d62845f7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.050198761s
STEP: Saw pod success
Aug  9 13:11:43.985: INFO: Pod "downward-api-62d20782-90d1-4492-8fe2-2305d62845f7" satisfied condition "success or failure"
Aug  9 13:11:43.996: INFO: Trying to get logs from node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d pod downward-api-62d20782-90d1-4492-8fe2-2305d62845f7 container dapi-container: <nil>
STEP: delete the pod
Aug  9 13:11:44.068: INFO: Waiting for pod downward-api-62d20782-90d1-4492-8fe2-2305d62845f7 to disappear
Aug  9 13:11:44.077: INFO: Pod downward-api-62d20782-90d1-4492-8fe2-2305d62845f7 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:11:44.077: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-664" for this suite.
Aug  9 13:11:50.137: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:11:50.552: INFO: namespace downward-api-664 deletion completed in 6.458607459s

• [SLOW TEST:10.862 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:11:50.554: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4154
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-0fd35346-7a33-4d81-ac74-35a6a6d4af9d
STEP: Creating a pod to test consume configMaps
Aug  9 13:11:50.811: INFO: Waiting up to 5m0s for pod "pod-configmaps-c8c6791d-b8fa-40e6-be8b-cc1f67dde918" in namespace "configmap-4154" to be "success or failure"
Aug  9 13:11:50.824: INFO: Pod "pod-configmaps-c8c6791d-b8fa-40e6-be8b-cc1f67dde918": Phase="Pending", Reason="", readiness=false. Elapsed: 13.355423ms
Aug  9 13:11:52.841: INFO: Pod "pod-configmaps-c8c6791d-b8fa-40e6-be8b-cc1f67dde918": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030561558s
Aug  9 13:11:54.861: INFO: Pod "pod-configmaps-c8c6791d-b8fa-40e6-be8b-cc1f67dde918": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.050324061s
STEP: Saw pod success
Aug  9 13:11:54.862: INFO: Pod "pod-configmaps-c8c6791d-b8fa-40e6-be8b-cc1f67dde918" satisfied condition "success or failure"
Aug  9 13:11:54.873: INFO: Trying to get logs from node scw-flan15-default-fbc750a75c7f4c499b691cc5ccd pod pod-configmaps-c8c6791d-b8fa-40e6-be8b-cc1f67dde918 container configmap-volume-test: <nil>
STEP: delete the pod
Aug  9 13:11:54.940: INFO: Waiting for pod pod-configmaps-c8c6791d-b8fa-40e6-be8b-cc1f67dde918 to disappear
Aug  9 13:11:54.952: INFO: Pod pod-configmaps-c8c6791d-b8fa-40e6-be8b-cc1f67dde918 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:11:54.954: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4154" for this suite.
Aug  9 13:12:01.015: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:12:01.400: INFO: namespace configmap-4154 deletion completed in 6.425081085s

• [SLOW TEST:10.849 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:12:01.404: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-2613
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test use defaults
Aug  9 13:12:01.660: INFO: Waiting up to 5m0s for pod "client-containers-ffb98fb6-e27e-4d86-864f-340142d23f70" in namespace "containers-2613" to be "success or failure"
Aug  9 13:12:01.674: INFO: Pod "client-containers-ffb98fb6-e27e-4d86-864f-340142d23f70": Phase="Pending", Reason="", readiness=false. Elapsed: 13.404491ms
Aug  9 13:12:03.686: INFO: Pod "client-containers-ffb98fb6-e27e-4d86-864f-340142d23f70": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025623318s
Aug  9 13:12:05.695: INFO: Pod "client-containers-ffb98fb6-e27e-4d86-864f-340142d23f70": Phase="Pending", Reason="", readiness=false. Elapsed: 4.035282289s
Aug  9 13:12:07.708: INFO: Pod "client-containers-ffb98fb6-e27e-4d86-864f-340142d23f70": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.047975249s
STEP: Saw pod success
Aug  9 13:12:07.708: INFO: Pod "client-containers-ffb98fb6-e27e-4d86-864f-340142d23f70" satisfied condition "success or failure"
Aug  9 13:12:07.719: INFO: Trying to get logs from node scw-flan15-default-fbc750a75c7f4c499b691cc5ccd pod client-containers-ffb98fb6-e27e-4d86-864f-340142d23f70 container test-container: <nil>
STEP: delete the pod
Aug  9 13:12:07.769: INFO: Waiting for pod client-containers-ffb98fb6-e27e-4d86-864f-340142d23f70 to disappear
Aug  9 13:12:07.785: INFO: Pod client-containers-ffb98fb6-e27e-4d86-864f-340142d23f70 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:12:07.785: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-2613" for this suite.
Aug  9 13:12:13.849: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:12:14.183: INFO: namespace containers-2613 deletion completed in 6.377677171s

• [SLOW TEST:12.780 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:12:14.184: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-94
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug  9 13:12:14.403: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:12:15.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-94" for this suite.
Aug  9 13:12:21.845: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:12:22.225: INFO: namespace custom-resource-definition-94 deletion completed in 6.420045921s

• [SLOW TEST:8.042 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:12:22.227: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3957
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the initial replication controller
Aug  9 13:12:22.440: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 create -f - --namespace=kubectl-3957'
Aug  9 13:12:23.573: INFO: stderr: ""
Aug  9 13:12:23.573: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug  9 13:12:23.573: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3957'
Aug  9 13:12:23.877: INFO: stderr: ""
Aug  9 13:12:23.877: INFO: stdout: "update-demo-nautilus-ng5qv update-demo-nautilus-p5ljw "
Aug  9 13:12:23.877: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 get pods update-demo-nautilus-ng5qv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3957'
Aug  9 13:12:24.089: INFO: stderr: ""
Aug  9 13:12:24.089: INFO: stdout: ""
Aug  9 13:12:24.089: INFO: update-demo-nautilus-ng5qv is created but not running
Aug  9 13:12:29.090: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3957'
Aug  9 13:12:29.378: INFO: stderr: ""
Aug  9 13:12:29.378: INFO: stdout: "update-demo-nautilus-ng5qv update-demo-nautilus-p5ljw "
Aug  9 13:12:29.378: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 get pods update-demo-nautilus-ng5qv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3957'
Aug  9 13:12:29.607: INFO: stderr: ""
Aug  9 13:12:29.607: INFO: stdout: "true"
Aug  9 13:12:29.607: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 get pods update-demo-nautilus-ng5qv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3957'
Aug  9 13:12:29.818: INFO: stderr: ""
Aug  9 13:12:29.818: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug  9 13:12:29.818: INFO: validating pod update-demo-nautilus-ng5qv
Aug  9 13:12:29.918: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug  9 13:12:29.918: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug  9 13:12:29.918: INFO: update-demo-nautilus-ng5qv is verified up and running
Aug  9 13:12:29.918: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 get pods update-demo-nautilus-p5ljw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3957'
Aug  9 13:12:30.170: INFO: stderr: ""
Aug  9 13:12:30.170: INFO: stdout: "true"
Aug  9 13:12:30.170: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 get pods update-demo-nautilus-p5ljw -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3957'
Aug  9 13:12:30.355: INFO: stderr: ""
Aug  9 13:12:30.355: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug  9 13:12:30.355: INFO: validating pod update-demo-nautilus-p5ljw
Aug  9 13:12:30.462: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug  9 13:12:30.462: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug  9 13:12:30.462: INFO: update-demo-nautilus-p5ljw is verified up and running
STEP: rolling-update to new replication controller
Aug  9 13:12:30.465: INFO: scanned /root for discovery docs: <nil>
Aug  9 13:12:30.465: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-3957'
Aug  9 13:12:54.450: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Aug  9 13:12:54.450: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug  9 13:12:54.450: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3957'
Aug  9 13:12:54.656: INFO: stderr: ""
Aug  9 13:12:54.656: INFO: stdout: "update-demo-kitten-mpvbl update-demo-kitten-z4zgs "
Aug  9 13:12:54.657: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 get pods update-demo-kitten-mpvbl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3957'
Aug  9 13:12:54.858: INFO: stderr: ""
Aug  9 13:12:54.858: INFO: stdout: "true"
Aug  9 13:12:54.858: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 get pods update-demo-kitten-mpvbl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3957'
Aug  9 13:12:55.077: INFO: stderr: ""
Aug  9 13:12:55.077: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Aug  9 13:12:55.077: INFO: validating pod update-demo-kitten-mpvbl
Aug  9 13:12:55.177: INFO: got data: {
  "image": "kitten.jpg"
}

Aug  9 13:12:55.178: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Aug  9 13:12:55.178: INFO: update-demo-kitten-mpvbl is verified up and running
Aug  9 13:12:55.178: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 get pods update-demo-kitten-z4zgs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3957'
Aug  9 13:12:55.350: INFO: stderr: ""
Aug  9 13:12:55.350: INFO: stdout: "true"
Aug  9 13:12:55.350: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 get pods update-demo-kitten-z4zgs -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3957'
Aug  9 13:12:55.507: INFO: stderr: ""
Aug  9 13:12:55.507: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Aug  9 13:12:55.507: INFO: validating pod update-demo-kitten-z4zgs
Aug  9 13:12:55.610: INFO: got data: {
  "image": "kitten.jpg"
}

Aug  9 13:12:55.610: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Aug  9 13:12:55.610: INFO: update-demo-kitten-z4zgs is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:12:55.610: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3957" for this suite.
Aug  9 13:13:19.664: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:13:20.007: INFO: namespace kubectl-3957 deletion completed in 24.384586958s

• [SLOW TEST:57.780 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:13:20.009: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-4779
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Aug  9 13:13:32.417: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug  9 13:13:32.428: INFO: Pod pod-with-prestop-exec-hook still exists
Aug  9 13:13:34.428: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug  9 13:13:34.439: INFO: Pod pod-with-prestop-exec-hook still exists
Aug  9 13:13:36.428: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug  9 13:13:36.450: INFO: Pod pod-with-prestop-exec-hook still exists
Aug  9 13:13:38.428: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug  9 13:13:38.440: INFO: Pod pod-with-prestop-exec-hook still exists
Aug  9 13:13:40.428: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug  9 13:13:40.438: INFO: Pod pod-with-prestop-exec-hook still exists
Aug  9 13:13:42.428: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug  9 13:13:42.439: INFO: Pod pod-with-prestop-exec-hook still exists
Aug  9 13:13:44.428: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug  9 13:13:44.444: INFO: Pod pod-with-prestop-exec-hook still exists
Aug  9 13:13:46.428: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug  9 13:13:46.441: INFO: Pod pod-with-prestop-exec-hook still exists
Aug  9 13:13:48.428: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug  9 13:13:48.439: INFO: Pod pod-with-prestop-exec-hook still exists
Aug  9 13:13:50.428: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug  9 13:13:50.442: INFO: Pod pod-with-prestop-exec-hook still exists
Aug  9 13:13:52.428: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Aug  9 13:13:52.439: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:13:52.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-4779" for this suite.
Aug  9 13:14:04.516: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:14:04.939: INFO: namespace container-lifecycle-hook-4779 deletion completed in 12.463090902s

• [SLOW TEST:44.931 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:14:04.944: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svc-latency-1770
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating replication controller svc-latency-rc in namespace svc-latency-1770
I0809 13:14:05.361796      19 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: svc-latency-1770, replica count: 1
I0809 13:14:06.412714      19 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0809 13:14:07.413180      19 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0809 13:14:08.413628      19 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0809 13:14:09.413953      19 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug  9 13:14:09.556: INFO: Created: latency-svc-hbfck
Aug  9 13:14:09.569: INFO: Got endpoints: latency-svc-hbfck [54.693016ms]
Aug  9 13:14:09.612: INFO: Created: latency-svc-sqxsq
Aug  9 13:14:09.639: INFO: Got endpoints: latency-svc-sqxsq [69.720694ms]
Aug  9 13:14:09.650: INFO: Created: latency-svc-227rm
Aug  9 13:14:09.679: INFO: Created: latency-svc-jnjzn
Aug  9 13:14:09.679: INFO: Got endpoints: latency-svc-227rm [109.760586ms]
Aug  9 13:14:09.703: INFO: Got endpoints: latency-svc-jnjzn [133.419324ms]
Aug  9 13:14:09.721: INFO: Created: latency-svc-wzww7
Aug  9 13:14:09.739: INFO: Got endpoints: latency-svc-wzww7 [170.15729ms]
Aug  9 13:14:09.753: INFO: Created: latency-svc-x6xrm
Aug  9 13:14:09.783: INFO: Got endpoints: latency-svc-x6xrm [213.453061ms]
Aug  9 13:14:09.797: INFO: Created: latency-svc-t9srx
Aug  9 13:14:09.817: INFO: Got endpoints: latency-svc-t9srx [247.265541ms]
Aug  9 13:14:09.831: INFO: Created: latency-svc-cr2rc
Aug  9 13:14:09.852: INFO: Got endpoints: latency-svc-cr2rc [282.641163ms]
Aug  9 13:14:09.867: INFO: Created: latency-svc-8rwtw
Aug  9 13:14:09.894: INFO: Got endpoints: latency-svc-8rwtw [324.075942ms]
Aug  9 13:14:09.897: INFO: Created: latency-svc-rsslk
Aug  9 13:14:09.923: INFO: Got endpoints: latency-svc-rsslk [70.119664ms]
Aug  9 13:14:09.936: INFO: Created: latency-svc-ntzpc
Aug  9 13:14:09.942: INFO: Got endpoints: latency-svc-ntzpc [372.275815ms]
Aug  9 13:14:09.948: INFO: Created: latency-svc-klrql
Aug  9 13:14:09.957: INFO: Got endpoints: latency-svc-klrql [387.754261ms]
Aug  9 13:14:10.124: INFO: Created: latency-svc-xl48v
Aug  9 13:14:10.200: INFO: Created: latency-svc-wsstr
Aug  9 13:14:10.224: INFO: Got endpoints: latency-svc-xl48v [654.820566ms]
Aug  9 13:14:10.226: INFO: Got endpoints: latency-svc-wsstr [656.306973ms]
Aug  9 13:14:10.227: INFO: Created: latency-svc-zhs4h
Aug  9 13:14:10.246: INFO: Got endpoints: latency-svc-zhs4h [676.664576ms]
Aug  9 13:14:10.265: INFO: Created: latency-svc-xmdtw
Aug  9 13:14:10.292: INFO: Got endpoints: latency-svc-xmdtw [722.298169ms]
Aug  9 13:14:10.293: INFO: Created: latency-svc-brgw7
Aug  9 13:14:10.325: INFO: Created: latency-svc-4bvhk
Aug  9 13:14:10.325: INFO: Got endpoints: latency-svc-brgw7 [755.846951ms]
Aug  9 13:14:10.343: INFO: Got endpoints: latency-svc-4bvhk [703.322898ms]
Aug  9 13:14:10.369: INFO: Created: latency-svc-6nh7z
Aug  9 13:14:10.382: INFO: Got endpoints: latency-svc-6nh7z [702.789725ms]
Aug  9 13:14:10.389: INFO: Created: latency-svc-6xm95
Aug  9 13:14:10.403: INFO: Created: latency-svc-s8ggm
Aug  9 13:14:10.405: INFO: Got endpoints: latency-svc-6xm95 [702.12295ms]
Aug  9 13:14:10.427: INFO: Got endpoints: latency-svc-s8ggm [687.587658ms]
Aug  9 13:14:10.431: INFO: Created: latency-svc-qxtfc
Aug  9 13:14:10.460: INFO: Created: latency-svc-6xmsd
Aug  9 13:14:10.468: INFO: Got endpoints: latency-svc-qxtfc [684.732132ms]
Aug  9 13:14:10.485: INFO: Got endpoints: latency-svc-6xmsd [668.042594ms]
Aug  9 13:14:10.492: INFO: Created: latency-svc-dxw84
Aug  9 13:14:10.511: INFO: Got endpoints: latency-svc-dxw84 [617.675912ms]
Aug  9 13:14:10.517: INFO: Created: latency-svc-znts5
Aug  9 13:14:10.546: INFO: Got endpoints: latency-svc-znts5 [623.23603ms]
Aug  9 13:14:10.550: INFO: Created: latency-svc-zzbh9
Aug  9 13:14:10.592: INFO: Got endpoints: latency-svc-zzbh9 [650.577787ms]
Aug  9 13:14:10.597: INFO: Created: latency-svc-69r94
Aug  9 13:14:10.627: INFO: Got endpoints: latency-svc-69r94 [669.162923ms]
Aug  9 13:14:10.629: INFO: Created: latency-svc-k46zh
Aug  9 13:14:10.650: INFO: Got endpoints: latency-svc-k46zh [425.202113ms]
Aug  9 13:14:10.655: INFO: Created: latency-svc-jk59r
Aug  9 13:14:10.679: INFO: Got endpoints: latency-svc-jk59r [453.264508ms]
Aug  9 13:14:10.692: INFO: Created: latency-svc-jq6c9
Aug  9 13:14:10.707: INFO: Got endpoints: latency-svc-jq6c9 [460.43096ms]
Aug  9 13:14:10.718: INFO: Created: latency-svc-lqgts
Aug  9 13:14:10.743: INFO: Got endpoints: latency-svc-lqgts [451.314649ms]
Aug  9 13:14:10.749: INFO: Created: latency-svc-vgg5r
Aug  9 13:14:10.770: INFO: Got endpoints: latency-svc-vgg5r [444.919561ms]
Aug  9 13:14:10.781: INFO: Created: latency-svc-7sp8c
Aug  9 13:14:10.812: INFO: Got endpoints: latency-svc-7sp8c [469.604368ms]
Aug  9 13:14:10.825: INFO: Created: latency-svc-m2ng4
Aug  9 13:14:10.851: INFO: Got endpoints: latency-svc-m2ng4 [468.541317ms]
Aug  9 13:14:10.857: INFO: Created: latency-svc-l8w5d
Aug  9 13:14:10.891: INFO: Created: latency-svc-2z57q
Aug  9 13:14:10.897: INFO: Got endpoints: latency-svc-l8w5d [491.580385ms]
Aug  9 13:14:10.921: INFO: Got endpoints: latency-svc-2z57q [493.652358ms]
Aug  9 13:14:10.928: INFO: Created: latency-svc-s42lq
Aug  9 13:14:10.950: INFO: Got endpoints: latency-svc-s42lq [481.854237ms]
Aug  9 13:14:10.957: INFO: Created: latency-svc-rjjlh
Aug  9 13:14:10.980: INFO: Got endpoints: latency-svc-rjjlh [495.154414ms]
Aug  9 13:14:10.989: INFO: Created: latency-svc-b4knr
Aug  9 13:14:10.997: INFO: Got endpoints: latency-svc-b4knr [485.542009ms]
Aug  9 13:14:11.018: INFO: Created: latency-svc-fs252
Aug  9 13:14:11.041: INFO: Got endpoints: latency-svc-fs252 [494.853576ms]
Aug  9 13:14:11.049: INFO: Created: latency-svc-htv6s
Aug  9 13:14:11.071: INFO: Got endpoints: latency-svc-htv6s [478.588309ms]
Aug  9 13:14:11.077: INFO: Created: latency-svc-jxrfm
Aug  9 13:14:11.098: INFO: Got endpoints: latency-svc-jxrfm [470.963064ms]
Aug  9 13:14:11.106: INFO: Created: latency-svc-498mg
Aug  9 13:14:11.133: INFO: Got endpoints: latency-svc-498mg [482.996958ms]
Aug  9 13:14:11.152: INFO: Created: latency-svc-qmhfx
Aug  9 13:14:11.153: INFO: Got endpoints: latency-svc-qmhfx [473.53722ms]
Aug  9 13:14:11.180: INFO: Created: latency-svc-mvg7q
Aug  9 13:14:11.209: INFO: Got endpoints: latency-svc-mvg7q [498.160653ms]
Aug  9 13:14:11.213: INFO: Created: latency-svc-xsjh2
Aug  9 13:14:11.234: INFO: Got endpoints: latency-svc-xsjh2 [490.114495ms]
Aug  9 13:14:11.245: INFO: Created: latency-svc-st45q
Aug  9 13:14:11.275: INFO: Created: latency-svc-5pmsl
Aug  9 13:14:11.277: INFO: Got endpoints: latency-svc-st45q [507.364348ms]
Aug  9 13:14:11.289: INFO: Got endpoints: latency-svc-5pmsl [476.359774ms]
Aug  9 13:14:11.305: INFO: Created: latency-svc-kwl6z
Aug  9 13:14:11.327: INFO: Got endpoints: latency-svc-kwl6z [476.518031ms]
Aug  9 13:14:11.334: INFO: Created: latency-svc-rkgrm
Aug  9 13:14:11.353: INFO: Got endpoints: latency-svc-rkgrm [455.72491ms]
Aug  9 13:14:11.365: INFO: Created: latency-svc-gtpf2
Aug  9 13:14:11.397: INFO: Got endpoints: latency-svc-gtpf2 [476.184604ms]
Aug  9 13:14:11.397: INFO: Created: latency-svc-qdzzm
Aug  9 13:14:11.417: INFO: Got endpoints: latency-svc-qdzzm [466.75865ms]
Aug  9 13:14:11.433: INFO: Created: latency-svc-snrpn
Aug  9 13:14:11.449: INFO: Got endpoints: latency-svc-snrpn [469.050564ms]
Aug  9 13:14:11.457: INFO: Created: latency-svc-nsx8h
Aug  9 13:14:11.480: INFO: Got endpoints: latency-svc-nsx8h [483.112515ms]
Aug  9 13:14:11.501: INFO: Created: latency-svc-lcpgt
Aug  9 13:14:11.526: INFO: Got endpoints: latency-svc-lcpgt [485.28282ms]
Aug  9 13:14:11.526: INFO: Created: latency-svc-m8mrt
Aug  9 13:14:11.558: INFO: Created: latency-svc-tztjp
Aug  9 13:14:11.558: INFO: Got endpoints: latency-svc-m8mrt [486.451419ms]
Aug  9 13:14:11.571: INFO: Got endpoints: latency-svc-tztjp [473.524325ms]
Aug  9 13:14:11.595: INFO: Created: latency-svc-lwmcm
Aug  9 13:14:11.615: INFO: Got endpoints: latency-svc-lwmcm [482.391076ms]
Aug  9 13:14:11.616: INFO: Created: latency-svc-qwfn9
Aug  9 13:14:11.642: INFO: Got endpoints: latency-svc-qwfn9 [488.685606ms]
Aug  9 13:14:11.650: INFO: Created: latency-svc-mqqkv
Aug  9 13:14:11.669: INFO: Got endpoints: latency-svc-mqqkv [460.534534ms]
Aug  9 13:14:11.681: INFO: Created: latency-svc-65sm2
Aug  9 13:14:11.720: INFO: Created: latency-svc-xxz78
Aug  9 13:14:11.721: INFO: Got endpoints: latency-svc-65sm2 [487.655857ms]
Aug  9 13:14:11.741: INFO: Created: latency-svc-xnxb2
Aug  9 13:14:11.741: INFO: Got endpoints: latency-svc-xxz78 [464.018271ms]
Aug  9 13:14:11.765: INFO: Got endpoints: latency-svc-xnxb2 [476.15084ms]
Aug  9 13:14:11.800: INFO: Created: latency-svc-qcp6z
Aug  9 13:14:11.800: INFO: Got endpoints: latency-svc-qcp6z [472.703851ms]
Aug  9 13:14:11.914: INFO: Created: latency-svc-jcwcc
Aug  9 13:14:11.937: INFO: Got endpoints: latency-svc-jcwcc [584.691039ms]
Aug  9 13:14:11.940: INFO: Created: latency-svc-msn5t
Aug  9 13:14:11.961: INFO: Got endpoints: latency-svc-msn5t [564.330071ms]
Aug  9 13:14:12.009: INFO: Created: latency-svc-s6jfl
Aug  9 13:14:12.023: INFO: Got endpoints: latency-svc-s6jfl [606.803674ms]
Aug  9 13:14:12.027: INFO: Created: latency-svc-7r8n8
Aug  9 13:14:12.053: INFO: Got endpoints: latency-svc-7r8n8 [603.843863ms]
Aug  9 13:14:12.061: INFO: Created: latency-svc-mllk9
Aug  9 13:14:12.081: INFO: Got endpoints: latency-svc-mllk9 [601.006813ms]
Aug  9 13:14:12.089: INFO: Created: latency-svc-x464k
Aug  9 13:14:12.115: INFO: Got endpoints: latency-svc-x464k [588.652826ms]
Aug  9 13:14:12.122: INFO: Created: latency-svc-mgfz4
Aug  9 13:14:12.142: INFO: Got endpoints: latency-svc-mgfz4 [583.742854ms]
Aug  9 13:14:12.153: INFO: Created: latency-svc-z7fkd
Aug  9 13:14:12.182: INFO: Got endpoints: latency-svc-z7fkd [610.673809ms]
Aug  9 13:14:12.186: INFO: Created: latency-svc-mnhf2
Aug  9 13:14:12.205: INFO: Got endpoints: latency-svc-mnhf2 [589.2176ms]
Aug  9 13:14:12.213: INFO: Created: latency-svc-7g5z4
Aug  9 13:14:12.243: INFO: Created: latency-svc-cckj4
Aug  9 13:14:12.248: INFO: Got endpoints: latency-svc-7g5z4 [606.232439ms]
Aug  9 13:14:12.259: INFO: Got endpoints: latency-svc-cckj4 [589.994691ms]
Aug  9 13:14:12.273: INFO: Created: latency-svc-rrh6l
Aug  9 13:14:12.295: INFO: Got endpoints: latency-svc-rrh6l [573.739592ms]
Aug  9 13:14:12.305: INFO: Created: latency-svc-bn8mf
Aug  9 13:14:12.324: INFO: Got endpoints: latency-svc-bn8mf [582.17397ms]
Aug  9 13:14:12.341: INFO: Created: latency-svc-xsxsr
Aug  9 13:14:12.365: INFO: Got endpoints: latency-svc-xsxsr [600.0186ms]
Aug  9 13:14:12.386: INFO: Created: latency-svc-vqfwd
Aug  9 13:14:12.404: INFO: Got endpoints: latency-svc-vqfwd [604.121424ms]
Aug  9 13:14:12.413: INFO: Created: latency-svc-h67qf
Aug  9 13:14:12.433: INFO: Got endpoints: latency-svc-h67qf [495.008096ms]
Aug  9 13:14:12.454: INFO: Created: latency-svc-bzmtx
Aug  9 13:14:12.465: INFO: Got endpoints: latency-svc-bzmtx [503.28695ms]
Aug  9 13:14:12.480: INFO: Created: latency-svc-pxmrp
Aug  9 13:14:12.485: INFO: Got endpoints: latency-svc-pxmrp [461.620917ms]
Aug  9 13:14:12.514: INFO: Created: latency-svc-qlhkh
Aug  9 13:14:12.540: INFO: Got endpoints: latency-svc-qlhkh [487.240353ms]
Aug  9 13:14:12.548: INFO: Created: latency-svc-qhsf5
Aug  9 13:14:12.567: INFO: Got endpoints: latency-svc-qhsf5 [485.162502ms]
Aug  9 13:14:12.580: INFO: Created: latency-svc-g65cl
Aug  9 13:14:12.608: INFO: Got endpoints: latency-svc-g65cl [492.682046ms]
Aug  9 13:14:12.624: INFO: Created: latency-svc-dmtgn
Aug  9 13:14:12.661: INFO: Created: latency-svc-m6k8d
Aug  9 13:14:12.661: INFO: Got endpoints: latency-svc-dmtgn [519.345318ms]
Aug  9 13:14:12.665: INFO: Got endpoints: latency-svc-m6k8d [482.493669ms]
Aug  9 13:14:12.679: INFO: Created: latency-svc-hxw9n
Aug  9 13:14:12.692: INFO: Got endpoints: latency-svc-hxw9n [487.846924ms]
Aug  9 13:14:12.716: INFO: Created: latency-svc-9svwr
Aug  9 13:14:12.739: INFO: Got endpoints: latency-svc-9svwr [490.725914ms]
Aug  9 13:14:12.739: INFO: Created: latency-svc-z4bjn
Aug  9 13:14:12.757: INFO: Got endpoints: latency-svc-z4bjn [497.115883ms]
Aug  9 13:14:12.762: INFO: Created: latency-svc-g5c9d
Aug  9 13:14:12.789: INFO: Got endpoints: latency-svc-g5c9d [493.415529ms]
Aug  9 13:14:12.796: INFO: Created: latency-svc-k28ft
Aug  9 13:14:12.823: INFO: Got endpoints: latency-svc-k28ft [499.442363ms]
Aug  9 13:14:12.831: INFO: Created: latency-svc-cswvh
Aug  9 13:14:12.853: INFO: Got endpoints: latency-svc-cswvh [488.221551ms]
Aug  9 13:14:12.866: INFO: Created: latency-svc-s5tfx
Aug  9 13:14:12.880: INFO: Got endpoints: latency-svc-s5tfx [475.637231ms]
Aug  9 13:14:12.893: INFO: Created: latency-svc-52kx4
Aug  9 13:14:12.909: INFO: Got endpoints: latency-svc-52kx4 [476.147562ms]
Aug  9 13:14:12.933: INFO: Created: latency-svc-zs9vt
Aug  9 13:14:12.933: INFO: Got endpoints: latency-svc-zs9vt [468.067482ms]
Aug  9 13:14:12.939: INFO: Created: latency-svc-wttmr
Aug  9 13:14:12.960: INFO: Got endpoints: latency-svc-wttmr [474.728821ms]
Aug  9 13:14:12.970: INFO: Created: latency-svc-lb6gg
Aug  9 13:14:12.981: INFO: Got endpoints: latency-svc-lb6gg [439.00931ms]
Aug  9 13:14:13.009: INFO: Created: latency-svc-2tsqh
Aug  9 13:14:13.034: INFO: Got endpoints: latency-svc-2tsqh [466.984262ms]
Aug  9 13:14:13.041: INFO: Created: latency-svc-thw85
Aug  9 13:14:13.065: INFO: Created: latency-svc-j2s9c
Aug  9 13:14:13.096: INFO: Created: latency-svc-8j48c
Aug  9 13:14:13.096: INFO: Got endpoints: latency-svc-thw85 [488.116212ms]
Aug  9 13:14:13.120: INFO: Created: latency-svc-j8lv4
Aug  9 13:14:13.124: INFO: Got endpoints: latency-svc-j2s9c [462.640075ms]
Aug  9 13:14:13.164: INFO: Created: latency-svc-prjmf
Aug  9 13:14:13.197: INFO: Created: latency-svc-s7nmp
Aug  9 13:14:13.197: INFO: Got endpoints: latency-svc-8j48c [532.118132ms]
Aug  9 13:14:13.217: INFO: Created: latency-svc-wmpjp
Aug  9 13:14:13.225: INFO: Got endpoints: latency-svc-j8lv4 [532.955387ms]
Aug  9 13:14:13.246: INFO: Created: latency-svc-gqlxc
Aug  9 13:14:13.281: INFO: Got endpoints: latency-svc-prjmf [541.857656ms]
Aug  9 13:14:13.282: INFO: Created: latency-svc-knv58
Aug  9 13:14:13.311: INFO: Created: latency-svc-47k45
Aug  9 13:14:13.336: INFO: Created: latency-svc-n8nd2
Aug  9 13:14:13.337: INFO: Got endpoints: latency-svc-s7nmp [579.858429ms]
Aug  9 13:14:13.368: INFO: Created: latency-svc-bklqn
Aug  9 13:14:13.386: INFO: Got endpoints: latency-svc-wmpjp [596.771176ms]
Aug  9 13:14:13.409: INFO: Created: latency-svc-nts7v
Aug  9 13:14:13.429: INFO: Got endpoints: latency-svc-gqlxc [605.545552ms]
Aug  9 13:14:13.437: INFO: Created: latency-svc-btj7c
Aug  9 13:14:13.470: INFO: Created: latency-svc-4mpwn
Aug  9 13:14:13.477: INFO: Got endpoints: latency-svc-knv58 [624.111071ms]
Aug  9 13:14:13.501: INFO: Created: latency-svc-7mtwn
Aug  9 13:14:13.525: INFO: Got endpoints: latency-svc-47k45 [644.573038ms]
Aug  9 13:14:13.525: INFO: Created: latency-svc-mnq5f
Aug  9 13:14:13.565: INFO: Created: latency-svc-flhkg
Aug  9 13:14:13.581: INFO: Got endpoints: latency-svc-n8nd2 [671.573314ms]
Aug  9 13:14:13.616: INFO: Created: latency-svc-8rz2t
Aug  9 13:14:13.709: INFO: Got endpoints: latency-svc-nts7v [748.70025ms]
Aug  9 13:14:13.709: INFO: Got endpoints: latency-svc-bklqn [775.739068ms]
Aug  9 13:14:13.741: INFO: Got endpoints: latency-svc-btj7c [760.202693ms]
Aug  9 13:14:13.749: INFO: Created: latency-svc-frfhx
Aug  9 13:14:13.785: INFO: Got endpoints: latency-svc-4mpwn [751.677996ms]
Aug  9 13:14:13.824: INFO: Got endpoints: latency-svc-7mtwn [728.058795ms]
Aug  9 13:14:13.825: INFO: Created: latency-svc-6glf9
Aug  9 13:14:13.852: INFO: Created: latency-svc-wf9nv
Aug  9 13:14:13.877: INFO: Got endpoints: latency-svc-mnq5f [752.702203ms]
Aug  9 13:14:13.882: INFO: Created: latency-svc-ksz2c
Aug  9 13:14:13.909: INFO: Created: latency-svc-hgb4t
Aug  9 13:14:13.938: INFO: Created: latency-svc-j5fb5
Aug  9 13:14:13.939: INFO: Got endpoints: latency-svc-flhkg [741.718688ms]
Aug  9 13:14:13.965: INFO: Created: latency-svc-b4tgf
Aug  9 13:14:13.985: INFO: Got endpoints: latency-svc-8rz2t [758.776167ms]
Aug  9 13:14:13.991: INFO: Created: latency-svc-tdjcm
Aug  9 13:14:14.032: INFO: Got endpoints: latency-svc-frfhx [750.340336ms]
Aug  9 13:14:14.044: INFO: Created: latency-svc-xtmms
Aug  9 13:14:14.071: INFO: Created: latency-svc-4bvwb
Aug  9 13:14:14.077: INFO: Got endpoints: latency-svc-6glf9 [740.377293ms]
Aug  9 13:14:14.107: INFO: Created: latency-svc-mqgqt
Aug  9 13:14:14.132: INFO: Got endpoints: latency-svc-wf9nv [746.49124ms]
Aug  9 13:14:14.140: INFO: Created: latency-svc-8qdj8
Aug  9 13:14:14.173: INFO: Created: latency-svc-n8gjg
Aug  9 13:14:14.193: INFO: Got endpoints: latency-svc-ksz2c [763.853424ms]
Aug  9 13:14:14.200: INFO: Created: latency-svc-pntgj
Aug  9 13:14:14.227: INFO: Got endpoints: latency-svc-hgb4t [749.301351ms]
Aug  9 13:14:14.232: INFO: Created: latency-svc-5fnxt
Aug  9 13:14:14.272: INFO: Created: latency-svc-n629k
Aug  9 13:14:14.293: INFO: Got endpoints: latency-svc-j5fb5 [768.134141ms]
Aug  9 13:14:14.301: INFO: Created: latency-svc-gm2tb
Aug  9 13:14:14.324: INFO: Created: latency-svc-6mv77
Aug  9 13:14:14.329: INFO: Got endpoints: latency-svc-b4tgf [748.516022ms]
Aug  9 13:14:14.377: INFO: Created: latency-svc-n9j45
Aug  9 13:14:14.385: INFO: Got endpoints: latency-svc-tdjcm [676.381724ms]
Aug  9 13:14:14.389: INFO: Created: latency-svc-9d468
Aug  9 13:14:14.418: INFO: Created: latency-svc-29vl6
Aug  9 13:14:14.437: INFO: Got endpoints: latency-svc-xtmms [727.836002ms]
Aug  9 13:14:14.443: INFO: Created: latency-svc-69z9r
Aug  9 13:14:14.482: INFO: Got endpoints: latency-svc-4bvwb [740.743421ms]
Aug  9 13:14:14.490: INFO: Created: latency-svc-t22z6
Aug  9 13:14:14.519: INFO: Created: latency-svc-54drw
Aug  9 13:14:14.540: INFO: Got endpoints: latency-svc-mqgqt [754.865151ms]
Aug  9 13:14:14.549: INFO: Created: latency-svc-g4ncw
Aug  9 13:14:14.589: INFO: Got endpoints: latency-svc-8qdj8 [764.431471ms]
Aug  9 13:14:14.601: INFO: Created: latency-svc-v5k6f
Aug  9 13:14:14.628: INFO: Created: latency-svc-grdq5
Aug  9 13:14:14.632: INFO: Got endpoints: latency-svc-n8gjg [755.517782ms]
Aug  9 13:14:14.673: INFO: Created: latency-svc-ctmjs
Aug  9 13:14:14.682: INFO: Got endpoints: latency-svc-pntgj [742.994878ms]
Aug  9 13:14:14.725: INFO: Created: latency-svc-bzk76
Aug  9 13:14:14.729: INFO: Got endpoints: latency-svc-5fnxt [743.461717ms]
Aug  9 13:14:14.780: INFO: Got endpoints: latency-svc-n629k [748.769988ms]
Aug  9 13:14:14.781: INFO: Created: latency-svc-fjxdn
Aug  9 13:14:14.829: INFO: Created: latency-svc-tzk8b
Aug  9 13:14:14.836: INFO: Got endpoints: latency-svc-gm2tb [758.777466ms]
Aug  9 13:14:14.877: INFO: Created: latency-svc-48mq8
Aug  9 13:14:14.885: INFO: Got endpoints: latency-svc-6mv77 [752.476026ms]
Aug  9 13:14:14.929: INFO: Got endpoints: latency-svc-n9j45 [736.399442ms]
Aug  9 13:14:14.937: INFO: Created: latency-svc-scgr6
Aug  9 13:14:14.965: INFO: Created: latency-svc-p9mhp
Aug  9 13:14:14.977: INFO: Got endpoints: latency-svc-9d468 [750.464358ms]
Aug  9 13:14:15.017: INFO: Created: latency-svc-6nvfp
Aug  9 13:14:15.027: INFO: Got endpoints: latency-svc-29vl6 [734.390692ms]
Aug  9 13:14:15.072: INFO: Created: latency-svc-4c8kw
Aug  9 13:14:15.077: INFO: Got endpoints: latency-svc-69z9r [748.025567ms]
Aug  9 13:14:15.119: INFO: Created: latency-svc-l6xbt
Aug  9 13:14:15.124: INFO: Got endpoints: latency-svc-t22z6 [738.777409ms]
Aug  9 13:14:15.173: INFO: Created: latency-svc-wf5c5
Aug  9 13:14:15.177: INFO: Got endpoints: latency-svc-54drw [740.031919ms]
Aug  9 13:14:15.230: INFO: Got endpoints: latency-svc-g4ncw [747.885273ms]
Aug  9 13:14:15.230: INFO: Created: latency-svc-cnk6r
Aug  9 13:14:15.275: INFO: Got endpoints: latency-svc-v5k6f [734.055901ms]
Aug  9 13:14:15.275: INFO: Created: latency-svc-9cs4j
Aug  9 13:14:15.311: INFO: Created: latency-svc-jcrg8
Aug  9 13:14:15.325: INFO: Got endpoints: latency-svc-grdq5 [736.274115ms]
Aug  9 13:14:15.369: INFO: Created: latency-svc-7hmv2
Aug  9 13:14:15.374: INFO: Got endpoints: latency-svc-ctmjs [741.623275ms]
Aug  9 13:14:15.409: INFO: Created: latency-svc-f9lvj
Aug  9 13:14:15.427: INFO: Got endpoints: latency-svc-bzk76 [745.776081ms]
Aug  9 13:14:15.482: INFO: Created: latency-svc-fpqbj
Aug  9 13:14:15.482: INFO: Got endpoints: latency-svc-fjxdn [751.919295ms]
Aug  9 13:14:15.523: INFO: Created: latency-svc-rqzlj
Aug  9 13:14:15.525: INFO: Got endpoints: latency-svc-tzk8b [744.555634ms]
Aug  9 13:14:15.557: INFO: Created: latency-svc-t4sbn
Aug  9 13:14:15.581: INFO: Got endpoints: latency-svc-48mq8 [745.279265ms]
Aug  9 13:14:15.615: INFO: Created: latency-svc-cdzh8
Aug  9 13:14:15.630: INFO: Got endpoints: latency-svc-scgr6 [745.214614ms]
Aug  9 13:14:15.677: INFO: Created: latency-svc-7lq5x
Aug  9 13:14:15.693: INFO: Got endpoints: latency-svc-p9mhp [763.763992ms]
Aug  9 13:14:15.729: INFO: Got endpoints: latency-svc-6nvfp [751.517989ms]
Aug  9 13:14:15.739: INFO: Created: latency-svc-d48wr
Aug  9 13:14:15.783: INFO: Got endpoints: latency-svc-4c8kw [754.98205ms]
Aug  9 13:14:15.783: INFO: Created: latency-svc-lvfsx
Aug  9 13:14:15.824: INFO: Created: latency-svc-n7t98
Aug  9 13:14:15.829: INFO: Got endpoints: latency-svc-l6xbt [751.592239ms]
Aug  9 13:14:15.864: INFO: Created: latency-svc-22gwd
Aug  9 13:14:15.872: INFO: Got endpoints: latency-svc-wf5c5 [748.26706ms]
Aug  9 13:14:15.922: INFO: Created: latency-svc-jnb4t
Aug  9 13:14:15.925: INFO: Got endpoints: latency-svc-cnk6r [748.355005ms]
Aug  9 13:14:16.001: INFO: Got endpoints: latency-svc-9cs4j [771.502608ms]
Aug  9 13:14:16.102: INFO: Got endpoints: latency-svc-7hmv2 [776.98025ms]
Aug  9 13:14:16.103: INFO: Got endpoints: latency-svc-jcrg8 [828.189025ms]
Aug  9 13:14:16.113: INFO: Created: latency-svc-wh2ch
Aug  9 13:14:16.133: INFO: Got endpoints: latency-svc-f9lvj [758.35608ms]
Aug  9 13:14:16.139: INFO: Created: latency-svc-rl7rs
Aug  9 13:14:16.169: INFO: Created: latency-svc-59mwb
Aug  9 13:14:16.191: INFO: Got endpoints: latency-svc-fpqbj [763.340573ms]
Aug  9 13:14:16.202: INFO: Created: latency-svc-mgvtl
Aug  9 13:14:16.225: INFO: Got endpoints: latency-svc-rqzlj [742.098597ms]
Aug  9 13:14:16.225: INFO: Created: latency-svc-zz6j9
Aug  9 13:14:16.254: INFO: Created: latency-svc-cp48k
Aug  9 13:14:16.281: INFO: Created: latency-svc-2wckz
Aug  9 13:14:16.281: INFO: Got endpoints: latency-svc-t4sbn [755.887734ms]
Aug  9 13:14:16.317: INFO: Created: latency-svc-4ql7n
Aug  9 13:14:16.325: INFO: Got endpoints: latency-svc-cdzh8 [743.419724ms]
Aug  9 13:14:16.366: INFO: Created: latency-svc-cmml2
Aug  9 13:14:16.375: INFO: Got endpoints: latency-svc-7lq5x [744.733857ms]
Aug  9 13:14:16.412: INFO: Created: latency-svc-wxlhm
Aug  9 13:14:16.424: INFO: Got endpoints: latency-svc-d48wr [730.789587ms]
Aug  9 13:14:16.470: INFO: Created: latency-svc-cpwpz
Aug  9 13:14:16.478: INFO: Got endpoints: latency-svc-lvfsx [748.431398ms]
Aug  9 13:14:16.520: INFO: Created: latency-svc-k4cxs
Aug  9 13:14:16.531: INFO: Got endpoints: latency-svc-n7t98 [747.5608ms]
Aug  9 13:14:16.581: INFO: Created: latency-svc-xbq8g
Aug  9 13:14:16.584: INFO: Got endpoints: latency-svc-22gwd [755.146418ms]
Aug  9 13:14:16.639: INFO: Got endpoints: latency-svc-jnb4t [766.703372ms]
Aug  9 13:14:16.641: INFO: Created: latency-svc-42jvq
Aug  9 13:14:16.683: INFO: Got endpoints: latency-svc-wh2ch [757.628961ms]
Aug  9 13:14:16.690: INFO: Created: latency-svc-c7qk7
Aug  9 13:14:16.732: INFO: Got endpoints: latency-svc-rl7rs [731.084623ms]
Aug  9 13:14:16.737: INFO: Created: latency-svc-frl5c
Aug  9 13:14:16.776: INFO: Got endpoints: latency-svc-59mwb [673.197695ms]
Aug  9 13:14:16.777: INFO: Created: latency-svc-nhjll
Aug  9 13:14:16.817: INFO: Created: latency-svc-6c7ff
Aug  9 13:14:16.823: INFO: Got endpoints: latency-svc-mgvtl [720.711417ms]
Aug  9 13:14:16.869: INFO: Created: latency-svc-49d7l
Aug  9 13:14:16.877: INFO: Got endpoints: latency-svc-zz6j9 [744.543678ms]
Aug  9 13:14:16.925: INFO: Got endpoints: latency-svc-cp48k [734.538996ms]
Aug  9 13:14:16.927: INFO: Created: latency-svc-2wqzc
Aug  9 13:14:16.974: INFO: Created: latency-svc-7n6qz
Aug  9 13:14:16.980: INFO: Got endpoints: latency-svc-2wckz [755.597507ms]
Aug  9 13:14:17.032: INFO: Got endpoints: latency-svc-4ql7n [750.611049ms]
Aug  9 13:14:17.053: INFO: Created: latency-svc-4qxlj
Aug  9 13:14:17.069: INFO: Created: latency-svc-f8t8f
Aug  9 13:14:17.081: INFO: Got endpoints: latency-svc-cmml2 [755.736979ms]
Aug  9 13:14:17.117: INFO: Created: latency-svc-6tmz2
Aug  9 13:14:17.130: INFO: Got endpoints: latency-svc-wxlhm [754.793212ms]
Aug  9 13:14:17.173: INFO: Created: latency-svc-qhvkv
Aug  9 13:14:17.177: INFO: Got endpoints: latency-svc-cpwpz [752.977404ms]
Aug  9 13:14:17.226: INFO: Got endpoints: latency-svc-k4cxs [748.201854ms]
Aug  9 13:14:17.227: INFO: Created: latency-svc-gdb9n
Aug  9 13:14:17.269: INFO: Created: latency-svc-bxmrm
Aug  9 13:14:17.273: INFO: Got endpoints: latency-svc-xbq8g [741.983709ms]
Aug  9 13:14:17.311: INFO: Created: latency-svc-7grvr
Aug  9 13:14:17.330: INFO: Got endpoints: latency-svc-42jvq [745.37379ms]
Aug  9 13:14:17.369: INFO: Created: latency-svc-qppz6
Aug  9 13:14:17.375: INFO: Got endpoints: latency-svc-c7qk7 [736.000657ms]
Aug  9 13:14:17.417: INFO: Created: latency-svc-nz9bc
Aug  9 13:14:17.428: INFO: Got endpoints: latency-svc-frl5c [744.417119ms]
Aug  9 13:14:17.491: INFO: Got endpoints: latency-svc-nhjll [758.763825ms]
Aug  9 13:14:17.524: INFO: Got endpoints: latency-svc-6c7ff [747.96146ms]
Aug  9 13:14:17.578: INFO: Got endpoints: latency-svc-49d7l [754.579909ms]
Aug  9 13:14:17.628: INFO: Got endpoints: latency-svc-2wqzc [750.334988ms]
Aug  9 13:14:17.674: INFO: Got endpoints: latency-svc-7n6qz [743.664071ms]
Aug  9 13:14:17.730: INFO: Got endpoints: latency-svc-4qxlj [749.973497ms]
Aug  9 13:14:17.781: INFO: Got endpoints: latency-svc-f8t8f [748.875701ms]
Aug  9 13:14:17.829: INFO: Got endpoints: latency-svc-6tmz2 [748.730277ms]
Aug  9 13:14:17.874: INFO: Got endpoints: latency-svc-qhvkv [743.926054ms]
Aug  9 13:14:17.926: INFO: Got endpoints: latency-svc-gdb9n [748.614118ms]
Aug  9 13:14:17.976: INFO: Got endpoints: latency-svc-bxmrm [750.192439ms]
Aug  9 13:14:18.032: INFO: Got endpoints: latency-svc-7grvr [758.992175ms]
Aug  9 13:14:18.075: INFO: Got endpoints: latency-svc-qppz6 [745.23692ms]
Aug  9 13:14:18.124: INFO: Got endpoints: latency-svc-nz9bc [748.807052ms]
Aug  9 13:14:18.124: INFO: Latencies: [69.720694ms 70.119664ms 109.760586ms 133.419324ms 170.15729ms 213.453061ms 247.265541ms 282.641163ms 324.075942ms 372.275815ms 387.754261ms 425.202113ms 439.00931ms 444.919561ms 451.314649ms 453.264508ms 455.72491ms 460.43096ms 460.534534ms 461.620917ms 462.640075ms 464.018271ms 466.75865ms 466.984262ms 468.067482ms 468.541317ms 469.050564ms 469.604368ms 470.963064ms 472.703851ms 473.524325ms 473.53722ms 474.728821ms 475.637231ms 476.147562ms 476.15084ms 476.184604ms 476.359774ms 476.518031ms 478.588309ms 481.854237ms 482.391076ms 482.493669ms 482.996958ms 483.112515ms 485.162502ms 485.28282ms 485.542009ms 486.451419ms 487.240353ms 487.655857ms 487.846924ms 488.116212ms 488.221551ms 488.685606ms 490.114495ms 490.725914ms 491.580385ms 492.682046ms 493.415529ms 493.652358ms 494.853576ms 495.008096ms 495.154414ms 497.115883ms 498.160653ms 499.442363ms 503.28695ms 507.364348ms 519.345318ms 532.118132ms 532.955387ms 541.857656ms 564.330071ms 573.739592ms 579.858429ms 582.17397ms 583.742854ms 584.691039ms 588.652826ms 589.2176ms 589.994691ms 596.771176ms 600.0186ms 601.006813ms 603.843863ms 604.121424ms 605.545552ms 606.232439ms 606.803674ms 610.673809ms 617.675912ms 623.23603ms 624.111071ms 644.573038ms 650.577787ms 654.820566ms 656.306973ms 668.042594ms 669.162923ms 671.573314ms 673.197695ms 676.381724ms 676.664576ms 684.732132ms 687.587658ms 702.12295ms 702.789725ms 703.322898ms 720.711417ms 722.298169ms 727.836002ms 728.058795ms 730.789587ms 731.084623ms 734.055901ms 734.390692ms 734.538996ms 736.000657ms 736.274115ms 736.399442ms 738.777409ms 740.031919ms 740.377293ms 740.743421ms 741.623275ms 741.718688ms 741.983709ms 742.098597ms 742.994878ms 743.419724ms 743.461717ms 743.664071ms 743.926054ms 744.417119ms 744.543678ms 744.555634ms 744.733857ms 745.214614ms 745.23692ms 745.279265ms 745.37379ms 745.776081ms 746.49124ms 747.5608ms 747.885273ms 747.96146ms 748.025567ms 748.201854ms 748.26706ms 748.355005ms 748.431398ms 748.516022ms 748.614118ms 748.70025ms 748.730277ms 748.769988ms 748.807052ms 748.875701ms 749.301351ms 749.973497ms 750.192439ms 750.334988ms 750.340336ms 750.464358ms 750.611049ms 751.517989ms 751.592239ms 751.677996ms 751.919295ms 752.476026ms 752.702203ms 752.977404ms 754.579909ms 754.793212ms 754.865151ms 754.98205ms 755.146418ms 755.517782ms 755.597507ms 755.736979ms 755.846951ms 755.887734ms 757.628961ms 758.35608ms 758.763825ms 758.776167ms 758.777466ms 758.992175ms 760.202693ms 763.340573ms 763.763992ms 763.853424ms 764.431471ms 766.703372ms 768.134141ms 771.502608ms 775.739068ms 776.98025ms 828.189025ms]
Aug  9 13:14:18.124: INFO: 50 %ile: 671.573314ms
Aug  9 13:14:18.124: INFO: 90 %ile: 755.736979ms
Aug  9 13:14:18.124: INFO: 99 %ile: 776.98025ms
Aug  9 13:14:18.124: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:14:18.124: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-1770" for this suite.
Aug  9 13:14:42.191: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:14:42.657: INFO: namespace svc-latency-1770 deletion completed in 24.519607536s

• [SLOW TEST:37.713 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:14:42.659: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-kubelet-etc-hosts-6132
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Aug  9 13:14:55.026: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6132 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  9 13:14:55.026: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
Aug  9 13:14:55.374: INFO: Exec stderr: ""
Aug  9 13:14:55.374: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6132 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  9 13:14:55.374: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
Aug  9 13:14:55.908: INFO: Exec stderr: ""
Aug  9 13:14:55.908: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6132 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  9 13:14:55.908: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
Aug  9 13:14:56.242: INFO: Exec stderr: ""
Aug  9 13:14:56.242: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6132 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  9 13:14:56.242: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
Aug  9 13:14:56.508: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Aug  9 13:14:56.508: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6132 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  9 13:14:56.508: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
Aug  9 13:14:56.759: INFO: Exec stderr: ""
Aug  9 13:14:56.759: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6132 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  9 13:14:56.759: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
Aug  9 13:14:57.039: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Aug  9 13:14:57.039: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6132 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  9 13:14:57.039: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
Aug  9 13:14:57.244: INFO: Exec stderr: ""
Aug  9 13:14:57.244: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6132 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  9 13:14:57.244: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
Aug  9 13:14:57.519: INFO: Exec stderr: ""
Aug  9 13:14:57.519: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6132 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  9 13:14:57.519: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
Aug  9 13:14:57.697: INFO: Exec stderr: ""
Aug  9 13:14:57.697: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6132 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  9 13:14:57.697: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
Aug  9 13:14:57.872: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:14:57.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-6132" for this suite.
Aug  9 13:15:45.925: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:15:46.432: INFO: namespace e2e-kubelet-etc-hosts-6132 deletion completed in 48.546201569s

• [SLOW TEST:63.773 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:15:46.433: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-8905
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug  9 13:15:46.734: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Aug  9 13:15:46.778: INFO: Number of nodes with available pods: 0
Aug  9 13:15:46.778: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Aug  9 13:15:46.836: INFO: Number of nodes with available pods: 0
Aug  9 13:15:46.837: INFO: Node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d is running more than one daemon pod
Aug  9 13:15:47.847: INFO: Number of nodes with available pods: 0
Aug  9 13:15:47.847: INFO: Node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d is running more than one daemon pod
Aug  9 13:15:48.848: INFO: Number of nodes with available pods: 0
Aug  9 13:15:48.848: INFO: Node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d is running more than one daemon pod
Aug  9 13:15:49.854: INFO: Number of nodes with available pods: 1
Aug  9 13:15:49.854: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Aug  9 13:15:49.929: INFO: Number of nodes with available pods: 1
Aug  9 13:15:49.929: INFO: Number of running nodes: 0, number of available pods: 1
Aug  9 13:15:51.001: INFO: Number of nodes with available pods: 0
Aug  9 13:15:51.001: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Aug  9 13:15:51.037: INFO: Number of nodes with available pods: 0
Aug  9 13:15:51.037: INFO: Node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d is running more than one daemon pod
Aug  9 13:15:52.053: INFO: Number of nodes with available pods: 0
Aug  9 13:15:52.053: INFO: Node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d is running more than one daemon pod
Aug  9 13:15:53.048: INFO: Number of nodes with available pods: 0
Aug  9 13:15:53.048: INFO: Node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d is running more than one daemon pod
Aug  9 13:15:54.053: INFO: Number of nodes with available pods: 0
Aug  9 13:15:54.053: INFO: Node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d is running more than one daemon pod
Aug  9 13:15:55.046: INFO: Number of nodes with available pods: 0
Aug  9 13:15:55.046: INFO: Node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d is running more than one daemon pod
Aug  9 13:15:56.047: INFO: Number of nodes with available pods: 0
Aug  9 13:15:56.047: INFO: Node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d is running more than one daemon pod
Aug  9 13:15:57.047: INFO: Number of nodes with available pods: 0
Aug  9 13:15:57.047: INFO: Node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d is running more than one daemon pod
Aug  9 13:15:58.049: INFO: Number of nodes with available pods: 0
Aug  9 13:15:58.049: INFO: Node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d is running more than one daemon pod
Aug  9 13:15:59.049: INFO: Number of nodes with available pods: 1
Aug  9 13:15:59.049: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8905, will wait for the garbage collector to delete the pods
Aug  9 13:15:59.155: INFO: Deleting DaemonSet.extensions daemon-set took: 26.018493ms
Aug  9 13:15:59.556: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.424128ms
Aug  9 13:16:05.868: INFO: Number of nodes with available pods: 0
Aug  9 13:16:05.868: INFO: Number of running nodes: 0, number of available pods: 0
Aug  9 13:16:05.877: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-8905/daemonsets","resourceVersion":"124622861"},"items":null}

Aug  9 13:16:05.886: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-8905/pods","resourceVersion":"124622861"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:16:05.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8905" for this suite.
Aug  9 13:16:14.014: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:16:14.341: INFO: namespace daemonsets-8905 deletion completed in 8.373378058s

• [SLOW TEST:27.908 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:16:14.342: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-171
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name projected-secret-test-d754776f-fb2d-4e5a-91de-24be92b404b1
STEP: Creating a pod to test consume secrets
Aug  9 13:16:14.589: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-dc457e7a-830f-4245-a5c4-023d433dd1aa" in namespace "projected-171" to be "success or failure"
Aug  9 13:16:14.608: INFO: Pod "pod-projected-secrets-dc457e7a-830f-4245-a5c4-023d433dd1aa": Phase="Pending", Reason="", readiness=false. Elapsed: 18.807056ms
Aug  9 13:16:16.620: INFO: Pod "pod-projected-secrets-dc457e7a-830f-4245-a5c4-023d433dd1aa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030113315s
Aug  9 13:16:18.630: INFO: Pod "pod-projected-secrets-dc457e7a-830f-4245-a5c4-023d433dd1aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.04030516s
STEP: Saw pod success
Aug  9 13:16:18.630: INFO: Pod "pod-projected-secrets-dc457e7a-830f-4245-a5c4-023d433dd1aa" satisfied condition "success or failure"
Aug  9 13:16:18.640: INFO: Trying to get logs from node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d pod pod-projected-secrets-dc457e7a-830f-4245-a5c4-023d433dd1aa container secret-volume-test: <nil>
STEP: delete the pod
Aug  9 13:16:18.710: INFO: Waiting for pod pod-projected-secrets-dc457e7a-830f-4245-a5c4-023d433dd1aa to disappear
Aug  9 13:16:18.720: INFO: Pod pod-projected-secrets-dc457e7a-830f-4245-a5c4-023d433dd1aa no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:16:18.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-171" for this suite.
Aug  9 13:16:24.767: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:16:25.102: INFO: namespace projected-171 deletion completed in 6.370363876s

• [SLOW TEST:10.760 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:16:25.106: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5033
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug  9 13:16:25.410: INFO: Waiting up to 5m0s for pod "downwardapi-volume-17d20d85-b4ba-47d1-b466-9e031b22cb71" in namespace "projected-5033" to be "success or failure"
Aug  9 13:16:25.421: INFO: Pod "downwardapi-volume-17d20d85-b4ba-47d1-b466-9e031b22cb71": Phase="Pending", Reason="", readiness=false. Elapsed: 10.478664ms
Aug  9 13:16:27.449: INFO: Pod "downwardapi-volume-17d20d85-b4ba-47d1-b466-9e031b22cb71": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038084916s
Aug  9 13:16:29.459: INFO: Pod "downwardapi-volume-17d20d85-b4ba-47d1-b466-9e031b22cb71": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.048722707s
STEP: Saw pod success
Aug  9 13:16:29.460: INFO: Pod "downwardapi-volume-17d20d85-b4ba-47d1-b466-9e031b22cb71" satisfied condition "success or failure"
Aug  9 13:16:29.469: INFO: Trying to get logs from node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d pod downwardapi-volume-17d20d85-b4ba-47d1-b466-9e031b22cb71 container client-container: <nil>
STEP: delete the pod
Aug  9 13:16:29.532: INFO: Waiting for pod downwardapi-volume-17d20d85-b4ba-47d1-b466-9e031b22cb71 to disappear
Aug  9 13:16:29.542: INFO: Pod downwardapi-volume-17d20d85-b4ba-47d1-b466-9e031b22cb71 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:16:29.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5033" for this suite.
Aug  9 13:16:37.608: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:16:37.992: INFO: namespace projected-5033 deletion completed in 8.427978933s

• [SLOW TEST:12.887 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:16:37.993: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5753
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name s-test-opt-del-54a92766-7c6e-4450-ac84-0503b98c9385
STEP: Creating secret with name s-test-opt-upd-72d2b1fa-e7f2-4baa-9834-010853334de5
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-54a92766-7c6e-4450-ac84-0503b98c9385
STEP: Updating secret s-test-opt-upd-72d2b1fa-e7f2-4baa-9834-010853334de5
STEP: Creating secret with name s-test-opt-create-c4ba93e5-7a6a-4971-b43a-cafc55d51961
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:16:46.798: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5753" for this suite.
Aug  9 13:17:10.852: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:17:11.191: INFO: namespace projected-5753 deletion completed in 24.377500198s

• [SLOW TEST:33.198 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:17:11.193: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7082
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting the proxy server
Aug  9 13:17:11.404: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-400702193 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:17:11.610: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7082" for this suite.
Aug  9 13:17:17.676: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:17:19.330: INFO: namespace kubectl-7082 deletion completed in 7.703726629s

• [SLOW TEST:8.137 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:17:19.330: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-195
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Aug  9 13:17:19.726: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug  9 13:17:19.821: INFO: Waiting for terminating namespaces to be deleted...
Aug  9 13:17:19.832: INFO: 
Logging pods the kubelet thinks is on node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d before test
Aug  9 13:17:19.855: INFO: sonobuoy from heptio-sonobuoy started at 2019-08-09 13:01:20 +0000 UTC (1 container statuses recorded)
Aug  9 13:17:19.855: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug  9 13:17:19.855: INFO: ingress-traefik-xvq78 from kube-system started at 2019-08-09 13:00:46 +0000 UTC (1 container statuses recorded)
Aug  9 13:17:19.855: INFO: 	Container ingress-traefik ready: true, restart count 0
Aug  9 13:17:19.855: INFO: kube-proxy-wjvhf from kube-system started at 2019-08-09 13:00:06 +0000 UTC (1 container statuses recorded)
Aug  9 13:17:19.855: INFO: 	Container kube-proxy ready: true, restart count 0
Aug  9 13:17:19.855: INFO: node-problem-detector-gqzjc from kube-system started at 2019-08-09 13:00:46 +0000 UTC (1 container statuses recorded)
Aug  9 13:17:19.855: INFO: 	Container node-problem-detector ready: true, restart count 0
Aug  9 13:17:19.855: INFO: csi-node-s6ph9 from kube-system started at 2019-08-09 13:00:46 +0000 UTC (2 container statuses recorded)
Aug  9 13:17:19.855: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Aug  9 13:17:19.855: INFO: 	Container csi-plugin ready: true, restart count 0
Aug  9 13:17:19.855: INFO: sonobuoy-systemd-logs-daemon-set-c59f53251cea452d-gww4w from heptio-sonobuoy started at 2019-08-09 13:01:29 +0000 UTC (2 container statuses recorded)
Aug  9 13:17:19.855: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug  9 13:17:19.855: INFO: 	Container systemd-logs ready: true, restart count 0
Aug  9 13:17:19.855: INFO: flannel-qwjfp from kube-system started at 2019-08-09 13:00:06 +0000 UTC (1 container statuses recorded)
Aug  9 13:17:19.855: INFO: 	Container kube-flannel ready: true, restart count 0
Aug  9 13:17:19.855: INFO: 
Logging pods the kubelet thinks is on node scw-flan15-default-f07a9b7e282146a6b5427e9aba2 before test
Aug  9 13:17:19.882: INFO: csi-node-89m4p from kube-system started at 2019-08-09 12:59:36 +0000 UTC (2 container statuses recorded)
Aug  9 13:17:19.882: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Aug  9 13:17:19.882: INFO: 	Container csi-plugin ready: true, restart count 0
Aug  9 13:17:19.882: INFO: node-problem-detector-wkzb6 from kube-system started at 2019-08-09 12:59:36 +0000 UTC (1 container statuses recorded)
Aug  9 13:17:19.882: INFO: 	Container node-problem-detector ready: true, restart count 0
Aug  9 13:17:19.882: INFO: ingress-traefik-tld7q from kube-system started at 2019-08-09 12:59:36 +0000 UTC (1 container statuses recorded)
Aug  9 13:17:19.882: INFO: 	Container ingress-traefik ready: true, restart count 0
Aug  9 13:17:19.882: INFO: flannel-thwpk from kube-system started at 2019-08-09 12:58:54 +0000 UTC (1 container statuses recorded)
Aug  9 13:17:19.882: INFO: 	Container kube-flannel ready: true, restart count 0
Aug  9 13:17:19.882: INFO: dashboard-metrics-scraper-57454df758-67n9f from kubernetes-dashboard started at 2019-08-09 12:59:35 +0000 UTC (1 container statuses recorded)
Aug  9 13:17:19.882: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Aug  9 13:17:19.882: INFO: kubernetes-dashboard-7dfbf7f9d6-rkhpn from kubernetes-dashboard started at 2019-08-09 12:59:36 +0000 UTC (1 container statuses recorded)
Aug  9 13:17:19.882: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Aug  9 13:17:19.882: INFO: sonobuoy-systemd-logs-daemon-set-c59f53251cea452d-62jrb from heptio-sonobuoy started at 2019-08-09 13:01:29 +0000 UTC (2 container statuses recorded)
Aug  9 13:17:19.882: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug  9 13:17:19.882: INFO: 	Container systemd-logs ready: true, restart count 0
Aug  9 13:17:19.882: INFO: kube-proxy-kv7tc from kube-system started at 2019-08-09 12:58:54 +0000 UTC (1 container statuses recorded)
Aug  9 13:17:19.882: INFO: 	Container kube-proxy ready: true, restart count 0
Aug  9 13:17:19.882: INFO: metrics-server-5dc57bbc74-qzlbl from kube-system started at 2019-08-09 12:59:35 +0000 UTC (1 container statuses recorded)
Aug  9 13:17:19.882: INFO: 	Container metrics-server ready: true, restart count 0
Aug  9 13:17:19.882: INFO: coredns-6f74b4c5f8-5ztrx from kube-system started at 2019-08-09 12:59:37 +0000 UTC (1 container statuses recorded)
Aug  9 13:17:19.882: INFO: 	Container coredns ready: true, restart count 0
Aug  9 13:17:19.882: INFO: 
Logging pods the kubelet thinks is on node scw-flan15-default-fbc750a75c7f4c499b691cc5ccd before test
Aug  9 13:17:19.920: INFO: sonobuoy-e2e-job-3cf2f524dc5540ab from heptio-sonobuoy started at 2019-08-09 13:01:29 +0000 UTC (2 container statuses recorded)
Aug  9 13:17:19.920: INFO: 	Container e2e ready: true, restart count 0
Aug  9 13:17:19.920: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug  9 13:17:19.920: INFO: sonobuoy-systemd-logs-daemon-set-c59f53251cea452d-9gl4b from heptio-sonobuoy started at 2019-08-09 13:01:29 +0000 UTC (2 container statuses recorded)
Aug  9 13:17:19.920: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug  9 13:17:19.920: INFO: 	Container systemd-logs ready: true, restart count 0
Aug  9 13:17:19.920: INFO: kube-proxy-s8p7n from kube-system started at 2019-08-09 13:00:08 +0000 UTC (1 container statuses recorded)
Aug  9 13:17:19.920: INFO: 	Container kube-proxy ready: true, restart count 0
Aug  9 13:17:19.920: INFO: flannel-v4kkt from kube-system started at 2019-08-09 13:00:08 +0000 UTC (1 container statuses recorded)
Aug  9 13:17:19.920: INFO: 	Container kube-flannel ready: true, restart count 0
Aug  9 13:17:19.920: INFO: node-problem-detector-4tg4w from kube-system started at 2019-08-09 13:00:58 +0000 UTC (1 container statuses recorded)
Aug  9 13:17:19.920: INFO: 	Container node-problem-detector ready: true, restart count 0
Aug  9 13:17:19.920: INFO: ingress-traefik-5rxqq from kube-system started at 2019-08-09 13:00:58 +0000 UTC (1 container statuses recorded)
Aug  9 13:17:19.920: INFO: 	Container ingress-traefik ready: true, restart count 0
Aug  9 13:17:19.920: INFO: csi-node-hn5ml from kube-system started at 2019-08-09 13:00:58 +0000 UTC (2 container statuses recorded)
Aug  9 13:17:19.920: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Aug  9 13:17:19.920: INFO: 	Container csi-plugin ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15b9439214f1839b], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:17:21.017: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-195" for this suite.
Aug  9 13:17:27.533: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:17:27.886: INFO: namespace sched-pred-195 deletion completed in 6.426003382s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:8.556 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:17:27.887: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-255
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Aug  9 13:17:32.706: INFO: Successfully updated pod "annotationupdate1c4e6ef1-b744-471e-a288-e59d3e34c77d"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:17:34.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-255" for this suite.
Aug  9 13:17:58.816: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:17:59.141: INFO: namespace projected-255 deletion completed in 24.362570665s

• [SLOW TEST:31.255 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:17:59.142: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4207
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-map-cd1ed641-07c0-4a32-83b1-15b6b07f1531
STEP: Creating a pod to test consume secrets
Aug  9 13:17:59.408: INFO: Waiting up to 5m0s for pod "pod-secrets-66f25f95-18b5-4272-a2d3-6f638a8e668a" in namespace "secrets-4207" to be "success or failure"
Aug  9 13:17:59.419: INFO: Pod "pod-secrets-66f25f95-18b5-4272-a2d3-6f638a8e668a": Phase="Pending", Reason="", readiness=false. Elapsed: 11.015562ms
Aug  9 13:18:01.438: INFO: Pod "pod-secrets-66f25f95-18b5-4272-a2d3-6f638a8e668a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029217838s
Aug  9 13:18:03.448: INFO: Pod "pod-secrets-66f25f95-18b5-4272-a2d3-6f638a8e668a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040180306s
STEP: Saw pod success
Aug  9 13:18:03.449: INFO: Pod "pod-secrets-66f25f95-18b5-4272-a2d3-6f638a8e668a" satisfied condition "success or failure"
Aug  9 13:18:03.458: INFO: Trying to get logs from node scw-flan15-default-fbc750a75c7f4c499b691cc5ccd pod pod-secrets-66f25f95-18b5-4272-a2d3-6f638a8e668a container secret-volume-test: <nil>
STEP: delete the pod
Aug  9 13:18:03.917: INFO: Waiting for pod pod-secrets-66f25f95-18b5-4272-a2d3-6f638a8e668a to disappear
Aug  9 13:18:03.926: INFO: Pod pod-secrets-66f25f95-18b5-4272-a2d3-6f638a8e668a no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:18:03.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4207" for this suite.
Aug  9 13:18:09.995: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:18:10.332: INFO: namespace secrets-4207 deletion completed in 6.383072809s

• [SLOW TEST:11.191 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:18:10.332: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-102
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-102
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a new StatefulSet
Aug  9 13:18:10.585: INFO: Found 0 stateful pods, waiting for 3
Aug  9 13:18:20.606: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug  9 13:18:20.606: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug  9 13:18:20.606: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Aug  9 13:18:20.669: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Aug  9 13:18:30.751: INFO: Updating stateful set ss2
Aug  9 13:18:30.772: INFO: Waiting for Pod statefulset-102/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Restoring Pods to the correct revision when they are deleted
Aug  9 13:18:40.891: INFO: Found 1 stateful pods, waiting for 3
Aug  9 13:18:50.904: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug  9 13:18:50.904: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug  9 13:18:50.904: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Aug  9 13:18:50.957: INFO: Updating stateful set ss2
Aug  9 13:18:50.982: INFO: Waiting for Pod statefulset-102/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Aug  9 13:19:01.044: INFO: Updating stateful set ss2
Aug  9 13:19:01.067: INFO: Waiting for StatefulSet statefulset-102/ss2 to complete update
Aug  9 13:19:01.067: INFO: Waiting for Pod statefulset-102/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Aug  9 13:19:11.089: INFO: Waiting for StatefulSet statefulset-102/ss2 to complete update
Aug  9 13:19:11.089: INFO: Waiting for Pod statefulset-102/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Aug  9 13:19:21.086: INFO: Deleting all statefulset in ns statefulset-102
Aug  9 13:19:21.095: INFO: Scaling statefulset ss2 to 0
Aug  9 13:19:51.138: INFO: Waiting for statefulset status.replicas updated to 0
Aug  9 13:19:51.203: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:19:51.244: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-102" for this suite.
Aug  9 13:19:59.310: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:19:59.628: INFO: namespace statefulset-102 deletion completed in 8.366877536s

• [SLOW TEST:109.296 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:19:59.629: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-8993
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Aug  9 13:19:59.865: INFO: Pod name pod-release: Found 0 pods out of 1
Aug  9 13:20:04.876: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:20:05.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-8993" for this suite.
Aug  9 13:20:11.974: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:20:12.327: INFO: namespace replication-controller-8993 deletion completed in 6.388000475s

• [SLOW TEST:12.698 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:20:12.328: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4265
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap configmap-4265/configmap-test-fdbd2643-0707-4ef5-8624-851d15354f53
STEP: Creating a pod to test consume configMaps
Aug  9 13:20:12.593: INFO: Waiting up to 5m0s for pod "pod-configmaps-e3ee50f0-2cf1-4f4f-80f9-6974be6ba7ee" in namespace "configmap-4265" to be "success or failure"
Aug  9 13:20:12.609: INFO: Pod "pod-configmaps-e3ee50f0-2cf1-4f4f-80f9-6974be6ba7ee": Phase="Pending", Reason="", readiness=false. Elapsed: 15.985486ms
Aug  9 13:20:14.620: INFO: Pod "pod-configmaps-e3ee50f0-2cf1-4f4f-80f9-6974be6ba7ee": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026079145s
Aug  9 13:20:16.631: INFO: Pod "pod-configmaps-e3ee50f0-2cf1-4f4f-80f9-6974be6ba7ee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037794483s
STEP: Saw pod success
Aug  9 13:20:16.631: INFO: Pod "pod-configmaps-e3ee50f0-2cf1-4f4f-80f9-6974be6ba7ee" satisfied condition "success or failure"
Aug  9 13:20:16.640: INFO: Trying to get logs from node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d pod pod-configmaps-e3ee50f0-2cf1-4f4f-80f9-6974be6ba7ee container env-test: <nil>
STEP: delete the pod
Aug  9 13:20:16.694: INFO: Waiting for pod pod-configmaps-e3ee50f0-2cf1-4f4f-80f9-6974be6ba7ee to disappear
Aug  9 13:20:16.702: INFO: Pod pod-configmaps-e3ee50f0-2cf1-4f4f-80f9-6974be6ba7ee no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:20:16.702: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4265" for this suite.
Aug  9 13:20:22.759: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:20:23.115: INFO: namespace configmap-4265 deletion completed in 6.398736759s

• [SLOW TEST:10.787 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:20:23.115: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in prestop-6413
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating server pod server in namespace prestop-6413
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-6413
STEP: Deleting pre-stop pod
Aug  9 13:20:38.559: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:20:38.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-6413" for this suite.
Aug  9 13:21:24.729: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:21:25.081: INFO: namespace prestop-6413 deletion completed in 46.402808905s

• [SLOW TEST:61.966 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:21:25.082: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-2337
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod liveness-ab36b65b-efa1-467a-992e-86da01bf08c7 in namespace container-probe-2337
Aug  9 13:21:31.363: INFO: Started pod liveness-ab36b65b-efa1-467a-992e-86da01bf08c7 in namespace container-probe-2337
STEP: checking the pod's current state and verifying that restartCount is present
Aug  9 13:21:31.373: INFO: Initial restart count of pod liveness-ab36b65b-efa1-467a-992e-86da01bf08c7 is 0
Aug  9 13:21:55.540: INFO: Restart count of pod container-probe-2337/liveness-ab36b65b-efa1-467a-992e-86da01bf08c7 is now 1 (24.167152888s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:21:55.589: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2337" for this suite.
Aug  9 13:22:08.023: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:22:08.383: INFO: namespace container-probe-2337 deletion completed in 12.435679582s

• [SLOW TEST:43.301 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:22:08.394: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-6478
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug  9 13:22:08.604: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Aug  9 13:22:08.626: INFO: Pod name sample-pod: Found 0 pods out of 1
Aug  9 13:22:13.637: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Aug  9 13:22:13.637: INFO: Creating deployment "test-rolling-update-deployment"
Aug  9 13:22:13.653: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Aug  9 13:22:13.679: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Aug  9 13:22:15.703: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Aug  9 13:22:15.710: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700953733, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700953733, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700953734, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700953733, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-79f6b9d75c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug  9 13:22:17.721: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700953733, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700953733, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700953734, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700953733, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-79f6b9d75c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug  9 13:22:19.720: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700953733, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700953733, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700953734, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700953733, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-79f6b9d75c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug  9 13:22:21.720: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700953733, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700953733, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700953734, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700953733, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-79f6b9d75c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug  9 13:22:23.746: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700953733, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700953733, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700953734, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700953733, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-79f6b9d75c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug  9 13:22:25.721: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Aug  9 13:22:25.770: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-6478,SelfLink:/apis/apps/v1/namespaces/deployment-6478/deployments/test-rolling-update-deployment,UID:bd4d1057-9d81-4565-9376-afc31584b0cf,ResourceVersion:124629990,Generation:1,CreationTimestamp:2019-08-09 13:22:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-08-09 13:22:13 +0000 UTC 2019-08-09 13:22:13 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-08-09 13:22:24 +0000 UTC 2019-08-09 13:22:13 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-79f6b9d75c" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Aug  9 13:22:25.782: INFO: New ReplicaSet "test-rolling-update-deployment-79f6b9d75c" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79f6b9d75c,GenerateName:,Namespace:deployment-6478,SelfLink:/apis/apps/v1/namespaces/deployment-6478/replicasets/test-rolling-update-deployment-79f6b9d75c,UID:3bf62241-d3e1-434d-bdbc-a4677d432eb1,ResourceVersion:124629978,Generation:1,CreationTimestamp:2019-08-09 13:22:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment bd4d1057-9d81-4565-9376-afc31584b0cf 0xc0020e2fe7 0xc0020e2fe8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Aug  9 13:22:25.782: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Aug  9 13:22:25.782: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-6478,SelfLink:/apis/apps/v1/namespaces/deployment-6478/replicasets/test-rolling-update-controller,UID:7784f09d-7734-41c3-ae8f-238bb6fd0be9,ResourceVersion:124629989,Generation:2,CreationTimestamp:2019-08-09 13:22:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment bd4d1057-9d81-4565-9376-afc31584b0cf 0xc0020e2f17 0xc0020e2f18}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug  9 13:22:25.796: INFO: Pod "test-rolling-update-deployment-79f6b9d75c-67bfc" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79f6b9d75c-67bfc,GenerateName:test-rolling-update-deployment-79f6b9d75c-,Namespace:deployment-6478,SelfLink:/api/v1/namespaces/deployment-6478/pods/test-rolling-update-deployment-79f6b9d75c-67bfc,UID:2a02afa7-7f29-4837-a572-01d774da03ab,ResourceVersion:124629977,Generation:0,CreationTimestamp:2019-08-09 13:22:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-79f6b9d75c 3bf62241-d3e1-434d-bdbc-a4677d432eb1 0xc0021fa407 0xc0021fa408}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-xfsgn {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-xfsgn,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-xfsgn true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-flan15-default-f07a9b7e282146a6b5427e9aba2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0021fa470} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0021fa490}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 13:22:15 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 13:22:23 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 13:22:23 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 13:22:14 +0000 UTC  }],Message:,Reason:,HostIP:10.12.155.153,PodIP:100.64.0.27,StartTime:2019-08-09 13:22:15 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-08-09 13:22:23 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://6273d1328f2f595eb4850fd10157210c73b3df21f952a2a96140e84a83b37d0f}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:22:25.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6478" for this suite.
Aug  9 13:22:31.863: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:22:32.206: INFO: namespace deployment-6478 deletion completed in 6.384707995s

• [SLOW TEST:23.812 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:22:32.211: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5172
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1686
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug  9 13:22:32.435: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-5172'
Aug  9 13:22:33.297: INFO: stderr: ""
Aug  9 13:22:33.297: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1691
Aug  9 13:22:33.366: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 delete pods e2e-test-nginx-pod --namespace=kubectl-5172'
Aug  9 13:22:35.977: INFO: stderr: ""
Aug  9 13:22:35.977: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:22:35.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5172" for this suite.
Aug  9 13:22:42.062: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:22:42.421: INFO: namespace kubectl-5172 deletion completed in 6.413083906s

• [SLOW TEST:10.211 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:22:42.422: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4641
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug  9 13:22:42.711: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fbc4d20f-856e-4f05-aeb3-3ba509fe506f" in namespace "projected-4641" to be "success or failure"
Aug  9 13:22:42.723: INFO: Pod "downwardapi-volume-fbc4d20f-856e-4f05-aeb3-3ba509fe506f": Phase="Pending", Reason="", readiness=false. Elapsed: 12.285342ms
Aug  9 13:22:44.735: INFO: Pod "downwardapi-volume-fbc4d20f-856e-4f05-aeb3-3ba509fe506f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024387577s
Aug  9 13:22:46.748: INFO: Pod "downwardapi-volume-fbc4d20f-856e-4f05-aeb3-3ba509fe506f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036891499s
STEP: Saw pod success
Aug  9 13:22:46.748: INFO: Pod "downwardapi-volume-fbc4d20f-856e-4f05-aeb3-3ba509fe506f" satisfied condition "success or failure"
Aug  9 13:22:46.758: INFO: Trying to get logs from node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d pod downwardapi-volume-fbc4d20f-856e-4f05-aeb3-3ba509fe506f container client-container: <nil>
STEP: delete the pod
Aug  9 13:22:46.830: INFO: Waiting for pod downwardapi-volume-fbc4d20f-856e-4f05-aeb3-3ba509fe506f to disappear
Aug  9 13:22:46.844: INFO: Pod downwardapi-volume-fbc4d20f-856e-4f05-aeb3-3ba509fe506f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:22:46.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4641" for this suite.
Aug  9 13:22:52.937: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:22:53.315: INFO: namespace projected-4641 deletion completed in 6.418664236s

• [SLOW TEST:10.894 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:22:53.315: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7073
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name secret-emptykey-test-bd1a743a-7d53-45c4-be87-96c4cb04373d
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:22:53.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7073" for this suite.
Aug  9 13:23:01.592: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:23:01.960: INFO: namespace secrets-7073 deletion completed in 8.412770106s

• [SLOW TEST:8.645 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:23:01.961: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2820
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-b3e5b2ea-11cd-4466-8241-05d7763f8b5d
STEP: Creating a pod to test consume configMaps
Aug  9 13:23:02.233: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4532caf6-0985-4d6d-87e6-d03b97f23704" in namespace "projected-2820" to be "success or failure"
Aug  9 13:23:02.251: INFO: Pod "pod-projected-configmaps-4532caf6-0985-4d6d-87e6-d03b97f23704": Phase="Pending", Reason="", readiness=false. Elapsed: 17.238844ms
Aug  9 13:23:04.261: INFO: Pod "pod-projected-configmaps-4532caf6-0985-4d6d-87e6-d03b97f23704": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.028076177s
STEP: Saw pod success
Aug  9 13:23:04.261: INFO: Pod "pod-projected-configmaps-4532caf6-0985-4d6d-87e6-d03b97f23704" satisfied condition "success or failure"
Aug  9 13:23:04.272: INFO: Trying to get logs from node scw-flan15-default-f07a9b7e282146a6b5427e9aba2 pod pod-projected-configmaps-4532caf6-0985-4d6d-87e6-d03b97f23704 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug  9 13:23:05.321: INFO: Waiting for pod pod-projected-configmaps-4532caf6-0985-4d6d-87e6-d03b97f23704 to disappear
Aug  9 13:23:05.330: INFO: Pod pod-projected-configmaps-4532caf6-0985-4d6d-87e6-d03b97f23704 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:23:05.330: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2820" for this suite.
Aug  9 13:23:21.126: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:23:23.162: INFO: namespace projected-2820 deletion completed in 16.073517217s

• [SLOW TEST:21.201 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:23:23.162: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3663
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug  9 13:23:24.492: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1a7fe6e2-6d19-4969-a25b-13fcb6959d03" in namespace "projected-3663" to be "success or failure"
Aug  9 13:23:24.502: INFO: Pod "downwardapi-volume-1a7fe6e2-6d19-4969-a25b-13fcb6959d03": Phase="Pending", Reason="", readiness=false. Elapsed: 10.31777ms
Aug  9 13:23:26.514: INFO: Pod "downwardapi-volume-1a7fe6e2-6d19-4969-a25b-13fcb6959d03": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021959664s
Aug  9 13:23:28.525: INFO: Pod "downwardapi-volume-1a7fe6e2-6d19-4969-a25b-13fcb6959d03": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033237614s
STEP: Saw pod success
Aug  9 13:23:28.525: INFO: Pod "downwardapi-volume-1a7fe6e2-6d19-4969-a25b-13fcb6959d03" satisfied condition "success or failure"
Aug  9 13:23:28.537: INFO: Trying to get logs from node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d pod downwardapi-volume-1a7fe6e2-6d19-4969-a25b-13fcb6959d03 container client-container: <nil>
STEP: delete the pod
Aug  9 13:23:28.728: INFO: Waiting for pod downwardapi-volume-1a7fe6e2-6d19-4969-a25b-13fcb6959d03 to disappear
Aug  9 13:23:28.739: INFO: Pod downwardapi-volume-1a7fe6e2-6d19-4969-a25b-13fcb6959d03 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:23:28.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3663" for this suite.
Aug  9 13:23:35.488: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:23:35.820: INFO: namespace projected-3663 deletion completed in 6.370691325s

• [SLOW TEST:12.658 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:23:35.820: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in events-7795
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Aug  9 13:23:40.094: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-23e42680-4b5d-4ef2-8c1c-739a1aee6ecc,GenerateName:,Namespace:events-7795,SelfLink:/api/v1/namespaces/events-7795/pods/send-events-23e42680-4b5d-4ef2-8c1c-739a1aee6ecc,UID:c6b347ec-8bad-4c79-ab0f-dc50d445bdb6,ResourceVersion:124631371,Generation:0,CreationTimestamp:2019-08-09 13:23:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 30345524,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-nx67h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-nx67h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-nx67h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-flan15-default-f07a9b7e282146a6b5427e9aba2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000c34320} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000c34340}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 13:23:36 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 13:23:39 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 13:23:39 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 13:23:36 +0000 UTC  }],Message:,Reason:,HostIP:10.12.155.153,PodIP:100.64.0.29,StartTime:2019-08-09 13:23:36 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-08-09 13:23:39 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://7a50c4dd9d8a8c4577fa7ed506d96f96a056aeb1349ce2d15566fae295ab78e0}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Aug  9 13:23:42.108: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Aug  9 13:23:44.120: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:23:44.139: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-7795" for this suite.
Aug  9 13:24:26.202: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:24:26.537: INFO: namespace events-7795 deletion completed in 42.381361125s

• [SLOW TEST:50.716 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:24:26.538: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6673
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-104bbd6a-3aff-4ff6-b9a5-4ff71735668c
STEP: Creating a pod to test consume secrets
Aug  9 13:24:26.795: INFO: Waiting up to 5m0s for pod "pod-secrets-add091c3-2647-46bb-a410-c8d5bff66657" in namespace "secrets-6673" to be "success or failure"
Aug  9 13:24:26.805: INFO: Pod "pod-secrets-add091c3-2647-46bb-a410-c8d5bff66657": Phase="Pending", Reason="", readiness=false. Elapsed: 10.277082ms
Aug  9 13:24:28.816: INFO: Pod "pod-secrets-add091c3-2647-46bb-a410-c8d5bff66657": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021596136s
Aug  9 13:24:30.831: INFO: Pod "pod-secrets-add091c3-2647-46bb-a410-c8d5bff66657": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036015142s
STEP: Saw pod success
Aug  9 13:24:30.831: INFO: Pod "pod-secrets-add091c3-2647-46bb-a410-c8d5bff66657" satisfied condition "success or failure"
Aug  9 13:24:30.840: INFO: Trying to get logs from node scw-flan15-default-f07a9b7e282146a6b5427e9aba2 pod pod-secrets-add091c3-2647-46bb-a410-c8d5bff66657 container secret-volume-test: <nil>
STEP: delete the pod
Aug  9 13:24:30.892: INFO: Waiting for pod pod-secrets-add091c3-2647-46bb-a410-c8d5bff66657 to disappear
Aug  9 13:24:30.901: INFO: Pod pod-secrets-add091c3-2647-46bb-a410-c8d5bff66657 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:24:30.901: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6673" for this suite.
Aug  9 13:24:36.959: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:24:37.314: INFO: namespace secrets-6673 deletion completed in 6.398580963s

• [SLOW TEST:10.776 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:24:37.315: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-90
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug  9 13:24:37.533: INFO: Creating ReplicaSet my-hostname-basic-410893da-6748-45b5-a5b5-831401ce5148
Aug  9 13:24:37.559: INFO: Pod name my-hostname-basic-410893da-6748-45b5-a5b5-831401ce5148: Found 0 pods out of 1
Aug  9 13:24:42.572: INFO: Pod name my-hostname-basic-410893da-6748-45b5-a5b5-831401ce5148: Found 1 pods out of 1
Aug  9 13:24:42.572: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-410893da-6748-45b5-a5b5-831401ce5148" is running
Aug  9 13:24:42.585: INFO: Pod "my-hostname-basic-410893da-6748-45b5-a5b5-831401ce5148-rlngz" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-09 13:24:37 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-09 13:24:40 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-09 13:24:40 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-09 13:24:37 +0000 UTC Reason: Message:}])
Aug  9 13:24:42.586: INFO: Trying to dial the pod
Aug  9 13:24:47.714: INFO: Controller my-hostname-basic-410893da-6748-45b5-a5b5-831401ce5148: Got expected result from replica 1 [my-hostname-basic-410893da-6748-45b5-a5b5-831401ce5148-rlngz]: "my-hostname-basic-410893da-6748-45b5-a5b5-831401ce5148-rlngz", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:24:47.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-90" for this suite.
Aug  9 13:24:53.769: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:24:54.108: INFO: namespace replicaset-90 deletion completed in 6.38140852s

• [SLOW TEST:16.793 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:24:54.109: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6695
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with configMap that has name projected-configmap-test-upd-a97688d1-cc85-40fb-9765-e7e9b6c8210e
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-a97688d1-cc85-40fb-9765-e7e9b6c8210e
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:26:17.186: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6695" for this suite.
Aug  9 13:26:46.076: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:26:47.113: INFO: namespace projected-6695 deletion completed in 29.075870223s

• [SLOW TEST:113.005 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:26:47.114: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-7868
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7868.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-7868.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7868.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-7868.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7868.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-7868.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7868.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-7868.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7868.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-7868.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7868.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-7868.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7868.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 4.239.46.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.46.239.4_udp@PTR;check="$$(dig +tcp +noall +answer +search 4.239.46.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.46.239.4_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7868.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-7868.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7868.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-7868.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7868.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-7868.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7868.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-7868.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7868.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-7868.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7868.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-7868.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7868.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 4.239.46.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.46.239.4_udp@PTR;check="$$(dig +tcp +noall +answer +search 4.239.46.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.46.239.4_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug  9 13:26:54.150: INFO: Unable to read wheezy_udp@dns-test-service.dns-7868.svc.cluster.local from pod dns-7868/dns-test-18485d07-9576-4ee6-90aa-7768b85329a0: the server could not find the requested resource (get pods dns-test-18485d07-9576-4ee6-90aa-7768b85329a0)
Aug  9 13:26:54.202: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7868.svc.cluster.local from pod dns-7868/dns-test-18485d07-9576-4ee6-90aa-7768b85329a0: the server could not find the requested resource (get pods dns-test-18485d07-9576-4ee6-90aa-7768b85329a0)
Aug  9 13:26:54.217: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7868.svc.cluster.local from pod dns-7868/dns-test-18485d07-9576-4ee6-90aa-7768b85329a0: the server could not find the requested resource (get pods dns-test-18485d07-9576-4ee6-90aa-7768b85329a0)
Aug  9 13:26:54.237: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7868.svc.cluster.local from pod dns-7868/dns-test-18485d07-9576-4ee6-90aa-7768b85329a0: the server could not find the requested resource (get pods dns-test-18485d07-9576-4ee6-90aa-7768b85329a0)
Aug  9 13:26:54.728: INFO: Unable to read jessie_udp@dns-test-service.dns-7868.svc.cluster.local from pod dns-7868/dns-test-18485d07-9576-4ee6-90aa-7768b85329a0: the server could not find the requested resource (get pods dns-test-18485d07-9576-4ee6-90aa-7768b85329a0)
Aug  9 13:26:54.746: INFO: Unable to read jessie_tcp@dns-test-service.dns-7868.svc.cluster.local from pod dns-7868/dns-test-18485d07-9576-4ee6-90aa-7768b85329a0: the server could not find the requested resource (get pods dns-test-18485d07-9576-4ee6-90aa-7768b85329a0)
Aug  9 13:26:54.774: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7868.svc.cluster.local from pod dns-7868/dns-test-18485d07-9576-4ee6-90aa-7768b85329a0: the server could not find the requested resource (get pods dns-test-18485d07-9576-4ee6-90aa-7768b85329a0)
Aug  9 13:26:54.798: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7868.svc.cluster.local from pod dns-7868/dns-test-18485d07-9576-4ee6-90aa-7768b85329a0: the server could not find the requested resource (get pods dns-test-18485d07-9576-4ee6-90aa-7768b85329a0)
Aug  9 13:26:55.188: INFO: Lookups using dns-7868/dns-test-18485d07-9576-4ee6-90aa-7768b85329a0 failed for: [wheezy_udp@dns-test-service.dns-7868.svc.cluster.local wheezy_tcp@dns-test-service.dns-7868.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-7868.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-7868.svc.cluster.local jessie_udp@dns-test-service.dns-7868.svc.cluster.local jessie_tcp@dns-test-service.dns-7868.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-7868.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-7868.svc.cluster.local]

Aug  9 13:27:01.598: INFO: DNS probes using dns-7868/dns-test-18485d07-9576-4ee6-90aa-7768b85329a0 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:27:01.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7868" for this suite.
Aug  9 13:27:07.872: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:27:08.215: INFO: namespace dns-7868 deletion completed in 6.413025926s

• [SLOW TEST:21.101 seconds]
[sig-network] DNS
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:27:08.216: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1525
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating Redis RC
Aug  9 13:27:08.435: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 create -f - --namespace=kubectl-1525'
Aug  9 13:27:09.281: INFO: stderr: ""
Aug  9 13:27:09.281: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Aug  9 13:27:10.292: INFO: Selector matched 1 pods for map[app:redis]
Aug  9 13:27:10.292: INFO: Found 0 / 1
Aug  9 13:27:11.297: INFO: Selector matched 1 pods for map[app:redis]
Aug  9 13:27:11.297: INFO: Found 0 / 1
Aug  9 13:27:12.294: INFO: Selector matched 1 pods for map[app:redis]
Aug  9 13:27:12.294: INFO: Found 0 / 1
Aug  9 13:27:13.292: INFO: Selector matched 1 pods for map[app:redis]
Aug  9 13:27:13.292: INFO: Found 0 / 1
Aug  9 13:27:14.293: INFO: Selector matched 1 pods for map[app:redis]
Aug  9 13:27:14.293: INFO: Found 1 / 1
Aug  9 13:27:14.293: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Aug  9 13:27:14.303: INFO: Selector matched 1 pods for map[app:redis]
Aug  9 13:27:14.304: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug  9 13:27:14.304: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 patch pod redis-master-rl5qf --namespace=kubectl-1525 -p {"metadata":{"annotations":{"x":"y"}}}'
Aug  9 13:27:14.599: INFO: stderr: ""
Aug  9 13:27:14.599: INFO: stdout: "pod/redis-master-rl5qf patched\n"
STEP: checking annotations
Aug  9 13:27:14.611: INFO: Selector matched 1 pods for map[app:redis]
Aug  9 13:27:14.611: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:27:14.611: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1525" for this suite.
Aug  9 13:27:40.065: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:27:42.254: INFO: namespace kubectl-1525 deletion completed in 26.239881858s

• [SLOW TEST:34.039 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl patch
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:27:42.255: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-3488
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Aug  9 13:27:42.526: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-3488,SelfLink:/api/v1/namespaces/watch-3488/configmaps/e2e-watch-test-watch-closed,UID:3ace8b84-9d1f-4e78-a75f-f9b411864e78,ResourceVersion:124636460,Generation:0,CreationTimestamp:2019-08-09 13:27:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug  9 13:27:42.527: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-3488,SelfLink:/api/v1/namespaces/watch-3488/configmaps/e2e-watch-test-watch-closed,UID:3ace8b84-9d1f-4e78-a75f-f9b411864e78,ResourceVersion:124636461,Generation:0,CreationTimestamp:2019-08-09 13:27:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Aug  9 13:27:42.581: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-3488,SelfLink:/api/v1/namespaces/watch-3488/configmaps/e2e-watch-test-watch-closed,UID:3ace8b84-9d1f-4e78-a75f-f9b411864e78,ResourceVersion:124636463,Generation:0,CreationTimestamp:2019-08-09 13:27:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug  9 13:27:42.581: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-3488,SelfLink:/api/v1/namespaces/watch-3488/configmaps/e2e-watch-test-watch-closed,UID:3ace8b84-9d1f-4e78-a75f-f9b411864e78,ResourceVersion:124636467,Generation:0,CreationTimestamp:2019-08-09 13:27:42 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:27:42.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3488" for this suite.
Aug  9 13:27:50.659: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:27:51.003: INFO: namespace watch-3488 deletion completed in 8.390291421s

• [SLOW TEST:8.749 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:27:51.006: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7131
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-1383e01e-cd17-4d62-a0f3-e89ee9360bee
STEP: Creating a pod to test consume secrets
Aug  9 13:27:51.273: INFO: Waiting up to 5m0s for pod "pod-secrets-4bfb26db-2362-4e76-b209-2476b55ec939" in namespace "secrets-7131" to be "success or failure"
Aug  9 13:27:51.284: INFO: Pod "pod-secrets-4bfb26db-2362-4e76-b209-2476b55ec939": Phase="Pending", Reason="", readiness=false. Elapsed: 10.958083ms
Aug  9 13:27:53.295: INFO: Pod "pod-secrets-4bfb26db-2362-4e76-b209-2476b55ec939": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021653137s
Aug  9 13:27:55.307: INFO: Pod "pod-secrets-4bfb26db-2362-4e76-b209-2476b55ec939": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033291526s
STEP: Saw pod success
Aug  9 13:27:55.307: INFO: Pod "pod-secrets-4bfb26db-2362-4e76-b209-2476b55ec939" satisfied condition "success or failure"
Aug  9 13:27:55.316: INFO: Trying to get logs from node scw-flan15-default-f07a9b7e282146a6b5427e9aba2 pod pod-secrets-4bfb26db-2362-4e76-b209-2476b55ec939 container secret-volume-test: <nil>
STEP: delete the pod
Aug  9 13:27:55.378: INFO: Waiting for pod pod-secrets-4bfb26db-2362-4e76-b209-2476b55ec939 to disappear
Aug  9 13:27:55.393: INFO: Pod pod-secrets-4bfb26db-2362-4e76-b209-2476b55ec939 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:27:55.394: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7131" for this suite.
Aug  9 13:28:03.455: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:28:03.848: INFO: namespace secrets-7131 deletion completed in 8.439255352s

• [SLOW TEST:12.842 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:28:03.850: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5926
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug  9 13:28:04.093: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bfdf816f-6b79-4fc9-b231-121f6783c093" in namespace "downward-api-5926" to be "success or failure"
Aug  9 13:28:04.105: INFO: Pod "downwardapi-volume-bfdf816f-6b79-4fc9-b231-121f6783c093": Phase="Pending", Reason="", readiness=false. Elapsed: 12.146481ms
Aug  9 13:28:06.117: INFO: Pod "downwardapi-volume-bfdf816f-6b79-4fc9-b231-121f6783c093": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024036524s
Aug  9 13:28:08.129: INFO: Pod "downwardapi-volume-bfdf816f-6b79-4fc9-b231-121f6783c093": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036436146s
STEP: Saw pod success
Aug  9 13:28:08.129: INFO: Pod "downwardapi-volume-bfdf816f-6b79-4fc9-b231-121f6783c093" satisfied condition "success or failure"
Aug  9 13:28:08.141: INFO: Trying to get logs from node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d pod downwardapi-volume-bfdf816f-6b79-4fc9-b231-121f6783c093 container client-container: <nil>
STEP: delete the pod
Aug  9 13:28:08.209: INFO: Waiting for pod downwardapi-volume-bfdf816f-6b79-4fc9-b231-121f6783c093 to disappear
Aug  9 13:28:08.217: INFO: Pod downwardapi-volume-bfdf816f-6b79-4fc9-b231-121f6783c093 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:28:08.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5926" for this suite.
Aug  9 13:28:14.268: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:28:14.619: INFO: namespace downward-api-5926 deletion completed in 6.388541462s

• [SLOW TEST:10.770 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:28:14.625: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7864
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Aug  9 13:28:14.885: INFO: Waiting up to 5m0s for pod "downward-api-3967f42a-b581-46b9-b146-eaa56d41db5b" in namespace "downward-api-7864" to be "success or failure"
Aug  9 13:28:14.896: INFO: Pod "downward-api-3967f42a-b581-46b9-b146-eaa56d41db5b": Phase="Pending", Reason="", readiness=false. Elapsed: 10.617794ms
Aug  9 13:28:16.906: INFO: Pod "downward-api-3967f42a-b581-46b9-b146-eaa56d41db5b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020760562s
Aug  9 13:28:18.918: INFO: Pod "downward-api-3967f42a-b581-46b9-b146-eaa56d41db5b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031977798s
STEP: Saw pod success
Aug  9 13:28:18.918: INFO: Pod "downward-api-3967f42a-b581-46b9-b146-eaa56d41db5b" satisfied condition "success or failure"
Aug  9 13:28:18.932: INFO: Trying to get logs from node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d pod downward-api-3967f42a-b581-46b9-b146-eaa56d41db5b container dapi-container: <nil>
STEP: delete the pod
Aug  9 13:28:19.001: INFO: Waiting for pod downward-api-3967f42a-b581-46b9-b146-eaa56d41db5b to disappear
Aug  9 13:28:19.011: INFO: Pod downward-api-3967f42a-b581-46b9-b146-eaa56d41db5b no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:28:19.011: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7864" for this suite.
Aug  9 13:28:26.189: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:28:26.560: INFO: namespace downward-api-7864 deletion completed in 6.411623412s

• [SLOW TEST:11.937 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:28:26.562: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1703
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap configmap-1703/configmap-test-891eee5b-ebce-476a-8c8a-1ea2f7df5fee
STEP: Creating a pod to test consume configMaps
Aug  9 13:28:26.824: INFO: Waiting up to 5m0s for pod "pod-configmaps-95a7e897-5fa4-46ce-97ca-c308c7634100" in namespace "configmap-1703" to be "success or failure"
Aug  9 13:28:26.838: INFO: Pod "pod-configmaps-95a7e897-5fa4-46ce-97ca-c308c7634100": Phase="Pending", Reason="", readiness=false. Elapsed: 14.421892ms
Aug  9 13:28:28.848: INFO: Pod "pod-configmaps-95a7e897-5fa4-46ce-97ca-c308c7634100": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02399742s
Aug  9 13:28:30.858: INFO: Pod "pod-configmaps-95a7e897-5fa4-46ce-97ca-c308c7634100": Phase="Pending", Reason="", readiness=false. Elapsed: 4.034040846s
Aug  9 13:28:32.867: INFO: Pod "pod-configmaps-95a7e897-5fa4-46ce-97ca-c308c7634100": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.043395989s
STEP: Saw pod success
Aug  9 13:28:32.867: INFO: Pod "pod-configmaps-95a7e897-5fa4-46ce-97ca-c308c7634100" satisfied condition "success or failure"
Aug  9 13:28:32.877: INFO: Trying to get logs from node scw-flan15-default-fbc750a75c7f4c499b691cc5ccd pod pod-configmaps-95a7e897-5fa4-46ce-97ca-c308c7634100 container env-test: <nil>
STEP: delete the pod
Aug  9 13:28:32.938: INFO: Waiting for pod pod-configmaps-95a7e897-5fa4-46ce-97ca-c308c7634100 to disappear
Aug  9 13:28:32.949: INFO: Pod pod-configmaps-95a7e897-5fa4-46ce-97ca-c308c7634100 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:28:32.949: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1703" for this suite.
Aug  9 13:28:39.001: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:28:39.353: INFO: namespace configmap-1703 deletion completed in 6.392147047s

• [SLOW TEST:12.790 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:28:39.354: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-6286
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Aug  9 13:28:39.565: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug  9 13:28:39.594: INFO: Waiting for terminating namespaces to be deleted...
Aug  9 13:28:39.604: INFO: 
Logging pods the kubelet thinks is on node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d before test
Aug  9 13:28:39.624: INFO: kube-proxy-wjvhf from kube-system started at 2019-08-09 13:00:06 +0000 UTC (1 container statuses recorded)
Aug  9 13:28:39.624: INFO: 	Container kube-proxy ready: true, restart count 0
Aug  9 13:28:39.624: INFO: node-problem-detector-gqzjc from kube-system started at 2019-08-09 13:00:46 +0000 UTC (1 container statuses recorded)
Aug  9 13:28:39.624: INFO: 	Container node-problem-detector ready: true, restart count 0
Aug  9 13:28:39.624: INFO: csi-node-s6ph9 from kube-system started at 2019-08-09 13:00:46 +0000 UTC (2 container statuses recorded)
Aug  9 13:28:39.624: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Aug  9 13:28:39.624: INFO: 	Container csi-plugin ready: true, restart count 0
Aug  9 13:28:39.624: INFO: sonobuoy-systemd-logs-daemon-set-c59f53251cea452d-gww4w from heptio-sonobuoy started at 2019-08-09 13:01:29 +0000 UTC (2 container statuses recorded)
Aug  9 13:28:39.624: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug  9 13:28:39.624: INFO: 	Container systemd-logs ready: true, restart count 0
Aug  9 13:28:39.624: INFO: flannel-qwjfp from kube-system started at 2019-08-09 13:00:06 +0000 UTC (1 container statuses recorded)
Aug  9 13:28:39.624: INFO: 	Container kube-flannel ready: true, restart count 0
Aug  9 13:28:39.624: INFO: sonobuoy from heptio-sonobuoy started at 2019-08-09 13:01:20 +0000 UTC (1 container statuses recorded)
Aug  9 13:28:39.624: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug  9 13:28:39.624: INFO: ingress-traefik-xvq78 from kube-system started at 2019-08-09 13:00:46 +0000 UTC (1 container statuses recorded)
Aug  9 13:28:39.624: INFO: 	Container ingress-traefik ready: true, restart count 0
Aug  9 13:28:39.624: INFO: 
Logging pods the kubelet thinks is on node scw-flan15-default-f07a9b7e282146a6b5427e9aba2 before test
Aug  9 13:28:39.648: INFO: kube-proxy-kv7tc from kube-system started at 2019-08-09 12:58:54 +0000 UTC (1 container statuses recorded)
Aug  9 13:28:39.648: INFO: 	Container kube-proxy ready: true, restart count 0
Aug  9 13:28:39.648: INFO: metrics-server-5dc57bbc74-qzlbl from kube-system started at 2019-08-09 12:59:35 +0000 UTC (1 container statuses recorded)
Aug  9 13:28:39.648: INFO: 	Container metrics-server ready: true, restart count 0
Aug  9 13:28:39.648: INFO: coredns-6f74b4c5f8-5ztrx from kube-system started at 2019-08-09 12:59:37 +0000 UTC (1 container statuses recorded)
Aug  9 13:28:39.648: INFO: 	Container coredns ready: true, restart count 0
Aug  9 13:28:39.648: INFO: sonobuoy-systemd-logs-daemon-set-c59f53251cea452d-62jrb from heptio-sonobuoy started at 2019-08-09 13:01:29 +0000 UTC (2 container statuses recorded)
Aug  9 13:28:39.648: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug  9 13:28:39.648: INFO: 	Container systemd-logs ready: true, restart count 0
Aug  9 13:28:39.648: INFO: flannel-thwpk from kube-system started at 2019-08-09 12:58:54 +0000 UTC (1 container statuses recorded)
Aug  9 13:28:39.648: INFO: 	Container kube-flannel ready: true, restart count 0
Aug  9 13:28:39.648: INFO: dashboard-metrics-scraper-57454df758-67n9f from kubernetes-dashboard started at 2019-08-09 12:59:35 +0000 UTC (1 container statuses recorded)
Aug  9 13:28:39.648: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Aug  9 13:28:39.648: INFO: kubernetes-dashboard-7dfbf7f9d6-rkhpn from kubernetes-dashboard started at 2019-08-09 12:59:36 +0000 UTC (1 container statuses recorded)
Aug  9 13:28:39.648: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Aug  9 13:28:39.648: INFO: csi-node-89m4p from kube-system started at 2019-08-09 12:59:36 +0000 UTC (2 container statuses recorded)
Aug  9 13:28:39.648: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Aug  9 13:28:39.648: INFO: 	Container csi-plugin ready: true, restart count 0
Aug  9 13:28:39.648: INFO: node-problem-detector-wkzb6 from kube-system started at 2019-08-09 12:59:36 +0000 UTC (1 container statuses recorded)
Aug  9 13:28:39.648: INFO: 	Container node-problem-detector ready: true, restart count 0
Aug  9 13:28:39.648: INFO: ingress-traefik-tld7q from kube-system started at 2019-08-09 12:59:36 +0000 UTC (1 container statuses recorded)
Aug  9 13:28:39.648: INFO: 	Container ingress-traefik ready: true, restart count 0
Aug  9 13:28:39.648: INFO: 
Logging pods the kubelet thinks is on node scw-flan15-default-fbc750a75c7f4c499b691cc5ccd before test
Aug  9 13:28:39.666: INFO: ingress-traefik-5rxqq from kube-system started at 2019-08-09 13:00:58 +0000 UTC (1 container statuses recorded)
Aug  9 13:28:39.666: INFO: 	Container ingress-traefik ready: true, restart count 0
Aug  9 13:28:39.666: INFO: csi-node-hn5ml from kube-system started at 2019-08-09 13:00:58 +0000 UTC (2 container statuses recorded)
Aug  9 13:28:39.666: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Aug  9 13:28:39.666: INFO: 	Container csi-plugin ready: true, restart count 0
Aug  9 13:28:39.666: INFO: sonobuoy-e2e-job-3cf2f524dc5540ab from heptio-sonobuoy started at 2019-08-09 13:01:29 +0000 UTC (2 container statuses recorded)
Aug  9 13:28:39.666: INFO: 	Container e2e ready: true, restart count 0
Aug  9 13:28:39.666: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug  9 13:28:39.666: INFO: sonobuoy-systemd-logs-daemon-set-c59f53251cea452d-9gl4b from heptio-sonobuoy started at 2019-08-09 13:01:29 +0000 UTC (2 container statuses recorded)
Aug  9 13:28:39.666: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug  9 13:28:39.666: INFO: 	Container systemd-logs ready: true, restart count 0
Aug  9 13:28:39.666: INFO: kube-proxy-s8p7n from kube-system started at 2019-08-09 13:00:08 +0000 UTC (1 container statuses recorded)
Aug  9 13:28:39.667: INFO: 	Container kube-proxy ready: true, restart count 0
Aug  9 13:28:39.667: INFO: flannel-v4kkt from kube-system started at 2019-08-09 13:00:08 +0000 UTC (1 container statuses recorded)
Aug  9 13:28:39.667: INFO: 	Container kube-flannel ready: true, restart count 0
Aug  9 13:28:39.667: INFO: node-problem-detector-4tg4w from kube-system started at 2019-08-09 13:00:58 +0000 UTC (1 container statuses recorded)
Aug  9 13:28:39.667: INFO: 	Container node-problem-detector ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: verifying the node has the label node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d
STEP: verifying the node has the label node scw-flan15-default-f07a9b7e282146a6b5427e9aba2
STEP: verifying the node has the label node scw-flan15-default-fbc750a75c7f4c499b691cc5ccd
Aug  9 13:28:39.846: INFO: Pod sonobuoy requesting resource cpu=0m on Node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d
Aug  9 13:28:39.846: INFO: Pod sonobuoy-e2e-job-3cf2f524dc5540ab requesting resource cpu=0m on Node scw-flan15-default-fbc750a75c7f4c499b691cc5ccd
Aug  9 13:28:39.846: INFO: Pod sonobuoy-systemd-logs-daemon-set-c59f53251cea452d-62jrb requesting resource cpu=0m on Node scw-flan15-default-f07a9b7e282146a6b5427e9aba2
Aug  9 13:28:39.846: INFO: Pod sonobuoy-systemd-logs-daemon-set-c59f53251cea452d-9gl4b requesting resource cpu=0m on Node scw-flan15-default-fbc750a75c7f4c499b691cc5ccd
Aug  9 13:28:39.846: INFO: Pod sonobuoy-systemd-logs-daemon-set-c59f53251cea452d-gww4w requesting resource cpu=0m on Node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d
Aug  9 13:28:39.846: INFO: Pod coredns-6f74b4c5f8-5ztrx requesting resource cpu=100m on Node scw-flan15-default-f07a9b7e282146a6b5427e9aba2
Aug  9 13:28:39.846: INFO: Pod csi-node-89m4p requesting resource cpu=0m on Node scw-flan15-default-f07a9b7e282146a6b5427e9aba2
Aug  9 13:28:39.846: INFO: Pod csi-node-hn5ml requesting resource cpu=0m on Node scw-flan15-default-fbc750a75c7f4c499b691cc5ccd
Aug  9 13:28:39.846: INFO: Pod csi-node-s6ph9 requesting resource cpu=0m on Node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d
Aug  9 13:28:39.846: INFO: Pod flannel-qwjfp requesting resource cpu=100m on Node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d
Aug  9 13:28:39.846: INFO: Pod flannel-thwpk requesting resource cpu=100m on Node scw-flan15-default-f07a9b7e282146a6b5427e9aba2
Aug  9 13:28:39.846: INFO: Pod flannel-v4kkt requesting resource cpu=100m on Node scw-flan15-default-fbc750a75c7f4c499b691cc5ccd
Aug  9 13:28:39.846: INFO: Pod ingress-traefik-5rxqq requesting resource cpu=0m on Node scw-flan15-default-fbc750a75c7f4c499b691cc5ccd
Aug  9 13:28:39.846: INFO: Pod ingress-traefik-tld7q requesting resource cpu=0m on Node scw-flan15-default-f07a9b7e282146a6b5427e9aba2
Aug  9 13:28:39.846: INFO: Pod ingress-traefik-xvq78 requesting resource cpu=0m on Node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d
Aug  9 13:28:39.846: INFO: Pod kube-proxy-kv7tc requesting resource cpu=0m on Node scw-flan15-default-f07a9b7e282146a6b5427e9aba2
Aug  9 13:28:39.846: INFO: Pod kube-proxy-s8p7n requesting resource cpu=0m on Node scw-flan15-default-fbc750a75c7f4c499b691cc5ccd
Aug  9 13:28:39.846: INFO: Pod kube-proxy-wjvhf requesting resource cpu=0m on Node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d
Aug  9 13:28:39.846: INFO: Pod metrics-server-5dc57bbc74-qzlbl requesting resource cpu=0m on Node scw-flan15-default-f07a9b7e282146a6b5427e9aba2
Aug  9 13:28:39.846: INFO: Pod node-problem-detector-4tg4w requesting resource cpu=20m on Node scw-flan15-default-fbc750a75c7f4c499b691cc5ccd
Aug  9 13:28:39.846: INFO: Pod node-problem-detector-gqzjc requesting resource cpu=20m on Node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d
Aug  9 13:28:39.846: INFO: Pod node-problem-detector-wkzb6 requesting resource cpu=20m on Node scw-flan15-default-f07a9b7e282146a6b5427e9aba2
Aug  9 13:28:39.846: INFO: Pod dashboard-metrics-scraper-57454df758-67n9f requesting resource cpu=0m on Node scw-flan15-default-f07a9b7e282146a6b5427e9aba2
Aug  9 13:28:39.846: INFO: Pod kubernetes-dashboard-7dfbf7f9d6-rkhpn requesting resource cpu=0m on Node scw-flan15-default-f07a9b7e282146a6b5427e9aba2
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b1de19f6-0bdf-4ec3-806b-72fefa502e1d.15b944305705e498], Reason = [Scheduled], Message = [Successfully assigned sched-pred-6286/filler-pod-b1de19f6-0bdf-4ec3-806b-72fefa502e1d to scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b1de19f6-0bdf-4ec3-806b-72fefa502e1d.15b94430a6a174f4], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b1de19f6-0bdf-4ec3-806b-72fefa502e1d.15b94430b4b8a1dc], Reason = [Created], Message = [Created container filler-pod-b1de19f6-0bdf-4ec3-806b-72fefa502e1d]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b1de19f6-0bdf-4ec3-806b-72fefa502e1d.15b94430c68c0a93], Reason = [Started], Message = [Started container filler-pod-b1de19f6-0bdf-4ec3-806b-72fefa502e1d]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-bec90375-7f0f-41b4-b7d0-a569d63f391b.15b9443058bc4429], Reason = [Scheduled], Message = [Successfully assigned sched-pred-6286/filler-pod-bec90375-7f0f-41b4-b7d0-a569d63f391b to scw-flan15-default-f07a9b7e282146a6b5427e9aba2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-bec90375-7f0f-41b4-b7d0-a569d63f391b.15b94430b357c018], Reason = [Pulling], Message = [Pulling image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-bec90375-7f0f-41b4-b7d0-a569d63f391b.15b94430d754137d], Reason = [Pulled], Message = [Successfully pulled image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-bec90375-7f0f-41b4-b7d0-a569d63f391b.15b94430df5b17e9], Reason = [Created], Message = [Created container filler-pod-bec90375-7f0f-41b4-b7d0-a569d63f391b]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-bec90375-7f0f-41b4-b7d0-a569d63f391b.15b94430f2b7bc74], Reason = [Started], Message = [Started container filler-pod-bec90375-7f0f-41b4-b7d0-a569d63f391b]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e6efdbb9-11f2-4399-865e-9ce90d5d1726.15b944305a0bc9aa], Reason = [Scheduled], Message = [Successfully assigned sched-pred-6286/filler-pod-e6efdbb9-11f2-4399-865e-9ce90d5d1726 to scw-flan15-default-fbc750a75c7f4c499b691cc5ccd]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e6efdbb9-11f2-4399-865e-9ce90d5d1726.15b94430b645da53], Reason = [Pulling], Message = [Pulling image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e6efdbb9-11f2-4399-865e-9ce90d5d1726.15b94430d57e0e65], Reason = [Pulled], Message = [Successfully pulled image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e6efdbb9-11f2-4399-865e-9ce90d5d1726.15b94430dbc71bfa], Reason = [Created], Message = [Created container filler-pod-e6efdbb9-11f2-4399-865e-9ce90d5d1726]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e6efdbb9-11f2-4399-865e-9ce90d5d1726.15b94430f704adaa], Reason = [Started], Message = [Started container filler-pod-e6efdbb9-11f2-4399-865e-9ce90d5d1726]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15b944314b923d1c], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node scw-flan15-default-fbc750a75c7f4c499b691cc5ccd
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node scw-flan15-default-f07a9b7e282146a6b5427e9aba2
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:28:47.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-6286" for this suite.
Aug  9 13:28:55.438: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:28:57.450: INFO: namespace sched-pred-6286 deletion completed in 10.056289185s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:18.096 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:28:57.450: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4080
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secret-namespace-6100
STEP: Creating secret with name secret-test-ed01c8e3-8433-4d20-b3dd-cde6fa51a2bb
STEP: Creating a pod to test consume secrets
Aug  9 13:28:57.925: INFO: Waiting up to 5m0s for pod "pod-secrets-a136dec7-aa96-4054-a569-f96033169603" in namespace "secrets-4080" to be "success or failure"
Aug  9 13:28:57.937: INFO: Pod "pod-secrets-a136dec7-aa96-4054-a569-f96033169603": Phase="Pending", Reason="", readiness=false. Elapsed: 11.246346ms
Aug  9 13:28:59.947: INFO: Pod "pod-secrets-a136dec7-aa96-4054-a569-f96033169603": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021306024s
Aug  9 13:29:01.957: INFO: Pod "pod-secrets-a136dec7-aa96-4054-a569-f96033169603": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031528552s
STEP: Saw pod success
Aug  9 13:29:01.957: INFO: Pod "pod-secrets-a136dec7-aa96-4054-a569-f96033169603" satisfied condition "success or failure"
Aug  9 13:29:01.966: INFO: Trying to get logs from node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d pod pod-secrets-a136dec7-aa96-4054-a569-f96033169603 container secret-volume-test: <nil>
STEP: delete the pod
Aug  9 13:29:02.068: INFO: Waiting for pod pod-secrets-a136dec7-aa96-4054-a569-f96033169603 to disappear
Aug  9 13:29:02.076: INFO: Pod pod-secrets-a136dec7-aa96-4054-a569-f96033169603 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:29:02.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4080" for this suite.
Aug  9 13:29:08.133: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:29:08.480: INFO: namespace secrets-4080 deletion completed in 6.389504905s
STEP: Destroying namespace "secret-namespace-6100" for this suite.
Aug  9 13:29:16.523: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:29:16.877: INFO: namespace secret-namespace-6100 deletion completed in 8.396391891s

• [SLOW TEST:19.428 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:29:16.879: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-8240
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:29:43.894: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-8240" for this suite.
Aug  9 13:29:51.968: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:29:52.300: INFO: namespace container-runtime-8240 deletion completed in 8.377787316s

• [SLOW TEST:35.421 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    when starting a container that exits
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:29:52.301: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-196
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test env composition
Aug  9 13:29:52.562: INFO: Waiting up to 5m0s for pod "var-expansion-55066346-2275-4f66-b2d1-33101056f5cd" in namespace "var-expansion-196" to be "success or failure"
Aug  9 13:29:52.578: INFO: Pod "var-expansion-55066346-2275-4f66-b2d1-33101056f5cd": Phase="Pending", Reason="", readiness=false. Elapsed: 14.830101ms
Aug  9 13:29:54.590: INFO: Pod "var-expansion-55066346-2275-4f66-b2d1-33101056f5cd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027558211s
Aug  9 13:29:56.601: INFO: Pod "var-expansion-55066346-2275-4f66-b2d1-33101056f5cd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038218883s
STEP: Saw pod success
Aug  9 13:29:56.601: INFO: Pod "var-expansion-55066346-2275-4f66-b2d1-33101056f5cd" satisfied condition "success or failure"
Aug  9 13:29:56.610: INFO: Trying to get logs from node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d pod var-expansion-55066346-2275-4f66-b2d1-33101056f5cd container dapi-container: <nil>
STEP: delete the pod
Aug  9 13:29:56.700: INFO: Waiting for pod var-expansion-55066346-2275-4f66-b2d1-33101056f5cd to disappear
Aug  9 13:29:56.707: INFO: Pod var-expansion-55066346-2275-4f66-b2d1-33101056f5cd no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:29:56.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-196" for this suite.
Aug  9 13:30:04.807: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:30:05.163: INFO: namespace var-expansion-196 deletion completed in 8.393703881s

• [SLOW TEST:12.861 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:30:05.163: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2873
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug  9 13:30:05.437: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f598ad3f-43de-4e36-bf7d-74e441a7b467" in namespace "downward-api-2873" to be "success or failure"
Aug  9 13:30:05.452: INFO: Pod "downwardapi-volume-f598ad3f-43de-4e36-bf7d-74e441a7b467": Phase="Pending", Reason="", readiness=false. Elapsed: 15.327747ms
Aug  9 13:30:07.463: INFO: Pod "downwardapi-volume-f598ad3f-43de-4e36-bf7d-74e441a7b467": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025853773s
Aug  9 13:30:09.475: INFO: Pod "downwardapi-volume-f598ad3f-43de-4e36-bf7d-74e441a7b467": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037931788s
STEP: Saw pod success
Aug  9 13:30:09.475: INFO: Pod "downwardapi-volume-f598ad3f-43de-4e36-bf7d-74e441a7b467" satisfied condition "success or failure"
Aug  9 13:30:09.484: INFO: Trying to get logs from node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d pod downwardapi-volume-f598ad3f-43de-4e36-bf7d-74e441a7b467 container client-container: <nil>
STEP: delete the pod
Aug  9 13:30:09.543: INFO: Waiting for pod downwardapi-volume-f598ad3f-43de-4e36-bf7d-74e441a7b467 to disappear
Aug  9 13:30:09.552: INFO: Pod downwardapi-volume-f598ad3f-43de-4e36-bf7d-74e441a7b467 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:30:09.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2873" for this suite.
Aug  9 13:30:15.618: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:30:15.969: INFO: namespace downward-api-2873 deletion completed in 6.40288247s

• [SLOW TEST:10.807 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:30:15.972: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-6183
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-6183
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-6183
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-6183
Aug  9 13:30:16.331: INFO: Found 0 stateful pods, waiting for 1
Aug  9 13:30:26.343: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Aug  9 13:30:26.353: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-6183 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug  9 13:30:26.852: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug  9 13:30:26.852: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug  9 13:30:26.853: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug  9 13:30:26.864: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Aug  9 13:30:36.877: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug  9 13:30:36.877: INFO: Waiting for statefulset status.replicas updated to 0
Aug  9 13:30:36.922: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999479s
Aug  9 13:30:37.932: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.989151016s
Aug  9 13:30:38.947: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.978408381s
Aug  9 13:30:39.958: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.964327674s
Aug  9 13:30:41.001: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.953329287s
Aug  9 13:30:42.012: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.910291191s
Aug  9 13:30:43.024: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.898530368s
Aug  9 13:30:44.035: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.887095792s
Aug  9 13:30:45.049: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.875459975s
Aug  9 13:30:46.061: INFO: Verifying statefulset ss doesn't scale past 1 for another 861.962696ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-6183
Aug  9 13:30:47.109: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-6183 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  9 13:30:47.724: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Aug  9 13:30:47.724: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug  9 13:30:47.724: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug  9 13:30:47.735: INFO: Found 1 stateful pods, waiting for 3
Aug  9 13:30:57.778: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Aug  9 13:30:57.778: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Aug  9 13:30:57.778: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Aug  9 13:30:57.825: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-6183 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug  9 13:30:58.271: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug  9 13:30:58.271: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug  9 13:30:58.271: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug  9 13:30:58.271: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-6183 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug  9 13:30:58.898: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug  9 13:30:58.900: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug  9 13:30:58.900: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug  9 13:30:58.901: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-6183 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug  9 13:30:59.365: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug  9 13:30:59.365: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug  9 13:30:59.365: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug  9 13:30:59.365: INFO: Waiting for statefulset status.replicas updated to 0
Aug  9 13:30:59.374: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Aug  9 13:31:09.396: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug  9 13:31:09.396: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Aug  9 13:31:09.396: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Aug  9 13:31:09.432: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999529s
Aug  9 13:31:10.445: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.983148379s
Aug  9 13:31:11.457: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.971025235s
Aug  9 13:31:12.469: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.958554987s
Aug  9 13:31:13.485: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.946663221s
Aug  9 13:31:14.496: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.930677749s
Aug  9 13:31:15.509: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.919046868s
Aug  9 13:31:16.526: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.9062724s
Aug  9 13:31:17.539: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.889063907s
Aug  9 13:31:18.551: INFO: Verifying statefulset ss doesn't scale past 3 for another 876.951925ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-6183
Aug  9 13:31:19.567: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-6183 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  9 13:31:20.208: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Aug  9 13:31:20.208: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug  9 13:31:20.208: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug  9 13:31:20.208: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-6183 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  9 13:31:20.832: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Aug  9 13:31:20.832: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug  9 13:31:20.832: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug  9 13:31:20.832: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-6183 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  9 13:31:21.374: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Aug  9 13:31:21.374: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug  9 13:31:21.374: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug  9 13:31:21.374: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Aug  9 13:31:51.422: INFO: Deleting all statefulset in ns statefulset-6183
Aug  9 13:31:51.435: INFO: Scaling statefulset ss to 0
Aug  9 13:31:51.472: INFO: Waiting for statefulset status.replicas updated to 0
Aug  9 13:31:51.481: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:31:51.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6183" for this suite.
Aug  9 13:31:59.594: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:31:59.983: INFO: namespace statefulset-6183 deletion completed in 8.43262506s

• [SLOW TEST:104.011 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:31:59.983: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4835
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on tmpfs
Aug  9 13:32:00.418: INFO: Waiting up to 5m0s for pod "pod-0dcfec01-7796-42fa-9e6c-edbff5aa50bd" in namespace "emptydir-4835" to be "success or failure"
Aug  9 13:32:00.428: INFO: Pod "pod-0dcfec01-7796-42fa-9e6c-edbff5aa50bd": Phase="Pending", Reason="", readiness=false. Elapsed: 10.619296ms
Aug  9 13:32:02.442: INFO: Pod "pod-0dcfec01-7796-42fa-9e6c-edbff5aa50bd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024277305s
Aug  9 13:32:04.455: INFO: Pod "pod-0dcfec01-7796-42fa-9e6c-edbff5aa50bd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037359241s
STEP: Saw pod success
Aug  9 13:32:04.455: INFO: Pod "pod-0dcfec01-7796-42fa-9e6c-edbff5aa50bd" satisfied condition "success or failure"
Aug  9 13:32:04.464: INFO: Trying to get logs from node scw-flan15-default-f07a9b7e282146a6b5427e9aba2 pod pod-0dcfec01-7796-42fa-9e6c-edbff5aa50bd container test-container: <nil>
STEP: delete the pod
Aug  9 13:32:04.528: INFO: Waiting for pod pod-0dcfec01-7796-42fa-9e6c-edbff5aa50bd to disappear
Aug  9 13:32:04.538: INFO: Pod pod-0dcfec01-7796-42fa-9e6c-edbff5aa50bd no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:32:04.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4835" for this suite.
Aug  9 13:32:10.590: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:32:10.967: INFO: namespace emptydir-4835 deletion completed in 6.416944705s

• [SLOW TEST:10.984 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:32:10.967: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-2586
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: getting the auto-created API token
STEP: reading a file in the container
Aug  9 13:32:15.827: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-2586 pod-service-account-f4598a24-f827-4a10-ba08-7c61149369e0 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Aug  9 13:32:16.300: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-2586 pod-service-account-f4598a24-f827-4a10-ba08-7c61149369e0 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Aug  9 13:32:16.753: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-2586 pod-service-account-f4598a24-f827-4a10-ba08-7c61149369e0 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:32:17.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-2586" for this suite.
Aug  9 13:32:23.249: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:32:23.644: INFO: namespace svcaccounts-2586 deletion completed in 6.450888869s

• [SLOW TEST:12.677 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:32:23.647: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-6784
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug  9 13:32:23.921: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:32:28.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6784" for this suite.
Aug  9 13:33:18.097: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:33:18.461: INFO: namespace pods-6784 deletion completed in 50.400716535s

• [SLOW TEST:54.814 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:33:18.463: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-2638
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Aug  9 13:33:18.773: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-2638,SelfLink:/api/v1/namespaces/watch-2638/configmaps/e2e-watch-test-resource-version,UID:56c414d3-b534-428f-9d75-ebc9ea573865,ResourceVersion:124641685,Generation:0,CreationTimestamp:2019-08-09 13:33:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug  9 13:33:18.773: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-2638,SelfLink:/api/v1/namespaces/watch-2638/configmaps/e2e-watch-test-resource-version,UID:56c414d3-b534-428f-9d75-ebc9ea573865,ResourceVersion:124641686,Generation:0,CreationTimestamp:2019-08-09 13:33:18 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:33:18.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2638" for this suite.
Aug  9 13:33:24.844: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:33:25.212: INFO: namespace watch-2638 deletion completed in 6.42359283s

• [SLOW TEST:6.750 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:33:25.215: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-1539
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:33:29.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1539" for this suite.
Aug  9 13:34:19.580: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:34:19.899: INFO: namespace kubelet-test-1539 deletion completed in 50.357279709s

• [SLOW TEST:54.684 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command in a pod
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:34:19.902: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5457
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-projected-all-test-volume-15c8aa6b-3162-441a-a41d-44ff033541de
STEP: Creating secret with name secret-projected-all-test-volume-7d2863c1-6e64-4713-a09b-284d456c6a0f
STEP: Creating a pod to test Check all projections for projected volume plugin
Aug  9 13:34:20.189: INFO: Waiting up to 5m0s for pod "projected-volume-4a4e9f12-2d1a-4bef-b384-96e0e9110c91" in namespace "projected-5457" to be "success or failure"
Aug  9 13:34:20.199: INFO: Pod "projected-volume-4a4e9f12-2d1a-4bef-b384-96e0e9110c91": Phase="Pending", Reason="", readiness=false. Elapsed: 9.743135ms
Aug  9 13:34:22.208: INFO: Pod "projected-volume-4a4e9f12-2d1a-4bef-b384-96e0e9110c91": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019351909s
Aug  9 13:34:24.224: INFO: Pod "projected-volume-4a4e9f12-2d1a-4bef-b384-96e0e9110c91": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035256638s
STEP: Saw pod success
Aug  9 13:34:24.224: INFO: Pod "projected-volume-4a4e9f12-2d1a-4bef-b384-96e0e9110c91" satisfied condition "success or failure"
Aug  9 13:34:24.233: INFO: Trying to get logs from node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d pod projected-volume-4a4e9f12-2d1a-4bef-b384-96e0e9110c91 container projected-all-volume-test: <nil>
STEP: delete the pod
Aug  9 13:34:24.305: INFO: Waiting for pod projected-volume-4a4e9f12-2d1a-4bef-b384-96e0e9110c91 to disappear
Aug  9 13:34:24.319: INFO: Pod projected-volume-4a4e9f12-2d1a-4bef-b384-96e0e9110c91 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:34:24.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5457" for this suite.
Aug  9 13:34:30.382: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:34:30.742: INFO: namespace projected-5457 deletion completed in 6.403666193s

• [SLOW TEST:10.840 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:34:30.742: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename aggregator
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in aggregator-3007
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:76
Aug  9 13:34:30.960: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Registering the sample API server.
Aug  9 13:34:32.445: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Aug  9 13:34:34.588: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700954472, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700954472, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700954472, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700954472, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug  9 13:34:36.600: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700954472, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700954472, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700954472, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700954472, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug  9 13:34:38.610: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700954472, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700954472, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700954472, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700954472, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug  9 13:34:40.600: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700954472, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700954472, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700954472, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700954472, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug  9 13:34:42.602: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700954472, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700954472, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700954472, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700954472, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug  9 13:34:44.602: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700954472, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700954472, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700954472, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700954472, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug  9 13:34:46.609: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700954472, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700954472, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700954472, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700954472, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug  9 13:34:48.606: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700954472, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700954472, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700954472, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700954472, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug  9 13:34:50.604: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700954472, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700954472, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700954472, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700954472, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug  9 13:34:52.601: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700954472, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700954472, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700954472, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700954472, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug  9 13:34:54.597: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700954472, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700954472, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700954472, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700954472, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug  9 13:34:58.128: INFO: Waited 1.512221763s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:67
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:34:59.514: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-3007" for this suite.
Aug  9 13:35:05.711: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:35:06.059: INFO: namespace aggregator-3007 deletion completed in 6.448449682s

• [SLOW TEST:35.317 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:35:06.059: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3892
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1722
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug  9 13:35:06.290: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=kubectl-3892'
Aug  9 13:35:07.146: INFO: stderr: ""
Aug  9 13:35:07.146: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Aug  9 13:35:12.197: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 get pod e2e-test-nginx-pod --namespace=kubectl-3892 -o json'
Aug  9 13:35:12.387: INFO: stderr: ""
Aug  9 13:35:12.387: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-08-09T13:35:07Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"kubectl-3892\",\n        \"resourceVersion\": \"124643874\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-3892/pods/e2e-test-nginx-pod\",\n        \"uid\": \"ff2f5e51-bd3e-4039-8de7-648b705696ca\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-n78xn\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"scw-flan15-default-f07a9b7e282146a6b5427e9aba2\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-n78xn\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-n78xn\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-08-09T13:35:07Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-08-09T13:35:09Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-08-09T13:35:09Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-08-09T13:35:07Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://1136c6d70ee5ef7ea89a64d1f02b0b6503f799ee0cafba73a76241597478350f\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-08-09T13:35:08Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.12.155.153\",\n        \"phase\": \"Running\",\n        \"podIP\": \"100.64.0.37\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-08-09T13:35:07Z\"\n    }\n}\n"
STEP: replace the image in the pod
Aug  9 13:35:12.388: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 replace -f - --namespace=kubectl-3892'
Aug  9 13:35:13.010: INFO: stderr: ""
Aug  9 13:35:13.010: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1727
Aug  9 13:35:13.020: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 delete pods e2e-test-nginx-pod --namespace=kubectl-3892'
Aug  9 13:35:24.451: INFO: stderr: ""
Aug  9 13:35:24.451: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:35:24.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3892" for this suite.
Aug  9 13:35:30.506: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:35:30.869: INFO: namespace kubectl-3892 deletion completed in 6.40461539s

• [SLOW TEST:24.810 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl replace
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:35:30.870: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5030
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug  9 13:35:31.088: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ac4d0d63-2ad7-4046-9062-9e10195cf902" in namespace "downward-api-5030" to be "success or failure"
Aug  9 13:35:31.098: INFO: Pod "downwardapi-volume-ac4d0d63-2ad7-4046-9062-9e10195cf902": Phase="Pending", Reason="", readiness=false. Elapsed: 9.441792ms
Aug  9 13:35:33.111: INFO: Pod "downwardapi-volume-ac4d0d63-2ad7-4046-9062-9e10195cf902": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022122942s
Aug  9 13:35:35.125: INFO: Pod "downwardapi-volume-ac4d0d63-2ad7-4046-9062-9e10195cf902": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036034663s
STEP: Saw pod success
Aug  9 13:35:35.125: INFO: Pod "downwardapi-volume-ac4d0d63-2ad7-4046-9062-9e10195cf902" satisfied condition "success or failure"
Aug  9 13:35:35.133: INFO: Trying to get logs from node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d pod downwardapi-volume-ac4d0d63-2ad7-4046-9062-9e10195cf902 container client-container: <nil>
STEP: delete the pod
Aug  9 13:35:35.195: INFO: Waiting for pod downwardapi-volume-ac4d0d63-2ad7-4046-9062-9e10195cf902 to disappear
Aug  9 13:35:35.204: INFO: Pod downwardapi-volume-ac4d0d63-2ad7-4046-9062-9e10195cf902 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:35:35.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5030" for this suite.
Aug  9 13:35:41.257: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:35:41.595: INFO: namespace downward-api-5030 deletion completed in 6.375993627s

• [SLOW TEST:10.725 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:35:41.596: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-5298
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:35:45.924: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-5298" for this suite.
Aug  9 13:36:29.979: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:36:30.337: INFO: namespace kubelet-test-5298 deletion completed in 44.39817461s

• [SLOW TEST:48.742 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a read only busybox container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:36:30.341: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-6675
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6675.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-6675.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6675.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-6675.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug  9 13:36:34.821: INFO: DNS probes using dns-test-0782b205-7f36-4302-a9ce-0af4c269df4f succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6675.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-6675.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6675.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-6675.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug  9 13:36:57.133: INFO: DNS probes using dns-test-e480d949-f5dc-42b4-b0d4-252b79c07713 succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6675.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-6675.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6675.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-6675.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug  9 13:37:01.609: INFO: DNS probes using dns-test-aa276997-8f23-4cac-8935-1bee64546020 succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:37:01.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6675" for this suite.
Aug  9 13:37:09.795: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:37:10.223: INFO: namespace dns-6675 deletion completed in 8.483947369s

• [SLOW TEST:39.882 seconds]
[sig-network] DNS
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:37:10.224: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-9023
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug  9 13:37:14.596: INFO: Waiting up to 5m0s for pod "client-envvars-10dbd836-20cc-4065-be29-d29a1a099686" in namespace "pods-9023" to be "success or failure"
Aug  9 13:37:14.613: INFO: Pod "client-envvars-10dbd836-20cc-4065-be29-d29a1a099686": Phase="Pending", Reason="", readiness=false. Elapsed: 16.752542ms
Aug  9 13:37:16.623: INFO: Pod "client-envvars-10dbd836-20cc-4065-be29-d29a1a099686": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026783383s
Aug  9 13:37:18.635: INFO: Pod "client-envvars-10dbd836-20cc-4065-be29-d29a1a099686": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038504939s
STEP: Saw pod success
Aug  9 13:37:18.635: INFO: Pod "client-envvars-10dbd836-20cc-4065-be29-d29a1a099686" satisfied condition "success or failure"
Aug  9 13:37:18.648: INFO: Trying to get logs from node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d pod client-envvars-10dbd836-20cc-4065-be29-d29a1a099686 container env3cont: <nil>
STEP: delete the pod
Aug  9 13:37:18.718: INFO: Waiting for pod client-envvars-10dbd836-20cc-4065-be29-d29a1a099686 to disappear
Aug  9 13:37:18.729: INFO: Pod client-envvars-10dbd836-20cc-4065-be29-d29a1a099686 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:37:18.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9023" for this suite.
Aug  9 13:38:08.785: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:38:09.114: INFO: namespace pods-9023 deletion completed in 50.373003217s

• [SLOW TEST:58.890 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:38:09.115: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-320
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-320, will wait for the garbage collector to delete the pods
Aug  9 13:38:13.449: INFO: Deleting Job.batch foo took: 22.176572ms
Aug  9 13:38:13.749: INFO: Terminating Job.batch foo pods took: 300.426808ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:38:46.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-320" for this suite.
Aug  9 13:38:52.819: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:38:53.166: INFO: namespace job-320 deletion completed in 6.392258217s

• [SLOW TEST:44.052 seconds]
[sig-apps] Job
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:38:53.168: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8077
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir volume type on tmpfs
Aug  9 13:38:53.416: INFO: Waiting up to 5m0s for pod "pod-a7e14551-10d1-4c3f-898e-b745a5c7a942" in namespace "emptydir-8077" to be "success or failure"
Aug  9 13:38:53.430: INFO: Pod "pod-a7e14551-10d1-4c3f-898e-b745a5c7a942": Phase="Pending", Reason="", readiness=false. Elapsed: 13.706804ms
Aug  9 13:38:55.441: INFO: Pod "pod-a7e14551-10d1-4c3f-898e-b745a5c7a942": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024808676s
Aug  9 13:38:57.453: INFO: Pod "pod-a7e14551-10d1-4c3f-898e-b745a5c7a942": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037294727s
STEP: Saw pod success
Aug  9 13:38:57.457: INFO: Pod "pod-a7e14551-10d1-4c3f-898e-b745a5c7a942" satisfied condition "success or failure"
Aug  9 13:38:57.467: INFO: Trying to get logs from node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d pod pod-a7e14551-10d1-4c3f-898e-b745a5c7a942 container test-container: <nil>
STEP: delete the pod
Aug  9 13:38:57.535: INFO: Waiting for pod pod-a7e14551-10d1-4c3f-898e-b745a5c7a942 to disappear
Aug  9 13:38:57.546: INFO: Pod pod-a7e14551-10d1-4c3f-898e-b745a5c7a942 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:38:57.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8077" for this suite.
Aug  9 13:39:03.612: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:39:04.039: INFO: namespace emptydir-8077 deletion completed in 6.471252146s

• [SLOW TEST:10.871 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:39:04.039: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-7211
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Aug  9 13:39:04.301: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-7211,SelfLink:/api/v1/namespaces/watch-7211/configmaps/e2e-watch-test-configmap-a,UID:f2c8848e-7d95-4e64-a618-561c81099217,ResourceVersion:124648233,Generation:0,CreationTimestamp:2019-08-09 13:39:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug  9 13:39:04.302: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-7211,SelfLink:/api/v1/namespaces/watch-7211/configmaps/e2e-watch-test-configmap-a,UID:f2c8848e-7d95-4e64-a618-561c81099217,ResourceVersion:124648233,Generation:0,CreationTimestamp:2019-08-09 13:39:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Aug  9 13:39:14.330: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-7211,SelfLink:/api/v1/namespaces/watch-7211/configmaps/e2e-watch-test-configmap-a,UID:f2c8848e-7d95-4e64-a618-561c81099217,ResourceVersion:124648415,Generation:0,CreationTimestamp:2019-08-09 13:39:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Aug  9 13:39:14.330: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-7211,SelfLink:/api/v1/namespaces/watch-7211/configmaps/e2e-watch-test-configmap-a,UID:f2c8848e-7d95-4e64-a618-561c81099217,ResourceVersion:124648415,Generation:0,CreationTimestamp:2019-08-09 13:39:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Aug  9 13:39:24.355: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-7211,SelfLink:/api/v1/namespaces/watch-7211/configmaps/e2e-watch-test-configmap-a,UID:f2c8848e-7d95-4e64-a618-561c81099217,ResourceVersion:124648610,Generation:0,CreationTimestamp:2019-08-09 13:39:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug  9 13:39:24.355: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-7211,SelfLink:/api/v1/namespaces/watch-7211/configmaps/e2e-watch-test-configmap-a,UID:f2c8848e-7d95-4e64-a618-561c81099217,ResourceVersion:124648610,Generation:0,CreationTimestamp:2019-08-09 13:39:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Aug  9 13:39:34.374: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-7211,SelfLink:/api/v1/namespaces/watch-7211/configmaps/e2e-watch-test-configmap-a,UID:f2c8848e-7d95-4e64-a618-561c81099217,ResourceVersion:124648758,Generation:0,CreationTimestamp:2019-08-09 13:39:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug  9 13:39:34.375: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-7211,SelfLink:/api/v1/namespaces/watch-7211/configmaps/e2e-watch-test-configmap-a,UID:f2c8848e-7d95-4e64-a618-561c81099217,ResourceVersion:124648758,Generation:0,CreationTimestamp:2019-08-09 13:39:04 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Aug  9 13:39:44.397: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-7211,SelfLink:/api/v1/namespaces/watch-7211/configmaps/e2e-watch-test-configmap-b,UID:a5d0f687-3008-42fd-b72e-20d9dd633740,ResourceVersion:124648923,Generation:0,CreationTimestamp:2019-08-09 13:39:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug  9 13:39:44.397: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-7211,SelfLink:/api/v1/namespaces/watch-7211/configmaps/e2e-watch-test-configmap-b,UID:a5d0f687-3008-42fd-b72e-20d9dd633740,ResourceVersion:124648923,Generation:0,CreationTimestamp:2019-08-09 13:39:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Aug  9 13:39:54.418: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-7211,SelfLink:/api/v1/namespaces/watch-7211/configmaps/e2e-watch-test-configmap-b,UID:a5d0f687-3008-42fd-b72e-20d9dd633740,ResourceVersion:124649096,Generation:0,CreationTimestamp:2019-08-09 13:39:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug  9 13:39:54.418: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-7211,SelfLink:/api/v1/namespaces/watch-7211/configmaps/e2e-watch-test-configmap-b,UID:a5d0f687-3008-42fd-b72e-20d9dd633740,ResourceVersion:124649096,Generation:0,CreationTimestamp:2019-08-09 13:39:44 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:40:04.419: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7211" for this suite.
Aug  9 13:40:10.481: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:40:10.898: INFO: namespace watch-7211 deletion completed in 6.461897864s

• [SLOW TEST:66.859 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:40:10.899: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-6603
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod busybox-5935d7f4-0754-4ae9-85d7-e3f132d918e8 in namespace container-probe-6603
Aug  9 13:40:19.189: INFO: Started pod busybox-5935d7f4-0754-4ae9-85d7-e3f132d918e8 in namespace container-probe-6603
STEP: checking the pod's current state and verifying that restartCount is present
Aug  9 13:40:19.197: INFO: Initial restart count of pod busybox-5935d7f4-0754-4ae9-85d7-e3f132d918e8 is 0
Aug  9 13:41:07.524: INFO: Restart count of pod container-probe-6603/busybox-5935d7f4-0754-4ae9-85d7-e3f132d918e8 is now 1 (48.326573958s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:41:07.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6603" for this suite.
Aug  9 13:41:13.658: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:41:14.045: INFO: namespace container-probe-6603 deletion completed in 6.433931545s

• [SLOW TEST:63.146 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:41:14.049: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-6850
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override arguments
Aug  9 13:41:14.311: INFO: Waiting up to 5m0s for pod "client-containers-353f5696-3447-4825-90e4-fa52e2161b1f" in namespace "containers-6850" to be "success or failure"
Aug  9 13:41:14.334: INFO: Pod "client-containers-353f5696-3447-4825-90e4-fa52e2161b1f": Phase="Pending", Reason="", readiness=false. Elapsed: 23.578043ms
Aug  9 13:41:16.350: INFO: Pod "client-containers-353f5696-3447-4825-90e4-fa52e2161b1f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039164428s
Aug  9 13:41:18.362: INFO: Pod "client-containers-353f5696-3447-4825-90e4-fa52e2161b1f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.050849956s
Aug  9 13:41:20.373: INFO: Pod "client-containers-353f5696-3447-4825-90e4-fa52e2161b1f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.062077532s
STEP: Saw pod success
Aug  9 13:41:20.373: INFO: Pod "client-containers-353f5696-3447-4825-90e4-fa52e2161b1f" satisfied condition "success or failure"
Aug  9 13:41:20.384: INFO: Trying to get logs from node scw-flan15-default-f07a9b7e282146a6b5427e9aba2 pod client-containers-353f5696-3447-4825-90e4-fa52e2161b1f container test-container: <nil>
STEP: delete the pod
Aug  9 13:41:20.455: INFO: Waiting for pod client-containers-353f5696-3447-4825-90e4-fa52e2161b1f to disappear
Aug  9 13:41:20.465: INFO: Pod client-containers-353f5696-3447-4825-90e4-fa52e2161b1f no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:41:20.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-6850" for this suite.
Aug  9 13:41:26.520: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:41:26.884: INFO: namespace containers-6850 deletion completed in 6.406638639s

• [SLOW TEST:12.836 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:41:26.887: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5146
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1457
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug  9 13:41:27.975: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-5146'
Aug  9 13:41:28.167: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug  9 13:41:28.167: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Aug  9 13:41:28.224: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-mmn4z]
Aug  9 13:41:28.224: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-mmn4z" in namespace "kubectl-5146" to be "running and ready"
Aug  9 13:41:28.232: INFO: Pod "e2e-test-nginx-rc-mmn4z": Phase="Pending", Reason="", readiness=false. Elapsed: 8.384412ms
Aug  9 13:41:30.249: INFO: Pod "e2e-test-nginx-rc-mmn4z": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025023968s
Aug  9 13:41:32.258: INFO: Pod "e2e-test-nginx-rc-mmn4z": Phase="Running", Reason="", readiness=true. Elapsed: 4.0344838s
Aug  9 13:41:32.258: INFO: Pod "e2e-test-nginx-rc-mmn4z" satisfied condition "running and ready"
Aug  9 13:41:32.259: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-mmn4z]
Aug  9 13:41:32.259: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 logs rc/e2e-test-nginx-rc --namespace=kubectl-5146'
Aug  9 13:41:32.792: INFO: stderr: ""
Aug  9 13:41:32.792: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1462
Aug  9 13:41:32.793: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 delete rc e2e-test-nginx-rc --namespace=kubectl-5146'
Aug  9 13:41:33.028: INFO: stderr: ""
Aug  9 13:41:33.028: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:41:33.028: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5146" for this suite.
Aug  9 13:41:57.083: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:41:57.443: INFO: namespace kubectl-5146 deletion completed in 24.400814416s

• [SLOW TEST:30.556 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:41:57.443: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-818
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Aug  9 13:42:00.754: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:42:00.801: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-818" for this suite.
Aug  9 13:42:06.853: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:42:07.210: INFO: namespace container-runtime-818 deletion completed in 6.393793002s

• [SLOW TEST:9.767 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:42:07.211: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-9356
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug  9 13:42:07.517: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Aug  9 13:42:07.561: INFO: Number of nodes with available pods: 0
Aug  9 13:42:07.561: INFO: Node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d is running more than one daemon pod
Aug  9 13:42:08.585: INFO: Number of nodes with available pods: 0
Aug  9 13:42:08.585: INFO: Node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d is running more than one daemon pod
Aug  9 13:42:09.595: INFO: Number of nodes with available pods: 0
Aug  9 13:42:09.595: INFO: Node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d is running more than one daemon pod
Aug  9 13:42:10.592: INFO: Number of nodes with available pods: 3
Aug  9 13:42:10.592: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Aug  9 13:42:10.706: INFO: Wrong image for pod: daemon-set-bkm2q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:10.706: INFO: Wrong image for pod: daemon-set-mqvf2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:10.706: INFO: Wrong image for pod: daemon-set-ph4z4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:11.731: INFO: Wrong image for pod: daemon-set-bkm2q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:11.731: INFO: Wrong image for pod: daemon-set-mqvf2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:11.731: INFO: Wrong image for pod: daemon-set-ph4z4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:12.733: INFO: Wrong image for pod: daemon-set-bkm2q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:12.733: INFO: Wrong image for pod: daemon-set-mqvf2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:12.733: INFO: Wrong image for pod: daemon-set-ph4z4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:13.729: INFO: Wrong image for pod: daemon-set-bkm2q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:13.730: INFO: Wrong image for pod: daemon-set-mqvf2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:13.730: INFO: Wrong image for pod: daemon-set-ph4z4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:13.730: INFO: Pod daemon-set-ph4z4 is not available
Aug  9 13:42:14.733: INFO: Wrong image for pod: daemon-set-bkm2q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:14.733: INFO: Wrong image for pod: daemon-set-mqvf2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:14.733: INFO: Wrong image for pod: daemon-set-ph4z4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:14.733: INFO: Pod daemon-set-ph4z4 is not available
Aug  9 13:42:15.730: INFO: Wrong image for pod: daemon-set-bkm2q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:15.730: INFO: Wrong image for pod: daemon-set-mqvf2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:15.730: INFO: Wrong image for pod: daemon-set-ph4z4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:15.730: INFO: Pod daemon-set-ph4z4 is not available
Aug  9 13:42:16.730: INFO: Wrong image for pod: daemon-set-bkm2q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:16.730: INFO: Wrong image for pod: daemon-set-mqvf2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:16.731: INFO: Wrong image for pod: daemon-set-ph4z4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:16.731: INFO: Pod daemon-set-ph4z4 is not available
Aug  9 13:42:17.730: INFO: Wrong image for pod: daemon-set-bkm2q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:17.730: INFO: Wrong image for pod: daemon-set-mqvf2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:17.730: INFO: Wrong image for pod: daemon-set-ph4z4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:17.730: INFO: Pod daemon-set-ph4z4 is not available
Aug  9 13:42:18.730: INFO: Wrong image for pod: daemon-set-bkm2q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:18.730: INFO: Wrong image for pod: daemon-set-mqvf2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:18.730: INFO: Wrong image for pod: daemon-set-ph4z4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:18.730: INFO: Pod daemon-set-ph4z4 is not available
Aug  9 13:42:19.730: INFO: Wrong image for pod: daemon-set-bkm2q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:19.730: INFO: Wrong image for pod: daemon-set-mqvf2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:19.730: INFO: Wrong image for pod: daemon-set-ph4z4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:19.730: INFO: Pod daemon-set-ph4z4 is not available
Aug  9 13:42:20.735: INFO: Wrong image for pod: daemon-set-bkm2q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:20.735: INFO: Wrong image for pod: daemon-set-mqvf2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:20.735: INFO: Wrong image for pod: daemon-set-ph4z4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:20.735: INFO: Pod daemon-set-ph4z4 is not available
Aug  9 13:42:21.729: INFO: Wrong image for pod: daemon-set-bkm2q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:21.729: INFO: Wrong image for pod: daemon-set-mqvf2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:21.729: INFO: Wrong image for pod: daemon-set-ph4z4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:21.729: INFO: Pod daemon-set-ph4z4 is not available
Aug  9 13:42:22.730: INFO: Wrong image for pod: daemon-set-bkm2q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:22.730: INFO: Wrong image for pod: daemon-set-mqvf2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:22.730: INFO: Wrong image for pod: daemon-set-ph4z4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:22.730: INFO: Pod daemon-set-ph4z4 is not available
Aug  9 13:42:23.738: INFO: Wrong image for pod: daemon-set-bkm2q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:23.738: INFO: Wrong image for pod: daemon-set-mqvf2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:23.738: INFO: Wrong image for pod: daemon-set-ph4z4. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:23.738: INFO: Pod daemon-set-ph4z4 is not available
Aug  9 13:42:24.733: INFO: Wrong image for pod: daemon-set-bkm2q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:24.733: INFO: Wrong image for pod: daemon-set-mqvf2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:24.733: INFO: Pod daemon-set-tg9s8 is not available
Aug  9 13:42:25.730: INFO: Wrong image for pod: daemon-set-bkm2q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:25.730: INFO: Wrong image for pod: daemon-set-mqvf2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:25.730: INFO: Pod daemon-set-tg9s8 is not available
Aug  9 13:42:26.730: INFO: Wrong image for pod: daemon-set-bkm2q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:26.730: INFO: Wrong image for pod: daemon-set-mqvf2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:27.728: INFO: Wrong image for pod: daemon-set-bkm2q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:27.728: INFO: Wrong image for pod: daemon-set-mqvf2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:28.732: INFO: Wrong image for pod: daemon-set-bkm2q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:28.732: INFO: Pod daemon-set-bkm2q is not available
Aug  9 13:42:28.732: INFO: Wrong image for pod: daemon-set-mqvf2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:29.730: INFO: Wrong image for pod: daemon-set-bkm2q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:29.730: INFO: Pod daemon-set-bkm2q is not available
Aug  9 13:42:29.730: INFO: Wrong image for pod: daemon-set-mqvf2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:30.729: INFO: Wrong image for pod: daemon-set-bkm2q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:30.729: INFO: Pod daemon-set-bkm2q is not available
Aug  9 13:42:30.729: INFO: Wrong image for pod: daemon-set-mqvf2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:31.730: INFO: Wrong image for pod: daemon-set-bkm2q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:31.730: INFO: Pod daemon-set-bkm2q is not available
Aug  9 13:42:31.730: INFO: Wrong image for pod: daemon-set-mqvf2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:32.733: INFO: Wrong image for pod: daemon-set-bkm2q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:32.733: INFO: Pod daemon-set-bkm2q is not available
Aug  9 13:42:32.733: INFO: Wrong image for pod: daemon-set-mqvf2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:33.740: INFO: Wrong image for pod: daemon-set-bkm2q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:33.740: INFO: Pod daemon-set-bkm2q is not available
Aug  9 13:42:33.740: INFO: Wrong image for pod: daemon-set-mqvf2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:34.732: INFO: Wrong image for pod: daemon-set-bkm2q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:34.732: INFO: Pod daemon-set-bkm2q is not available
Aug  9 13:42:34.732: INFO: Wrong image for pod: daemon-set-mqvf2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:35.730: INFO: Wrong image for pod: daemon-set-bkm2q. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:35.730: INFO: Pod daemon-set-bkm2q is not available
Aug  9 13:42:35.730: INFO: Wrong image for pod: daemon-set-mqvf2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:36.730: INFO: Pod daemon-set-dpnsr is not available
Aug  9 13:42:36.730: INFO: Wrong image for pod: daemon-set-mqvf2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:37.730: INFO: Pod daemon-set-dpnsr is not available
Aug  9 13:42:37.730: INFO: Wrong image for pod: daemon-set-mqvf2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:38.737: INFO: Wrong image for pod: daemon-set-mqvf2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:39.732: INFO: Wrong image for pod: daemon-set-mqvf2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:40.731: INFO: Wrong image for pod: daemon-set-mqvf2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:40.731: INFO: Pod daemon-set-mqvf2 is not available
Aug  9 13:42:41.729: INFO: Wrong image for pod: daemon-set-mqvf2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:41.730: INFO: Pod daemon-set-mqvf2 is not available
Aug  9 13:42:42.729: INFO: Wrong image for pod: daemon-set-mqvf2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:42.729: INFO: Pod daemon-set-mqvf2 is not available
Aug  9 13:42:43.730: INFO: Wrong image for pod: daemon-set-mqvf2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:43.730: INFO: Pod daemon-set-mqvf2 is not available
Aug  9 13:42:44.732: INFO: Wrong image for pod: daemon-set-mqvf2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:44.732: INFO: Pod daemon-set-mqvf2 is not available
Aug  9 13:42:45.736: INFO: Wrong image for pod: daemon-set-mqvf2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:45.736: INFO: Pod daemon-set-mqvf2 is not available
Aug  9 13:42:46.736: INFO: Wrong image for pod: daemon-set-mqvf2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:46.737: INFO: Pod daemon-set-mqvf2 is not available
Aug  9 13:42:47.730: INFO: Wrong image for pod: daemon-set-mqvf2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Aug  9 13:42:47.730: INFO: Pod daemon-set-mqvf2 is not available
Aug  9 13:42:48.730: INFO: Pod daemon-set-dvcnb is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Aug  9 13:42:48.769: INFO: Number of nodes with available pods: 2
Aug  9 13:42:48.769: INFO: Node scw-flan15-default-fbc750a75c7f4c499b691cc5ccd is running more than one daemon pod
Aug  9 13:42:49.795: INFO: Number of nodes with available pods: 2
Aug  9 13:42:49.795: INFO: Node scw-flan15-default-fbc750a75c7f4c499b691cc5ccd is running more than one daemon pod
Aug  9 13:42:50.795: INFO: Number of nodes with available pods: 2
Aug  9 13:42:50.795: INFO: Node scw-flan15-default-fbc750a75c7f4c499b691cc5ccd is running more than one daemon pod
Aug  9 13:42:51.807: INFO: Number of nodes with available pods: 3
Aug  9 13:42:51.807: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9356, will wait for the garbage collector to delete the pods
Aug  9 13:42:51.964: INFO: Deleting DaemonSet.extensions daemon-set took: 31.318564ms
Aug  9 13:42:52.365: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.422862ms
Aug  9 13:43:04.511: INFO: Number of nodes with available pods: 0
Aug  9 13:43:04.511: INFO: Number of running nodes: 0, number of available pods: 0
Aug  9 13:43:04.519: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9356/daemonsets","resourceVersion":"124652653"},"items":null}

Aug  9 13:43:04.529: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9356/pods","resourceVersion":"124652653"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:43:04.618: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9356" for this suite.
Aug  9 13:43:12.690: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:43:13.104: INFO: namespace daemonsets-9356 deletion completed in 8.475558109s

• [SLOW TEST:65.893 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:43:13.106: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4165
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on node default medium
Aug  9 13:43:13.394: INFO: Waiting up to 5m0s for pod "pod-ed50d377-508e-4c31-a7f0-8cf7237f60dd" in namespace "emptydir-4165" to be "success or failure"
Aug  9 13:43:13.412: INFO: Pod "pod-ed50d377-508e-4c31-a7f0-8cf7237f60dd": Phase="Pending", Reason="", readiness=false. Elapsed: 17.9192ms
Aug  9 13:43:15.425: INFO: Pod "pod-ed50d377-508e-4c31-a7f0-8cf7237f60dd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030247304s
Aug  9 13:43:17.436: INFO: Pod "pod-ed50d377-508e-4c31-a7f0-8cf7237f60dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.041351313s
STEP: Saw pod success
Aug  9 13:43:17.436: INFO: Pod "pod-ed50d377-508e-4c31-a7f0-8cf7237f60dd" satisfied condition "success or failure"
Aug  9 13:43:17.445: INFO: Trying to get logs from node scw-flan15-default-f07a9b7e282146a6b5427e9aba2 pod pod-ed50d377-508e-4c31-a7f0-8cf7237f60dd container test-container: <nil>
STEP: delete the pod
Aug  9 13:43:17.522: INFO: Waiting for pod pod-ed50d377-508e-4c31-a7f0-8cf7237f60dd to disappear
Aug  9 13:43:17.532: INFO: Pod pod-ed50d377-508e-4c31-a7f0-8cf7237f60dd no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:43:17.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4165" for this suite.
Aug  9 13:43:23.603: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:43:23.944: INFO: namespace emptydir-4165 deletion completed in 6.389911748s

• [SLOW TEST:10.839 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:43:23.947: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-8651
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:43:28.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-8651" for this suite.
Aug  9 13:43:34.306: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:43:34.705: INFO: namespace kubelet-test-8651 deletion completed in 6.436517701s

• [SLOW TEST:10.758 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:43:34.705: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5735
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-974584d9-1de1-4701-8178-9ab4fd7c6c89
STEP: Creating a pod to test consume configMaps
Aug  9 13:43:34.969: INFO: Waiting up to 5m0s for pod "pod-configmaps-5a59d936-79bb-4691-8ee2-70961c9771ad" in namespace "configmap-5735" to be "success or failure"
Aug  9 13:43:34.989: INFO: Pod "pod-configmaps-5a59d936-79bb-4691-8ee2-70961c9771ad": Phase="Pending", Reason="", readiness=false. Elapsed: 20.259073ms
Aug  9 13:43:37.005: INFO: Pod "pod-configmaps-5a59d936-79bb-4691-8ee2-70961c9771ad": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035949422s
Aug  9 13:43:39.019: INFO: Pod "pod-configmaps-5a59d936-79bb-4691-8ee2-70961c9771ad": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.050581632s
STEP: Saw pod success
Aug  9 13:43:39.019: INFO: Pod "pod-configmaps-5a59d936-79bb-4691-8ee2-70961c9771ad" satisfied condition "success or failure"
Aug  9 13:43:39.029: INFO: Trying to get logs from node scw-flan15-default-fbc750a75c7f4c499b691cc5ccd pod pod-configmaps-5a59d936-79bb-4691-8ee2-70961c9771ad container configmap-volume-test: <nil>
STEP: delete the pod
Aug  9 13:43:39.106: INFO: Waiting for pod pod-configmaps-5a59d936-79bb-4691-8ee2-70961c9771ad to disappear
Aug  9 13:43:39.115: INFO: Pod pod-configmaps-5a59d936-79bb-4691-8ee2-70961c9771ad no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:43:39.116: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5735" for this suite.
Aug  9 13:43:45.180: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:43:45.581: INFO: namespace configmap-5735 deletion completed in 6.448720498s

• [SLOW TEST:10.876 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:43:45.585: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-1762
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Aug  9 13:43:46.668: INFO: Pod name wrapped-volume-race-b8eaf477-a227-4f95-a15c-e6323e21a180: Found 0 pods out of 5
Aug  9 13:43:51.713: INFO: Pod name wrapped-volume-race-b8eaf477-a227-4f95-a15c-e6323e21a180: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-b8eaf477-a227-4f95-a15c-e6323e21a180 in namespace emptydir-wrapper-1762, will wait for the garbage collector to delete the pods
Aug  9 13:44:03.888: INFO: Deleting ReplicationController wrapped-volume-race-b8eaf477-a227-4f95-a15c-e6323e21a180 took: 30.670798ms
Aug  9 13:44:04.288: INFO: Terminating ReplicationController wrapped-volume-race-b8eaf477-a227-4f95-a15c-e6323e21a180 pods took: 400.533825ms
STEP: Creating RC which spawns configmap-volume pods
Aug  9 13:44:46.047: INFO: Pod name wrapped-volume-race-21d4415d-2953-475e-8056-7f24930cc8af: Found 0 pods out of 5
Aug  9 13:44:51.063: INFO: Pod name wrapped-volume-race-21d4415d-2953-475e-8056-7f24930cc8af: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-21d4415d-2953-475e-8056-7f24930cc8af in namespace emptydir-wrapper-1762, will wait for the garbage collector to delete the pods
Aug  9 13:45:03.249: INFO: Deleting ReplicationController wrapped-volume-race-21d4415d-2953-475e-8056-7f24930cc8af took: 43.226935ms
Aug  9 13:45:03.650: INFO: Terminating ReplicationController wrapped-volume-race-21d4415d-2953-475e-8056-7f24930cc8af pods took: 400.449566ms
STEP: Creating RC which spawns configmap-volume pods
Aug  9 13:45:46.003: INFO: Pod name wrapped-volume-race-3c70a5d2-defd-45f9-863c-342c7253f73b: Found 0 pods out of 5
Aug  9 13:45:51.020: INFO: Pod name wrapped-volume-race-3c70a5d2-defd-45f9-863c-342c7253f73b: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-3c70a5d2-defd-45f9-863c-342c7253f73b in namespace emptydir-wrapper-1762, will wait for the garbage collector to delete the pods
Aug  9 13:46:03.184: INFO: Deleting ReplicationController wrapped-volume-race-3c70a5d2-defd-45f9-863c-342c7253f73b took: 29.351926ms
Aug  9 13:46:03.585: INFO: Terminating ReplicationController wrapped-volume-race-3c70a5d2-defd-45f9-863c-342c7253f73b pods took: 400.494939ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:46:47.013: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-1762" for this suite.
Aug  9 13:46:57.061: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:46:57.433: INFO: namespace emptydir-wrapper-1762 deletion completed in 10.407818541s

• [SLOW TEST:191.848 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:46:57.435: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5283
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating all guestbook components
Aug  9 13:46:57.655: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Aug  9 13:46:57.656: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 create -f - --namespace=kubectl-5283'
Aug  9 13:46:58.752: INFO: stderr: ""
Aug  9 13:46:58.752: INFO: stdout: "service/redis-slave created\n"
Aug  9 13:46:58.756: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Aug  9 13:46:58.756: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 create -f - --namespace=kubectl-5283'
Aug  9 13:46:59.338: INFO: stderr: ""
Aug  9 13:46:59.338: INFO: stdout: "service/redis-master created\n"
Aug  9 13:46:59.339: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Aug  9 13:46:59.339: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 create -f - --namespace=kubectl-5283'
Aug  9 13:47:00.095: INFO: stderr: ""
Aug  9 13:47:00.095: INFO: stdout: "service/frontend created\n"
Aug  9 13:47:00.095: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Aug  9 13:47:00.095: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 create -f - --namespace=kubectl-5283'
Aug  9 13:47:00.639: INFO: stderr: ""
Aug  9 13:47:00.639: INFO: stdout: "deployment.apps/frontend created\n"
Aug  9 13:47:00.640: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Aug  9 13:47:00.640: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 create -f - --namespace=kubectl-5283'
Aug  9 13:47:01.137: INFO: stderr: ""
Aug  9 13:47:01.138: INFO: stdout: "deployment.apps/redis-master created\n"
Aug  9 13:47:01.138: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Aug  9 13:47:01.138: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 create -f - --namespace=kubectl-5283'
Aug  9 13:47:02.045: INFO: stderr: ""
Aug  9 13:47:02.045: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Aug  9 13:47:02.045: INFO: Waiting for all frontend pods to be Running.
Aug  9 13:47:42.106: INFO: Waiting for frontend to serve content.
Aug  9 13:47:42.289: INFO: Trying to add a new entry to the guestbook.
Aug  9 13:47:42.421: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Aug  9 13:47:42.562: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 delete --grace-period=0 --force -f - --namespace=kubectl-5283'
Aug  9 13:47:42.958: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug  9 13:47:42.958: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Aug  9 13:47:42.958: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 delete --grace-period=0 --force -f - --namespace=kubectl-5283'
Aug  9 13:47:43.353: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug  9 13:47:43.353: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Aug  9 13:47:43.353: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 delete --grace-period=0 --force -f - --namespace=kubectl-5283'
Aug  9 13:47:43.929: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug  9 13:47:43.929: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Aug  9 13:47:43.932: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 delete --grace-period=0 --force -f - --namespace=kubectl-5283'
Aug  9 13:47:44.340: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug  9 13:47:44.340: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Aug  9 13:47:44.340: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 delete --grace-period=0 --force -f - --namespace=kubectl-5283'
Aug  9 13:47:44.609: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug  9 13:47:44.609: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Aug  9 13:47:44.610: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 delete --grace-period=0 --force -f - --namespace=kubectl-5283'
Aug  9 13:47:44.858: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug  9 13:47:44.858: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:47:44.868: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5283" for this suite.
Aug  9 13:48:24.956: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:48:25.314: INFO: namespace kubectl-5283 deletion completed in 40.42060883s

• [SLOW TEST:87.879 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Guestbook application
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:48:25.316: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8548
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-c23c51c3-0527-4172-8ca1-882ff23025be
STEP: Creating a pod to test consume configMaps
Aug  9 13:48:25.602: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-397ec549-77e4-4a3e-bb19-1fdd7809a2f2" in namespace "projected-8548" to be "success or failure"
Aug  9 13:48:25.616: INFO: Pod "pod-projected-configmaps-397ec549-77e4-4a3e-bb19-1fdd7809a2f2": Phase="Pending", Reason="", readiness=false. Elapsed: 14.506314ms
Aug  9 13:48:27.627: INFO: Pod "pod-projected-configmaps-397ec549-77e4-4a3e-bb19-1fdd7809a2f2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025711291s
Aug  9 13:48:29.640: INFO: Pod "pod-projected-configmaps-397ec549-77e4-4a3e-bb19-1fdd7809a2f2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.038354013s
Aug  9 13:48:31.652: INFO: Pod "pod-projected-configmaps-397ec549-77e4-4a3e-bb19-1fdd7809a2f2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.049959003s
STEP: Saw pod success
Aug  9 13:48:31.652: INFO: Pod "pod-projected-configmaps-397ec549-77e4-4a3e-bb19-1fdd7809a2f2" satisfied condition "success or failure"
Aug  9 13:48:31.663: INFO: Trying to get logs from node scw-flan15-default-f07a9b7e282146a6b5427e9aba2 pod pod-projected-configmaps-397ec549-77e4-4a3e-bb19-1fdd7809a2f2 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug  9 13:48:31.753: INFO: Waiting for pod pod-projected-configmaps-397ec549-77e4-4a3e-bb19-1fdd7809a2f2 to disappear
Aug  9 13:48:31.762: INFO: Pod pod-projected-configmaps-397ec549-77e4-4a3e-bb19-1fdd7809a2f2 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:48:31.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8548" for this suite.
Aug  9 13:48:37.830: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:48:38.208: INFO: namespace projected-8548 deletion completed in 6.430365403s

• [SLOW TEST:12.893 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:48:38.208: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-987
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Aug  9 13:48:41.551: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:48:41.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-987" for this suite.
Aug  9 13:48:47.666: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:48:48.053: INFO: namespace container-runtime-987 deletion completed in 6.42787389s

• [SLOW TEST:9.845 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:48:48.054: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-7008
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-7008
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-7008
STEP: Creating statefulset with conflicting port in namespace statefulset-7008
STEP: Waiting until pod test-pod will start running in namespace statefulset-7008
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-7008
Aug  9 13:48:52.412: INFO: Observed stateful pod in namespace: statefulset-7008, name: ss-0, uid: ba065c55-b448-4796-b3cb-8b9ade1f64b4, status phase: Failed. Waiting for statefulset controller to delete.
Aug  9 13:48:52.421: INFO: Observed stateful pod in namespace: statefulset-7008, name: ss-0, uid: ba065c55-b448-4796-b3cb-8b9ade1f64b4, status phase: Failed. Waiting for statefulset controller to delete.
Aug  9 13:48:52.434: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-7008
STEP: Removing pod with conflicting port in namespace statefulset-7008
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-7008 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Aug  9 13:48:56.530: INFO: Deleting all statefulset in ns statefulset-7008
Aug  9 13:48:56.542: INFO: Scaling statefulset ss to 0
Aug  9 13:49:06.601: INFO: Waiting for statefulset status.replicas updated to 0
Aug  9 13:49:06.612: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:49:06.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7008" for this suite.
Aug  9 13:49:12.713: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:49:13.145: INFO: namespace statefulset-7008 deletion completed in 6.471836416s

• [SLOW TEST:25.091 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:49:13.147: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-3455
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Aug  9 13:49:23.547: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug  9 13:49:23.556: INFO: Pod pod-with-poststart-http-hook still exists
Aug  9 13:49:25.557: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug  9 13:49:25.568: INFO: Pod pod-with-poststart-http-hook still exists
Aug  9 13:49:27.557: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug  9 13:49:27.569: INFO: Pod pod-with-poststart-http-hook still exists
Aug  9 13:49:29.557: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Aug  9 13:49:29.567: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:49:29.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-3455" for this suite.
Aug  9 13:49:53.622: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:49:53.972: INFO: namespace container-lifecycle-hook-3455 deletion completed in 24.390967028s

• [SLOW TEST:40.825 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:49:53.972: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-1150
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug  9 13:49:54.196: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Aug  9 13:49:56.320: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:49:56.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-1150" for this suite.
Aug  9 13:50:04.403: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:50:04.787: INFO: namespace replication-controller-1150 deletion completed in 8.445269953s

• [SLOW TEST:10.814 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:50:04.787: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-5446
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug  9 13:50:05.018: INFO: Creating deployment "test-recreate-deployment"
Aug  9 13:50:05.034: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Aug  9 13:50:05.058: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Aug  9 13:50:07.077: INFO: Waiting deployment "test-recreate-deployment" to complete
Aug  9 13:50:07.085: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700955405, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700955405, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700955405, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700955405, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-6df85df6b9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug  9 13:50:09.098: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Aug  9 13:50:09.145: INFO: Updating deployment test-recreate-deployment
Aug  9 13:50:09.145: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Aug  9 13:50:09.405: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-5446,SelfLink:/apis/apps/v1/namespaces/deployment-5446/deployments/test-recreate-deployment,UID:c6ef53fc-cb2e-441e-9d5f-df10600554a4,ResourceVersion:124659823,Generation:2,CreationTimestamp:2019-08-09 13:50:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-08-09 13:50:09 +0000 UTC 2019-08-09 13:50:09 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-08-09 13:50:09 +0000 UTC 2019-08-09 13:50:05 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-5c8c9cc69d" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Aug  9 13:50:09.424: INFO: New ReplicaSet "test-recreate-deployment-5c8c9cc69d" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5c8c9cc69d,GenerateName:,Namespace:deployment-5446,SelfLink:/apis/apps/v1/namespaces/deployment-5446/replicasets/test-recreate-deployment-5c8c9cc69d,UID:1b9516f6-2e29-4395-96ef-6970a03734e4,ResourceVersion:124659820,Generation:1,CreationTimestamp:2019-08-09 13:50:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment c6ef53fc-cb2e-441e-9d5f-df10600554a4 0xc0021377c7 0xc0021377c8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug  9 13:50:09.424: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Aug  9 13:50:09.424: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-6df85df6b9,GenerateName:,Namespace:deployment-5446,SelfLink:/apis/apps/v1/namespaces/deployment-5446/replicasets/test-recreate-deployment-6df85df6b9,UID:5319a093-3113-431d-a68b-abbda3e49db0,ResourceVersion:124659805,Generation:2,CreationTimestamp:2019-08-09 13:50:05 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment c6ef53fc-cb2e-441e-9d5f-df10600554a4 0xc002137897 0xc002137898}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug  9 13:50:09.435: INFO: Pod "test-recreate-deployment-5c8c9cc69d-fddm4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5c8c9cc69d-fddm4,GenerateName:test-recreate-deployment-5c8c9cc69d-,Namespace:deployment-5446,SelfLink:/api/v1/namespaces/deployment-5446/pods/test-recreate-deployment-5c8c9cc69d-fddm4,UID:bda2b37b-2112-4a5c-97e5-d101716aa105,ResourceVersion:124659825,Generation:0,CreationTimestamp:2019-08-09 13:50:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-5c8c9cc69d 1b9516f6-2e29-4395-96ef-6970a03734e4 0xc000877897 0xc000877898}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-ckq8j {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-ckq8j,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-ckq8j true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000877900} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000877920}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 13:50:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 13:50:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 13:50:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 13:50:09 +0000 UTC  }],Message:,Reason:,HostIP:10.12.129.91,PodIP:,StartTime:2019-08-09 13:50:09 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:50:09.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5446" for this suite.
Aug  9 13:50:15.488: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:50:15.906: INFO: namespace deployment-5446 deletion completed in 6.458716663s

• [SLOW TEST:11.119 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:50:15.911: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4852
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1211
STEP: creating the pod
Aug  9 13:50:16.162: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 create -f - --namespace=kubectl-4852'
Aug  9 13:50:16.768: INFO: stderr: ""
Aug  9 13:50:16.768: INFO: stdout: "pod/pause created\n"
Aug  9 13:50:16.768: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Aug  9 13:50:16.768: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-4852" to be "running and ready"
Aug  9 13:50:16.781: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 13.356711ms
Aug  9 13:50:18.791: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022680481s
Aug  9 13:50:20.802: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.033515699s
Aug  9 13:50:20.802: INFO: Pod "pause" satisfied condition "running and ready"
Aug  9 13:50:20.802: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: adding the label testing-label with value testing-label-value to a pod
Aug  9 13:50:20.802: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 label pods pause testing-label=testing-label-value --namespace=kubectl-4852'
Aug  9 13:50:21.064: INFO: stderr: ""
Aug  9 13:50:21.064: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Aug  9 13:50:21.065: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 get pod pause -L testing-label --namespace=kubectl-4852'
Aug  9 13:50:21.318: INFO: stderr: ""
Aug  9 13:50:21.318: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Aug  9 13:50:21.318: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 label pods pause testing-label- --namespace=kubectl-4852'
Aug  9 13:50:21.589: INFO: stderr: ""
Aug  9 13:50:21.589: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Aug  9 13:50:21.589: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 get pod pause -L testing-label --namespace=kubectl-4852'
Aug  9 13:50:21.812: INFO: stderr: ""
Aug  9 13:50:21.812: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1218
STEP: using delete to clean up resources
Aug  9 13:50:21.812: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 delete --grace-period=0 --force -f - --namespace=kubectl-4852'
Aug  9 13:50:22.029: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug  9 13:50:22.029: INFO: stdout: "pod \"pause\" force deleted\n"
Aug  9 13:50:22.029: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 get rc,svc -l name=pause --no-headers --namespace=kubectl-4852'
Aug  9 13:50:22.328: INFO: stderr: "No resources found.\n"
Aug  9 13:50:22.328: INFO: stdout: ""
Aug  9 13:50:22.328: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 get pods -l name=pause --namespace=kubectl-4852 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug  9 13:50:22.715: INFO: stderr: ""
Aug  9 13:50:22.715: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:50:22.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4852" for this suite.
Aug  9 13:50:28.771: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:50:29.101: INFO: namespace kubectl-4852 deletion completed in 6.372547762s

• [SLOW TEST:13.190 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl label
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:50:29.103: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-8198
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0809 13:50:39.652938      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug  9 13:50:39.653: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:50:39.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8198" for this suite.
Aug  9 13:50:47.714: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:50:48.066: INFO: namespace gc-8198 deletion completed in 8.400502087s

• [SLOW TEST:18.964 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:50:48.068: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4716
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Aug  9 13:50:48.401: INFO: Waiting up to 5m0s for pod "downward-api-1bdb2253-e901-4ff0-9494-bba22eae6a94" in namespace "downward-api-4716" to be "success or failure"
Aug  9 13:50:48.414: INFO: Pod "downward-api-1bdb2253-e901-4ff0-9494-bba22eae6a94": Phase="Pending", Reason="", readiness=false. Elapsed: 13.221032ms
Aug  9 13:50:50.504: INFO: Pod "downward-api-1bdb2253-e901-4ff0-9494-bba22eae6a94": Phase="Pending", Reason="", readiness=false. Elapsed: 2.103261059s
Aug  9 13:50:52.516: INFO: Pod "downward-api-1bdb2253-e901-4ff0-9494-bba22eae6a94": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.115032957s
STEP: Saw pod success
Aug  9 13:50:52.516: INFO: Pod "downward-api-1bdb2253-e901-4ff0-9494-bba22eae6a94" satisfied condition "success or failure"
Aug  9 13:50:52.527: INFO: Trying to get logs from node scw-flan15-default-fbc750a75c7f4c499b691cc5ccd pod downward-api-1bdb2253-e901-4ff0-9494-bba22eae6a94 container dapi-container: <nil>
STEP: delete the pod
Aug  9 13:50:52.596: INFO: Waiting for pod downward-api-1bdb2253-e901-4ff0-9494-bba22eae6a94 to disappear
Aug  9 13:50:52.610: INFO: Pod downward-api-1bdb2253-e901-4ff0-9494-bba22eae6a94 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:50:52.610: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4716" for this suite.
Aug  9 13:50:58.665: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:50:58.999: INFO: namespace downward-api-4716 deletion completed in 6.373188175s

• [SLOW TEST:10.932 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:50:59.001: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9279
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on node default medium
Aug  9 13:50:59.280: INFO: Waiting up to 5m0s for pod "pod-e03b074b-45c5-4048-a7c3-190d45dac9be" in namespace "emptydir-9279" to be "success or failure"
Aug  9 13:50:59.289: INFO: Pod "pod-e03b074b-45c5-4048-a7c3-190d45dac9be": Phase="Pending", Reason="", readiness=false. Elapsed: 9.343343ms
Aug  9 13:51:01.301: INFO: Pod "pod-e03b074b-45c5-4048-a7c3-190d45dac9be": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020722806s
Aug  9 13:51:03.311: INFO: Pod "pod-e03b074b-45c5-4048-a7c3-190d45dac9be": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03127621s
STEP: Saw pod success
Aug  9 13:51:03.311: INFO: Pod "pod-e03b074b-45c5-4048-a7c3-190d45dac9be" satisfied condition "success or failure"
Aug  9 13:51:03.321: INFO: Trying to get logs from node scw-flan15-default-f07a9b7e282146a6b5427e9aba2 pod pod-e03b074b-45c5-4048-a7c3-190d45dac9be container test-container: <nil>
STEP: delete the pod
Aug  9 13:51:03.396: INFO: Waiting for pod pod-e03b074b-45c5-4048-a7c3-190d45dac9be to disappear
Aug  9 13:51:03.404: INFO: Pod pod-e03b074b-45c5-4048-a7c3-190d45dac9be no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:51:03.404: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9279" for this suite.
Aug  9 13:51:09.463: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:51:09.785: INFO: namespace emptydir-9279 deletion completed in 6.365849268s

• [SLOW TEST:10.784 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:51:09.785: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1687
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on node default medium
Aug  9 13:51:10.117: INFO: Waiting up to 5m0s for pod "pod-2a9ef358-b036-4bcb-911a-5963d4d19e21" in namespace "emptydir-1687" to be "success or failure"
Aug  9 13:51:10.144: INFO: Pod "pod-2a9ef358-b036-4bcb-911a-5963d4d19e21": Phase="Pending", Reason="", readiness=false. Elapsed: 27.074046ms
Aug  9 13:51:12.165: INFO: Pod "pod-2a9ef358-b036-4bcb-911a-5963d4d19e21": Phase="Pending", Reason="", readiness=false. Elapsed: 2.047666361s
Aug  9 13:51:14.184: INFO: Pod "pod-2a9ef358-b036-4bcb-911a-5963d4d19e21": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.066687864s
STEP: Saw pod success
Aug  9 13:51:14.184: INFO: Pod "pod-2a9ef358-b036-4bcb-911a-5963d4d19e21" satisfied condition "success or failure"
Aug  9 13:51:14.207: INFO: Trying to get logs from node scw-flan15-default-fbc750a75c7f4c499b691cc5ccd pod pod-2a9ef358-b036-4bcb-911a-5963d4d19e21 container test-container: <nil>
STEP: delete the pod
Aug  9 13:51:14.277: INFO: Waiting for pod pod-2a9ef358-b036-4bcb-911a-5963d4d19e21 to disappear
Aug  9 13:51:14.287: INFO: Pod pod-2a9ef358-b036-4bcb-911a-5963d4d19e21 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:51:14.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1687" for this suite.
Aug  9 13:51:20.345: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:51:20.710: INFO: namespace emptydir-1687 deletion completed in 6.40912714s

• [SLOW TEST:10.925 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:51:20.713: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4212
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1558
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug  9 13:51:20.927: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/apps.v1 --namespace=kubectl-4212'
Aug  9 13:51:21.149: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug  9 13:51:21.149: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
Aug  9 13:51:25.183: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 delete deployment e2e-test-nginx-deployment --namespace=kubectl-4212'
Aug  9 13:51:25.376: INFO: stderr: ""
Aug  9 13:51:25.376: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:51:25.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4212" for this suite.
Aug  9 13:51:49.440: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:51:49.803: INFO: namespace kubectl-4212 deletion completed in 24.39850819s

• [SLOW TEST:29.091 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:51:49.804: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-3134
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3134.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3134.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Aug  9 13:51:54.706: INFO: DNS probes using dns-3134/dns-test-4c8cb834-32be-44e6-a777-a932b52060ae succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:51:54.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3134" for this suite.
Aug  9 13:52:00.809: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:52:01.153: INFO: namespace dns-3134 deletion completed in 6.376130743s

• [SLOW TEST:11.348 seconds]
[sig-network] DNS
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:52:01.154: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1186
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: validating api versions
Aug  9 13:52:01.385: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 api-versions'
Aug  9 13:52:01.645: INFO: stderr: ""
Aug  9 13:52:01.645: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:52:01.645: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1186" for this suite.
Aug  9 13:52:07.737: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:52:08.112: INFO: namespace kubectl-1186 deletion completed in 6.41945451s

• [SLOW TEST:6.957 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:52:08.112: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3849
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-70973e64-071a-4b95-bdb7-a236bfb06c1c
STEP: Creating a pod to test consume configMaps
Aug  9 13:52:08.415: INFO: Waiting up to 5m0s for pod "pod-configmaps-fba8af43-60a0-43b4-9797-9b10a8723007" in namespace "configmap-3849" to be "success or failure"
Aug  9 13:52:08.427: INFO: Pod "pod-configmaps-fba8af43-60a0-43b4-9797-9b10a8723007": Phase="Pending", Reason="", readiness=false. Elapsed: 12.580343ms
Aug  9 13:52:10.440: INFO: Pod "pod-configmaps-fba8af43-60a0-43b4-9797-9b10a8723007": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025750647s
Aug  9 13:52:12.454: INFO: Pod "pod-configmaps-fba8af43-60a0-43b4-9797-9b10a8723007": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.039346725s
STEP: Saw pod success
Aug  9 13:52:12.454: INFO: Pod "pod-configmaps-fba8af43-60a0-43b4-9797-9b10a8723007" satisfied condition "success or failure"
Aug  9 13:52:12.462: INFO: Trying to get logs from node scw-flan15-default-f07a9b7e282146a6b5427e9aba2 pod pod-configmaps-fba8af43-60a0-43b4-9797-9b10a8723007 container configmap-volume-test: <nil>
STEP: delete the pod
Aug  9 13:52:12.526: INFO: Waiting for pod pod-configmaps-fba8af43-60a0-43b4-9797-9b10a8723007 to disappear
Aug  9 13:52:12.538: INFO: Pod pod-configmaps-fba8af43-60a0-43b4-9797-9b10a8723007 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:52:12.538: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3849" for this suite.
Aug  9 13:52:18.609: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:52:18.966: INFO: namespace configmap-3849 deletion completed in 6.413753947s

• [SLOW TEST:10.854 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:52:18.968: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4125
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug  9 13:52:19.213: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9e69963a-4506-4678-a857-3deaffeb440f" in namespace "projected-4125" to be "success or failure"
Aug  9 13:52:19.226: INFO: Pod "downwardapi-volume-9e69963a-4506-4678-a857-3deaffeb440f": Phase="Pending", Reason="", readiness=false. Elapsed: 13.155417ms
Aug  9 13:52:21.245: INFO: Pod "downwardapi-volume-9e69963a-4506-4678-a857-3deaffeb440f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032139615s
Aug  9 13:52:23.256: INFO: Pod "downwardapi-volume-9e69963a-4506-4678-a857-3deaffeb440f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.043251394s
STEP: Saw pod success
Aug  9 13:52:23.256: INFO: Pod "downwardapi-volume-9e69963a-4506-4678-a857-3deaffeb440f" satisfied condition "success or failure"
Aug  9 13:52:23.269: INFO: Trying to get logs from node scw-flan15-default-fbc750a75c7f4c499b691cc5ccd pod downwardapi-volume-9e69963a-4506-4678-a857-3deaffeb440f container client-container: <nil>
STEP: delete the pod
Aug  9 13:52:23.344: INFO: Waiting for pod downwardapi-volume-9e69963a-4506-4678-a857-3deaffeb440f to disappear
Aug  9 13:52:23.353: INFO: Pod downwardapi-volume-9e69963a-4506-4678-a857-3deaffeb440f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:52:23.353: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4125" for this suite.
Aug  9 13:52:29.407: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:52:29.743: INFO: namespace projected-4125 deletion completed in 6.377585678s

• [SLOW TEST:10.775 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:52:29.743: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-1632
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug  9 13:52:50.017: INFO: Container started at 2019-08-09 13:52:31 +0000 UTC, pod became ready at 2019-08-09 13:52:48 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:52:50.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1632" for this suite.
Aug  9 13:53:14.100: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:53:14.553: INFO: namespace container-probe-1632 deletion completed in 24.512708664s

• [SLOW TEST:44.810 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:53:14.558: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-4572
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Aug  9 13:53:14.782: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:53:19.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4572" for this suite.
Aug  9 13:53:25.192: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:53:25.553: INFO: namespace init-container-4572 deletion completed in 6.410188848s

• [SLOW TEST:10.996 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:53:25.555: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-697
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug  9 13:53:25.825: INFO: (0) /api/v1/nodes/scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 27.768237ms)
Aug  9 13:53:25.839: INFO: (1) /api/v1/nodes/scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 13.865633ms)
Aug  9 13:53:25.859: INFO: (2) /api/v1/nodes/scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 20.000125ms)
Aug  9 13:53:25.872: INFO: (3) /api/v1/nodes/scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 12.56886ms)
Aug  9 13:53:25.891: INFO: (4) /api/v1/nodes/scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 18.616657ms)
Aug  9 13:53:25.903: INFO: (5) /api/v1/nodes/scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 11.840646ms)
Aug  9 13:53:25.914: INFO: (6) /api/v1/nodes/scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 11.108938ms)
Aug  9 13:53:25.925: INFO: (7) /api/v1/nodes/scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 10.696209ms)
Aug  9 13:53:25.939: INFO: (8) /api/v1/nodes/scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 13.465729ms)
Aug  9 13:53:25.952: INFO: (9) /api/v1/nodes/scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 13.758341ms)
Aug  9 13:53:25.966: INFO: (10) /api/v1/nodes/scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 13.22171ms)
Aug  9 13:53:25.978: INFO: (11) /api/v1/nodes/scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 11.942709ms)
Aug  9 13:53:26.000: INFO: (12) /api/v1/nodes/scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 21.993974ms)
Aug  9 13:53:26.017: INFO: (13) /api/v1/nodes/scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 16.821867ms)
Aug  9 13:53:26.029: INFO: (14) /api/v1/nodes/scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 12.021357ms)
Aug  9 13:53:26.044: INFO: (15) /api/v1/nodes/scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 14.426891ms)
Aug  9 13:53:26.058: INFO: (16) /api/v1/nodes/scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 13.79504ms)
Aug  9 13:53:26.072: INFO: (17) /api/v1/nodes/scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 13.596727ms)
Aug  9 13:53:26.085: INFO: (18) /api/v1/nodes/scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 13.412009ms)
Aug  9 13:53:26.123: INFO: (19) /api/v1/nodes/scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 37.930711ms)
[AfterEach] version v1
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:53:26.124: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-697" for this suite.
Aug  9 13:53:32.178: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:53:32.564: INFO: namespace proxy-697 deletion completed in 6.426057294s

• [SLOW TEST:7.009 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:53:32.565: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-6383
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:54:32.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6383" for this suite.
Aug  9 13:54:56.929: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:54:57.302: INFO: namespace container-probe-6383 deletion completed in 24.419466429s

• [SLOW TEST:84.737 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:54:57.303: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5105
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name cm-test-opt-del-09767084-8f4b-4b30-a944-e0b823a10c24
STEP: Creating configMap with name cm-test-opt-upd-aac5aaa8-bdfb-445d-9b7c-df05f5863439
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-09767084-8f4b-4b30-a944-e0b823a10c24
STEP: Updating configmap cm-test-opt-upd-aac5aaa8-bdfb-445d-9b7c-df05f5863439
STEP: Creating configMap with name cm-test-opt-create-c6c5a3f4-ddde-41a8-a3f4-55cc42f7dc8b
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:55:06.004: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5105" for this suite.
Aug  9 13:55:30.072: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:55:30.411: INFO: namespace configmap-5105 deletion completed in 24.392698655s

• [SLOW TEST:33.109 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:55:30.412: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7506
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-c575cd50-2e02-4933-929a-e563a7c47207
STEP: Creating a pod to test consume configMaps
Aug  9 13:55:30.728: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-2d5af11c-b2cf-45bb-b20b-8318c7f73a11" in namespace "projected-7506" to be "success or failure"
Aug  9 13:55:30.741: INFO: Pod "pod-projected-configmaps-2d5af11c-b2cf-45bb-b20b-8318c7f73a11": Phase="Pending", Reason="", readiness=false. Elapsed: 13.09068ms
Aug  9 13:55:32.766: INFO: Pod "pod-projected-configmaps-2d5af11c-b2cf-45bb-b20b-8318c7f73a11": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037543891s
Aug  9 13:55:34.777: INFO: Pod "pod-projected-configmaps-2d5af11c-b2cf-45bb-b20b-8318c7f73a11": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.048142918s
STEP: Saw pod success
Aug  9 13:55:34.777: INFO: Pod "pod-projected-configmaps-2d5af11c-b2cf-45bb-b20b-8318c7f73a11" satisfied condition "success or failure"
Aug  9 13:55:34.785: INFO: Trying to get logs from node scw-flan15-default-fbc750a75c7f4c499b691cc5ccd pod pod-projected-configmaps-2d5af11c-b2cf-45bb-b20b-8318c7f73a11 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug  9 13:55:34.848: INFO: Waiting for pod pod-projected-configmaps-2d5af11c-b2cf-45bb-b20b-8318c7f73a11 to disappear
Aug  9 13:55:34.859: INFO: Pod pod-projected-configmaps-2d5af11c-b2cf-45bb-b20b-8318c7f73a11 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:55:34.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7506" for this suite.
Aug  9 13:55:40.939: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:55:41.330: INFO: namespace projected-7506 deletion completed in 6.44003378s

• [SLOW TEST:10.918 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:55:41.335: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-925
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-925
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug  9 13:55:41.558: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Aug  9 13:56:04.021: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.64.0.56:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-925 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  9 13:56:04.021: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
Aug  9 13:56:04.481: INFO: Found all expected endpoints: [netserver-0]
Aug  9 13:56:04.496: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.64.1.74:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-925 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  9 13:56:04.496: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
Aug  9 13:56:04.942: INFO: Found all expected endpoints: [netserver-1]
Aug  9 13:56:04.951: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.64.2.56:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-925 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  9 13:56:04.951: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
Aug  9 13:56:05.336: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:56:05.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-925" for this suite.
Aug  9 13:56:29.403: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:56:29.784: INFO: namespace pod-network-test-925 deletion completed in 24.43148891s

• [SLOW TEST:48.449 seconds]
[sig-network] Networking
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:56:29.785: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7858
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on tmpfs
Aug  9 13:56:30.026: INFO: Waiting up to 5m0s for pod "pod-d93b4813-0771-4780-832f-403c5deb79b6" in namespace "emptydir-7858" to be "success or failure"
Aug  9 13:56:30.035: INFO: Pod "pod-d93b4813-0771-4780-832f-403c5deb79b6": Phase="Pending", Reason="", readiness=false. Elapsed: 9.120676ms
Aug  9 13:56:32.047: INFO: Pod "pod-d93b4813-0771-4780-832f-403c5deb79b6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020703787s
Aug  9 13:56:34.058: INFO: Pod "pod-d93b4813-0771-4780-832f-403c5deb79b6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031655664s
STEP: Saw pod success
Aug  9 13:56:34.058: INFO: Pod "pod-d93b4813-0771-4780-832f-403c5deb79b6" satisfied condition "success or failure"
Aug  9 13:56:34.068: INFO: Trying to get logs from node scw-flan15-default-f07a9b7e282146a6b5427e9aba2 pod pod-d93b4813-0771-4780-832f-403c5deb79b6 container test-container: <nil>
STEP: delete the pod
Aug  9 13:56:34.139: INFO: Waiting for pod pod-d93b4813-0771-4780-832f-403c5deb79b6 to disappear
Aug  9 13:56:34.147: INFO: Pod pod-d93b4813-0771-4780-832f-403c5deb79b6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:56:34.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7858" for this suite.
Aug  9 13:56:40.200: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:56:40.580: INFO: namespace emptydir-7858 deletion completed in 6.419075712s

• [SLOW TEST:10.796 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:56:40.584: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6870
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-map-4766c64c-a0bc-4801-89b0-a95f50483edb
STEP: Creating a pod to test consume secrets
Aug  9 13:56:40.892: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-1e51c7c6-fb2b-41b6-9bce-d12bb51c518a" in namespace "projected-6870" to be "success or failure"
Aug  9 13:56:40.907: INFO: Pod "pod-projected-secrets-1e51c7c6-fb2b-41b6-9bce-d12bb51c518a": Phase="Pending", Reason="", readiness=false. Elapsed: 14.024817ms
Aug  9 13:56:42.939: INFO: Pod "pod-projected-secrets-1e51c7c6-fb2b-41b6-9bce-d12bb51c518a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.046177818s
Aug  9 13:56:44.950: INFO: Pod "pod-projected-secrets-1e51c7c6-fb2b-41b6-9bce-d12bb51c518a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.057280877s
STEP: Saw pod success
Aug  9 13:56:44.950: INFO: Pod "pod-projected-secrets-1e51c7c6-fb2b-41b6-9bce-d12bb51c518a" satisfied condition "success or failure"
Aug  9 13:56:44.960: INFO: Trying to get logs from node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d pod pod-projected-secrets-1e51c7c6-fb2b-41b6-9bce-d12bb51c518a container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug  9 13:56:45.069: INFO: Waiting for pod pod-projected-secrets-1e51c7c6-fb2b-41b6-9bce-d12bb51c518a to disappear
Aug  9 13:56:45.084: INFO: Pod pod-projected-secrets-1e51c7c6-fb2b-41b6-9bce-d12bb51c518a no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:56:45.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6870" for this suite.
Aug  9 13:56:53.164: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:56:53.543: INFO: namespace projected-6870 deletion completed in 8.442200962s

• [SLOW TEST:12.960 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:56:53.543: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2658
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-map-cce0a8a7-af9b-40a0-a9c6-8814b192f98a
STEP: Creating a pod to test consume secrets
Aug  9 13:56:53.815: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-07c72b8e-3ad8-4106-9df1-e168ed6a5e8f" in namespace "projected-2658" to be "success or failure"
Aug  9 13:56:53.828: INFO: Pod "pod-projected-secrets-07c72b8e-3ad8-4106-9df1-e168ed6a5e8f": Phase="Pending", Reason="", readiness=false. Elapsed: 13.328887ms
Aug  9 13:56:55.844: INFO: Pod "pod-projected-secrets-07c72b8e-3ad8-4106-9df1-e168ed6a5e8f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02929638s
Aug  9 13:56:57.854: INFO: Pod "pod-projected-secrets-07c72b8e-3ad8-4106-9df1-e168ed6a5e8f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038578889s
STEP: Saw pod success
Aug  9 13:56:57.854: INFO: Pod "pod-projected-secrets-07c72b8e-3ad8-4106-9df1-e168ed6a5e8f" satisfied condition "success or failure"
Aug  9 13:56:57.863: INFO: Trying to get logs from node scw-flan15-default-fbc750a75c7f4c499b691cc5ccd pod pod-projected-secrets-07c72b8e-3ad8-4106-9df1-e168ed6a5e8f container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug  9 13:56:57.921: INFO: Waiting for pod pod-projected-secrets-07c72b8e-3ad8-4106-9df1-e168ed6a5e8f to disappear
Aug  9 13:56:57.935: INFO: Pod pod-projected-secrets-07c72b8e-3ad8-4106-9df1-e168ed6a5e8f no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:56:57.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2658" for this suite.
Aug  9 13:57:04.010: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:57:04.580: INFO: namespace projected-2658 deletion completed in 6.62593441s

• [SLOW TEST:11.037 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:57:04.582: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4646
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1517
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug  9 13:57:04.836: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-4646'
Aug  9 13:57:05.662: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug  9 13:57:05.662: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Aug  9 13:57:05.678: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Aug  9 13:57:05.708: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Aug  9 13:57:05.720: INFO: scanned /root for discovery docs: <nil>
Aug  9 13:57:05.720: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-4646'
Aug  9 13:57:22.112: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Aug  9 13:57:22.112: INFO: stdout: "Created e2e-test-nginx-rc-75ca437fe4f2f5ef18dbe84b323e3a42\nScaling up e2e-test-nginx-rc-75ca437fe4f2f5ef18dbe84b323e3a42 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-75ca437fe4f2f5ef18dbe84b323e3a42 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-75ca437fe4f2f5ef18dbe84b323e3a42 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Aug  9 13:57:22.112: INFO: stdout: "Created e2e-test-nginx-rc-75ca437fe4f2f5ef18dbe84b323e3a42\nScaling up e2e-test-nginx-rc-75ca437fe4f2f5ef18dbe84b323e3a42 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-75ca437fe4f2f5ef18dbe84b323e3a42 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-75ca437fe4f2f5ef18dbe84b323e3a42 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Aug  9 13:57:22.112: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-4646'
Aug  9 13:57:22.308: INFO: stderr: ""
Aug  9 13:57:22.308: INFO: stdout: "e2e-test-nginx-rc-75ca437fe4f2f5ef18dbe84b323e3a42-m9dpt "
Aug  9 13:57:22.308: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 get pods e2e-test-nginx-rc-75ca437fe4f2f5ef18dbe84b323e3a42-m9dpt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4646'
Aug  9 13:57:22.494: INFO: stderr: ""
Aug  9 13:57:22.494: INFO: stdout: "true"
Aug  9 13:57:22.494: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 get pods e2e-test-nginx-rc-75ca437fe4f2f5ef18dbe84b323e3a42-m9dpt -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4646'
Aug  9 13:57:22.664: INFO: stderr: ""
Aug  9 13:57:22.664: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Aug  9 13:57:22.664: INFO: e2e-test-nginx-rc-75ca437fe4f2f5ef18dbe84b323e3a42-m9dpt is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1523
Aug  9 13:57:22.664: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 delete rc e2e-test-nginx-rc --namespace=kubectl-4646'
Aug  9 13:57:22.834: INFO: stderr: ""
Aug  9 13:57:22.834: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:57:22.834: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4646" for this suite.
Aug  9 13:57:46.947: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:57:47.329: INFO: namespace kubectl-4646 deletion completed in 24.430057071s

• [SLOW TEST:42.747 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:57:47.329: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-3702
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-3702
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug  9 13:57:47.542: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Aug  9 13:58:11.827: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.64.0.60:8080/dial?request=hostName&protocol=udp&host=100.64.2.58&port=8081&tries=1'] Namespace:pod-network-test-3702 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  9 13:58:11.827: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
Aug  9 13:58:12.206: INFO: Waiting for endpoints: map[]
Aug  9 13:58:12.217: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.64.0.60:8080/dial?request=hostName&protocol=udp&host=100.64.1.78&port=8081&tries=1'] Namespace:pod-network-test-3702 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  9 13:58:12.217: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
Aug  9 13:58:12.788: INFO: Waiting for endpoints: map[]
Aug  9 13:58:12.804: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.64.0.60:8080/dial?request=hostName&protocol=udp&host=100.64.0.59&port=8081&tries=1'] Namespace:pod-network-test-3702 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  9 13:58:12.804: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
Aug  9 13:58:13.365: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:58:13.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3702" for this suite.
Aug  9 13:58:37.488: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:58:37.874: INFO: namespace pod-network-test-3702 deletion completed in 24.466029301s

• [SLOW TEST:50.546 seconds]
[sig-network] Networking
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:58:37.876: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5211
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug  9 13:58:38.140: INFO: Waiting up to 5m0s for pod "downwardapi-volume-782f96d1-b8c8-4a27-8edb-d0a196e6aaec" in namespace "downward-api-5211" to be "success or failure"
Aug  9 13:58:38.157: INFO: Pod "downwardapi-volume-782f96d1-b8c8-4a27-8edb-d0a196e6aaec": Phase="Pending", Reason="", readiness=false. Elapsed: 16.144489ms
Aug  9 13:58:40.168: INFO: Pod "downwardapi-volume-782f96d1-b8c8-4a27-8edb-d0a196e6aaec": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027725786s
Aug  9 13:58:42.186: INFO: Pod "downwardapi-volume-782f96d1-b8c8-4a27-8edb-d0a196e6aaec": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.045204379s
STEP: Saw pod success
Aug  9 13:58:42.186: INFO: Pod "downwardapi-volume-782f96d1-b8c8-4a27-8edb-d0a196e6aaec" satisfied condition "success or failure"
Aug  9 13:58:42.208: INFO: Trying to get logs from node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d pod downwardapi-volume-782f96d1-b8c8-4a27-8edb-d0a196e6aaec container client-container: <nil>
STEP: delete the pod
Aug  9 13:58:42.277: INFO: Waiting for pod downwardapi-volume-782f96d1-b8c8-4a27-8edb-d0a196e6aaec to disappear
Aug  9 13:58:42.287: INFO: Pod downwardapi-volume-782f96d1-b8c8-4a27-8edb-d0a196e6aaec no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:58:42.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5211" for this suite.
Aug  9 13:58:48.337: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:58:48.680: INFO: namespace downward-api-5211 deletion completed in 6.38077721s

• [SLOW TEST:10.805 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:58:48.683: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8828
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on node default medium
Aug  9 13:58:49.003: INFO: Waiting up to 5m0s for pod "pod-298d6f81-e4ca-4b47-846c-752cf1b9a367" in namespace "emptydir-8828" to be "success or failure"
Aug  9 13:58:49.013: INFO: Pod "pod-298d6f81-e4ca-4b47-846c-752cf1b9a367": Phase="Pending", Reason="", readiness=false. Elapsed: 10.462544ms
Aug  9 13:58:51.027: INFO: Pod "pod-298d6f81-e4ca-4b47-846c-752cf1b9a367": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024029366s
Aug  9 13:58:53.045: INFO: Pod "pod-298d6f81-e4ca-4b47-846c-752cf1b9a367": Phase="Pending", Reason="", readiness=false. Elapsed: 4.042491367s
Aug  9 13:58:55.055: INFO: Pod "pod-298d6f81-e4ca-4b47-846c-752cf1b9a367": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.052769261s
STEP: Saw pod success
Aug  9 13:58:55.055: INFO: Pod "pod-298d6f81-e4ca-4b47-846c-752cf1b9a367" satisfied condition "success or failure"
Aug  9 13:58:55.066: INFO: Trying to get logs from node scw-flan15-default-fbc750a75c7f4c499b691cc5ccd pod pod-298d6f81-e4ca-4b47-846c-752cf1b9a367 container test-container: <nil>
STEP: delete the pod
Aug  9 13:58:55.149: INFO: Waiting for pod pod-298d6f81-e4ca-4b47-846c-752cf1b9a367 to disappear
Aug  9 13:58:55.161: INFO: Pod pod-298d6f81-e4ca-4b47-846c-752cf1b9a367 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:58:55.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8828" for this suite.
Aug  9 13:59:01.217: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:59:01.668: INFO: namespace emptydir-8828 deletion completed in 6.483063461s

• [SLOW TEST:12.985 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:59:01.668: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-9502
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-8023
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-2680
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:59:08.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-9502" for this suite.
Aug  9 13:59:14.483: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:59:14.820: INFO: namespace namespaces-9502 deletion completed in 6.377181432s
STEP: Destroying namespace "nsdeletetest-8023" for this suite.
Aug  9 13:59:14.830: INFO: Namespace nsdeletetest-8023 was already deleted
STEP: Destroying namespace "nsdeletetest-2680" for this suite.
Aug  9 13:59:20.876: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 13:59:21.210: INFO: namespace nsdeletetest-2680 deletion completed in 6.378873304s

• [SLOW TEST:19.541 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 13:59:21.210: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-1580
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Aug  9 13:59:29.578: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug  9 13:59:29.589: INFO: Pod pod-with-prestop-http-hook still exists
Aug  9 13:59:31.590: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug  9 13:59:31.601: INFO: Pod pod-with-prestop-http-hook still exists
Aug  9 13:59:33.590: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug  9 13:59:33.609: INFO: Pod pod-with-prestop-http-hook still exists
Aug  9 13:59:35.590: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug  9 13:59:35.600: INFO: Pod pod-with-prestop-http-hook still exists
Aug  9 13:59:37.590: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Aug  9 13:59:37.604: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 13:59:37.627: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-1580" for this suite.
Aug  9 14:00:01.687: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:00:02.066: INFO: namespace container-lifecycle-hook-1580 deletion completed in 24.426227352s

• [SLOW TEST:40.857 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:00:02.067: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-5736
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-configmap-qj8r
STEP: Creating a pod to test atomic-volume-subpath
Aug  9 14:00:02.376: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-qj8r" in namespace "subpath-5736" to be "success or failure"
Aug  9 14:00:02.387: INFO: Pod "pod-subpath-test-configmap-qj8r": Phase="Pending", Reason="", readiness=false. Elapsed: 11.182ms
Aug  9 14:00:04.404: INFO: Pod "pod-subpath-test-configmap-qj8r": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027729674s
Aug  9 14:00:06.414: INFO: Pod "pod-subpath-test-configmap-qj8r": Phase="Running", Reason="", readiness=true. Elapsed: 4.038431992s
Aug  9 14:00:08.424: INFO: Pod "pod-subpath-test-configmap-qj8r": Phase="Running", Reason="", readiness=true. Elapsed: 6.048031659s
Aug  9 14:00:10.435: INFO: Pod "pod-subpath-test-configmap-qj8r": Phase="Running", Reason="", readiness=true. Elapsed: 8.058950386s
Aug  9 14:00:12.446: INFO: Pod "pod-subpath-test-configmap-qj8r": Phase="Running", Reason="", readiness=true. Elapsed: 10.069888239s
Aug  9 14:00:14.457: INFO: Pod "pod-subpath-test-configmap-qj8r": Phase="Running", Reason="", readiness=true. Elapsed: 12.081520424s
Aug  9 14:00:16.468: INFO: Pod "pod-subpath-test-configmap-qj8r": Phase="Running", Reason="", readiness=true. Elapsed: 14.09250904s
Aug  9 14:00:18.484: INFO: Pod "pod-subpath-test-configmap-qj8r": Phase="Running", Reason="", readiness=true. Elapsed: 16.108148576s
Aug  9 14:00:20.512: INFO: Pod "pod-subpath-test-configmap-qj8r": Phase="Running", Reason="", readiness=true. Elapsed: 18.136141574s
Aug  9 14:00:22.522: INFO: Pod "pod-subpath-test-configmap-qj8r": Phase="Running", Reason="", readiness=true. Elapsed: 20.146557563s
Aug  9 14:00:24.533: INFO: Pod "pod-subpath-test-configmap-qj8r": Phase="Running", Reason="", readiness=true. Elapsed: 22.156837099s
Aug  9 14:00:26.545: INFO: Pod "pod-subpath-test-configmap-qj8r": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.169045063s
STEP: Saw pod success
Aug  9 14:00:26.545: INFO: Pod "pod-subpath-test-configmap-qj8r" satisfied condition "success or failure"
Aug  9 14:00:26.554: INFO: Trying to get logs from node scw-flan15-default-fbc750a75c7f4c499b691cc5ccd pod pod-subpath-test-configmap-qj8r container test-container-subpath-configmap-qj8r: <nil>
STEP: delete the pod
Aug  9 14:00:26.639: INFO: Waiting for pod pod-subpath-test-configmap-qj8r to disappear
Aug  9 14:00:26.646: INFO: Pod pod-subpath-test-configmap-qj8r no longer exists
STEP: Deleting pod pod-subpath-test-configmap-qj8r
Aug  9 14:00:26.647: INFO: Deleting pod "pod-subpath-test-configmap-qj8r" in namespace "subpath-5736"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:00:26.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5736" for this suite.
Aug  9 14:00:32.711: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:00:33.029: INFO: namespace subpath-5736 deletion completed in 6.356133522s

• [SLOW TEST:30.963 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:00:33.031: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-802
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug  9 14:00:33.292: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7cd614f2-be8e-403a-9475-30e705640889" in namespace "projected-802" to be "success or failure"
Aug  9 14:00:33.313: INFO: Pod "downwardapi-volume-7cd614f2-be8e-403a-9475-30e705640889": Phase="Pending", Reason="", readiness=false. Elapsed: 20.62508ms
Aug  9 14:00:35.325: INFO: Pod "downwardapi-volume-7cd614f2-be8e-403a-9475-30e705640889": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032721006s
Aug  9 14:00:37.344: INFO: Pod "downwardapi-volume-7cd614f2-be8e-403a-9475-30e705640889": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.051769962s
STEP: Saw pod success
Aug  9 14:00:37.344: INFO: Pod "downwardapi-volume-7cd614f2-be8e-403a-9475-30e705640889" satisfied condition "success or failure"
Aug  9 14:00:37.362: INFO: Trying to get logs from node scw-flan15-default-f07a9b7e282146a6b5427e9aba2 pod downwardapi-volume-7cd614f2-be8e-403a-9475-30e705640889 container client-container: <nil>
STEP: delete the pod
Aug  9 14:00:37.431: INFO: Waiting for pod downwardapi-volume-7cd614f2-be8e-403a-9475-30e705640889 to disappear
Aug  9 14:00:37.441: INFO: Pod downwardapi-volume-7cd614f2-be8e-403a-9475-30e705640889 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:00:37.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-802" for this suite.
Aug  9 14:00:43.509: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:00:43.870: INFO: namespace projected-802 deletion completed in 6.417402524s

• [SLOW TEST:10.839 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:00:43.873: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1378
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-0224c63e-5647-4905-9c22-df73c8f0a1c5
STEP: Creating a pod to test consume secrets
Aug  9 14:00:44.137: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-8e8e286c-a9a7-4a85-966f-2935c202c4c1" in namespace "projected-1378" to be "success or failure"
Aug  9 14:00:44.145: INFO: Pod "pod-projected-secrets-8e8e286c-a9a7-4a85-966f-2935c202c4c1": Phase="Pending", Reason="", readiness=false. Elapsed: 8.131571ms
Aug  9 14:00:46.158: INFO: Pod "pod-projected-secrets-8e8e286c-a9a7-4a85-966f-2935c202c4c1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020797582s
Aug  9 14:00:48.170: INFO: Pod "pod-projected-secrets-8e8e286c-a9a7-4a85-966f-2935c202c4c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03306663s
STEP: Saw pod success
Aug  9 14:00:48.170: INFO: Pod "pod-projected-secrets-8e8e286c-a9a7-4a85-966f-2935c202c4c1" satisfied condition "success or failure"
Aug  9 14:00:48.182: INFO: Trying to get logs from node scw-flan15-default-f07a9b7e282146a6b5427e9aba2 pod pod-projected-secrets-8e8e286c-a9a7-4a85-966f-2935c202c4c1 container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug  9 14:00:48.249: INFO: Waiting for pod pod-projected-secrets-8e8e286c-a9a7-4a85-966f-2935c202c4c1 to disappear
Aug  9 14:00:48.264: INFO: Pod pod-projected-secrets-8e8e286c-a9a7-4a85-966f-2935c202c4c1 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:00:48.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1378" for this suite.
Aug  9 14:00:54.316: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:00:54.704: INFO: namespace projected-1378 deletion completed in 6.427358656s

• [SLOW TEST:10.831 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:00:54.705: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6231
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-upd-9d0a6dfb-5d55-44c8-90b9-64ac2126000a
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:00:59.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6231" for this suite.
Aug  9 14:01:23.149: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:01:23.580: INFO: namespace configmap-6231 deletion completed in 24.472412211s

• [SLOW TEST:28.875 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:01:23.580: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-3785
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating service endpoint-test2 in namespace services-3785
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3785 to expose endpoints map[]
Aug  9 14:01:23.853: INFO: successfully validated that service endpoint-test2 in namespace services-3785 exposes endpoints map[] (11.704943ms elapsed)
STEP: Creating pod pod1 in namespace services-3785
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3785 to expose endpoints map[pod1:[80]]
Aug  9 14:01:26.961: INFO: successfully validated that service endpoint-test2 in namespace services-3785 exposes endpoints map[pod1:[80]] (3.081652514s elapsed)
STEP: Creating pod pod2 in namespace services-3785
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3785 to expose endpoints map[pod1:[80] pod2:[80]]
Aug  9 14:01:30.213: INFO: successfully validated that service endpoint-test2 in namespace services-3785 exposes endpoints map[pod1:[80] pod2:[80]] (3.213575667s elapsed)
STEP: Deleting pod pod1 in namespace services-3785
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3785 to expose endpoints map[pod2:[80]]
Aug  9 14:01:31.299: INFO: successfully validated that service endpoint-test2 in namespace services-3785 exposes endpoints map[pod2:[80]] (1.066365925s elapsed)
STEP: Deleting pod pod2 in namespace services-3785
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3785 to expose endpoints map[]
Aug  9 14:01:32.341: INFO: successfully validated that service endpoint-test2 in namespace services-3785 exposes endpoints map[] (1.019988926s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:01:32.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3785" for this suite.
Aug  9 14:01:56.504: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:01:56.843: INFO: namespace services-3785 deletion completed in 24.393712553s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:33.263 seconds]
[sig-network] Services
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:01:56.845: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-1450
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Aug  9 14:02:00.153: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:02:00.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1450" for this suite.
Aug  9 14:02:06.264: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:02:06.661: INFO: namespace container-runtime-1450 deletion completed in 6.439085259s

• [SLOW TEST:9.817 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:02:06.662: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-2084
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-5967b3e3-8a85-47aa-a684-02287e443852
STEP: Creating a pod to test consume secrets
Aug  9 14:02:06.948: INFO: Waiting up to 5m0s for pod "pod-secrets-31c52e5a-848f-4e57-a06d-ac9d7785ef5f" in namespace "secrets-2084" to be "success or failure"
Aug  9 14:02:06.982: INFO: Pod "pod-secrets-31c52e5a-848f-4e57-a06d-ac9d7785ef5f": Phase="Pending", Reason="", readiness=false. Elapsed: 34.243015ms
Aug  9 14:02:09.003: INFO: Pod "pod-secrets-31c52e5a-848f-4e57-a06d-ac9d7785ef5f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.055381152s
Aug  9 14:02:11.017: INFO: Pod "pod-secrets-31c52e5a-848f-4e57-a06d-ac9d7785ef5f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.06890962s
STEP: Saw pod success
Aug  9 14:02:11.017: INFO: Pod "pod-secrets-31c52e5a-848f-4e57-a06d-ac9d7785ef5f" satisfied condition "success or failure"
Aug  9 14:02:11.028: INFO: Trying to get logs from node scw-flan15-default-fbc750a75c7f4c499b691cc5ccd pod pod-secrets-31c52e5a-848f-4e57-a06d-ac9d7785ef5f container secret-volume-test: <nil>
STEP: delete the pod
Aug  9 14:02:11.104: INFO: Waiting for pod pod-secrets-31c52e5a-848f-4e57-a06d-ac9d7785ef5f to disappear
Aug  9 14:02:11.112: INFO: Pod pod-secrets-31c52e5a-848f-4e57-a06d-ac9d7785ef5f no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:02:11.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2084" for this suite.
Aug  9 14:02:17.170: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:02:17.573: INFO: namespace secrets-2084 deletion completed in 6.441954627s

• [SLOW TEST:10.911 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:02:17.584: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2544
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1613
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug  9 14:02:17.809: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-2544'
Aug  9 14:02:18.099: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug  9 14:02:18.099: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1618
Aug  9 14:02:18.111: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 delete jobs e2e-test-nginx-job --namespace=kubectl-2544'
Aug  9 14:02:18.357: INFO: stderr: ""
Aug  9 14:02:18.357: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:02:18.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2544" for this suite.
Aug  9 14:02:24.410: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:02:24.728: INFO: namespace kubectl-2544 deletion completed in 6.358286631s

• [SLOW TEST:7.144 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run job
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:02:24.729: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5539
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug  9 14:02:24.971: INFO: Waiting up to 5m0s for pod "downwardapi-volume-36f997c9-01ac-4758-8399-06b5cb11d7f0" in namespace "downward-api-5539" to be "success or failure"
Aug  9 14:02:24.995: INFO: Pod "downwardapi-volume-36f997c9-01ac-4758-8399-06b5cb11d7f0": Phase="Pending", Reason="", readiness=false. Elapsed: 24.357109ms
Aug  9 14:02:27.018: INFO: Pod "downwardapi-volume-36f997c9-01ac-4758-8399-06b5cb11d7f0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.047484154s
STEP: Saw pod success
Aug  9 14:02:27.018: INFO: Pod "downwardapi-volume-36f997c9-01ac-4758-8399-06b5cb11d7f0" satisfied condition "success or failure"
Aug  9 14:02:27.028: INFO: Trying to get logs from node scw-flan15-default-f07a9b7e282146a6b5427e9aba2 pod downwardapi-volume-36f997c9-01ac-4758-8399-06b5cb11d7f0 container client-container: <nil>
STEP: delete the pod
Aug  9 14:02:27.104: INFO: Waiting for pod downwardapi-volume-36f997c9-01ac-4758-8399-06b5cb11d7f0 to disappear
Aug  9 14:02:27.112: INFO: Pod downwardapi-volume-36f997c9-01ac-4758-8399-06b5cb11d7f0 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:02:27.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5539" for this suite.
Aug  9 14:02:33.168: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:02:33.546: INFO: namespace downward-api-5539 deletion completed in 6.416410535s

• [SLOW TEST:8.817 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:02:33.546: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7896
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug  9 14:02:33.825: INFO: Waiting up to 5m0s for pod "downwardapi-volume-38055d3c-c7ca-4154-affa-317ec6886e7e" in namespace "projected-7896" to be "success or failure"
Aug  9 14:02:33.839: INFO: Pod "downwardapi-volume-38055d3c-c7ca-4154-affa-317ec6886e7e": Phase="Pending", Reason="", readiness=false. Elapsed: 13.580876ms
Aug  9 14:02:35.851: INFO: Pod "downwardapi-volume-38055d3c-c7ca-4154-affa-317ec6886e7e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025444348s
Aug  9 14:02:37.864: INFO: Pod "downwardapi-volume-38055d3c-c7ca-4154-affa-317ec6886e7e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038320633s
STEP: Saw pod success
Aug  9 14:02:37.864: INFO: Pod "downwardapi-volume-38055d3c-c7ca-4154-affa-317ec6886e7e" satisfied condition "success or failure"
Aug  9 14:02:37.874: INFO: Trying to get logs from node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d pod downwardapi-volume-38055d3c-c7ca-4154-affa-317ec6886e7e container client-container: <nil>
STEP: delete the pod
Aug  9 14:02:37.937: INFO: Waiting for pod downwardapi-volume-38055d3c-c7ca-4154-affa-317ec6886e7e to disappear
Aug  9 14:02:37.952: INFO: Pod downwardapi-volume-38055d3c-c7ca-4154-affa-317ec6886e7e no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:02:37.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7896" for this suite.
Aug  9 14:02:44.006: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:02:44.350: INFO: namespace projected-7896 deletion completed in 6.381099116s

• [SLOW TEST:10.804 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:02:44.351: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-4071
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod busybox-a938271c-4cd3-4491-b3f7-7b679e04345a in namespace container-probe-4071
Aug  9 14:02:48.653: INFO: Started pod busybox-a938271c-4cd3-4491-b3f7-7b679e04345a in namespace container-probe-4071
STEP: checking the pod's current state and verifying that restartCount is present
Aug  9 14:02:48.662: INFO: Initial restart count of pod busybox-a938271c-4cd3-4491-b3f7-7b679e04345a is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:06:50.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4071" for this suite.
Aug  9 14:06:56.486: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:06:56.854: INFO: namespace container-probe-4071 deletion completed in 6.413678458s

• [SLOW TEST:252.504 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:06:56.856: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-3903
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Aug  9 14:07:01.689: INFO: Successfully updated pod "pod-update-activedeadlineseconds-985990d8-0a89-4764-9cdf-ce72aceaa2a6"
Aug  9 14:07:01.689: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-985990d8-0a89-4764-9cdf-ce72aceaa2a6" in namespace "pods-3903" to be "terminated due to deadline exceeded"
Aug  9 14:07:01.698: INFO: Pod "pod-update-activedeadlineseconds-985990d8-0a89-4764-9cdf-ce72aceaa2a6": Phase="Running", Reason="", readiness=true. Elapsed: 8.919329ms
Aug  9 14:07:03.796: INFO: Pod "pod-update-activedeadlineseconds-985990d8-0a89-4764-9cdf-ce72aceaa2a6": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.106769942s
Aug  9 14:07:03.796: INFO: Pod "pod-update-activedeadlineseconds-985990d8-0a89-4764-9cdf-ce72aceaa2a6" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:07:03.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3903" for this suite.
Aug  9 14:07:09.856: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:07:10.263: INFO: namespace pods-3903 deletion completed in 6.449013728s

• [SLOW TEST:13.407 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:07:10.265: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-8279
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-8279
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating stateful set ss in namespace statefulset-8279
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-8279
Aug  9 14:07:10.544: INFO: Found 0 stateful pods, waiting for 1
Aug  9 14:07:20.555: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Aug  9 14:07:20.567: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-8279 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug  9 14:07:21.549: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug  9 14:07:21.550: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug  9 14:07:21.550: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug  9 14:07:21.561: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Aug  9 14:07:31.573: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug  9 14:07:31.573: INFO: Waiting for statefulset status.replicas updated to 0
Aug  9 14:07:31.614: INFO: POD   NODE                                            PHASE    GRACE  CONDITIONS
Aug  9 14:07:31.614: INFO: ss-0  scw-flan15-default-f07a9b7e282146a6b5427e9aba2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:10 +0000 UTC  }]
Aug  9 14:07:31.614: INFO: 
Aug  9 14:07:31.614: INFO: StatefulSet ss has not reached scale 3, at 1
Aug  9 14:07:32.628: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.992292114s
Aug  9 14:07:33.640: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.97764993s
Aug  9 14:07:34.653: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.965410347s
Aug  9 14:07:35.666: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.952048349s
Aug  9 14:07:36.679: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.939733747s
Aug  9 14:07:37.693: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.926890733s
Aug  9 14:07:38.709: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.912803881s
Aug  9 14:07:39.724: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.896261668s
Aug  9 14:07:40.734: INFO: Verifying statefulset ss doesn't scale past 3 for another 881.898125ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-8279
Aug  9 14:07:41.746: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-8279 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  9 14:07:42.188: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Aug  9 14:07:42.188: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug  9 14:07:42.188: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug  9 14:07:42.188: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-8279 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  9 14:07:42.618: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Aug  9 14:07:42.618: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug  9 14:07:42.618: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug  9 14:07:42.619: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-8279 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  9 14:07:43.154: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Aug  9 14:07:43.154: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug  9 14:07:43.154: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug  9 14:07:43.168: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Aug  9 14:07:43.168: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Aug  9 14:07:43.168: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Aug  9 14:07:43.180: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-8279 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug  9 14:07:43.625: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug  9 14:07:43.625: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug  9 14:07:43.625: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug  9 14:07:43.625: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-8279 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug  9 14:07:44.013: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug  9 14:07:44.013: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug  9 14:07:44.013: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug  9 14:07:44.013: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-8279 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug  9 14:07:44.578: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug  9 14:07:44.578: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug  9 14:07:44.578: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug  9 14:07:44.578: INFO: Waiting for statefulset status.replicas updated to 0
Aug  9 14:07:44.592: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Aug  9 14:07:54.612: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Aug  9 14:07:54.612: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Aug  9 14:07:54.612: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Aug  9 14:07:54.643: INFO: POD   NODE                                            PHASE    GRACE  CONDITIONS
Aug  9 14:07:54.643: INFO: ss-0  scw-flan15-default-f07a9b7e282146a6b5427e9aba2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:10 +0000 UTC  }]
Aug  9 14:07:54.643: INFO: ss-1  scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:31 +0000 UTC  }]
Aug  9 14:07:54.643: INFO: ss-2  scw-flan15-default-fbc750a75c7f4c499b691cc5ccd  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:31 +0000 UTC  }]
Aug  9 14:07:54.643: INFO: 
Aug  9 14:07:54.643: INFO: StatefulSet ss has not reached scale 0, at 3
Aug  9 14:07:55.656: INFO: POD   NODE                                            PHASE    GRACE  CONDITIONS
Aug  9 14:07:55.656: INFO: ss-0  scw-flan15-default-f07a9b7e282146a6b5427e9aba2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:10 +0000 UTC  }]
Aug  9 14:07:55.656: INFO: ss-1  scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:31 +0000 UTC  }]
Aug  9 14:07:55.656: INFO: ss-2  scw-flan15-default-fbc750a75c7f4c499b691cc5ccd  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:31 +0000 UTC  }]
Aug  9 14:07:55.656: INFO: 
Aug  9 14:07:55.656: INFO: StatefulSet ss has not reached scale 0, at 3
Aug  9 14:07:56.667: INFO: POD   NODE                                            PHASE    GRACE  CONDITIONS
Aug  9 14:07:56.668: INFO: ss-0  scw-flan15-default-f07a9b7e282146a6b5427e9aba2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:10 +0000 UTC  }]
Aug  9 14:07:56.668: INFO: ss-1  scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:31 +0000 UTC  }]
Aug  9 14:07:56.668: INFO: ss-2  scw-flan15-default-fbc750a75c7f4c499b691cc5ccd  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:31 +0000 UTC  }]
Aug  9 14:07:56.668: INFO: 
Aug  9 14:07:56.668: INFO: StatefulSet ss has not reached scale 0, at 3
Aug  9 14:07:57.680: INFO: POD   NODE                                            PHASE    GRACE  CONDITIONS
Aug  9 14:07:57.680: INFO: ss-0  scw-flan15-default-f07a9b7e282146a6b5427e9aba2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:10 +0000 UTC  }]
Aug  9 14:07:57.680: INFO: ss-1  scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:31 +0000 UTC  }]
Aug  9 14:07:57.680: INFO: ss-2  scw-flan15-default-fbc750a75c7f4c499b691cc5ccd  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:31 +0000 UTC  }]
Aug  9 14:07:57.680: INFO: 
Aug  9 14:07:57.680: INFO: StatefulSet ss has not reached scale 0, at 3
Aug  9 14:07:58.694: INFO: POD   NODE                                            PHASE    GRACE  CONDITIONS
Aug  9 14:07:58.694: INFO: ss-0  scw-flan15-default-f07a9b7e282146a6b5427e9aba2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:10 +0000 UTC  }]
Aug  9 14:07:58.694: INFO: ss-1  scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:31 +0000 UTC  }]
Aug  9 14:07:58.694: INFO: ss-2  scw-flan15-default-fbc750a75c7f4c499b691cc5ccd  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:31 +0000 UTC  }]
Aug  9 14:07:58.694: INFO: 
Aug  9 14:07:58.694: INFO: StatefulSet ss has not reached scale 0, at 3
Aug  9 14:07:59.705: INFO: POD   NODE                                            PHASE    GRACE  CONDITIONS
Aug  9 14:07:59.705: INFO: ss-0  scw-flan15-default-f07a9b7e282146a6b5427e9aba2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:10 +0000 UTC  }]
Aug  9 14:07:59.705: INFO: ss-1  scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:31 +0000 UTC  }]
Aug  9 14:07:59.706: INFO: ss-2  scw-flan15-default-fbc750a75c7f4c499b691cc5ccd  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:31 +0000 UTC  }]
Aug  9 14:07:59.706: INFO: 
Aug  9 14:07:59.706: INFO: StatefulSet ss has not reached scale 0, at 3
Aug  9 14:08:00.717: INFO: POD   NODE                                            PHASE    GRACE  CONDITIONS
Aug  9 14:08:00.717: INFO: ss-0  scw-flan15-default-f07a9b7e282146a6b5427e9aba2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:10 +0000 UTC  }]
Aug  9 14:08:00.717: INFO: ss-1  scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:31 +0000 UTC  }]
Aug  9 14:08:00.717: INFO: ss-2  scw-flan15-default-fbc750a75c7f4c499b691cc5ccd  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:31 +0000 UTC  }]
Aug  9 14:08:00.718: INFO: 
Aug  9 14:08:00.718: INFO: StatefulSet ss has not reached scale 0, at 3
Aug  9 14:08:01.728: INFO: POD   NODE                                            PHASE    GRACE  CONDITIONS
Aug  9 14:08:01.728: INFO: ss-0  scw-flan15-default-f07a9b7e282146a6b5427e9aba2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:10 +0000 UTC  }]
Aug  9 14:08:01.728: INFO: ss-1  scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:31 +0000 UTC  }]
Aug  9 14:08:01.728: INFO: ss-2  scw-flan15-default-fbc750a75c7f4c499b691cc5ccd  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:31 +0000 UTC  }]
Aug  9 14:08:01.728: INFO: 
Aug  9 14:08:01.728: INFO: StatefulSet ss has not reached scale 0, at 3
Aug  9 14:08:02.737: INFO: POD   NODE                                            PHASE    GRACE  CONDITIONS
Aug  9 14:08:02.737: INFO: ss-0  scw-flan15-default-f07a9b7e282146a6b5427e9aba2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:10 +0000 UTC  }]
Aug  9 14:08:02.737: INFO: ss-1  scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:31 +0000 UTC  }]
Aug  9 14:08:02.737: INFO: ss-2  scw-flan15-default-fbc750a75c7f4c499b691cc5ccd  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:31 +0000 UTC  }]
Aug  9 14:08:02.737: INFO: 
Aug  9 14:08:02.737: INFO: StatefulSet ss has not reached scale 0, at 3
Aug  9 14:08:03.748: INFO: POD   NODE                                            PHASE    GRACE  CONDITIONS
Aug  9 14:08:03.748: INFO: ss-0  scw-flan15-default-f07a9b7e282146a6b5427e9aba2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:10 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:43 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:10 +0000 UTC  }]
Aug  9 14:08:03.748: INFO: ss-1  scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:44 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:31 +0000 UTC  }]
Aug  9 14:08:03.748: INFO: ss-2  scw-flan15-default-fbc750a75c7f4c499b691cc5ccd  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:31 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:45 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:07:31 +0000 UTC  }]
Aug  9 14:08:03.748: INFO: 
Aug  9 14:08:03.748: INFO: StatefulSet ss has not reached scale 0, at 3
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-8279
Aug  9 14:08:04.761: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-8279 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  9 14:08:05.024: INFO: rc: 1
Aug  9 14:08:05.024: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-8279 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc002554cf0 exit status 1 <nil> <nil> true [0xc000641ab0 0xc000641c48 0xc000641dc8] [0xc000641ab0 0xc000641c48 0xc000641dc8] [0xc000641bc0 0xc000641d80] [0x9d17b0 0x9d17b0] 0xc0026c3680 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1
Aug  9 14:08:15.024: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-8279 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  9 14:08:15.206: INFO: rc: 1
Aug  9 14:08:15.207: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-8279 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002346120 exit status 1 <nil> <nil> true [0xc001c34360 0xc001c34378 0xc001c34390] [0xc001c34360 0xc001c34378 0xc001c34390] [0xc001c34370 0xc001c34388] [0x9d17b0 0x9d17b0] 0xc0028bc600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Aug  9 14:08:25.207: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-8279 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  9 14:08:25.457: INFO: rc: 1
Aug  9 14:08:25.457: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-8279 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc00317d890 exit status 1 <nil> <nil> true [0xc001ac2b40 0xc001ac2b90 0xc001ac2c28] [0xc001ac2b40 0xc001ac2b90 0xc001ac2c28] [0xc001ac2b68 0xc001ac2c08] [0x9d17b0 0x9d17b0] 0xc001fe9c80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Aug  9 14:08:35.457: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-8279 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  9 14:08:35.643: INFO: rc: 1
Aug  9 14:08:35.643: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-8279 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc00317dcb0 exit status 1 <nil> <nil> true [0xc001ac2c40 0xc001ac2c70 0xc001ac2d30] [0xc001ac2c40 0xc001ac2c70 0xc001ac2d30] [0xc001ac2c68 0xc001ac2ce0] [0x9d17b0 0x9d17b0] 0xc002660540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Aug  9 14:08:45.643: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-8279 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  9 14:08:45.856: INFO: rc: 1
Aug  9 14:08:45.857: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-8279 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0023464e0 exit status 1 <nil> <nil> true [0xc001c34398 0xc001c343b0 0xc001c343c8] [0xc001c34398 0xc001c343b0 0xc001c343c8] [0xc001c343a8 0xc001c343c0] [0x9d17b0 0x9d17b0] 0xc0028bccc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Aug  9 14:08:55.857: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-8279 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  9 14:08:56.002: INFO: rc: 1
Aug  9 14:08:56.002: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-8279 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0019c8090 exit status 1 <nil> <nil> true [0xc001ac2d40 0xc001ac2da0 0xc001ac2e00] [0xc001ac2d40 0xc001ac2da0 0xc001ac2e00] [0xc001ac2d80 0xc001ac2de0] [0x9d17b0 0x9d17b0] 0xc002661200 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Aug  9 14:09:06.003: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-8279 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  9 14:09:06.218: INFO: rc: 1
Aug  9 14:09:06.218: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-8279 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0019c8420 exit status 1 <nil> <nil> true [0xc001ac2e60 0xc001ac2eb0 0xc001ac2ed8] [0xc001ac2e60 0xc001ac2eb0 0xc001ac2ed8] [0xc001ac2ea0 0xc001ac2ec0] [0x9d17b0 0x9d17b0] 0xc0026618c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Aug  9 14:09:16.218: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-8279 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  9 14:09:16.380: INFO: rc: 1
Aug  9 14:09:16.380: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-8279 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0019c8780 exit status 1 <nil> <nil> true [0xc001ac2ef8 0xc001ac2f30 0xc001ac2f88] [0xc001ac2ef8 0xc001ac2f30 0xc001ac2f88] [0xc001ac2f20 0xc001ac2f78] [0x9d17b0 0x9d17b0] 0xc002661f80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Aug  9 14:09:26.382: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-8279 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  9 14:09:26.597: INFO: rc: 1
Aug  9 14:09:26.597: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-8279 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002712360 exit status 1 <nil> <nil> true [0xc000011220 0xc000011c00 0xc001c34010] [0xc000011220 0xc000011c00 0xc001c34010] [0xc000011660 0xc001c34008] [0x9d17b0 0x9d17b0] 0xc002661020 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Aug  9 14:09:36.598: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-8279 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  9 14:09:36.809: INFO: rc: 1
Aug  9 14:09:36.809: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-8279 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc00317c360 exit status 1 <nil> <nil> true [0xc000641208 0xc0006413e8 0xc000641658] [0xc000641208 0xc0006413e8 0xc000641658] [0xc000641398 0xc000641628] [0x9d17b0 0x9d17b0] 0xc001fe8300 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Aug  9 14:09:46.810: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-8279 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  9 14:09:47.016: INFO: rc: 1
Aug  9 14:09:47.016: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-8279 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc00317c6f0 exit status 1 <nil> <nil> true [0xc0006416e8 0xc0006418b8 0xc0006419a8] [0xc0006416e8 0xc0006418b8 0xc0006419a8] [0xc000641810 0xc000641980] [0x9d17b0 0x9d17b0] 0xc001fe8660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Aug  9 14:09:57.016: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-8279 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  9 14:09:57.239: INFO: rc: 1
Aug  9 14:09:57.239: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-8279 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002712960 exit status 1 <nil> <nil> true [0xc001c34018 0xc001c34030 0xc001c34058] [0xc001c34018 0xc001c34030 0xc001c34058] [0xc001c34028 0xc001c34050] [0x9d17b0 0x9d17b0] 0xc002661620 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Aug  9 14:10:07.240: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-8279 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  9 14:10:07.483: INFO: rc: 1
Aug  9 14:10:07.483: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-8279 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc00317ca80 exit status 1 <nil> <nil> true [0xc000641a18 0xc000641bc0 0xc000641d80] [0xc000641a18 0xc000641bc0 0xc000641d80] [0xc000641b88 0xc000641cb0] [0x9d17b0 0x9d17b0] 0xc001fe89c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Aug  9 14:10:17.483: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-8279 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  9 14:10:17.703: INFO: rc: 1
Aug  9 14:10:17.703: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-8279 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc00149e360 exit status 1 <nil> <nil> true [0xc001ac2000 0xc001ac2090 0xc001ac2120] [0xc001ac2000 0xc001ac2090 0xc001ac2120] [0xc001ac2010 0xc001ac2110] [0x9d17b0 0x9d17b0] 0xc001c2ccc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Aug  9 14:10:27.703: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-8279 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  9 14:10:27.930: INFO: rc: 1
Aug  9 14:10:27.930: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-8279 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc00149e6f0 exit status 1 <nil> <nil> true [0xc001ac2130 0xc001ac21e0 0xc001ac2250] [0xc001ac2130 0xc001ac21e0 0xc001ac2250] [0xc001ac2190 0xc001ac2220] [0x9d17b0 0x9d17b0] 0xc001c2d8c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Aug  9 14:10:37.931: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-8279 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  9 14:10:38.123: INFO: rc: 1
Aug  9 14:10:38.123: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-8279 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002712d20 exit status 1 <nil> <nil> true [0xc001c34060 0xc001c34078 0xc001c34090] [0xc001c34060 0xc001c34078 0xc001c34090] [0xc001c34070 0xc001c34088] [0x9d17b0 0x9d17b0] 0xc002661d40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Aug  9 14:10:48.124: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-8279 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  9 14:10:48.306: INFO: rc: 1
Aug  9 14:10:48.306: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-8279 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0029f0630 exit status 1 <nil> <nil> true [0xc0002b8288 0xc0002b8540 0xc0002b8a60] [0xc0002b8288 0xc0002b8540 0xc0002b8a60] [0xc0002b8460 0xc0002b87e0] [0x9d17b0 0x9d17b0] 0xc0025d6420 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Aug  9 14:10:58.306: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-8279 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  9 14:10:58.554: INFO: rc: 1
Aug  9 14:10:58.555: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-8279 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002713110 exit status 1 <nil> <nil> true [0xc001c34098 0xc001c340b0 0xc001c340c8] [0xc001c34098 0xc001c340b0 0xc001c340c8] [0xc001c340a8 0xc001c340c0] [0x9d17b0 0x9d17b0] 0xc0028bc480 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Aug  9 14:11:08.555: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-8279 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  9 14:11:08.749: INFO: rc: 1
Aug  9 14:11:08.749: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-8279 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0029f09c0 exit status 1 <nil> <nil> true [0xc0002b8b48 0xc0002b8e58 0xc0002b90b0] [0xc0002b8b48 0xc0002b8e58 0xc0002b90b0] [0xc0002b8dc0 0xc0002b8ff0] [0x9d17b0 0x9d17b0] 0xc0025d6780 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Aug  9 14:11:18.750: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-8279 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  9 14:11:18.965: INFO: rc: 1
Aug  9 14:11:18.965: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-8279 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0029f0d50 exit status 1 <nil> <nil> true [0xc0002b91a0 0xc0002b94c0 0xc0002b97b8] [0xc0002b91a0 0xc0002b94c0 0xc0002b97b8] [0xc0002b9478 0xc0002b96b8] [0x9d17b0 0x9d17b0] 0xc0025d6b40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Aug  9 14:11:28.966: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-8279 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  9 14:11:29.216: INFO: rc: 1
Aug  9 14:11:29.216: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-8279 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc00149e330 exit status 1 <nil> <nil> true [0xc000011530 0xc000011ff0 0xc001ac2008] [0xc000011530 0xc000011ff0 0xc001ac2008] [0xc000011c00 0xc001ac2000] [0x9d17b0 0x9d17b0] 0xc002661020 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Aug  9 14:11:39.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-8279 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  9 14:11:39.367: INFO: rc: 1
Aug  9 14:11:39.367: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-8279 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc00317c330 exit status 1 <nil> <nil> true [0xc000641208 0xc0006413e8 0xc000641658] [0xc000641208 0xc0006413e8 0xc000641658] [0xc000641398 0xc000641628] [0x9d17b0 0x9d17b0] 0xc001c2ccc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Aug  9 14:11:49.368: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-8279 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  9 14:11:49.537: INFO: rc: 1
Aug  9 14:11:49.537: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-8279 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc00149e750 exit status 1 <nil> <nil> true [0xc001ac2010 0xc001ac2110 0xc001ac2150] [0xc001ac2010 0xc001ac2110 0xc001ac2150] [0xc001ac20c8 0xc001ac2130] [0x9d17b0 0x9d17b0] 0xc002661620 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Aug  9 14:11:59.537: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-8279 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  9 14:11:59.738: INFO: rc: 1
Aug  9 14:11:59.738: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-8279 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc00149eae0 exit status 1 <nil> <nil> true [0xc001ac2190 0xc001ac2220 0xc001ac2290] [0xc001ac2190 0xc001ac2220 0xc001ac2290] [0xc001ac21f0 0xc001ac2268] [0x9d17b0 0x9d17b0] 0xc002661d40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Aug  9 14:12:09.738: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-8279 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  9 14:12:09.949: INFO: rc: 1
Aug  9 14:12:09.949: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-8279 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002712390 exit status 1 <nil> <nil> true [0xc001c34008 0xc001c34020 0xc001c34048] [0xc001c34008 0xc001c34020 0xc001c34048] [0xc001c34018 0xc001c34030] [0x9d17b0 0x9d17b0] 0xc001fe8300 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Aug  9 14:12:19.950: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-8279 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  9 14:12:20.202: INFO: rc: 1
Aug  9 14:12:20.202: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-8279 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc00149ee70 exit status 1 <nil> <nil> true [0xc001ac22d0 0xc001ac2360 0xc001ac23c8] [0xc001ac22d0 0xc001ac2360 0xc001ac23c8] [0xc001ac2340 0xc001ac2398] [0x9d17b0 0x9d17b0] 0xc0028bc480 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Aug  9 14:12:30.202: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-8279 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  9 14:12:30.435: INFO: rc: 1
Aug  9 14:12:30.435: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-8279 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc00149f1d0 exit status 1 <nil> <nil> true [0xc001ac23f8 0xc001ac2418 0xc001ac24b0] [0xc001ac23f8 0xc001ac2418 0xc001ac24b0] [0xc001ac2410 0xc001ac2480] [0x9d17b0 0x9d17b0] 0xc0028bcb40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Aug  9 14:12:40.435: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-8279 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  9 14:12:40.622: INFO: rc: 1
Aug  9 14:12:40.622: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-8279 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc00149f530 exit status 1 <nil> <nil> true [0xc001ac24c0 0xc001ac2560 0xc001ac25b8] [0xc001ac24c0 0xc001ac2560 0xc001ac25b8] [0xc001ac24f8 0xc001ac25b0] [0x9d17b0 0x9d17b0] 0xc0028bd260 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Aug  9 14:12:50.623: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-8279 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  9 14:12:50.926: INFO: rc: 1
Aug  9 14:12:50.926: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-8279 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc002712a20 exit status 1 <nil> <nil> true [0xc001c34050 0xc001c34068 0xc001c34080] [0xc001c34050 0xc001c34068 0xc001c34080] [0xc001c34060 0xc001c34078] [0x9d17b0 0x9d17b0] 0xc001fe8660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Aug  9 14:13:00.927: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-8279 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  9 14:13:01.112: INFO: rc: 1
Aug  9 14:13:01.113: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-8279 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc00149f8c0 exit status 1 <nil> <nil> true [0xc001ac25c8 0xc001ac2668 0xc001ac26e8] [0xc001ac25c8 0xc001ac2668 0xc001ac26e8] [0xc001ac2638 0xc001ac26d0] [0x9d17b0 0x9d17b0] 0xc0028bdc80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Aug  9 14:13:11.113: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-8279 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  9 14:13:11.303: INFO: rc: 1
Aug  9 14:13:11.304: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: 
Aug  9 14:13:11.304: INFO: Scaling statefulset ss to 0
Aug  9 14:13:11.343: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Aug  9 14:13:11.352: INFO: Deleting all statefulset in ns statefulset-8279
Aug  9 14:13:11.364: INFO: Scaling statefulset ss to 0
Aug  9 14:13:11.395: INFO: Waiting for statefulset status.replicas updated to 0
Aug  9 14:13:11.406: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:13:11.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8279" for this suite.
Aug  9 14:13:19.527: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:13:19.887: INFO: namespace statefulset-8279 deletion completed in 8.413091626s

• [SLOW TEST:369.623 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:13:19.889: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-9814
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Aug  9 14:13:20.365: INFO: Number of nodes with available pods: 0
Aug  9 14:13:20.365: INFO: Node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d is running more than one daemon pod
Aug  9 14:13:21.391: INFO: Number of nodes with available pods: 0
Aug  9 14:13:21.391: INFO: Node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d is running more than one daemon pod
Aug  9 14:13:22.399: INFO: Number of nodes with available pods: 0
Aug  9 14:13:22.399: INFO: Node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d is running more than one daemon pod
Aug  9 14:13:23.392: INFO: Number of nodes with available pods: 3
Aug  9 14:13:23.392: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Aug  9 14:13:23.466: INFO: Number of nodes with available pods: 2
Aug  9 14:13:23.466: INFO: Node scw-flan15-default-fbc750a75c7f4c499b691cc5ccd is running more than one daemon pod
Aug  9 14:13:24.495: INFO: Number of nodes with available pods: 2
Aug  9 14:13:24.495: INFO: Node scw-flan15-default-fbc750a75c7f4c499b691cc5ccd is running more than one daemon pod
Aug  9 14:13:25.497: INFO: Number of nodes with available pods: 2
Aug  9 14:13:25.497: INFO: Node scw-flan15-default-fbc750a75c7f4c499b691cc5ccd is running more than one daemon pod
Aug  9 14:13:26.495: INFO: Number of nodes with available pods: 2
Aug  9 14:13:26.495: INFO: Node scw-flan15-default-fbc750a75c7f4c499b691cc5ccd is running more than one daemon pod
Aug  9 14:13:27.515: INFO: Number of nodes with available pods: 2
Aug  9 14:13:27.516: INFO: Node scw-flan15-default-fbc750a75c7f4c499b691cc5ccd is running more than one daemon pod
Aug  9 14:13:28.500: INFO: Number of nodes with available pods: 2
Aug  9 14:13:28.500: INFO: Node scw-flan15-default-fbc750a75c7f4c499b691cc5ccd is running more than one daemon pod
Aug  9 14:13:29.496: INFO: Number of nodes with available pods: 2
Aug  9 14:13:29.496: INFO: Node scw-flan15-default-fbc750a75c7f4c499b691cc5ccd is running more than one daemon pod
Aug  9 14:13:30.503: INFO: Number of nodes with available pods: 2
Aug  9 14:13:30.503: INFO: Node scw-flan15-default-fbc750a75c7f4c499b691cc5ccd is running more than one daemon pod
Aug  9 14:13:31.494: INFO: Number of nodes with available pods: 2
Aug  9 14:13:31.494: INFO: Node scw-flan15-default-fbc750a75c7f4c499b691cc5ccd is running more than one daemon pod
Aug  9 14:13:32.490: INFO: Number of nodes with available pods: 2
Aug  9 14:13:32.490: INFO: Node scw-flan15-default-fbc750a75c7f4c499b691cc5ccd is running more than one daemon pod
Aug  9 14:13:33.490: INFO: Number of nodes with available pods: 2
Aug  9 14:13:33.490: INFO: Node scw-flan15-default-fbc750a75c7f4c499b691cc5ccd is running more than one daemon pod
Aug  9 14:13:34.488: INFO: Number of nodes with available pods: 2
Aug  9 14:13:34.488: INFO: Node scw-flan15-default-fbc750a75c7f4c499b691cc5ccd is running more than one daemon pod
Aug  9 14:13:35.491: INFO: Number of nodes with available pods: 2
Aug  9 14:13:35.491: INFO: Node scw-flan15-default-fbc750a75c7f4c499b691cc5ccd is running more than one daemon pod
Aug  9 14:13:36.491: INFO: Number of nodes with available pods: 2
Aug  9 14:13:36.491: INFO: Node scw-flan15-default-fbc750a75c7f4c499b691cc5ccd is running more than one daemon pod
Aug  9 14:13:37.833: INFO: Number of nodes with available pods: 2
Aug  9 14:13:37.833: INFO: Node scw-flan15-default-fbc750a75c7f4c499b691cc5ccd is running more than one daemon pod
Aug  9 14:13:38.696: INFO: Number of nodes with available pods: 2
Aug  9 14:13:38.696: INFO: Node scw-flan15-default-fbc750a75c7f4c499b691cc5ccd is running more than one daemon pod
Aug  9 14:13:39.491: INFO: Number of nodes with available pods: 2
Aug  9 14:13:39.492: INFO: Node scw-flan15-default-fbc750a75c7f4c499b691cc5ccd is running more than one daemon pod
Aug  9 14:13:40.603: INFO: Number of nodes with available pods: 2
Aug  9 14:13:40.603: INFO: Node scw-flan15-default-fbc750a75c7f4c499b691cc5ccd is running more than one daemon pod
Aug  9 14:13:41.500: INFO: Number of nodes with available pods: 2
Aug  9 14:13:41.500: INFO: Node scw-flan15-default-fbc750a75c7f4c499b691cc5ccd is running more than one daemon pod
Aug  9 14:13:42.489: INFO: Number of nodes with available pods: 3
Aug  9 14:13:42.489: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9814, will wait for the garbage collector to delete the pods
Aug  9 14:13:42.585: INFO: Deleting DaemonSet.extensions daemon-set took: 25.653402ms
Aug  9 14:13:42.985: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.390979ms
Aug  9 14:13:55.898: INFO: Number of nodes with available pods: 0
Aug  9 14:13:55.898: INFO: Number of running nodes: 0, number of available pods: 0
Aug  9 14:13:55.911: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9814/daemonsets","resourceVersion":"124687594"},"items":null}

Aug  9 14:13:55.921: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9814/pods","resourceVersion":"124687594"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:13:55.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9814" for this suite.
Aug  9 14:14:04.038: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:14:05.267: INFO: namespace daemonsets-9814 deletion completed in 9.272048105s

• [SLOW TEST:45.378 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:14:05.268: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-4965
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:14:10.478: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-4965" for this suite.
Aug  9 14:14:16.557: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:14:17.057: INFO: namespace emptydir-wrapper-4965 deletion completed in 6.560589002s

• [SLOW TEST:11.789 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:14:17.058: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-983
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Aug  9 14:14:18.075: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Aug  9 14:14:18.915: INFO: Waiting for terminating namespaces to be deleted...
Aug  9 14:14:18.925: INFO: 
Logging pods the kubelet thinks is on node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d before test
Aug  9 14:14:18.945: INFO: flannel-qwjfp from kube-system started at 2019-08-09 13:00:06 +0000 UTC (1 container statuses recorded)
Aug  9 14:14:18.946: INFO: 	Container kube-flannel ready: true, restart count 0
Aug  9 14:14:18.946: INFO: kube-proxy-wjvhf from kube-system started at 2019-08-09 13:00:06 +0000 UTC (1 container statuses recorded)
Aug  9 14:14:18.946: INFO: 	Container kube-proxy ready: true, restart count 0
Aug  9 14:14:18.946: INFO: node-problem-detector-gqzjc from kube-system started at 2019-08-09 13:00:46 +0000 UTC (1 container statuses recorded)
Aug  9 14:14:18.946: INFO: 	Container node-problem-detector ready: true, restart count 0
Aug  9 14:14:18.946: INFO: csi-node-s6ph9 from kube-system started at 2019-08-09 13:00:46 +0000 UTC (2 container statuses recorded)
Aug  9 14:14:18.946: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Aug  9 14:14:18.946: INFO: 	Container csi-plugin ready: true, restart count 0
Aug  9 14:14:18.946: INFO: sonobuoy-systemd-logs-daemon-set-c59f53251cea452d-gww4w from heptio-sonobuoy started at 2019-08-09 13:01:29 +0000 UTC (2 container statuses recorded)
Aug  9 14:14:18.946: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Aug  9 14:14:18.946: INFO: 	Container systemd-logs ready: true, restart count 1
Aug  9 14:14:18.946: INFO: ingress-traefik-xvq78 from kube-system started at 2019-08-09 13:00:46 +0000 UTC (1 container statuses recorded)
Aug  9 14:14:18.946: INFO: 	Container ingress-traefik ready: true, restart count 0
Aug  9 14:14:18.946: INFO: sonobuoy from heptio-sonobuoy started at 2019-08-09 13:01:20 +0000 UTC (1 container statuses recorded)
Aug  9 14:14:18.946: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Aug  9 14:14:18.946: INFO: 
Logging pods the kubelet thinks is on node scw-flan15-default-f07a9b7e282146a6b5427e9aba2 before test
Aug  9 14:14:18.989: INFO: node-problem-detector-wkzb6 from kube-system started at 2019-08-09 12:59:36 +0000 UTC (1 container statuses recorded)
Aug  9 14:14:18.989: INFO: 	Container node-problem-detector ready: true, restart count 0
Aug  9 14:14:18.990: INFO: ingress-traefik-tld7q from kube-system started at 2019-08-09 12:59:36 +0000 UTC (1 container statuses recorded)
Aug  9 14:14:18.990: INFO: 	Container ingress-traefik ready: true, restart count 0
Aug  9 14:14:18.990: INFO: flannel-thwpk from kube-system started at 2019-08-09 12:58:54 +0000 UTC (1 container statuses recorded)
Aug  9 14:14:18.990: INFO: 	Container kube-flannel ready: true, restart count 0
Aug  9 14:14:18.990: INFO: dashboard-metrics-scraper-57454df758-67n9f from kubernetes-dashboard started at 2019-08-09 12:59:35 +0000 UTC (1 container statuses recorded)
Aug  9 14:14:18.990: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Aug  9 14:14:18.990: INFO: kubernetes-dashboard-7dfbf7f9d6-rkhpn from kubernetes-dashboard started at 2019-08-09 12:59:36 +0000 UTC (1 container statuses recorded)
Aug  9 14:14:18.990: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Aug  9 14:14:18.990: INFO: csi-node-89m4p from kube-system started at 2019-08-09 12:59:36 +0000 UTC (2 container statuses recorded)
Aug  9 14:14:18.990: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Aug  9 14:14:18.990: INFO: 	Container csi-plugin ready: true, restart count 0
Aug  9 14:14:18.991: INFO: kube-proxy-kv7tc from kube-system started at 2019-08-09 12:58:54 +0000 UTC (1 container statuses recorded)
Aug  9 14:14:18.991: INFO: 	Container kube-proxy ready: true, restart count 0
Aug  9 14:14:18.991: INFO: metrics-server-5dc57bbc74-qzlbl from kube-system started at 2019-08-09 12:59:35 +0000 UTC (1 container statuses recorded)
Aug  9 14:14:18.991: INFO: 	Container metrics-server ready: true, restart count 0
Aug  9 14:14:18.991: INFO: coredns-6f74b4c5f8-5ztrx from kube-system started at 2019-08-09 12:59:37 +0000 UTC (1 container statuses recorded)
Aug  9 14:14:18.991: INFO: 	Container coredns ready: true, restart count 0
Aug  9 14:14:18.991: INFO: sonobuoy-systemd-logs-daemon-set-c59f53251cea452d-62jrb from heptio-sonobuoy started at 2019-08-09 13:01:29 +0000 UTC (2 container statuses recorded)
Aug  9 14:14:18.991: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Aug  9 14:14:18.991: INFO: 	Container systemd-logs ready: true, restart count 1
Aug  9 14:14:18.991: INFO: 
Logging pods the kubelet thinks is on node scw-flan15-default-fbc750a75c7f4c499b691cc5ccd before test
Aug  9 14:14:19.017: INFO: csi-node-hn5ml from kube-system started at 2019-08-09 13:00:58 +0000 UTC (2 container statuses recorded)
Aug  9 14:14:19.017: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Aug  9 14:14:19.017: INFO: 	Container csi-plugin ready: true, restart count 0
Aug  9 14:14:19.017: INFO: sonobuoy-e2e-job-3cf2f524dc5540ab from heptio-sonobuoy started at 2019-08-09 13:01:29 +0000 UTC (2 container statuses recorded)
Aug  9 14:14:19.017: INFO: 	Container e2e ready: true, restart count 0
Aug  9 14:14:19.017: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Aug  9 14:14:19.017: INFO: sonobuoy-systemd-logs-daemon-set-c59f53251cea452d-9gl4b from heptio-sonobuoy started at 2019-08-09 13:01:29 +0000 UTC (2 container statuses recorded)
Aug  9 14:14:19.017: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Aug  9 14:14:19.017: INFO: 	Container systemd-logs ready: true, restart count 1
Aug  9 14:14:19.017: INFO: kube-proxy-s8p7n from kube-system started at 2019-08-09 13:00:08 +0000 UTC (1 container statuses recorded)
Aug  9 14:14:19.017: INFO: 	Container kube-proxy ready: true, restart count 0
Aug  9 14:14:19.017: INFO: flannel-v4kkt from kube-system started at 2019-08-09 13:00:08 +0000 UTC (1 container statuses recorded)
Aug  9 14:14:19.017: INFO: 	Container kube-flannel ready: true, restart count 0
Aug  9 14:14:19.017: INFO: node-problem-detector-4tg4w from kube-system started at 2019-08-09 13:00:58 +0000 UTC (1 container statuses recorded)
Aug  9 14:14:19.017: INFO: 	Container node-problem-detector ready: true, restart count 0
Aug  9 14:14:19.017: INFO: ingress-traefik-5rxqq from kube-system started at 2019-08-09 13:00:58 +0000 UTC (1 container statuses recorded)
Aug  9 14:14:19.017: INFO: 	Container ingress-traefik ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-314904e1-6a5d-4bd9-8371-1d8ae922f37e 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-314904e1-6a5d-4bd9-8371-1d8ae922f37e off the node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d
STEP: verifying the node doesn't have the label kubernetes.io/e2e-314904e1-6a5d-4bd9-8371-1d8ae922f37e
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:14:27.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-983" for this suite.
Aug  9 14:14:51.377: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:14:51.737: INFO: namespace sched-pred-983 deletion completed in 24.398463556s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:34.679 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:14:51.739: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9669
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name cm-test-opt-del-dccbaa5a-c6da-43cd-bc7d-bc8ab1ca0107
STEP: Creating configMap with name cm-test-opt-upd-69f5ac6c-a9e1-490d-ac1b-95d17e1aa34a
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-dccbaa5a-c6da-43cd-bc7d-bc8ab1ca0107
STEP: Updating configmap cm-test-opt-upd-69f5ac6c-a9e1-490d-ac1b-95d17e1aa34a
STEP: Creating configMap with name cm-test-opt-create-3fdc2284-2e36-4eea-ba62-5d47c9dd3da9
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:15:00.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9669" for this suite.
Aug  9 14:15:25.015: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:15:25.414: INFO: namespace projected-9669 deletion completed in 24.444805285s

• [SLOW TEST:33.676 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:15:25.415: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-671
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Aug  9 14:15:25.644: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Aug  9 14:15:34.793: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:15:34.804: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-671" for this suite.
Aug  9 14:15:42.867: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:15:43.233: INFO: namespace pods-671 deletion completed in 8.414682648s

• [SLOW TEST:17.818 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:15:43.233: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-3057
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug  9 14:15:43.503: INFO: Pod name rollover-pod: Found 0 pods out of 1
Aug  9 14:15:48.515: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Aug  9 14:15:48.515: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Aug  9 14:15:50.700: INFO: Creating deployment "test-rollover-deployment"
Aug  9 14:15:50.747: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Aug  9 14:15:52.765: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Aug  9 14:15:52.785: INFO: Ensure that both replica sets have 1 created replica
Aug  9 14:15:52.810: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Aug  9 14:15:52.838: INFO: Updating deployment test-rollover-deployment
Aug  9 14:15:52.838: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Aug  9 14:15:54.858: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Aug  9 14:15:54.877: INFO: Make sure deployment "test-rollover-deployment" is complete
Aug  9 14:15:54.898: INFO: all replica sets need to contain the pod-template-hash label
Aug  9 14:15:54.898: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700956950, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700956950, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700956953, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700956950, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug  9 14:15:56.919: INFO: all replica sets need to contain the pod-template-hash label
Aug  9 14:15:56.919: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700956950, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700956950, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700956955, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700956950, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug  9 14:15:58.920: INFO: all replica sets need to contain the pod-template-hash label
Aug  9 14:15:58.920: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700956950, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700956950, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700956955, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700956950, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug  9 14:16:00.919: INFO: all replica sets need to contain the pod-template-hash label
Aug  9 14:16:00.919: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700956950, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700956950, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700956955, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700956950, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug  9 14:16:02.918: INFO: all replica sets need to contain the pod-template-hash label
Aug  9 14:16:02.919: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700956950, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700956950, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700956955, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700956950, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug  9 14:16:04.916: INFO: all replica sets need to contain the pod-template-hash label
Aug  9 14:16:04.917: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700956950, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700956950, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63700956955, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700956950, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Aug  9 14:16:06.920: INFO: 
Aug  9 14:16:06.920: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Aug  9 14:16:07.108: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-3057,SelfLink:/apis/apps/v1/namespaces/deployment-3057/deployments/test-rollover-deployment,UID:96dd3765-72c9-4b65-b947-cb2368763842,ResourceVersion:124689846,Generation:2,CreationTimestamp:2019-08-09 14:15:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-08-09 14:15:50 +0000 UTC 2019-08-09 14:15:50 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-08-09 14:16:05 +0000 UTC 2019-08-09 14:15:50 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-854595fc44" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Aug  9 14:16:07.130: INFO: New ReplicaSet "test-rollover-deployment-854595fc44" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-854595fc44,GenerateName:,Namespace:deployment-3057,SelfLink:/apis/apps/v1/namespaces/deployment-3057/replicasets/test-rollover-deployment-854595fc44,UID:a05af54d-5708-41ad-9c23-79a1ede4e4dd,ResourceVersion:124689836,Generation:2,CreationTimestamp:2019-08-09 14:15:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 96dd3765-72c9-4b65-b947-cb2368763842 0xc003488bd7 0xc003488bd8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Aug  9 14:16:07.130: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Aug  9 14:16:07.131: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-3057,SelfLink:/apis/apps/v1/namespaces/deployment-3057/replicasets/test-rollover-controller,UID:6b3154ac-b52b-4521-99a0-3a43b50d7963,ResourceVersion:124689845,Generation:2,CreationTimestamp:2019-08-09 14:15:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 96dd3765-72c9-4b65-b947-cb2368763842 0xc003488b07 0xc003488b08}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug  9 14:16:07.131: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-9b8b997cf,GenerateName:,Namespace:deployment-3057,SelfLink:/apis/apps/v1/namespaces/deployment-3057/replicasets/test-rollover-deployment-9b8b997cf,UID:ba48ff69-c8c3-4da3-80ea-cdf5091ada74,ResourceVersion:124689672,Generation:2,CreationTimestamp:2019-08-09 14:15:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 96dd3765-72c9-4b65-b947-cb2368763842 0xc003488ca0 0xc003488ca1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug  9 14:16:07.142: INFO: Pod "test-rollover-deployment-854595fc44-jf6sm" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-854595fc44-jf6sm,GenerateName:test-rollover-deployment-854595fc44-,Namespace:deployment-3057,SelfLink:/api/v1/namespaces/deployment-3057/pods/test-rollover-deployment-854595fc44-jf6sm,UID:84df2a04-e48d-449b-9877-3866beb63c59,ResourceVersion:124689710,Generation:0,CreationTimestamp:2019-08-09 14:15:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-854595fc44 a05af54d-5708-41ad-9c23-79a1ede4e4dd 0xc0034898a7 0xc0034898a8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-rt4pd {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-rt4pd,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-rt4pd true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-flan15-default-f07a9b7e282146a6b5427e9aba2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003489910} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003489930}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:15:53 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:15:55 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:15:55 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:15:53 +0000 UTC  }],Message:,Reason:,HostIP:10.12.155.153,PodIP:100.64.0.70,StartTime:2019-08-09 14:15:53 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-08-09 14:15:54 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://c07447367d0619dba4cc7b2cbc337f9d158b8f54c2a09d7afd181d6e833fa183}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:16:07.142: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3057" for this suite.
Aug  9 14:16:15.227: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:16:15.599: INFO: namespace deployment-3057 deletion completed in 8.441419951s

• [SLOW TEST:32.366 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:16:15.599: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-6144
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Aug  9 14:16:15.877: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-6144,SelfLink:/api/v1/namespaces/watch-6144/configmaps/e2e-watch-test-label-changed,UID:fd450c21-cd12-49d1-99c4-4fd50bb7eda9,ResourceVersion:124690029,Generation:0,CreationTimestamp:2019-08-09 14:16:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Aug  9 14:16:15.878: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-6144,SelfLink:/api/v1/namespaces/watch-6144/configmaps/e2e-watch-test-label-changed,UID:fd450c21-cd12-49d1-99c4-4fd50bb7eda9,ResourceVersion:124690030,Generation:0,CreationTimestamp:2019-08-09 14:16:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Aug  9 14:16:15.878: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-6144,SelfLink:/api/v1/namespaces/watch-6144/configmaps/e2e-watch-test-label-changed,UID:fd450c21-cd12-49d1-99c4-4fd50bb7eda9,ResourceVersion:124690031,Generation:0,CreationTimestamp:2019-08-09 14:16:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Aug  9 14:16:25.980: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-6144,SelfLink:/api/v1/namespaces/watch-6144/configmaps/e2e-watch-test-label-changed,UID:fd450c21-cd12-49d1-99c4-4fd50bb7eda9,ResourceVersion:124690163,Generation:0,CreationTimestamp:2019-08-09 14:16:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Aug  9 14:16:25.980: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-6144,SelfLink:/api/v1/namespaces/watch-6144/configmaps/e2e-watch-test-label-changed,UID:fd450c21-cd12-49d1-99c4-4fd50bb7eda9,ResourceVersion:124690164,Generation:0,CreationTimestamp:2019-08-09 14:16:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Aug  9 14:16:25.980: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-6144,SelfLink:/api/v1/namespaces/watch-6144/configmaps/e2e-watch-test-label-changed,UID:fd450c21-cd12-49d1-99c4-4fd50bb7eda9,ResourceVersion:124690165,Generation:0,CreationTimestamp:2019-08-09 14:16:15 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:16:25.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6144" for this suite.
Aug  9 14:16:40.738: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:16:41.691: INFO: namespace watch-6144 deletion completed in 15.003345215s

• [SLOW TEST:26.092 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:16:41.691: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4972
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug  9 14:16:42.609: INFO: Waiting up to 5m0s for pod "downwardapi-volume-552853ac-3e7e-4289-b500-c0a347f655a2" in namespace "projected-4972" to be "success or failure"
Aug  9 14:16:42.619: INFO: Pod "downwardapi-volume-552853ac-3e7e-4289-b500-c0a347f655a2": Phase="Pending", Reason="", readiness=false. Elapsed: 9.573931ms
Aug  9 14:16:44.629: INFO: Pod "downwardapi-volume-552853ac-3e7e-4289-b500-c0a347f655a2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019323949s
Aug  9 14:16:46.641: INFO: Pod "downwardapi-volume-552853ac-3e7e-4289-b500-c0a347f655a2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.031355172s
Aug  9 14:16:48.654: INFO: Pod "downwardapi-volume-552853ac-3e7e-4289-b500-c0a347f655a2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.044163591s
STEP: Saw pod success
Aug  9 14:16:48.654: INFO: Pod "downwardapi-volume-552853ac-3e7e-4289-b500-c0a347f655a2" satisfied condition "success or failure"
Aug  9 14:16:48.664: INFO: Trying to get logs from node scw-flan15-default-fbc750a75c7f4c499b691cc5ccd pod downwardapi-volume-552853ac-3e7e-4289-b500-c0a347f655a2 container client-container: <nil>
STEP: delete the pod
Aug  9 14:16:48.729: INFO: Waiting for pod downwardapi-volume-552853ac-3e7e-4289-b500-c0a347f655a2 to disappear
Aug  9 14:16:48.738: INFO: Pod downwardapi-volume-552853ac-3e7e-4289-b500-c0a347f655a2 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:16:48.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4972" for this suite.
Aug  9 14:16:56.797: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:16:57.207: INFO: namespace projected-4972 deletion completed in 8.454775516s

• [SLOW TEST:15.516 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:16:57.207: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7084
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a replication controller
Aug  9 14:16:57.447: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 create -f - --namespace=kubectl-7084'
Aug  9 14:16:58.011: INFO: stderr: ""
Aug  9 14:16:58.011: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug  9 14:16:58.011: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7084'
Aug  9 14:16:58.226: INFO: stderr: ""
Aug  9 14:16:58.226: INFO: stdout: "update-demo-nautilus-26dqd update-demo-nautilus-j79t2 "
Aug  9 14:16:58.226: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 get pods update-demo-nautilus-26dqd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7084'
Aug  9 14:16:58.920: INFO: stderr: ""
Aug  9 14:16:58.920: INFO: stdout: ""
Aug  9 14:16:58.920: INFO: update-demo-nautilus-26dqd is created but not running
Aug  9 14:17:03.921: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7084'
Aug  9 14:17:04.119: INFO: stderr: ""
Aug  9 14:17:04.119: INFO: stdout: "update-demo-nautilus-26dqd update-demo-nautilus-j79t2 "
Aug  9 14:17:04.119: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 get pods update-demo-nautilus-26dqd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7084'
Aug  9 14:17:04.338: INFO: stderr: ""
Aug  9 14:17:04.338: INFO: stdout: "true"
Aug  9 14:17:04.338: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 get pods update-demo-nautilus-26dqd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7084'
Aug  9 14:17:04.505: INFO: stderr: ""
Aug  9 14:17:04.505: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug  9 14:17:04.506: INFO: validating pod update-demo-nautilus-26dqd
Aug  9 14:17:04.611: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug  9 14:17:04.611: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug  9 14:17:04.611: INFO: update-demo-nautilus-26dqd is verified up and running
Aug  9 14:17:04.611: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 get pods update-demo-nautilus-j79t2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7084'
Aug  9 14:17:04.856: INFO: stderr: ""
Aug  9 14:17:04.856: INFO: stdout: ""
Aug  9 14:17:04.856: INFO: update-demo-nautilus-j79t2 is created but not running
Aug  9 14:17:09.856: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7084'
Aug  9 14:17:10.227: INFO: stderr: ""
Aug  9 14:17:10.227: INFO: stdout: "update-demo-nautilus-26dqd update-demo-nautilus-j79t2 "
Aug  9 14:17:10.227: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 get pods update-demo-nautilus-26dqd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7084'
Aug  9 14:17:10.447: INFO: stderr: ""
Aug  9 14:17:10.447: INFO: stdout: "true"
Aug  9 14:17:10.447: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 get pods update-demo-nautilus-26dqd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7084'
Aug  9 14:17:10.636: INFO: stderr: ""
Aug  9 14:17:10.636: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug  9 14:17:10.636: INFO: validating pod update-demo-nautilus-26dqd
Aug  9 14:17:10.650: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug  9 14:17:10.651: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug  9 14:17:10.651: INFO: update-demo-nautilus-26dqd is verified up and running
Aug  9 14:17:10.651: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 get pods update-demo-nautilus-j79t2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7084'
Aug  9 14:17:10.851: INFO: stderr: ""
Aug  9 14:17:10.851: INFO: stdout: "true"
Aug  9 14:17:10.851: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 get pods update-demo-nautilus-j79t2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7084'
Aug  9 14:17:11.063: INFO: stderr: ""
Aug  9 14:17:11.063: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug  9 14:17:11.063: INFO: validating pod update-demo-nautilus-j79t2
Aug  9 14:17:11.162: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug  9 14:17:11.162: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug  9 14:17:11.162: INFO: update-demo-nautilus-j79t2 is verified up and running
STEP: scaling down the replication controller
Aug  9 14:17:11.166: INFO: scanned /root for discovery docs: <nil>
Aug  9 14:17:11.166: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-7084'
Aug  9 14:17:12.469: INFO: stderr: ""
Aug  9 14:17:12.469: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug  9 14:17:12.469: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7084'
Aug  9 14:17:12.670: INFO: stderr: ""
Aug  9 14:17:12.670: INFO: stdout: "update-demo-nautilus-26dqd update-demo-nautilus-j79t2 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Aug  9 14:17:17.670: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7084'
Aug  9 14:17:18.260: INFO: stderr: ""
Aug  9 14:17:18.260: INFO: stdout: "update-demo-nautilus-26dqd "
Aug  9 14:17:18.260: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 get pods update-demo-nautilus-26dqd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7084'
Aug  9 14:17:18.652: INFO: stderr: ""
Aug  9 14:17:18.652: INFO: stdout: "true"
Aug  9 14:17:18.653: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 get pods update-demo-nautilus-26dqd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7084'
Aug  9 14:17:18.919: INFO: stderr: ""
Aug  9 14:17:18.919: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug  9 14:17:18.919: INFO: validating pod update-demo-nautilus-26dqd
Aug  9 14:17:18.937: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug  9 14:17:18.937: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug  9 14:17:18.937: INFO: update-demo-nautilus-26dqd is verified up and running
STEP: scaling up the replication controller
Aug  9 14:17:18.939: INFO: scanned /root for discovery docs: <nil>
Aug  9 14:17:18.940: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-7084'
Aug  9 14:17:21.821: INFO: stderr: ""
Aug  9 14:17:21.821: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug  9 14:17:21.821: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7084'
Aug  9 14:17:22.284: INFO: stderr: ""
Aug  9 14:17:22.284: INFO: stdout: "update-demo-nautilus-26dqd update-demo-nautilus-f5f46 "
Aug  9 14:17:22.285: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 get pods update-demo-nautilus-26dqd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7084'
Aug  9 14:17:22.528: INFO: stderr: ""
Aug  9 14:17:22.528: INFO: stdout: "true"
Aug  9 14:17:22.528: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 get pods update-demo-nautilus-26dqd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7084'
Aug  9 14:17:22.836: INFO: stderr: ""
Aug  9 14:17:22.836: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug  9 14:17:22.836: INFO: validating pod update-demo-nautilus-26dqd
Aug  9 14:17:22.851: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug  9 14:17:22.851: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug  9 14:17:22.851: INFO: update-demo-nautilus-26dqd is verified up and running
Aug  9 14:17:22.851: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 get pods update-demo-nautilus-f5f46 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7084'
Aug  9 14:17:23.051: INFO: stderr: ""
Aug  9 14:17:23.051: INFO: stdout: "true"
Aug  9 14:17:23.051: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 get pods update-demo-nautilus-f5f46 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7084'
Aug  9 14:17:23.229: INFO: stderr: ""
Aug  9 14:17:23.229: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug  9 14:17:23.229: INFO: validating pod update-demo-nautilus-f5f46
Aug  9 14:17:23.343: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug  9 14:17:23.343: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug  9 14:17:23.343: INFO: update-demo-nautilus-f5f46 is verified up and running
STEP: using delete to clean up resources
Aug  9 14:17:23.343: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 delete --grace-period=0 --force -f - --namespace=kubectl-7084'
Aug  9 14:17:23.537: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug  9 14:17:23.537: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Aug  9 14:17:23.538: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-7084'
Aug  9 14:17:23.811: INFO: stderr: "No resources found.\n"
Aug  9 14:17:23.811: INFO: stdout: ""
Aug  9 14:17:23.811: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 get pods -l name=update-demo --namespace=kubectl-7084 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug  9 14:17:24.081: INFO: stderr: ""
Aug  9 14:17:24.081: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:17:24.081: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7084" for this suite.
Aug  9 14:17:52.146: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:17:53.738: INFO: namespace kubectl-7084 deletion completed in 29.635243488s

• [SLOW TEST:56.531 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:17:53.739: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-6509
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-2099
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-6530
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:18:29.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-6509" for this suite.
Aug  9 14:18:37.623: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:18:38.002: INFO: namespace namespaces-6509 deletion completed in 8.435948553s
STEP: Destroying namespace "nsdeletetest-2099" for this suite.
Aug  9 14:18:38.015: INFO: Namespace nsdeletetest-2099 was already deleted
STEP: Destroying namespace "nsdeletetest-6530" for this suite.
Aug  9 14:18:44.061: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:18:44.402: INFO: namespace nsdeletetest-6530 deletion completed in 6.386217329s

• [SLOW TEST:50.663 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:18:44.403: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-1255
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating service multi-endpoint-test in namespace services-1255
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1255 to expose endpoints map[]
Aug  9 14:18:44.763: INFO: Get endpoints failed (10.594491ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Aug  9 14:18:45.781: INFO: successfully validated that service multi-endpoint-test in namespace services-1255 exposes endpoints map[] (1.028923978s elapsed)
STEP: Creating pod pod1 in namespace services-1255
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1255 to expose endpoints map[pod1:[100]]
Aug  9 14:18:48.998: INFO: successfully validated that service multi-endpoint-test in namespace services-1255 exposes endpoints map[pod1:[100]] (3.194209534s elapsed)
STEP: Creating pod pod2 in namespace services-1255
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1255 to expose endpoints map[pod1:[100] pod2:[101]]
Aug  9 14:18:52.143: INFO: successfully validated that service multi-endpoint-test in namespace services-1255 exposes endpoints map[pod1:[100] pod2:[101]] (3.130417968s elapsed)
STEP: Deleting pod pod1 in namespace services-1255
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1255 to expose endpoints map[pod2:[101]]
Aug  9 14:18:53.208: INFO: successfully validated that service multi-endpoint-test in namespace services-1255 exposes endpoints map[pod2:[101]] (1.040042055s elapsed)
STEP: Deleting pod pod2 in namespace services-1255
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-1255 to expose endpoints map[]
Aug  9 14:18:53.260: INFO: successfully validated that service multi-endpoint-test in namespace services-1255 exposes endpoints map[] (18.756181ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:18:53.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1255" for this suite.
Aug  9 14:19:17.436: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:19:17.806: INFO: namespace services-1255 deletion completed in 24.442458342s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:33.403 seconds]
[sig-network] Services
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:19:17.807: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5475
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating Redis RC
Aug  9 14:19:18.026: INFO: namespace kubectl-5475
Aug  9 14:19:18.027: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 create -f - --namespace=kubectl-5475'
Aug  9 14:19:18.597: INFO: stderr: ""
Aug  9 14:19:18.597: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Aug  9 14:19:19.609: INFO: Selector matched 1 pods for map[app:redis]
Aug  9 14:19:19.609: INFO: Found 0 / 1
Aug  9 14:19:20.608: INFO: Selector matched 1 pods for map[app:redis]
Aug  9 14:19:20.609: INFO: Found 0 / 1
Aug  9 14:19:21.645: INFO: Selector matched 1 pods for map[app:redis]
Aug  9 14:19:21.645: INFO: Found 0 / 1
Aug  9 14:19:22.608: INFO: Selector matched 1 pods for map[app:redis]
Aug  9 14:19:22.608: INFO: Found 1 / 1
Aug  9 14:19:22.608: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Aug  9 14:19:22.625: INFO: Selector matched 1 pods for map[app:redis]
Aug  9 14:19:22.625: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug  9 14:19:22.625: INFO: wait on redis-master startup in kubectl-5475 
Aug  9 14:19:22.625: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 logs redis-master-fkplc redis-master --namespace=kubectl-5475'
Aug  9 14:19:22.891: INFO: stderr: ""
Aug  9 14:19:22.891: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 09 Aug 14:19:21.235 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 09 Aug 14:19:21.236 # Server started, Redis version 3.2.12\n1:M 09 Aug 14:19:21.236 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 09 Aug 14:19:21.236 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Aug  9 14:19:22.891: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-5475'
Aug  9 14:19:23.104: INFO: stderr: ""
Aug  9 14:19:23.104: INFO: stdout: "service/rm2 exposed\n"
Aug  9 14:19:23.112: INFO: Service rm2 in namespace kubectl-5475 found.
STEP: exposing service
Aug  9 14:19:25.152: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-5475'
Aug  9 14:19:25.514: INFO: stderr: ""
Aug  9 14:19:25.514: INFO: stdout: "service/rm3 exposed\n"
Aug  9 14:19:25.540: INFO: Service rm3 in namespace kubectl-5475 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:19:27.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5475" for this suite.
Aug  9 14:19:51.629: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:19:52.001: INFO: namespace kubectl-5475 deletion completed in 24.410539924s

• [SLOW TEST:34.194 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl expose
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create services for rc  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:19:52.001: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-2978
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug  9 14:19:52.289: INFO: Creating deployment "nginx-deployment"
Aug  9 14:19:52.302: INFO: Waiting for observed generation 1
Aug  9 14:19:54.332: INFO: Waiting for all required pods to come up
Aug  9 14:19:54.354: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Aug  9 14:19:58.399: INFO: Waiting for deployment "nginx-deployment" to complete
Aug  9 14:19:58.419: INFO: Updating deployment "nginx-deployment" with a non-existent image
Aug  9 14:19:58.442: INFO: Updating deployment nginx-deployment
Aug  9 14:19:58.442: INFO: Waiting for observed generation 2
Aug  9 14:20:00.470: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Aug  9 14:20:00.479: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Aug  9 14:20:00.489: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Aug  9 14:20:00.520: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Aug  9 14:20:00.520: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Aug  9 14:20:00.533: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Aug  9 14:20:00.560: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Aug  9 14:20:00.560: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Aug  9 14:20:00.596: INFO: Updating deployment nginx-deployment
Aug  9 14:20:00.596: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Aug  9 14:20:00.626: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Aug  9 14:20:02.667: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Aug  9 14:20:02.701: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-2978,SelfLink:/apis/apps/v1/namespaces/deployment-2978/deployments/nginx-deployment,UID:500d37b7-4941-4cc2-8173-ae819803cab2,ResourceVersion:124694585,Generation:3,CreationTimestamp:2019-08-09 14:19:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2019-08-09 14:20:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-08-09 14:20:00 +0000 UTC 2019-08-09 14:19:52 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-55fb7cb77f" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Aug  9 14:20:02.713: INFO: New ReplicaSet "nginx-deployment-55fb7cb77f" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f,GenerateName:,Namespace:deployment-2978,SelfLink:/apis/apps/v1/namespaces/deployment-2978/replicasets/nginx-deployment-55fb7cb77f,UID:77afc63a-4967-4dde-acf8-41ac1dfb2613,ResourceVersion:124694577,Generation:3,CreationTimestamp:2019-08-09 14:19:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 500d37b7-4941-4cc2-8173-ae819803cab2 0xc000c342d7 0xc000c342d8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Aug  9 14:20:02.713: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Aug  9 14:20:02.713: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498,GenerateName:,Namespace:deployment-2978,SelfLink:/apis/apps/v1/namespaces/deployment-2978/replicasets/nginx-deployment-7b8c6f4498,UID:1ac1b47a-8434-4daa-8301-f833f9cbb70a,ResourceVersion:124694572,Generation:3,CreationTimestamp:2019-08-09 14:19:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 500d37b7-4941-4cc2-8173-ae819803cab2 0xc000c343a7 0xc000c343a8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Aug  9 14:20:02.746: INFO: Pod "nginx-deployment-55fb7cb77f-77wxj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-77wxj,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-2978,SelfLink:/api/v1/namespaces/deployment-2978/pods/nginx-deployment-55fb7cb77f-77wxj,UID:1fe39cd4-c2c0-4a69-a844-7f915631cdea,ResourceVersion:124694645,Generation:0,CreationTimestamp:2019-08-09 14:19:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 77afc63a-4967-4dde-acf8-41ac1dfb2613 0xc0029ccad7 0xc0029ccad8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wsb95 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wsb95,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-wsb95 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0029ccb50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0029ccb70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:19:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:19:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:19:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:19:58 +0000 UTC  }],Message:,Reason:,HostIP:10.12.129.91,PodIP:100.64.1.97,StartTime:2019-08-09 14:19:58 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  9 14:20:02.746: INFO: Pod "nginx-deployment-55fb7cb77f-7lqvv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-7lqvv,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-2978,SelfLink:/api/v1/namespaces/deployment-2978/pods/nginx-deployment-55fb7cb77f-7lqvv,UID:7da7b7e8-16d9-403c-8bb0-ce2589d9778d,ResourceVersion:124694610,Generation:0,CreationTimestamp:2019-08-09 14:20:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 77afc63a-4967-4dde-acf8-41ac1dfb2613 0xc0029ccc67 0xc0029ccc68}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wsb95 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wsb95,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-wsb95 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-flan15-default-fbc750a75c7f4c499b691cc5ccd,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0029cccd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0029cccf0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC  }],Message:,Reason:,HostIP:10.12.167.225,PodIP:,StartTime:2019-08-09 14:20:00 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  9 14:20:02.746: INFO: Pod "nginx-deployment-55fb7cb77f-7p7jr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-7p7jr,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-2978,SelfLink:/api/v1/namespaces/deployment-2978/pods/nginx-deployment-55fb7cb77f-7p7jr,UID:553140b5-46f6-4ddc-abfc-bad039b99cac,ResourceVersion:124694446,Generation:0,CreationTimestamp:2019-08-09 14:19:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 77afc63a-4967-4dde-acf8-41ac1dfb2613 0xc0029ccdc7 0xc0029ccdc8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wsb95 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wsb95,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-wsb95 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-flan15-default-fbc750a75c7f4c499b691cc5ccd,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0029cce30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0029cce50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:19:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:19:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:19:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:19:58 +0000 UTC  }],Message:,Reason:,HostIP:10.12.167.225,PodIP:,StartTime:2019-08-09 14:19:58 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  9 14:20:02.747: INFO: Pod "nginx-deployment-55fb7cb77f-8rgm7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-8rgm7,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-2978,SelfLink:/api/v1/namespaces/deployment-2978/pods/nginx-deployment-55fb7cb77f-8rgm7,UID:d1770e35-ef9c-4c20-b2d4-f7be6be0f53d,ResourceVersion:124694483,Generation:0,CreationTimestamp:2019-08-09 14:19:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 77afc63a-4967-4dde-acf8-41ac1dfb2613 0xc0029ccf27 0xc0029ccf28}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wsb95 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wsb95,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-wsb95 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-flan15-default-fbc750a75c7f4c499b691cc5ccd,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0029ccfa0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0029ccfd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:19:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:19:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:19:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:19:58 +0000 UTC  }],Message:,Reason:,HostIP:10.12.167.225,PodIP:,StartTime:2019-08-09 14:19:58 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  9 14:20:02.747: INFO: Pod "nginx-deployment-55fb7cb77f-8vzbw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-8vzbw,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-2978,SelfLink:/api/v1/namespaces/deployment-2978/pods/nginx-deployment-55fb7cb77f-8vzbw,UID:f5705695-cb0f-4819-aa74-cff4176d26fd,ResourceVersion:124694589,Generation:0,CreationTimestamp:2019-08-09 14:20:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 77afc63a-4967-4dde-acf8-41ac1dfb2613 0xc0029cd0a7 0xc0029cd0a8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wsb95 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wsb95,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-wsb95 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0029cd110} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0029cd130}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC  }],Message:,Reason:,HostIP:10.12.129.91,PodIP:,StartTime:2019-08-09 14:20:00 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  9 14:20:02.747: INFO: Pod "nginx-deployment-55fb7cb77f-c5l77" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-c5l77,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-2978,SelfLink:/api/v1/namespaces/deployment-2978/pods/nginx-deployment-55fb7cb77f-c5l77,UID:6276f325-f434-4350-afff-dd5a0d8d3f78,ResourceVersion:124694542,Generation:0,CreationTimestamp:2019-08-09 14:20:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 77afc63a-4967-4dde-acf8-41ac1dfb2613 0xc0029cd207 0xc0029cd208}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wsb95 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wsb95,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-wsb95 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-flan15-default-f07a9b7e282146a6b5427e9aba2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0029cd290} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0029cd2b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC  }],Message:,Reason:,HostIP:10.12.155.153,PodIP:,StartTime:2019-08-09 14:20:00 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  9 14:20:02.747: INFO: Pod "nginx-deployment-55fb7cb77f-dddzd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-dddzd,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-2978,SelfLink:/api/v1/namespaces/deployment-2978/pods/nginx-deployment-55fb7cb77f-dddzd,UID:5fafae03-573c-4da2-889c-f5092d03a0fb,ResourceVersion:124694578,Generation:0,CreationTimestamp:2019-08-09 14:20:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 77afc63a-4967-4dde-acf8-41ac1dfb2613 0xc0029cd387 0xc0029cd388}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wsb95 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wsb95,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-wsb95 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0029cd3f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0029cd410}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC  }],Message:,Reason:,HostIP:10.12.129.91,PodIP:,StartTime:2019-08-09 14:20:00 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  9 14:20:02.767: INFO: Pod "nginx-deployment-55fb7cb77f-g4nlt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-g4nlt,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-2978,SelfLink:/api/v1/namespaces/deployment-2978/pods/nginx-deployment-55fb7cb77f-g4nlt,UID:e2725aff-16b1-466b-aa8c-d9efb9a48ddc,ResourceVersion:124694641,Generation:0,CreationTimestamp:2019-08-09 14:19:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 77afc63a-4967-4dde-acf8-41ac1dfb2613 0xc0029cd4e7 0xc0029cd4e8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wsb95 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wsb95,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-wsb95 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-flan15-default-f07a9b7e282146a6b5427e9aba2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0029cd570} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0029cd590}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:19:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:19:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:19:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:19:58 +0000 UTC  }],Message:,Reason:,HostIP:10.12.155.153,PodIP:100.64.0.76,StartTime:2019-08-09 14:19:58 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: manifest for nginx:404 not found,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  9 14:20:02.768: INFO: Pod "nginx-deployment-55fb7cb77f-jvbmv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-jvbmv,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-2978,SelfLink:/api/v1/namespaces/deployment-2978/pods/nginx-deployment-55fb7cb77f-jvbmv,UID:7149bd9a-3a6c-45df-9341-831e7df0251a,ResourceVersion:124694596,Generation:0,CreationTimestamp:2019-08-09 14:20:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 77afc63a-4967-4dde-acf8-41ac1dfb2613 0xc0029cd687 0xc0029cd688}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wsb95 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wsb95,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-wsb95 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-flan15-default-f07a9b7e282146a6b5427e9aba2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0029cd700} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0029cd720}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC  }],Message:,Reason:,HostIP:10.12.155.153,PodIP:,StartTime:2019-08-09 14:20:00 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  9 14:20:02.768: INFO: Pod "nginx-deployment-55fb7cb77f-n4hvr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-n4hvr,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-2978,SelfLink:/api/v1/namespaces/deployment-2978/pods/nginx-deployment-55fb7cb77f-n4hvr,UID:fa528663-b099-4fb2-9bac-036ece137d04,ResourceVersion:124694643,Generation:0,CreationTimestamp:2019-08-09 14:20:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 77afc63a-4967-4dde-acf8-41ac1dfb2613 0xc0029cd7f7 0xc0029cd7f8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wsb95 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wsb95,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-wsb95 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-flan15-default-fbc750a75c7f4c499b691cc5ccd,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0029cd870} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0029cd890}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC  }],Message:,Reason:,HostIP:10.12.167.225,PodIP:,StartTime:2019-08-09 14:20:00 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  9 14:20:02.768: INFO: Pod "nginx-deployment-55fb7cb77f-nr68r" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-nr68r,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-2978,SelfLink:/api/v1/namespaces/deployment-2978/pods/nginx-deployment-55fb7cb77f-nr68r,UID:6b132f88-44ae-4afa-9859-8d48a229f805,ResourceVersion:124694565,Generation:0,CreationTimestamp:2019-08-09 14:20:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 77afc63a-4967-4dde-acf8-41ac1dfb2613 0xc0029cd967 0xc0029cd968}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wsb95 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wsb95,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-wsb95 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-flan15-default-f07a9b7e282146a6b5427e9aba2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0029cd9d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0029cda10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC  }],Message:,Reason:,HostIP:10.12.155.153,PodIP:,StartTime:2019-08-09 14:20:00 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  9 14:20:02.768: INFO: Pod "nginx-deployment-55fb7cb77f-qvwx4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-qvwx4,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-2978,SelfLink:/api/v1/namespaces/deployment-2978/pods/nginx-deployment-55fb7cb77f-qvwx4,UID:4709988e-d796-4a4a-b0b1-a39c2422541e,ResourceVersion:124694477,Generation:0,CreationTimestamp:2019-08-09 14:19:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 77afc63a-4967-4dde-acf8-41ac1dfb2613 0xc0029cdae7 0xc0029cdae8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wsb95 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wsb95,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-wsb95 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0029cdb50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0029cdb80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:19:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:19:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:19:58 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:19:58 +0000 UTC  }],Message:,Reason:,HostIP:10.12.129.91,PodIP:,StartTime:2019-08-09 14:19:58 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  9 14:20:02.768: INFO: Pod "nginx-deployment-55fb7cb77f-slvr2" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-slvr2,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-2978,SelfLink:/api/v1/namespaces/deployment-2978/pods/nginx-deployment-55fb7cb77f-slvr2,UID:f319a3b6-1e7d-4367-b0d1-c5b53779b70b,ResourceVersion:124694599,Generation:0,CreationTimestamp:2019-08-09 14:20:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 77afc63a-4967-4dde-acf8-41ac1dfb2613 0xc0029cdc57 0xc0029cdc58}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wsb95 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wsb95,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-wsb95 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-flan15-default-fbc750a75c7f4c499b691cc5ccd,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0029cdcc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0029cdce0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC  }],Message:,Reason:,HostIP:10.12.167.225,PodIP:,StartTime:2019-08-09 14:20:00 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  9 14:20:02.769: INFO: Pod "nginx-deployment-7b8c6f4498-2pxqg" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-2pxqg,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2978,SelfLink:/api/v1/namespaces/deployment-2978/pods/nginx-deployment-7b8c6f4498-2pxqg,UID:8c0d45aa-6d23-4423-b71a-fdbad296a99f,ResourceVersion:124694404,Generation:0,CreationTimestamp:2019-08-09 14:19:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 1ac1b47a-8434-4daa-8301-f833f9cbb70a 0xc0029cddc7 0xc0029cddc8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wsb95 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wsb95,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wsb95 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-flan15-default-fbc750a75c7f4c499b691cc5ccd,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0029cde30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0029cde50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:19:52 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:19:56 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:19:56 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:19:52 +0000 UTC  }],Message:,Reason:,HostIP:10.12.167.225,PodIP:100.64.2.75,StartTime:2019-08-09 14:19:52 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-09 14:19:55 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://65ac08275f6a201f556cafaff045b858e949aa6bf65e91aa4bae9024be5d33a3}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  9 14:20:02.769: INFO: Pod "nginx-deployment-7b8c6f4498-49bxg" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-49bxg,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2978,SelfLink:/api/v1/namespaces/deployment-2978/pods/nginx-deployment-7b8c6f4498-49bxg,UID:16048d4f-6aa3-413e-a031-290e875fd56a,ResourceVersion:124694407,Generation:0,CreationTimestamp:2019-08-09 14:19:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 1ac1b47a-8434-4daa-8301-f833f9cbb70a 0xc0029cdf37 0xc0029cdf38}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wsb95 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wsb95,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wsb95 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-flan15-default-fbc750a75c7f4c499b691cc5ccd,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0029cdfa0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0029cdfc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:19:52 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:19:56 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:19:56 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:19:52 +0000 UTC  }],Message:,Reason:,HostIP:10.12.167.225,PodIP:100.64.2.74,StartTime:2019-08-09 14:19:52 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-09 14:19:55 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://38166792053d51061f00d28c8c462d00e7d1027718a40581eaea2b2ad1716bf4}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  9 14:20:02.769: INFO: Pod "nginx-deployment-7b8c6f4498-5f6ct" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-5f6ct,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2978,SelfLink:/api/v1/namespaces/deployment-2978/pods/nginx-deployment-7b8c6f4498-5f6ct,UID:06c34817-2869-4369-a2c3-d1660ba45b0d,ResourceVersion:124694630,Generation:0,CreationTimestamp:2019-08-09 14:20:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 1ac1b47a-8434-4daa-8301-f833f9cbb70a 0xc000d18097 0xc000d18098}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wsb95 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wsb95,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wsb95 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-flan15-default-fbc750a75c7f4c499b691cc5ccd,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000d18100} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000d18120}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC  }],Message:,Reason:,HostIP:10.12.167.225,PodIP:,StartTime:2019-08-09 14:20:00 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  9 14:20:02.769: INFO: Pod "nginx-deployment-7b8c6f4498-6kckj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-6kckj,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2978,SelfLink:/api/v1/namespaces/deployment-2978/pods/nginx-deployment-7b8c6f4498-6kckj,UID:e343dc8a-f361-4178-bd6a-0b101edaa49d,ResourceVersion:124694611,Generation:0,CreationTimestamp:2019-08-09 14:20:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 1ac1b47a-8434-4daa-8301-f833f9cbb70a 0xc000d181e7 0xc000d181e8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wsb95 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wsb95,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wsb95 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000d18250} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000d18270}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC  }],Message:,Reason:,HostIP:10.12.129.91,PodIP:,StartTime:2019-08-09 14:20:00 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  9 14:20:02.770: INFO: Pod "nginx-deployment-7b8c6f4498-9hz9j" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-9hz9j,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2978,SelfLink:/api/v1/namespaces/deployment-2978/pods/nginx-deployment-7b8c6f4498-9hz9j,UID:9e0e144a-6b5e-49b0-bcb6-690063c30c7c,ResourceVersion:124694377,Generation:0,CreationTimestamp:2019-08-09 14:19:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 1ac1b47a-8434-4daa-8301-f833f9cbb70a 0xc000d18337 0xc000d18338}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wsb95 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wsb95,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wsb95 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-flan15-default-fbc750a75c7f4c499b691cc5ccd,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000d183b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000d183d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:19:52 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:19:55 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:19:55 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:19:52 +0000 UTC  }],Message:,Reason:,HostIP:10.12.167.225,PodIP:100.64.2.73,StartTime:2019-08-09 14:19:52 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-09 14:19:55 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://1c4f1081f29b0ff5984039b1043b9a7ce5578cc8d9ee7033919e3ec436d86b99}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  9 14:20:02.770: INFO: Pod "nginx-deployment-7b8c6f4498-c97dx" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-c97dx,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2978,SelfLink:/api/v1/namespaces/deployment-2978/pods/nginx-deployment-7b8c6f4498-c97dx,UID:a88b7d7e-4e75-468e-9fef-5cafe40fd9db,ResourceVersion:124694354,Generation:0,CreationTimestamp:2019-08-09 14:19:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 1ac1b47a-8434-4daa-8301-f833f9cbb70a 0xc000d184b7 0xc000d184b8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wsb95 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wsb95,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wsb95 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-flan15-default-f07a9b7e282146a6b5427e9aba2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000d18520} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000d18540}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:19:52 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:19:54 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:19:54 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:19:52 +0000 UTC  }],Message:,Reason:,HostIP:10.12.155.153,PodIP:100.64.0.75,StartTime:2019-08-09 14:19:52 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-09 14:19:54 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://7948c357225a671218cda546395b2984e0cd97fc359174a397c1b03e8b20c1b4}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  9 14:20:02.771: INFO: Pod "nginx-deployment-7b8c6f4498-dm48w" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-dm48w,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2978,SelfLink:/api/v1/namespaces/deployment-2978/pods/nginx-deployment-7b8c6f4498-dm48w,UID:1cf2d04f-9268-402d-ad86-ee18012d5a1e,ResourceVersion:124694587,Generation:0,CreationTimestamp:2019-08-09 14:20:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 1ac1b47a-8434-4daa-8301-f833f9cbb70a 0xc000d18617 0xc000d18618}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wsb95 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wsb95,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wsb95 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-flan15-default-f07a9b7e282146a6b5427e9aba2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000d18690} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000d186b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC  }],Message:,Reason:,HostIP:10.12.155.153,PodIP:,StartTime:2019-08-09 14:20:00 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  9 14:20:02.771: INFO: Pod "nginx-deployment-7b8c6f4498-gb7p8" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-gb7p8,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2978,SelfLink:/api/v1/namespaces/deployment-2978/pods/nginx-deployment-7b8c6f4498-gb7p8,UID:a99e2f73-87b3-4ff5-aacc-32ae71fc07a0,ResourceVersion:124694387,Generation:0,CreationTimestamp:2019-08-09 14:19:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 1ac1b47a-8434-4daa-8301-f833f9cbb70a 0xc000d18777 0xc000d18778}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wsb95 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wsb95,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wsb95 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000d187e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000d18800}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:19:52 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:19:56 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:19:56 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:19:52 +0000 UTC  }],Message:,Reason:,HostIP:10.12.129.91,PodIP:100.64.1.94,StartTime:2019-08-09 14:19:52 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-09 14:19:55 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://22aad98788cc264e95910deaaea7d02c6c952289495ea8e2181befcf294f6202}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  9 14:20:02.771: INFO: Pod "nginx-deployment-7b8c6f4498-h4qhj" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-h4qhj,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2978,SelfLink:/api/v1/namespaces/deployment-2978/pods/nginx-deployment-7b8c6f4498-h4qhj,UID:c6616aa5-d655-4258-a2c7-e785254fc10c,ResourceVersion:124694351,Generation:0,CreationTimestamp:2019-08-09 14:19:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 1ac1b47a-8434-4daa-8301-f833f9cbb70a 0xc000d19007 0xc000d19008}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wsb95 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wsb95,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wsb95 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-flan15-default-f07a9b7e282146a6b5427e9aba2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000d19070} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000d19090}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:19:52 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:19:54 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:19:54 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:19:52 +0000 UTC  }],Message:,Reason:,HostIP:10.12.155.153,PodIP:100.64.0.73,StartTime:2019-08-09 14:19:52 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-09 14:19:53 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://ad419f7ca6e5be57e686f5e8f4d8a3c30d095dc4230043844c4ef456db42202c}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  9 14:20:02.771: INFO: Pod "nginx-deployment-7b8c6f4498-jrtpr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-jrtpr,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2978,SelfLink:/api/v1/namespaces/deployment-2978/pods/nginx-deployment-7b8c6f4498-jrtpr,UID:77fcabe0-e52b-41c4-9a19-441fae1c1f70,ResourceVersion:124694555,Generation:0,CreationTimestamp:2019-08-09 14:20:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 1ac1b47a-8434-4daa-8301-f833f9cbb70a 0xc000d19167 0xc000d19168}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wsb95 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wsb95,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wsb95 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000d191d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000d19200}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC  }],Message:,Reason:,HostIP:10.12.129.91,PodIP:,StartTime:2019-08-09 14:20:00 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  9 14:20:02.772: INFO: Pod "nginx-deployment-7b8c6f4498-kdkfv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-kdkfv,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2978,SelfLink:/api/v1/namespaces/deployment-2978/pods/nginx-deployment-7b8c6f4498-kdkfv,UID:2577efc5-b183-46d9-b385-98434f98a575,ResourceVersion:124694523,Generation:0,CreationTimestamp:2019-08-09 14:20:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 1ac1b47a-8434-4daa-8301-f833f9cbb70a 0xc000d192c7 0xc000d192c8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wsb95 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wsb95,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wsb95 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000d19340} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000d19370}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC  }],Message:,Reason:,HostIP:10.12.129.91,PodIP:,StartTime:2019-08-09 14:20:00 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  9 14:20:02.772: INFO: Pod "nginx-deployment-7b8c6f4498-ksddb" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-ksddb,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2978,SelfLink:/api/v1/namespaces/deployment-2978/pods/nginx-deployment-7b8c6f4498-ksddb,UID:ad1d76f4-00ad-46e5-9561-6040568c9ad0,ResourceVersion:124694581,Generation:0,CreationTimestamp:2019-08-09 14:20:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 1ac1b47a-8434-4daa-8301-f833f9cbb70a 0xc000d19437 0xc000d19438}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wsb95 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wsb95,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wsb95 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000d194a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000d194d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC  }],Message:,Reason:,HostIP:10.12.129.91,PodIP:,StartTime:2019-08-09 14:20:00 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  9 14:20:02.773: INFO: Pod "nginx-deployment-7b8c6f4498-lld64" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-lld64,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2978,SelfLink:/api/v1/namespaces/deployment-2978/pods/nginx-deployment-7b8c6f4498-lld64,UID:3d7d9fa4-ec52-42b8-a58a-808b998f6bfd,ResourceVersion:124694391,Generation:0,CreationTimestamp:2019-08-09 14:19:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 1ac1b47a-8434-4daa-8301-f833f9cbb70a 0xc000d19597 0xc000d19598}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wsb95 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wsb95,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wsb95 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000d19600} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000d19620}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:19:52 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:19:56 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:19:56 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:19:52 +0000 UTC  }],Message:,Reason:,HostIP:10.12.129.91,PodIP:100.64.1.93,StartTime:2019-08-09 14:19:52 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-09 14:19:55 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://52cee6042ce8e254df58e8c771e450bf01fbba1f5e23116183fd0226794ddee6}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  9 14:20:02.774: INFO: Pod "nginx-deployment-7b8c6f4498-n7bvq" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-n7bvq,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2978,SelfLink:/api/v1/namespaces/deployment-2978/pods/nginx-deployment-7b8c6f4498-n7bvq,UID:d1663c8f-1d98-4722-a1fd-762dd33a7f5a,ResourceVersion:124694573,Generation:0,CreationTimestamp:2019-08-09 14:20:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 1ac1b47a-8434-4daa-8301-f833f9cbb70a 0xc000d196f7 0xc000d196f8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wsb95 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wsb95,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wsb95 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-flan15-default-fbc750a75c7f4c499b691cc5ccd,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000d19760} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000d19780}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC  }],Message:,Reason:,HostIP:10.12.167.225,PodIP:,StartTime:2019-08-09 14:20:00 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  9 14:20:02.774: INFO: Pod "nginx-deployment-7b8c6f4498-p44bf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-p44bf,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2978,SelfLink:/api/v1/namespaces/deployment-2978/pods/nginx-deployment-7b8c6f4498-p44bf,UID:89be3edc-4977-42fa-98be-b5085d00caef,ResourceVersion:124694634,Generation:0,CreationTimestamp:2019-08-09 14:20:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 1ac1b47a-8434-4daa-8301-f833f9cbb70a 0xc000d19847 0xc000d19848}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wsb95 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wsb95,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wsb95 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000d198c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000d198e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC  }],Message:,Reason:,HostIP:10.12.129.91,PodIP:,StartTime:2019-08-09 14:20:00 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  9 14:20:02.784: INFO: Pod "nginx-deployment-7b8c6f4498-sp5g6" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-sp5g6,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2978,SelfLink:/api/v1/namespaces/deployment-2978/pods/nginx-deployment-7b8c6f4498-sp5g6,UID:bee5b269-b680-42ef-907c-8a572ab47a27,ResourceVersion:124694617,Generation:0,CreationTimestamp:2019-08-09 14:20:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 1ac1b47a-8434-4daa-8301-f833f9cbb70a 0xc000d199a7 0xc000d199a8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wsb95 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wsb95,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wsb95 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-flan15-default-f07a9b7e282146a6b5427e9aba2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000d19a10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000d19a30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC  }],Message:,Reason:,HostIP:10.12.155.153,PodIP:,StartTime:2019-08-09 14:20:00 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  9 14:20:02.784: INFO: Pod "nginx-deployment-7b8c6f4498-splhk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-splhk,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2978,SelfLink:/api/v1/namespaces/deployment-2978/pods/nginx-deployment-7b8c6f4498-splhk,UID:e438e104-081b-48ab-82dd-3482edd0a429,ResourceVersion:124694590,Generation:0,CreationTimestamp:2019-08-09 14:20:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 1ac1b47a-8434-4daa-8301-f833f9cbb70a 0xc000d19b07 0xc000d19b08}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wsb95 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wsb95,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wsb95 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-flan15-default-fbc750a75c7f4c499b691cc5ccd,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000d19b70} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000d19b90}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC  }],Message:,Reason:,HostIP:10.12.167.225,PodIP:,StartTime:2019-08-09 14:20:00 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  9 14:20:02.785: INFO: Pod "nginx-deployment-7b8c6f4498-vwzmw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-vwzmw,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2978,SelfLink:/api/v1/namespaces/deployment-2978/pods/nginx-deployment-7b8c6f4498-vwzmw,UID:308713b5-57cc-48dd-96a3-5d4bc4d42978,ResourceVersion:124694579,Generation:0,CreationTimestamp:2019-08-09 14:20:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 1ac1b47a-8434-4daa-8301-f833f9cbb70a 0xc000d19c67 0xc000d19c68}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wsb95 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wsb95,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wsb95 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-flan15-default-f07a9b7e282146a6b5427e9aba2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000d19cd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000d19cf0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC  }],Message:,Reason:,HostIP:10.12.155.153,PodIP:,StartTime:2019-08-09 14:20:00 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  9 14:20:02.785: INFO: Pod "nginx-deployment-7b8c6f4498-x29sm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-x29sm,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2978,SelfLink:/api/v1/namespaces/deployment-2978/pods/nginx-deployment-7b8c6f4498-x29sm,UID:ed73a763-ed9f-4fc8-8bc1-5b50ebb472ac,ResourceVersion:124694621,Generation:0,CreationTimestamp:2019-08-09 14:20:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 1ac1b47a-8434-4daa-8301-f833f9cbb70a 0xc000d19db7 0xc000d19db8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wsb95 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wsb95,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wsb95 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-flan15-default-fbc750a75c7f4c499b691cc5ccd,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000d19e20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000d19e40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:20:00 +0000 UTC  }],Message:,Reason:,HostIP:10.12.167.225,PodIP:,StartTime:2019-08-09 14:20:00 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Aug  9 14:20:02.785: INFO: Pod "nginx-deployment-7b8c6f4498-zgzj4" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-zgzj4,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2978,SelfLink:/api/v1/namespaces/deployment-2978/pods/nginx-deployment-7b8c6f4498-zgzj4,UID:f1404a71-e49c-43f0-b11e-11dabae03933,ResourceVersion:124694346,Generation:0,CreationTimestamp:2019-08-09 14:19:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 1ac1b47a-8434-4daa-8301-f833f9cbb70a 0xc000d19f17 0xc000d19f18}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-wsb95 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-wsb95,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-wsb95 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-flan15-default-f07a9b7e282146a6b5427e9aba2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc000d19f80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc000d19fa0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:19:52 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:19:54 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:19:54 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:19:52 +0000 UTC  }],Message:,Reason:,HostIP:10.12.155.153,PodIP:100.64.0.74,StartTime:2019-08-09 14:19:52 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-08-09 14:19:54 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://38126e1c700b4c353d1d3f8691cb08097b4c81dcd55e0b72ffe1614a37bf60ac}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:20:02.785: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2978" for this suite.
Aug  9 14:20:14.903: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:20:15.335: INFO: namespace deployment-2978 deletion completed in 12.488682554s

• [SLOW TEST:23.334 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:20:15.336: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-4276
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating replication controller my-hostname-basic-7ca76894-d549-422d-9709-4d93b3a22a7d
Aug  9 14:20:15.621: INFO: Pod name my-hostname-basic-7ca76894-d549-422d-9709-4d93b3a22a7d: Found 0 pods out of 1
Aug  9 14:20:20.632: INFO: Pod name my-hostname-basic-7ca76894-d549-422d-9709-4d93b3a22a7d: Found 1 pods out of 1
Aug  9 14:20:20.632: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-7ca76894-d549-422d-9709-4d93b3a22a7d" are running
Aug  9 14:20:20.641: INFO: Pod "my-hostname-basic-7ca76894-d549-422d-9709-4d93b3a22a7d-xzmm5" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-09 14:20:15 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-09 14:20:17 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-09 14:20:17 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-08-09 14:20:15 +0000 UTC Reason: Message:}])
Aug  9 14:20:20.642: INFO: Trying to dial the pod
Aug  9 14:20:25.759: INFO: Controller my-hostname-basic-7ca76894-d549-422d-9709-4d93b3a22a7d: Got expected result from replica 1 [my-hostname-basic-7ca76894-d549-422d-9709-4d93b3a22a7d-xzmm5]: "my-hostname-basic-7ca76894-d549-422d-9709-4d93b3a22a7d-xzmm5", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:20:25.759: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-4276" for this suite.
Aug  9 14:20:31.819: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:20:32.284: INFO: namespace replication-controller-4276 deletion completed in 6.509485309s

• [SLOW TEST:16.949 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:20:32.286: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-9600
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug  9 14:20:32.562: INFO: (0) /api/v1/nodes/scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 18.339196ms)
Aug  9 14:20:32.577: INFO: (1) /api/v1/nodes/scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 15.277151ms)
Aug  9 14:20:32.589: INFO: (2) /api/v1/nodes/scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 11.948992ms)
Aug  9 14:20:32.620: INFO: (3) /api/v1/nodes/scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 30.731435ms)
Aug  9 14:20:32.634: INFO: (4) /api/v1/nodes/scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 13.343783ms)
Aug  9 14:20:32.646: INFO: (5) /api/v1/nodes/scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 12.097873ms)
Aug  9 14:20:32.659: INFO: (6) /api/v1/nodes/scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 12.773487ms)
Aug  9 14:20:32.673: INFO: (7) /api/v1/nodes/scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 14.427889ms)
Aug  9 14:20:32.688: INFO: (8) /api/v1/nodes/scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 13.984331ms)
Aug  9 14:20:32.701: INFO: (9) /api/v1/nodes/scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 13.152372ms)
Aug  9 14:20:32.714: INFO: (10) /api/v1/nodes/scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 12.609808ms)
Aug  9 14:20:32.737: INFO: (11) /api/v1/nodes/scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 23.213703ms)
Aug  9 14:20:32.750: INFO: (12) /api/v1/nodes/scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 13.287045ms)
Aug  9 14:20:32.763: INFO: (13) /api/v1/nodes/scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 12.738881ms)
Aug  9 14:20:32.802: INFO: (14) /api/v1/nodes/scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 39.341368ms)
Aug  9 14:20:32.815: INFO: (15) /api/v1/nodes/scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 12.480834ms)
Aug  9 14:20:32.844: INFO: (16) /api/v1/nodes/scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 28.500155ms)
Aug  9 14:20:32.856: INFO: (17) /api/v1/nodes/scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 12.065582ms)
Aug  9 14:20:32.867: INFO: (18) /api/v1/nodes/scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 11.398683ms)
Aug  9 14:20:32.885: INFO: (19) /api/v1/nodes/scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 17.949511ms)
[AfterEach] version v1
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:20:32.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-9600" for this suite.
Aug  9 14:20:40.950: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:20:41.410: INFO: namespace proxy-9600 deletion completed in 8.513262858s

• [SLOW TEST:9.125 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:20:41.411: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-4594
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: getting the auto-created API token
Aug  9 14:20:42.195: INFO: created pod pod-service-account-defaultsa
Aug  9 14:20:42.195: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Aug  9 14:20:42.214: INFO: created pod pod-service-account-mountsa
Aug  9 14:20:42.214: INFO: pod pod-service-account-mountsa service account token volume mount: true
Aug  9 14:20:42.233: INFO: created pod pod-service-account-nomountsa
Aug  9 14:20:42.233: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Aug  9 14:20:42.245: INFO: created pod pod-service-account-defaultsa-mountspec
Aug  9 14:20:42.245: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Aug  9 14:20:42.265: INFO: created pod pod-service-account-mountsa-mountspec
Aug  9 14:20:42.265: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Aug  9 14:20:42.279: INFO: created pod pod-service-account-nomountsa-mountspec
Aug  9 14:20:42.279: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Aug  9 14:20:42.304: INFO: created pod pod-service-account-defaultsa-nomountspec
Aug  9 14:20:42.304: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Aug  9 14:20:42.337: INFO: created pod pod-service-account-mountsa-nomountspec
Aug  9 14:20:42.338: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Aug  9 14:20:42.363: INFO: created pod pod-service-account-nomountsa-nomountspec
Aug  9 14:20:42.363: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:20:42.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-4594" for this suite.
Aug  9 14:20:50.462: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:20:50.828: INFO: namespace svcaccounts-4594 deletion completed in 8.425148347s

• [SLOW TEST:9.417 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:20:50.830: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-4847
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0809 14:21:21.394433      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug  9 14:21:21.394: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:21:21.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4847" for this suite.
Aug  9 14:21:29.460: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:21:29.782: INFO: namespace gc-4847 deletion completed in 8.374905566s

• [SLOW TEST:38.952 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:21:29.782: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-5494
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Aug  9 14:21:34.566: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:21:34.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5494" for this suite.
Aug  9 14:21:46.922: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:21:47.287: INFO: namespace container-runtime-5494 deletion completed in 12.438390475s

• [SLOW TEST:17.506 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:21:47.291: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5833
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-11b6fc4d-8699-4c6f-8b03-0930db0c2ae2
STEP: Creating a pod to test consume configMaps
Aug  9 14:21:47.589: INFO: Waiting up to 5m0s for pod "pod-configmaps-a3d1b037-7a73-4f41-bf8e-d78f5c59c390" in namespace "configmap-5833" to be "success or failure"
Aug  9 14:21:47.601: INFO: Pod "pod-configmaps-a3d1b037-7a73-4f41-bf8e-d78f5c59c390": Phase="Pending", Reason="", readiness=false. Elapsed: 10.377976ms
Aug  9 14:21:49.614: INFO: Pod "pod-configmaps-a3d1b037-7a73-4f41-bf8e-d78f5c59c390": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02286571s
Aug  9 14:21:51.625: INFO: Pod "pod-configmaps-a3d1b037-7a73-4f41-bf8e-d78f5c59c390": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034126047s
STEP: Saw pod success
Aug  9 14:21:51.625: INFO: Pod "pod-configmaps-a3d1b037-7a73-4f41-bf8e-d78f5c59c390" satisfied condition "success or failure"
Aug  9 14:21:51.634: INFO: Trying to get logs from node scw-flan15-default-f07a9b7e282146a6b5427e9aba2 pod pod-configmaps-a3d1b037-7a73-4f41-bf8e-d78f5c59c390 container configmap-volume-test: <nil>
STEP: delete the pod
Aug  9 14:21:52.141: INFO: Waiting for pod pod-configmaps-a3d1b037-7a73-4f41-bf8e-d78f5c59c390 to disappear
Aug  9 14:21:52.149: INFO: Pod pod-configmaps-a3d1b037-7a73-4f41-bf8e-d78f5c59c390 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:21:52.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5833" for this suite.
Aug  9 14:22:00.391: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:22:00.769: INFO: namespace configmap-5833 deletion completed in 8.426097325s

• [SLOW TEST:13.478 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:22:00.769: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1124
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug  9 14:22:01.124: INFO: Waiting up to 5m0s for pod "downwardapi-volume-84124708-e7c8-4d88-97c2-8eca1482a870" in namespace "downward-api-1124" to be "success or failure"
Aug  9 14:22:01.148: INFO: Pod "downwardapi-volume-84124708-e7c8-4d88-97c2-8eca1482a870": Phase="Pending", Reason="", readiness=false. Elapsed: 23.863982ms
Aug  9 14:22:03.164: INFO: Pod "downwardapi-volume-84124708-e7c8-4d88-97c2-8eca1482a870": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039085116s
Aug  9 14:22:05.175: INFO: Pod "downwardapi-volume-84124708-e7c8-4d88-97c2-8eca1482a870": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.050453581s
STEP: Saw pod success
Aug  9 14:22:05.175: INFO: Pod "downwardapi-volume-84124708-e7c8-4d88-97c2-8eca1482a870" satisfied condition "success or failure"
Aug  9 14:22:05.198: INFO: Trying to get logs from node scw-flan15-default-fbc750a75c7f4c499b691cc5ccd pod downwardapi-volume-84124708-e7c8-4d88-97c2-8eca1482a870 container client-container: <nil>
STEP: delete the pod
Aug  9 14:22:05.278: INFO: Waiting for pod downwardapi-volume-84124708-e7c8-4d88-97c2-8eca1482a870 to disappear
Aug  9 14:22:05.284: INFO: Pod downwardapi-volume-84124708-e7c8-4d88-97c2-8eca1482a870 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:22:05.285: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1124" for this suite.
Aug  9 14:22:11.398: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:22:11.761: INFO: namespace downward-api-1124 deletion completed in 6.464737736s

• [SLOW TEST:10.992 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:22:11.763: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-7688
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:22:17.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7688" for this suite.
Aug  9 14:22:25.735: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:22:26.133: INFO: namespace watch-7688 deletion completed in 8.445291659s

• [SLOW TEST:14.370 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:22:26.134: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9671
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug  9 14:22:26.372: INFO: Waiting up to 5m0s for pod "downwardapi-volume-70ee04b4-91c7-4caa-8a35-5265094f0827" in namespace "projected-9671" to be "success or failure"
Aug  9 14:22:26.382: INFO: Pod "downwardapi-volume-70ee04b4-91c7-4caa-8a35-5265094f0827": Phase="Pending", Reason="", readiness=false. Elapsed: 9.805074ms
Aug  9 14:22:28.401: INFO: Pod "downwardapi-volume-70ee04b4-91c7-4caa-8a35-5265094f0827": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028822496s
Aug  9 14:22:30.414: INFO: Pod "downwardapi-volume-70ee04b4-91c7-4caa-8a35-5265094f0827": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.042211346s
STEP: Saw pod success
Aug  9 14:22:30.414: INFO: Pod "downwardapi-volume-70ee04b4-91c7-4caa-8a35-5265094f0827" satisfied condition "success or failure"
Aug  9 14:22:30.426: INFO: Trying to get logs from node scw-flan15-default-fbc750a75c7f4c499b691cc5ccd pod downwardapi-volume-70ee04b4-91c7-4caa-8a35-5265094f0827 container client-container: <nil>
STEP: delete the pod
Aug  9 14:22:30.601: INFO: Waiting for pod downwardapi-volume-70ee04b4-91c7-4caa-8a35-5265094f0827 to disappear
Aug  9 14:22:30.619: INFO: Pod downwardapi-volume-70ee04b4-91c7-4caa-8a35-5265094f0827 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:22:30.619: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9671" for this suite.
Aug  9 14:22:36.713: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:22:37.178: INFO: namespace projected-9671 deletion completed in 6.519899875s

• [SLOW TEST:11.045 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:22:37.183: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-3158
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:22:41.629: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3158" for this suite.
Aug  9 14:23:21.694: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:23:22.795: INFO: namespace kubelet-test-3158 deletion completed in 41.149749129s

• [SLOW TEST:45.612 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:23:22.796: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-14
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on node default medium
Aug  9 14:23:23.184: INFO: Waiting up to 5m0s for pod "pod-acb0a0f5-3dbf-4def-a31e-deb81e44ff41" in namespace "emptydir-14" to be "success or failure"
Aug  9 14:23:23.196: INFO: Pod "pod-acb0a0f5-3dbf-4def-a31e-deb81e44ff41": Phase="Pending", Reason="", readiness=false. Elapsed: 12.485156ms
Aug  9 14:23:25.207: INFO: Pod "pod-acb0a0f5-3dbf-4def-a31e-deb81e44ff41": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023403626s
Aug  9 14:23:27.222: INFO: Pod "pod-acb0a0f5-3dbf-4def-a31e-deb81e44ff41": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038841661s
STEP: Saw pod success
Aug  9 14:23:27.223: INFO: Pod "pod-acb0a0f5-3dbf-4def-a31e-deb81e44ff41" satisfied condition "success or failure"
Aug  9 14:23:27.232: INFO: Trying to get logs from node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d pod pod-acb0a0f5-3dbf-4def-a31e-deb81e44ff41 container test-container: <nil>
STEP: delete the pod
Aug  9 14:23:27.307: INFO: Waiting for pod pod-acb0a0f5-3dbf-4def-a31e-deb81e44ff41 to disappear
Aug  9 14:23:27.320: INFO: Pod pod-acb0a0f5-3dbf-4def-a31e-deb81e44ff41 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:23:27.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-14" for this suite.
Aug  9 14:23:35.383: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:23:36.577: INFO: namespace emptydir-14 deletion completed in 9.235857399s

• [SLOW TEST:13.781 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:23:36.582: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-9781
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-projected-w4wz
STEP: Creating a pod to test atomic-volume-subpath
Aug  9 14:23:36.876: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-w4wz" in namespace "subpath-9781" to be "success or failure"
Aug  9 14:23:36.885: INFO: Pod "pod-subpath-test-projected-w4wz": Phase="Pending", Reason="", readiness=false. Elapsed: 8.777334ms
Aug  9 14:23:38.897: INFO: Pod "pod-subpath-test-projected-w4wz": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02137261s
Aug  9 14:23:40.910: INFO: Pod "pod-subpath-test-projected-w4wz": Phase="Running", Reason="", readiness=true. Elapsed: 4.033922439s
Aug  9 14:23:42.921: INFO: Pod "pod-subpath-test-projected-w4wz": Phase="Running", Reason="", readiness=true. Elapsed: 6.044935333s
Aug  9 14:23:44.931: INFO: Pod "pod-subpath-test-projected-w4wz": Phase="Running", Reason="", readiness=true. Elapsed: 8.055299093s
Aug  9 14:23:46.947: INFO: Pod "pod-subpath-test-projected-w4wz": Phase="Running", Reason="", readiness=true. Elapsed: 10.070598655s
Aug  9 14:23:48.957: INFO: Pod "pod-subpath-test-projected-w4wz": Phase="Running", Reason="", readiness=true. Elapsed: 12.081004685s
Aug  9 14:23:50.969: INFO: Pod "pod-subpath-test-projected-w4wz": Phase="Running", Reason="", readiness=true. Elapsed: 14.092395659s
Aug  9 14:23:52.980: INFO: Pod "pod-subpath-test-projected-w4wz": Phase="Running", Reason="", readiness=true. Elapsed: 16.10411226s
Aug  9 14:23:54.990: INFO: Pod "pod-subpath-test-projected-w4wz": Phase="Running", Reason="", readiness=true. Elapsed: 18.114022764s
Aug  9 14:23:57.005: INFO: Pod "pod-subpath-test-projected-w4wz": Phase="Running", Reason="", readiness=true. Elapsed: 20.128524117s
Aug  9 14:23:59.015: INFO: Pod "pod-subpath-test-projected-w4wz": Phase="Running", Reason="", readiness=true. Elapsed: 22.139063889s
Aug  9 14:24:01.027: INFO: Pod "pod-subpath-test-projected-w4wz": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.151162681s
STEP: Saw pod success
Aug  9 14:24:01.027: INFO: Pod "pod-subpath-test-projected-w4wz" satisfied condition "success or failure"
Aug  9 14:24:01.038: INFO: Trying to get logs from node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d pod pod-subpath-test-projected-w4wz container test-container-subpath-projected-w4wz: <nil>
STEP: delete the pod
Aug  9 14:24:01.110: INFO: Waiting for pod pod-subpath-test-projected-w4wz to disappear
Aug  9 14:24:01.128: INFO: Pod pod-subpath-test-projected-w4wz no longer exists
STEP: Deleting pod pod-subpath-test-projected-w4wz
Aug  9 14:24:01.128: INFO: Deleting pod "pod-subpath-test-projected-w4wz" in namespace "subpath-9781"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:24:01.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9781" for this suite.
Aug  9 14:24:07.212: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:24:07.587: INFO: namespace subpath-9781 deletion completed in 6.428994036s

• [SLOW TEST:31.006 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:24:07.587: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1588
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-35afab5e-e502-4760-9cf6-5f8f5abec324
STEP: Creating a pod to test consume secrets
Aug  9 14:24:07.849: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f345bd72-e612-48eb-9bc2-f25de662e349" in namespace "projected-1588" to be "success or failure"
Aug  9 14:24:07.862: INFO: Pod "pod-projected-secrets-f345bd72-e612-48eb-9bc2-f25de662e349": Phase="Pending", Reason="", readiness=false. Elapsed: 13.513997ms
Aug  9 14:24:09.874: INFO: Pod "pod-projected-secrets-f345bd72-e612-48eb-9bc2-f25de662e349": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025455731s
Aug  9 14:24:11.884: INFO: Pod "pod-projected-secrets-f345bd72-e612-48eb-9bc2-f25de662e349": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035304222s
STEP: Saw pod success
Aug  9 14:24:11.884: INFO: Pod "pod-projected-secrets-f345bd72-e612-48eb-9bc2-f25de662e349" satisfied condition "success or failure"
Aug  9 14:24:11.894: INFO: Trying to get logs from node scw-flan15-default-f07a9b7e282146a6b5427e9aba2 pod pod-projected-secrets-f345bd72-e612-48eb-9bc2-f25de662e349 container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug  9 14:24:12.249: INFO: Waiting for pod pod-projected-secrets-f345bd72-e612-48eb-9bc2-f25de662e349 to disappear
Aug  9 14:24:12.259: INFO: Pod pod-projected-secrets-f345bd72-e612-48eb-9bc2-f25de662e349 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:24:12.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1588" for this suite.
Aug  9 14:24:22.859: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:24:25.808: INFO: namespace projected-1588 deletion completed in 13.092561821s

• [SLOW TEST:18.220 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:24:25.808: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-4243
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-downwardapi-zkr6
STEP: Creating a pod to test atomic-volume-subpath
Aug  9 14:24:26.146: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-zkr6" in namespace "subpath-4243" to be "success or failure"
Aug  9 14:24:26.158: INFO: Pod "pod-subpath-test-downwardapi-zkr6": Phase="Pending", Reason="", readiness=false. Elapsed: 11.913707ms
Aug  9 14:24:28.170: INFO: Pod "pod-subpath-test-downwardapi-zkr6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023400332s
Aug  9 14:24:30.181: INFO: Pod "pod-subpath-test-downwardapi-zkr6": Phase="Running", Reason="", readiness=true. Elapsed: 4.034584508s
Aug  9 14:24:32.199: INFO: Pod "pod-subpath-test-downwardapi-zkr6": Phase="Running", Reason="", readiness=true. Elapsed: 6.052158846s
Aug  9 14:24:34.211: INFO: Pod "pod-subpath-test-downwardapi-zkr6": Phase="Running", Reason="", readiness=true. Elapsed: 8.06411559s
Aug  9 14:24:36.221: INFO: Pod "pod-subpath-test-downwardapi-zkr6": Phase="Running", Reason="", readiness=true. Elapsed: 10.074897891s
Aug  9 14:24:38.232: INFO: Pod "pod-subpath-test-downwardapi-zkr6": Phase="Running", Reason="", readiness=true. Elapsed: 12.085347095s
Aug  9 14:24:40.242: INFO: Pod "pod-subpath-test-downwardapi-zkr6": Phase="Running", Reason="", readiness=true. Elapsed: 14.095495974s
Aug  9 14:24:42.258: INFO: Pod "pod-subpath-test-downwardapi-zkr6": Phase="Running", Reason="", readiness=true. Elapsed: 16.111868638s
Aug  9 14:24:44.270: INFO: Pod "pod-subpath-test-downwardapi-zkr6": Phase="Running", Reason="", readiness=true. Elapsed: 18.123991174s
Aug  9 14:24:46.282: INFO: Pod "pod-subpath-test-downwardapi-zkr6": Phase="Running", Reason="", readiness=true. Elapsed: 20.135451672s
Aug  9 14:24:48.305: INFO: Pod "pod-subpath-test-downwardapi-zkr6": Phase="Running", Reason="", readiness=true. Elapsed: 22.159073041s
Aug  9 14:24:50.317: INFO: Pod "pod-subpath-test-downwardapi-zkr6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.170890644s
STEP: Saw pod success
Aug  9 14:24:50.317: INFO: Pod "pod-subpath-test-downwardapi-zkr6" satisfied condition "success or failure"
Aug  9 14:24:50.328: INFO: Trying to get logs from node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d pod pod-subpath-test-downwardapi-zkr6 container test-container-subpath-downwardapi-zkr6: <nil>
STEP: delete the pod
Aug  9 14:24:50.876: INFO: Waiting for pod pod-subpath-test-downwardapi-zkr6 to disappear
Aug  9 14:24:50.886: INFO: Pod pod-subpath-test-downwardapi-zkr6 no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-zkr6
Aug  9 14:24:50.886: INFO: Deleting pod "pod-subpath-test-downwardapi-zkr6" in namespace "subpath-4243"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:24:50.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4243" for this suite.
Aug  9 14:24:57.563: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:24:57.933: INFO: namespace subpath-4243 deletion completed in 6.413627628s

• [SLOW TEST:32.125 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:24:57.936: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7050
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a replication controller
Aug  9 14:24:58.194: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 create -f - --namespace=kubectl-7050'
Aug  9 14:24:58.998: INFO: stderr: ""
Aug  9 14:24:58.998: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Aug  9 14:24:58.998: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7050'
Aug  9 14:24:59.265: INFO: stderr: ""
Aug  9 14:24:59.265: INFO: stdout: ""
STEP: Replicas for name=update-demo: expected=2 actual=0
Aug  9 14:25:04.268: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7050'
Aug  9 14:25:04.472: INFO: stderr: ""
Aug  9 14:25:04.472: INFO: stdout: "update-demo-nautilus-2fr66 update-demo-nautilus-97cdq "
Aug  9 14:25:04.472: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 get pods update-demo-nautilus-2fr66 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7050'
Aug  9 14:25:04.668: INFO: stderr: ""
Aug  9 14:25:04.668: INFO: stdout: "true"
Aug  9 14:25:04.668: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 get pods update-demo-nautilus-2fr66 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7050'
Aug  9 14:25:05.449: INFO: stderr: ""
Aug  9 14:25:05.449: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug  9 14:25:05.449: INFO: validating pod update-demo-nautilus-2fr66
Aug  9 14:25:05.547: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug  9 14:25:05.547: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug  9 14:25:05.547: INFO: update-demo-nautilus-2fr66 is verified up and running
Aug  9 14:25:05.547: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 get pods update-demo-nautilus-97cdq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7050'
Aug  9 14:25:05.720: INFO: stderr: ""
Aug  9 14:25:05.720: INFO: stdout: "true"
Aug  9 14:25:05.720: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 get pods update-demo-nautilus-97cdq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7050'
Aug  9 14:25:05.937: INFO: stderr: ""
Aug  9 14:25:05.937: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Aug  9 14:25:05.937: INFO: validating pod update-demo-nautilus-97cdq
Aug  9 14:25:06.047: INFO: got data: {
  "image": "nautilus.jpg"
}

Aug  9 14:25:06.047: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Aug  9 14:25:06.047: INFO: update-demo-nautilus-97cdq is verified up and running
STEP: using delete to clean up resources
Aug  9 14:25:06.047: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 delete --grace-period=0 --force -f - --namespace=kubectl-7050'
Aug  9 14:25:06.289: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug  9 14:25:06.289: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Aug  9 14:25:06.289: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-7050'
Aug  9 14:25:06.539: INFO: stderr: "No resources found.\n"
Aug  9 14:25:06.539: INFO: stdout: ""
Aug  9 14:25:06.539: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 get pods -l name=update-demo --namespace=kubectl-7050 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug  9 14:25:06.807: INFO: stderr: ""
Aug  9 14:25:06.807: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:25:06.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7050" for this suite.
Aug  9 14:25:34.865: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:25:35.349: INFO: namespace kubectl-7050 deletion completed in 28.528312035s

• [SLOW TEST:37.414 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:25:35.352: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7239
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug  9 14:25:35.565: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 create -f - --namespace=kubectl-7239'
Aug  9 14:25:36.121: INFO: stderr: ""
Aug  9 14:25:36.121: INFO: stdout: "replicationcontroller/redis-master created\n"
Aug  9 14:25:36.121: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 create -f - --namespace=kubectl-7239'
Aug  9 14:25:36.876: INFO: stderr: ""
Aug  9 14:25:36.876: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Aug  9 14:25:37.891: INFO: Selector matched 1 pods for map[app:redis]
Aug  9 14:25:37.891: INFO: Found 0 / 1
Aug  9 14:25:38.888: INFO: Selector matched 1 pods for map[app:redis]
Aug  9 14:25:38.888: INFO: Found 0 / 1
Aug  9 14:25:39.894: INFO: Selector matched 1 pods for map[app:redis]
Aug  9 14:25:39.894: INFO: Found 1 / 1
Aug  9 14:25:39.894: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Aug  9 14:25:39.904: INFO: Selector matched 1 pods for map[app:redis]
Aug  9 14:25:39.904: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Aug  9 14:25:39.904: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 describe pod redis-master-wpj9n --namespace=kubectl-7239'
Aug  9 14:25:40.257: INFO: stderr: ""
Aug  9 14:25:40.259: INFO: stdout: "Name:           redis-master-wpj9n\nNamespace:      kubectl-7239\nPriority:       0\nNode:           scw-flan15-default-fbc750a75c7f4c499b691cc5ccd/10.12.167.225\nStart Time:     Fri, 09 Aug 2019 14:25:36 +0000\nLabels:         app=redis\n                role=master\nAnnotations:    <none>\nStatus:         Running\nIP:             100.64.2.94\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://0d5f9c609074bd90580b9fa936df32a1d12837eee7ef79ee37e1dcb695b6c79b\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Fri, 09 Aug 2019 14:25:38 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-qpfbw (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-qpfbw:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-qpfbw\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                                                     Message\n  ----    ------     ----  ----                                                     -------\n  Normal  Scheduled  4s    default-scheduler                                        Successfully assigned kubectl-7239/redis-master-wpj9n to scw-flan15-default-fbc750a75c7f4c499b691cc5ccd\n  Normal  Pulled     2s    kubelet, scw-flan15-default-fbc750a75c7f4c499b691cc5ccd  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    2s    kubelet, scw-flan15-default-fbc750a75c7f4c499b691cc5ccd  Created container redis-master\n  Normal  Started    2s    kubelet, scw-flan15-default-fbc750a75c7f4c499b691cc5ccd  Started container redis-master\n"
Aug  9 14:25:40.263: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 describe rc redis-master --namespace=kubectl-7239'
Aug  9 14:25:40.588: INFO: stderr: ""
Aug  9 14:25:40.588: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-7239\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  4s    replication-controller  Created pod: redis-master-wpj9n\n"
Aug  9 14:25:40.589: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 describe service redis-master --namespace=kubectl-7239'
Aug  9 14:25:40.883: INFO: stderr: ""
Aug  9 14:25:40.883: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-7239\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.44.227.4\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         100.64.2.94:6379\nSession Affinity:  None\nEvents:            <none>\n"
Aug  9 14:25:40.897: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 describe node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d'
Aug  9 14:25:41.233: INFO: stderr: ""
Aug  9 14:25:41.233: INFO: stdout: "Name:               scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=GP1-XS\n                    beta.kubernetes.io/os=linux\n                    cloud.scaleway.com/scw-clusterid=50a15538-2502-4efb-982e-714822fafaf7\n                    cloud.scaleway.com/scw-clustername=flan15\n                    cloud.scaleway.com/scw-cniname=flannel\n                    cloud.scaleway.com/scw-container-runtime=docker\n                    cloud.scaleway.com/scw-nodeid=dae50f7b-5eb4-4e2e-9ec9-5580a7dded05\n                    cloud.scaleway.com/scw-nodename=scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d\n                    cloud.scaleway.com/scw-poolid=14c27a03-e3aa-4baa-aa18-f96d6e7528f8\n                    cloud.scaleway.com/scw-poolname=default\n                    failure-domain.beta.kubernetes.io/region=par1\n                    failure-domain.beta.kubernetes.io/zone=14-1-302\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d\n                    kubernetes.io/os=linux\n                    zoneID=par1\nAnnotations:        csi.volume.kubernetes.io/nodeid: {\"csi.scaleway.com\":\"48ece3a6-c5df-4e4e-8dc7-5becb7613586\"}\n                    flannel.alpha.coreos.com/backend-data: {\"VtepMAC\":\"16:27:a3:51:c2:24\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 10.12.129.91\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Fri, 09 Aug 2019 13:00:05 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  KernelDeadlock       False   Fri, 09 Aug 2019 14:24:45 +0000   Fri, 09 Aug 2019 13:00:57 +0000   KernelHasNoDeadlock          kernel has no deadlock\n  ReadonlyFilesystem   False   Fri, 09 Aug 2019 14:24:45 +0000   Fri, 09 Aug 2019 13:00:57 +0000   FilesystemIsNotReadOnly      Filesystem is not read-only\n  MemoryPressure       False   Fri, 09 Aug 2019 14:25:40 +0000   Fri, 09 Aug 2019 13:00:05 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Fri, 09 Aug 2019 14:25:40 +0000   Fri, 09 Aug 2019 13:00:05 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Fri, 09 Aug 2019 14:25:40 +0000   Fri, 09 Aug 2019 13:00:05 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Fri, 09 Aug 2019 14:25:40 +0000   Fri, 09 Aug 2019 13:00:46 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  Hostname:    scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d\n  InternalIP:  10.12.129.91\n  ExternalIP:  51.158.103.108\nCapacity:\n attachable-volumes-csi-csi.scaleway.com:  15\n cpu:                                      4\n ephemeral-storage:                        143957176Ki\n hugepages-1Gi:                            0\n hugepages-2Mi:                            0\n memory:                                   16421996Ki\n pods:                                     110\nAllocatable:\n attachable-volumes-csi-csi.scaleway.com:  15\n cpu:                                      3800m\n ephemeral-storage:                        133471416Ki\n hugepages-1Gi:                            0\n hugepages-2Mi:                            0\n memory:                                   15373420Ki\n pods:                                     110\nSystem Info:\n Machine ID:                 f8424794116f4445952d37299091e3f0\n System UUID:                f8424794116f4445952d37299091e3f0\n Boot ID:                    2019526a-c717-4f39-9e18-dd7b9bf44363\n Kernel Version:             4.15.0-55-generic\n OS Image:                   Ubuntu 18.04.3 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.6.3\n Kubelet Version:            v1.15.2\n Kube-Proxy Version:         v1.15.2\nPodCIDR:                     100.64.1.0/24\nProviderID:                  scaleway://48ece3a6-c5df-4e4e-8dc7-5becb7613586\nNon-terminated Pods:         (7 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  heptio-sonobuoy            sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         84m\n  heptio-sonobuoy            sonobuoy-systemd-logs-daemon-set-c59f53251cea452d-gww4w    0 (0%)        0 (0%)      0 (0%)           0 (0%)         84m\n  kube-system                csi-node-s6ph9                                             0 (0%)        0 (0%)      0 (0%)           0 (0%)         84m\n  kube-system                flannel-qwjfp                                              100m (2%)     100m (2%)   50Mi (0%)        50Mi (0%)      85m\n  kube-system                ingress-traefik-xvq78                                      0 (0%)        0 (0%)      0 (0%)           0 (0%)         84m\n  kube-system                kube-proxy-wjvhf                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         85m\n  kube-system                node-problem-detector-gqzjc                                20m (0%)      200m (5%)   20Mi (0%)        100Mi (0%)     84m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource                                 Requests   Limits\n  --------                                 --------   ------\n  cpu                                      120m (3%)  300m (7%)\n  memory                                   70Mi (0%)  150Mi (0%)\n  ephemeral-storage                        0 (0%)     0 (0%)\n  attachable-volumes-csi-csi.scaleway.com  0          0\nEvents:                                    <none>\n"
Aug  9 14:25:41.233: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 describe namespace kubectl-7239'
Aug  9 14:25:41.471: INFO: stderr: ""
Aug  9 14:25:41.471: INFO: stdout: "Name:         kubectl-7239\nLabels:       e2e-framework=kubectl\n              e2e-run=11f8fffa-f849-4f57-adcb-7f713fa15a16\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:25:41.471: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7239" for this suite.
Aug  9 14:26:05.533: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:26:05.973: INFO: namespace kubectl-7239 deletion completed in 24.486794538s

• [SLOW TEST:30.621 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl describe
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:26:05.974: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-207
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override all
Aug  9 14:26:06.215: INFO: Waiting up to 5m0s for pod "client-containers-43aa4eef-7719-42d7-af69-681d996703d3" in namespace "containers-207" to be "success or failure"
Aug  9 14:26:06.225: INFO: Pod "client-containers-43aa4eef-7719-42d7-af69-681d996703d3": Phase="Pending", Reason="", readiness=false. Elapsed: 9.865342ms
Aug  9 14:26:08.238: INFO: Pod "client-containers-43aa4eef-7719-42d7-af69-681d996703d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022650661s
Aug  9 14:26:10.264: INFO: Pod "client-containers-43aa4eef-7719-42d7-af69-681d996703d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.048650943s
STEP: Saw pod success
Aug  9 14:26:10.264: INFO: Pod "client-containers-43aa4eef-7719-42d7-af69-681d996703d3" satisfied condition "success or failure"
Aug  9 14:26:10.285: INFO: Trying to get logs from node scw-flan15-default-f07a9b7e282146a6b5427e9aba2 pod client-containers-43aa4eef-7719-42d7-af69-681d996703d3 container test-container: <nil>
STEP: delete the pod
Aug  9 14:26:10.401: INFO: Waiting for pod client-containers-43aa4eef-7719-42d7-af69-681d996703d3 to disappear
Aug  9 14:26:10.410: INFO: Pod client-containers-43aa4eef-7719-42d7-af69-681d996703d3 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:26:10.410: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-207" for this suite.
Aug  9 14:26:16.478: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:26:16.872: INFO: namespace containers-207 deletion completed in 6.445142322s

• [SLOW TEST:10.899 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:26:16.872: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-131
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name s-test-opt-del-8a44dd5e-f616-40cd-a163-df29fccb56d2
STEP: Creating secret with name s-test-opt-upd-082f2afa-d9ac-4e5b-a396-7e4d9c1abbcc
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-8a44dd5e-f616-40cd-a163-df29fccb56d2
STEP: Updating secret s-test-opt-upd-082f2afa-d9ac-4e5b-a396-7e4d9c1abbcc
STEP: Creating secret with name s-test-opt-create-8cac291d-1e11-44ca-957b-cdc83e295014
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:26:27.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-131" for this suite.
Aug  9 14:26:51.648: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:26:52.090: INFO: namespace secrets-131 deletion completed in 24.480466122s

• [SLOW TEST:35.218 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:26:52.091: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-2517
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug  9 14:26:52.397: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Aug  9 14:26:57.410: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Aug  9 14:26:57.411: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Aug  9 14:27:01.604: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-2517,SelfLink:/apis/apps/v1/namespaces/deployment-2517/deployments/test-cleanup-deployment,UID:c9b9561c-91e3-46ae-964a-cbeaf2f094a2,ResourceVersion:124703986,Generation:1,CreationTimestamp:2019-08-09 14:26:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 1,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-08-09 14:26:57 +0000 UTC 2019-08-09 14:26:57 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-08-09 14:27:00 +0000 UTC 2019-08-09 14:26:57 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-cleanup-deployment-55bbcbc84c" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Aug  9 14:27:01.617: INFO: New ReplicaSet "test-cleanup-deployment-55bbcbc84c" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55bbcbc84c,GenerateName:,Namespace:deployment-2517,SelfLink:/apis/apps/v1/namespaces/deployment-2517/replicasets/test-cleanup-deployment-55bbcbc84c,UID:d35e2906-3cc2-4216-af34-dee809e1092e,ResourceVersion:124703976,Generation:1,CreationTimestamp:2019-08-09 14:26:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment c9b9561c-91e3-46ae-964a-cbeaf2f094a2 0xc00230d647 0xc00230d648}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Aug  9 14:27:01.628: INFO: Pod "test-cleanup-deployment-55bbcbc84c-66vh7" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55bbcbc84c-66vh7,GenerateName:test-cleanup-deployment-55bbcbc84c-,Namespace:deployment-2517,SelfLink:/api/v1/namespaces/deployment-2517/pods/test-cleanup-deployment-55bbcbc84c-66vh7,UID:b073f7c2-d8d9-4182-ae38-e07c154e574e,ResourceVersion:124703975,Generation:0,CreationTimestamp:2019-08-09 14:26:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-55bbcbc84c d35e2906-3cc2-4216-af34-dee809e1092e 0xc00230dc67 0xc00230dc68}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-z42nz {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-z42nz,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-z42nz true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:scw-flan15-default-fbc750a75c7f4c499b691cc5ccd,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00230dcd0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00230dcf0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:26:57 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:27:00 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:27:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-08-09 14:26:57 +0000 UTC  }],Message:,Reason:,HostIP:10.12.167.225,PodIP:100.64.2.96,StartTime:2019-08-09 14:26:57 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-08-09 14:27:00 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://5e7dc79d145e467500ae04a71c8e15b596ff720c62eb90c66b340f6e5f6497a9}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:27:01.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2517" for this suite.
Aug  9 14:27:07.687: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:27:08.171: INFO: namespace deployment-2517 deletion completed in 6.529660048s

• [SLOW TEST:16.080 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:27:08.171: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7642
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-c96b7dfb-4274-4b6c-a9c5-7fbc18117c74
STEP: Creating a pod to test consume secrets
Aug  9 14:27:08.496: INFO: Waiting up to 5m0s for pod "pod-secrets-bc6669f0-a1e2-4d19-8ee5-4fe68e809fa4" in namespace "secrets-7642" to be "success or failure"
Aug  9 14:27:08.516: INFO: Pod "pod-secrets-bc6669f0-a1e2-4d19-8ee5-4fe68e809fa4": Phase="Pending", Reason="", readiness=false. Elapsed: 20.252346ms
Aug  9 14:27:10.528: INFO: Pod "pod-secrets-bc6669f0-a1e2-4d19-8ee5-4fe68e809fa4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031832849s
Aug  9 14:27:12.540: INFO: Pod "pod-secrets-bc6669f0-a1e2-4d19-8ee5-4fe68e809fa4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.044396432s
STEP: Saw pod success
Aug  9 14:27:12.541: INFO: Pod "pod-secrets-bc6669f0-a1e2-4d19-8ee5-4fe68e809fa4" satisfied condition "success or failure"
Aug  9 14:27:12.551: INFO: Trying to get logs from node scw-flan15-default-f07a9b7e282146a6b5427e9aba2 pod pod-secrets-bc6669f0-a1e2-4d19-8ee5-4fe68e809fa4 container secret-volume-test: <nil>
STEP: delete the pod
Aug  9 14:27:12.626: INFO: Waiting for pod pod-secrets-bc6669f0-a1e2-4d19-8ee5-4fe68e809fa4 to disappear
Aug  9 14:27:12.640: INFO: Pod pod-secrets-bc6669f0-a1e2-4d19-8ee5-4fe68e809fa4 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:27:12.640: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7642" for this suite.
Aug  9 14:27:18.720: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:27:19.044: INFO: namespace secrets-7642 deletion completed in 6.386812931s

• [SLOW TEST:10.873 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:27:19.044: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-3358
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test substitution in container's command
Aug  9 14:27:19.321: INFO: Waiting up to 5m0s for pod "var-expansion-24244609-fe57-4137-b2f3-ffd04a4fd61a" in namespace "var-expansion-3358" to be "success or failure"
Aug  9 14:27:19.331: INFO: Pod "var-expansion-24244609-fe57-4137-b2f3-ffd04a4fd61a": Phase="Pending", Reason="", readiness=false. Elapsed: 10.277297ms
Aug  9 14:27:21.346: INFO: Pod "var-expansion-24244609-fe57-4137-b2f3-ffd04a4fd61a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025012836s
Aug  9 14:27:23.357: INFO: Pod "var-expansion-24244609-fe57-4137-b2f3-ffd04a4fd61a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036420973s
STEP: Saw pod success
Aug  9 14:27:23.358: INFO: Pod "var-expansion-24244609-fe57-4137-b2f3-ffd04a4fd61a" satisfied condition "success or failure"
Aug  9 14:27:23.373: INFO: Trying to get logs from node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d pod var-expansion-24244609-fe57-4137-b2f3-ffd04a4fd61a container dapi-container: <nil>
STEP: delete the pod
Aug  9 14:27:23.447: INFO: Waiting for pod var-expansion-24244609-fe57-4137-b2f3-ffd04a4fd61a to disappear
Aug  9 14:27:23.456: INFO: Pod var-expansion-24244609-fe57-4137-b2f3-ffd04a4fd61a no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:27:23.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-3358" for this suite.
Aug  9 14:27:29.510: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:27:29.873: INFO: namespace var-expansion-3358 deletion completed in 6.400892901s

• [SLOW TEST:10.829 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:27:29.873: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9652
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug  9 14:27:30.150: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f68a9468-0f9e-47a3-bb0a-9deb832663f7" in namespace "projected-9652" to be "success or failure"
Aug  9 14:27:30.160: INFO: Pod "downwardapi-volume-f68a9468-0f9e-47a3-bb0a-9deb832663f7": Phase="Pending", Reason="", readiness=false. Elapsed: 9.792605ms
Aug  9 14:27:32.170: INFO: Pod "downwardapi-volume-f68a9468-0f9e-47a3-bb0a-9deb832663f7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02020059s
Aug  9 14:27:34.182: INFO: Pod "downwardapi-volume-f68a9468-0f9e-47a3-bb0a-9deb832663f7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031790797s
STEP: Saw pod success
Aug  9 14:27:34.182: INFO: Pod "downwardapi-volume-f68a9468-0f9e-47a3-bb0a-9deb832663f7" satisfied condition "success or failure"
Aug  9 14:27:34.191: INFO: Trying to get logs from node scw-flan15-default-f07a9b7e282146a6b5427e9aba2 pod downwardapi-volume-f68a9468-0f9e-47a3-bb0a-9deb832663f7 container client-container: <nil>
STEP: delete the pod
Aug  9 14:27:34.264: INFO: Waiting for pod downwardapi-volume-f68a9468-0f9e-47a3-bb0a-9deb832663f7 to disappear
Aug  9 14:27:34.273: INFO: Pod downwardapi-volume-f68a9468-0f9e-47a3-bb0a-9deb832663f7 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:27:34.273: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9652" for this suite.
Aug  9 14:27:40.335: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:27:40.763: INFO: namespace projected-9652 deletion completed in 6.474148187s

• [SLOW TEST:10.890 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:27:40.763: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1829
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-743f02b3-1198-4d70-ac63-fb872c2aa4b1
STEP: Creating a pod to test consume configMaps
Aug  9 14:27:41.012: INFO: Waiting up to 5m0s for pod "pod-configmaps-929c0bff-6f8e-48e4-b8e2-ad91e9035e33" in namespace "configmap-1829" to be "success or failure"
Aug  9 14:27:41.024: INFO: Pod "pod-configmaps-929c0bff-6f8e-48e4-b8e2-ad91e9035e33": Phase="Pending", Reason="", readiness=false. Elapsed: 11.584122ms
Aug  9 14:27:43.035: INFO: Pod "pod-configmaps-929c0bff-6f8e-48e4-b8e2-ad91e9035e33": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022804766s
Aug  9 14:27:45.049: INFO: Pod "pod-configmaps-929c0bff-6f8e-48e4-b8e2-ad91e9035e33": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0363152s
STEP: Saw pod success
Aug  9 14:27:45.051: INFO: Pod "pod-configmaps-929c0bff-6f8e-48e4-b8e2-ad91e9035e33" satisfied condition "success or failure"
Aug  9 14:27:45.060: INFO: Trying to get logs from node scw-flan15-default-f07a9b7e282146a6b5427e9aba2 pod pod-configmaps-929c0bff-6f8e-48e4-b8e2-ad91e9035e33 container configmap-volume-test: <nil>
STEP: delete the pod
Aug  9 14:27:45.137: INFO: Waiting for pod pod-configmaps-929c0bff-6f8e-48e4-b8e2-ad91e9035e33 to disappear
Aug  9 14:27:45.147: INFO: Pod pod-configmaps-929c0bff-6f8e-48e4-b8e2-ad91e9035e33 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:27:45.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1829" for this suite.
Aug  9 14:27:51.201: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:27:51.528: INFO: namespace configmap-1829 deletion completed in 6.366076403s

• [SLOW TEST:10.764 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:27:51.529: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5734
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on tmpfs
Aug  9 14:27:51.812: INFO: Waiting up to 5m0s for pod "pod-c57a1c91-d3cd-4159-90d3-06a125f94cfd" in namespace "emptydir-5734" to be "success or failure"
Aug  9 14:27:51.829: INFO: Pod "pod-c57a1c91-d3cd-4159-90d3-06a125f94cfd": Phase="Pending", Reason="", readiness=false. Elapsed: 16.857815ms
Aug  9 14:27:53.839: INFO: Pod "pod-c57a1c91-d3cd-4159-90d3-06a125f94cfd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027203265s
Aug  9 14:27:55.851: INFO: Pod "pod-c57a1c91-d3cd-4159-90d3-06a125f94cfd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.039332464s
STEP: Saw pod success
Aug  9 14:27:55.851: INFO: Pod "pod-c57a1c91-d3cd-4159-90d3-06a125f94cfd" satisfied condition "success or failure"
Aug  9 14:27:55.863: INFO: Trying to get logs from node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d pod pod-c57a1c91-d3cd-4159-90d3-06a125f94cfd container test-container: <nil>
STEP: delete the pod
Aug  9 14:27:55.935: INFO: Waiting for pod pod-c57a1c91-d3cd-4159-90d3-06a125f94cfd to disappear
Aug  9 14:27:55.946: INFO: Pod pod-c57a1c91-d3cd-4159-90d3-06a125f94cfd no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:27:55.946: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5734" for this suite.
Aug  9 14:28:02.003: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:28:02.354: INFO: namespace emptydir-5734 deletion completed in 6.395264975s

• [SLOW TEST:10.824 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:28:02.354: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5831
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug  9 14:28:02.574: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 version'
Aug  9 14:28:02.770: INFO: stderr: ""
Aug  9 14:28:02.770: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.2\", GitCommit:\"f6278300bebbb750328ac16ee6dd3aa7d3549568\", GitTreeState:\"clean\", BuildDate:\"2019-08-05T09:23:26Z\", GoVersion:\"go1.12.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.2\", GitCommit:\"f6278300bebbb750328ac16ee6dd3aa7d3549568\", GitTreeState:\"clean\", BuildDate:\"2019-08-05T09:15:22Z\", GoVersion:\"go1.12.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:28:02.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5831" for this suite.
Aug  9 14:28:08.822: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:28:09.505: INFO: namespace kubectl-5831 deletion completed in 6.720526828s

• [SLOW TEST:7.153 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl version
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:28:09.508: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in hostpath-4615
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test hostPath mode
Aug  9 14:28:09.806: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-4615" to be "success or failure"
Aug  9 14:28:09.826: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 19.884763ms
Aug  9 14:28:11.836: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030648639s
Aug  9 14:28:13.863: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.057644976s
STEP: Saw pod success
Aug  9 14:28:13.863: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Aug  9 14:28:13.879: INFO: Trying to get logs from node scw-flan15-default-fbc750a75c7f4c499b691cc5ccd pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Aug  9 14:28:13.995: INFO: Waiting for pod pod-host-path-test to disappear
Aug  9 14:28:14.005: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:28:14.005: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-4615" for this suite.
Aug  9 14:28:20.098: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:28:20.415: INFO: namespace hostpath-4615 deletion completed in 6.398125253s

• [SLOW TEST:10.907 seconds]
[sig-storage] HostPath
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:28:20.415: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-5304
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod liveness-c362f308-91e8-43da-aef4-20a73c18ab11 in namespace container-probe-5304
Aug  9 14:28:24.702: INFO: Started pod liveness-c362f308-91e8-43da-aef4-20a73c18ab11 in namespace container-probe-5304
STEP: checking the pod's current state and verifying that restartCount is present
Aug  9 14:28:24.713: INFO: Initial restart count of pod liveness-c362f308-91e8-43da-aef4-20a73c18ab11 is 0
Aug  9 14:28:38.804: INFO: Restart count of pod container-probe-5304/liveness-c362f308-91e8-43da-aef4-20a73c18ab11 is now 1 (14.090600489s elapsed)
Aug  9 14:28:58.990: INFO: Restart count of pod container-probe-5304/liveness-c362f308-91e8-43da-aef4-20a73c18ab11 is now 2 (34.277007019s elapsed)
Aug  9 14:29:19.110: INFO: Restart count of pod container-probe-5304/liveness-c362f308-91e8-43da-aef4-20a73c18ab11 is now 3 (54.397323527s elapsed)
Aug  9 14:29:39.309: INFO: Restart count of pod container-probe-5304/liveness-c362f308-91e8-43da-aef4-20a73c18ab11 is now 4 (1m14.595975859s elapsed)
Aug  9 14:30:51.880: INFO: Restart count of pod container-probe-5304/liveness-c362f308-91e8-43da-aef4-20a73c18ab11 is now 5 (2m27.167400165s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:30:51.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5304" for this suite.
Aug  9 14:30:58.101: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:30:58.488: INFO: namespace container-probe-5304 deletion completed in 6.428025247s

• [SLOW TEST:158.072 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:30:58.490: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-8477
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override command
Aug  9 14:30:58.771: INFO: Waiting up to 5m0s for pod "client-containers-7cdd2816-53a2-4083-8bd7-2f8e67bca470" in namespace "containers-8477" to be "success or failure"
Aug  9 14:30:58.780: INFO: Pod "client-containers-7cdd2816-53a2-4083-8bd7-2f8e67bca470": Phase="Pending", Reason="", readiness=false. Elapsed: 9.113521ms
Aug  9 14:31:00.792: INFO: Pod "client-containers-7cdd2816-53a2-4083-8bd7-2f8e67bca470": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020886809s
Aug  9 14:31:02.813: INFO: Pod "client-containers-7cdd2816-53a2-4083-8bd7-2f8e67bca470": Phase="Pending", Reason="", readiness=false. Elapsed: 4.04137359s
Aug  9 14:31:04.825: INFO: Pod "client-containers-7cdd2816-53a2-4083-8bd7-2f8e67bca470": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.05384179s
STEP: Saw pod success
Aug  9 14:31:04.825: INFO: Pod "client-containers-7cdd2816-53a2-4083-8bd7-2f8e67bca470" satisfied condition "success or failure"
Aug  9 14:31:04.836: INFO: Trying to get logs from node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d pod client-containers-7cdd2816-53a2-4083-8bd7-2f8e67bca470 container test-container: <nil>
STEP: delete the pod
Aug  9 14:31:04.903: INFO: Waiting for pod client-containers-7cdd2816-53a2-4083-8bd7-2f8e67bca470 to disappear
Aug  9 14:31:04.912: INFO: Pod client-containers-7cdd2816-53a2-4083-8bd7-2f8e67bca470 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:31:04.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8477" for this suite.
Aug  9 14:31:10.990: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:31:11.354: INFO: namespace containers-8477 deletion completed in 6.427057359s

• [SLOW TEST:12.864 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:31:11.354: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4353
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Aug  9 14:31:15.685: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec pod-sharedvolume-67a5f381-8297-4ded-9a10-e648cb21ed42 -c busybox-main-container --namespace=emptydir-4353 -- cat /usr/share/volumeshare/shareddata.txt'
Aug  9 14:31:16.907: INFO: stderr: ""
Aug  9 14:31:16.907: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:31:16.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4353" for this suite.
Aug  9 14:31:22.984: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:31:23.536: INFO: namespace emptydir-4353 deletion completed in 6.604562668s

• [SLOW TEST:12.183 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:31:23.539: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-5146
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Aug  9 14:31:28.339: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-400702193 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Aug  9 14:31:33.887: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:31:33.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5146" for this suite.
Aug  9 14:31:42.109: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:31:42.466: INFO: namespace pods-5146 deletion completed in 8.393100619s

• [SLOW TEST:18.927 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be submitted and removed [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:31:42.467: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4718
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on tmpfs
Aug  9 14:31:42.748: INFO: Waiting up to 5m0s for pod "pod-8d786652-b41e-4011-96d5-26296aca4d8b" in namespace "emptydir-4718" to be "success or failure"
Aug  9 14:31:42.767: INFO: Pod "pod-8d786652-b41e-4011-96d5-26296aca4d8b": Phase="Pending", Reason="", readiness=false. Elapsed: 19.382577ms
Aug  9 14:31:44.781: INFO: Pod "pod-8d786652-b41e-4011-96d5-26296aca4d8b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033386424s
Aug  9 14:31:46.794: INFO: Pod "pod-8d786652-b41e-4011-96d5-26296aca4d8b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.046308265s
STEP: Saw pod success
Aug  9 14:31:46.794: INFO: Pod "pod-8d786652-b41e-4011-96d5-26296aca4d8b" satisfied condition "success or failure"
Aug  9 14:31:46.805: INFO: Trying to get logs from node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d pod pod-8d786652-b41e-4011-96d5-26296aca4d8b container test-container: <nil>
STEP: delete the pod
Aug  9 14:31:46.878: INFO: Waiting for pod pod-8d786652-b41e-4011-96d5-26296aca4d8b to disappear
Aug  9 14:31:46.893: INFO: Pod pod-8d786652-b41e-4011-96d5-26296aca4d8b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:31:46.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4718" for this suite.
Aug  9 14:31:54.999: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:31:55.377: INFO: namespace emptydir-4718 deletion completed in 8.471262127s

• [SLOW TEST:12.910 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:31:55.378: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-67
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-9df0d2f3-7fe6-4ea3-a05a-0b796430669d
STEP: Creating a pod to test consume configMaps
Aug  9 14:31:55.658: INFO: Waiting up to 5m0s for pod "pod-configmaps-06c083b3-39f6-4a8f-812d-01de675f6e72" in namespace "configmap-67" to be "success or failure"
Aug  9 14:31:55.669: INFO: Pod "pod-configmaps-06c083b3-39f6-4a8f-812d-01de675f6e72": Phase="Pending", Reason="", readiness=false. Elapsed: 10.196412ms
Aug  9 14:31:57.682: INFO: Pod "pod-configmaps-06c083b3-39f6-4a8f-812d-01de675f6e72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023368635s
Aug  9 14:31:59.693: INFO: Pod "pod-configmaps-06c083b3-39f6-4a8f-812d-01de675f6e72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034365435s
STEP: Saw pod success
Aug  9 14:31:59.693: INFO: Pod "pod-configmaps-06c083b3-39f6-4a8f-812d-01de675f6e72" satisfied condition "success or failure"
Aug  9 14:31:59.702: INFO: Trying to get logs from node scw-flan15-default-fbc750a75c7f4c499b691cc5ccd pod pod-configmaps-06c083b3-39f6-4a8f-812d-01de675f6e72 container configmap-volume-test: <nil>
STEP: delete the pod
Aug  9 14:31:59.774: INFO: Waiting for pod pod-configmaps-06c083b3-39f6-4a8f-812d-01de675f6e72 to disappear
Aug  9 14:31:59.782: INFO: Pod pod-configmaps-06c083b3-39f6-4a8f-812d-01de675f6e72 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:31:59.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-67" for this suite.
Aug  9 14:32:05.859: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:32:06.268: INFO: namespace configmap-67 deletion completed in 6.45958911s

• [SLOW TEST:10.890 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:32:06.269: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6529
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1421
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Aug  9 14:32:06.478: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-6529'
Aug  9 14:32:06.669: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Aug  9 14:32:06.669: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1427
Aug  9 14:32:08.710: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 delete deployment e2e-test-nginx-deployment --namespace=kubectl-6529'
Aug  9 14:32:08.967: INFO: stderr: ""
Aug  9 14:32:08.967: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:32:08.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6529" for this suite.
Aug  9 14:32:15.028: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:32:15.482: INFO: namespace kubectl-6529 deletion completed in 6.503316618s

• [SLOW TEST:9.214 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run default
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:32:15.483: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8974
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap that has name configmap-test-emptyKey-93b0fb7a-bb83-4246-a633-37b46e8c096b
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:32:15.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8974" for this suite.
Aug  9 14:32:21.799: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:32:22.167: INFO: namespace configmap-8974 deletion completed in 6.410681098s

• [SLOW TEST:6.685 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:32:22.168: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8804
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on node default medium
Aug  9 14:32:22.423: INFO: Waiting up to 5m0s for pod "pod-3f6d7609-3ce7-45d6-9605-fde58bb81447" in namespace "emptydir-8804" to be "success or failure"
Aug  9 14:32:22.432: INFO: Pod "pod-3f6d7609-3ce7-45d6-9605-fde58bb81447": Phase="Pending", Reason="", readiness=false. Elapsed: 9.289854ms
Aug  9 14:32:24.442: INFO: Pod "pod-3f6d7609-3ce7-45d6-9605-fde58bb81447": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018813872s
Aug  9 14:32:26.461: INFO: Pod "pod-3f6d7609-3ce7-45d6-9605-fde58bb81447": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038086295s
STEP: Saw pod success
Aug  9 14:32:26.461: INFO: Pod "pod-3f6d7609-3ce7-45d6-9605-fde58bb81447" satisfied condition "success or failure"
Aug  9 14:32:26.472: INFO: Trying to get logs from node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d pod pod-3f6d7609-3ce7-45d6-9605-fde58bb81447 container test-container: <nil>
STEP: delete the pod
Aug  9 14:32:27.094: INFO: Waiting for pod pod-3f6d7609-3ce7-45d6-9605-fde58bb81447 to disappear
Aug  9 14:32:27.108: INFO: Pod pod-3f6d7609-3ce7-45d6-9605-fde58bb81447 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:32:27.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8804" for this suite.
Aug  9 14:32:33.172: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:32:33.570: INFO: namespace emptydir-8804 deletion completed in 6.447214415s

• [SLOW TEST:11.403 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:32:33.570: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2190
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: validating cluster-info
Aug  9 14:32:33.804: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 cluster-info'
Aug  9 14:32:34.002: INFO: stderr: ""
Aug  9 14:32:34.002: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.32.0.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://10.32.0.1:443/api/v1/namespaces/kube-system/services/coredns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:32:34.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2190" for this suite.
Aug  9 14:32:40.076: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:32:40.472: INFO: namespace kubectl-2190 deletion completed in 6.449914687s

• [SLOW TEST:6.901 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:32:40.473: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-9104
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-9104
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug  9 14:32:40.712: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Aug  9 14:32:59.016: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.64.2.102:8080/dial?request=hostName&protocol=http&host=100.64.2.101&port=8080&tries=1'] Namespace:pod-network-test-9104 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  9 14:32:59.016: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
Aug  9 14:32:59.263: INFO: Waiting for endpoints: map[]
Aug  9 14:32:59.276: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.64.2.102:8080/dial?request=hostName&protocol=http&host=100.64.0.96&port=8080&tries=1'] Namespace:pod-network-test-9104 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  9 14:32:59.276: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
Aug  9 14:32:59.471: INFO: Waiting for endpoints: map[]
Aug  9 14:32:59.483: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.64.2.102:8080/dial?request=hostName&protocol=http&host=100.64.1.119&port=8080&tries=1'] Namespace:pod-network-test-9104 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  9 14:32:59.483: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
Aug  9 14:32:59.667: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:32:59.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-9104" for this suite.
Aug  9 14:33:23.748: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:33:24.213: INFO: namespace pod-network-test-9104 deletion completed in 24.509855912s

• [SLOW TEST:43.740 seconds]
[sig-network] Networking
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:33:24.214: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9872
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Aug  9 14:33:24.467: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e42e158b-87e9-420a-b3a2-65ef5b2b358b" in namespace "downward-api-9872" to be "success or failure"
Aug  9 14:33:24.477: INFO: Pod "downwardapi-volume-e42e158b-87e9-420a-b3a2-65ef5b2b358b": Phase="Pending", Reason="", readiness=false. Elapsed: 10.189018ms
Aug  9 14:33:26.491: INFO: Pod "downwardapi-volume-e42e158b-87e9-420a-b3a2-65ef5b2b358b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024077371s
Aug  9 14:33:28.503: INFO: Pod "downwardapi-volume-e42e158b-87e9-420a-b3a2-65ef5b2b358b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036150949s
STEP: Saw pod success
Aug  9 14:33:28.503: INFO: Pod "downwardapi-volume-e42e158b-87e9-420a-b3a2-65ef5b2b358b" satisfied condition "success or failure"
Aug  9 14:33:28.514: INFO: Trying to get logs from node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d pod downwardapi-volume-e42e158b-87e9-420a-b3a2-65ef5b2b358b container client-container: <nil>
STEP: delete the pod
Aug  9 14:33:28.593: INFO: Waiting for pod downwardapi-volume-e42e158b-87e9-420a-b3a2-65ef5b2b358b to disappear
Aug  9 14:33:28.608: INFO: Pod downwardapi-volume-e42e158b-87e9-420a-b3a2-65ef5b2b358b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:33:28.608: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9872" for this suite.
Aug  9 14:33:34.683: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:33:35.089: INFO: namespace downward-api-9872 deletion completed in 6.462837265s

• [SLOW TEST:10.875 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:33:35.091: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6212
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Aug  9 14:33:35.435: INFO: Waiting up to 5m0s for pod "downward-api-e906056d-474b-4654-bd82-01f5d8ed8345" in namespace "downward-api-6212" to be "success or failure"
Aug  9 14:33:35.467: INFO: Pod "downward-api-e906056d-474b-4654-bd82-01f5d8ed8345": Phase="Pending", Reason="", readiness=false. Elapsed: 32.090713ms
Aug  9 14:33:37.478: INFO: Pod "downward-api-e906056d-474b-4654-bd82-01f5d8ed8345": Phase="Pending", Reason="", readiness=false. Elapsed: 2.043084203s
Aug  9 14:33:39.488: INFO: Pod "downward-api-e906056d-474b-4654-bd82-01f5d8ed8345": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.052729508s
STEP: Saw pod success
Aug  9 14:33:39.488: INFO: Pod "downward-api-e906056d-474b-4654-bd82-01f5d8ed8345" satisfied condition "success or failure"
Aug  9 14:33:39.497: INFO: Trying to get logs from node scw-flan15-default-fbc750a75c7f4c499b691cc5ccd pod downward-api-e906056d-474b-4654-bd82-01f5d8ed8345 container dapi-container: <nil>
STEP: delete the pod
Aug  9 14:33:39.582: INFO: Waiting for pod downward-api-e906056d-474b-4654-bd82-01f5d8ed8345 to disappear
Aug  9 14:33:39.591: INFO: Pod downward-api-e906056d-474b-4654-bd82-01f5d8ed8345 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:33:39.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6212" for this suite.
Aug  9 14:33:45.684: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:33:46.121: INFO: namespace downward-api-6212 deletion completed in 6.502475343s

• [SLOW TEST:11.031 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:33:46.123: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-4546
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug  9 14:33:46.420: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"154dadb8-2815-425b-9acc-2ed8c11855de", Controller:(*bool)(0xc003609b32), BlockOwnerDeletion:(*bool)(0xc003609b33)}}
Aug  9 14:33:46.440: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"c19a0ca3-7310-4415-acf9-f0c0b1e74d11", Controller:(*bool)(0xc002816bb2), BlockOwnerDeletion:(*bool)(0xc002816bb3)}}
Aug  9 14:33:46.475: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"d6a9068c-7fcc-4356-91dc-da1f16d73b56", Controller:(*bool)(0xc003609cea), BlockOwnerDeletion:(*bool)(0xc003609ceb)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:33:51.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4546" for this suite.
Aug  9 14:33:59.566: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:33:59.967: INFO: namespace gc-4546 deletion completed in 8.440659428s

• [SLOW TEST:13.844 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:33:59.967: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-681
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:34:00.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-681" for this suite.
Aug  9 14:34:06.336: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:34:06.717: INFO: namespace kubelet-test-681 deletion completed in 6.429103895s

• [SLOW TEST:6.751 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:34:06.718: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4774
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1293
STEP: creating an rc
Aug  9 14:34:07.045: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 create -f - --namespace=kubectl-4774'
Aug  9 14:34:07.559: INFO: stderr: ""
Aug  9 14:34:07.559: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Waiting for Redis master to start.
Aug  9 14:34:08.608: INFO: Selector matched 1 pods for map[app:redis]
Aug  9 14:34:08.608: INFO: Found 0 / 1
Aug  9 14:34:09.577: INFO: Selector matched 1 pods for map[app:redis]
Aug  9 14:34:09.577: INFO: Found 0 / 1
Aug  9 14:34:10.575: INFO: Selector matched 1 pods for map[app:redis]
Aug  9 14:34:10.575: INFO: Found 1 / 1
Aug  9 14:34:10.575: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Aug  9 14:34:10.585: INFO: Selector matched 1 pods for map[app:redis]
Aug  9 14:34:10.585: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Aug  9 14:34:10.585: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 logs redis-master-pvkxb redis-master --namespace=kubectl-4774'
Aug  9 14:34:10.836: INFO: stderr: ""
Aug  9 14:34:10.837: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 09 Aug 14:34:09.583 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 09 Aug 14:34:09.583 # Server started, Redis version 3.2.12\n1:M 09 Aug 14:34:09.583 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 09 Aug 14:34:09.583 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Aug  9 14:34:10.837: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 log redis-master-pvkxb redis-master --namespace=kubectl-4774 --tail=1'
Aug  9 14:34:11.120: INFO: stderr: ""
Aug  9 14:34:11.120: INFO: stdout: "1:M 09 Aug 14:34:09.583 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Aug  9 14:34:11.120: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 log redis-master-pvkxb redis-master --namespace=kubectl-4774 --limit-bytes=1'
Aug  9 14:34:11.420: INFO: stderr: ""
Aug  9 14:34:11.421: INFO: stdout: " "
STEP: exposing timestamps
Aug  9 14:34:11.421: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 log redis-master-pvkxb redis-master --namespace=kubectl-4774 --tail=1 --timestamps'
Aug  9 14:34:11.677: INFO: stderr: ""
Aug  9 14:34:11.677: INFO: stdout: "2019-08-09T14:34:09.584163626Z 1:M 09 Aug 14:34:09.583 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Aug  9 14:34:14.177: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 log redis-master-pvkxb redis-master --namespace=kubectl-4774 --since=1s'
Aug  9 14:34:14.480: INFO: stderr: ""
Aug  9 14:34:14.480: INFO: stdout: ""
Aug  9 14:34:14.481: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 log redis-master-pvkxb redis-master --namespace=kubectl-4774 --since=24h'
Aug  9 14:34:14.702: INFO: stderr: ""
Aug  9 14:34:14.702: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 09 Aug 14:34:09.583 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 09 Aug 14:34:09.583 # Server started, Redis version 3.2.12\n1:M 09 Aug 14:34:09.583 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 09 Aug 14:34:09.583 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1299
STEP: using delete to clean up resources
Aug  9 14:34:14.702: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 delete --grace-period=0 --force -f - --namespace=kubectl-4774'
Aug  9 14:34:14.926: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Aug  9 14:34:14.927: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Aug  9 14:34:14.927: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 get rc,svc -l name=nginx --no-headers --namespace=kubectl-4774'
Aug  9 14:34:15.189: INFO: stderr: "No resources found.\n"
Aug  9 14:34:15.189: INFO: stdout: ""
Aug  9 14:34:15.189: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 get pods -l name=nginx --namespace=kubectl-4774 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Aug  9 14:34:15.699: INFO: stderr: ""
Aug  9 14:34:15.699: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:34:15.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4774" for this suite.
Aug  9 14:34:40.034: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:34:40.377: INFO: namespace kubectl-4774 deletion completed in 24.383656042s

• [SLOW TEST:33.659 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl logs
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:34:40.377: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8568
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating secret secrets-8568/secret-test-4b09a87d-bb74-49e1-93cb-0f78a5f2bbd1
STEP: Creating a pod to test consume secrets
Aug  9 14:34:40.636: INFO: Waiting up to 5m0s for pod "pod-configmaps-97ba4bd2-f675-4b3f-bc79-f27bc1a46cff" in namespace "secrets-8568" to be "success or failure"
Aug  9 14:34:40.655: INFO: Pod "pod-configmaps-97ba4bd2-f675-4b3f-bc79-f27bc1a46cff": Phase="Pending", Reason="", readiness=false. Elapsed: 19.122088ms
Aug  9 14:34:42.667: INFO: Pod "pod-configmaps-97ba4bd2-f675-4b3f-bc79-f27bc1a46cff": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031315077s
Aug  9 14:34:44.676: INFO: Pod "pod-configmaps-97ba4bd2-f675-4b3f-bc79-f27bc1a46cff": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040190699s
STEP: Saw pod success
Aug  9 14:34:44.676: INFO: Pod "pod-configmaps-97ba4bd2-f675-4b3f-bc79-f27bc1a46cff" satisfied condition "success or failure"
Aug  9 14:34:44.698: INFO: Trying to get logs from node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d pod pod-configmaps-97ba4bd2-f675-4b3f-bc79-f27bc1a46cff container env-test: <nil>
STEP: delete the pod
Aug  9 14:34:44.758: INFO: Waiting for pod pod-configmaps-97ba4bd2-f675-4b3f-bc79-f27bc1a46cff to disappear
Aug  9 14:34:44.767: INFO: Pod pod-configmaps-97ba4bd2-f675-4b3f-bc79-f27bc1a46cff no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:34:44.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8568" for this suite.
Aug  9 14:34:50.830: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:34:51.368: INFO: namespace secrets-8568 deletion completed in 6.587950732s

• [SLOW TEST:10.991 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:34:51.368: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-1388
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
Aug  9 14:34:52.304: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
W0809 14:34:52.304787      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug  9 14:34:52.305: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1388" for this suite.
Aug  9 14:34:58.377: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:34:58.833: INFO: namespace gc-1388 deletion completed in 6.508939519s

• [SLOW TEST:7.464 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:34:58.834: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-399
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir volume type on node default medium
Aug  9 14:34:59.081: INFO: Waiting up to 5m0s for pod "pod-112c6a9e-07fc-4e7d-9681-6aa16c6beca1" in namespace "emptydir-399" to be "success or failure"
Aug  9 14:34:59.095: INFO: Pod "pod-112c6a9e-07fc-4e7d-9681-6aa16c6beca1": Phase="Pending", Reason="", readiness=false. Elapsed: 13.901176ms
Aug  9 14:35:01.106: INFO: Pod "pod-112c6a9e-07fc-4e7d-9681-6aa16c6beca1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024730639s
Aug  9 14:35:03.117: INFO: Pod "pod-112c6a9e-07fc-4e7d-9681-6aa16c6beca1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036019315s
STEP: Saw pod success
Aug  9 14:35:03.117: INFO: Pod "pod-112c6a9e-07fc-4e7d-9681-6aa16c6beca1" satisfied condition "success or failure"
Aug  9 14:35:03.127: INFO: Trying to get logs from node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d pod pod-112c6a9e-07fc-4e7d-9681-6aa16c6beca1 container test-container: <nil>
STEP: delete the pod
Aug  9 14:35:03.206: INFO: Waiting for pod pod-112c6a9e-07fc-4e7d-9681-6aa16c6beca1 to disappear
Aug  9 14:35:03.216: INFO: Pod pod-112c6a9e-07fc-4e7d-9681-6aa16c6beca1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:35:03.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-399" for this suite.
Aug  9 14:35:09.277: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:35:09.663: INFO: namespace emptydir-399 deletion completed in 6.433281235s

• [SLOW TEST:10.829 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:35:09.666: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-1795
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating pod
Aug  9 14:35:14.020: INFO: Pod pod-hostip-483dd44e-abf6-4087-9233-5fa124edbc36 has hostIP: 10.12.167.225
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:35:14.020: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1795" for this suite.
Aug  9 14:35:44.087: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:35:46.642: INFO: namespace pods-1795 deletion completed in 32.606916246s

• [SLOW TEST:36.977 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:35:46.643: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2382
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: executing a command with run --rm and attach with stdin
Aug  9 14:35:48.056: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 --namespace=kubectl-2382 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Aug  9 14:35:59.247: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Aug  9 14:35:59.247: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:36:01.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2382" for this suite.
Aug  9 14:36:09.918: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:36:10.291: INFO: namespace kubectl-2382 deletion completed in 8.481411621s

• [SLOW TEST:23.648 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:36:10.291: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3130
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Aug  9 14:36:15.813: INFO: Successfully updated pod "labelsupdate0789feed-2b12-4f10-b6c2-08ce40276eb9"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:36:17.889: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3130" for this suite.
Aug  9 14:36:53.998: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:36:55.553: INFO: namespace downward-api-3130 deletion completed in 37.65050703s

• [SLOW TEST:45.262 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:36:55.553: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6234
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-e89db761-c962-4595-ae90-6422aee732e4
STEP: Creating a pod to test consume configMaps
Aug  9 14:36:55.827: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4503b63d-f347-4dfe-b8ce-876b8e4e1c08" in namespace "projected-6234" to be "success or failure"
Aug  9 14:36:55.835: INFO: Pod "pod-projected-configmaps-4503b63d-f347-4dfe-b8ce-876b8e4e1c08": Phase="Pending", Reason="", readiness=false. Elapsed: 8.359417ms
Aug  9 14:36:57.852: INFO: Pod "pod-projected-configmaps-4503b63d-f347-4dfe-b8ce-876b8e4e1c08": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025502978s
Aug  9 14:36:59.869: INFO: Pod "pod-projected-configmaps-4503b63d-f347-4dfe-b8ce-876b8e4e1c08": Phase="Pending", Reason="", readiness=false. Elapsed: 4.042088576s
Aug  9 14:37:01.880: INFO: Pod "pod-projected-configmaps-4503b63d-f347-4dfe-b8ce-876b8e4e1c08": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.05323157s
STEP: Saw pod success
Aug  9 14:37:01.880: INFO: Pod "pod-projected-configmaps-4503b63d-f347-4dfe-b8ce-876b8e4e1c08" satisfied condition "success or failure"
Aug  9 14:37:01.908: INFO: Trying to get logs from node scw-flan15-default-f07a9b7e282146a6b5427e9aba2 pod pod-projected-configmaps-4503b63d-f347-4dfe-b8ce-876b8e4e1c08 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug  9 14:37:02.713: INFO: Waiting for pod pod-projected-configmaps-4503b63d-f347-4dfe-b8ce-876b8e4e1c08 to disappear
Aug  9 14:37:02.726: INFO: Pod pod-projected-configmaps-4503b63d-f347-4dfe-b8ce-876b8e4e1c08 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:37:02.726: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6234" for this suite.
Aug  9 14:37:14.797: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:37:15.195: INFO: namespace projected-6234 deletion completed in 12.452141019s

• [SLOW TEST:19.641 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:37:15.196: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-5882
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Aug  9 14:37:15.690: INFO: Number of nodes with available pods: 0
Aug  9 14:37:15.690: INFO: Node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d is running more than one daemon pod
Aug  9 14:37:16.721: INFO: Number of nodes with available pods: 0
Aug  9 14:37:16.722: INFO: Node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d is running more than one daemon pod
Aug  9 14:37:17.785: INFO: Number of nodes with available pods: 0
Aug  9 14:37:17.785: INFO: Node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d is running more than one daemon pod
Aug  9 14:37:18.760: INFO: Number of nodes with available pods: 1
Aug  9 14:37:18.760: INFO: Node scw-flan15-default-f07a9b7e282146a6b5427e9aba2 is running more than one daemon pod
Aug  9 14:37:20.037: INFO: Number of nodes with available pods: 3
Aug  9 14:37:20.037: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Aug  9 14:37:20.948: INFO: Number of nodes with available pods: 3
Aug  9 14:37:20.948: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5882, will wait for the garbage collector to delete the pods
Aug  9 14:37:24.079: INFO: Deleting DaemonSet.extensions daemon-set took: 34.856102ms
Aug  9 14:37:29.679: INFO: Terminating DaemonSet.extensions daemon-set pods took: 5.600374665s
Aug  9 14:37:37.991: INFO: Number of nodes with available pods: 0
Aug  9 14:37:37.991: INFO: Number of running nodes: 0, number of available pods: 0
Aug  9 14:37:38.001: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-5882/daemonsets","resourceVersion":"124716900"},"items":null}

Aug  9 14:37:38.010: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-5882/pods","resourceVersion":"124716900"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:37:39.818: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5882" for this suite.
Aug  9 14:38:08.628: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:38:16.225: INFO: namespace daemonsets-5882 deletion completed in 35.638139623s

• [SLOW TEST:61.030 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:38:16.230: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9862
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Starting the proxy
Aug  9 14:38:18.082: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-400702193 proxy --unix-socket=/tmp/kubectl-proxy-unix858437776/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:38:18.212: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9862" for this suite.
Aug  9 14:38:27.583: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:38:27.963: INFO: namespace kubectl-9862 deletion completed in 6.433842374s

• [SLOW TEST:11.733 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:38:27.964: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5811
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-ab318315-aadc-473c-9bdb-43b138c6ebe5
STEP: Creating a pod to test consume configMaps
Aug  9 14:38:28.231: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-2d9baadd-1c15-4907-a886-8803573c3b0d" in namespace "projected-5811" to be "success or failure"
Aug  9 14:38:28.250: INFO: Pod "pod-projected-configmaps-2d9baadd-1c15-4907-a886-8803573c3b0d": Phase="Pending", Reason="", readiness=false. Elapsed: 18.408178ms
Aug  9 14:38:30.267: INFO: Pod "pod-projected-configmaps-2d9baadd-1c15-4907-a886-8803573c3b0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035910047s
Aug  9 14:38:32.278: INFO: Pod "pod-projected-configmaps-2d9baadd-1c15-4907-a886-8803573c3b0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.046816753s
STEP: Saw pod success
Aug  9 14:38:32.278: INFO: Pod "pod-projected-configmaps-2d9baadd-1c15-4907-a886-8803573c3b0d" satisfied condition "success or failure"
Aug  9 14:38:32.287: INFO: Trying to get logs from node scw-flan15-default-fbc750a75c7f4c499b691cc5ccd pod pod-projected-configmaps-2d9baadd-1c15-4907-a886-8803573c3b0d container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug  9 14:38:32.383: INFO: Waiting for pod pod-projected-configmaps-2d9baadd-1c15-4907-a886-8803573c3b0d to disappear
Aug  9 14:38:32.392: INFO: Pod pod-projected-configmaps-2d9baadd-1c15-4907-a886-8803573c3b0d no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:38:32.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5811" for this suite.
Aug  9 14:38:38.467: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:38:38.863: INFO: namespace projected-5811 deletion completed in 6.459505908s

• [SLOW TEST:10.899 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:38:38.865: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-3640
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Aug  9 14:38:39.146: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:38:45.192: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-3640" for this suite.
Aug  9 14:39:03.294: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:39:03.637: INFO: namespace init-container-3640 deletion completed in 18.397569422s

• [SLOW TEST:24.772 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:39:03.638: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on tmpfs
Aug  9 14:39:03.948: INFO: Waiting up to 5m0s for pod "pod-d5d535a9-d019-4f54-915a-295cead5062c" in namespace "emptydir-5" to be "success or failure"
Aug  9 14:39:03.956: INFO: Pod "pod-d5d535a9-d019-4f54-915a-295cead5062c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.088927ms
Aug  9 14:39:05.971: INFO: Pod "pod-d5d535a9-d019-4f54-915a-295cead5062c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023409384s
Aug  9 14:39:08.003: INFO: Pod "pod-d5d535a9-d019-4f54-915a-295cead5062c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.055252975s
STEP: Saw pod success
Aug  9 14:39:08.003: INFO: Pod "pod-d5d535a9-d019-4f54-915a-295cead5062c" satisfied condition "success or failure"
Aug  9 14:39:08.015: INFO: Trying to get logs from node scw-flan15-default-fbc750a75c7f4c499b691cc5ccd pod pod-d5d535a9-d019-4f54-915a-295cead5062c container test-container: <nil>
STEP: delete the pod
Aug  9 14:39:08.087: INFO: Waiting for pod pod-d5d535a9-d019-4f54-915a-295cead5062c to disappear
Aug  9 14:39:08.098: INFO: Pod pod-d5d535a9-d019-4f54-915a-295cead5062c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:39:08.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5" for this suite.
Aug  9 14:39:14.183: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:39:14.654: INFO: namespace emptydir-5 deletion completed in 6.538453845s

• [SLOW TEST:11.016 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:39:14.655: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-472
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:39:14.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-472" for this suite.
Aug  9 14:39:39.068: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:39:39.461: INFO: namespace pods-472 deletion completed in 24.462700477s

• [SLOW TEST:24.807 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:39:39.461: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5436
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-c3ce9929-0ef7-4758-b550-fee646bae859
STEP: Creating a pod to test consume secrets
Aug  9 14:39:39.732: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-119efb00-3e8c-4c1d-b661-486281ccd530" in namespace "projected-5436" to be "success or failure"
Aug  9 14:39:39.752: INFO: Pod "pod-projected-secrets-119efb00-3e8c-4c1d-b661-486281ccd530": Phase="Pending", Reason="", readiness=false. Elapsed: 20.525309ms
Aug  9 14:39:41.771: INFO: Pod "pod-projected-secrets-119efb00-3e8c-4c1d-b661-486281ccd530": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039427899s
Aug  9 14:39:43.781: INFO: Pod "pod-projected-secrets-119efb00-3e8c-4c1d-b661-486281ccd530": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.049168921s
STEP: Saw pod success
Aug  9 14:39:43.781: INFO: Pod "pod-projected-secrets-119efb00-3e8c-4c1d-b661-486281ccd530" satisfied condition "success or failure"
Aug  9 14:39:43.792: INFO: Trying to get logs from node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d pod pod-projected-secrets-119efb00-3e8c-4c1d-b661-486281ccd530 container projected-secret-volume-test: <nil>
STEP: delete the pod
Aug  9 14:39:43.854: INFO: Waiting for pod pod-projected-secrets-119efb00-3e8c-4c1d-b661-486281ccd530 to disappear
Aug  9 14:39:43.874: INFO: Pod pod-projected-secrets-119efb00-3e8c-4c1d-b661-486281ccd530 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:39:43.874: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5436" for this suite.
Aug  9 14:39:49.933: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:39:50.274: INFO: namespace projected-5436 deletion completed in 6.386069225s

• [SLOW TEST:10.813 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:39:50.274: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-325
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Aug  9 14:39:55.323: INFO: Successfully updated pod "annotationupdate127cd9ae-42f5-40ec-9b51-f17ccea8f217"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:39:57.387: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-325" for this suite.
Aug  9 14:40:21.466: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:40:21.830: INFO: namespace downward-api-325 deletion completed in 24.430843722s

• [SLOW TEST:31.556 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:40:21.833: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-5738
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-qr2hs in namespace proxy-5738
I0809 14:40:22.132485      19 runners.go:180] Created replication controller with name: proxy-service-qr2hs, namespace: proxy-5738, replica count: 1
I0809 14:40:23.187277      19 runners.go:180] proxy-service-qr2hs Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0809 14:40:24.187657      19 runners.go:180] proxy-service-qr2hs Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0809 14:40:25.188095      19 runners.go:180] proxy-service-qr2hs Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0809 14:40:26.189846      19 runners.go:180] proxy-service-qr2hs Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0809 14:40:27.190260      19 runners.go:180] proxy-service-qr2hs Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0809 14:40:28.190996      19 runners.go:180] proxy-service-qr2hs Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0809 14:40:29.191598      19 runners.go:180] proxy-service-qr2hs Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0809 14:40:30.192052      19 runners.go:180] proxy-service-qr2hs Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0809 14:40:31.192521      19 runners.go:180] proxy-service-qr2hs Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Aug  9 14:40:31.206: INFO: setup took 9.152126639s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Aug  9 14:40:31.231: INFO: (0) /api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:160/proxy/: foo (200; 23.600133ms)
Aug  9 14:40:31.302: INFO: (0) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:1080/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:1080/proxy/rewriteme">test<... (200; 95.664257ms)
Aug  9 14:40:31.302: INFO: (0) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:162/proxy/: bar (200; 95.418443ms)
Aug  9 14:40:31.302: INFO: (0) /api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:162/proxy/: bar (200; 94.449086ms)
Aug  9 14:40:31.302: INFO: (0) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7/proxy/rewriteme">test</a> (200; 95.954514ms)
Aug  9 14:40:31.302: INFO: (0) /api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:1080/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:1080/proxy/rewriteme">... (200; 96.252175ms)
Aug  9 14:40:31.302: INFO: (0) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:160/proxy/: foo (200; 95.694583ms)
Aug  9 14:40:31.347: INFO: (0) /api/v1/namespaces/proxy-5738/services/proxy-service-qr2hs:portname2/proxy/: bar (200; 139.341954ms)
Aug  9 14:40:31.348: INFO: (0) /api/v1/namespaces/proxy-5738/services/http:proxy-service-qr2hs:portname2/proxy/: bar (200; 140.253542ms)
Aug  9 14:40:31.348: INFO: (0) /api/v1/namespaces/proxy-5738/services/proxy-service-qr2hs:portname1/proxy/: foo (200; 140.020081ms)
Aug  9 14:40:31.348: INFO: (0) /api/v1/namespaces/proxy-5738/services/http:proxy-service-qr2hs:portname1/proxy/: foo (200; 140.790615ms)
Aug  9 14:40:31.350: INFO: (0) /api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:460/proxy/: tls baz (200; 142.70846ms)
Aug  9 14:40:31.350: INFO: (0) /api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:443/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:443/proxy/tlsrewritem... (200; 143.274036ms)
Aug  9 14:40:31.352: INFO: (0) /api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:462/proxy/: tls qux (200; 144.01944ms)
Aug  9 14:40:31.396: INFO: (0) /api/v1/namespaces/proxy-5738/services/https:proxy-service-qr2hs:tlsportname1/proxy/: tls baz (200; 188.241955ms)
Aug  9 14:40:31.397: INFO: (0) /api/v1/namespaces/proxy-5738/services/https:proxy-service-qr2hs:tlsportname2/proxy/: tls qux (200; 188.758137ms)
Aug  9 14:40:31.413: INFO: (1) /api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:1080/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:1080/proxy/rewriteme">... (200; 15.258352ms)
Aug  9 14:40:31.413: INFO: (1) /api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:160/proxy/: foo (200; 15.663986ms)
Aug  9 14:40:31.414: INFO: (1) /api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:162/proxy/: bar (200; 16.11201ms)
Aug  9 14:40:31.414: INFO: (1) /api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:460/proxy/: tls baz (200; 16.420242ms)
Aug  9 14:40:31.414: INFO: (1) /api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:462/proxy/: tls qux (200; 16.66894ms)
Aug  9 14:40:31.414: INFO: (1) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7/proxy/rewriteme">test</a> (200; 16.900337ms)
Aug  9 14:40:31.415: INFO: (1) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:1080/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:1080/proxy/rewriteme">test<... (200; 17.383727ms)
Aug  9 14:40:31.416: INFO: (1) /api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:443/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:443/proxy/tlsrewritem... (200; 17.92051ms)
Aug  9 14:40:31.419: INFO: (1) /api/v1/namespaces/proxy-5738/services/http:proxy-service-qr2hs:portname2/proxy/: bar (200; 21.78883ms)
Aug  9 14:40:31.419: INFO: (1) /api/v1/namespaces/proxy-5738/services/proxy-service-qr2hs:portname1/proxy/: foo (200; 21.95901ms)
Aug  9 14:40:31.419: INFO: (1) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:160/proxy/: foo (200; 21.707738ms)
Aug  9 14:40:31.419: INFO: (1) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:162/proxy/: bar (200; 21.678041ms)
Aug  9 14:40:31.463: INFO: (1) /api/v1/namespaces/proxy-5738/services/http:proxy-service-qr2hs:portname1/proxy/: foo (200; 65.726818ms)
Aug  9 14:40:31.463: INFO: (1) /api/v1/namespaces/proxy-5738/services/https:proxy-service-qr2hs:tlsportname2/proxy/: tls qux (200; 65.768186ms)
Aug  9 14:40:31.463: INFO: (1) /api/v1/namespaces/proxy-5738/services/proxy-service-qr2hs:portname2/proxy/: bar (200; 65.714544ms)
Aug  9 14:40:31.463: INFO: (1) /api/v1/namespaces/proxy-5738/services/https:proxy-service-qr2hs:tlsportname1/proxy/: tls baz (200; 65.67411ms)
Aug  9 14:40:31.482: INFO: (2) /api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:160/proxy/: foo (200; 18.292169ms)
Aug  9 14:40:31.483: INFO: (2) /api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:162/proxy/: bar (200; 18.595141ms)
Aug  9 14:40:31.483: INFO: (2) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:162/proxy/: bar (200; 18.518756ms)
Aug  9 14:40:31.483: INFO: (2) /api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:443/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:443/proxy/tlsrewritem... (200; 18.79121ms)
Aug  9 14:40:31.483: INFO: (2) /api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:1080/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:1080/proxy/rewriteme">... (200; 18.55804ms)
Aug  9 14:40:31.483: INFO: (2) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:160/proxy/: foo (200; 18.706079ms)
Aug  9 14:40:31.483: INFO: (2) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:1080/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:1080/proxy/rewriteme">test<... (200; 18.898773ms)
Aug  9 14:40:31.483: INFO: (2) /api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:460/proxy/: tls baz (200; 19.23722ms)
Aug  9 14:40:31.483: INFO: (2) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7/proxy/rewriteme">test</a> (200; 18.666785ms)
Aug  9 14:40:31.484: INFO: (2) /api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:462/proxy/: tls qux (200; 19.546443ms)
Aug  9 14:40:31.487: INFO: (2) /api/v1/namespaces/proxy-5738/services/proxy-service-qr2hs:portname2/proxy/: bar (200; 22.677115ms)
Aug  9 14:40:31.489: INFO: (2) /api/v1/namespaces/proxy-5738/services/https:proxy-service-qr2hs:tlsportname1/proxy/: tls baz (200; 25.628467ms)
Aug  9 14:40:31.489: INFO: (2) /api/v1/namespaces/proxy-5738/services/proxy-service-qr2hs:portname1/proxy/: foo (200; 25.883827ms)
Aug  9 14:40:31.489: INFO: (2) /api/v1/namespaces/proxy-5738/services/http:proxy-service-qr2hs:portname1/proxy/: foo (200; 25.519702ms)
Aug  9 14:40:31.489: INFO: (2) /api/v1/namespaces/proxy-5738/services/https:proxy-service-qr2hs:tlsportname2/proxy/: tls qux (200; 25.350664ms)
Aug  9 14:40:31.531: INFO: (2) /api/v1/namespaces/proxy-5738/services/http:proxy-service-qr2hs:portname2/proxy/: bar (200; 67.35656ms)
Aug  9 14:40:31.548: INFO: (3) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:162/proxy/: bar (200; 15.548447ms)
Aug  9 14:40:31.548: INFO: (3) /api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:1080/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:1080/proxy/rewriteme">... (200; 16.216596ms)
Aug  9 14:40:31.548: INFO: (3) /api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:462/proxy/: tls qux (200; 14.432704ms)
Aug  9 14:40:31.548: INFO: (3) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:1080/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:1080/proxy/rewriteme">test<... (200; 15.904429ms)
Aug  9 14:40:31.548: INFO: (3) /api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:162/proxy/: bar (200; 14.704216ms)
Aug  9 14:40:31.548: INFO: (3) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:160/proxy/: foo (200; 16.12875ms)
Aug  9 14:40:31.548: INFO: (3) /api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:160/proxy/: foo (200; 15.532898ms)
Aug  9 14:40:31.548: INFO: (3) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7/proxy/rewriteme">test</a> (200; 16.437413ms)
Aug  9 14:40:31.548: INFO: (3) /api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:460/proxy/: tls baz (200; 15.459018ms)
Aug  9 14:40:31.548: INFO: (3) /api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:443/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:443/proxy/tlsrewritem... (200; 16.065141ms)
Aug  9 14:40:31.565: INFO: (3) /api/v1/namespaces/proxy-5738/services/http:proxy-service-qr2hs:portname1/proxy/: foo (200; 32.565993ms)
Aug  9 14:40:31.623: INFO: (3) /api/v1/namespaces/proxy-5738/services/https:proxy-service-qr2hs:tlsportname1/proxy/: tls baz (200; 90.112411ms)
Aug  9 14:40:31.623: INFO: (3) /api/v1/namespaces/proxy-5738/services/http:proxy-service-qr2hs:portname2/proxy/: bar (200; 90.709157ms)
Aug  9 14:40:31.623: INFO: (3) /api/v1/namespaces/proxy-5738/services/https:proxy-service-qr2hs:tlsportname2/proxy/: tls qux (200; 89.675517ms)
Aug  9 14:40:31.623: INFO: (3) /api/v1/namespaces/proxy-5738/services/proxy-service-qr2hs:portname1/proxy/: foo (200; 90.37695ms)
Aug  9 14:40:31.623: INFO: (3) /api/v1/namespaces/proxy-5738/services/proxy-service-qr2hs:portname2/proxy/: bar (200; 89.830149ms)
Aug  9 14:40:31.638: INFO: (4) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:160/proxy/: foo (200; 13.280183ms)
Aug  9 14:40:31.638: INFO: (4) /api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:443/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:443/proxy/tlsrewritem... (200; 13.652654ms)
Aug  9 14:40:31.638: INFO: (4) /api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:1080/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:1080/proxy/rewriteme">... (200; 14.263958ms)
Aug  9 14:40:31.639: INFO: (4) /api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:160/proxy/: foo (200; 14.050985ms)
Aug  9 14:40:31.639: INFO: (4) /api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:162/proxy/: bar (200; 13.765757ms)
Aug  9 14:40:31.639: INFO: (4) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:162/proxy/: bar (200; 14.789979ms)
Aug  9 14:40:31.639: INFO: (4) /api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:460/proxy/: tls baz (200; 14.298262ms)
Aug  9 14:40:31.640: INFO: (4) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:1080/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:1080/proxy/rewriteme">test<... (200; 15.189812ms)
Aug  9 14:40:31.640: INFO: (4) /api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:462/proxy/: tls qux (200; 16.184086ms)
Aug  9 14:40:31.640: INFO: (4) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7/proxy/rewriteme">test</a> (200; 15.673364ms)
Aug  9 14:40:31.647: INFO: (4) /api/v1/namespaces/proxy-5738/services/proxy-service-qr2hs:portname2/proxy/: bar (200; 23.229645ms)
Aug  9 14:40:31.647: INFO: (4) /api/v1/namespaces/proxy-5738/services/https:proxy-service-qr2hs:tlsportname2/proxy/: tls qux (200; 23.067761ms)
Aug  9 14:40:31.694: INFO: (4) /api/v1/namespaces/proxy-5738/services/http:proxy-service-qr2hs:portname1/proxy/: foo (200; 68.894417ms)
Aug  9 14:40:31.694: INFO: (4) /api/v1/namespaces/proxy-5738/services/proxy-service-qr2hs:portname1/proxy/: foo (200; 68.493103ms)
Aug  9 14:40:31.694: INFO: (4) /api/v1/namespaces/proxy-5738/services/http:proxy-service-qr2hs:portname2/proxy/: bar (200; 68.865455ms)
Aug  9 14:40:31.694: INFO: (4) /api/v1/namespaces/proxy-5738/services/https:proxy-service-qr2hs:tlsportname1/proxy/: tls baz (200; 68.448899ms)
Aug  9 14:40:31.710: INFO: (5) /api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:460/proxy/: tls baz (200; 15.705783ms)
Aug  9 14:40:31.711: INFO: (5) /api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:160/proxy/: foo (200; 16.249198ms)
Aug  9 14:40:31.711: INFO: (5) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7/proxy/rewriteme">test</a> (200; 15.983989ms)
Aug  9 14:40:31.711: INFO: (5) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:1080/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:1080/proxy/rewriteme">test<... (200; 16.761003ms)
Aug  9 14:40:31.711: INFO: (5) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:160/proxy/: foo (200; 16.216907ms)
Aug  9 14:40:31.711: INFO: (5) /api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:1080/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:1080/proxy/rewriteme">... (200; 16.363483ms)
Aug  9 14:40:31.711: INFO: (5) /api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:443/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:443/proxy/tlsrewritem... (200; 16.168336ms)
Aug  9 14:40:31.711: INFO: (5) /api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:462/proxy/: tls qux (200; 15.96934ms)
Aug  9 14:40:31.711: INFO: (5) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:162/proxy/: bar (200; 16.877942ms)
Aug  9 14:40:31.712: INFO: (5) /api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:162/proxy/: bar (200; 16.927627ms)
Aug  9 14:40:31.719: INFO: (5) /api/v1/namespaces/proxy-5738/services/http:proxy-service-qr2hs:portname2/proxy/: bar (200; 23.883397ms)
Aug  9 14:40:31.764: INFO: (5) /api/v1/namespaces/proxy-5738/services/https:proxy-service-qr2hs:tlsportname1/proxy/: tls baz (200; 69.92983ms)
Aug  9 14:40:31.764: INFO: (5) /api/v1/namespaces/proxy-5738/services/proxy-service-qr2hs:portname1/proxy/: foo (200; 68.938312ms)
Aug  9 14:40:31.764: INFO: (5) /api/v1/namespaces/proxy-5738/services/http:proxy-service-qr2hs:portname1/proxy/: foo (200; 69.02165ms)
Aug  9 14:40:31.764: INFO: (5) /api/v1/namespaces/proxy-5738/services/https:proxy-service-qr2hs:tlsportname2/proxy/: tls qux (200; 69.46226ms)
Aug  9 14:40:31.764: INFO: (5) /api/v1/namespaces/proxy-5738/services/proxy-service-qr2hs:portname2/proxy/: bar (200; 69.682445ms)
Aug  9 14:40:31.783: INFO: (6) /api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:1080/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:1080/proxy/rewriteme">... (200; 17.348369ms)
Aug  9 14:40:31.790: INFO: (6) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:162/proxy/: bar (200; 25.533397ms)
Aug  9 14:40:31.790: INFO: (6) /api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:443/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:443/proxy/tlsrewritem... (200; 25.559826ms)
Aug  9 14:40:31.790: INFO: (6) /api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:162/proxy/: bar (200; 25.12656ms)
Aug  9 14:40:31.790: INFO: (6) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:160/proxy/: foo (200; 25.208414ms)
Aug  9 14:40:31.790: INFO: (6) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:1080/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:1080/proxy/rewriteme">test<... (200; 25.338489ms)
Aug  9 14:40:31.790: INFO: (6) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7/proxy/rewriteme">test</a> (200; 25.523027ms)
Aug  9 14:40:31.791: INFO: (6) /api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:462/proxy/: tls qux (200; 25.042702ms)
Aug  9 14:40:31.791: INFO: (6) /api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:460/proxy/: tls baz (200; 26.111606ms)
Aug  9 14:40:31.792: INFO: (6) /api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:160/proxy/: foo (200; 27.149994ms)
Aug  9 14:40:31.839: INFO: (6) /api/v1/namespaces/proxy-5738/services/proxy-service-qr2hs:portname2/proxy/: bar (200; 73.912567ms)
Aug  9 14:40:31.839: INFO: (6) /api/v1/namespaces/proxy-5738/services/http:proxy-service-qr2hs:portname2/proxy/: bar (200; 74.584303ms)
Aug  9 14:40:31.839: INFO: (6) /api/v1/namespaces/proxy-5738/services/https:proxy-service-qr2hs:tlsportname1/proxy/: tls baz (200; 74.414273ms)
Aug  9 14:40:31.840: INFO: (6) /api/v1/namespaces/proxy-5738/services/proxy-service-qr2hs:portname1/proxy/: foo (200; 74.60821ms)
Aug  9 14:40:31.840: INFO: (6) /api/v1/namespaces/proxy-5738/services/http:proxy-service-qr2hs:portname1/proxy/: foo (200; 74.965101ms)
Aug  9 14:40:31.840: INFO: (6) /api/v1/namespaces/proxy-5738/services/https:proxy-service-qr2hs:tlsportname2/proxy/: tls qux (200; 74.04614ms)
Aug  9 14:40:31.862: INFO: (7) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:162/proxy/: bar (200; 20.499398ms)
Aug  9 14:40:31.862: INFO: (7) /api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:162/proxy/: bar (200; 21.316629ms)
Aug  9 14:40:31.864: INFO: (7) /api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:443/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:443/proxy/tlsrewritem... (200; 24.006759ms)
Aug  9 14:40:31.864: INFO: (7) /api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:1080/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:1080/proxy/rewriteme">... (200; 22.905574ms)
Aug  9 14:40:31.864: INFO: (7) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7/proxy/rewriteme">test</a> (200; 22.847755ms)
Aug  9 14:40:31.864: INFO: (7) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:1080/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:1080/proxy/rewriteme">test<... (200; 22.783684ms)
Aug  9 14:40:31.864: INFO: (7) /api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:462/proxy/: tls qux (200; 23.281722ms)
Aug  9 14:40:31.864: INFO: (7) /api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:160/proxy/: foo (200; 23.797195ms)
Aug  9 14:40:31.864: INFO: (7) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:160/proxy/: foo (200; 22.786329ms)
Aug  9 14:40:31.864: INFO: (7) /api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:460/proxy/: tls baz (200; 23.743904ms)
Aug  9 14:40:31.864: INFO: (7) /api/v1/namespaces/proxy-5738/services/https:proxy-service-qr2hs:tlsportname1/proxy/: tls baz (200; 23.632854ms)
Aug  9 14:40:31.865: INFO: (7) /api/v1/namespaces/proxy-5738/services/http:proxy-service-qr2hs:portname1/proxy/: foo (200; 25.091163ms)
Aug  9 14:40:31.908: INFO: (7) /api/v1/namespaces/proxy-5738/services/http:proxy-service-qr2hs:portname2/proxy/: bar (200; 67.600317ms)
Aug  9 14:40:31.908: INFO: (7) /api/v1/namespaces/proxy-5738/services/proxy-service-qr2hs:portname1/proxy/: foo (200; 67.410518ms)
Aug  9 14:40:31.908: INFO: (7) /api/v1/namespaces/proxy-5738/services/https:proxy-service-qr2hs:tlsportname2/proxy/: tls qux (200; 66.98668ms)
Aug  9 14:40:31.908: INFO: (7) /api/v1/namespaces/proxy-5738/services/proxy-service-qr2hs:portname2/proxy/: bar (200; 67.16199ms)
Aug  9 14:40:31.925: INFO: (8) /api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:462/proxy/: tls qux (200; 16.474444ms)
Aug  9 14:40:31.925: INFO: (8) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:162/proxy/: bar (200; 16.701141ms)
Aug  9 14:40:31.925: INFO: (8) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7/proxy/rewriteme">test</a> (200; 16.916307ms)
Aug  9 14:40:31.925: INFO: (8) /api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:460/proxy/: tls baz (200; 17.276114ms)
Aug  9 14:40:31.925: INFO: (8) /api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:1080/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:1080/proxy/rewriteme">... (200; 16.463934ms)
Aug  9 14:40:31.925: INFO: (8) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:160/proxy/: foo (200; 16.863748ms)
Aug  9 14:40:31.925: INFO: (8) /api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:443/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:443/proxy/tlsrewritem... (200; 16.77452ms)
Aug  9 14:40:31.925: INFO: (8) /api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:162/proxy/: bar (200; 16.745333ms)
Aug  9 14:40:31.925: INFO: (8) /api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:160/proxy/: foo (200; 16.675593ms)
Aug  9 14:40:31.925: INFO: (8) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:1080/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:1080/proxy/rewriteme">test<... (200; 17.02942ms)
Aug  9 14:40:31.926: INFO: (8) /api/v1/namespaces/proxy-5738/services/http:proxy-service-qr2hs:portname1/proxy/: foo (200; 17.600486ms)
Aug  9 14:40:31.926: INFO: (8) /api/v1/namespaces/proxy-5738/services/proxy-service-qr2hs:portname1/proxy/: foo (200; 17.769534ms)
Aug  9 14:40:32.012: INFO: (8) /api/v1/namespaces/proxy-5738/services/https:proxy-service-qr2hs:tlsportname2/proxy/: tls qux (200; 102.880949ms)
Aug  9 14:40:32.012: INFO: (8) /api/v1/namespaces/proxy-5738/services/http:proxy-service-qr2hs:portname2/proxy/: bar (200; 103.205331ms)
Aug  9 14:40:32.012: INFO: (8) /api/v1/namespaces/proxy-5738/services/https:proxy-service-qr2hs:tlsportname1/proxy/: tls baz (200; 103.428291ms)
Aug  9 14:40:32.012: INFO: (8) /api/v1/namespaces/proxy-5738/services/proxy-service-qr2hs:portname2/proxy/: bar (200; 102.954398ms)
Aug  9 14:40:32.028: INFO: (9) /api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:162/proxy/: bar (200; 15.441256ms)
Aug  9 14:40:32.029: INFO: (9) /api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:160/proxy/: foo (200; 15.515395ms)
Aug  9 14:40:32.029: INFO: (9) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:160/proxy/: foo (200; 16.165751ms)
Aug  9 14:40:32.029: INFO: (9) /api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:460/proxy/: tls baz (200; 16.767235ms)
Aug  9 14:40:32.030: INFO: (9) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7/proxy/rewriteme">test</a> (200; 17.392874ms)
Aug  9 14:40:32.030: INFO: (9) /api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:1080/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:1080/proxy/rewriteme">... (200; 16.700871ms)
Aug  9 14:40:32.031: INFO: (9) /api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:443/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:443/proxy/tlsrewritem... (200; 16.984856ms)
Aug  9 14:40:32.031: INFO: (9) /api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:462/proxy/: tls qux (200; 17.958462ms)
Aug  9 14:40:32.031: INFO: (9) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:1080/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:1080/proxy/rewriteme">test<... (200; 17.881666ms)
Aug  9 14:40:32.031: INFO: (9) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:162/proxy/: bar (200; 17.911732ms)
Aug  9 14:40:32.035: INFO: (9) /api/v1/namespaces/proxy-5738/services/http:proxy-service-qr2hs:portname1/proxy/: foo (200; 21.449241ms)
Aug  9 14:40:32.035: INFO: (9) /api/v1/namespaces/proxy-5738/services/https:proxy-service-qr2hs:tlsportname2/proxy/: tls qux (200; 21.802677ms)
Aug  9 14:40:32.035: INFO: (9) /api/v1/namespaces/proxy-5738/services/http:proxy-service-qr2hs:portname2/proxy/: bar (200; 21.727214ms)
Aug  9 14:40:32.036: INFO: (9) /api/v1/namespaces/proxy-5738/services/proxy-service-qr2hs:portname2/proxy/: bar (200; 22.412706ms)
Aug  9 14:40:32.036: INFO: (9) /api/v1/namespaces/proxy-5738/services/https:proxy-service-qr2hs:tlsportname1/proxy/: tls baz (200; 23.284409ms)
Aug  9 14:40:32.036: INFO: (9) /api/v1/namespaces/proxy-5738/services/proxy-service-qr2hs:portname1/proxy/: foo (200; 23.478044ms)
Aug  9 14:40:32.057: INFO: (10) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:1080/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:1080/proxy/rewriteme">test<... (200; 18.14406ms)
Aug  9 14:40:32.057: INFO: (10) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7/proxy/rewriteme">test</a> (200; 18.482568ms)
Aug  9 14:40:32.057: INFO: (10) /api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:460/proxy/: tls baz (200; 17.838763ms)
Aug  9 14:40:32.057: INFO: (10) /api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:462/proxy/: tls qux (200; 17.052512ms)
Aug  9 14:40:32.057: INFO: (10) /api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:162/proxy/: bar (200; 17.365942ms)
Aug  9 14:40:32.057: INFO: (10) /api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:1080/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:1080/proxy/rewriteme">... (200; 20.059299ms)
Aug  9 14:40:32.057: INFO: (10) /api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:443/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:443/proxy/tlsrewritem... (200; 18.99947ms)
Aug  9 14:40:32.057: INFO: (10) /api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:160/proxy/: foo (200; 18.451939ms)
Aug  9 14:40:32.058: INFO: (10) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:160/proxy/: foo (200; 19.935215ms)
Aug  9 14:40:32.058: INFO: (10) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:162/proxy/: bar (200; 19.739877ms)
Aug  9 14:40:32.105: INFO: (10) /api/v1/namespaces/proxy-5738/services/proxy-service-qr2hs:portname1/proxy/: foo (200; 65.205716ms)
Aug  9 14:40:32.105: INFO: (10) /api/v1/namespaces/proxy-5738/services/https:proxy-service-qr2hs:tlsportname2/proxy/: tls qux (200; 67.952193ms)
Aug  9 14:40:32.105: INFO: (10) /api/v1/namespaces/proxy-5738/services/http:proxy-service-qr2hs:portname1/proxy/: foo (200; 66.165334ms)
Aug  9 14:40:32.105: INFO: (10) /api/v1/namespaces/proxy-5738/services/proxy-service-qr2hs:portname2/proxy/: bar (200; 68.196612ms)
Aug  9 14:40:32.105: INFO: (10) /api/v1/namespaces/proxy-5738/services/https:proxy-service-qr2hs:tlsportname1/proxy/: tls baz (200; 68.794911ms)
Aug  9 14:40:32.106: INFO: (10) /api/v1/namespaces/proxy-5738/services/http:proxy-service-qr2hs:portname2/proxy/: bar (200; 66.018277ms)
Aug  9 14:40:32.121: INFO: (11) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:1080/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:1080/proxy/rewriteme">test<... (200; 13.836319ms)
Aug  9 14:40:32.122: INFO: (11) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:162/proxy/: bar (200; 14.222538ms)
Aug  9 14:40:32.122: INFO: (11) /api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:160/proxy/: foo (200; 15.601787ms)
Aug  9 14:40:32.122: INFO: (11) /api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:443/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:443/proxy/tlsrewritem... (200; 16.05445ms)
Aug  9 14:40:32.122: INFO: (11) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7/proxy/rewriteme">test</a> (200; 14.646407ms)
Aug  9 14:40:32.122: INFO: (11) /api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:460/proxy/: tls baz (200; 15.571109ms)
Aug  9 14:40:32.122: INFO: (11) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:160/proxy/: foo (200; 14.476597ms)
Aug  9 14:40:32.122: INFO: (11) /api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:1080/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:1080/proxy/rewriteme">... (200; 14.853797ms)
Aug  9 14:40:32.122: INFO: (11) /api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:162/proxy/: bar (200; 15.876214ms)
Aug  9 14:40:32.122: INFO: (11) /api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:462/proxy/: tls qux (200; 15.934554ms)
Aug  9 14:40:32.130: INFO: (11) /api/v1/namespaces/proxy-5738/services/http:proxy-service-qr2hs:portname2/proxy/: bar (200; 24.019073ms)
Aug  9 14:40:32.172: INFO: (11) /api/v1/namespaces/proxy-5738/services/http:proxy-service-qr2hs:portname1/proxy/: foo (200; 66.115237ms)
Aug  9 14:40:32.172: INFO: (11) /api/v1/namespaces/proxy-5738/services/https:proxy-service-qr2hs:tlsportname2/proxy/: tls qux (200; 65.588986ms)
Aug  9 14:40:32.172: INFO: (11) /api/v1/namespaces/proxy-5738/services/proxy-service-qr2hs:portname2/proxy/: bar (200; 65.78194ms)
Aug  9 14:40:32.172: INFO: (11) /api/v1/namespaces/proxy-5738/services/proxy-service-qr2hs:portname1/proxy/: foo (200; 66.293624ms)
Aug  9 14:40:32.173: INFO: (11) /api/v1/namespaces/proxy-5738/services/https:proxy-service-qr2hs:tlsportname1/proxy/: tls baz (200; 66.279347ms)
Aug  9 14:40:32.190: INFO: (12) /api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:443/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:443/proxy/tlsrewritem... (200; 16.893103ms)
Aug  9 14:40:32.191: INFO: (12) /api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:160/proxy/: foo (200; 17.022808ms)
Aug  9 14:40:32.191: INFO: (12) /api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:460/proxy/: tls baz (200; 17.935277ms)
Aug  9 14:40:32.191: INFO: (12) /api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:162/proxy/: bar (200; 17.74631ms)
Aug  9 14:40:32.191: INFO: (12) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:162/proxy/: bar (200; 18.124945ms)
Aug  9 14:40:32.191: INFO: (12) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:1080/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:1080/proxy/rewriteme">test<... (200; 17.717266ms)
Aug  9 14:40:32.191: INFO: (12) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:160/proxy/: foo (200; 17.764777ms)
Aug  9 14:40:32.192: INFO: (12) /api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:1080/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:1080/proxy/rewriteme">... (200; 17.914809ms)
Aug  9 14:40:32.192: INFO: (12) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7/proxy/rewriteme">test</a> (200; 18.750242ms)
Aug  9 14:40:32.193: INFO: (12) /api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:462/proxy/: tls qux (200; 19.103068ms)
Aug  9 14:40:32.199: INFO: (12) /api/v1/namespaces/proxy-5738/services/proxy-service-qr2hs:portname2/proxy/: bar (200; 25.720381ms)
Aug  9 14:40:32.244: INFO: (12) /api/v1/namespaces/proxy-5738/services/http:proxy-service-qr2hs:portname2/proxy/: bar (200; 70.419924ms)
Aug  9 14:40:32.244: INFO: (12) /api/v1/namespaces/proxy-5738/services/http:proxy-service-qr2hs:portname1/proxy/: foo (200; 70.02987ms)
Aug  9 14:40:32.244: INFO: (12) /api/v1/namespaces/proxy-5738/services/https:proxy-service-qr2hs:tlsportname1/proxy/: tls baz (200; 70.241238ms)
Aug  9 14:40:32.244: INFO: (12) /api/v1/namespaces/proxy-5738/services/proxy-service-qr2hs:portname1/proxy/: foo (200; 70.613539ms)
Aug  9 14:40:32.244: INFO: (12) /api/v1/namespaces/proxy-5738/services/https:proxy-service-qr2hs:tlsportname2/proxy/: tls qux (200; 70.374138ms)
Aug  9 14:40:32.266: INFO: (13) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:162/proxy/: bar (200; 21.615723ms)
Aug  9 14:40:32.266: INFO: (13) /api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:460/proxy/: tls baz (200; 21.06223ms)
Aug  9 14:40:32.266: INFO: (13) /api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:162/proxy/: bar (200; 21.081566ms)
Aug  9 14:40:32.266: INFO: (13) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7/proxy/rewriteme">test</a> (200; 21.284519ms)
Aug  9 14:40:32.266: INFO: (13) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:1080/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:1080/proxy/rewriteme">test<... (200; 21.546322ms)
Aug  9 14:40:32.266: INFO: (13) /api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:160/proxy/: foo (200; 21.06797ms)
Aug  9 14:40:32.266: INFO: (13) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:160/proxy/: foo (200; 21.448547ms)
Aug  9 14:40:32.266: INFO: (13) /api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:1080/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:1080/proxy/rewriteme">... (200; 21.522728ms)
Aug  9 14:40:32.267: INFO: (13) /api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:443/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:443/proxy/tlsrewritem... (200; 22.250941ms)
Aug  9 14:40:32.267: INFO: (13) /api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:462/proxy/: tls qux (200; 22.418166ms)
Aug  9 14:40:32.272: INFO: (13) /api/v1/namespaces/proxy-5738/services/proxy-service-qr2hs:portname2/proxy/: bar (200; 27.715951ms)
Aug  9 14:40:32.308: INFO: (13) /api/v1/namespaces/proxy-5738/services/https:proxy-service-qr2hs:tlsportname1/proxy/: tls baz (200; 62.954805ms)
Aug  9 14:40:32.308: INFO: (13) /api/v1/namespaces/proxy-5738/services/proxy-service-qr2hs:portname1/proxy/: foo (200; 62.996854ms)
Aug  9 14:40:32.308: INFO: (13) /api/v1/namespaces/proxy-5738/services/https:proxy-service-qr2hs:tlsportname2/proxy/: tls qux (200; 63.494613ms)
Aug  9 14:40:32.308: INFO: (13) /api/v1/namespaces/proxy-5738/services/http:proxy-service-qr2hs:portname1/proxy/: foo (200; 63.349097ms)
Aug  9 14:40:32.308: INFO: (13) /api/v1/namespaces/proxy-5738/services/http:proxy-service-qr2hs:portname2/proxy/: bar (200; 63.098084ms)
Aug  9 14:40:32.325: INFO: (14) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7/proxy/rewriteme">test</a> (200; 16.189735ms)
Aug  9 14:40:32.326: INFO: (14) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:162/proxy/: bar (200; 16.142226ms)
Aug  9 14:40:32.326: INFO: (14) /api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:162/proxy/: bar (200; 16.02808ms)
Aug  9 14:40:32.326: INFO: (14) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:1080/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:1080/proxy/rewriteme">test<... (200; 16.354195ms)
Aug  9 14:40:32.326: INFO: (14) /api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:443/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:443/proxy/tlsrewritem... (200; 16.83969ms)
Aug  9 14:40:32.326: INFO: (14) /api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:460/proxy/: tls baz (200; 16.695268ms)
Aug  9 14:40:32.326: INFO: (14) /api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:1080/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:1080/proxy/rewriteme">... (200; 16.564493ms)
Aug  9 14:40:32.326: INFO: (14) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:160/proxy/: foo (200; 16.438033ms)
Aug  9 14:40:32.326: INFO: (14) /api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:462/proxy/: tls qux (200; 17.16335ms)
Aug  9 14:40:32.326: INFO: (14) /api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:160/proxy/: foo (200; 16.585071ms)
Aug  9 14:40:32.333: INFO: (14) /api/v1/namespaces/proxy-5738/services/http:proxy-service-qr2hs:portname2/proxy/: bar (200; 24.159837ms)
Aug  9 14:40:32.379: INFO: (14) /api/v1/namespaces/proxy-5738/services/https:proxy-service-qr2hs:tlsportname1/proxy/: tls baz (200; 69.864955ms)
Aug  9 14:40:32.379: INFO: (14) /api/v1/namespaces/proxy-5738/services/proxy-service-qr2hs:portname1/proxy/: foo (200; 69.869455ms)
Aug  9 14:40:32.379: INFO: (14) /api/v1/namespaces/proxy-5738/services/proxy-service-qr2hs:portname2/proxy/: bar (200; 70.444488ms)
Aug  9 14:40:32.379: INFO: (14) /api/v1/namespaces/proxy-5738/services/https:proxy-service-qr2hs:tlsportname2/proxy/: tls qux (200; 70.252987ms)
Aug  9 14:40:32.380: INFO: (14) /api/v1/namespaces/proxy-5738/services/http:proxy-service-qr2hs:portname1/proxy/: foo (200; 70.46173ms)
Aug  9 14:40:32.391: INFO: (15) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:160/proxy/: foo (200; 10.619306ms)
Aug  9 14:40:32.393: INFO: (15) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:162/proxy/: bar (200; 12.97731ms)
Aug  9 14:40:32.394: INFO: (15) /api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:162/proxy/: bar (200; 14.241644ms)
Aug  9 14:40:32.409: INFO: (15) /api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:443/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:443/proxy/tlsrewritem... (200; 28.406585ms)
Aug  9 14:40:32.409: INFO: (15) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:1080/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:1080/proxy/rewriteme">test<... (200; 28.468642ms)
Aug  9 14:40:32.409: INFO: (15) /api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:460/proxy/: tls baz (200; 28.826788ms)
Aug  9 14:40:32.409: INFO: (15) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7/proxy/rewriteme">test</a> (200; 28.593066ms)
Aug  9 14:40:32.409: INFO: (15) /api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:1080/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:1080/proxy/rewriteme">... (200; 29.390378ms)
Aug  9 14:40:32.409: INFO: (15) /api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:160/proxy/: foo (200; 29.28467ms)
Aug  9 14:40:32.409: INFO: (15) /api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:462/proxy/: tls qux (200; 29.112135ms)
Aug  9 14:40:32.409: INFO: (15) /api/v1/namespaces/proxy-5738/services/http:proxy-service-qr2hs:portname1/proxy/: foo (200; 28.948556ms)
Aug  9 14:40:32.410: INFO: (15) /api/v1/namespaces/proxy-5738/services/https:proxy-service-qr2hs:tlsportname2/proxy/: tls qux (200; 29.432128ms)
Aug  9 14:40:32.410: INFO: (15) /api/v1/namespaces/proxy-5738/services/http:proxy-service-qr2hs:portname2/proxy/: bar (200; 29.33273ms)
Aug  9 14:40:32.410: INFO: (15) /api/v1/namespaces/proxy-5738/services/https:proxy-service-qr2hs:tlsportname1/proxy/: tls baz (200; 29.771338ms)
Aug  9 14:40:32.410: INFO: (15) /api/v1/namespaces/proxy-5738/services/proxy-service-qr2hs:portname2/proxy/: bar (200; 29.747562ms)
Aug  9 14:40:32.410: INFO: (15) /api/v1/namespaces/proxy-5738/services/proxy-service-qr2hs:portname1/proxy/: foo (200; 30.067736ms)
Aug  9 14:40:32.431: INFO: (16) /api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:1080/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:1080/proxy/rewriteme">... (200; 20.189244ms)
Aug  9 14:40:32.431: INFO: (16) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7/proxy/rewriteme">test</a> (200; 20.286236ms)
Aug  9 14:40:32.431: INFO: (16) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:1080/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:1080/proxy/rewriteme">test<... (200; 20.196687ms)
Aug  9 14:40:32.431: INFO: (16) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:160/proxy/: foo (200; 20.929027ms)
Aug  9 14:40:32.431: INFO: (16) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:162/proxy/: bar (200; 20.888031ms)
Aug  9 14:40:32.431: INFO: (16) /api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:443/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:443/proxy/tlsrewritem... (200; 20.894563ms)
Aug  9 14:40:32.431: INFO: (16) /api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:460/proxy/: tls baz (200; 21.161787ms)
Aug  9 14:40:32.431: INFO: (16) /api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:462/proxy/: tls qux (200; 21.184199ms)
Aug  9 14:40:32.431: INFO: (16) /api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:160/proxy/: foo (200; 20.437612ms)
Aug  9 14:40:32.432: INFO: (16) /api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:162/proxy/: bar (200; 20.462659ms)
Aug  9 14:40:32.432: INFO: (16) /api/v1/namespaces/proxy-5738/services/https:proxy-service-qr2hs:tlsportname2/proxy/: tls qux (200; 21.528197ms)
Aug  9 14:40:32.433: INFO: (16) /api/v1/namespaces/proxy-5738/services/http:proxy-service-qr2hs:portname2/proxy/: bar (200; 22.25129ms)
Aug  9 14:40:32.433: INFO: (16) /api/v1/namespaces/proxy-5738/services/proxy-service-qr2hs:portname1/proxy/: foo (200; 22.339056ms)
Aug  9 14:40:32.433: INFO: (16) /api/v1/namespaces/proxy-5738/services/http:proxy-service-qr2hs:portname1/proxy/: foo (200; 22.300544ms)
Aug  9 14:40:32.519: INFO: (16) /api/v1/namespaces/proxy-5738/services/https:proxy-service-qr2hs:tlsportname1/proxy/: tls baz (200; 109.091775ms)
Aug  9 14:40:32.520: INFO: (16) /api/v1/namespaces/proxy-5738/services/proxy-service-qr2hs:portname2/proxy/: bar (200; 108.942695ms)
Aug  9 14:40:32.538: INFO: (17) /api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:162/proxy/: bar (200; 17.745227ms)
Aug  9 14:40:32.542: INFO: (17) /api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:443/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:443/proxy/tlsrewritem... (200; 22.684366ms)
Aug  9 14:40:32.543: INFO: (17) /api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:160/proxy/: foo (200; 22.301585ms)
Aug  9 14:40:32.543: INFO: (17) /api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:460/proxy/: tls baz (200; 22.651404ms)
Aug  9 14:40:32.543: INFO: (17) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:162/proxy/: bar (200; 22.41018ms)
Aug  9 14:40:32.543: INFO: (17) /api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:462/proxy/: tls qux (200; 22.931032ms)
Aug  9 14:40:32.543: INFO: (17) /api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:1080/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:1080/proxy/rewriteme">... (200; 22.674868ms)
Aug  9 14:40:32.543: INFO: (17) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:160/proxy/: foo (200; 22.682644ms)
Aug  9 14:40:32.543: INFO: (17) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7/proxy/rewriteme">test</a> (200; 22.731775ms)
Aug  9 14:40:32.543: INFO: (17) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:1080/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:1080/proxy/rewriteme">test<... (200; 22.86656ms)
Aug  9 14:40:32.549: INFO: (17) /api/v1/namespaces/proxy-5738/services/http:proxy-service-qr2hs:portname2/proxy/: bar (200; 29.309985ms)
Aug  9 14:40:32.597: INFO: (17) /api/v1/namespaces/proxy-5738/services/proxy-service-qr2hs:portname1/proxy/: foo (200; 76.892685ms)
Aug  9 14:40:32.597: INFO: (17) /api/v1/namespaces/proxy-5738/services/proxy-service-qr2hs:portname2/proxy/: bar (200; 76.822633ms)
Aug  9 14:40:32.597: INFO: (17) /api/v1/namespaces/proxy-5738/services/https:proxy-service-qr2hs:tlsportname1/proxy/: tls baz (200; 76.921839ms)
Aug  9 14:40:32.597: INFO: (17) /api/v1/namespaces/proxy-5738/services/https:proxy-service-qr2hs:tlsportname2/proxy/: tls qux (200; 76.876604ms)
Aug  9 14:40:32.597: INFO: (17) /api/v1/namespaces/proxy-5738/services/http:proxy-service-qr2hs:portname1/proxy/: foo (200; 76.923893ms)
Aug  9 14:40:32.614: INFO: (18) /api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:162/proxy/: bar (200; 17.07278ms)
Aug  9 14:40:32.617: INFO: (18) /api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:443/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:443/proxy/tlsrewritem... (200; 19.409575ms)
Aug  9 14:40:32.617: INFO: (18) /api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:460/proxy/: tls baz (200; 19.671137ms)
Aug  9 14:40:32.617: INFO: (18) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:1080/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:1080/proxy/rewriteme">test<... (200; 19.521015ms)
Aug  9 14:40:32.617: INFO: (18) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:160/proxy/: foo (200; 19.524229ms)
Aug  9 14:40:32.618: INFO: (18) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7/proxy/rewriteme">test</a> (200; 20.895865ms)
Aug  9 14:40:32.621: INFO: (18) /api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:1080/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:1080/proxy/rewriteme">... (200; 23.681245ms)
Aug  9 14:40:32.621: INFO: (18) /api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:462/proxy/: tls qux (200; 23.649827ms)
Aug  9 14:40:32.621: INFO: (18) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:162/proxy/: bar (200; 23.784912ms)
Aug  9 14:40:32.622: INFO: (18) /api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:160/proxy/: foo (200; 24.368762ms)
Aug  9 14:40:32.623: INFO: (18) /api/v1/namespaces/proxy-5738/services/https:proxy-service-qr2hs:tlsportname1/proxy/: tls baz (200; 25.396549ms)
Aug  9 14:40:32.624: INFO: (18) /api/v1/namespaces/proxy-5738/services/https:proxy-service-qr2hs:tlsportname2/proxy/: tls qux (200; 26.052545ms)
Aug  9 14:40:32.624: INFO: (18) /api/v1/namespaces/proxy-5738/services/http:proxy-service-qr2hs:portname2/proxy/: bar (200; 26.350787ms)
Aug  9 14:40:32.625: INFO: (18) /api/v1/namespaces/proxy-5738/services/proxy-service-qr2hs:portname2/proxy/: bar (200; 26.942633ms)
Aug  9 14:40:32.625: INFO: (18) /api/v1/namespaces/proxy-5738/services/http:proxy-service-qr2hs:portname1/proxy/: foo (200; 27.427206ms)
Aug  9 14:40:32.625: INFO: (18) /api/v1/namespaces/proxy-5738/services/proxy-service-qr2hs:portname1/proxy/: foo (200; 27.893876ms)
Aug  9 14:40:32.644: INFO: (19) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7/proxy/rewriteme">test</a> (200; 18.34012ms)
Aug  9 14:40:32.644: INFO: (19) /api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:1080/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:1080/proxy/rewriteme">... (200; 18.810966ms)
Aug  9 14:40:32.645: INFO: (19) /api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:443/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:443/proxy/tlsrewritem... (200; 19.795291ms)
Aug  9 14:40:32.645: INFO: (19) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:1080/proxy/: <a href="/api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:1080/proxy/rewriteme">test<... (200; 20.004967ms)
Aug  9 14:40:32.645: INFO: (19) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:160/proxy/: foo (200; 20.000629ms)
Aug  9 14:40:32.646: INFO: (19) /api/v1/namespaces/proxy-5738/services/proxy-service-qr2hs:portname1/proxy/: foo (200; 20.578147ms)
Aug  9 14:40:32.646: INFO: (19) /api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:462/proxy/: tls qux (200; 20.167674ms)
Aug  9 14:40:32.646: INFO: (19) /api/v1/namespaces/proxy-5738/pods/proxy-service-qr2hs-m6zz7:162/proxy/: bar (200; 20.804453ms)
Aug  9 14:40:32.646: INFO: (19) /api/v1/namespaces/proxy-5738/pods/https:proxy-service-qr2hs-m6zz7:460/proxy/: tls baz (200; 20.471336ms)
Aug  9 14:40:32.646: INFO: (19) /api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:162/proxy/: bar (200; 20.615187ms)
Aug  9 14:40:32.648: INFO: (19) /api/v1/namespaces/proxy-5738/services/http:proxy-service-qr2hs:portname1/proxy/: foo (200; 22.453592ms)
Aug  9 14:40:32.648: INFO: (19) /api/v1/namespaces/proxy-5738/pods/http:proxy-service-qr2hs-m6zz7:160/proxy/: foo (200; 21.957807ms)
Aug  9 14:40:32.650: INFO: (19) /api/v1/namespaces/proxy-5738/services/https:proxy-service-qr2hs:tlsportname2/proxy/: tls qux (200; 24.59604ms)
Aug  9 14:40:32.650: INFO: (19) /api/v1/namespaces/proxy-5738/services/proxy-service-qr2hs:portname2/proxy/: bar (200; 24.544704ms)
Aug  9 14:40:32.691: INFO: (19) /api/v1/namespaces/proxy-5738/services/http:proxy-service-qr2hs:portname2/proxy/: bar (200; 65.624857ms)
Aug  9 14:40:32.692: INFO: (19) /api/v1/namespaces/proxy-5738/services/https:proxy-service-qr2hs:tlsportname1/proxy/: tls baz (200; 65.870929ms)
STEP: deleting ReplicationController proxy-service-qr2hs in namespace proxy-5738, will wait for the garbage collector to delete the pods
Aug  9 14:40:32.786: INFO: Deleting ReplicationController proxy-service-qr2hs took: 32.020594ms
Aug  9 14:40:33.187: INFO: Terminating ReplicationController proxy-service-qr2hs pods took: 400.576532ms
[AfterEach] version v1
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:40:44.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-5738" for this suite.
Aug  9 14:40:50.590: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:40:51.012: INFO: namespace proxy-5738 deletion completed in 6.480534449s

• [SLOW TEST:29.180 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:40:51.014: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-1897
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Aug  9 14:41:07.404: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug  9 14:41:07.413: INFO: Pod pod-with-poststart-exec-hook still exists
Aug  9 14:41:09.413: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug  9 14:41:09.424: INFO: Pod pod-with-poststart-exec-hook still exists
Aug  9 14:41:11.413: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug  9 14:41:11.425: INFO: Pod pod-with-poststart-exec-hook still exists
Aug  9 14:41:13.413: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug  9 14:41:13.425: INFO: Pod pod-with-poststart-exec-hook still exists
Aug  9 14:41:15.413: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug  9 14:41:15.425: INFO: Pod pod-with-poststart-exec-hook still exists
Aug  9 14:41:17.413: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug  9 14:41:17.425: INFO: Pod pod-with-poststart-exec-hook still exists
Aug  9 14:41:19.413: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug  9 14:41:19.428: INFO: Pod pod-with-poststart-exec-hook still exists
Aug  9 14:41:21.413: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug  9 14:41:21.424: INFO: Pod pod-with-poststart-exec-hook still exists
Aug  9 14:41:23.413: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug  9 14:41:23.424: INFO: Pod pod-with-poststart-exec-hook still exists
Aug  9 14:41:25.413: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug  9 14:41:25.426: INFO: Pod pod-with-poststart-exec-hook still exists
Aug  9 14:41:27.413: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug  9 14:41:27.425: INFO: Pod pod-with-poststart-exec-hook still exists
Aug  9 14:41:29.413: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug  9 14:41:29.427: INFO: Pod pod-with-poststart-exec-hook still exists
Aug  9 14:41:31.413: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug  9 14:41:31.425: INFO: Pod pod-with-poststart-exec-hook still exists
Aug  9 14:41:33.413: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug  9 14:41:33.426: INFO: Pod pod-with-poststart-exec-hook still exists
Aug  9 14:41:35.413: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Aug  9 14:41:35.425: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:41:35.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-1897" for this suite.
Aug  9 14:41:59.704: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:42:05.574: INFO: namespace container-lifecycle-hook-1897 deletion completed in 29.952174825s

• [SLOW TEST:74.561 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:42:05.576: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-4211
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Aug  9 14:42:07.277: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:42:11.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4211" for this suite.
Aug  9 14:42:57.738: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:42:58.081: INFO: namespace pods-4211 deletion completed in 46.482399833s

• [SLOW TEST:52.506 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:42:58.083: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-4351
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:43:02.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-4351" for this suite.
Aug  9 14:43:28.516: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:43:28.953: INFO: namespace replication-controller-4351 deletion completed in 26.483936631s

• [SLOW TEST:30.871 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:43:28.955: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-1946
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-1946
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a new StatefulSet
Aug  9 14:43:29.264: INFO: Found 0 stateful pods, waiting for 3
Aug  9 14:43:39.276: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Aug  9 14:43:39.276: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Aug  9 14:43:39.276: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Aug  9 14:43:39.314: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-1946 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug  9 14:43:40.552: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug  9 14:43:40.553: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug  9 14:43:40.553: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Aug  9 14:43:50.638: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Aug  9 14:44:00.715: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-1946 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  9 14:44:03.285: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Aug  9 14:44:03.285: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug  9 14:44:03.285: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug  9 14:44:23.352: INFO: Waiting for StatefulSet statefulset-1946/ss2 to complete update
STEP: Rolling back to a previous revision
Aug  9 14:44:33.382: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-1946 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Aug  9 14:44:34.057: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Aug  9 14:44:34.057: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Aug  9 14:44:34.057: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Aug  9 14:44:44.163: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Aug  9 14:44:54.236: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-400702193 exec --namespace=statefulset-1946 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Aug  9 14:44:55.153: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Aug  9 14:44:55.153: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Aug  9 14:44:55.153: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Aug  9 14:45:15.212: INFO: Waiting for StatefulSet statefulset-1946/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Aug  9 14:45:25.233: INFO: Deleting all statefulset in ns statefulset-1946
Aug  9 14:45:25.243: INFO: Scaling statefulset ss2 to 0
Aug  9 14:45:45.294: INFO: Waiting for statefulset status.replicas updated to 0
Aug  9 14:45:45.303: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:45:45.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1946" for this suite.
Aug  9 14:45:53.407: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:45:53.875: INFO: namespace statefulset-1946 deletion completed in 8.507502559s

• [SLOW TEST:144.921 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:45:53.876: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-1675
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Aug  9 14:46:00.425: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:46:01.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-1675" for this suite.
Aug  9 14:46:25.567: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:46:27.683: INFO: namespace replicaset-1675 deletion completed in 26.170929968s

• [SLOW TEST:33.808 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:46:27.686: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8228
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on tmpfs
Aug  9 14:46:27.958: INFO: Waiting up to 5m0s for pod "pod-3ae76d7d-6248-4d61-afcd-83feac5d17c5" in namespace "emptydir-8228" to be "success or failure"
Aug  9 14:46:27.979: INFO: Pod "pod-3ae76d7d-6248-4d61-afcd-83feac5d17c5": Phase="Pending", Reason="", readiness=false. Elapsed: 21.233753ms
Aug  9 14:46:29.992: INFO: Pod "pod-3ae76d7d-6248-4d61-afcd-83feac5d17c5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034209167s
Aug  9 14:46:32.003: INFO: Pod "pod-3ae76d7d-6248-4d61-afcd-83feac5d17c5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.045648884s
STEP: Saw pod success
Aug  9 14:46:32.004: INFO: Pod "pod-3ae76d7d-6248-4d61-afcd-83feac5d17c5" satisfied condition "success or failure"
Aug  9 14:46:32.013: INFO: Trying to get logs from node scw-flan15-default-dae50f7b5eb44e2e9ec95580a7d pod pod-3ae76d7d-6248-4d61-afcd-83feac5d17c5 container test-container: <nil>
STEP: delete the pod
Aug  9 14:46:33.074: INFO: Waiting for pod pod-3ae76d7d-6248-4d61-afcd-83feac5d17c5 to disappear
Aug  9 14:46:33.082: INFO: Pod pod-3ae76d7d-6248-4d61-afcd-83feac5d17c5 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:46:33.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8228" for this suite.
Aug  9 14:46:39.193: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:46:39.557: INFO: namespace emptydir-8228 deletion completed in 6.419518678s

• [SLOW TEST:11.871 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:46:39.558: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-8438
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0809 14:46:45.888799      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug  9 14:46:45.889: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:46:45.889: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8438" for this suite.
Aug  9 14:46:53.958: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:46:54.307: INFO: namespace gc-8438 deletion completed in 8.403166644s

• [SLOW TEST:14.749 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:46:54.308: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-820
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-eac14ee1-8735-4557-b409-6cb19307fe7b
STEP: Creating a pod to test consume configMaps
Aug  9 14:46:54.571: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-8a9ac2ec-1836-4a5a-84ee-494fe5bb3eb4" in namespace "projected-820" to be "success or failure"
Aug  9 14:46:54.587: INFO: Pod "pod-projected-configmaps-8a9ac2ec-1836-4a5a-84ee-494fe5bb3eb4": Phase="Pending", Reason="", readiness=false. Elapsed: 16.373236ms
Aug  9 14:46:56.597: INFO: Pod "pod-projected-configmaps-8a9ac2ec-1836-4a5a-84ee-494fe5bb3eb4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026657446s
Aug  9 14:46:58.609: INFO: Pod "pod-projected-configmaps-8a9ac2ec-1836-4a5a-84ee-494fe5bb3eb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037861665s
STEP: Saw pod success
Aug  9 14:46:58.609: INFO: Pod "pod-projected-configmaps-8a9ac2ec-1836-4a5a-84ee-494fe5bb3eb4" satisfied condition "success or failure"
Aug  9 14:46:58.620: INFO: Trying to get logs from node scw-flan15-default-f07a9b7e282146a6b5427e9aba2 pod pod-projected-configmaps-8a9ac2ec-1836-4a5a-84ee-494fe5bb3eb4 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Aug  9 14:46:58.693: INFO: Waiting for pod pod-projected-configmaps-8a9ac2ec-1836-4a5a-84ee-494fe5bb3eb4 to disappear
Aug  9 14:46:58.715: INFO: Pod pod-projected-configmaps-8a9ac2ec-1836-4a5a-84ee-494fe5bb3eb4 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:46:58.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-820" for this suite.
Aug  9 14:47:04.770: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:47:05.180: INFO: namespace projected-820 deletion completed in 6.451845223s

• [SLOW TEST:10.873 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:47:05.183: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-378
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-378
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Aug  9 14:47:05.430: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Aug  9 14:47:31.739: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 100.64.1.139 8081 | grep -v '^\s*$'] Namespace:pod-network-test-378 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  9 14:47:31.739: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
Aug  9 14:47:32.948: INFO: Found all expected endpoints: [netserver-0]
Aug  9 14:47:32.960: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 100.64.0.113 8081 | grep -v '^\s*$'] Namespace:pod-network-test-378 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  9 14:47:32.960: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
Aug  9 14:47:34.140: INFO: Found all expected endpoints: [netserver-1]
Aug  9 14:47:34.150: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 100.64.2.121 8081 | grep -v '^\s*$'] Namespace:pod-network-test-378 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Aug  9 14:47:34.150: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
Aug  9 14:47:35.340: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:47:35.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-378" for this suite.
Aug  9 14:47:59.401: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:47:59.769: INFO: namespace pod-network-test-378 deletion completed in 24.412504072s

• [SLOW TEST:54.586 seconds]
[sig-network] Networking
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:47:59.771: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3772
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Aug  9 14:48:00.011: INFO: Waiting up to 5m0s for pod "downward-api-5ef66912-3a7b-461f-b1fd-9b4dd7758e4e" in namespace "downward-api-3772" to be "success or failure"
Aug  9 14:48:00.032: INFO: Pod "downward-api-5ef66912-3a7b-461f-b1fd-9b4dd7758e4e": Phase="Pending", Reason="", readiness=false. Elapsed: 20.947044ms
Aug  9 14:48:02.042: INFO: Pod "downward-api-5ef66912-3a7b-461f-b1fd-9b4dd7758e4e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031011761s
Aug  9 14:48:04.055: INFO: Pod "downward-api-5ef66912-3a7b-461f-b1fd-9b4dd7758e4e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.044015097s
STEP: Saw pod success
Aug  9 14:48:04.055: INFO: Pod "downward-api-5ef66912-3a7b-461f-b1fd-9b4dd7758e4e" satisfied condition "success or failure"
Aug  9 14:48:04.065: INFO: Trying to get logs from node scw-flan15-default-fbc750a75c7f4c499b691cc5ccd pod downward-api-5ef66912-3a7b-461f-b1fd-9b4dd7758e4e container dapi-container: <nil>
STEP: delete the pod
Aug  9 14:48:04.151: INFO: Waiting for pod downward-api-5ef66912-3a7b-461f-b1fd-9b4dd7758e4e to disappear
Aug  9 14:48:04.161: INFO: Pod downward-api-5ef66912-3a7b-461f-b1fd-9b4dd7758e4e no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:48:04.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3772" for this suite.
Aug  9 14:48:10.244: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:48:10.592: INFO: namespace downward-api-3772 deletion completed in 6.406839822s

• [SLOW TEST:10.821 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:48:10.592: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7741
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Aug  9 14:48:15.470: INFO: Successfully updated pod "labelsupdate04b92549-2124-48be-b31f-f6d3a615bb30"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:48:17.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7741" for this suite.
Aug  9 14:48:41.587: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:48:41.989: INFO: namespace projected-7741 deletion completed in 24.442891378s

• [SLOW TEST:31.397 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:48:41.989: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-8320
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Aug  9 14:48:42.285: INFO: PodSpec: initContainers in spec.initContainers
Aug  9 14:49:30.762: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-6d151330-8bcf-4520-81cb-3e38bdfaa3e8", GenerateName:"", Namespace:"init-container-8320", SelfLink:"/api/v1/namespaces/init-container-8320/pods/pod-init-6d151330-8bcf-4520-81cb-3e38bdfaa3e8", UID:"445ecd83-cfd2-4b84-a549-e744e4938c6d", ResourceVersion:"124731097", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63700958922, loc:(*time.Location)(0x80bfa40)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"285347711"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-gmrl6", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001c5a880), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-gmrl6", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-gmrl6", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-gmrl6", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc002a4b778), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"scw-flan15-default-fbc750a75c7f4c499b691cc5ccd", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc00234afc0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002a4b7f0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002a4b810)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc002a4b818), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc002a4b81c), PreemptionPolicy:(*v1.PreemptionPolicy)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700958922, loc:(*time.Location)(0x80bfa40)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700958922, loc:(*time.Location)(0x80bfa40)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700958922, loc:(*time.Location)(0x80bfa40)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63700958922, loc:(*time.Location)(0x80bfa40)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.12.167.225", PodIP:"100.64.2.123", StartTime:(*v1.Time)(0xc002523c00), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002aba4d0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002aba540)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://2488c0f411db8f1c922641d13d2e41d57b0d3a1c4d03575faba53b07e4a3513e"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002523c40), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002523c20), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Aug  9 14:49:30.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-8320" for this suite.
Aug  9 14:49:54.868: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:49:55.232: INFO: namespace init-container-8320 deletion completed in 24.404587465s

• [SLOW TEST:73.243 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Aug  9 14:49:55.232: INFO: >>> kubeConfig: /tmp/kubeconfig-400702193
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-1635
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Aug  9 14:50:35.569: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
W0809 14:50:35.569875      19 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Aug  9 14:50:35.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1635" for this suite.
Aug  9 14:50:43.624: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Aug  9 14:50:44.087: INFO: namespace gc-1635 deletion completed in 8.504455786s

• [SLOW TEST:48.855 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSAug  9 14:50:44.087: INFO: Running AfterSuite actions on all nodes
Aug  9 14:50:44.087: INFO: Running AfterSuite actions on node 1
Aug  9 14:50:44.087: INFO: Skipping dumping logs from cluster

Ran 215 of 4413 Specs in 6510.859 seconds
SUCCESS! -- 215 Passed | 0 Failed | 0 Pending | 4198 Skipped
PASS

Ginkgo ran 1 suite in 1h48m34.269825867s
Test Suite Passed
