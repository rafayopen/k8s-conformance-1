I1122 17:53:31.675165      19 test_context.go:406] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-880417063
I1122 17:53:31.675410      19 e2e.go:241] Starting e2e run "3b67a62c-e62f-45eb-b65f-c4a1e157653a" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1574445204 - Will randomize all specs
Will run 210 of 4413 specs

Nov 22 17:53:32.454: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
Nov 22 17:53:32.469: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Nov 22 17:53:32.507: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Nov 22 17:53:32.620: INFO: 16 / 16 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Nov 22 17:53:32.620: INFO: expected 6 pod replicas in namespace 'kube-system', 6 are Running and Ready.
Nov 22 17:53:32.620: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Nov 22 17:53:32.663: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Nov 22 17:53:32.663: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'nodelocaldns' (0 seconds elapsed)
Nov 22 17:53:32.663: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'weave-net' (0 seconds elapsed)
Nov 22 17:53:32.663: INFO: e2e test version: v1.15.3
Nov 22 17:53:32.664: INFO: kube-apiserver version: v1.15.3
SSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 17:53:32.664: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename container-probe
Nov 22 17:53:32.777: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Nov 22 17:53:58.871: INFO: Container started at 2019-11-22 17:53:34 +0000 UTC, pod became ready at 2019-11-22 17:53:58 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 17:53:58.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-612" for this suite.
Nov 22 17:54:22.935: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 17:54:23.149: INFO: namespace container-probe-612 deletion completed in 24.268476351s

• [SLOW TEST:50.485 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 17:54:23.150: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating server pod server in namespace prestop-4396
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-4396
STEP: Deleting pre-stop pod
Nov 22 17:54:36.325: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 17:54:36.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-4396" for this suite.
Nov 22 17:55:16.421: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 17:55:16.488: INFO: namespace prestop-4396 deletion completed in 40.136758291s

• [SLOW TEST:53.338 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 17:55:16.488: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Nov 22 17:55:20.551: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov 22 17:55:20.553: INFO: Pod pod-with-prestop-http-hook still exists
Nov 22 17:55:22.553: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov 22 17:55:22.554: INFO: Pod pod-with-prestop-http-hook still exists
Nov 22 17:55:24.553: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov 22 17:55:24.555: INFO: Pod pod-with-prestop-http-hook still exists
Nov 22 17:55:26.553: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov 22 17:55:26.554: INFO: Pod pod-with-prestop-http-hook still exists
Nov 22 17:55:28.553: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov 22 17:55:28.555: INFO: Pod pod-with-prestop-http-hook still exists
Nov 22 17:55:30.553: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov 22 17:55:30.554: INFO: Pod pod-with-prestop-http-hook still exists
Nov 22 17:55:32.555: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov 22 17:55:32.562: INFO: Pod pod-with-prestop-http-hook still exists
Nov 22 17:55:34.553: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov 22 17:55:34.555: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 17:55:34.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-5198" for this suite.
Nov 22 17:55:56.569: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 17:55:56.648: INFO: namespace container-lifecycle-hook-5198 deletion completed in 22.084413197s

• [SLOW TEST:40.159 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 17:55:56.648: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-7033
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Nov 22 17:55:56.725: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Nov 22 17:56:14.811: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.251.128.9:8080/dial?request=hostName&protocol=udp&host=10.251.128.8&port=8081&tries=1'] Namespace:pod-network-test-7033 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 22 17:56:14.811: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
Nov 22 17:56:14.960: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 17:56:14.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7033" for this suite.
Nov 22 17:56:39.038: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 17:56:39.315: INFO: namespace pod-network-test-7033 deletion completed in 24.334531941s

• [SLOW TEST:42.668 seconds]
[sig-network] Networking
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 17:56:39.316: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Nov 22 17:56:39.418: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a6c06c1a-26e1-4f91-a87d-466dc2810aaa" in namespace "projected-8845" to be "success or failure"
Nov 22 17:56:39.449: INFO: Pod "downwardapi-volume-a6c06c1a-26e1-4f91-a87d-466dc2810aaa": Phase="Pending", Reason="", readiness=false. Elapsed: 30.986046ms
Nov 22 17:56:41.453: INFO: Pod "downwardapi-volume-a6c06c1a-26e1-4f91-a87d-466dc2810aaa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034938257s
Nov 22 17:56:43.455: INFO: Pod "downwardapi-volume-a6c06c1a-26e1-4f91-a87d-466dc2810aaa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037075103s
STEP: Saw pod success
Nov 22 17:56:43.463: INFO: Pod "downwardapi-volume-a6c06c1a-26e1-4f91-a87d-466dc2810aaa" satisfied condition "success or failure"
Nov 22 17:56:43.480: INFO: Trying to get logs from node minion pod downwardapi-volume-a6c06c1a-26e1-4f91-a87d-466dc2810aaa container client-container: <nil>
STEP: delete the pod
Nov 22 17:56:43.529: INFO: Waiting for pod downwardapi-volume-a6c06c1a-26e1-4f91-a87d-466dc2810aaa to disappear
Nov 22 17:56:43.531: INFO: Pod downwardapi-volume-a6c06c1a-26e1-4f91-a87d-466dc2810aaa no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 17:56:43.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8845" for this suite.
Nov 22 17:56:49.566: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 17:56:49.819: INFO: namespace projected-8845 deletion completed in 6.273935011s

• [SLOW TEST:10.503 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 17:56:49.820: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Nov 22 17:56:49.941: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 17:56:52.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1453" for this suite.
Nov 22 17:57:32.149: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 17:57:32.425: INFO: namespace pods-1453 deletion completed in 40.336275411s

• [SLOW TEST:42.605 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 17:57:32.425: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 17:57:34.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6618" for this suite.
Nov 22 17:58:24.591: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 17:58:24.894: INFO: namespace kubelet-test-6618 deletion completed in 50.335252338s

• [SLOW TEST:52.469 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 17:58:24.895: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Nov 22 17:58:24.974: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c66c5457-5e7a-4983-9f63-f820ddb56476" in namespace "projected-2929" to be "success or failure"
Nov 22 17:58:24.998: INFO: Pod "downwardapi-volume-c66c5457-5e7a-4983-9f63-f820ddb56476": Phase="Pending", Reason="", readiness=false. Elapsed: 23.843707ms
Nov 22 17:58:27.009: INFO: Pod "downwardapi-volume-c66c5457-5e7a-4983-9f63-f820ddb56476": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035076966s
Nov 22 17:58:29.015: INFO: Pod "downwardapi-volume-c66c5457-5e7a-4983-9f63-f820ddb56476": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.041072669s
STEP: Saw pod success
Nov 22 17:58:29.015: INFO: Pod "downwardapi-volume-c66c5457-5e7a-4983-9f63-f820ddb56476" satisfied condition "success or failure"
Nov 22 17:58:29.017: INFO: Trying to get logs from node minion pod downwardapi-volume-c66c5457-5e7a-4983-9f63-f820ddb56476 container client-container: <nil>
STEP: delete the pod
Nov 22 17:58:29.053: INFO: Waiting for pod downwardapi-volume-c66c5457-5e7a-4983-9f63-f820ddb56476 to disappear
Nov 22 17:58:29.063: INFO: Pod downwardapi-volume-c66c5457-5e7a-4983-9f63-f820ddb56476 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 17:58:29.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2929" for this suite.
Nov 22 17:58:35.095: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 17:58:35.419: INFO: namespace projected-2929 deletion completed in 6.35137889s

• [SLOW TEST:10.524 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 17:58:35.419: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Nov 22 17:58:37.596: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 17:58:37.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-4991" for this suite.
Nov 22 17:58:43.649: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 17:58:43.973: INFO: namespace container-runtime-4991 deletion completed in 6.34545408s

• [SLOW TEST:8.554 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 17:58:43.974: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 17:58:50.323: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-9848" for this suite.
Nov 22 17:58:56.379: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 17:58:56.667: INFO: namespace namespaces-9848 deletion completed in 6.34228069s
STEP: Destroying namespace "nsdeletetest-4247" for this suite.
Nov 22 17:58:56.669: INFO: Namespace nsdeletetest-4247 was already deleted
STEP: Destroying namespace "nsdeletetest-2714" for this suite.
Nov 22 17:59:02.692: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 17:59:02.947: INFO: namespace nsdeletetest-2714 deletion completed in 6.278514127s

• [SLOW TEST:18.974 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 17:59:02.948: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override command
Nov 22 17:59:03.030: INFO: Waiting up to 5m0s for pod "client-containers-03008046-66dd-4753-8f2a-5807625d028a" in namespace "containers-1168" to be "success or failure"
Nov 22 17:59:03.045: INFO: Pod "client-containers-03008046-66dd-4753-8f2a-5807625d028a": Phase="Pending", Reason="", readiness=false. Elapsed: 14.743055ms
Nov 22 17:59:05.047: INFO: Pod "client-containers-03008046-66dd-4753-8f2a-5807625d028a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016596559s
STEP: Saw pod success
Nov 22 17:59:05.047: INFO: Pod "client-containers-03008046-66dd-4753-8f2a-5807625d028a" satisfied condition "success or failure"
Nov 22 17:59:05.065: INFO: Trying to get logs from node minion pod client-containers-03008046-66dd-4753-8f2a-5807625d028a container test-container: <nil>
STEP: delete the pod
Nov 22 17:59:05.093: INFO: Waiting for pod client-containers-03008046-66dd-4753-8f2a-5807625d028a to disappear
Nov 22 17:59:05.108: INFO: Pod client-containers-03008046-66dd-4753-8f2a-5807625d028a no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 17:59:05.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-1168" for this suite.
Nov 22 17:59:11.140: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 17:59:11.581: INFO: namespace containers-1168 deletion completed in 6.463088166s

• [SLOW TEST:8.634 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 17:59:11.581: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 17:59:15.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-9750" for this suite.
Nov 22 17:59:21.823: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 17:59:22.120: INFO: namespace emptydir-wrapper-9750 deletion completed in 6.331319298s

• [SLOW TEST:10.539 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 17:59:22.121: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 17:59:26.282: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1623" for this suite.
Nov 22 18:00:14.310: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:00:14.535: INFO: namespace kubelet-test-1623 deletion completed in 48.243016002s

• [SLOW TEST:52.414 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command in a pod
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:00:14.536: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-configmap-jt2g
STEP: Creating a pod to test atomic-volume-subpath
Nov 22 18:00:14.572: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-jt2g" in namespace "subpath-5457" to be "success or failure"
Nov 22 18:00:14.575: INFO: Pod "pod-subpath-test-configmap-jt2g": Phase="Pending", Reason="", readiness=false. Elapsed: 3.06756ms
Nov 22 18:00:16.579: INFO: Pod "pod-subpath-test-configmap-jt2g": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006504758s
Nov 22 18:00:18.581: INFO: Pod "pod-subpath-test-configmap-jt2g": Phase="Running", Reason="", readiness=true. Elapsed: 4.008281935s
Nov 22 18:00:20.583: INFO: Pod "pod-subpath-test-configmap-jt2g": Phase="Running", Reason="", readiness=true. Elapsed: 6.010682098s
Nov 22 18:00:22.585: INFO: Pod "pod-subpath-test-configmap-jt2g": Phase="Running", Reason="", readiness=true. Elapsed: 8.012578174s
Nov 22 18:00:24.587: INFO: Pod "pod-subpath-test-configmap-jt2g": Phase="Running", Reason="", readiness=true. Elapsed: 10.014153836s
Nov 22 18:00:26.589: INFO: Pod "pod-subpath-test-configmap-jt2g": Phase="Running", Reason="", readiness=true. Elapsed: 12.016292722s
Nov 22 18:00:28.591: INFO: Pod "pod-subpath-test-configmap-jt2g": Phase="Running", Reason="", readiness=true. Elapsed: 14.018345518s
Nov 22 18:00:30.592: INFO: Pod "pod-subpath-test-configmap-jt2g": Phase="Running", Reason="", readiness=true. Elapsed: 16.019939966s
Nov 22 18:00:32.594: INFO: Pod "pod-subpath-test-configmap-jt2g": Phase="Running", Reason="", readiness=true. Elapsed: 18.021543035s
Nov 22 18:00:34.596: INFO: Pod "pod-subpath-test-configmap-jt2g": Phase="Running", Reason="", readiness=true. Elapsed: 20.023495747s
Nov 22 18:00:36.598: INFO: Pod "pod-subpath-test-configmap-jt2g": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.025416277s
STEP: Saw pod success
Nov 22 18:00:36.598: INFO: Pod "pod-subpath-test-configmap-jt2g" satisfied condition "success or failure"
Nov 22 18:00:36.599: INFO: Trying to get logs from node minion pod pod-subpath-test-configmap-jt2g container test-container-subpath-configmap-jt2g: <nil>
STEP: delete the pod
Nov 22 18:00:36.611: INFO: Waiting for pod pod-subpath-test-configmap-jt2g to disappear
Nov 22 18:00:36.620: INFO: Pod pod-subpath-test-configmap-jt2g no longer exists
STEP: Deleting pod pod-subpath-test-configmap-jt2g
Nov 22 18:00:36.620: INFO: Deleting pod "pod-subpath-test-configmap-jt2g" in namespace "subpath-5457"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:00:36.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5457" for this suite.
Nov 22 18:00:42.634: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:00:42.704: INFO: namespace subpath-5457 deletion completed in 6.079294112s

• [SLOW TEST:28.168 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:00:42.704: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-2b8eb254-3534-4049-89d4-6c1fab04a29e
STEP: Creating a pod to test consume secrets
Nov 22 18:00:42.736: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-18a103f0-181f-466d-9ad0-addcfc4bf9e1" in namespace "projected-6639" to be "success or failure"
Nov 22 18:00:42.738: INFO: Pod "pod-projected-secrets-18a103f0-181f-466d-9ad0-addcfc4bf9e1": Phase="Pending", Reason="", readiness=false. Elapsed: 1.402915ms
Nov 22 18:00:44.739: INFO: Pod "pod-projected-secrets-18a103f0-181f-466d-9ad0-addcfc4bf9e1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003247115s
STEP: Saw pod success
Nov 22 18:00:44.739: INFO: Pod "pod-projected-secrets-18a103f0-181f-466d-9ad0-addcfc4bf9e1" satisfied condition "success or failure"
Nov 22 18:00:44.741: INFO: Trying to get logs from node minion pod pod-projected-secrets-18a103f0-181f-466d-9ad0-addcfc4bf9e1 container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov 22 18:00:44.751: INFO: Waiting for pod pod-projected-secrets-18a103f0-181f-466d-9ad0-addcfc4bf9e1 to disappear
Nov 22 18:00:44.759: INFO: Pod pod-projected-secrets-18a103f0-181f-466d-9ad0-addcfc4bf9e1 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:00:44.759: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6639" for this suite.
Nov 22 18:00:50.768: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:00:50.831: INFO: namespace projected-6639 deletion completed in 6.070283976s

• [SLOW TEST:8.127 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:00:50.832: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name s-test-opt-del-5b09b2dc-a733-4810-834f-65c30431983c
STEP: Creating secret with name s-test-opt-upd-dbf62cb3-bd06-420f-8408-8483e0e536f1
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-5b09b2dc-a733-4810-834f-65c30431983c
STEP: Updating secret s-test-opt-upd-dbf62cb3-bd06-420f-8408-8483e0e536f1
STEP: Creating secret with name s-test-opt-create-ca432100-03a1-47dc-932e-517bad3df22b
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:00:56.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4977" for this suite.
Nov 22 18:01:18.942: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:01:19.419: INFO: namespace projected-4977 deletion completed in 22.494700893s

• [SLOW TEST:28.587 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:01:19.419: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Nov 22 18:01:19.500: INFO: Waiting up to 5m0s for pod "downward-api-695b86aa-9432-401b-87a6-2888749e9826" in namespace "downward-api-7360" to be "success or failure"
Nov 22 18:01:19.534: INFO: Pod "downward-api-695b86aa-9432-401b-87a6-2888749e9826": Phase="Pending", Reason="", readiness=false. Elapsed: 33.506236ms
Nov 22 18:01:21.539: INFO: Pod "downward-api-695b86aa-9432-401b-87a6-2888749e9826": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.038512882s
STEP: Saw pod success
Nov 22 18:01:21.539: INFO: Pod "downward-api-695b86aa-9432-401b-87a6-2888749e9826" satisfied condition "success or failure"
Nov 22 18:01:21.540: INFO: Trying to get logs from node minion pod downward-api-695b86aa-9432-401b-87a6-2888749e9826 container dapi-container: <nil>
STEP: delete the pod
Nov 22 18:01:21.583: INFO: Waiting for pod downward-api-695b86aa-9432-401b-87a6-2888749e9826 to disappear
Nov 22 18:01:21.584: INFO: Pod downward-api-695b86aa-9432-401b-87a6-2888749e9826 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:01:21.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7360" for this suite.
Nov 22 18:01:27.617: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:01:27.900: INFO: namespace downward-api-7360 deletion completed in 6.302102866s

• [SLOW TEST:8.481 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:01:27.901: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-configmap-pk6g
STEP: Creating a pod to test atomic-volume-subpath
Nov 22 18:01:28.102: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-pk6g" in namespace "subpath-9986" to be "success or failure"
Nov 22 18:01:28.137: INFO: Pod "pod-subpath-test-configmap-pk6g": Phase="Pending", Reason="", readiness=false. Elapsed: 35.239815ms
Nov 22 18:01:30.143: INFO: Pod "pod-subpath-test-configmap-pk6g": Phase="Running", Reason="", readiness=true. Elapsed: 2.041767198s
Nov 22 18:01:32.153: INFO: Pod "pod-subpath-test-configmap-pk6g": Phase="Running", Reason="", readiness=true. Elapsed: 4.051763899s
Nov 22 18:01:34.156: INFO: Pod "pod-subpath-test-configmap-pk6g": Phase="Running", Reason="", readiness=true. Elapsed: 6.053962299s
Nov 22 18:01:36.159: INFO: Pod "pod-subpath-test-configmap-pk6g": Phase="Running", Reason="", readiness=true. Elapsed: 8.057334792s
Nov 22 18:01:38.176: INFO: Pod "pod-subpath-test-configmap-pk6g": Phase="Running", Reason="", readiness=true. Elapsed: 10.07472656s
Nov 22 18:01:40.179: INFO: Pod "pod-subpath-test-configmap-pk6g": Phase="Running", Reason="", readiness=true. Elapsed: 12.077647993s
Nov 22 18:01:42.188: INFO: Pod "pod-subpath-test-configmap-pk6g": Phase="Running", Reason="", readiness=true. Elapsed: 14.086135991s
Nov 22 18:01:44.190: INFO: Pod "pod-subpath-test-configmap-pk6g": Phase="Running", Reason="", readiness=true. Elapsed: 16.088006166s
Nov 22 18:01:46.196: INFO: Pod "pod-subpath-test-configmap-pk6g": Phase="Running", Reason="", readiness=true. Elapsed: 18.094162347s
Nov 22 18:01:48.198: INFO: Pod "pod-subpath-test-configmap-pk6g": Phase="Running", Reason="", readiness=true. Elapsed: 20.09607265s
Nov 22 18:01:50.200: INFO: Pod "pod-subpath-test-configmap-pk6g": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.098768355s
STEP: Saw pod success
Nov 22 18:01:50.201: INFO: Pod "pod-subpath-test-configmap-pk6g" satisfied condition "success or failure"
Nov 22 18:01:50.202: INFO: Trying to get logs from node minion pod pod-subpath-test-configmap-pk6g container test-container-subpath-configmap-pk6g: <nil>
STEP: delete the pod
Nov 22 18:01:50.245: INFO: Waiting for pod pod-subpath-test-configmap-pk6g to disappear
Nov 22 18:01:50.247: INFO: Pod pod-subpath-test-configmap-pk6g no longer exists
STEP: Deleting pod pod-subpath-test-configmap-pk6g
Nov 22 18:01:50.247: INFO: Deleting pod "pod-subpath-test-configmap-pk6g" in namespace "subpath-9986"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:01:50.276: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9986" for this suite.
Nov 22 18:01:56.296: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:01:56.589: INFO: namespace subpath-9986 deletion completed in 6.311119024s

• [SLOW TEST:28.688 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:01:56.589: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with configMap that has name projected-configmap-test-upd-27dd0fe6-ee93-4d6f-9f1a-6f79a421ce53
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-27dd0fe6-ee93-4d6f-9f1a-6f79a421ce53
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:03:05.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-740" for this suite.
Nov 22 18:03:25.509: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:03:25.780: INFO: namespace projected-740 deletion completed in 20.291957346s

• [SLOW TEST:89.191 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:03:25.780: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-secret-6s6f
STEP: Creating a pod to test atomic-volume-subpath
Nov 22 18:03:25.903: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-6s6f" in namespace "subpath-3038" to be "success or failure"
Nov 22 18:03:25.918: INFO: Pod "pod-subpath-test-secret-6s6f": Phase="Pending", Reason="", readiness=false. Elapsed: 15.55199ms
Nov 22 18:03:27.924: INFO: Pod "pod-subpath-test-secret-6s6f": Phase="Running", Reason="", readiness=true. Elapsed: 2.020912354s
Nov 22 18:03:29.934: INFO: Pod "pod-subpath-test-secret-6s6f": Phase="Running", Reason="", readiness=true. Elapsed: 4.030954389s
Nov 22 18:03:31.936: INFO: Pod "pod-subpath-test-secret-6s6f": Phase="Running", Reason="", readiness=true. Elapsed: 6.032941485s
Nov 22 18:03:33.944: INFO: Pod "pod-subpath-test-secret-6s6f": Phase="Running", Reason="", readiness=true. Elapsed: 8.041439362s
Nov 22 18:03:35.948: INFO: Pod "pod-subpath-test-secret-6s6f": Phase="Running", Reason="", readiness=true. Elapsed: 10.045180695s
Nov 22 18:03:37.950: INFO: Pod "pod-subpath-test-secret-6s6f": Phase="Running", Reason="", readiness=true. Elapsed: 12.047213948s
Nov 22 18:03:39.962: INFO: Pod "pod-subpath-test-secret-6s6f": Phase="Running", Reason="", readiness=true. Elapsed: 14.059014942s
Nov 22 18:03:41.985: INFO: Pod "pod-subpath-test-secret-6s6f": Phase="Running", Reason="", readiness=true. Elapsed: 16.08203012s
Nov 22 18:03:43.990: INFO: Pod "pod-subpath-test-secret-6s6f": Phase="Running", Reason="", readiness=true. Elapsed: 18.087255085s
Nov 22 18:03:46.002: INFO: Pod "pod-subpath-test-secret-6s6f": Phase="Running", Reason="", readiness=true. Elapsed: 20.099435811s
Nov 22 18:03:48.007: INFO: Pod "pod-subpath-test-secret-6s6f": Phase="Running", Reason="", readiness=true. Elapsed: 22.104376615s
Nov 22 18:03:50.011: INFO: Pod "pod-subpath-test-secret-6s6f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.108151148s
STEP: Saw pod success
Nov 22 18:03:50.011: INFO: Pod "pod-subpath-test-secret-6s6f" satisfied condition "success or failure"
Nov 22 18:03:50.012: INFO: Trying to get logs from node minion pod pod-subpath-test-secret-6s6f container test-container-subpath-secret-6s6f: <nil>
STEP: delete the pod
Nov 22 18:03:50.055: INFO: Waiting for pod pod-subpath-test-secret-6s6f to disappear
Nov 22 18:03:50.069: INFO: Pod pod-subpath-test-secret-6s6f no longer exists
STEP: Deleting pod pod-subpath-test-secret-6s6f
Nov 22 18:03:50.069: INFO: Deleting pod "pod-subpath-test-secret-6s6f" in namespace "subpath-3038"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:03:50.070: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-3038" for this suite.
Nov 22 18:03:56.105: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:03:56.431: INFO: namespace subpath-3038 deletion completed in 6.345852372s

• [SLOW TEST:30.651 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:03:56.431: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Nov 22 18:03:56.542: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8aaba90a-27ee-40a0-b786-be36b98353f9" in namespace "downward-api-2842" to be "success or failure"
Nov 22 18:03:56.556: INFO: Pod "downwardapi-volume-8aaba90a-27ee-40a0-b786-be36b98353f9": Phase="Pending", Reason="", readiness=false. Elapsed: 14.33455ms
Nov 22 18:03:58.559: INFO: Pod "downwardapi-volume-8aaba90a-27ee-40a0-b786-be36b98353f9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017373915s
STEP: Saw pod success
Nov 22 18:03:58.559: INFO: Pod "downwardapi-volume-8aaba90a-27ee-40a0-b786-be36b98353f9" satisfied condition "success or failure"
Nov 22 18:03:58.561: INFO: Trying to get logs from node minion pod downwardapi-volume-8aaba90a-27ee-40a0-b786-be36b98353f9 container client-container: <nil>
STEP: delete the pod
Nov 22 18:03:58.593: INFO: Waiting for pod downwardapi-volume-8aaba90a-27ee-40a0-b786-be36b98353f9 to disappear
Nov 22 18:03:58.611: INFO: Pod downwardapi-volume-8aaba90a-27ee-40a0-b786-be36b98353f9 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:03:58.611: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2842" for this suite.
Nov 22 18:04:04.630: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:04:04.898: INFO: namespace downward-api-2842 deletion completed in 6.284500378s

• [SLOW TEST:8.466 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:04:04.898: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-6407
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Nov 22 18:04:05.004: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Nov 22 18:04:31.139: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.251.128.8 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6407 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 22 18:04:31.139: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
Nov 22 18:04:32.271: INFO: Found all expected endpoints: [netserver-0]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:04:32.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-6407" for this suite.
Nov 22 18:04:56.293: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:04:56.550: INFO: namespace pod-network-test-6407 deletion completed in 24.277476129s

• [SLOW TEST:51.653 seconds]
[sig-network] Networking
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:04:56.551: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1421
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Nov 22 18:04:56.620: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-6905'
Nov 22 18:04:58.349: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Nov 22 18:04:58.349: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1427
Nov 22 18:05:00.364: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 delete deployment e2e-test-nginx-deployment --namespace=kubectl-6905'
Nov 22 18:05:00.803: INFO: stderr: ""
Nov 22 18:05:00.803: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:05:00.803: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6905" for this suite.
Nov 22 18:05:22.864: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:05:22.944: INFO: namespace kubectl-6905 deletion completed in 22.10546078s

• [SLOW TEST:26.393 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run default
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:05:22.944: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-75wlb in namespace proxy-1213
I1122 18:05:22.987923      19 runners.go:180] Created replication controller with name: proxy-service-75wlb, namespace: proxy-1213, replica count: 1
I1122 18:05:24.038451      19 runners.go:180] proxy-service-75wlb Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1122 18:05:25.038646      19 runners.go:180] proxy-service-75wlb Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1122 18:05:26.038852      19 runners.go:180] proxy-service-75wlb Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1122 18:05:27.039062      19 runners.go:180] proxy-service-75wlb Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1122 18:05:28.039272      19 runners.go:180] proxy-service-75wlb Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1122 18:05:29.039542      19 runners.go:180] proxy-service-75wlb Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov 22 18:05:29.041: INFO: setup took 6.07928409s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Nov 22 18:05:29.051: INFO: (0) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:1080/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:1080/proxy/rewriteme">test<... (200; 9.560973ms)
Nov 22 18:05:29.051: INFO: (0) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:160/proxy/: foo (200; 8.925521ms)
Nov 22 18:05:29.052: INFO: (0) /api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:160/proxy/: foo (200; 10.059764ms)
Nov 22 18:05:29.052: INFO: (0) /api/v1/namespaces/proxy-1213/services/http:proxy-service-75wlb:portname1/proxy/: foo (200; 10.703387ms)
Nov 22 18:05:29.052: INFO: (0) /api/v1/namespaces/proxy-1213/services/proxy-service-75wlb:portname1/proxy/: foo (200; 10.841432ms)
Nov 22 18:05:29.052: INFO: (0) /api/v1/namespaces/proxy-1213/services/http:proxy-service-75wlb:portname2/proxy/: bar (200; 10.361948ms)
Nov 22 18:05:29.052: INFO: (0) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d/proxy/rewriteme">test</a> (200; 10.357553ms)
Nov 22 18:05:29.052: INFO: (0) /api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:162/proxy/: bar (200; 10.605866ms)
Nov 22 18:05:29.052: INFO: (0) /api/v1/namespaces/proxy-1213/services/proxy-service-75wlb:portname2/proxy/: bar (200; 10.189316ms)
Nov 22 18:05:29.052: INFO: (0) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:162/proxy/: bar (200; 10.411179ms)
Nov 22 18:05:29.056: INFO: (0) /api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:1080/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:1080/proxy/rewriteme">... (200; 13.802191ms)
Nov 22 18:05:29.056: INFO: (0) /api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:443/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:443/proxy/tlsrewritem... (200; 14.538857ms)
Nov 22 18:05:29.056: INFO: (0) /api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:462/proxy/: tls qux (200; 15.222431ms)
Nov 22 18:05:29.057: INFO: (0) /api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:460/proxy/: tls baz (200; 14.62026ms)
Nov 22 18:05:29.057: INFO: (0) /api/v1/namespaces/proxy-1213/services/https:proxy-service-75wlb:tlsportname2/proxy/: tls qux (200; 14.694678ms)
Nov 22 18:05:29.057: INFO: (0) /api/v1/namespaces/proxy-1213/services/https:proxy-service-75wlb:tlsportname1/proxy/: tls baz (200; 15.550659ms)
Nov 22 18:05:29.063: INFO: (1) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d/proxy/rewriteme">test</a> (200; 5.778273ms)
Nov 22 18:05:29.063: INFO: (1) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:1080/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:1080/proxy/rewriteme">test<... (200; 5.121759ms)
Nov 22 18:05:29.063: INFO: (1) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:160/proxy/: foo (200; 4.451297ms)
Nov 22 18:05:29.063: INFO: (1) /api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:443/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:443/proxy/tlsrewritem... (200; 5.760514ms)
Nov 22 18:05:29.063: INFO: (1) /api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:162/proxy/: bar (200; 5.141387ms)
Nov 22 18:05:29.063: INFO: (1) /api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:460/proxy/: tls baz (200; 5.097019ms)
Nov 22 18:05:29.063: INFO: (1) /api/v1/namespaces/proxy-1213/services/https:proxy-service-75wlb:tlsportname1/proxy/: tls baz (200; 5.669972ms)
Nov 22 18:05:29.063: INFO: (1) /api/v1/namespaces/proxy-1213/services/https:proxy-service-75wlb:tlsportname2/proxy/: tls qux (200; 4.656407ms)
Nov 22 18:05:29.063: INFO: (1) /api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:462/proxy/: tls qux (200; 6.2236ms)
Nov 22 18:05:29.065: INFO: (1) /api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:1080/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:1080/proxy/rewriteme">... (200; 6.1863ms)
Nov 22 18:05:29.065: INFO: (1) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:162/proxy/: bar (200; 6.179176ms)
Nov 22 18:05:29.065: INFO: (1) /api/v1/namespaces/proxy-1213/services/proxy-service-75wlb:portname2/proxy/: bar (200; 6.697286ms)
Nov 22 18:05:29.066: INFO: (1) /api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:160/proxy/: foo (200; 6.707766ms)
Nov 22 18:05:29.066: INFO: (1) /api/v1/namespaces/proxy-1213/services/http:proxy-service-75wlb:portname1/proxy/: foo (200; 8.602001ms)
Nov 22 18:05:29.066: INFO: (1) /api/v1/namespaces/proxy-1213/services/http:proxy-service-75wlb:portname2/proxy/: bar (200; 4.189393ms)
Nov 22 18:05:29.069: INFO: (1) /api/v1/namespaces/proxy-1213/services/proxy-service-75wlb:portname1/proxy/: foo (200; 6.375358ms)
Nov 22 18:05:29.075: INFO: (2) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:162/proxy/: bar (200; 5.366087ms)
Nov 22 18:05:29.075: INFO: (2) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:1080/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:1080/proxy/rewriteme">test<... (200; 6.219648ms)
Nov 22 18:05:29.075: INFO: (2) /api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:443/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:443/proxy/tlsrewritem... (200; 5.91767ms)
Nov 22 18:05:29.075: INFO: (2) /api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:162/proxy/: bar (200; 6.128744ms)
Nov 22 18:05:29.075: INFO: (2) /api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:462/proxy/: tls qux (200; 5.067145ms)
Nov 22 18:05:29.075: INFO: (2) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:160/proxy/: foo (200; 5.215166ms)
Nov 22 18:05:29.075: INFO: (2) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d/proxy/rewriteme">test</a> (200; 6.08853ms)
Nov 22 18:05:29.075: INFO: (2) /api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:160/proxy/: foo (200; 5.855025ms)
Nov 22 18:05:29.075: INFO: (2) /api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:1080/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:1080/proxy/rewriteme">... (200; 5.939894ms)
Nov 22 18:05:29.075: INFO: (2) /api/v1/namespaces/proxy-1213/services/proxy-service-75wlb:portname2/proxy/: bar (200; 5.62187ms)
Nov 22 18:05:29.075: INFO: (2) /api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:460/proxy/: tls baz (200; 5.708848ms)
Nov 22 18:05:29.077: INFO: (2) /api/v1/namespaces/proxy-1213/services/proxy-service-75wlb:portname1/proxy/: foo (200; 6.784328ms)
Nov 22 18:05:29.077: INFO: (2) /api/v1/namespaces/proxy-1213/services/http:proxy-service-75wlb:portname1/proxy/: foo (200; 5.366256ms)
Nov 22 18:05:29.077: INFO: (2) /api/v1/namespaces/proxy-1213/services/http:proxy-service-75wlb:portname2/proxy/: bar (200; 8.199305ms)
Nov 22 18:05:29.078: INFO: (2) /api/v1/namespaces/proxy-1213/services/https:proxy-service-75wlb:tlsportname1/proxy/: tls baz (200; 9.1124ms)
Nov 22 18:05:29.078: INFO: (2) /api/v1/namespaces/proxy-1213/services/https:proxy-service-75wlb:tlsportname2/proxy/: tls qux (200; 7.850027ms)
Nov 22 18:05:29.081: INFO: (3) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:160/proxy/: foo (200; 2.354786ms)
Nov 22 18:05:29.081: INFO: (3) /api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:460/proxy/: tls baz (200; 3.130658ms)
Nov 22 18:05:29.083: INFO: (3) /api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:162/proxy/: bar (200; 4.284322ms)
Nov 22 18:05:29.083: INFO: (3) /api/v1/namespaces/proxy-1213/services/proxy-service-75wlb:portname2/proxy/: bar (200; 5.468835ms)
Nov 22 18:05:29.084: INFO: (3) /api/v1/namespaces/proxy-1213/services/https:proxy-service-75wlb:tlsportname2/proxy/: tls qux (200; 5.38953ms)
Nov 22 18:05:29.084: INFO: (3) /api/v1/namespaces/proxy-1213/services/proxy-service-75wlb:portname1/proxy/: foo (200; 4.679564ms)
Nov 22 18:05:29.085: INFO: (3) /api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:1080/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:1080/proxy/rewriteme">... (200; 3.722462ms)
Nov 22 18:05:29.085: INFO: (3) /api/v1/namespaces/proxy-1213/services/http:proxy-service-75wlb:portname1/proxy/: foo (200; 5.15435ms)
Nov 22 18:05:29.085: INFO: (3) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d/proxy/rewriteme">test</a> (200; 4.153772ms)
Nov 22 18:05:29.085: INFO: (3) /api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:160/proxy/: foo (200; 3.858359ms)
Nov 22 18:05:29.085: INFO: (3) /api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:443/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:443/proxy/tlsrewritem... (200; 4.025864ms)
Nov 22 18:05:29.086: INFO: (3) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:1080/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:1080/proxy/rewriteme">test<... (200; 3.282208ms)
Nov 22 18:05:29.086: INFO: (3) /api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:462/proxy/: tls qux (200; 6.997707ms)
Nov 22 18:05:29.087: INFO: (3) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:162/proxy/: bar (200; 4.764213ms)
Nov 22 18:05:29.087: INFO: (3) /api/v1/namespaces/proxy-1213/services/http:proxy-service-75wlb:portname2/proxy/: bar (200; 5.752841ms)
Nov 22 18:05:29.087: INFO: (3) /api/v1/namespaces/proxy-1213/services/https:proxy-service-75wlb:tlsportname1/proxy/: tls baz (200; 4.598844ms)
Nov 22 18:05:29.096: INFO: (4) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:1080/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:1080/proxy/rewriteme">test<... (200; 7.417838ms)
Nov 22 18:05:29.096: INFO: (4) /api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:162/proxy/: bar (200; 8.020949ms)
Nov 22 18:05:29.096: INFO: (4) /api/v1/namespaces/proxy-1213/services/proxy-service-75wlb:portname2/proxy/: bar (200; 7.105317ms)
Nov 22 18:05:29.096: INFO: (4) /api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:1080/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:1080/proxy/rewriteme">... (200; 6.874366ms)
Nov 22 18:05:29.096: INFO: (4) /api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:443/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:443/proxy/tlsrewritem... (200; 7.64349ms)
Nov 22 18:05:29.096: INFO: (4) /api/v1/namespaces/proxy-1213/services/http:proxy-service-75wlb:portname1/proxy/: foo (200; 7.121199ms)
Nov 22 18:05:29.096: INFO: (4) /api/v1/namespaces/proxy-1213/services/https:proxy-service-75wlb:tlsportname2/proxy/: tls qux (200; 7.407929ms)
Nov 22 18:05:29.096: INFO: (4) /api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:462/proxy/: tls qux (200; 7.278847ms)
Nov 22 18:05:29.096: INFO: (4) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d/proxy/rewriteme">test</a> (200; 7.57233ms)
Nov 22 18:05:29.096: INFO: (4) /api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:160/proxy/: foo (200; 7.062298ms)
Nov 22 18:05:29.096: INFO: (4) /api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:460/proxy/: tls baz (200; 6.87851ms)
Nov 22 18:05:29.096: INFO: (4) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:162/proxy/: bar (200; 6.96842ms)
Nov 22 18:05:29.096: INFO: (4) /api/v1/namespaces/proxy-1213/services/https:proxy-service-75wlb:tlsportname1/proxy/: tls baz (200; 7.162631ms)
Nov 22 18:05:29.096: INFO: (4) /api/v1/namespaces/proxy-1213/services/http:proxy-service-75wlb:portname2/proxy/: bar (200; 7.720656ms)
Nov 22 18:05:29.096: INFO: (4) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:160/proxy/: foo (200; 7.443794ms)
Nov 22 18:05:29.096: INFO: (4) /api/v1/namespaces/proxy-1213/services/proxy-service-75wlb:portname1/proxy/: foo (200; 8.46495ms)
Nov 22 18:05:29.098: INFO: (5) /api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:443/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:443/proxy/tlsrewritem... (200; 2.447615ms)
Nov 22 18:05:29.106: INFO: (5) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:1080/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:1080/proxy/rewriteme">test<... (200; 9.929948ms)
Nov 22 18:05:29.106: INFO: (5) /api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:160/proxy/: foo (200; 10.245943ms)
Nov 22 18:05:29.109: INFO: (5) /api/v1/namespaces/proxy-1213/services/https:proxy-service-75wlb:tlsportname1/proxy/: tls baz (200; 12.849547ms)
Nov 22 18:05:29.109: INFO: (5) /api/v1/namespaces/proxy-1213/services/http:proxy-service-75wlb:portname2/proxy/: bar (200; 13.248874ms)
Nov 22 18:05:29.109: INFO: (5) /api/v1/namespaces/proxy-1213/services/https:proxy-service-75wlb:tlsportname2/proxy/: tls qux (200; 13.368118ms)
Nov 22 18:05:29.109: INFO: (5) /api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:460/proxy/: tls baz (200; 13.30858ms)
Nov 22 18:05:29.109: INFO: (5) /api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:462/proxy/: tls qux (200; 13.043102ms)
Nov 22 18:05:29.109: INFO: (5) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:160/proxy/: foo (200; 13.137486ms)
Nov 22 18:05:29.110: INFO: (5) /api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:162/proxy/: bar (200; 12.990466ms)
Nov 22 18:05:29.110: INFO: (5) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:162/proxy/: bar (200; 13.465293ms)
Nov 22 18:05:29.110: INFO: (5) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d/proxy/rewriteme">test</a> (200; 13.430404ms)
Nov 22 18:05:29.110: INFO: (5) /api/v1/namespaces/proxy-1213/services/http:proxy-service-75wlb:portname1/proxy/: foo (200; 13.41439ms)
Nov 22 18:05:29.110: INFO: (5) /api/v1/namespaces/proxy-1213/services/proxy-service-75wlb:portname1/proxy/: foo (200; 13.348539ms)
Nov 22 18:05:29.110: INFO: (5) /api/v1/namespaces/proxy-1213/services/proxy-service-75wlb:portname2/proxy/: bar (200; 13.50505ms)
Nov 22 18:05:29.111: INFO: (5) /api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:1080/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:1080/proxy/rewriteme">... (200; 14.740261ms)
Nov 22 18:05:29.115: INFO: (6) /api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:1080/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:1080/proxy/rewriteme">... (200; 3.992336ms)
Nov 22 18:05:29.119: INFO: (6) /api/v1/namespaces/proxy-1213/services/https:proxy-service-75wlb:tlsportname2/proxy/: tls qux (200; 8.370192ms)
Nov 22 18:05:29.119: INFO: (6) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:1080/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:1080/proxy/rewriteme">test<... (200; 7.534498ms)
Nov 22 18:05:29.119: INFO: (6) /api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:162/proxy/: bar (200; 7.485747ms)
Nov 22 18:05:29.120: INFO: (6) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d/proxy/rewriteme">test</a> (200; 7.618836ms)
Nov 22 18:05:29.120: INFO: (6) /api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:462/proxy/: tls qux (200; 7.906107ms)
Nov 22 18:05:29.120: INFO: (6) /api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:460/proxy/: tls baz (200; 8.172344ms)
Nov 22 18:05:29.120: INFO: (6) /api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:160/proxy/: foo (200; 8.316876ms)
Nov 22 18:05:29.120: INFO: (6) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:162/proxy/: bar (200; 8.271919ms)
Nov 22 18:05:29.120: INFO: (6) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:160/proxy/: foo (200; 8.158937ms)
Nov 22 18:05:29.120: INFO: (6) /api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:443/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:443/proxy/tlsrewritem... (200; 8.630407ms)
Nov 22 18:05:29.122: INFO: (6) /api/v1/namespaces/proxy-1213/services/proxy-service-75wlb:portname1/proxy/: foo (200; 10.24533ms)
Nov 22 18:05:29.122: INFO: (6) /api/v1/namespaces/proxy-1213/services/http:proxy-service-75wlb:portname2/proxy/: bar (200; 9.938062ms)
Nov 22 18:05:29.122: INFO: (6) /api/v1/namespaces/proxy-1213/services/http:proxy-service-75wlb:portname1/proxy/: foo (200; 10.287547ms)
Nov 22 18:05:29.122: INFO: (6) /api/v1/namespaces/proxy-1213/services/proxy-service-75wlb:portname2/proxy/: bar (200; 10.077879ms)
Nov 22 18:05:29.123: INFO: (6) /api/v1/namespaces/proxy-1213/services/https:proxy-service-75wlb:tlsportname1/proxy/: tls baz (200; 10.960317ms)
Nov 22 18:05:29.133: INFO: (7) /api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:1080/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:1080/proxy/rewriteme">... (200; 9.535194ms)
Nov 22 18:05:29.133: INFO: (7) /api/v1/namespaces/proxy-1213/services/https:proxy-service-75wlb:tlsportname1/proxy/: tls baz (200; 10.105234ms)
Nov 22 18:05:29.133: INFO: (7) /api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:162/proxy/: bar (200; 9.896258ms)
Nov 22 18:05:29.133: INFO: (7) /api/v1/namespaces/proxy-1213/services/proxy-service-75wlb:portname2/proxy/: bar (200; 9.492261ms)
Nov 22 18:05:29.133: INFO: (7) /api/v1/namespaces/proxy-1213/services/https:proxy-service-75wlb:tlsportname2/proxy/: tls qux (200; 9.472776ms)
Nov 22 18:05:29.133: INFO: (7) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:160/proxy/: foo (200; 9.570689ms)
Nov 22 18:05:29.133: INFO: (7) /api/v1/namespaces/proxy-1213/services/http:proxy-service-75wlb:portname2/proxy/: bar (200; 9.729753ms)
Nov 22 18:05:29.133: INFO: (7) /api/v1/namespaces/proxy-1213/services/http:proxy-service-75wlb:portname1/proxy/: foo (200; 9.886864ms)
Nov 22 18:05:29.134: INFO: (7) /api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:460/proxy/: tls baz (200; 10.763025ms)
Nov 22 18:05:29.134: INFO: (7) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:1080/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:1080/proxy/rewriteme">test<... (200; 11.143088ms)
Nov 22 18:05:29.134: INFO: (7) /api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:443/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:443/proxy/tlsrewritem... (200; 10.890657ms)
Nov 22 18:05:29.134: INFO: (7) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:162/proxy/: bar (200; 10.689117ms)
Nov 22 18:05:29.134: INFO: (7) /api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:160/proxy/: foo (200; 10.730524ms)
Nov 22 18:05:29.134: INFO: (7) /api/v1/namespaces/proxy-1213/services/proxy-service-75wlb:portname1/proxy/: foo (200; 10.602723ms)
Nov 22 18:05:29.134: INFO: (7) /api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:462/proxy/: tls qux (200; 10.58955ms)
Nov 22 18:05:29.134: INFO: (7) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d/proxy/rewriteme">test</a> (200; 10.826305ms)
Nov 22 18:05:29.139: INFO: (8) /api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:1080/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:1080/proxy/rewriteme">... (200; 4.452704ms)
Nov 22 18:05:29.142: INFO: (8) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d/proxy/rewriteme">test</a> (200; 7.095702ms)
Nov 22 18:05:29.142: INFO: (8) /api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:443/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:443/proxy/tlsrewritem... (200; 7.188621ms)
Nov 22 18:05:29.142: INFO: (8) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:160/proxy/: foo (200; 7.115709ms)
Nov 22 18:05:29.142: INFO: (8) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:162/proxy/: bar (200; 7.219171ms)
Nov 22 18:05:29.142: INFO: (8) /api/v1/namespaces/proxy-1213/services/http:proxy-service-75wlb:portname1/proxy/: foo (200; 7.398381ms)
Nov 22 18:05:29.142: INFO: (8) /api/v1/namespaces/proxy-1213/services/https:proxy-service-75wlb:tlsportname2/proxy/: tls qux (200; 7.176104ms)
Nov 22 18:05:29.142: INFO: (8) /api/v1/namespaces/proxy-1213/services/http:proxy-service-75wlb:portname2/proxy/: bar (200; 7.241085ms)
Nov 22 18:05:29.142: INFO: (8) /api/v1/namespaces/proxy-1213/services/https:proxy-service-75wlb:tlsportname1/proxy/: tls baz (200; 7.366118ms)
Nov 22 18:05:29.142: INFO: (8) /api/v1/namespaces/proxy-1213/services/proxy-service-75wlb:portname1/proxy/: foo (200; 7.370587ms)
Nov 22 18:05:29.142: INFO: (8) /api/v1/namespaces/proxy-1213/services/proxy-service-75wlb:portname2/proxy/: bar (200; 8.012014ms)
Nov 22 18:05:29.142: INFO: (8) /api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:460/proxy/: tls baz (200; 7.372467ms)
Nov 22 18:05:29.142: INFO: (8) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:1080/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:1080/proxy/rewriteme">test<... (200; 7.553694ms)
Nov 22 18:05:29.142: INFO: (8) /api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:160/proxy/: foo (200; 7.486552ms)
Nov 22 18:05:29.142: INFO: (8) /api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:462/proxy/: tls qux (200; 7.245692ms)
Nov 22 18:05:29.142: INFO: (8) /api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:162/proxy/: bar (200; 7.650704ms)
Nov 22 18:05:29.145: INFO: (9) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:160/proxy/: foo (200; 2.456183ms)
Nov 22 18:05:29.146: INFO: (9) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:162/proxy/: bar (200; 3.376347ms)
Nov 22 18:05:29.146: INFO: (9) /api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:462/proxy/: tls qux (200; 2.768463ms)
Nov 22 18:05:29.150: INFO: (9) /api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:1080/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:1080/proxy/rewriteme">... (200; 5.605397ms)
Nov 22 18:05:29.150: INFO: (9) /api/v1/namespaces/proxy-1213/services/proxy-service-75wlb:portname2/proxy/: bar (200; 7.930122ms)
Nov 22 18:05:29.150: INFO: (9) /api/v1/namespaces/proxy-1213/services/https:proxy-service-75wlb:tlsportname2/proxy/: tls qux (200; 7.630074ms)
Nov 22 18:05:29.150: INFO: (9) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d/proxy/rewriteme">test</a> (200; 5.788348ms)
Nov 22 18:05:29.150: INFO: (9) /api/v1/namespaces/proxy-1213/services/http:proxy-service-75wlb:portname1/proxy/: foo (200; 5.936473ms)
Nov 22 18:05:29.150: INFO: (9) /api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:460/proxy/: tls baz (200; 5.79189ms)
Nov 22 18:05:29.150: INFO: (9) /api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:162/proxy/: bar (200; 5.867824ms)
Nov 22 18:05:29.150: INFO: (9) /api/v1/namespaces/proxy-1213/services/https:proxy-service-75wlb:tlsportname1/proxy/: tls baz (200; 5.941319ms)
Nov 22 18:05:29.150: INFO: (9) /api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:160/proxy/: foo (200; 5.718105ms)
Nov 22 18:05:29.150: INFO: (9) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:1080/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:1080/proxy/rewriteme">test<... (200; 5.937967ms)
Nov 22 18:05:29.151: INFO: (9) /api/v1/namespaces/proxy-1213/services/http:proxy-service-75wlb:portname2/proxy/: bar (200; 5.9078ms)
Nov 22 18:05:29.151: INFO: (9) /api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:443/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:443/proxy/tlsrewritem... (200; 6.419836ms)
Nov 22 18:05:29.151: INFO: (9) /api/v1/namespaces/proxy-1213/services/proxy-service-75wlb:portname1/proxy/: foo (200; 6.591841ms)
Nov 22 18:05:29.154: INFO: (10) /api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:162/proxy/: bar (200; 2.700469ms)
Nov 22 18:05:29.154: INFO: (10) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:160/proxy/: foo (200; 3.208912ms)
Nov 22 18:05:29.154: INFO: (10) /api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:462/proxy/: tls qux (200; 3.166409ms)
Nov 22 18:05:29.160: INFO: (10) /api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:160/proxy/: foo (200; 8.480422ms)
Nov 22 18:05:29.160: INFO: (10) /api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:460/proxy/: tls baz (200; 8.377782ms)
Nov 22 18:05:29.160: INFO: (10) /api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:1080/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:1080/proxy/rewriteme">... (200; 8.592474ms)
Nov 22 18:05:29.160: INFO: (10) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:1080/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:1080/proxy/rewriteme">test<... (200; 8.740246ms)
Nov 22 18:05:29.160: INFO: (10) /api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:443/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:443/proxy/tlsrewritem... (200; 8.86181ms)
Nov 22 18:05:29.160: INFO: (10) /api/v1/namespaces/proxy-1213/services/http:proxy-service-75wlb:portname2/proxy/: bar (200; 9.468579ms)
Nov 22 18:05:29.160: INFO: (10) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d/proxy/rewriteme">test</a> (200; 8.703558ms)
Nov 22 18:05:29.160: INFO: (10) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:162/proxy/: bar (200; 8.524163ms)
Nov 22 18:05:29.162: INFO: (10) /api/v1/namespaces/proxy-1213/services/https:proxy-service-75wlb:tlsportname2/proxy/: tls qux (200; 11.156619ms)
Nov 22 18:05:29.162: INFO: (10) /api/v1/namespaces/proxy-1213/services/http:proxy-service-75wlb:portname1/proxy/: foo (200; 10.90308ms)
Nov 22 18:05:29.162: INFO: (10) /api/v1/namespaces/proxy-1213/services/proxy-service-75wlb:portname1/proxy/: foo (200; 10.947458ms)
Nov 22 18:05:29.162: INFO: (10) /api/v1/namespaces/proxy-1213/services/proxy-service-75wlb:portname2/proxy/: bar (200; 11.150657ms)
Nov 22 18:05:29.162: INFO: (10) /api/v1/namespaces/proxy-1213/services/https:proxy-service-75wlb:tlsportname1/proxy/: tls baz (200; 11.041779ms)
Nov 22 18:05:29.165: INFO: (11) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:162/proxy/: bar (200; 2.442919ms)
Nov 22 18:05:29.165: INFO: (11) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:1080/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:1080/proxy/rewriteme">test<... (200; 2.343906ms)
Nov 22 18:05:29.169: INFO: (11) /api/v1/namespaces/proxy-1213/services/proxy-service-75wlb:portname2/proxy/: bar (200; 6.331893ms)
Nov 22 18:05:29.170: INFO: (11) /api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:1080/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:1080/proxy/rewriteme">... (200; 6.76395ms)
Nov 22 18:05:29.170: INFO: (11) /api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:160/proxy/: foo (200; 6.762275ms)
Nov 22 18:05:29.170: INFO: (11) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d/proxy/rewriteme">test</a> (200; 6.943589ms)
Nov 22 18:05:29.170: INFO: (11) /api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:162/proxy/: bar (200; 7.318831ms)
Nov 22 18:05:29.170: INFO: (11) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:160/proxy/: foo (200; 6.795923ms)
Nov 22 18:05:29.170: INFO: (11) /api/v1/namespaces/proxy-1213/services/https:proxy-service-75wlb:tlsportname2/proxy/: tls qux (200; 6.675924ms)
Nov 22 18:05:29.170: INFO: (11) /api/v1/namespaces/proxy-1213/services/proxy-service-75wlb:portname1/proxy/: foo (200; 6.631058ms)
Nov 22 18:05:29.170: INFO: (11) /api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:462/proxy/: tls qux (200; 6.626205ms)
Nov 22 18:05:29.170: INFO: (11) /api/v1/namespaces/proxy-1213/services/https:proxy-service-75wlb:tlsportname1/proxy/: tls baz (200; 7.758111ms)
Nov 22 18:05:29.170: INFO: (11) /api/v1/namespaces/proxy-1213/services/http:proxy-service-75wlb:portname2/proxy/: bar (200; 7.226611ms)
Nov 22 18:05:29.170: INFO: (11) /api/v1/namespaces/proxy-1213/services/http:proxy-service-75wlb:portname1/proxy/: foo (200; 6.626408ms)
Nov 22 18:05:29.170: INFO: (11) /api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:443/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:443/proxy/tlsrewritem... (200; 7.298935ms)
Nov 22 18:05:29.170: INFO: (11) /api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:460/proxy/: tls baz (200; 7.045445ms)
Nov 22 18:05:29.178: INFO: (12) /api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:443/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:443/proxy/tlsrewritem... (200; 7.332389ms)
Nov 22 18:05:29.178: INFO: (12) /api/v1/namespaces/proxy-1213/services/https:proxy-service-75wlb:tlsportname2/proxy/: tls qux (200; 6.844355ms)
Nov 22 18:05:29.178: INFO: (12) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:1080/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:1080/proxy/rewriteme">test<... (200; 7.31025ms)
Nov 22 18:05:29.178: INFO: (12) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:162/proxy/: bar (200; 7.054178ms)
Nov 22 18:05:29.178: INFO: (12) /api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:162/proxy/: bar (200; 7.453967ms)
Nov 22 18:05:29.178: INFO: (12) /api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:462/proxy/: tls qux (200; 6.820126ms)
Nov 22 18:05:29.178: INFO: (12) /api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:160/proxy/: foo (200; 7.142013ms)
Nov 22 18:05:29.178: INFO: (12) /api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:1080/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:1080/proxy/rewriteme">... (200; 7.227917ms)
Nov 22 18:05:29.178: INFO: (12) /api/v1/namespaces/proxy-1213/services/http:proxy-service-75wlb:portname2/proxy/: bar (200; 7.757153ms)
Nov 22 18:05:29.178: INFO: (12) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d/proxy/rewriteme">test</a> (200; 7.305096ms)
Nov 22 18:05:29.178: INFO: (12) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:160/proxy/: foo (200; 6.986868ms)
Nov 22 18:05:29.178: INFO: (12) /api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:460/proxy/: tls baz (200; 7.067243ms)
Nov 22 18:05:29.178: INFO: (12) /api/v1/namespaces/proxy-1213/services/https:proxy-service-75wlb:tlsportname1/proxy/: tls baz (200; 7.690235ms)
Nov 22 18:05:29.178: INFO: (12) /api/v1/namespaces/proxy-1213/services/proxy-service-75wlb:portname1/proxy/: foo (200; 7.618175ms)
Nov 22 18:05:29.178: INFO: (12) /api/v1/namespaces/proxy-1213/services/proxy-service-75wlb:portname2/proxy/: bar (200; 7.022924ms)
Nov 22 18:05:29.181: INFO: (12) /api/v1/namespaces/proxy-1213/services/http:proxy-service-75wlb:portname1/proxy/: foo (200; 10.408713ms)
Nov 22 18:05:29.186: INFO: (13) /api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:443/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:443/proxy/tlsrewritem... (200; 5.105524ms)
Nov 22 18:05:29.186: INFO: (13) /api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:162/proxy/: bar (200; 4.132066ms)
Nov 22 18:05:29.186: INFO: (13) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:1080/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:1080/proxy/rewriteme">test<... (200; 4.220338ms)
Nov 22 18:05:29.186: INFO: (13) /api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:460/proxy/: tls baz (200; 5.12948ms)
Nov 22 18:05:29.186: INFO: (13) /api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:462/proxy/: tls qux (200; 4.945811ms)
Nov 22 18:05:29.187: INFO: (13) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:160/proxy/: foo (200; 5.354422ms)
Nov 22 18:05:29.187: INFO: (13) /api/v1/namespaces/proxy-1213/services/http:proxy-service-75wlb:portname2/proxy/: bar (200; 5.846891ms)
Nov 22 18:05:29.188: INFO: (13) /api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:160/proxy/: foo (200; 6.701587ms)
Nov 22 18:05:29.188: INFO: (13) /api/v1/namespaces/proxy-1213/services/http:proxy-service-75wlb:portname1/proxy/: foo (200; 6.233452ms)
Nov 22 18:05:29.188: INFO: (13) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:162/proxy/: bar (200; 6.668749ms)
Nov 22 18:05:29.188: INFO: (13) /api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:1080/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:1080/proxy/rewriteme">... (200; 6.799848ms)
Nov 22 18:05:29.188: INFO: (13) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d/proxy/rewriteme">test</a> (200; 6.884579ms)
Nov 22 18:05:29.189: INFO: (13) /api/v1/namespaces/proxy-1213/services/proxy-service-75wlb:portname1/proxy/: foo (200; 7.526048ms)
Nov 22 18:05:29.190: INFO: (13) /api/v1/namespaces/proxy-1213/services/https:proxy-service-75wlb:tlsportname1/proxy/: tls baz (200; 8.205874ms)
Nov 22 18:05:29.190: INFO: (13) /api/v1/namespaces/proxy-1213/services/proxy-service-75wlb:portname2/proxy/: bar (200; 8.898535ms)
Nov 22 18:05:29.190: INFO: (13) /api/v1/namespaces/proxy-1213/services/https:proxy-service-75wlb:tlsportname2/proxy/: tls qux (200; 8.914742ms)
Nov 22 18:05:29.193: INFO: (14) /api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:443/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:443/proxy/tlsrewritem... (200; 2.722397ms)
Nov 22 18:05:29.195: INFO: (14) /api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:462/proxy/: tls qux (200; 4.07178ms)
Nov 22 18:05:29.195: INFO: (14) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:1080/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:1080/proxy/rewriteme">test<... (200; 3.766042ms)
Nov 22 18:05:29.195: INFO: (14) /api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:1080/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:1080/proxy/rewriteme">... (200; 3.339125ms)
Nov 22 18:05:29.195: INFO: (14) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d/proxy/rewriteme">test</a> (200; 3.647192ms)
Nov 22 18:05:29.195: INFO: (14) /api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:160/proxy/: foo (200; 3.426163ms)
Nov 22 18:05:29.195: INFO: (14) /api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:460/proxy/: tls baz (200; 3.601798ms)
Nov 22 18:05:29.195: INFO: (14) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:160/proxy/: foo (200; 4.507412ms)
Nov 22 18:05:29.196: INFO: (14) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:162/proxy/: bar (200; 5.921368ms)
Nov 22 18:05:29.196: INFO: (14) /api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:162/proxy/: bar (200; 4.12606ms)
Nov 22 18:05:29.196: INFO: (14) /api/v1/namespaces/proxy-1213/services/proxy-service-75wlb:portname1/proxy/: foo (200; 4.830305ms)
Nov 22 18:05:29.197: INFO: (14) /api/v1/namespaces/proxy-1213/services/proxy-service-75wlb:portname2/proxy/: bar (200; 5.277175ms)
Nov 22 18:05:29.198: INFO: (14) /api/v1/namespaces/proxy-1213/services/http:proxy-service-75wlb:portname1/proxy/: foo (200; 7.067404ms)
Nov 22 18:05:29.198: INFO: (14) /api/v1/namespaces/proxy-1213/services/https:proxy-service-75wlb:tlsportname1/proxy/: tls baz (200; 6.214493ms)
Nov 22 18:05:29.198: INFO: (14) /api/v1/namespaces/proxy-1213/services/http:proxy-service-75wlb:portname2/proxy/: bar (200; 6.003528ms)
Nov 22 18:05:29.199: INFO: (14) /api/v1/namespaces/proxy-1213/services/https:proxy-service-75wlb:tlsportname2/proxy/: tls qux (200; 8.55864ms)
Nov 22 18:05:29.206: INFO: (15) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:160/proxy/: foo (200; 6.406444ms)
Nov 22 18:05:29.206: INFO: (15) /api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:1080/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:1080/proxy/rewriteme">... (200; 6.818442ms)
Nov 22 18:05:29.207: INFO: (15) /api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:460/proxy/: tls baz (200; 6.639821ms)
Nov 22 18:05:29.207: INFO: (15) /api/v1/namespaces/proxy-1213/services/http:proxy-service-75wlb:portname1/proxy/: foo (200; 7.299707ms)
Nov 22 18:05:29.207: INFO: (15) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d/proxy/rewriteme">test</a> (200; 6.932728ms)
Nov 22 18:05:29.207: INFO: (15) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:162/proxy/: bar (200; 6.75467ms)
Nov 22 18:05:29.207: INFO: (15) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:1080/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:1080/proxy/rewriteme">test<... (200; 7.265977ms)
Nov 22 18:05:29.207: INFO: (15) /api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:162/proxy/: bar (200; 7.217936ms)
Nov 22 18:05:29.207: INFO: (15) /api/v1/namespaces/proxy-1213/services/proxy-service-75wlb:portname1/proxy/: foo (200; 7.694401ms)
Nov 22 18:05:29.207: INFO: (15) /api/v1/namespaces/proxy-1213/services/https:proxy-service-75wlb:tlsportname2/proxy/: tls qux (200; 6.869355ms)
Nov 22 18:05:29.207: INFO: (15) /api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:160/proxy/: foo (200; 7.237151ms)
Nov 22 18:05:29.207: INFO: (15) /api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:443/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:443/proxy/tlsrewritem... (200; 7.532203ms)
Nov 22 18:05:29.208: INFO: (15) /api/v1/namespaces/proxy-1213/services/http:proxy-service-75wlb:portname2/proxy/: bar (200; 8.183366ms)
Nov 22 18:05:29.208: INFO: (15) /api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:462/proxy/: tls qux (200; 8.81406ms)
Nov 22 18:05:29.209: INFO: (15) /api/v1/namespaces/proxy-1213/services/proxy-service-75wlb:portname2/proxy/: bar (200; 9.108743ms)
Nov 22 18:05:29.209: INFO: (15) /api/v1/namespaces/proxy-1213/services/https:proxy-service-75wlb:tlsportname1/proxy/: tls baz (200; 9.787913ms)
Nov 22 18:05:29.213: INFO: (16) /api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:462/proxy/: tls qux (200; 3.393065ms)
Nov 22 18:05:29.213: INFO: (16) /api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:160/proxy/: foo (200; 2.628426ms)
Nov 22 18:05:29.213: INFO: (16) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:160/proxy/: foo (200; 2.918935ms)
Nov 22 18:05:29.217: INFO: (16) /api/v1/namespaces/proxy-1213/services/proxy-service-75wlb:portname1/proxy/: foo (200; 7.416375ms)
Nov 22 18:05:29.217: INFO: (16) /api/v1/namespaces/proxy-1213/services/proxy-service-75wlb:portname2/proxy/: bar (200; 8.104772ms)
Nov 22 18:05:29.218: INFO: (16) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:1080/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:1080/proxy/rewriteme">test<... (200; 7.511349ms)
Nov 22 18:05:29.218: INFO: (16) /api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:162/proxy/: bar (200; 7.520327ms)
Nov 22 18:05:29.218: INFO: (16) /api/v1/namespaces/proxy-1213/services/http:proxy-service-75wlb:portname2/proxy/: bar (200; 7.316395ms)
Nov 22 18:05:29.218: INFO: (16) /api/v1/namespaces/proxy-1213/services/https:proxy-service-75wlb:tlsportname1/proxy/: tls baz (200; 8.62282ms)
Nov 22 18:05:29.218: INFO: (16) /api/v1/namespaces/proxy-1213/services/https:proxy-service-75wlb:tlsportname2/proxy/: tls qux (200; 8.426545ms)
Nov 22 18:05:29.218: INFO: (16) /api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:460/proxy/: tls baz (200; 7.590263ms)
Nov 22 18:05:29.218: INFO: (16) /api/v1/namespaces/proxy-1213/services/http:proxy-service-75wlb:portname1/proxy/: foo (200; 8.0842ms)
Nov 22 18:05:29.218: INFO: (16) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d/proxy/rewriteme">test</a> (200; 7.627077ms)
Nov 22 18:05:29.218: INFO: (16) /api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:443/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:443/proxy/tlsrewritem... (200; 7.899152ms)
Nov 22 18:05:29.218: INFO: (16) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:162/proxy/: bar (200; 7.795534ms)
Nov 22 18:05:29.218: INFO: (16) /api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:1080/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:1080/proxy/rewriteme">... (200; 9.076046ms)
Nov 22 18:05:29.222: INFO: (17) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:160/proxy/: foo (200; 3.585731ms)
Nov 22 18:05:29.225: INFO: (17) /api/v1/namespaces/proxy-1213/services/https:proxy-service-75wlb:tlsportname1/proxy/: tls baz (200; 6.342219ms)
Nov 22 18:05:29.225: INFO: (17) /api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:1080/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:1080/proxy/rewriteme">... (200; 5.848458ms)
Nov 22 18:05:29.225: INFO: (17) /api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:443/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:443/proxy/tlsrewritem... (200; 6.503933ms)
Nov 22 18:05:29.225: INFO: (17) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:1080/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:1080/proxy/rewriteme">test<... (200; 6.805236ms)
Nov 22 18:05:29.227: INFO: (17) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d/proxy/rewriteme">test</a> (200; 8.186145ms)
Nov 22 18:05:29.227: INFO: (17) /api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:160/proxy/: foo (200; 8.462742ms)
Nov 22 18:05:29.227: INFO: (17) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:162/proxy/: bar (200; 8.405831ms)
Nov 22 18:05:29.227: INFO: (17) /api/v1/namespaces/proxy-1213/services/http:proxy-service-75wlb:portname1/proxy/: foo (200; 9.046535ms)
Nov 22 18:05:29.227: INFO: (17) /api/v1/namespaces/proxy-1213/services/proxy-service-75wlb:portname2/proxy/: bar (200; 7.935847ms)
Nov 22 18:05:29.227: INFO: (17) /api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:460/proxy/: tls baz (200; 8.363961ms)
Nov 22 18:05:29.228: INFO: (17) /api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:462/proxy/: tls qux (200; 8.098162ms)
Nov 22 18:05:29.228: INFO: (17) /api/v1/namespaces/proxy-1213/services/http:proxy-service-75wlb:portname2/proxy/: bar (200; 8.424614ms)
Nov 22 18:05:29.228: INFO: (17) /api/v1/namespaces/proxy-1213/services/https:proxy-service-75wlb:tlsportname2/proxy/: tls qux (200; 7.911831ms)
Nov 22 18:05:29.228: INFO: (17) /api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:162/proxy/: bar (200; 8.879991ms)
Nov 22 18:05:29.228: INFO: (17) /api/v1/namespaces/proxy-1213/services/proxy-service-75wlb:portname1/proxy/: foo (200; 9.337698ms)
Nov 22 18:05:29.236: INFO: (18) /api/v1/namespaces/proxy-1213/services/https:proxy-service-75wlb:tlsportname1/proxy/: tls baz (200; 7.72208ms)
Nov 22 18:05:29.236: INFO: (18) /api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:462/proxy/: tls qux (200; 8.420661ms)
Nov 22 18:05:29.236: INFO: (18) /api/v1/namespaces/proxy-1213/services/https:proxy-service-75wlb:tlsportname2/proxy/: tls qux (200; 7.910799ms)
Nov 22 18:05:29.236: INFO: (18) /api/v1/namespaces/proxy-1213/services/proxy-service-75wlb:portname2/proxy/: bar (200; 7.975048ms)
Nov 22 18:05:29.236: INFO: (18) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:162/proxy/: bar (200; 7.934866ms)
Nov 22 18:05:29.236: INFO: (18) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:1080/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:1080/proxy/rewriteme">test<... (200; 7.880196ms)
Nov 22 18:05:29.236: INFO: (18) /api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:160/proxy/: foo (200; 7.917398ms)
Nov 22 18:05:29.236: INFO: (18) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d/proxy/rewriteme">test</a> (200; 7.943764ms)
Nov 22 18:05:29.236: INFO: (18) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:160/proxy/: foo (200; 7.891557ms)
Nov 22 18:05:29.240: INFO: (18) /api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:162/proxy/: bar (200; 11.333982ms)
Nov 22 18:05:29.240: INFO: (18) /api/v1/namespaces/proxy-1213/services/http:proxy-service-75wlb:portname1/proxy/: foo (200; 11.465699ms)
Nov 22 18:05:29.240: INFO: (18) /api/v1/namespaces/proxy-1213/services/http:proxy-service-75wlb:portname2/proxy/: bar (200; 11.324433ms)
Nov 22 18:05:29.240: INFO: (18) /api/v1/namespaces/proxy-1213/services/proxy-service-75wlb:portname1/proxy/: foo (200; 11.503383ms)
Nov 22 18:05:29.240: INFO: (18) /api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:460/proxy/: tls baz (200; 11.766656ms)
Nov 22 18:05:29.240: INFO: (18) /api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:443/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:443/proxy/tlsrewritem... (200; 11.77287ms)
Nov 22 18:05:29.240: INFO: (18) /api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:1080/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:1080/proxy/rewriteme">... (200; 11.936792ms)
Nov 22 18:05:29.244: INFO: (19) /api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:1080/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:1080/proxy/rewriteme">... (200; 3.635277ms)
Nov 22 18:05:29.244: INFO: (19) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:162/proxy/: bar (200; 4.057348ms)
Nov 22 18:05:29.244: INFO: (19) /api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:162/proxy/: bar (200; 4.306603ms)
Nov 22 18:05:29.245: INFO: (19) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:1080/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:1080/proxy/rewriteme">test<... (200; 4.191965ms)
Nov 22 18:05:29.245: INFO: (19) /api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:462/proxy/: tls qux (200; 4.389502ms)
Nov 22 18:05:29.245: INFO: (19) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d:160/proxy/: foo (200; 4.438295ms)
Nov 22 18:05:29.246: INFO: (19) /api/v1/namespaces/proxy-1213/pods/http:proxy-service-75wlb-86l6d:160/proxy/: foo (200; 5.426665ms)
Nov 22 18:05:29.246: INFO: (19) /api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:460/proxy/: tls baz (200; 5.443746ms)
Nov 22 18:05:29.246: INFO: (19) /api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:443/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/https:proxy-service-75wlb-86l6d:443/proxy/tlsrewritem... (200; 5.545753ms)
Nov 22 18:05:29.246: INFO: (19) /api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d/proxy/: <a href="/api/v1/namespaces/proxy-1213/pods/proxy-service-75wlb-86l6d/proxy/rewriteme">test</a> (200; 5.534192ms)
Nov 22 18:05:29.250: INFO: (19) /api/v1/namespaces/proxy-1213/services/proxy-service-75wlb:portname2/proxy/: bar (200; 9.399601ms)
Nov 22 18:05:29.250: INFO: (19) /api/v1/namespaces/proxy-1213/services/https:proxy-service-75wlb:tlsportname1/proxy/: tls baz (200; 9.197797ms)
Nov 22 18:05:29.250: INFO: (19) /api/v1/namespaces/proxy-1213/services/http:proxy-service-75wlb:portname1/proxy/: foo (200; 9.046742ms)
Nov 22 18:05:29.250: INFO: (19) /api/v1/namespaces/proxy-1213/services/proxy-service-75wlb:portname1/proxy/: foo (200; 9.23842ms)
Nov 22 18:05:29.250: INFO: (19) /api/v1/namespaces/proxy-1213/services/https:proxy-service-75wlb:tlsportname2/proxy/: tls qux (200; 10.016524ms)
Nov 22 18:05:29.250: INFO: (19) /api/v1/namespaces/proxy-1213/services/http:proxy-service-75wlb:portname2/proxy/: bar (200; 9.614984ms)
STEP: deleting ReplicationController proxy-service-75wlb in namespace proxy-1213, will wait for the garbage collector to delete the pods
Nov 22 18:05:29.306: INFO: Deleting ReplicationController proxy-service-75wlb took: 3.295719ms
Nov 22 18:05:29.406: INFO: Terminating ReplicationController proxy-service-75wlb pods took: 100.171734ms
[AfterEach] version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:05:31.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-1213" for this suite.
Nov 22 18:05:37.120: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:05:37.236: INFO: namespace proxy-1213 deletion completed in 6.127495514s

• [SLOW TEST:14.292 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:05:37.236: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Nov 22 18:05:37.266: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov 22 18:05:37.270: INFO: Waiting for terminating namespaces to be deleted...
Nov 22 18:05:37.272: INFO: 
Logging pods the kubelet thinks is on node minion before test
Nov 22 18:05:37.278: INFO: rook-ceph-operator-546844bb58-tn99w from rook-ceph-system started at 2019-11-22 15:22:18 +0000 UTC (1 container statuses recorded)
Nov 22 18:05:37.278: INFO: 	Container rook-ceph-operator ready: true, restart count 1
Nov 22 18:05:37.278: INFO: nodelocaldns-k6f7w from kube-system started at 2019-11-22 15:21:08 +0000 UTC (1 container statuses recorded)
Nov 22 18:05:37.278: INFO: 	Container node-cache ready: true, restart count 0
Nov 22 18:05:37.278: INFO: weave-scope-app-599d8c957d-jn8r9 from weave started at 2019-11-22 15:22:13 +0000 UTC (1 container statuses recorded)
Nov 22 18:05:37.278: INFO: 	Container app ready: true, restart count 0
Nov 22 18:05:37.278: INFO: kubernetes-dashboard-7c547b4c64-hvmms from kube-system started at 2019-11-22 15:21:09 +0000 UTC (1 container statuses recorded)
Nov 22 18:05:37.278: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Nov 22 18:05:37.278: INFO: kube-proxy-g8j8f from kube-system started at 2019-11-22 15:20:11 +0000 UTC (1 container statuses recorded)
Nov 22 18:05:37.278: INFO: 	Container kube-proxy ready: true, restart count 0
Nov 22 18:05:37.278: INFO: weave-net-jh7zq from kube-system started at 2019-11-22 15:20:33 +0000 UTC (2 container statuses recorded)
Nov 22 18:05:37.278: INFO: 	Container weave ready: true, restart count 0
Nov 22 18:05:37.278: INFO: 	Container weave-npc ready: true, restart count 0
Nov 22 18:05:37.278: INFO: coredns-74c9d4d795-9mn9q from kube-system started at 2019-11-22 15:21:08 +0000 UTC (1 container statuses recorded)
Nov 22 18:05:37.278: INFO: 	Container coredns ready: true, restart count 0
Nov 22 18:05:37.278: INFO: rook-discover-nr6bp from rook-ceph-system started at 2019-11-22 15:23:13 +0000 UTC (1 container statuses recorded)
Nov 22 18:05:37.278: INFO: 	Container rook-discover ready: true, restart count 0
Nov 22 18:05:37.278: INFO: sonobuoy from sonobuoy started at 2019-11-22 17:53:18 +0000 UTC (1 container statuses recorded)
Nov 22 18:05:37.278: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov 22 18:05:37.278: INFO: sonobuoy-systemd-logs-daemon-set-125c3bb177a94023-5h6ln from sonobuoy started at 2019-11-22 17:53:20 +0000 UTC (2 container statuses recorded)
Nov 22 18:05:37.278: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 22 18:05:37.278: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 22 18:05:37.278: INFO: nginx-proxy-minion from kube-system started at 2019-11-22 15:20:11 +0000 UTC (1 container statuses recorded)
Nov 22 18:05:37.278: INFO: 	Container nginx-proxy ready: true, restart count 0
Nov 22 18:05:37.278: INFO: rook-ceph-agent-7x8xt from rook-ceph-system started at 2019-11-22 15:23:13 +0000 UTC (1 container statuses recorded)
Nov 22 18:05:37.278: INFO: 	Container rook-ceph-agent ready: true, restart count 0
Nov 22 18:05:37.278: INFO: tiller-deploy-7b9579457f-nz8lg from kube-system started at 2019-11-22 15:21:20 +0000 UTC (1 container statuses recorded)
Nov 22 18:05:37.278: INFO: 	Container tiller ready: true, restart count 0
Nov 22 18:05:37.278: INFO: weave-scope-agent-hw2c7 from weave started at 2019-11-22 15:22:13 +0000 UTC (1 container statuses recorded)
Nov 22 18:05:37.278: INFO: 	Container agent ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15d98e3cfa3cf73e], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:05:38.295: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-9146" for this suite.
Nov 22 18:05:44.303: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:05:44.362: INFO: namespace sched-pred-9146 deletion completed in 6.064917652s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:7.126 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:05:44.362: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Nov 22 18:05:44.406: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"4b146ab1-abf9-40ad-9867-6a1fb43bbb6e", Controller:(*bool)(0xc002038526), BlockOwnerDeletion:(*bool)(0xc002038527)}}
Nov 22 18:05:44.419: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"b4ec7c1a-4fe7-428b-8b28-3ebfb0a24f05", Controller:(*bool)(0xc002969fc6), BlockOwnerDeletion:(*bool)(0xc002969fc7)}}
Nov 22 18:05:44.422: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"48c54aff-ec31-4810-993e-c6a631171517", Controller:(*bool)(0xc0026c9966), BlockOwnerDeletion:(*bool)(0xc0026c9967)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:05:49.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1503" for this suite.
Nov 22 18:05:55.443: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:05:55.508: INFO: namespace gc-1503 deletion completed in 6.070978368s

• [SLOW TEST:11.146 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:05:55.510: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Nov 22 18:05:55.539: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ef8b7561-0ff6-48a1-8e9a-5df8038b2ec7" in namespace "downward-api-2087" to be "success or failure"
Nov 22 18:05:55.541: INFO: Pod "downwardapi-volume-ef8b7561-0ff6-48a1-8e9a-5df8038b2ec7": Phase="Pending", Reason="", readiness=false. Elapsed: 1.639726ms
Nov 22 18:05:57.543: INFO: Pod "downwardapi-volume-ef8b7561-0ff6-48a1-8e9a-5df8038b2ec7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003712573s
Nov 22 18:05:59.545: INFO: Pod "downwardapi-volume-ef8b7561-0ff6-48a1-8e9a-5df8038b2ec7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00593326s
STEP: Saw pod success
Nov 22 18:05:59.545: INFO: Pod "downwardapi-volume-ef8b7561-0ff6-48a1-8e9a-5df8038b2ec7" satisfied condition "success or failure"
Nov 22 18:05:59.547: INFO: Trying to get logs from node minion pod downwardapi-volume-ef8b7561-0ff6-48a1-8e9a-5df8038b2ec7 container client-container: <nil>
STEP: delete the pod
Nov 22 18:05:59.690: INFO: Waiting for pod downwardapi-volume-ef8b7561-0ff6-48a1-8e9a-5df8038b2ec7 to disappear
Nov 22 18:05:59.695: INFO: Pod downwardapi-volume-ef8b7561-0ff6-48a1-8e9a-5df8038b2ec7 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:05:59.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2087" for this suite.
Nov 22 18:06:05.703: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:06:05.834: INFO: namespace downward-api-2087 deletion completed in 6.136654551s

• [SLOW TEST:10.324 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:06:05.835: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on node default medium
Nov 22 18:06:05.869: INFO: Waiting up to 5m0s for pod "pod-e7ca4683-9ba4-429d-96d4-0ff47f6c7bd6" in namespace "emptydir-733" to be "success or failure"
Nov 22 18:06:05.872: INFO: Pod "pod-e7ca4683-9ba4-429d-96d4-0ff47f6c7bd6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.091021ms
Nov 22 18:06:07.874: INFO: Pod "pod-e7ca4683-9ba4-429d-96d4-0ff47f6c7bd6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003982067s
Nov 22 18:06:09.876: INFO: Pod "pod-e7ca4683-9ba4-429d-96d4-0ff47f6c7bd6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.006095731s
STEP: Saw pod success
Nov 22 18:06:09.876: INFO: Pod "pod-e7ca4683-9ba4-429d-96d4-0ff47f6c7bd6" satisfied condition "success or failure"
Nov 22 18:06:09.877: INFO: Trying to get logs from node minion pod pod-e7ca4683-9ba4-429d-96d4-0ff47f6c7bd6 container test-container: <nil>
STEP: delete the pod
Nov 22 18:06:09.897: INFO: Waiting for pod pod-e7ca4683-9ba4-429d-96d4-0ff47f6c7bd6 to disappear
Nov 22 18:06:09.898: INFO: Pod pod-e7ca4683-9ba4-429d-96d4-0ff47f6c7bd6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:06:09.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-733" for this suite.
Nov 22 18:06:15.915: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:06:16.189: INFO: namespace emptydir-733 deletion completed in 6.280526086s

• [SLOW TEST:10.354 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:06:16.189: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-5d825e29-694e-45cf-9c0c-5faa4b6880e2
STEP: Creating a pod to test consume configMaps
Nov 22 18:06:16.319: INFO: Waiting up to 5m0s for pod "pod-configmaps-a037743f-d48f-4ab5-aa05-d80997f2e8fb" in namespace "configmap-3905" to be "success or failure"
Nov 22 18:06:16.321: INFO: Pod "pod-configmaps-a037743f-d48f-4ab5-aa05-d80997f2e8fb": Phase="Pending", Reason="", readiness=false. Elapsed: 1.533561ms
Nov 22 18:06:18.335: INFO: Pod "pod-configmaps-a037743f-d48f-4ab5-aa05-d80997f2e8fb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015949099s
STEP: Saw pod success
Nov 22 18:06:18.335: INFO: Pod "pod-configmaps-a037743f-d48f-4ab5-aa05-d80997f2e8fb" satisfied condition "success or failure"
Nov 22 18:06:18.337: INFO: Trying to get logs from node minion pod pod-configmaps-a037743f-d48f-4ab5-aa05-d80997f2e8fb container configmap-volume-test: <nil>
STEP: delete the pod
Nov 22 18:06:18.409: INFO: Waiting for pod pod-configmaps-a037743f-d48f-4ab5-aa05-d80997f2e8fb to disappear
Nov 22 18:06:18.414: INFO: Pod pod-configmaps-a037743f-d48f-4ab5-aa05-d80997f2e8fb no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:06:18.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3905" for this suite.
Nov 22 18:06:24.454: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:06:24.758: INFO: namespace configmap-3905 deletion completed in 6.328936248s

• [SLOW TEST:8.569 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:06:24.758: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Nov 22 18:06:28.955: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec pod-sharedvolume-e307ff0b-d74b-4d44-85b3-d501015b14f0 -c busybox-main-container --namespace=emptydir-6891 -- cat /usr/share/volumeshare/shareddata.txt'
Nov 22 18:06:29.449: INFO: stderr: ""
Nov 22 18:06:29.449: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:06:29.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6891" for this suite.
Nov 22 18:06:35.504: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:06:35.729: INFO: namespace emptydir-6891 deletion completed in 6.26485384s

• [SLOW TEST:10.971 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:06:35.729: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-6209
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Nov 22 18:06:35.854: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Nov 22 18:07:02.061: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.251.128.8:8080/dial?request=hostName&protocol=http&host=10.251.128.11&port=8080&tries=1'] Namespace:pod-network-test-6209 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 22 18:07:02.061: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
Nov 22 18:07:02.175: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:07:02.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-6209" for this suite.
Nov 22 18:07:26.212: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:07:26.530: INFO: namespace pod-network-test-6209 deletion completed in 24.351905428s

• [SLOW TEST:50.801 seconds]
[sig-network] Networking
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:07:26.530: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Nov 22 18:10:10.710: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 22 18:10:10.712: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 22 18:10:12.712: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 22 18:10:12.714: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 22 18:10:14.712: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 22 18:10:14.714: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 22 18:10:16.712: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 22 18:10:16.714: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 22 18:10:18.712: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 22 18:10:18.715: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 22 18:10:20.712: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 22 18:10:20.714: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 22 18:10:22.712: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 22 18:10:22.714: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 22 18:10:24.712: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 22 18:10:24.714: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 22 18:10:26.712: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 22 18:10:26.715: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 22 18:10:28.712: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 22 18:10:28.714: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 22 18:10:30.712: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 22 18:10:30.714: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 22 18:10:32.712: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 22 18:10:32.714: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 22 18:10:34.712: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 22 18:10:34.714: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 22 18:10:36.712: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 22 18:10:36.714: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 22 18:10:38.712: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 22 18:10:38.715: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 22 18:10:40.712: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 22 18:10:40.714: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 22 18:10:42.712: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 22 18:10:42.714: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 22 18:10:44.712: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 22 18:10:44.714: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 22 18:10:46.712: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 22 18:10:46.714: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 22 18:10:48.712: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 22 18:10:48.715: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 22 18:10:50.712: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 22 18:10:50.714: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 22 18:10:52.712: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 22 18:10:52.714: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 22 18:10:54.712: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 22 18:10:54.714: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 22 18:10:56.712: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 22 18:10:56.714: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 22 18:10:58.712: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 22 18:10:58.714: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 22 18:11:00.712: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 22 18:11:00.714: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 22 18:11:02.712: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 22 18:11:02.714: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 22 18:11:04.712: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 22 18:11:04.714: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 22 18:11:06.712: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 22 18:11:06.714: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 22 18:11:08.713: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 22 18:11:08.715: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 22 18:11:10.712: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 22 18:11:10.719: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 22 18:11:12.712: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 22 18:11:12.715: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 22 18:11:14.712: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 22 18:11:14.727: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 22 18:11:16.712: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 22 18:11:16.714: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 22 18:11:18.712: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 22 18:11:18.714: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 22 18:11:20.712: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 22 18:11:20.714: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 22 18:11:22.719: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 22 18:11:22.721: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 22 18:11:24.719: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 22 18:11:24.721: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 22 18:11:26.719: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 22 18:11:26.721: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 22 18:11:28.719: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 22 18:11:28.720: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 22 18:11:30.712: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 22 18:11:30.714: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 22 18:11:32.725: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 22 18:11:32.742: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 22 18:11:34.712: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 22 18:11:34.714: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 22 18:11:36.718: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 22 18:11:36.719: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 22 18:11:38.712: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 22 18:11:38.722: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 22 18:11:40.712: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 22 18:11:40.714: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 22 18:11:42.727: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 22 18:11:42.731: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 22 18:11:44.720: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 22 18:11:44.722: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 22 18:11:46.714: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 22 18:11:46.719: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 22 18:11:48.713: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 22 18:11:48.716: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 22 18:11:50.712: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 22 18:11:50.718: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 22 18:11:52.713: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 22 18:11:52.726: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 22 18:11:54.712: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 22 18:11:54.714: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 22 18:11:56.718: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 22 18:11:56.720: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 22 18:11:58.713: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 22 18:11:58.725: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 22 18:12:00.721: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 22 18:12:00.723: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 22 18:12:02.712: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 22 18:12:02.715: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 22 18:12:04.717: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 22 18:12:04.722: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:12:04.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-1302" for this suite.
Nov 22 18:12:28.774: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:12:29.159: INFO: namespace container-lifecycle-hook-1302 deletion completed in 24.432639323s

• [SLOW TEST:302.629 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:12:29.160: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Nov 22 18:12:29.216: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:12:32.424: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-7874" for this suite.
Nov 22 18:12:38.448: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:12:38.771: INFO: namespace init-container-7874 deletion completed in 6.344907453s

• [SLOW TEST:9.612 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:12:38.771: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Nov 22 18:12:40.998: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:12:41.060: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-2936" for this suite.
Nov 22 18:12:47.085: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:12:47.396: INFO: namespace container-runtime-2936 deletion completed in 6.328875596s

• [SLOW TEST:8.625 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:12:47.396: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Nov 22 18:12:47.545: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Nov 22 18:12:47.549: INFO: Pod name sample-pod: Found 0 pods out of 1
Nov 22 18:12:52.566: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Nov 22 18:12:52.566: INFO: Creating deployment "test-rolling-update-deployment"
Nov 22 18:12:52.568: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Nov 22 18:12:52.599: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Nov 22 18:12:54.609: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Nov 22 18:12:54.623: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Nov 22 18:12:54.635: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-3632,SelfLink:/apis/apps/v1/namespaces/deployment-3632/deployments/test-rolling-update-deployment,UID:b5422fc9-bd17-40e9-adf9-4b555787378f,ResourceVersion:38961,Generation:1,CreationTimestamp:2019-11-22 18:12:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-11-22 18:12:52 +0000 UTC 2019-11-22 18:12:52 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-11-22 18:12:54 +0000 UTC 2019-11-22 18:12:52 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-79f6b9d75c" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Nov 22 18:12:54.637: INFO: New ReplicaSet "test-rolling-update-deployment-79f6b9d75c" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79f6b9d75c,GenerateName:,Namespace:deployment-3632,SelfLink:/apis/apps/v1/namespaces/deployment-3632/replicasets/test-rolling-update-deployment-79f6b9d75c,UID:cf93b936-73ec-4b53-a878-ccd5b63bf286,ResourceVersion:38948,Generation:1,CreationTimestamp:2019-11-22 18:12:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment b5422fc9-bd17-40e9-adf9-4b555787378f 0xc0019b0327 0xc0019b0328}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Nov 22 18:12:54.637: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Nov 22 18:12:54.637: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-3632,SelfLink:/apis/apps/v1/namespaces/deployment-3632/replicasets/test-rolling-update-controller,UID:4b05d7bf-6950-4fe9-906b-70659c9295e8,ResourceVersion:38960,Generation:2,CreationTimestamp:2019-11-22 18:12:47 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment b5422fc9-bd17-40e9-adf9-4b555787378f 0xc0019b01c7 0xc0019b01c8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Nov 22 18:12:54.652: INFO: Pod "test-rolling-update-deployment-79f6b9d75c-7k7wd" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79f6b9d75c-7k7wd,GenerateName:test-rolling-update-deployment-79f6b9d75c-,Namespace:deployment-3632,SelfLink:/api/v1/namespaces/deployment-3632/pods/test-rolling-update-deployment-79f6b9d75c-7k7wd,UID:15c0c0d5-e03e-48e6-8a51-3a0906baa717,ResourceVersion:38947,Generation:0,CreationTimestamp:2019-11-22 18:12:52 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-79f6b9d75c cf93b936-73ec-4b53-a878-ccd5b63bf286 0xc0016cf357 0xc0016cf358}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-2s8zr {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-2s8zr,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-2s8zr true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0016cf450} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0016cf470}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:12:52 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:12:54 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:12:54 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:12:52 +0000 UTC  }],Message:,Reason:,HostIP:172.31.44.47,PodIP:10.251.128.9,StartTime:2019-11-22 18:12:52 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-11-22 18:12:54 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://37f38c8e46788541025e7d6ee6c8c04db9cd48e951ac4328c9ab549fa2316ff0}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:12:54.652: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3632" for this suite.
Nov 22 18:13:00.687: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:13:01.103: INFO: namespace deployment-3632 deletion completed in 6.44864741s

• [SLOW TEST:13.707 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:13:01.103: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Nov 22 18:13:11.331: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
	[quantile=0.5] = 10
	[quantile=0.9] = 6777
	[quantile=0.99] = 9137
For garbage_collector_attempt_to_delete_work_duration:
	[quantile=0.5] = 7874
	[quantile=0.9] = 594534
	[quantile=0.99] = 595249
For garbage_collector_attempt_to_orphan_queue_latency:
	[quantile=0.5] = NaN
	[quantile=0.9] = NaN
	[quantile=0.99] = NaN
For garbage_collector_attempt_to_orphan_work_duration:
	[quantile=0.5] = NaN
	[quantile=0.9] = NaN
	[quantile=0.99] = NaN
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
	[quantile=0.5] = 5
	[quantile=0.9] = 6
	[quantile=0.99] = 23
For garbage_collector_graph_changes_work_duration:
	[quantile=0.5] = 14
	[quantile=0.9] = 24
	[quantile=0.99] = 61
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
	[quantile=0.5] = 11
	[quantile=0.9] = 19
	[quantile=0.99] = 21
For namespace_queue_latency_sum:
	[] = 5699
For namespace_queue_latency_count:
	[] = 419
For namespace_retries:
	[] = 428
For namespace_work_duration:
	[quantile=0.5] = 560752
	[quantile=0.9] = 929699
	[quantile=0.99] = 988297
For namespace_work_duration_sum:
	[] = 144204097
For namespace_work_duration_count:
	[] = 419
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:13:11.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1861" for this suite.
Nov 22 18:13:17.351: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:13:17.596: INFO: namespace gc-1861 deletion completed in 6.259820334s

• [SLOW TEST:16.494 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:13:17.597: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Nov 22 18:13:17.673: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov 22 18:13:17.691: INFO: Waiting for terminating namespaces to be deleted...
Nov 22 18:13:17.705: INFO: 
Logging pods the kubelet thinks is on node minion before test
Nov 22 18:13:17.723: INFO: nodelocaldns-k6f7w from kube-system started at 2019-11-22 15:21:08 +0000 UTC (1 container statuses recorded)
Nov 22 18:13:17.724: INFO: 	Container node-cache ready: true, restart count 0
Nov 22 18:13:17.724: INFO: weave-scope-app-599d8c957d-jn8r9 from weave started at 2019-11-22 15:22:13 +0000 UTC (1 container statuses recorded)
Nov 22 18:13:17.724: INFO: 	Container app ready: true, restart count 0
Nov 22 18:13:17.724: INFO: rook-ceph-operator-546844bb58-tn99w from rook-ceph-system started at 2019-11-22 15:22:18 +0000 UTC (1 container statuses recorded)
Nov 22 18:13:17.724: INFO: 	Container rook-ceph-operator ready: true, restart count 1
Nov 22 18:13:17.724: INFO: kube-proxy-g8j8f from kube-system started at 2019-11-22 15:20:11 +0000 UTC (1 container statuses recorded)
Nov 22 18:13:17.724: INFO: 	Container kube-proxy ready: true, restart count 0
Nov 22 18:13:17.724: INFO: weave-net-jh7zq from kube-system started at 2019-11-22 15:20:33 +0000 UTC (2 container statuses recorded)
Nov 22 18:13:17.724: INFO: 	Container weave ready: true, restart count 0
Nov 22 18:13:17.724: INFO: 	Container weave-npc ready: true, restart count 0
Nov 22 18:13:17.724: INFO: kubernetes-dashboard-7c547b4c64-hvmms from kube-system started at 2019-11-22 15:21:09 +0000 UTC (1 container statuses recorded)
Nov 22 18:13:17.724: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Nov 22 18:13:17.724: INFO: coredns-74c9d4d795-9mn9q from kube-system started at 2019-11-22 15:21:08 +0000 UTC (1 container statuses recorded)
Nov 22 18:13:17.724: INFO: 	Container coredns ready: true, restart count 0
Nov 22 18:13:17.724: INFO: rook-discover-nr6bp from rook-ceph-system started at 2019-11-22 15:23:13 +0000 UTC (1 container statuses recorded)
Nov 22 18:13:17.724: INFO: 	Container rook-discover ready: true, restart count 0
Nov 22 18:13:17.724: INFO: nginx-proxy-minion from kube-system started at 2019-11-22 15:20:11 +0000 UTC (1 container statuses recorded)
Nov 22 18:13:17.724: INFO: 	Container nginx-proxy ready: true, restart count 0
Nov 22 18:13:17.724: INFO: rook-ceph-agent-7x8xt from rook-ceph-system started at 2019-11-22 15:23:13 +0000 UTC (1 container statuses recorded)
Nov 22 18:13:17.724: INFO: 	Container rook-ceph-agent ready: true, restart count 0
Nov 22 18:13:17.724: INFO: sonobuoy from sonobuoy started at 2019-11-22 17:53:18 +0000 UTC (1 container statuses recorded)
Nov 22 18:13:17.724: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov 22 18:13:17.724: INFO: sonobuoy-systemd-logs-daemon-set-125c3bb177a94023-5h6ln from sonobuoy started at 2019-11-22 17:53:20 +0000 UTC (2 container statuses recorded)
Nov 22 18:13:17.724: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 22 18:13:17.724: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 22 18:13:17.724: INFO: tiller-deploy-7b9579457f-nz8lg from kube-system started at 2019-11-22 15:21:20 +0000 UTC (1 container statuses recorded)
Nov 22 18:13:17.724: INFO: 	Container tiller ready: true, restart count 0
Nov 22 18:13:17.724: INFO: weave-scope-agent-hw2c7 from weave started at 2019-11-22 15:22:13 +0000 UTC (1 container statuses recorded)
Nov 22 18:13:17.724: INFO: 	Container agent ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-a3a504a2-d3c7-4382-88c0-0e0702a9a3c0 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-a3a504a2-d3c7-4382-88c0-0e0702a9a3c0 off the node minion
STEP: verifying the node doesn't have the label kubernetes.io/e2e-a3a504a2-d3c7-4382-88c0-0e0702a9a3c0
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:13:21.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2311" for this suite.
Nov 22 18:13:29.946: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:13:30.269: INFO: namespace sched-pred-2311 deletion completed in 8.338671616s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:12.674 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:13:30.286: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test substitution in container's command
Nov 22 18:13:30.421: INFO: Waiting up to 5m0s for pod "var-expansion-a9d9d991-8062-46ec-ab7e-aa3fff4a8dc4" in namespace "var-expansion-756" to be "success or failure"
Nov 22 18:13:30.427: INFO: Pod "var-expansion-a9d9d991-8062-46ec-ab7e-aa3fff4a8dc4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.003592ms
Nov 22 18:13:32.454: INFO: Pod "var-expansion-a9d9d991-8062-46ec-ab7e-aa3fff4a8dc4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.032847794s
STEP: Saw pod success
Nov 22 18:13:32.454: INFO: Pod "var-expansion-a9d9d991-8062-46ec-ab7e-aa3fff4a8dc4" satisfied condition "success or failure"
Nov 22 18:13:32.456: INFO: Trying to get logs from node minion pod var-expansion-a9d9d991-8062-46ec-ab7e-aa3fff4a8dc4 container dapi-container: <nil>
STEP: delete the pod
Nov 22 18:13:32.499: INFO: Waiting for pod var-expansion-a9d9d991-8062-46ec-ab7e-aa3fff4a8dc4 to disappear
Nov 22 18:13:32.500: INFO: Pod var-expansion-a9d9d991-8062-46ec-ab7e-aa3fff4a8dc4 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:13:32.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-756" for this suite.
Nov 22 18:13:38.579: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:13:38.857: INFO: namespace var-expansion-756 deletion completed in 6.327064495s

• [SLOW TEST:8.571 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:13:38.857: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Nov 22 18:13:38.969: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-5009,SelfLink:/api/v1/namespaces/watch-5009/configmaps/e2e-watch-test-configmap-a,UID:748a1c47-4d8f-4c74-9f16-62b08618380c,ResourceVersion:39225,Generation:0,CreationTimestamp:2019-11-22 18:13:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov 22 18:13:38.969: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-5009,SelfLink:/api/v1/namespaces/watch-5009/configmaps/e2e-watch-test-configmap-a,UID:748a1c47-4d8f-4c74-9f16-62b08618380c,ResourceVersion:39225,Generation:0,CreationTimestamp:2019-11-22 18:13:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Nov 22 18:13:48.995: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-5009,SelfLink:/api/v1/namespaces/watch-5009/configmaps/e2e-watch-test-configmap-a,UID:748a1c47-4d8f-4c74-9f16-62b08618380c,ResourceVersion:39251,Generation:0,CreationTimestamp:2019-11-22 18:13:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Nov 22 18:13:48.995: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-5009,SelfLink:/api/v1/namespaces/watch-5009/configmaps/e2e-watch-test-configmap-a,UID:748a1c47-4d8f-4c74-9f16-62b08618380c,ResourceVersion:39251,Generation:0,CreationTimestamp:2019-11-22 18:13:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Nov 22 18:13:58.999: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-5009,SelfLink:/api/v1/namespaces/watch-5009/configmaps/e2e-watch-test-configmap-a,UID:748a1c47-4d8f-4c74-9f16-62b08618380c,ResourceVersion:39277,Generation:0,CreationTimestamp:2019-11-22 18:13:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov 22 18:13:58.999: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-5009,SelfLink:/api/v1/namespaces/watch-5009/configmaps/e2e-watch-test-configmap-a,UID:748a1c47-4d8f-4c74-9f16-62b08618380c,ResourceVersion:39277,Generation:0,CreationTimestamp:2019-11-22 18:13:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Nov 22 18:14:09.004: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-5009,SelfLink:/api/v1/namespaces/watch-5009/configmaps/e2e-watch-test-configmap-a,UID:748a1c47-4d8f-4c74-9f16-62b08618380c,ResourceVersion:39303,Generation:0,CreationTimestamp:2019-11-22 18:13:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov 22 18:14:09.004: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-5009,SelfLink:/api/v1/namespaces/watch-5009/configmaps/e2e-watch-test-configmap-a,UID:748a1c47-4d8f-4c74-9f16-62b08618380c,ResourceVersion:39303,Generation:0,CreationTimestamp:2019-11-22 18:13:38 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Nov 22 18:14:19.025: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-5009,SelfLink:/api/v1/namespaces/watch-5009/configmaps/e2e-watch-test-configmap-b,UID:a2fa865d-8b6c-42b0-9511-0687bde9033b,ResourceVersion:39327,Generation:0,CreationTimestamp:2019-11-22 18:14:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov 22 18:14:19.026: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-5009,SelfLink:/api/v1/namespaces/watch-5009/configmaps/e2e-watch-test-configmap-b,UID:a2fa865d-8b6c-42b0-9511-0687bde9033b,ResourceVersion:39327,Generation:0,CreationTimestamp:2019-11-22 18:14:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Nov 22 18:14:29.052: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-5009,SelfLink:/api/v1/namespaces/watch-5009/configmaps/e2e-watch-test-configmap-b,UID:a2fa865d-8b6c-42b0-9511-0687bde9033b,ResourceVersion:39352,Generation:0,CreationTimestamp:2019-11-22 18:14:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov 22 18:14:29.052: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-5009,SelfLink:/api/v1/namespaces/watch-5009/configmaps/e2e-watch-test-configmap-b,UID:a2fa865d-8b6c-42b0-9511-0687bde9033b,ResourceVersion:39352,Generation:0,CreationTimestamp:2019-11-22 18:14:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:14:39.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-5009" for this suite.
Nov 22 18:14:45.092: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:14:45.412: INFO: namespace watch-5009 deletion completed in 6.337895728s

• [SLOW TEST:66.555 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:14:45.413: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap that has name configmap-test-emptyKey-09ac0801-f7a9-4568-8c61-0d4fea106870
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:14:45.483: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7801" for this suite.
Nov 22 18:14:51.516: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:14:52.032: INFO: namespace configmap-7801 deletion completed in 6.538176604s

• [SLOW TEST:6.619 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:14:52.032: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-map-e9bfed08-64e8-4cc1-bdc0-5e9e1d17c4d6
STEP: Creating a pod to test consume secrets
Nov 22 18:14:52.162: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e99541b4-ec92-4404-a82a-4534053fa3d6" in namespace "projected-2723" to be "success or failure"
Nov 22 18:14:52.164: INFO: Pod "pod-projected-secrets-e99541b4-ec92-4404-a82a-4534053fa3d6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.5344ms
Nov 22 18:14:54.166: INFO: Pod "pod-projected-secrets-e99541b4-ec92-4404-a82a-4534053fa3d6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00386366s
Nov 22 18:14:56.171: INFO: Pod "pod-projected-secrets-e99541b4-ec92-4404-a82a-4534053fa3d6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008749985s
STEP: Saw pod success
Nov 22 18:14:56.171: INFO: Pod "pod-projected-secrets-e99541b4-ec92-4404-a82a-4534053fa3d6" satisfied condition "success or failure"
Nov 22 18:14:56.172: INFO: Trying to get logs from node minion pod pod-projected-secrets-e99541b4-ec92-4404-a82a-4534053fa3d6 container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov 22 18:14:56.216: INFO: Waiting for pod pod-projected-secrets-e99541b4-ec92-4404-a82a-4534053fa3d6 to disappear
Nov 22 18:14:56.231: INFO: Pod pod-projected-secrets-e99541b4-ec92-4404-a82a-4534053fa3d6 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:14:56.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2723" for this suite.
Nov 22 18:15:02.263: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:15:02.527: INFO: namespace projected-2723 deletion completed in 6.294242429s

• [SLOW TEST:10.496 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:15:02.527: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting the proxy server
Nov 22 18:15:02.602: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-880417063 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:15:02.890: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5015" for this suite.
Nov 22 18:15:08.942: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:15:09.006: INFO: namespace kubectl-5015 deletion completed in 6.104372909s

• [SLOW TEST:6.479 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:15:09.008: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name s-test-opt-del-209a984b-50c3-4968-a69f-6c29df66c987
STEP: Creating secret with name s-test-opt-upd-2dde6934-c570-4c01-8f69-57add361b117
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-209a984b-50c3-4968-a69f-6c29df66c987
STEP: Updating secret s-test-opt-upd-2dde6934-c570-4c01-8f69-57add361b117
STEP: Creating secret with name s-test-opt-create-3960188b-249d-446a-8d17-4c1e1ffc3d76
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:16:39.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9170" for this suite.
Nov 22 18:17:03.636: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:17:04.040: INFO: namespace secrets-9170 deletion completed in 24.432111052s

• [SLOW TEST:115.032 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:17:04.041: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-37ae0397-63e1-4d37-a4bc-6097a20c1639
STEP: Creating a pod to test consume configMaps
Nov 22 18:17:04.182: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-1ccc397d-c51e-4b23-a1ae-d15af2eb15c7" in namespace "projected-3399" to be "success or failure"
Nov 22 18:17:04.197: INFO: Pod "pod-projected-configmaps-1ccc397d-c51e-4b23-a1ae-d15af2eb15c7": Phase="Pending", Reason="", readiness=false. Elapsed: 15.408918ms
Nov 22 18:17:06.204: INFO: Pod "pod-projected-configmaps-1ccc397d-c51e-4b23-a1ae-d15af2eb15c7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02246612s
STEP: Saw pod success
Nov 22 18:17:06.204: INFO: Pod "pod-projected-configmaps-1ccc397d-c51e-4b23-a1ae-d15af2eb15c7" satisfied condition "success or failure"
Nov 22 18:17:06.205: INFO: Trying to get logs from node minion pod pod-projected-configmaps-1ccc397d-c51e-4b23-a1ae-d15af2eb15c7 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov 22 18:17:06.251: INFO: Waiting for pod pod-projected-configmaps-1ccc397d-c51e-4b23-a1ae-d15af2eb15c7 to disappear
Nov 22 18:17:06.253: INFO: Pod pod-projected-configmaps-1ccc397d-c51e-4b23-a1ae-d15af2eb15c7 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:17:06.253: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3399" for this suite.
Nov 22 18:17:12.310: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:17:12.578: INFO: namespace projected-3399 deletion completed in 6.323237752s

• [SLOW TEST:8.537 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:17:12.578: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name cm-test-opt-del-eef5ac1d-870d-4bbc-9e42-80c5c62ccbc7
STEP: Creating configMap with name cm-test-opt-upd-e7e8ade3-ff8d-48e0-abfb-60e054b584a2
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-eef5ac1d-870d-4bbc-9e42-80c5c62ccbc7
STEP: Updating configmap cm-test-opt-upd-e7e8ade3-ff8d-48e0-abfb-60e054b584a2
STEP: Creating configMap with name cm-test-opt-create-39748546-c386-4336-8392-bfa0be04cea7
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:18:47.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7893" for this suite.
Nov 22 18:19:11.875: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:19:12.208: INFO: namespace configmap-7893 deletion completed in 24.40285818s

• [SLOW TEST:119.630 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:19:12.209: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating Redis RC
Nov 22 18:19:12.289: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 create -f - --namespace=kubectl-7041'
Nov 22 18:19:14.411: INFO: stderr: ""
Nov 22 18:19:14.411: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Nov 22 18:19:15.423: INFO: Selector matched 1 pods for map[app:redis]
Nov 22 18:19:15.423: INFO: Found 0 / 1
Nov 22 18:19:16.436: INFO: Selector matched 1 pods for map[app:redis]
Nov 22 18:19:16.436: INFO: Found 1 / 1
Nov 22 18:19:16.436: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Nov 22 18:19:16.438: INFO: Selector matched 1 pods for map[app:redis]
Nov 22 18:19:16.438: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Nov 22 18:19:16.438: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 patch pod redis-master-b2dc6 --namespace=kubectl-7041 -p {"metadata":{"annotations":{"x":"y"}}}'
Nov 22 18:19:16.827: INFO: stderr: ""
Nov 22 18:19:16.827: INFO: stdout: "pod/redis-master-b2dc6 patched\n"
STEP: checking annotations
Nov 22 18:19:16.829: INFO: Selector matched 1 pods for map[app:redis]
Nov 22 18:19:16.829: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:19:16.829: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7041" for this suite.
Nov 22 18:19:40.858: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:19:41.221: INFO: namespace kubectl-7041 deletion completed in 24.381902179s

• [SLOW TEST:29.013 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl patch
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:19:41.222: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on tmpfs
Nov 22 18:19:41.395: INFO: Waiting up to 5m0s for pod "pod-6bdd809b-d54e-4f13-8646-992d0f6b6a6c" in namespace "emptydir-8241" to be "success or failure"
Nov 22 18:19:41.412: INFO: Pod "pod-6bdd809b-d54e-4f13-8646-992d0f6b6a6c": Phase="Pending", Reason="", readiness=false. Elapsed: 16.180298ms
Nov 22 18:19:43.421: INFO: Pod "pod-6bdd809b-d54e-4f13-8646-992d0f6b6a6c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025176805s
Nov 22 18:19:45.431: INFO: Pod "pod-6bdd809b-d54e-4f13-8646-992d0f6b6a6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035635377s
STEP: Saw pod success
Nov 22 18:19:45.431: INFO: Pod "pod-6bdd809b-d54e-4f13-8646-992d0f6b6a6c" satisfied condition "success or failure"
Nov 22 18:19:45.433: INFO: Trying to get logs from node minion pod pod-6bdd809b-d54e-4f13-8646-992d0f6b6a6c container test-container: <nil>
STEP: delete the pod
Nov 22 18:19:45.461: INFO: Waiting for pod pod-6bdd809b-d54e-4f13-8646-992d0f6b6a6c to disappear
Nov 22 18:19:45.482: INFO: Pod pod-6bdd809b-d54e-4f13-8646-992d0f6b6a6c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:19:45.482: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8241" for this suite.
Nov 22 18:19:51.507: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:19:51.822: INFO: namespace emptydir-8241 deletion completed in 6.337067262s

• [SLOW TEST:10.600 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:19:51.822: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-map-62af7db5-9407-457f-8efd-b422e202b326
STEP: Creating a pod to test consume secrets
Nov 22 18:19:51.907: INFO: Waiting up to 5m0s for pod "pod-secrets-6ddf3208-6a58-46b0-954f-6645bba6538b" in namespace "secrets-5083" to be "success or failure"
Nov 22 18:19:51.932: INFO: Pod "pod-secrets-6ddf3208-6a58-46b0-954f-6645bba6538b": Phase="Pending", Reason="", readiness=false. Elapsed: 25.329768ms
Nov 22 18:19:53.938: INFO: Pod "pod-secrets-6ddf3208-6a58-46b0-954f-6645bba6538b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031080847s
Nov 22 18:19:55.941: INFO: Pod "pod-secrets-6ddf3208-6a58-46b0-954f-6645bba6538b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033541781s
STEP: Saw pod success
Nov 22 18:19:55.941: INFO: Pod "pod-secrets-6ddf3208-6a58-46b0-954f-6645bba6538b" satisfied condition "success or failure"
Nov 22 18:19:55.979: INFO: Trying to get logs from node minion pod pod-secrets-6ddf3208-6a58-46b0-954f-6645bba6538b container secret-volume-test: <nil>
STEP: delete the pod
Nov 22 18:19:56.021: INFO: Waiting for pod pod-secrets-6ddf3208-6a58-46b0-954f-6645bba6538b to disappear
Nov 22 18:19:56.026: INFO: Pod pod-secrets-6ddf3208-6a58-46b0-954f-6645bba6538b no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:19:56.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5083" for this suite.
Nov 22 18:20:02.059: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:20:02.342: INFO: namespace secrets-5083 deletion completed in 6.304311896s

• [SLOW TEST:10.520 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:20:02.355: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod liveness-b1380bf8-b649-4a2c-bc14-71cfabbdd5bd in namespace container-probe-6260
Nov 22 18:20:04.483: INFO: Started pod liveness-b1380bf8-b649-4a2c-bc14-71cfabbdd5bd in namespace container-probe-6260
STEP: checking the pod's current state and verifying that restartCount is present
Nov 22 18:20:04.484: INFO: Initial restart count of pod liveness-b1380bf8-b649-4a2c-bc14-71cfabbdd5bd is 0
Nov 22 18:20:28.527: INFO: Restart count of pod container-probe-6260/liveness-b1380bf8-b649-4a2c-bc14-71cfabbdd5bd is now 1 (24.043113915s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:20:28.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6260" for this suite.
Nov 22 18:20:34.548: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:20:34.638: INFO: namespace container-probe-6260 deletion completed in 6.096487374s

• [SLOW TEST:32.284 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:20:34.639: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-478fd157-6096-4898-98dc-ad54399b3ddf
STEP: Creating a pod to test consume configMaps
Nov 22 18:20:34.670: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c4a043ab-6251-45a7-a441-f35d260c193b" in namespace "projected-4345" to be "success or failure"
Nov 22 18:20:34.671: INFO: Pod "pod-projected-configmaps-c4a043ab-6251-45a7-a441-f35d260c193b": Phase="Pending", Reason="", readiness=false. Elapsed: 1.283299ms
Nov 22 18:20:36.674: INFO: Pod "pod-projected-configmaps-c4a043ab-6251-45a7-a441-f35d260c193b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003486627s
Nov 22 18:20:38.675: INFO: Pod "pod-projected-configmaps-c4a043ab-6251-45a7-a441-f35d260c193b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005415586s
STEP: Saw pod success
Nov 22 18:20:38.675: INFO: Pod "pod-projected-configmaps-c4a043ab-6251-45a7-a441-f35d260c193b" satisfied condition "success or failure"
Nov 22 18:20:38.677: INFO: Trying to get logs from node minion pod pod-projected-configmaps-c4a043ab-6251-45a7-a441-f35d260c193b container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov 22 18:20:38.690: INFO: Waiting for pod pod-projected-configmaps-c4a043ab-6251-45a7-a441-f35d260c193b to disappear
Nov 22 18:20:38.696: INFO: Pod pod-projected-configmaps-c4a043ab-6251-45a7-a441-f35d260c193b no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:20:38.696: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4345" for this suite.
Nov 22 18:20:44.704: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:20:44.839: INFO: namespace projected-4345 deletion completed in 6.140528631s

• [SLOW TEST:10.199 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:20:44.839: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap configmap-6892/configmap-test-945c70d4-a54f-473d-bcad-bbe3c819f109
STEP: Creating a pod to test consume configMaps
Nov 22 18:20:44.871: INFO: Waiting up to 5m0s for pod "pod-configmaps-20e23ca8-9c2d-4c0c-a93d-f37ddfca305b" in namespace "configmap-6892" to be "success or failure"
Nov 22 18:20:44.873: INFO: Pod "pod-configmaps-20e23ca8-9c2d-4c0c-a93d-f37ddfca305b": Phase="Pending", Reason="", readiness=false. Elapsed: 1.217675ms
Nov 22 18:20:46.874: INFO: Pod "pod-configmaps-20e23ca8-9c2d-4c0c-a93d-f37ddfca305b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003078623s
Nov 22 18:20:48.877: INFO: Pod "pod-configmaps-20e23ca8-9c2d-4c0c-a93d-f37ddfca305b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.005185396s
STEP: Saw pod success
Nov 22 18:20:48.877: INFO: Pod "pod-configmaps-20e23ca8-9c2d-4c0c-a93d-f37ddfca305b" satisfied condition "success or failure"
Nov 22 18:20:48.878: INFO: Trying to get logs from node minion pod pod-configmaps-20e23ca8-9c2d-4c0c-a93d-f37ddfca305b container env-test: <nil>
STEP: delete the pod
Nov 22 18:20:48.893: INFO: Waiting for pod pod-configmaps-20e23ca8-9c2d-4c0c-a93d-f37ddfca305b to disappear
Nov 22 18:20:48.899: INFO: Pod pod-configmaps-20e23ca8-9c2d-4c0c-a93d-f37ddfca305b no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:20:48.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6892" for this suite.
Nov 22 18:20:54.907: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:20:54.969: INFO: namespace configmap-6892 deletion completed in 6.068379604s

• [SLOW TEST:10.130 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:20:54.969: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename aggregator
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:76
Nov 22 18:20:54.991: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Registering the sample API server.
Nov 22 18:20:55.389: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Nov 22 18:21:02.636: INFO: Waited 5.193691277s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:67
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:21:03.189: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-8401" for this suite.
Nov 22 18:21:09.339: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:21:09.445: INFO: namespace aggregator-8401 deletion completed in 6.161615573s

• [SLOW TEST:14.475 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:21:09.445: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name projected-secret-test-7205caec-e03a-4045-bc58-b1fc1bb57ff3
STEP: Creating a pod to test consume secrets
Nov 22 18:21:09.493: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-924a099e-4608-432a-b4d3-d508e44ca224" in namespace "projected-9481" to be "success or failure"
Nov 22 18:21:09.498: INFO: Pod "pod-projected-secrets-924a099e-4608-432a-b4d3-d508e44ca224": Phase="Pending", Reason="", readiness=false. Elapsed: 4.671102ms
Nov 22 18:21:11.500: INFO: Pod "pod-projected-secrets-924a099e-4608-432a-b4d3-d508e44ca224": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006740592s
Nov 22 18:21:13.508: INFO: Pod "pod-projected-secrets-924a099e-4608-432a-b4d3-d508e44ca224": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014630656s
STEP: Saw pod success
Nov 22 18:21:13.508: INFO: Pod "pod-projected-secrets-924a099e-4608-432a-b4d3-d508e44ca224" satisfied condition "success or failure"
Nov 22 18:21:13.510: INFO: Trying to get logs from node minion pod pod-projected-secrets-924a099e-4608-432a-b4d3-d508e44ca224 container secret-volume-test: <nil>
STEP: delete the pod
Nov 22 18:21:13.534: INFO: Waiting for pod pod-projected-secrets-924a099e-4608-432a-b4d3-d508e44ca224 to disappear
Nov 22 18:21:13.563: INFO: Pod pod-projected-secrets-924a099e-4608-432a-b4d3-d508e44ca224 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:21:13.563: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9481" for this suite.
Nov 22 18:21:19.592: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:21:19.997: INFO: namespace projected-9481 deletion completed in 6.431570128s

• [SLOW TEST:10.552 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:21:19.997: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:22:20.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-175" for this suite.
Nov 22 18:22:44.159: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:22:44.385: INFO: namespace container-probe-175 deletion completed in 24.249314212s

• [SLOW TEST:84.388 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:22:44.386: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Nov 22 18:22:44.511: INFO: Waiting up to 5m0s for pod "downward-api-e76211d9-60b6-4fcf-804f-1f4d948542d6" in namespace "downward-api-3902" to be "success or failure"
Nov 22 18:22:44.538: INFO: Pod "downward-api-e76211d9-60b6-4fcf-804f-1f4d948542d6": Phase="Pending", Reason="", readiness=false. Elapsed: 26.952939ms
Nov 22 18:22:46.540: INFO: Pod "downward-api-e76211d9-60b6-4fcf-804f-1f4d948542d6": Phase="Running", Reason="", readiness=true. Elapsed: 2.029013597s
Nov 22 18:22:48.553: INFO: Pod "downward-api-e76211d9-60b6-4fcf-804f-1f4d948542d6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.04172495s
STEP: Saw pod success
Nov 22 18:22:48.553: INFO: Pod "downward-api-e76211d9-60b6-4fcf-804f-1f4d948542d6" satisfied condition "success or failure"
Nov 22 18:22:48.555: INFO: Trying to get logs from node minion pod downward-api-e76211d9-60b6-4fcf-804f-1f4d948542d6 container dapi-container: <nil>
STEP: delete the pod
Nov 22 18:22:48.605: INFO: Waiting for pod downward-api-e76211d9-60b6-4fcf-804f-1f4d948542d6 to disappear
Nov 22 18:22:48.614: INFO: Pod downward-api-e76211d9-60b6-4fcf-804f-1f4d948542d6 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:22:48.614: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3902" for this suite.
Nov 22 18:22:54.646: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:22:55.236: INFO: namespace downward-api-3902 deletion completed in 6.620744873s

• [SLOW TEST:10.850 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:22:55.237: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-49491d10-0992-48f0-93c5-b44486f15d5e
STEP: Creating a pod to test consume secrets
Nov 22 18:22:55.335: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ebfcb5b3-4f02-4276-9f30-f4a998b94032" in namespace "projected-8800" to be "success or failure"
Nov 22 18:22:55.341: INFO: Pod "pod-projected-secrets-ebfcb5b3-4f02-4276-9f30-f4a998b94032": Phase="Pending", Reason="", readiness=false. Elapsed: 5.310935ms
Nov 22 18:22:57.342: INFO: Pod "pod-projected-secrets-ebfcb5b3-4f02-4276-9f30-f4a998b94032": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006826935s
STEP: Saw pod success
Nov 22 18:22:57.342: INFO: Pod "pod-projected-secrets-ebfcb5b3-4f02-4276-9f30-f4a998b94032" satisfied condition "success or failure"
Nov 22 18:22:57.355: INFO: Trying to get logs from node minion pod pod-projected-secrets-ebfcb5b3-4f02-4276-9f30-f4a998b94032 container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov 22 18:22:57.396: INFO: Waiting for pod pod-projected-secrets-ebfcb5b3-4f02-4276-9f30-f4a998b94032 to disappear
Nov 22 18:22:57.440: INFO: Pod pod-projected-secrets-ebfcb5b3-4f02-4276-9f30-f4a998b94032 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:22:57.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8800" for this suite.
Nov 22 18:23:03.554: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:23:04.081: INFO: namespace projected-8800 deletion completed in 6.638485308s

• [SLOW TEST:8.844 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:23:04.081: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test substitution in container's args
Nov 22 18:23:04.174: INFO: Waiting up to 5m0s for pod "var-expansion-175d439c-e8f2-4e22-abc1-d7f0287abddc" in namespace "var-expansion-2" to be "success or failure"
Nov 22 18:23:04.191: INFO: Pod "var-expansion-175d439c-e8f2-4e22-abc1-d7f0287abddc": Phase="Pending", Reason="", readiness=false. Elapsed: 17.13316ms
Nov 22 18:23:06.194: INFO: Pod "var-expansion-175d439c-e8f2-4e22-abc1-d7f0287abddc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020258662s
Nov 22 18:23:08.203: INFO: Pod "var-expansion-175d439c-e8f2-4e22-abc1-d7f0287abddc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028725853s
STEP: Saw pod success
Nov 22 18:23:08.203: INFO: Pod "var-expansion-175d439c-e8f2-4e22-abc1-d7f0287abddc" satisfied condition "success or failure"
Nov 22 18:23:08.217: INFO: Trying to get logs from node minion pod var-expansion-175d439c-e8f2-4e22-abc1-d7f0287abddc container dapi-container: <nil>
STEP: delete the pod
Nov 22 18:23:08.261: INFO: Waiting for pod var-expansion-175d439c-e8f2-4e22-abc1-d7f0287abddc to disappear
Nov 22 18:23:08.278: INFO: Pod var-expansion-175d439c-e8f2-4e22-abc1-d7f0287abddc no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:23:08.278: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2" for this suite.
Nov 22 18:23:14.318: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:23:14.622: INFO: namespace var-expansion-2 deletion completed in 6.341840998s

• [SLOW TEST:10.541 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:23:14.622: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Nov 22 18:23:16.779: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-880417063 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Nov 22 18:23:22.156: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:23:22.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9393" for this suite.
Nov 22 18:23:28.208: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:23:28.529: INFO: namespace pods-9393 deletion completed in 6.357737181s

• [SLOW TEST:13.907 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be submitted and removed [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:23:28.529: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Nov 22 18:23:28.650: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Nov 22 18:23:37.756: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:23:37.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9547" for this suite.
Nov 22 18:23:43.807: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:23:44.040: INFO: namespace pods-9547 deletion completed in 6.264069459s

• [SLOW TEST:15.511 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:23:44.053: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir volume type on tmpfs
Nov 22 18:23:44.153: INFO: Waiting up to 5m0s for pod "pod-6a66c9db-67b9-4f35-8d8f-f1e51b01a867" in namespace "emptydir-9308" to be "success or failure"
Nov 22 18:23:44.177: INFO: Pod "pod-6a66c9db-67b9-4f35-8d8f-f1e51b01a867": Phase="Pending", Reason="", readiness=false. Elapsed: 24.483706ms
Nov 22 18:23:46.209: INFO: Pod "pod-6a66c9db-67b9-4f35-8d8f-f1e51b01a867": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.055990158s
STEP: Saw pod success
Nov 22 18:23:46.209: INFO: Pod "pod-6a66c9db-67b9-4f35-8d8f-f1e51b01a867" satisfied condition "success or failure"
Nov 22 18:23:46.211: INFO: Trying to get logs from node minion pod pod-6a66c9db-67b9-4f35-8d8f-f1e51b01a867 container test-container: <nil>
STEP: delete the pod
Nov 22 18:23:46.265: INFO: Waiting for pod pod-6a66c9db-67b9-4f35-8d8f-f1e51b01a867 to disappear
Nov 22 18:23:46.267: INFO: Pod pod-6a66c9db-67b9-4f35-8d8f-f1e51b01a867 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:23:46.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9308" for this suite.
Nov 22 18:23:52.301: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:23:52.570: INFO: namespace emptydir-9308 deletion completed in 6.301220512s

• [SLOW TEST:8.517 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:23:52.570: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Nov 22 18:23:53.171: INFO: Pod name wrapped-volume-race-c28248b5-5eb7-49b2-bfe6-e1e7d195981d: Found 0 pods out of 5
Nov 22 18:23:58.199: INFO: Pod name wrapped-volume-race-c28248b5-5eb7-49b2-bfe6-e1e7d195981d: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-c28248b5-5eb7-49b2-bfe6-e1e7d195981d in namespace emptydir-wrapper-224, will wait for the garbage collector to delete the pods
Nov 22 18:24:10.315: INFO: Deleting ReplicationController wrapped-volume-race-c28248b5-5eb7-49b2-bfe6-e1e7d195981d took: 17.838655ms
Nov 22 18:24:10.833: INFO: Terminating ReplicationController wrapped-volume-race-c28248b5-5eb7-49b2-bfe6-e1e7d195981d pods took: 517.891615ms
STEP: Creating RC which spawns configmap-volume pods
Nov 22 18:24:52.863: INFO: Pod name wrapped-volume-race-adc053e1-a5a8-4571-b591-7c2425823777: Found 0 pods out of 5
Nov 22 18:24:57.878: INFO: Pod name wrapped-volume-race-adc053e1-a5a8-4571-b591-7c2425823777: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-adc053e1-a5a8-4571-b591-7c2425823777 in namespace emptydir-wrapper-224, will wait for the garbage collector to delete the pods
Nov 22 18:25:07.989: INFO: Deleting ReplicationController wrapped-volume-race-adc053e1-a5a8-4571-b591-7c2425823777 took: 13.103458ms
Nov 22 18:25:08.497: INFO: Terminating ReplicationController wrapped-volume-race-adc053e1-a5a8-4571-b591-7c2425823777 pods took: 507.614657ms
STEP: Creating RC which spawns configmap-volume pods
Nov 22 18:25:52.807: INFO: Pod name wrapped-volume-race-d50bdac3-05de-4b2c-894b-c6135a8c0f9a: Found 0 pods out of 5
Nov 22 18:25:57.811: INFO: Pod name wrapped-volume-race-d50bdac3-05de-4b2c-894b-c6135a8c0f9a: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-d50bdac3-05de-4b2c-894b-c6135a8c0f9a in namespace emptydir-wrapper-224, will wait for the garbage collector to delete the pods
Nov 22 18:26:07.894: INFO: Deleting ReplicationController wrapped-volume-race-d50bdac3-05de-4b2c-894b-c6135a8c0f9a took: 4.582978ms
Nov 22 18:26:08.394: INFO: Terminating ReplicationController wrapped-volume-race-d50bdac3-05de-4b2c-894b-c6135a8c0f9a pods took: 500.323991ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:26:54.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-224" for this suite.
Nov 22 18:27:02.602: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:27:02.906: INFO: namespace emptydir-wrapper-224 deletion completed in 8.35036365s

• [SLOW TEST:190.336 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:27:02.906: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-85252cf6-1dbe-4560-a624-67ccac35c4d6
STEP: Creating a pod to test consume secrets
Nov 22 18:27:03.050: INFO: Waiting up to 5m0s for pod "pod-secrets-b7d0ae3f-286d-4a82-9c6a-457ece6c38a3" in namespace "secrets-3219" to be "success or failure"
Nov 22 18:27:03.052: INFO: Pod "pod-secrets-b7d0ae3f-286d-4a82-9c6a-457ece6c38a3": Phase="Pending", Reason="", readiness=false. Elapsed: 1.758448ms
Nov 22 18:27:05.060: INFO: Pod "pod-secrets-b7d0ae3f-286d-4a82-9c6a-457ece6c38a3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00977339s
Nov 22 18:27:07.076: INFO: Pod "pod-secrets-b7d0ae3f-286d-4a82-9c6a-457ece6c38a3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025709426s
STEP: Saw pod success
Nov 22 18:27:07.076: INFO: Pod "pod-secrets-b7d0ae3f-286d-4a82-9c6a-457ece6c38a3" satisfied condition "success or failure"
Nov 22 18:27:07.078: INFO: Trying to get logs from node minion pod pod-secrets-b7d0ae3f-286d-4a82-9c6a-457ece6c38a3 container secret-env-test: <nil>
STEP: delete the pod
Nov 22 18:27:07.125: INFO: Waiting for pod pod-secrets-b7d0ae3f-286d-4a82-9c6a-457ece6c38a3 to disappear
Nov 22 18:27:07.127: INFO: Pod pod-secrets-b7d0ae3f-286d-4a82-9c6a-457ece6c38a3 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:27:07.127: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3219" for this suite.
Nov 22 18:27:13.173: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:27:13.435: INFO: namespace secrets-3219 deletion completed in 6.29371916s

• [SLOW TEST:10.529 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:27:13.435: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-eba68438-e85f-43a4-8f86-2b0f99421c40
STEP: Creating a pod to test consume configMaps
Nov 22 18:27:13.526: INFO: Waiting up to 5m0s for pod "pod-configmaps-3e9f9086-dde6-4c5a-b6c4-e4b94788e74a" in namespace "configmap-7859" to be "success or failure"
Nov 22 18:27:13.547: INFO: Pod "pod-configmaps-3e9f9086-dde6-4c5a-b6c4-e4b94788e74a": Phase="Pending", Reason="", readiness=false. Elapsed: 21.153115ms
Nov 22 18:27:15.565: INFO: Pod "pod-configmaps-3e9f9086-dde6-4c5a-b6c4-e4b94788e74a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039631195s
Nov 22 18:27:17.567: INFO: Pod "pod-configmaps-3e9f9086-dde6-4c5a-b6c4-e4b94788e74a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.04170993s
STEP: Saw pod success
Nov 22 18:27:17.567: INFO: Pod "pod-configmaps-3e9f9086-dde6-4c5a-b6c4-e4b94788e74a" satisfied condition "success or failure"
Nov 22 18:27:17.569: INFO: Trying to get logs from node minion pod pod-configmaps-3e9f9086-dde6-4c5a-b6c4-e4b94788e74a container configmap-volume-test: <nil>
STEP: delete the pod
Nov 22 18:27:17.603: INFO: Waiting for pod pod-configmaps-3e9f9086-dde6-4c5a-b6c4-e4b94788e74a to disappear
Nov 22 18:27:17.618: INFO: Pod pod-configmaps-3e9f9086-dde6-4c5a-b6c4-e4b94788e74a no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:27:17.618: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7859" for this suite.
Nov 22 18:27:23.650: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:27:23.976: INFO: namespace configmap-7859 deletion completed in 6.356421133s

• [SLOW TEST:10.540 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:27:23.989: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-c661036b-2cd3-404a-be7a-24a0d9805e48
STEP: Creating a pod to test consume configMaps
Nov 22 18:27:24.095: INFO: Waiting up to 5m0s for pod "pod-configmaps-13e06cf6-702a-4c48-89d7-96351696ce8b" in namespace "configmap-1415" to be "success or failure"
Nov 22 18:27:24.098: INFO: Pod "pod-configmaps-13e06cf6-702a-4c48-89d7-96351696ce8b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.896447ms
Nov 22 18:27:26.116: INFO: Pod "pod-configmaps-13e06cf6-702a-4c48-89d7-96351696ce8b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020947316s
STEP: Saw pod success
Nov 22 18:27:26.116: INFO: Pod "pod-configmaps-13e06cf6-702a-4c48-89d7-96351696ce8b" satisfied condition "success or failure"
Nov 22 18:27:26.135: INFO: Trying to get logs from node minion pod pod-configmaps-13e06cf6-702a-4c48-89d7-96351696ce8b container configmap-volume-test: <nil>
STEP: delete the pod
Nov 22 18:27:26.170: INFO: Waiting for pod pod-configmaps-13e06cf6-702a-4c48-89d7-96351696ce8b to disappear
Nov 22 18:27:26.188: INFO: Pod pod-configmaps-13e06cf6-702a-4c48-89d7-96351696ce8b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:27:26.188: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1415" for this suite.
Nov 22 18:27:32.222: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:27:32.519: INFO: namespace configmap-1415 deletion completed in 6.316827893s

• [SLOW TEST:8.530 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:27:32.520: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Nov 22 18:27:32.669: INFO: Waiting up to 5m0s for pod "downwardapi-volume-361edc20-a7a8-4736-af1a-2c1569b7b793" in namespace "downward-api-8772" to be "success or failure"
Nov 22 18:27:32.707: INFO: Pod "downwardapi-volume-361edc20-a7a8-4736-af1a-2c1569b7b793": Phase="Pending", Reason="", readiness=false. Elapsed: 38.282198ms
Nov 22 18:27:34.719: INFO: Pod "downwardapi-volume-361edc20-a7a8-4736-af1a-2c1569b7b793": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.049592459s
STEP: Saw pod success
Nov 22 18:27:34.719: INFO: Pod "downwardapi-volume-361edc20-a7a8-4736-af1a-2c1569b7b793" satisfied condition "success or failure"
Nov 22 18:27:34.720: INFO: Trying to get logs from node minion pod downwardapi-volume-361edc20-a7a8-4736-af1a-2c1569b7b793 container client-container: <nil>
STEP: delete the pod
Nov 22 18:27:34.788: INFO: Waiting for pod downwardapi-volume-361edc20-a7a8-4736-af1a-2c1569b7b793 to disappear
Nov 22 18:27:34.789: INFO: Pod downwardapi-volume-361edc20-a7a8-4736-af1a-2c1569b7b793 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:27:34.789: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8772" for this suite.
Nov 22 18:27:40.844: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:27:41.056: INFO: namespace downward-api-8772 deletion completed in 6.252450746s

• [SLOW TEST:8.536 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:27:41.056: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Nov 22 18:27:41.196: INFO: Waiting up to 5m0s for pod "downward-api-134ce3d6-a591-428b-b187-ffe21b52b689" in namespace "downward-api-7505" to be "success or failure"
Nov 22 18:27:41.211: INFO: Pod "downward-api-134ce3d6-a591-428b-b187-ffe21b52b689": Phase="Pending", Reason="", readiness=false. Elapsed: 15.185564ms
Nov 22 18:27:43.229: INFO: Pod "downward-api-134ce3d6-a591-428b-b187-ffe21b52b689": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.033546592s
STEP: Saw pod success
Nov 22 18:27:43.229: INFO: Pod "downward-api-134ce3d6-a591-428b-b187-ffe21b52b689" satisfied condition "success or failure"
Nov 22 18:27:43.231: INFO: Trying to get logs from node minion pod downward-api-134ce3d6-a591-428b-b187-ffe21b52b689 container dapi-container: <nil>
STEP: delete the pod
Nov 22 18:27:43.275: INFO: Waiting for pod downward-api-134ce3d6-a591-428b-b187-ffe21b52b689 to disappear
Nov 22 18:27:43.288: INFO: Pod downward-api-134ce3d6-a591-428b-b187-ffe21b52b689 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:27:43.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7505" for this suite.
Nov 22 18:27:49.313: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:27:49.626: INFO: namespace downward-api-7505 deletion completed in 6.333559672s

• [SLOW TEST:8.570 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:27:49.627: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-d4d3b6f5-9fe9-47bc-94f3-ad90280af624
STEP: Creating a pod to test consume configMaps
Nov 22 18:27:49.750: INFO: Waiting up to 5m0s for pod "pod-configmaps-60e66db3-de32-4994-a882-6ba51f1ec78e" in namespace "configmap-3131" to be "success or failure"
Nov 22 18:27:49.761: INFO: Pod "pod-configmaps-60e66db3-de32-4994-a882-6ba51f1ec78e": Phase="Pending", Reason="", readiness=false. Elapsed: 10.928784ms
Nov 22 18:27:51.771: INFO: Pod "pod-configmaps-60e66db3-de32-4994-a882-6ba51f1ec78e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020071199s
STEP: Saw pod success
Nov 22 18:27:51.771: INFO: Pod "pod-configmaps-60e66db3-de32-4994-a882-6ba51f1ec78e" satisfied condition "success or failure"
Nov 22 18:27:51.772: INFO: Trying to get logs from node minion pod pod-configmaps-60e66db3-de32-4994-a882-6ba51f1ec78e container configmap-volume-test: <nil>
STEP: delete the pod
Nov 22 18:27:51.817: INFO: Waiting for pod pod-configmaps-60e66db3-de32-4994-a882-6ba51f1ec78e to disappear
Nov 22 18:27:51.827: INFO: Pod pod-configmaps-60e66db3-de32-4994-a882-6ba51f1ec78e no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:27:51.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3131" for this suite.
Nov 22 18:27:59.863: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:28:00.271: INFO: namespace configmap-3131 deletion completed in 8.441267679s

• [SLOW TEST:10.644 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:28:00.271: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test hostPath mode
Nov 22 18:28:00.383: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-9824" to be "success or failure"
Nov 22 18:28:00.394: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 11.369125ms
Nov 22 18:28:02.403: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019532473s
Nov 22 18:28:04.405: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021678839s
STEP: Saw pod success
Nov 22 18:28:04.405: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Nov 22 18:28:04.418: INFO: Trying to get logs from node minion pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Nov 22 18:28:04.467: INFO: Waiting for pod pod-host-path-test to disappear
Nov 22 18:28:04.493: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:28:04.493: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-9824" for this suite.
Nov 22 18:28:10.565: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:28:10.808: INFO: namespace hostpath-9824 deletion completed in 6.304019638s

• [SLOW TEST:10.537 seconds]
[sig-storage] HostPath
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:28:10.808: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Nov 22 18:28:10.894: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 create -f - --namespace=kubectl-3558'
Nov 22 18:28:11.934: INFO: stderr: ""
Nov 22 18:28:11.934: INFO: stdout: "replicationcontroller/redis-master created\n"
Nov 22 18:28:11.934: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 create -f - --namespace=kubectl-3558'
Nov 22 18:28:12.800: INFO: stderr: ""
Nov 22 18:28:12.800: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Nov 22 18:28:13.805: INFO: Selector matched 1 pods for map[app:redis]
Nov 22 18:28:13.805: INFO: Found 0 / 1
Nov 22 18:28:14.805: INFO: Selector matched 1 pods for map[app:redis]
Nov 22 18:28:14.805: INFO: Found 1 / 1
Nov 22 18:28:14.805: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Nov 22 18:28:14.807: INFO: Selector matched 1 pods for map[app:redis]
Nov 22 18:28:14.807: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Nov 22 18:28:14.807: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 describe pod redis-master-xkhcm --namespace=kubectl-3558'
Nov 22 18:28:15.226: INFO: stderr: ""
Nov 22 18:28:15.226: INFO: stdout: "Name:           redis-master-xkhcm\nNamespace:      kubectl-3558\nPriority:       0\nNode:           minion/172.31.44.47\nStart Time:     Fri, 22 Nov 2019 18:28:11 +0000\nLabels:         app=redis\n                role=master\nAnnotations:    <none>\nStatus:         Running\nIP:             10.251.128.8\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://7d56bcfbe1af1f9d8294a372b01a5bba979b2c95451881c244859ff97fc1595a\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Fri, 22 Nov 2019 18:28:13 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-jkc9q (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-jkc9q:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-jkc9q\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  4s    default-scheduler  Successfully assigned kubectl-3558/redis-master-xkhcm to minion\n  Normal  Pulled     2s    kubelet, minion    Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    2s    kubelet, minion    Created container redis-master\n  Normal  Started    2s    kubelet, minion    Started container redis-master\n"
Nov 22 18:28:15.226: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 describe rc redis-master --namespace=kubectl-3558'
Nov 22 18:28:15.691: INFO: stderr: ""
Nov 22 18:28:15.691: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-3558\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  4s    replication-controller  Created pod: redis-master-xkhcm\n"
Nov 22 18:28:15.692: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 describe service redis-master --namespace=kubectl-3558'
Nov 22 18:28:16.100: INFO: stderr: ""
Nov 22 18:28:16.100: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-3558\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.241.195.170\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.251.128.8:6379\nSession Affinity:  None\nEvents:            <none>\n"
Nov 22 18:28:16.110: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 describe node master'
Nov 22 18:28:16.498: INFO: stderr: ""
Nov 22 18:28:16.498: INFO: stdout: "Name:               master\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=master\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/master=\n                    zone=master\nAnnotations:        kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Fri, 22 Nov 2019 15:19:43 +0000\nTaints:             node-role.kubernetes.io/master:NoSchedule\nUnschedulable:      false\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Fri, 22 Nov 2019 15:20:39 +0000   Fri, 22 Nov 2019 15:20:39 +0000   WeaveIsUp                    Weave pod has set this\n  MemoryPressure       False   Fri, 22 Nov 2019 18:28:15 +0000   Fri, 22 Nov 2019 15:19:40 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Fri, 22 Nov 2019 18:28:15 +0000   Fri, 22 Nov 2019 15:19:40 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Fri, 22 Nov 2019 18:28:15 +0000   Fri, 22 Nov 2019 15:19:40 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Fri, 22 Nov 2019 18:28:15 +0000   Fri, 22 Nov 2019 15:20:23 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  172.31.43.50\n  Hostname:    master\nCapacity:\n cpu:                4\n ephemeral-storage:  20263484Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             16424480Ki\n pods:               110\nAllocatable:\n cpu:                3800m\n ephemeral-storage:  18674826824\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             15822080Ki\n pods:               110\nSystem Info:\n Machine ID:                 9b6aff7d9abf4568a73445412a730b8b\n System UUID:                EC22AC25-6B9A-4007-CEAF-ABAF93F827CB\n Boot ID:                    6bb67b69-fb3e-4bbe-a11f-d5bfe9fa09ce\n Kernel Version:             4.15.0-1044-aws\n OS Image:                   Ubuntu 18.04.2 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.6.0\n Kubelet Version:            v1.15.3\n Kube-Proxy Version:         v1.15.3\nPodCIDR:                     10.251.0.0/24\nNon-terminated Pods:         (11 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                coredns-74c9d4d795-ddr8w                                   100m (2%)     0 (0%)      70Mi (0%)        170Mi (1%)     3h7m\n  kube-system                dns-autoscaler-7d95989447-8nshw                            20m (0%)      0 (0%)      10Mi (0%)        0 (0%)         3h7m\n  kube-system                kube-apiserver-master                                      250m (6%)     0 (0%)      0 (0%)           0 (0%)         3h8m\n  kube-system                kube-controller-manager-master                             200m (5%)     0 (0%)      0 (0%)           0 (0%)         3h8m\n  kube-system                kube-proxy-wbvbt                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         3h8m\n  kube-system                kube-scheduler-master                                      100m (2%)     0 (0%)      0 (0%)           0 (0%)         3h8m\n  kube-system                metrics-server-68b75fdf4f-w4dwb                            48m (1%)      143m (3%)   105Mi (0%)       355Mi (2%)     3h6m\n  kube-system                nodelocaldns-nclh4                                         100m (2%)     0 (0%)      70Mi (0%)        170Mi (1%)     3h7m\n  kube-system                weave-net-br64t                                            20m (0%)      0 (0%)      0 (0%)           0 (0%)         3h7m\n  sonobuoy                   sonobuoy-e2e-job-93ba17c6bc384736                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         34m\n  sonobuoy                   sonobuoy-systemd-logs-daemon-set-125c3bb177a94023-gp664    0 (0%)        0 (0%)      0 (0%)           0 (0%)         34m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                838m (22%)  143m (3%)\n  memory             255Mi (1%)  695Mi (4%)\n  ephemeral-storage  0 (0%)      0 (0%)\nEvents:              <none>\n"
Nov 22 18:28:16.498: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 describe namespace kubectl-3558'
Nov 22 18:28:16.943: INFO: stderr: ""
Nov 22 18:28:16.943: INFO: stdout: "Name:         kubectl-3558\nLabels:       e2e-framework=kubectl\n              e2e-run=3b67a62c-e62f-45eb-b65f-c4a1e157653a\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:28:16.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3558" for this suite.
Nov 22 18:28:40.973: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:28:41.267: INFO: namespace kubectl-3558 deletion completed in 24.322425517s

• [SLOW TEST:30.459 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl describe
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:28:41.268: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1293
STEP: creating an rc
Nov 22 18:28:41.366: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 create -f - --namespace=kubectl-3982'
Nov 22 18:28:42.147: INFO: stderr: ""
Nov 22 18:28:42.147: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Waiting for Redis master to start.
Nov 22 18:28:43.156: INFO: Selector matched 1 pods for map[app:redis]
Nov 22 18:28:43.156: INFO: Found 0 / 1
Nov 22 18:28:44.151: INFO: Selector matched 1 pods for map[app:redis]
Nov 22 18:28:44.151: INFO: Found 0 / 1
Nov 22 18:28:45.186: INFO: Selector matched 1 pods for map[app:redis]
Nov 22 18:28:45.186: INFO: Found 1 / 1
Nov 22 18:28:45.186: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Nov 22 18:28:45.187: INFO: Selector matched 1 pods for map[app:redis]
Nov 22 18:28:45.187: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Nov 22 18:28:45.187: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 logs redis-master-c8dm2 redis-master --namespace=kubectl-3982'
Nov 22 18:28:45.601: INFO: stderr: ""
Nov 22 18:28:45.601: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 22 Nov 18:28:43.591 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 22 Nov 18:28:43.591 # Server started, Redis version 3.2.12\n1:M 22 Nov 18:28:43.591 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 22 Nov 18:28:43.591 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Nov 22 18:28:45.602: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 log redis-master-c8dm2 redis-master --namespace=kubectl-3982 --tail=1'
Nov 22 18:28:45.994: INFO: stderr: ""
Nov 22 18:28:45.994: INFO: stdout: "1:M 22 Nov 18:28:43.591 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Nov 22 18:28:45.994: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 log redis-master-c8dm2 redis-master --namespace=kubectl-3982 --limit-bytes=1'
Nov 22 18:28:46.362: INFO: stderr: ""
Nov 22 18:28:46.362: INFO: stdout: " "
STEP: exposing timestamps
Nov 22 18:28:46.362: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 log redis-master-c8dm2 redis-master --namespace=kubectl-3982 --tail=1 --timestamps'
Nov 22 18:28:46.773: INFO: stderr: ""
Nov 22 18:28:46.773: INFO: stdout: "2019-11-22T18:28:43.591828681Z 1:M 22 Nov 18:28:43.591 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Nov 22 18:28:49.273: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 log redis-master-c8dm2 redis-master --namespace=kubectl-3982 --since=1s'
Nov 22 18:28:49.614: INFO: stderr: ""
Nov 22 18:28:49.614: INFO: stdout: ""
Nov 22 18:28:49.614: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 log redis-master-c8dm2 redis-master --namespace=kubectl-3982 --since=24h'
Nov 22 18:28:50.082: INFO: stderr: ""
Nov 22 18:28:50.082: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 22 Nov 18:28:43.591 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 22 Nov 18:28:43.591 # Server started, Redis version 3.2.12\n1:M 22 Nov 18:28:43.591 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 22 Nov 18:28:43.591 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1299
STEP: using delete to clean up resources
Nov 22 18:28:50.082: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 delete --grace-period=0 --force -f - --namespace=kubectl-3982'
Nov 22 18:28:50.438: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 22 18:28:50.438: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Nov 22 18:28:50.438: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 get rc,svc -l name=nginx --no-headers --namespace=kubectl-3982'
Nov 22 18:28:50.882: INFO: stderr: "No resources found.\n"
Nov 22 18:28:50.882: INFO: stdout: ""
Nov 22 18:28:50.882: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 get pods -l name=nginx --namespace=kubectl-3982 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov 22 18:28:51.259: INFO: stderr: ""
Nov 22 18:28:51.259: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:28:51.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3982" for this suite.
Nov 22 18:29:15.300: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:29:15.591: INFO: namespace kubectl-3982 deletion completed in 24.308751884s

• [SLOW TEST:34.324 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl logs
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:29:15.592: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on tmpfs
Nov 22 18:29:15.673: INFO: Waiting up to 5m0s for pod "pod-6491cade-e5c9-46ce-9172-9268fe9de8ca" in namespace "emptydir-4578" to be "success or failure"
Nov 22 18:29:15.701: INFO: Pod "pod-6491cade-e5c9-46ce-9172-9268fe9de8ca": Phase="Pending", Reason="", readiness=false. Elapsed: 28.124367ms
Nov 22 18:29:17.703: INFO: Pod "pod-6491cade-e5c9-46ce-9172-9268fe9de8ca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03021843s
Nov 22 18:29:19.717: INFO: Pod "pod-6491cade-e5c9-46ce-9172-9268fe9de8ca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.043778063s
STEP: Saw pod success
Nov 22 18:29:19.717: INFO: Pod "pod-6491cade-e5c9-46ce-9172-9268fe9de8ca" satisfied condition "success or failure"
Nov 22 18:29:19.731: INFO: Trying to get logs from node minion pod pod-6491cade-e5c9-46ce-9172-9268fe9de8ca container test-container: <nil>
STEP: delete the pod
Nov 22 18:29:19.767: INFO: Waiting for pod pod-6491cade-e5c9-46ce-9172-9268fe9de8ca to disappear
Nov 22 18:29:19.769: INFO: Pod pod-6491cade-e5c9-46ce-9172-9268fe9de8ca no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:29:19.769: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4578" for this suite.
Nov 22 18:29:25.821: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:29:26.120: INFO: namespace emptydir-4578 deletion completed in 6.349438334s

• [SLOW TEST:10.529 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:29:26.120: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name secret-emptykey-test-4f79b937-4929-4f02-bc19-00a8a1955083
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:29:26.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7146" for this suite.
Nov 22 18:29:32.263: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:29:32.522: INFO: namespace secrets-7146 deletion completed in 6.284458952s

• [SLOW TEST:6.401 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:29:32.522: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod liveness-85fd927a-693d-4715-a94b-d00627f3ecd2 in namespace container-probe-2749
Nov 22 18:29:36.651: INFO: Started pod liveness-85fd927a-693d-4715-a94b-d00627f3ecd2 in namespace container-probe-2749
STEP: checking the pod's current state and verifying that restartCount is present
Nov 22 18:29:36.652: INFO: Initial restart count of pod liveness-85fd927a-693d-4715-a94b-d00627f3ecd2 is 0
Nov 22 18:29:48.702: INFO: Restart count of pod container-probe-2749/liveness-85fd927a-693d-4715-a94b-d00627f3ecd2 is now 1 (12.049370537s elapsed)
Nov 22 18:30:08.777: INFO: Restart count of pod container-probe-2749/liveness-85fd927a-693d-4715-a94b-d00627f3ecd2 is now 2 (32.124617522s elapsed)
Nov 22 18:30:28.797: INFO: Restart count of pod container-probe-2749/liveness-85fd927a-693d-4715-a94b-d00627f3ecd2 is now 3 (52.14497754s elapsed)
Nov 22 18:30:48.817: INFO: Restart count of pod container-probe-2749/liveness-85fd927a-693d-4715-a94b-d00627f3ecd2 is now 4 (1m12.16510368s elapsed)
Nov 22 18:32:01.043: INFO: Restart count of pod container-probe-2749/liveness-85fd927a-693d-4715-a94b-d00627f3ecd2 is now 5 (2m24.391125172s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:32:01.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2749" for this suite.
Nov 22 18:32:07.123: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:32:07.399: INFO: namespace container-probe-2749 deletion completed in 6.300930274s

• [SLOW TEST:154.878 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:32:07.400: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on node default medium
Nov 22 18:32:07.541: INFO: Waiting up to 5m0s for pod "pod-08e642c8-7a94-4d3a-85ff-0464caa41cd8" in namespace "emptydir-4370" to be "success or failure"
Nov 22 18:32:07.543: INFO: Pod "pod-08e642c8-7a94-4d3a-85ff-0464caa41cd8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.205634ms
Nov 22 18:32:09.545: INFO: Pod "pod-08e642c8-7a94-4d3a-85ff-0464caa41cd8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004457791s
Nov 22 18:32:11.557: INFO: Pod "pod-08e642c8-7a94-4d3a-85ff-0464caa41cd8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016579855s
STEP: Saw pod success
Nov 22 18:32:11.557: INFO: Pod "pod-08e642c8-7a94-4d3a-85ff-0464caa41cd8" satisfied condition "success or failure"
Nov 22 18:32:11.558: INFO: Trying to get logs from node minion pod pod-08e642c8-7a94-4d3a-85ff-0464caa41cd8 container test-container: <nil>
STEP: delete the pod
Nov 22 18:32:11.605: INFO: Waiting for pod pod-08e642c8-7a94-4d3a-85ff-0464caa41cd8 to disappear
Nov 22 18:32:11.606: INFO: Pod pod-08e642c8-7a94-4d3a-85ff-0464caa41cd8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:32:11.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4370" for this suite.
Nov 22 18:32:17.636: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:32:17.907: INFO: namespace emptydir-4370 deletion completed in 6.281231515s

• [SLOW TEST:10.507 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:32:17.907: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Nov 22 18:32:22.569: INFO: Successfully updated pod "pod-update-activedeadlineseconds-71cc8928-b605-4573-be17-d80dac9abed2"
Nov 22 18:32:22.569: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-71cc8928-b605-4573-be17-d80dac9abed2" in namespace "pods-3179" to be "terminated due to deadline exceeded"
Nov 22 18:32:22.570: INFO: Pod "pod-update-activedeadlineseconds-71cc8928-b605-4573-be17-d80dac9abed2": Phase="Running", Reason="", readiness=true. Elapsed: 1.317206ms
Nov 22 18:32:24.573: INFO: Pod "pod-update-activedeadlineseconds-71cc8928-b605-4573-be17-d80dac9abed2": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.00454724s
Nov 22 18:32:24.573: INFO: Pod "pod-update-activedeadlineseconds-71cc8928-b605-4573-be17-d80dac9abed2" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:32:24.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3179" for this suite.
Nov 22 18:32:30.612: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:32:30.933: INFO: namespace pods-3179 deletion completed in 6.35727301s

• [SLOW TEST:13.025 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:32:30.933: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Starting the proxy
Nov 22 18:32:31.027: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-880417063 proxy --unix-socket=/tmp/kubectl-proxy-unix736516142/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:32:31.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5168" for this suite.
Nov 22 18:32:37.351: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:32:37.589: INFO: namespace kubectl-5168 deletion completed in 6.276903998s

• [SLOW TEST:6.656 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:32:37.597: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating replication controller my-hostname-basic-d386b29d-a3e3-4a86-be0a-b0b3c2fcd535
Nov 22 18:32:37.688: INFO: Pod name my-hostname-basic-d386b29d-a3e3-4a86-be0a-b0b3c2fcd535: Found 0 pods out of 1
Nov 22 18:32:42.694: INFO: Pod name my-hostname-basic-d386b29d-a3e3-4a86-be0a-b0b3c2fcd535: Found 1 pods out of 1
Nov 22 18:32:42.694: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-d386b29d-a3e3-4a86-be0a-b0b3c2fcd535" are running
Nov 22 18:32:42.695: INFO: Pod "my-hostname-basic-d386b29d-a3e3-4a86-be0a-b0b3c2fcd535-pd542" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-11-22 18:32:37 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-11-22 18:32:39 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-11-22 18:32:39 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-11-22 18:32:37 +0000 UTC Reason: Message:}])
Nov 22 18:32:42.695: INFO: Trying to dial the pod
Nov 22 18:32:47.930: INFO: Controller my-hostname-basic-d386b29d-a3e3-4a86-be0a-b0b3c2fcd535: Got expected result from replica 1 [my-hostname-basic-d386b29d-a3e3-4a86-be0a-b0b3c2fcd535-pd542]: "my-hostname-basic-d386b29d-a3e3-4a86-be0a-b0b3c2fcd535-pd542", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:32:47.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-2760" for this suite.
Nov 22 18:32:53.954: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:32:54.418: INFO: namespace replication-controller-2760 deletion completed in 6.48569474s

• [SLOW TEST:16.821 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:32:54.418: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Nov 22 18:33:02.653: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov 22 18:33:02.655: INFO: Pod pod-with-poststart-http-hook still exists
Nov 22 18:33:04.656: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov 22 18:33:04.663: INFO: Pod pod-with-poststart-http-hook still exists
Nov 22 18:33:06.656: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov 22 18:33:06.658: INFO: Pod pod-with-poststart-http-hook still exists
Nov 22 18:33:08.657: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov 22 18:33:08.659: INFO: Pod pod-with-poststart-http-hook still exists
Nov 22 18:33:10.656: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov 22 18:33:10.658: INFO: Pod pod-with-poststart-http-hook still exists
Nov 22 18:33:12.656: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov 22 18:33:12.661: INFO: Pod pod-with-poststart-http-hook still exists
Nov 22 18:33:14.659: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov 22 18:33:14.668: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:33:14.668: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-5281" for this suite.
Nov 22 18:33:38.700: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:33:38.893: INFO: namespace container-lifecycle-hook-5281 deletion completed in 24.222423545s

• [SLOW TEST:44.475 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:33:38.893: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Nov 22 18:33:38.980: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Nov 22 18:33:41.060: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:33:41.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-9924" for this suite.
Nov 22 18:33:47.127: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:33:47.364: INFO: namespace replication-controller-9924 deletion completed in 6.288023462s

• [SLOW TEST:8.471 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:33:47.364: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1722
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Nov 22 18:33:47.473: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=kubectl-1668'
Nov 22 18:33:49.091: INFO: stderr: ""
Nov 22 18:33:49.091: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Nov 22 18:33:54.152: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 get pod e2e-test-nginx-pod --namespace=kubectl-1668 -o json'
Nov 22 18:33:54.526: INFO: stderr: ""
Nov 22 18:33:54.526: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-11-22T18:33:48Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"kubectl-1668\",\n        \"resourceVersion\": \"44235\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-1668/pods/e2e-test-nginx-pod\",\n        \"uid\": \"c30f2f62-5b36-47fd-9557-756eb0e4e01f\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-lsxkw\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"minion\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-lsxkw\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-lsxkw\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-11-22T18:33:49Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-11-22T18:33:50Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-11-22T18:33:50Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-11-22T18:33:49Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://b5148acf54a319ae2bc0e1a45e985762e26eb5dc8ba2abcdf296679285c7672e\",\n                \"image\": \"nginx:1.14-alpine\",\n                \"imageID\": \"docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-11-22T18:33:50Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"172.31.44.47\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.251.128.8\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-11-22T18:33:49Z\"\n    }\n}\n"
STEP: replace the image in the pod
Nov 22 18:33:54.526: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 replace -f - --namespace=kubectl-1668'
Nov 22 18:33:55.389: INFO: stderr: ""
Nov 22 18:33:55.389: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1727
Nov 22 18:33:55.409: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 delete pods e2e-test-nginx-pod --namespace=kubectl-1668'
Nov 22 18:33:57.590: INFO: stderr: ""
Nov 22 18:33:57.590: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:33:57.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1668" for this suite.
Nov 22 18:34:03.632: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:34:03.967: INFO: namespace kubectl-1668 deletion completed in 6.372997651s

• [SLOW TEST:16.603 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl replace
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:34:03.968: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the initial replication controller
Nov 22 18:34:04.033: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 create -f - --namespace=kubectl-1728'
Nov 22 18:34:04.793: INFO: stderr: ""
Nov 22 18:34:04.793: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov 22 18:34:04.794: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1728'
Nov 22 18:34:05.229: INFO: stderr: ""
Nov 22 18:34:05.230: INFO: stdout: "update-demo-nautilus-4ggqk update-demo-nautilus-bk5h9 "
Nov 22 18:34:05.230: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 get pods update-demo-nautilus-4ggqk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1728'
Nov 22 18:34:05.584: INFO: stderr: ""
Nov 22 18:34:05.584: INFO: stdout: ""
Nov 22 18:34:05.584: INFO: update-demo-nautilus-4ggqk is created but not running
Nov 22 18:34:10.596: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1728'
Nov 22 18:34:10.918: INFO: stderr: ""
Nov 22 18:34:10.918: INFO: stdout: "update-demo-nautilus-4ggqk update-demo-nautilus-bk5h9 "
Nov 22 18:34:10.918: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 get pods update-demo-nautilus-4ggqk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1728'
Nov 22 18:34:11.380: INFO: stderr: ""
Nov 22 18:34:11.380: INFO: stdout: "true"
Nov 22 18:34:11.380: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 get pods update-demo-nautilus-4ggqk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1728'
Nov 22 18:34:11.694: INFO: stderr: ""
Nov 22 18:34:11.694: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov 22 18:34:11.694: INFO: validating pod update-demo-nautilus-4ggqk
Nov 22 18:34:11.707: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 22 18:34:11.707: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 22 18:34:11.707: INFO: update-demo-nautilus-4ggqk is verified up and running
Nov 22 18:34:11.707: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 get pods update-demo-nautilus-bk5h9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1728'
Nov 22 18:34:12.151: INFO: stderr: ""
Nov 22 18:34:12.151: INFO: stdout: "true"
Nov 22 18:34:12.152: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 get pods update-demo-nautilus-bk5h9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1728'
Nov 22 18:34:12.523: INFO: stderr: ""
Nov 22 18:34:12.523: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov 22 18:34:12.523: INFO: validating pod update-demo-nautilus-bk5h9
Nov 22 18:34:12.560: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 22 18:34:12.560: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 22 18:34:12.560: INFO: update-demo-nautilus-bk5h9 is verified up and running
STEP: rolling-update to new replication controller
Nov 22 18:34:12.562: INFO: scanned /root for discovery docs: <nil>
Nov 22 18:34:12.562: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-1728'
Nov 22 18:34:33.918: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Nov 22 18:34:33.918: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov 22 18:34:33.918: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1728'
Nov 22 18:34:34.336: INFO: stderr: ""
Nov 22 18:34:34.336: INFO: stdout: "update-demo-kitten-6nnqf update-demo-kitten-f5225 "
Nov 22 18:34:34.336: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 get pods update-demo-kitten-6nnqf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1728'
Nov 22 18:34:34.729: INFO: stderr: ""
Nov 22 18:34:34.729: INFO: stdout: "true"
Nov 22 18:34:34.729: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 get pods update-demo-kitten-6nnqf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1728'
Nov 22 18:34:35.110: INFO: stderr: ""
Nov 22 18:34:35.110: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Nov 22 18:34:35.110: INFO: validating pod update-demo-kitten-6nnqf
Nov 22 18:34:35.122: INFO: got data: {
  "image": "kitten.jpg"
}

Nov 22 18:34:35.122: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Nov 22 18:34:35.122: INFO: update-demo-kitten-6nnqf is verified up and running
Nov 22 18:34:35.122: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 get pods update-demo-kitten-f5225 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1728'
Nov 22 18:34:35.565: INFO: stderr: ""
Nov 22 18:34:35.565: INFO: stdout: "true"
Nov 22 18:34:35.565: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 get pods update-demo-kitten-f5225 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1728'
Nov 22 18:34:35.929: INFO: stderr: ""
Nov 22 18:34:35.929: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Nov 22 18:34:35.929: INFO: validating pod update-demo-kitten-f5225
Nov 22 18:34:35.933: INFO: got data: {
  "image": "kitten.jpg"
}

Nov 22 18:34:35.934: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Nov 22 18:34:35.934: INFO: update-demo-kitten-f5225 is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:34:35.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1728" for this suite.
Nov 22 18:34:59.992: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:35:00.322: INFO: namespace kubectl-1728 deletion completed in 24.374175039s

• [SLOW TEST:56.355 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:35:00.323: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-dc8eba0e-fe2a-4300-bef4-2a22c3e254a8
STEP: Creating a pod to test consume configMaps
Nov 22 18:35:00.449: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-75d71efb-1979-4f31-8187-937cecfcd5e5" in namespace "projected-7355" to be "success or failure"
Nov 22 18:35:00.463: INFO: Pod "pod-projected-configmaps-75d71efb-1979-4f31-8187-937cecfcd5e5": Phase="Pending", Reason="", readiness=false. Elapsed: 1.749477ms
Nov 22 18:35:02.485: INFO: Pod "pod-projected-configmaps-75d71efb-1979-4f31-8187-937cecfcd5e5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.024127372s
STEP: Saw pod success
Nov 22 18:35:02.485: INFO: Pod "pod-projected-configmaps-75d71efb-1979-4f31-8187-937cecfcd5e5" satisfied condition "success or failure"
Nov 22 18:35:02.487: INFO: Trying to get logs from node minion pod pod-projected-configmaps-75d71efb-1979-4f31-8187-937cecfcd5e5 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov 22 18:35:02.533: INFO: Waiting for pod pod-projected-configmaps-75d71efb-1979-4f31-8187-937cecfcd5e5 to disappear
Nov 22 18:35:02.535: INFO: Pod pod-projected-configmaps-75d71efb-1979-4f31-8187-937cecfcd5e5 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:35:02.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7355" for this suite.
Nov 22 18:35:08.571: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:35:08.639: INFO: namespace projected-7355 deletion completed in 6.081768609s

• [SLOW TEST:8.316 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:35:08.639: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Nov 22 18:35:14.701: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
	[quantile=0.5] = 186
	[quantile=0.9] = 41782
	[quantile=0.99] = 175396
For garbage_collector_attempt_to_delete_work_duration:
	[quantile=0.5] = 175568
	[quantile=0.9] = 403888
	[quantile=0.99] = 438304
For garbage_collector_attempt_to_orphan_queue_latency:
	[quantile=0.5] = 15
	[quantile=0.9] = 25
	[quantile=0.99] = 25
For garbage_collector_attempt_to_orphan_work_duration:
	[quantile=0.5] = 479437
	[quantile=0.9] = 505765
	[quantile=0.99] = 505765
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
	[quantile=0.5] = 5
	[quantile=0.9] = 6
	[quantile=0.99] = 25
For garbage_collector_graph_changes_work_duration:
	[quantile=0.5] = 13
	[quantile=0.9] = 22
	[quantile=0.99] = 47
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
	[quantile=0.5] = 12
	[quantile=0.9] = 23
	[quantile=0.99] = 31
For namespace_queue_latency_sum:
	[] = 6472
For namespace_queue_latency_count:
	[] = 477
For namespace_retries:
	[] = 488
For namespace_work_duration:
	[quantile=0.5] = 668170
	[quantile=0.9] = 954123
	[quantile=0.99] = 2769611
For namespace_work_duration_sum:
	[] = 182865675
For namespace_work_duration_count:
	[] = 477
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:35:14.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2649" for this suite.
Nov 22 18:35:20.710: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:35:20.774: INFO: namespace gc-2649 deletion completed in 6.070845902s

• [SLOW TEST:12.135 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:35:20.774: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Nov 22 18:35:23.331: INFO: Successfully updated pod "annotationupdate666e314d-05cb-4a55-a9b3-9d6f103e73c3"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:35:25.344: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5296" for this suite.
Nov 22 18:35:47.353: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:35:47.432: INFO: namespace projected-5296 deletion completed in 22.086012882s

• [SLOW TEST:26.658 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:35:47.432: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Nov 22 18:35:47.463: INFO: Waiting up to 5m0s for pod "downward-api-de6ad0f9-79c6-42cb-95c2-11c35de6851a" in namespace "downward-api-1340" to be "success or failure"
Nov 22 18:35:47.464: INFO: Pod "downward-api-de6ad0f9-79c6-42cb-95c2-11c35de6851a": Phase="Pending", Reason="", readiness=false. Elapsed: 1.610318ms
Nov 22 18:35:49.466: INFO: Pod "downward-api-de6ad0f9-79c6-42cb-95c2-11c35de6851a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003441538s
STEP: Saw pod success
Nov 22 18:35:49.466: INFO: Pod "downward-api-de6ad0f9-79c6-42cb-95c2-11c35de6851a" satisfied condition "success or failure"
Nov 22 18:35:49.468: INFO: Trying to get logs from node minion pod downward-api-de6ad0f9-79c6-42cb-95c2-11c35de6851a container dapi-container: <nil>
STEP: delete the pod
Nov 22 18:35:49.478: INFO: Waiting for pod downward-api-de6ad0f9-79c6-42cb-95c2-11c35de6851a to disappear
Nov 22 18:35:49.480: INFO: Pod downward-api-de6ad0f9-79c6-42cb-95c2-11c35de6851a no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:35:49.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1340" for this suite.
Nov 22 18:35:55.487: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:35:55.549: INFO: namespace downward-api-1340 deletion completed in 6.067572809s

• [SLOW TEST:8.117 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:35:55.550: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Nov 22 18:35:58.100: INFO: Successfully updated pod "annotationupdate75e7a5fe-498e-4260-b1f1-00d90cabc86e"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:36:00.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8145" for this suite.
Nov 22 18:36:22.119: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:36:22.360: INFO: namespace downward-api-8145 deletion completed in 22.247083077s

• [SLOW TEST:26.811 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:36:22.360: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:36:26.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7907" for this suite.
Nov 22 18:37:16.572: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:37:16.803: INFO: namespace kubelet-test-7907 deletion completed in 50.271912555s

• [SLOW TEST:54.443 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a read only busybox container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:37:16.803: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Nov 22 18:37:57.048: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
	[quantile=0.5] = 172
	[quantile=0.9] = 41782
	[quantile=0.99] = 175396
For garbage_collector_attempt_to_delete_work_duration:
	[quantile=0.5] = 61
	[quantile=0.9] = 399481
	[quantile=0.99] = 412615
For garbage_collector_attempt_to_orphan_queue_latency:
	[quantile=0.5] = 15
	[quantile=0.9] = 25
	[quantile=0.99] = 25
For garbage_collector_attempt_to_orphan_work_duration:
	[quantile=0.5] = 505765
	[quantile=0.9] = 529226
	[quantile=0.99] = 529226
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
	[quantile=0.5] = 5
	[quantile=0.9] = 6
	[quantile=0.99] = 26
For garbage_collector_graph_changes_work_duration:
	[quantile=0.5] = 13
	[quantile=0.9] = 20
	[quantile=0.99] = 50
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
	[quantile=0.5] = 12
	[quantile=0.9] = 20
	[quantile=0.99] = 31
For namespace_queue_latency_sum:
	[] = 6701
For namespace_queue_latency_count:
	[] = 496
For namespace_retries:
	[] = 507
For namespace_work_duration:
	[quantile=0.5] = 547758
	[quantile=0.9] = 828334
	[quantile=0.99] = 954123
For namespace_work_duration_sum:
	[] = 191557164
For namespace_work_duration_count:
	[] = 496
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:37:57.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2660" for this suite.
Nov 22 18:38:05.085: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:38:05.313: INFO: namespace gc-2660 deletion completed in 8.25945704s

• [SLOW TEST:48.510 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:38:05.313: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating secret secrets-5050/secret-test-db7c9c28-5b71-4431-93f8-37041a5087d4
STEP: Creating a pod to test consume secrets
Nov 22 18:38:05.432: INFO: Waiting up to 5m0s for pod "pod-configmaps-46e4fac7-07d2-44e0-9838-823a9016f462" in namespace "secrets-5050" to be "success or failure"
Nov 22 18:38:05.450: INFO: Pod "pod-configmaps-46e4fac7-07d2-44e0-9838-823a9016f462": Phase="Pending", Reason="", readiness=false. Elapsed: 17.62734ms
Nov 22 18:38:07.487: INFO: Pod "pod-configmaps-46e4fac7-07d2-44e0-9838-823a9016f462": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.055398583s
STEP: Saw pod success
Nov 22 18:38:07.487: INFO: Pod "pod-configmaps-46e4fac7-07d2-44e0-9838-823a9016f462" satisfied condition "success or failure"
Nov 22 18:38:07.509: INFO: Trying to get logs from node minion pod pod-configmaps-46e4fac7-07d2-44e0-9838-823a9016f462 container env-test: <nil>
STEP: delete the pod
Nov 22 18:38:07.535: INFO: Waiting for pod pod-configmaps-46e4fac7-07d2-44e0-9838-823a9016f462 to disappear
Nov 22 18:38:07.537: INFO: Pod pod-configmaps-46e4fac7-07d2-44e0-9838-823a9016f462 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:38:07.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5050" for this suite.
Nov 22 18:38:13.574: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:38:13.871: INFO: namespace secrets-5050 deletion completed in 6.315060579s

• [SLOW TEST:8.557 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:38:13.871: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: getting the auto-created API token
STEP: reading a file in the container
Nov 22 18:38:16.524: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6330 pod-service-account-6e2407cf-2ebc-480a-9261-f2ab7b344efe -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Nov 22 18:38:17.064: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6330 pod-service-account-6e2407cf-2ebc-480a-9261-f2ab7b344efe -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Nov 22 18:38:17.665: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6330 pod-service-account-6e2407cf-2ebc-480a-9261-f2ab7b344efe -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:38:18.200: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-6330" for this suite.
Nov 22 18:38:24.235: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:38:24.515: INFO: namespace svcaccounts-6330 deletion completed in 6.31312113s

• [SLOW TEST:10.644 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:38:24.515: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-ec5d1125-8ef0-43de-bbc3-28152d1c0974
STEP: Creating a pod to test consume secrets
Nov 22 18:38:24.635: INFO: Waiting up to 5m0s for pod "pod-secrets-d0f8d733-4dcf-463c-8333-9b8b75f3c469" in namespace "secrets-8018" to be "success or failure"
Nov 22 18:38:24.651: INFO: Pod "pod-secrets-d0f8d733-4dcf-463c-8333-9b8b75f3c469": Phase="Pending", Reason="", readiness=false. Elapsed: 15.52987ms
Nov 22 18:38:26.655: INFO: Pod "pod-secrets-d0f8d733-4dcf-463c-8333-9b8b75f3c469": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019574966s
Nov 22 18:38:28.668: INFO: Pod "pod-secrets-d0f8d733-4dcf-463c-8333-9b8b75f3c469": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032473941s
STEP: Saw pod success
Nov 22 18:38:28.669: INFO: Pod "pod-secrets-d0f8d733-4dcf-463c-8333-9b8b75f3c469" satisfied condition "success or failure"
Nov 22 18:38:28.683: INFO: Trying to get logs from node minion pod pod-secrets-d0f8d733-4dcf-463c-8333-9b8b75f3c469 container secret-volume-test: <nil>
STEP: delete the pod
Nov 22 18:38:28.753: INFO: Waiting for pod pod-secrets-d0f8d733-4dcf-463c-8333-9b8b75f3c469 to disappear
Nov 22 18:38:28.754: INFO: Pod pod-secrets-d0f8d733-4dcf-463c-8333-9b8b75f3c469 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:38:28.754: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8018" for this suite.
Nov 22 18:38:34.835: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:38:35.172: INFO: namespace secrets-8018 deletion completed in 6.375296963s

• [SLOW TEST:10.657 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:38:35.172: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Nov 22 18:38:39.397: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 22 18:38:39.399: INFO: Pod pod-with-prestop-exec-hook still exists
Nov 22 18:38:41.409: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 22 18:38:41.410: INFO: Pod pod-with-prestop-exec-hook still exists
Nov 22 18:38:43.400: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 22 18:38:43.422: INFO: Pod pod-with-prestop-exec-hook still exists
Nov 22 18:38:45.409: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 22 18:38:45.412: INFO: Pod pod-with-prestop-exec-hook still exists
Nov 22 18:38:47.399: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 22 18:38:47.401: INFO: Pod pod-with-prestop-exec-hook still exists
Nov 22 18:38:49.399: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 22 18:38:49.401: INFO: Pod pod-with-prestop-exec-hook still exists
Nov 22 18:38:51.407: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 22 18:38:51.412: INFO: Pod pod-with-prestop-exec-hook still exists
Nov 22 18:38:53.407: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 22 18:38:53.409: INFO: Pod pod-with-prestop-exec-hook still exists
Nov 22 18:38:55.399: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 22 18:38:55.409: INFO: Pod pod-with-prestop-exec-hook still exists
Nov 22 18:38:57.401: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 22 18:38:57.423: INFO: Pod pod-with-prestop-exec-hook still exists
Nov 22 18:38:59.405: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 22 18:38:59.407: INFO: Pod pod-with-prestop-exec-hook still exists
Nov 22 18:39:01.409: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 22 18:39:01.411: INFO: Pod pod-with-prestop-exec-hook still exists
Nov 22 18:39:03.399: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 22 18:39:03.413: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:39:03.419: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-3752" for this suite.
Nov 22 18:39:27.443: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:39:27.783: INFO: namespace container-lifecycle-hook-3752 deletion completed in 24.362784905s

• [SLOW TEST:52.611 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:39:27.783: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-9303, will wait for the garbage collector to delete the pods
Nov 22 18:39:31.981: INFO: Deleting Job.batch foo took: 3.851148ms
Nov 22 18:39:32.481: INFO: Terminating Job.batch foo pods took: 500.196496ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:40:12.783: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-9303" for this suite.
Nov 22 18:40:18.791: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:40:18.854: INFO: namespace job-9303 deletion completed in 6.068307422s

• [SLOW TEST:51.071 seconds]
[sig-apps] Job
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:40:18.854: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-80ff7a2f-4e2d-447d-b3d0-1fc4090d9054
STEP: Creating a pod to test consume secrets
Nov 22 18:40:18.883: INFO: Waiting up to 5m0s for pod "pod-secrets-2a07eb90-5f84-4c1f-a3e4-a2d9332231f2" in namespace "secrets-5912" to be "success or failure"
Nov 22 18:40:18.888: INFO: Pod "pod-secrets-2a07eb90-5f84-4c1f-a3e4-a2d9332231f2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.342244ms
Nov 22 18:40:20.890: INFO: Pod "pod-secrets-2a07eb90-5f84-4c1f-a3e4-a2d9332231f2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006332624s
STEP: Saw pod success
Nov 22 18:40:20.890: INFO: Pod "pod-secrets-2a07eb90-5f84-4c1f-a3e4-a2d9332231f2" satisfied condition "success or failure"
Nov 22 18:40:20.892: INFO: Trying to get logs from node minion pod pod-secrets-2a07eb90-5f84-4c1f-a3e4-a2d9332231f2 container secret-volume-test: <nil>
STEP: delete the pod
Nov 22 18:40:20.903: INFO: Waiting for pod pod-secrets-2a07eb90-5f84-4c1f-a3e4-a2d9332231f2 to disappear
Nov 22 18:40:20.906: INFO: Pod pod-secrets-2a07eb90-5f84-4c1f-a3e4-a2d9332231f2 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:40:20.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5912" for this suite.
Nov 22 18:40:26.917: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:40:26.978: INFO: namespace secrets-5912 deletion completed in 6.069264883s

• [SLOW TEST:8.124 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:40:26.978: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on node default medium
Nov 22 18:40:27.005: INFO: Waiting up to 5m0s for pod "pod-febdfd63-998b-4bb4-9a05-4307ea6aa664" in namespace "emptydir-76" to be "success or failure"
Nov 22 18:40:27.008: INFO: Pod "pod-febdfd63-998b-4bb4-9a05-4307ea6aa664": Phase="Pending", Reason="", readiness=false. Elapsed: 3.253542ms
Nov 22 18:40:29.010: INFO: Pod "pod-febdfd63-998b-4bb4-9a05-4307ea6aa664": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004964076s
STEP: Saw pod success
Nov 22 18:40:29.010: INFO: Pod "pod-febdfd63-998b-4bb4-9a05-4307ea6aa664" satisfied condition "success or failure"
Nov 22 18:40:29.011: INFO: Trying to get logs from node minion pod pod-febdfd63-998b-4bb4-9a05-4307ea6aa664 container test-container: <nil>
STEP: delete the pod
Nov 22 18:40:29.023: INFO: Waiting for pod pod-febdfd63-998b-4bb4-9a05-4307ea6aa664 to disappear
Nov 22 18:40:29.036: INFO: Pod pod-febdfd63-998b-4bb4-9a05-4307ea6aa664 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:40:29.036: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-76" for this suite.
Nov 22 18:40:35.045: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:40:35.103: INFO: namespace emptydir-76 deletion completed in 6.064544171s

• [SLOW TEST:8.125 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:40:35.104: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Nov 22 18:40:35.146: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-4300,SelfLink:/api/v1/namespaces/watch-4300/configmaps/e2e-watch-test-resource-version,UID:b3f0be6b-bd8b-4e70-ae61-26b0dd39f7ed,ResourceVersion:46121,Generation:0,CreationTimestamp:2019-11-22 18:40:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov 22 18:40:35.146: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-4300,SelfLink:/api/v1/namespaces/watch-4300/configmaps/e2e-watch-test-resource-version,UID:b3f0be6b-bd8b-4e70-ae61-26b0dd39f7ed,ResourceVersion:46122,Generation:0,CreationTimestamp:2019-11-22 18:40:35 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:40:35.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-4300" for this suite.
Nov 22 18:40:41.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:40:41.224: INFO: namespace watch-4300 deletion completed in 6.076887719s

• [SLOW TEST:6.121 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:40:41.224: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Nov 22 18:40:41.244: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:40:42.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-3778" for this suite.
Nov 22 18:40:48.327: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:40:48.432: INFO: namespace custom-resource-definition-3778 deletion completed in 6.110922346s

• [SLOW TEST:7.208 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:40:48.432: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-37f1cbc5-0bc7-4e44-bc25-f46176f5f61d
STEP: Creating a pod to test consume configMaps
Nov 22 18:40:48.467: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-264f942b-ce28-4e24-afc5-b476db0e0032" in namespace "projected-9914" to be "success or failure"
Nov 22 18:40:48.470: INFO: Pod "pod-projected-configmaps-264f942b-ce28-4e24-afc5-b476db0e0032": Phase="Pending", Reason="", readiness=false. Elapsed: 2.616707ms
Nov 22 18:40:50.471: INFO: Pod "pod-projected-configmaps-264f942b-ce28-4e24-afc5-b476db0e0032": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004421402s
STEP: Saw pod success
Nov 22 18:40:50.471: INFO: Pod "pod-projected-configmaps-264f942b-ce28-4e24-afc5-b476db0e0032" satisfied condition "success or failure"
Nov 22 18:40:50.473: INFO: Trying to get logs from node minion pod pod-projected-configmaps-264f942b-ce28-4e24-afc5-b476db0e0032 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov 22 18:40:50.483: INFO: Waiting for pod pod-projected-configmaps-264f942b-ce28-4e24-afc5-b476db0e0032 to disappear
Nov 22 18:40:50.485: INFO: Pod pod-projected-configmaps-264f942b-ce28-4e24-afc5-b476db0e0032 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:40:50.485: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9914" for this suite.
Nov 22 18:40:56.492: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:40:56.560: INFO: namespace projected-9914 deletion completed in 6.073938141s

• [SLOW TEST:8.128 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:40:56.561: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test use defaults
Nov 22 18:40:56.589: INFO: Waiting up to 5m0s for pod "client-containers-19a83cb7-c1b0-4c41-9d10-90b162ca1797" in namespace "containers-3520" to be "success or failure"
Nov 22 18:40:56.590: INFO: Pod "client-containers-19a83cb7-c1b0-4c41-9d10-90b162ca1797": Phase="Pending", Reason="", readiness=false. Elapsed: 1.454431ms
Nov 22 18:40:58.592: INFO: Pod "client-containers-19a83cb7-c1b0-4c41-9d10-90b162ca1797": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.003283914s
STEP: Saw pod success
Nov 22 18:40:58.592: INFO: Pod "client-containers-19a83cb7-c1b0-4c41-9d10-90b162ca1797" satisfied condition "success or failure"
Nov 22 18:40:58.594: INFO: Trying to get logs from node minion pod client-containers-19a83cb7-c1b0-4c41-9d10-90b162ca1797 container test-container: <nil>
STEP: delete the pod
Nov 22 18:40:58.605: INFO: Waiting for pod client-containers-19a83cb7-c1b0-4c41-9d10-90b162ca1797 to disappear
Nov 22 18:40:58.613: INFO: Pod client-containers-19a83cb7-c1b0-4c41-9d10-90b162ca1797 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:40:58.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3520" for this suite.
Nov 22 18:41:04.620: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:41:04.731: INFO: namespace containers-3520 deletion completed in 6.115788692s

• [SLOW TEST:8.170 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:41:04.731: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating pod
Nov 22 18:41:06.760: INFO: Pod pod-hostip-f2f6cb61-f6ef-4563-99b2-497cf60036bd has hostIP: 172.31.44.47
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:41:06.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8906" for this suite.
Nov 22 18:41:28.772: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:41:29.037: INFO: namespace pods-8906 deletion completed in 22.274371369s

• [SLOW TEST:24.306 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:41:29.038: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on tmpfs
Nov 22 18:41:29.149: INFO: Waiting up to 5m0s for pod "pod-c430890c-95d2-45c8-b787-e40637efbc72" in namespace "emptydir-813" to be "success or failure"
Nov 22 18:41:29.151: INFO: Pod "pod-c430890c-95d2-45c8-b787-e40637efbc72": Phase="Pending", Reason="", readiness=false. Elapsed: 1.438961ms
Nov 22 18:41:31.159: INFO: Pod "pod-c430890c-95d2-45c8-b787-e40637efbc72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009160495s
Nov 22 18:41:33.168: INFO: Pod "pod-c430890c-95d2-45c8-b787-e40637efbc72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018184696s
STEP: Saw pod success
Nov 22 18:41:33.168: INFO: Pod "pod-c430890c-95d2-45c8-b787-e40637efbc72" satisfied condition "success or failure"
Nov 22 18:41:33.169: INFO: Trying to get logs from node minion pod pod-c430890c-95d2-45c8-b787-e40637efbc72 container test-container: <nil>
STEP: delete the pod
Nov 22 18:41:33.228: INFO: Waiting for pod pod-c430890c-95d2-45c8-b787-e40637efbc72 to disappear
Nov 22 18:41:33.241: INFO: Pod pod-c430890c-95d2-45c8-b787-e40637efbc72 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:41:33.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-813" for this suite.
Nov 22 18:41:39.261: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:41:39.527: INFO: namespace emptydir-813 deletion completed in 6.283800908s

• [SLOW TEST:10.489 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:41:39.536: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override all
Nov 22 18:41:39.620: INFO: Waiting up to 5m0s for pod "client-containers-0e97ad69-7adb-4964-93c1-b11ff75d9316" in namespace "containers-2796" to be "success or failure"
Nov 22 18:41:39.642: INFO: Pod "client-containers-0e97ad69-7adb-4964-93c1-b11ff75d9316": Phase="Pending", Reason="", readiness=false. Elapsed: 21.758167ms
Nov 22 18:41:41.643: INFO: Pod "client-containers-0e97ad69-7adb-4964-93c1-b11ff75d9316": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023294405s
STEP: Saw pod success
Nov 22 18:41:41.643: INFO: Pod "client-containers-0e97ad69-7adb-4964-93c1-b11ff75d9316" satisfied condition "success or failure"
Nov 22 18:41:41.644: INFO: Trying to get logs from node minion pod client-containers-0e97ad69-7adb-4964-93c1-b11ff75d9316 container test-container: <nil>
STEP: delete the pod
Nov 22 18:41:41.679: INFO: Waiting for pod client-containers-0e97ad69-7adb-4964-93c1-b11ff75d9316 to disappear
Nov 22 18:41:41.694: INFO: Pod client-containers-0e97ad69-7adb-4964-93c1-b11ff75d9316 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:41:41.694: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-2796" for this suite.
Nov 22 18:41:47.728: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:41:48.367: INFO: namespace containers-2796 deletion completed in 6.654717599s

• [SLOW TEST:8.832 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:41:48.368: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1558
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Nov 22 18:41:48.462: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/apps.v1 --namespace=kubectl-2381'
Nov 22 18:41:48.847: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Nov 22 18:41:48.847: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
Nov 22 18:41:52.922: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 delete deployment e2e-test-nginx-deployment --namespace=kubectl-2381'
Nov 22 18:41:53.389: INFO: stderr: ""
Nov 22 18:41:53.389: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:41:53.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2381" for this suite.
Nov 22 18:42:17.469: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:42:17.719: INFO: namespace kubectl-2381 deletion completed in 24.30662517s

• [SLOW TEST:29.351 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:42:17.719: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Nov 22 18:42:17.868: INFO: Pod name pod-release: Found 0 pods out of 1
Nov 22 18:42:22.871: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:42:23.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-4940" for this suite.
Nov 22 18:42:29.956: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:42:30.341: INFO: namespace replication-controller-4940 deletion completed in 6.410715316s

• [SLOW TEST:12.622 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:42:30.341: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Nov 22 18:42:30.457: INFO: PodSpec: initContainers in spec.initContainers
Nov 22 18:43:18.164: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-34c1234e-a80f-468a-a30a-937574fa4335", GenerateName:"", Namespace:"init-container-4471", SelfLink:"/api/v1/namespaces/init-container-4471/pods/pod-init-34c1234e-a80f-468a-a30a-937574fa4335", UID:"cdf081bf-847a-4f37-bad6-cbde636eaad8", ResourceVersion:"46780", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63710044950, loc:(*time.Location)(0x7ec7a20)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"456995048"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-6qlh9", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001fdcdc0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-6qlh9", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-6qlh9", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-6qlh9", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc000b15078), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"minion", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc001cc4ba0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc000b15100)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc000b15120)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc000b15128), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc000b1512c), PreemptionPolicy:(*v1.PreemptionPolicy)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710044950, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710044950, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710044950, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710044950, loc:(*time.Location)(0x7ec7a20)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.31.44.47", PodIP:"10.251.128.8", StartTime:(*v1.Time)(0xc001ac6420), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002494460)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002494540)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://7def28eeaa4b6921bb698f51808b9b3f5cd727208cdfbe04b4f32c209dd90daf"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc001ac6460), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc001ac6440), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:43:18.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4471" for this suite.
Nov 22 18:43:42.202: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:43:42.484: INFO: namespace init-container-4471 deletion completed in 24.303669276s

• [SLOW TEST:72.143 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:43:42.484: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating service multi-endpoint-test in namespace services-5901
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5901 to expose endpoints map[]
Nov 22 18:43:42.628: INFO: Get endpoints failed (4.725418ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Nov 22 18:43:43.655: INFO: successfully validated that service multi-endpoint-test in namespace services-5901 exposes endpoints map[] (1.031823955s elapsed)
STEP: Creating pod pod1 in namespace services-5901
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5901 to expose endpoints map[pod1:[100]]
Nov 22 18:43:45.780: INFO: successfully validated that service multi-endpoint-test in namespace services-5901 exposes endpoints map[pod1:[100]] (2.111216582s elapsed)
STEP: Creating pod pod2 in namespace services-5901
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5901 to expose endpoints map[pod1:[100] pod2:[101]]
Nov 22 18:43:47.988: INFO: successfully validated that service multi-endpoint-test in namespace services-5901 exposes endpoints map[pod1:[100] pod2:[101]] (2.175736629s elapsed)
STEP: Deleting pod pod1 in namespace services-5901
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5901 to expose endpoints map[pod2:[101]]
Nov 22 18:43:48.041: INFO: successfully validated that service multi-endpoint-test in namespace services-5901 exposes endpoints map[pod2:[101]] (33.559751ms elapsed)
STEP: Deleting pod pod2 in namespace services-5901
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5901 to expose endpoints map[]
Nov 22 18:43:49.084: INFO: successfully validated that service multi-endpoint-test in namespace services-5901 exposes endpoints map[] (1.030178403s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:43:49.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5901" for this suite.
Nov 22 18:44:13.213: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:44:13.563: INFO: namespace services-5901 deletion completed in 24.411498855s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:31.079 seconds]
[sig-network] Services
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:44:13.563: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on node default medium
Nov 22 18:44:13.706: INFO: Waiting up to 5m0s for pod "pod-34da948f-51e0-446b-a0c5-23380bb22403" in namespace "emptydir-3379" to be "success or failure"
Nov 22 18:44:13.712: INFO: Pod "pod-34da948f-51e0-446b-a0c5-23380bb22403": Phase="Pending", Reason="", readiness=false. Elapsed: 6.420032ms
Nov 22 18:44:15.717: INFO: Pod "pod-34da948f-51e0-446b-a0c5-23380bb22403": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011724723s
Nov 22 18:44:17.727: INFO: Pod "pod-34da948f-51e0-446b-a0c5-23380bb22403": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021099356s
STEP: Saw pod success
Nov 22 18:44:17.727: INFO: Pod "pod-34da948f-51e0-446b-a0c5-23380bb22403" satisfied condition "success or failure"
Nov 22 18:44:17.728: INFO: Trying to get logs from node minion pod pod-34da948f-51e0-446b-a0c5-23380bb22403 container test-container: <nil>
STEP: delete the pod
Nov 22 18:44:17.831: INFO: Waiting for pod pod-34da948f-51e0-446b-a0c5-23380bb22403 to disappear
Nov 22 18:44:17.840: INFO: Pod pod-34da948f-51e0-446b-a0c5-23380bb22403 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:44:17.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3379" for this suite.
Nov 22 18:44:23.890: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:44:24.109: INFO: namespace emptydir-3379 deletion completed in 6.267854679s

• [SLOW TEST:10.546 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:44:24.110: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-1f47bec2-a759-41ac-8bae-9a90df05fa73
STEP: Creating a pod to test consume secrets
Nov 22 18:44:24.236: INFO: Waiting up to 5m0s for pod "pod-secrets-decceb56-ef2b-4047-972d-e392acb3d687" in namespace "secrets-9754" to be "success or failure"
Nov 22 18:44:24.266: INFO: Pod "pod-secrets-decceb56-ef2b-4047-972d-e392acb3d687": Phase="Pending", Reason="", readiness=false. Elapsed: 29.739443ms
Nov 22 18:44:26.268: INFO: Pod "pod-secrets-decceb56-ef2b-4047-972d-e392acb3d687": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031693406s
Nov 22 18:44:28.278: INFO: Pod "pod-secrets-decceb56-ef2b-4047-972d-e392acb3d687": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.041970168s
STEP: Saw pod success
Nov 22 18:44:28.278: INFO: Pod "pod-secrets-decceb56-ef2b-4047-972d-e392acb3d687" satisfied condition "success or failure"
Nov 22 18:44:28.280: INFO: Trying to get logs from node minion pod pod-secrets-decceb56-ef2b-4047-972d-e392acb3d687 container secret-volume-test: <nil>
STEP: delete the pod
Nov 22 18:44:28.328: INFO: Waiting for pod pod-secrets-decceb56-ef2b-4047-972d-e392acb3d687 to disappear
Nov 22 18:44:28.341: INFO: Pod pod-secrets-decceb56-ef2b-4047-972d-e392acb3d687 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:44:28.342: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9754" for this suite.
Nov 22 18:44:34.379: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:44:34.682: INFO: namespace secrets-9754 deletion completed in 6.337894614s

• [SLOW TEST:10.572 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:44:34.682: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1517
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Nov 22 18:44:34.782: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-6246'
Nov 22 18:44:36.343: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Nov 22 18:44:36.343: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Nov 22 18:44:36.363: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Nov 22 18:44:36.415: INFO: scanned /root for discovery docs: <nil>
Nov 22 18:44:36.415: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-6246'
Nov 22 18:44:49.686: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Nov 22 18:44:49.686: INFO: stdout: "Created e2e-test-nginx-rc-93f42aed64ab157a3f068700d8ce64a5\nScaling up e2e-test-nginx-rc-93f42aed64ab157a3f068700d8ce64a5 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-93f42aed64ab157a3f068700d8ce64a5 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-93f42aed64ab157a3f068700d8ce64a5 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Nov 22 18:44:49.686: INFO: stdout: "Created e2e-test-nginx-rc-93f42aed64ab157a3f068700d8ce64a5\nScaling up e2e-test-nginx-rc-93f42aed64ab157a3f068700d8ce64a5 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-93f42aed64ab157a3f068700d8ce64a5 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-93f42aed64ab157a3f068700d8ce64a5 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Nov 22 18:44:49.686: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-6246'
Nov 22 18:44:50.137: INFO: stderr: ""
Nov 22 18:44:50.137: INFO: stdout: "e2e-test-nginx-rc-93f42aed64ab157a3f068700d8ce64a5-kv5ns e2e-test-nginx-rc-pwvk9 "
STEP: Replicas for run=e2e-test-nginx-rc: expected=1 actual=2
Nov 22 18:44:55.145: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-6246'
Nov 22 18:44:55.479: INFO: stderr: ""
Nov 22 18:44:55.479: INFO: stdout: "e2e-test-nginx-rc-93f42aed64ab157a3f068700d8ce64a5-kv5ns "
Nov 22 18:44:55.479: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 get pods e2e-test-nginx-rc-93f42aed64ab157a3f068700d8ce64a5-kv5ns -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6246'
Nov 22 18:44:55.815: INFO: stderr: ""
Nov 22 18:44:55.815: INFO: stdout: "true"
Nov 22 18:44:55.815: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 get pods e2e-test-nginx-rc-93f42aed64ab157a3f068700d8ce64a5-kv5ns -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6246'
Nov 22 18:44:56.207: INFO: stderr: ""
Nov 22 18:44:56.207: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Nov 22 18:44:56.207: INFO: e2e-test-nginx-rc-93f42aed64ab157a3f068700d8ce64a5-kv5ns is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1523
Nov 22 18:44:56.207: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 delete rc e2e-test-nginx-rc --namespace=kubectl-6246'
Nov 22 18:44:56.686: INFO: stderr: ""
Nov 22 18:44:56.686: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:44:56.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6246" for this suite.
Nov 22 18:45:02.716: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:45:02.935: INFO: namespace kubectl-6246 deletion completed in 6.226333868s

• [SLOW TEST:28.253 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:45:02.936: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Nov 22 18:45:03.029: INFO: (0) /api/v1/nodes/minion/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 3.899628ms)
Nov 22 18:45:03.048: INFO: (1) /api/v1/nodes/minion/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 18.821238ms)
Nov 22 18:45:03.051: INFO: (2) /api/v1/nodes/minion/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.196529ms)
Nov 22 18:45:03.075: INFO: (3) /api/v1/nodes/minion/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 24.615416ms)
Nov 22 18:45:03.078: INFO: (4) /api/v1/nodes/minion/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.376377ms)
Nov 22 18:45:03.088: INFO: (5) /api/v1/nodes/minion/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 10.0415ms)
Nov 22 18:45:03.090: INFO: (6) /api/v1/nodes/minion/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.361704ms)
Nov 22 18:45:03.092: INFO: (7) /api/v1/nodes/minion/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.205486ms)
Nov 22 18:45:03.095: INFO: (8) /api/v1/nodes/minion/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.149801ms)
Nov 22 18:45:03.109: INFO: (9) /api/v1/nodes/minion/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 14.560809ms)
Nov 22 18:45:03.111: INFO: (10) /api/v1/nodes/minion/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.166752ms)
Nov 22 18:45:03.126: INFO: (11) /api/v1/nodes/minion/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 14.33361ms)
Nov 22 18:45:03.128: INFO: (12) /api/v1/nodes/minion/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 1.987031ms)
Nov 22 18:45:03.138: INFO: (13) /api/v1/nodes/minion/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 10.568672ms)
Nov 22 18:45:03.149: INFO: (14) /api/v1/nodes/minion/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 10.24343ms)
Nov 22 18:45:03.151: INFO: (15) /api/v1/nodes/minion/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.522768ms)
Nov 22 18:45:03.166: INFO: (16) /api/v1/nodes/minion/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 14.896828ms)
Nov 22 18:45:03.193: INFO: (17) /api/v1/nodes/minion/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 26.787315ms)
Nov 22 18:45:03.195: INFO: (18) /api/v1/nodes/minion/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.346981ms)
Nov 22 18:45:03.210: INFO: (19) /api/v1/nodes/minion/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 14.125318ms)
[AfterEach] version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:45:03.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-470" for this suite.
Nov 22 18:45:09.238: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:45:09.298: INFO: namespace proxy-470 deletion completed in 6.086999812s

• [SLOW TEST:6.362 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:45:09.299: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-0c0f2409-6740-4522-905f-5b38295024a7
STEP: Creating a pod to test consume secrets
Nov 22 18:45:09.414: INFO: Waiting up to 5m0s for pod "pod-secrets-c40c9cfd-abc8-4411-b761-ffcedb205e2c" in namespace "secrets-7222" to be "success or failure"
Nov 22 18:45:09.417: INFO: Pod "pod-secrets-c40c9cfd-abc8-4411-b761-ffcedb205e2c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.159724ms
Nov 22 18:45:11.419: INFO: Pod "pod-secrets-c40c9cfd-abc8-4411-b761-ffcedb205e2c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004682149s
STEP: Saw pod success
Nov 22 18:45:11.419: INFO: Pod "pod-secrets-c40c9cfd-abc8-4411-b761-ffcedb205e2c" satisfied condition "success or failure"
Nov 22 18:45:11.420: INFO: Trying to get logs from node minion pod pod-secrets-c40c9cfd-abc8-4411-b761-ffcedb205e2c container secret-volume-test: <nil>
STEP: delete the pod
Nov 22 18:45:11.435: INFO: Waiting for pod pod-secrets-c40c9cfd-abc8-4411-b761-ffcedb205e2c to disappear
Nov 22 18:45:11.443: INFO: Pod pod-secrets-c40c9cfd-abc8-4411-b761-ffcedb205e2c no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:45:11.443: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7222" for this suite.
Nov 22 18:45:17.450: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:45:17.523: INFO: namespace secrets-7222 deletion completed in 6.078286468s
STEP: Destroying namespace "secret-namespace-3970" for this suite.
Nov 22 18:45:23.529: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:45:23.601: INFO: namespace secret-namespace-3970 deletion completed in 6.077668533s

• [SLOW TEST:14.303 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:45:23.602: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod busybox-4851d157-2b13-419e-a447-cc1a6252fb89 in namespace container-probe-6538
Nov 22 18:45:25.636: INFO: Started pod busybox-4851d157-2b13-419e-a447-cc1a6252fb89 in namespace container-probe-6538
STEP: checking the pod's current state and verifying that restartCount is present
Nov 22 18:45:25.637: INFO: Initial restart count of pod busybox-4851d157-2b13-419e-a447-cc1a6252fb89 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:49:26.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6538" for this suite.
Nov 22 18:49:32.507: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:49:32.788: INFO: namespace container-probe-6538 deletion completed in 6.31565353s

• [SLOW TEST:249.186 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:49:32.788: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Nov 22 18:49:32.879: INFO: Waiting up to 5m0s for pod "downwardapi-volume-93e9e9da-765d-49bc-b555-e4e4d6ca14d1" in namespace "downward-api-9242" to be "success or failure"
Nov 22 18:49:32.881: INFO: Pod "downwardapi-volume-93e9e9da-765d-49bc-b555-e4e4d6ca14d1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.396488ms
Nov 22 18:49:34.890: INFO: Pod "downwardapi-volume-93e9e9da-765d-49bc-b555-e4e4d6ca14d1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011526585s
STEP: Saw pod success
Nov 22 18:49:34.890: INFO: Pod "downwardapi-volume-93e9e9da-765d-49bc-b555-e4e4d6ca14d1" satisfied condition "success or failure"
Nov 22 18:49:34.892: INFO: Trying to get logs from node minion pod downwardapi-volume-93e9e9da-765d-49bc-b555-e4e4d6ca14d1 container client-container: <nil>
STEP: delete the pod
Nov 22 18:49:34.958: INFO: Waiting for pod downwardapi-volume-93e9e9da-765d-49bc-b555-e4e4d6ca14d1 to disappear
Nov 22 18:49:34.961: INFO: Pod downwardapi-volume-93e9e9da-765d-49bc-b555-e4e4d6ca14d1 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:49:34.961: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9242" for this suite.
Nov 22 18:49:40.990: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:49:41.362: INFO: namespace downward-api-9242 deletion completed in 6.390930652s

• [SLOW TEST:8.574 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:49:41.362: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Nov 22 18:49:41.466: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bb4e3631-6a34-4553-8e72-9b148fbcc255" in namespace "projected-4310" to be "success or failure"
Nov 22 18:49:41.499: INFO: Pod "downwardapi-volume-bb4e3631-6a34-4553-8e72-9b148fbcc255": Phase="Pending", Reason="", readiness=false. Elapsed: 32.71545ms
Nov 22 18:49:43.509: INFO: Pod "downwardapi-volume-bb4e3631-6a34-4553-8e72-9b148fbcc255": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.042606381s
STEP: Saw pod success
Nov 22 18:49:43.509: INFO: Pod "downwardapi-volume-bb4e3631-6a34-4553-8e72-9b148fbcc255" satisfied condition "success or failure"
Nov 22 18:49:43.510: INFO: Trying to get logs from node minion pod downwardapi-volume-bb4e3631-6a34-4553-8e72-9b148fbcc255 container client-container: <nil>
STEP: delete the pod
Nov 22 18:49:43.542: INFO: Waiting for pod downwardapi-volume-bb4e3631-6a34-4553-8e72-9b148fbcc255 to disappear
Nov 22 18:49:43.562: INFO: Pod downwardapi-volume-bb4e3631-6a34-4553-8e72-9b148fbcc255 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:49:43.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4310" for this suite.
Nov 22 18:49:49.648: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:49:50.029: INFO: namespace projected-4310 deletion completed in 6.464678915s

• [SLOW TEST:8.666 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:49:50.029: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-4272.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-4272.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4272.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-4272.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-4272.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4272.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov 22 18:49:52.203: INFO: DNS probes using dns-4272/dns-test-5f518288-48f3-4667-8251-09c19051f1dd succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:49:52.250: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4272" for this suite.
Nov 22 18:49:58.306: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:49:58.540: INFO: namespace dns-4272 deletion completed in 6.27037289s

• [SLOW TEST:8.511 seconds]
[sig-network] DNS
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:49:58.540: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-ddc414e2-a981-434d-a162-3f6f54af2d1d
STEP: Creating a pod to test consume configMaps
Nov 22 18:49:58.665: INFO: Waiting up to 5m0s for pod "pod-configmaps-f19b88c4-c3a1-4102-9113-a66a9f8b06e8" in namespace "configmap-2575" to be "success or failure"
Nov 22 18:49:58.675: INFO: Pod "pod-configmaps-f19b88c4-c3a1-4102-9113-a66a9f8b06e8": Phase="Pending", Reason="", readiness=false. Elapsed: 9.782339ms
Nov 22 18:50:00.699: INFO: Pod "pod-configmaps-f19b88c4-c3a1-4102-9113-a66a9f8b06e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.034553336s
STEP: Saw pod success
Nov 22 18:50:00.699: INFO: Pod "pod-configmaps-f19b88c4-c3a1-4102-9113-a66a9f8b06e8" satisfied condition "success or failure"
Nov 22 18:50:00.701: INFO: Trying to get logs from node minion pod pod-configmaps-f19b88c4-c3a1-4102-9113-a66a9f8b06e8 container configmap-volume-test: <nil>
STEP: delete the pod
Nov 22 18:50:00.754: INFO: Waiting for pod pod-configmaps-f19b88c4-c3a1-4102-9113-a66a9f8b06e8 to disappear
Nov 22 18:50:00.768: INFO: Pod pod-configmaps-f19b88c4-c3a1-4102-9113-a66a9f8b06e8 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:50:00.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2575" for this suite.
Nov 22 18:50:06.806: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:50:07.143: INFO: namespace configmap-2575 deletion completed in 6.358151616s

• [SLOW TEST:8.602 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:50:07.143: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1613
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Nov 22 18:50:07.220: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-3174'
Nov 22 18:50:07.560: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Nov 22 18:50:07.560: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1618
Nov 22 18:50:07.582: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 delete jobs e2e-test-nginx-job --namespace=kubectl-3174'
Nov 22 18:50:07.997: INFO: stderr: ""
Nov 22 18:50:07.998: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:50:07.998: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3174" for this suite.
Nov 22 18:50:30.048: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:50:30.235: INFO: namespace kubectl-3174 deletion completed in 22.2280667s

• [SLOW TEST:23.092 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run job
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:50:30.236: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: validating api versions
Nov 22 18:50:30.257: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 api-versions'
Nov 22 18:50:30.375: INFO: stderr: ""
Nov 22 18:50:30.375: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\nceph.rook.io/v1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nrook.io/v1alpha2\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:50:30.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3923" for this suite.
Nov 22 18:50:36.385: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:50:36.449: INFO: namespace kubectl-3923 deletion completed in 6.071269546s

• [SLOW TEST:6.213 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:50:36.449: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-3116
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating stateful set ss in namespace statefulset-3116
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-3116
Nov 22 18:50:36.499: INFO: Found 0 stateful pods, waiting for 1
Nov 22 18:50:46.502: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Nov 22 18:50:46.504: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-3116 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov 22 18:50:46.684: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Nov 22 18:50:46.684: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov 22 18:50:46.684: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov 22 18:50:46.687: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Nov 22 18:50:56.690: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov 22 18:50:56.690: INFO: Waiting for statefulset status.replicas updated to 0
Nov 22 18:50:56.699: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Nov 22 18:50:56.699: INFO: ss-0  minion  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:50:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:50:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:50:47 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:50:36 +0000 UTC  }]
Nov 22 18:50:56.699: INFO: 
Nov 22 18:50:56.699: INFO: StatefulSet ss has not reached scale 3, at 1
Nov 22 18:50:57.702: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996207703s
Nov 22 18:50:58.704: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.993891076s
Nov 22 18:50:59.706: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.991503073s
Nov 22 18:51:00.709: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.989385818s
Nov 22 18:51:01.711: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.986865938s
Nov 22 18:51:02.713: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.984636309s
Nov 22 18:51:03.716: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.982317753s
Nov 22 18:51:04.718: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.979818637s
Nov 22 18:51:05.720: INFO: Verifying statefulset ss doesn't scale past 3 for another 977.295625ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-3116
Nov 22 18:51:06.723: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-3116 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 18:51:06.905: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Nov 22 18:51:06.905: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov 22 18:51:06.905: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Nov 22 18:51:06.905: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-3116 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 18:51:07.110: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Nov 22 18:51:07.110: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov 22 18:51:07.110: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Nov 22 18:51:07.110: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-3116 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 18:51:07.306: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Nov 22 18:51:07.306: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov 22 18:51:07.306: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Nov 22 18:51:07.310: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 22 18:51:07.310: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Nov 22 18:51:07.310: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Nov 22 18:51:07.312: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-3116 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov 22 18:51:07.520: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Nov 22 18:51:07.520: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov 22 18:51:07.520: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov 22 18:51:07.520: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-3116 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov 22 18:51:07.713: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Nov 22 18:51:07.714: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov 22 18:51:07.714: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov 22 18:51:07.714: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-3116 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov 22 18:51:07.945: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Nov 22 18:51:07.945: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov 22 18:51:07.945: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov 22 18:51:07.945: INFO: Waiting for statefulset status.replicas updated to 0
Nov 22 18:51:07.948: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Nov 22 18:51:17.971: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov 22 18:51:17.971: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Nov 22 18:51:17.971: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Nov 22 18:51:18.005: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Nov 22 18:51:18.005: INFO: ss-0  minion  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:50:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:51:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:51:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:50:36 +0000 UTC  }]
Nov 22 18:51:18.005: INFO: ss-1  minion  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:50:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:51:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:51:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:50:56 +0000 UTC  }]
Nov 22 18:51:18.005: INFO: ss-2  minion  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:50:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:51:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:51:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:50:56 +0000 UTC  }]
Nov 22 18:51:18.005: INFO: 
Nov 22 18:51:18.005: INFO: StatefulSet ss has not reached scale 0, at 3
Nov 22 18:51:19.007: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Nov 22 18:51:19.007: INFO: ss-0  minion  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:50:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:51:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:51:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:50:36 +0000 UTC  }]
Nov 22 18:51:19.007: INFO: ss-1  minion  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:50:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:51:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:51:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:50:56 +0000 UTC  }]
Nov 22 18:51:19.008: INFO: ss-2  minion  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:50:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:51:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:51:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:50:56 +0000 UTC  }]
Nov 22 18:51:19.008: INFO: 
Nov 22 18:51:19.008: INFO: StatefulSet ss has not reached scale 0, at 3
Nov 22 18:51:20.027: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Nov 22 18:51:20.027: INFO: ss-0  minion  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:50:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:51:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:51:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:50:36 +0000 UTC  }]
Nov 22 18:51:20.027: INFO: ss-1  minion  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:50:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:51:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:51:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:50:56 +0000 UTC  }]
Nov 22 18:51:20.027: INFO: ss-2  minion  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:50:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:51:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:51:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:50:56 +0000 UTC  }]
Nov 22 18:51:20.027: INFO: 
Nov 22 18:51:20.027: INFO: StatefulSet ss has not reached scale 0, at 3
Nov 22 18:51:21.034: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Nov 22 18:51:21.034: INFO: ss-0  minion  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:50:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:51:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:51:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:50:36 +0000 UTC  }]
Nov 22 18:51:21.034: INFO: ss-1  minion  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:50:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:51:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:51:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:50:56 +0000 UTC  }]
Nov 22 18:51:21.034: INFO: ss-2  minion  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:50:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:51:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:51:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:50:56 +0000 UTC  }]
Nov 22 18:51:21.034: INFO: 
Nov 22 18:51:21.034: INFO: StatefulSet ss has not reached scale 0, at 3
Nov 22 18:51:22.049: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Nov 22 18:51:22.049: INFO: ss-0  minion  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:50:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:51:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:51:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:50:36 +0000 UTC  }]
Nov 22 18:51:22.049: INFO: ss-1  minion  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:50:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:51:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:51:07 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:50:56 +0000 UTC  }]
Nov 22 18:51:22.049: INFO: ss-2  minion  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:50:56 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:51:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:51:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:50:56 +0000 UTC  }]
Nov 22 18:51:22.049: INFO: 
Nov 22 18:51:22.049: INFO: StatefulSet ss has not reached scale 0, at 3
Nov 22 18:51:23.053: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Nov 22 18:51:23.053: INFO: ss-0  minion  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:50:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:51:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:51:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:50:36 +0000 UTC  }]
Nov 22 18:51:23.053: INFO: 
Nov 22 18:51:23.053: INFO: StatefulSet ss has not reached scale 0, at 1
Nov 22 18:51:24.072: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Nov 22 18:51:24.072: INFO: ss-0  minion  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:50:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:51:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:51:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:50:36 +0000 UTC  }]
Nov 22 18:51:24.072: INFO: 
Nov 22 18:51:24.072: INFO: StatefulSet ss has not reached scale 0, at 1
Nov 22 18:51:25.080: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Nov 22 18:51:25.081: INFO: ss-0  minion  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:50:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:51:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:51:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:50:36 +0000 UTC  }]
Nov 22 18:51:25.081: INFO: 
Nov 22 18:51:25.081: INFO: StatefulSet ss has not reached scale 0, at 1
Nov 22 18:51:26.095: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Nov 22 18:51:26.095: INFO: ss-0  minion  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:50:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:51:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:51:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:50:36 +0000 UTC  }]
Nov 22 18:51:26.095: INFO: 
Nov 22 18:51:26.095: INFO: StatefulSet ss has not reached scale 0, at 1
Nov 22 18:51:27.104: INFO: POD   NODE    PHASE    GRACE  CONDITIONS
Nov 22 18:51:27.104: INFO: ss-0  minion  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:50:36 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:51:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:51:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 18:50:36 +0000 UTC  }]
Nov 22 18:51:27.104: INFO: 
Nov 22 18:51:27.104: INFO: StatefulSet ss has not reached scale 0, at 1
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-3116
Nov 22 18:51:28.107: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-3116 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 18:51:28.619: INFO: rc: 1
Nov 22 18:51:28.619: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-3116 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc0012731a0 exit status 1 <nil> <nil> true [0xc0021b4080 0xc0021b40a0 0xc0021b40c8] [0xc0021b4080 0xc0021b40a0 0xc0021b40c8] [0xc0021b4098 0xc0021b40b8] [0x9d21f0 0x9d21f0] 0xc00251eba0 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1
Nov 22 18:51:38.620: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-3116 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 18:51:39.105: INFO: rc: 1
Nov 22 18:51:39.105: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-3116 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0032124b0 exit status 1 <nil> <nil> true [0xc002d02130 0xc002d02178 0xc002d021b8] [0xc002d02130 0xc002d02178 0xc002d021b8] [0xc002d02160 0xc002d02188] [0x9d21f0 0x9d21f0] 0xc001d444e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Nov 22 18:51:49.105: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-3116 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 18:51:49.701: INFO: rc: 1
Nov 22 18:51:49.701: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-3116 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0032e6510 exit status 1 <nil> <nil> true [0xc0023c0048 0xc0023c0170 0xc0023c0208] [0xc0023c0048 0xc0023c0170 0xc0023c0208] [0xc0023c0108 0xc0023c01c0] [0x9d21f0 0x9d21f0] 0xc0021aca20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Nov 22 18:51:59.704: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-3116 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 18:52:00.095: INFO: rc: 1
Nov 22 18:52:00.096: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-3116 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001273530 exit status 1 <nil> <nil> true [0xc0021b40d8 0xc0021b40f0 0xc0021b4120] [0xc0021b40d8 0xc0021b40f0 0xc0021b4120] [0xc0021b40e8 0xc0021b4110] [0x9d21f0 0x9d21f0] 0xc00251f2c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Nov 22 18:52:10.096: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-3116 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 18:52:10.555: INFO: rc: 1
Nov 22 18:52:10.555: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-3116 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc003212810 exit status 1 <nil> <nil> true [0xc002d02200 0xc002d02230 0xc002d02260] [0xc002d02200 0xc002d02230 0xc002d02260] [0xc002d02220 0xc002d02258] [0x9d21f0 0x9d21f0] 0xc001d44840 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Nov 22 18:52:20.560: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-3116 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 18:52:20.949: INFO: rc: 1
Nov 22 18:52:20.949: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-3116 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001273860 exit status 1 <nil> <nil> true [0xc0021b4128 0xc0021b4170 0xc0021b41b8] [0xc0021b4128 0xc0021b4170 0xc0021b41b8] [0xc0021b4158 0xc0021b41a0] [0x9d21f0 0x9d21f0] 0xc00251f920 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Nov 22 18:52:30.962: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-3116 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 18:52:31.355: INFO: rc: 1
Nov 22 18:52:31.355: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-3116 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00195af30 exit status 1 <nil> <nil> true [0xc0018e0400 0xc0018e04b8 0xc0018e0550] [0xc0018e0400 0xc0018e04b8 0xc0018e0550] [0xc0018e0490 0xc0018e0500] [0x9d21f0 0x9d21f0] 0xc003186720 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Nov 22 18:52:41.355: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-3116 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 18:52:41.714: INFO: rc: 1
Nov 22 18:52:41.714: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-3116 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001273bc0 exit status 1 <nil> <nil> true [0xc0021b41d0 0xc0021b4230 0xc0021b4280] [0xc0021b41d0 0xc0021b4230 0xc0021b4280] [0xc0021b4210 0xc0021b4260] [0x9d21f0 0x9d21f0] 0xc00344a060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Nov 22 18:52:51.727: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-3116 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 18:52:52.089: INFO: rc: 1
Nov 22 18:52:52.089: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-3116 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001273f20 exit status 1 <nil> <nil> true [0xc0021b42a0 0xc0021b42f8 0xc0021b4360] [0xc0021b42a0 0xc0021b42f8 0xc0021b4360] [0xc0021b42e0 0xc0021b4340] [0x9d21f0 0x9d21f0] 0xc00344a3c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Nov 22 18:53:02.094: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-3116 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 18:53:02.463: INFO: rc: 1
Nov 22 18:53:02.463: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-3116 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0024f42d0 exit status 1 <nil> <nil> true [0xc0021b4378 0xc0021b43b8 0xc0021b43e8] [0xc0021b4378 0xc0021b43b8 0xc0021b43e8] [0xc0021b43a0 0xc0021b43d8] [0x9d21f0 0x9d21f0] 0xc00344a720 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Nov 22 18:53:12.472: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-3116 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 18:53:12.851: INFO: rc: 1
Nov 22 18:53:12.851: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-3116 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00195b320 exit status 1 <nil> <nil> true [0xc0018e0580 0xc0018e0648 0xc0018e0740] [0xc0018e0580 0xc0018e0648 0xc0018e0740] [0xc0018e05f0 0xc0018e06f8] [0x9d21f0 0x9d21f0] 0xc003186f60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Nov 22 18:53:22.851: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-3116 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 18:53:23.190: INFO: rc: 1
Nov 22 18:53:23.190: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-3116 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0032e6900 exit status 1 <nil> <nil> true [0xc0023c0260 0xc0023c02f8 0xc0023c0398] [0xc0023c0260 0xc0023c02f8 0xc0023c0398] [0xc0023c0298 0xc0023c0368] [0x9d21f0 0x9d21f0] 0xc0021ad5c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Nov 22 18:53:33.190: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-3116 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 18:53:33.612: INFO: rc: 1
Nov 22 18:53:33.612: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-3116 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0032e6540 exit status 1 <nil> <nil> true [0xc0023c00b0 0xc0023c0198 0xc0023c0260] [0xc0023c00b0 0xc0023c0198 0xc0023c0260] [0xc0023c0170 0xc0023c0208] [0x9d21f0 0x9d21f0] 0xc0021aca20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Nov 22 18:53:43.615: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-3116 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 18:53:43.950: INFO: rc: 1
Nov 22 18:53:43.950: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-3116 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0032e6870 exit status 1 <nil> <nil> true [0xc0023c0280 0xc0023c0328 0xc0023c03d0] [0xc0023c0280 0xc0023c0328 0xc0023c03d0] [0xc0023c02f8 0xc0023c0398] [0x9d21f0 0x9d21f0] 0xc0021ad5c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Nov 22 18:53:53.950: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-3116 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 18:53:54.331: INFO: rc: 1
Nov 22 18:53:54.331: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-3116 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0032e6c00 exit status 1 <nil> <nil> true [0xc0023c0400 0xc0023c0480 0xc0023c04f0] [0xc0023c0400 0xc0023c0480 0xc0023c04f0] [0xc0023c0440 0xc0023c04d8] [0x9d21f0 0x9d21f0] 0xc00344a0c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Nov 22 18:54:04.331: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-3116 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 18:54:04.787: INFO: rc: 1
Nov 22 18:54:04.787: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-3116 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0024f43c0 exit status 1 <nil> <nil> true [0xc0021b4000 0xc0021b4018 0xc0021b4048] [0xc0021b4000 0xc0021b4018 0xc0021b4048] [0xc0021b4010 0xc0021b4038] [0x9d21f0 0x9d21f0] 0xc00251e540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Nov 22 18:54:14.787: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-3116 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 18:54:15.172: INFO: rc: 1
Nov 22 18:54:15.172: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-3116 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0032e6f30 exit status 1 <nil> <nil> true [0xc0023c0518 0xc0023c05b0 0xc0023c0630] [0xc0023c0518 0xc0023c05b0 0xc0023c0630] [0xc0023c0580 0xc0023c0608] [0x9d21f0 0x9d21f0] 0xc00344a420 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Nov 22 18:54:25.172: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-3116 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 18:54:25.619: INFO: rc: 1
Nov 22 18:54:25.619: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-3116 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0024f4780 exit status 1 <nil> <nil> true [0xc0021b4050 0xc0021b4070 0xc0021b4098] [0xc0021b4050 0xc0021b4070 0xc0021b4098] [0xc0021b4060 0xc0021b4090] [0x9d21f0 0x9d21f0] 0xc00251ec00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Nov 22 18:54:35.622: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-3116 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 18:54:37.227: INFO: rc: 1
Nov 22 18:54:37.227: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-3116 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001272330 exit status 1 <nil> <nil> true [0xc0018e0080 0xc0018e0168 0xc0018e0340] [0xc0018e0080 0xc0018e0168 0xc0018e0340] [0xc0018e0140 0xc0018e0218] [0x9d21f0 0x9d21f0] 0xc003186360 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Nov 22 18:54:47.228: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-3116 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 18:54:47.566: INFO: rc: 1
Nov 22 18:54:47.566: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-3116 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0024f4ab0 exit status 1 <nil> <nil> true [0xc0021b40a0 0xc0021b40c8 0xc0021b40e8] [0xc0021b40a0 0xc0021b40c8 0xc0021b40e8] [0xc0021b40b8 0xc0021b40e0] [0x9d21f0 0x9d21f0] 0xc00251f380 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Nov 22 18:54:57.576: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-3116 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 18:54:57.955: INFO: rc: 1
Nov 22 18:54:57.955: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-3116 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0024f4de0 exit status 1 <nil> <nil> true [0xc0021b40f0 0xc0021b4120 0xc0021b4158] [0xc0021b40f0 0xc0021b4120 0xc0021b4158] [0xc0021b4110 0xc0021b4138] [0x9d21f0 0x9d21f0] 0xc00251f9e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Nov 22 18:55:07.955: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-3116 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 18:55:08.316: INFO: rc: 1
Nov 22 18:55:08.316: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-3116 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0024f51d0 exit status 1 <nil> <nil> true [0xc0021b4170 0xc0021b41b8 0xc0021b4210] [0xc0021b4170 0xc0021b41b8 0xc0021b4210] [0xc0021b41a0 0xc0021b41f0] [0x9d21f0 0x9d21f0] 0xc001d440c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Nov 22 18:55:18.316: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-3116 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 18:55:18.406: INFO: rc: 1
Nov 22 18:55:18.406: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-3116 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0012726f0 exit status 1 <nil> <nil> true [0xc0018e03a0 0xc0018e0400 0xc0018e04b8] [0xc0018e03a0 0xc0018e0400 0xc0018e04b8] [0xc0018e03d0 0xc0018e0490] [0x9d21f0 0x9d21f0] 0xc003186ae0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Nov 22 18:55:28.406: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-3116 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 18:55:28.496: INFO: rc: 1
Nov 22 18:55:28.496: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-3116 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0024f4330 exit status 1 <nil> <nil> true [0xc0021b4008 0xc0021b4028 0xc0021b4050] [0xc0021b4008 0xc0021b4028 0xc0021b4050] [0xc0021b4018 0xc0021b4048] [0x9d21f0 0x9d21f0] 0xc00251e540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Nov 22 18:55:38.496: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-3116 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 18:55:38.587: INFO: rc: 1
Nov 22 18:55:38.587: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-3116 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0024f46f0 exit status 1 <nil> <nil> true [0xc0021b4058 0xc0021b4080 0xc0021b40a0] [0xc0021b4058 0xc0021b4080 0xc0021b40a0] [0xc0021b4070 0xc0021b4098] [0x9d21f0 0x9d21f0] 0xc00251ec00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Nov 22 18:55:48.587: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-3116 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 18:55:48.676: INFO: rc: 1
Nov 22 18:55:48.676: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-3116 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0024f4a80 exit status 1 <nil> <nil> true [0xc0021b40a8 0xc0021b40d8 0xc0021b40f0] [0xc0021b40a8 0xc0021b40d8 0xc0021b40f0] [0xc0021b40c8 0xc0021b40e8] [0x9d21f0 0x9d21f0] 0xc00251f380 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Nov 22 18:55:58.676: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-3116 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 18:55:58.760: INFO: rc: 1
Nov 22 18:55:58.760: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-3116 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0032e6570 exit status 1 <nil> <nil> true [0xc0023c0048 0xc0023c0170 0xc0023c0208] [0xc0023c0048 0xc0023c0170 0xc0023c0208] [0xc0023c0108 0xc0023c01c0] [0x9d21f0 0x9d21f0] 0xc0021aca20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Nov 22 18:56:08.760: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-3116 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 18:56:08.910: INFO: rc: 1
Nov 22 18:56:08.910: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-3116 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc001272360 exit status 1 <nil> <nil> true [0xc0018e0080 0xc0018e0168 0xc0018e0340] [0xc0018e0080 0xc0018e0168 0xc0018e0340] [0xc0018e0140 0xc0018e0218] [0x9d21f0 0x9d21f0] 0xc001d44480 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Nov 22 18:56:18.911: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-3116 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 18:56:19.294: INFO: rc: 1
Nov 22 18:56:19.294: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-3116 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00195a330 exit status 1 <nil> <nil> true [0xc002d02010 0xc002d020b8 0xc002d02130] [0xc002d02010 0xc002d020b8 0xc002d02130] [0xc002d020a0 0xc002d02110] [0x9d21f0 0x9d21f0] 0xc00344a2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Nov 22 18:56:29.294: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-3116 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 18:56:29.637: INFO: rc: 1
Nov 22 18:56:29.637: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: 
Nov 22 18:56:29.637: INFO: Scaling statefulset ss to 0
Nov 22 18:56:29.654: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Nov 22 18:56:29.655: INFO: Deleting all statefulset in ns statefulset-3116
Nov 22 18:56:29.657: INFO: Scaling statefulset ss to 0
Nov 22 18:56:29.697: INFO: Waiting for statefulset status.replicas updated to 0
Nov 22 18:56:29.698: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:56:29.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3116" for this suite.
Nov 22 18:56:35.812: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:56:36.194: INFO: namespace statefulset-3116 deletion completed in 6.419786645s

• [SLOW TEST:359.745 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:56:36.195: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on tmpfs
Nov 22 18:56:36.296: INFO: Waiting up to 5m0s for pod "pod-e2d4da24-1937-4618-9c6e-37175dcca7cf" in namespace "emptydir-3051" to be "success or failure"
Nov 22 18:56:36.314: INFO: Pod "pod-e2d4da24-1937-4618-9c6e-37175dcca7cf": Phase="Pending", Reason="", readiness=false. Elapsed: 18.058872ms
Nov 22 18:56:38.316: INFO: Pod "pod-e2d4da24-1937-4618-9c6e-37175dcca7cf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020021221s
Nov 22 18:56:40.318: INFO: Pod "pod-e2d4da24-1937-4618-9c6e-37175dcca7cf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021955172s
STEP: Saw pod success
Nov 22 18:56:40.318: INFO: Pod "pod-e2d4da24-1937-4618-9c6e-37175dcca7cf" satisfied condition "success or failure"
Nov 22 18:56:40.319: INFO: Trying to get logs from node minion pod pod-e2d4da24-1937-4618-9c6e-37175dcca7cf container test-container: <nil>
STEP: delete the pod
Nov 22 18:56:40.373: INFO: Waiting for pod pod-e2d4da24-1937-4618-9c6e-37175dcca7cf to disappear
Nov 22 18:56:40.407: INFO: Pod pod-e2d4da24-1937-4618-9c6e-37175dcca7cf no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 18:56:40.407: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3051" for this suite.
Nov 22 18:56:48.460: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 18:56:48.803: INFO: namespace emptydir-3051 deletion completed in 8.393407779s

• [SLOW TEST:12.609 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 18:56:48.804: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-5393
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-5393
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-5393
Nov 22 18:56:48.958: INFO: Found 0 stateful pods, waiting for 1
Nov 22 18:56:58.959: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Nov 22 18:56:58.975: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-5393 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov 22 18:56:59.486: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Nov 22 18:56:59.486: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov 22 18:56:59.486: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov 22 18:56:59.489: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Nov 22 18:57:09.495: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov 22 18:57:09.495: INFO: Waiting for statefulset status.replicas updated to 0
Nov 22 18:57:09.520: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.99999856s
Nov 22 18:57:10.526: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.993315312s
Nov 22 18:57:11.536: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.982943873s
Nov 22 18:57:12.539: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.980629564s
Nov 22 18:57:13.545: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.974182542s
Nov 22 18:57:14.561: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.960483181s
Nov 22 18:57:15.573: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.956465359s
Nov 22 18:57:16.585: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.944612472s
Nov 22 18:57:17.593: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.926754575s
Nov 22 18:57:18.602: INFO: Verifying statefulset ss doesn't scale past 1 for another 924.011058ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-5393
Nov 22 18:57:19.630: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-5393 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 18:57:20.108: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Nov 22 18:57:20.108: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov 22 18:57:20.108: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Nov 22 18:57:20.110: INFO: Found 1 stateful pods, waiting for 3
Nov 22 18:57:30.115: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 22 18:57:30.115: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Nov 22 18:57:30.115: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Nov 22 18:57:30.130: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-5393 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov 22 18:57:30.616: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Nov 22 18:57:30.616: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov 22 18:57:30.616: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov 22 18:57:30.637: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-5393 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov 22 18:57:31.231: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Nov 22 18:57:31.231: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov 22 18:57:31.231: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov 22 18:57:31.231: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-5393 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov 22 18:57:31.769: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Nov 22 18:57:31.769: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov 22 18:57:31.769: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov 22 18:57:31.769: INFO: Waiting for statefulset status.replicas updated to 0
Nov 22 18:57:31.770: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Nov 22 18:57:41.783: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov 22 18:57:41.783: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Nov 22 18:57:41.783: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Nov 22 18:57:41.833: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999998575s
Nov 22 18:57:42.838: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.982006156s
Nov 22 18:57:43.855: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.964428537s
Nov 22 18:57:44.858: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.96158758s
Nov 22 18:57:45.874: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.94449337s
Nov 22 18:57:46.877: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.942111255s
Nov 22 18:57:47.883: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.939594918s
Nov 22 18:57:48.930: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.916944577s
Nov 22 18:57:49.943: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.878387904s
Nov 22 18:57:50.953: INFO: Verifying statefulset ss doesn't scale past 3 for another 873.779477ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-5393
Nov 22 18:57:51.958: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-5393 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 18:57:52.485: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Nov 22 18:57:52.485: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov 22 18:57:52.485: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Nov 22 18:57:52.485: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-5393 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 18:57:53.072: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Nov 22 18:57:53.072: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov 22 18:57:53.072: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Nov 22 18:57:53.072: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-5393 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 18:57:53.593: INFO: rc: 1
Nov 22 18:57:53.594: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-5393 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  error: unable to upgrade connection: container not found ("nginx")
 [] <nil> 0xc003ea5e60 exit status 1 <nil> <nil> true [0xc0023c0368 0xc0023c0400 0xc0023c0480] [0xc0023c0368 0xc0023c0400 0xc0023c0480] [0xc0023c03d0 0xc0023c0440] [0x9d21f0 0x9d21f0] 0xc001d45860 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("nginx")

error:
exit status 1
Nov 22 18:58:03.601: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-5393 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 18:58:03.979: INFO: rc: 1
Nov 22 18:58:03.979: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-5393 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0020011d0 exit status 1 <nil> <nil> true [0xc0018e0cc0 0xc0018e0d58 0xc0018e0da0] [0xc0018e0cc0 0xc0018e0d58 0xc0018e0da0] [0xc0018e0d48 0xc0018e0d70] [0x9d21f0 0x9d21f0] 0xc003187a40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov 22 18:58:13.979: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-5393 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 18:58:14.414: INFO: rc: 1
Nov 22 18:58:14.414: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-5393 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0020015c0 exit status 1 <nil> <nil> true [0xc0018e0dd0 0xc0018e0e08 0xc0018e0eb8] [0xc0018e0dd0 0xc0018e0e08 0xc0018e0eb8] [0xc0018e0de0 0xc0018e0ea0] [0x9d21f0 0x9d21f0] 0xc003187da0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov 22 18:58:24.418: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-5393 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 18:58:24.712: INFO: rc: 1
Nov 22 18:58:24.712: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-5393 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc003472210 exit status 1 <nil> <nil> true [0xc0023c0490 0xc0023c0518 0xc0023c05b0] [0xc0023c0490 0xc0023c0518 0xc0023c05b0] [0xc0023c04f0 0xc0023c0580] [0x9d21f0 0x9d21f0] 0xc001d45f20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov 22 18:58:34.718: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-5393 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 18:58:35.067: INFO: rc: 1
Nov 22 18:58:35.067: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-5393 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002001920 exit status 1 <nil> <nil> true [0xc0018e0ec8 0xc0018e0f20 0xc0018e0fe0] [0xc0018e0ec8 0xc0018e0f20 0xc0018e0fe0] [0xc0018e0ee8 0xc0018e0fb8] [0x9d21f0 0x9d21f0] 0xc00252e780 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov 22 18:58:45.067: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-5393 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 18:58:45.467: INFO: rc: 1
Nov 22 18:58:45.467: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-5393 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc003472570 exit status 1 <nil> <nil> true [0xc0023c05c8 0xc0023c0668 0xc0023c06d8] [0xc0023c05c8 0xc0023c0668 0xc0023c06d8] [0xc0023c0630 0xc0023c06b0] [0x9d21f0 0x9d21f0] 0xc0021acba0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov 22 18:58:55.471: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-5393 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 18:58:55.822: INFO: rc: 1
Nov 22 18:58:55.822: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-5393 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0034728d0 exit status 1 <nil> <nil> true [0xc0023c0708 0xc0023c0788 0xc0023c07e8] [0xc0023c0708 0xc0023c0788 0xc0023c07e8] [0xc0023c0768 0xc0023c07c8] [0x9d21f0 0x9d21f0] 0xc0021ad740 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov 22 18:59:05.823: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-5393 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 18:59:06.212: INFO: rc: 1
Nov 22 18:59:06.212: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-5393 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002001c80 exit status 1 <nil> <nil> true [0xc0018e1028 0xc0018e10a8 0xc0018e11a0] [0xc0018e1028 0xc0018e10a8 0xc0018e11a0] [0xc0018e1060 0xc0018e1148] [0x9d21f0 0x9d21f0] 0xc00252fd40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov 22 18:59:16.220: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-5393 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 18:59:16.683: INFO: rc: 1
Nov 22 18:59:16.683: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-5393 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00195a390 exit status 1 <nil> <nil> true [0xc002d02010 0xc002d020b8 0xc002d02130] [0xc002d02010 0xc002d020b8 0xc002d02130] [0xc002d020a0 0xc002d02110] [0x9d21f0 0x9d21f0] 0xc001f11bc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov 22 18:59:26.732: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-5393 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 18:59:27.051: INFO: rc: 1
Nov 22 18:59:27.051: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-5393 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc003ea4300 exit status 1 <nil> <nil> true [0xc000345170 0xc0003458f0 0xc000345ac8] [0xc000345170 0xc0003458f0 0xc000345ac8] [0xc0003454b8 0xc000345aa0] [0x9d21f0 0x9d21f0] 0xc00252f2c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov 22 18:59:37.051: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-5393 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 18:59:37.374: INFO: rc: 1
Nov 22 18:59:37.374: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-5393 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc003ea4a20 exit status 1 <nil> <nil> true [0xc000345b88 0xc000345c48 0xc000345e48] [0xc000345b88 0xc000345c48 0xc000345e48] [0xc000345bc8 0xc000345d78] [0x9d21f0 0x9d21f0] 0xc001d44180 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov 22 18:59:47.375: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-5393 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 18:59:47.652: INFO: rc: 1
Nov 22 18:59:47.652: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-5393 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0024f4360 exit status 1 <nil> <nil> true [0xc0000cc6f8 0xc0000cda68 0xc0023c0048] [0xc0000cc6f8 0xc0000cda68 0xc0023c0048] [0xc0000cd8a8 0xc000010010] [0x9d21f0 0x9d21f0] 0xc003186360 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov 22 18:59:57.653: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-5393 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 18:59:58.026: INFO: rc: 1
Nov 22 18:59:58.026: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-5393 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0032e6300 exit status 1 <nil> <nil> true [0xc002d02010 0xc002d020b8 0xc002d02130] [0xc002d02010 0xc002d020b8 0xc002d02130] [0xc002d020a0 0xc002d02110] [0x9d21f0 0x9d21f0] 0xc0021aca20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov 22 19:00:08.026: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-5393 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 19:00:08.450: INFO: rc: 1
Nov 22 19:00:08.450: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-5393 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001272300 exit status 1 <nil> <nil> true [0xc000ca4378 0xc000ca4540 0xc000ca4788] [0xc000ca4378 0xc000ca4540 0xc000ca4788] [0xc000ca44b0 0xc000ca4708] [0x9d21f0 0x9d21f0] 0xc001f11bc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov 22 19:00:18.450: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-5393 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 19:00:18.530: INFO: rc: 1
Nov 22 19:00:18.530: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-5393 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0024f46f0 exit status 1 <nil> <nil> true [0xc0023c00b0 0xc0023c0198 0xc0023c0260] [0xc0023c00b0 0xc0023c0198 0xc0023c0260] [0xc0023c0170 0xc0023c0208] [0x9d21f0 0x9d21f0] 0xc003186ae0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov 22 19:00:28.531: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-5393 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 19:00:28.613: INFO: rc: 1
Nov 22 19:00:28.614: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-5393 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0024f4a20 exit status 1 <nil> <nil> true [0xc0023c0280 0xc0023c0328 0xc0023c03d0] [0xc0023c0280 0xc0023c0328 0xc0023c03d0] [0xc0023c02f8 0xc0023c0398] [0x9d21f0 0x9d21f0] 0xc0031870e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov 22 19:00:38.614: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-5393 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 19:00:38.731: INFO: rc: 1
Nov 22 19:00:38.731: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-5393 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001272690 exit status 1 <nil> <nil> true [0xc000ca4838 0xc000ca4af0 0xc000ca4c20] [0xc000ca4838 0xc000ca4af0 0xc000ca4c20] [0xc000ca4a60 0xc000ca4bc0] [0x9d21f0 0x9d21f0] 0xc00344a300 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov 22 19:00:48.731: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-5393 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 19:00:48.819: INFO: rc: 1
Nov 22 19:00:48.819: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-5393 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0024f4db0 exit status 1 <nil> <nil> true [0xc0023c0400 0xc0023c0480 0xc0023c04f0] [0xc0023c0400 0xc0023c0480 0xc0023c04f0] [0xc0023c0440 0xc0023c04d8] [0x9d21f0 0x9d21f0] 0xc003187440 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov 22 19:00:58.820: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-5393 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 19:00:58.909: INFO: rc: 1
Nov 22 19:00:58.910: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-5393 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0024f5110 exit status 1 <nil> <nil> true [0xc0023c0518 0xc0023c05b0 0xc0023c0630] [0xc0023c0518 0xc0023c05b0 0xc0023c0630] [0xc0023c0580 0xc0023c0608] [0x9d21f0 0x9d21f0] 0xc003187920 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov 22 19:01:08.910: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-5393 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 19:01:09.111: INFO: rc: 1
Nov 22 19:01:09.111: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-5393 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0024f5470 exit status 1 <nil> <nil> true [0xc0023c0668 0xc0023c06d8 0xc0023c0768] [0xc0023c0668 0xc0023c06d8 0xc0023c0768] [0xc0023c06b0 0xc0023c0730] [0x9d21f0 0x9d21f0] 0xc003187c80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov 22 19:01:19.114: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-5393 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 19:01:19.493: INFO: rc: 1
Nov 22 19:01:19.493: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-5393 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0024f57a0 exit status 1 <nil> <nil> true [0xc0023c0788 0xc0023c07e8 0xc0023c0838] [0xc0023c0788 0xc0023c07e8 0xc0023c0838] [0xc0023c07c8 0xc0023c0828] [0x9d21f0 0x9d21f0] 0xc001d00120 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov 22 19:01:29.499: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-5393 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 19:01:29.787: INFO: rc: 1
Nov 22 19:01:29.787: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-5393 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0032e62a0 exit status 1 <nil> <nil> true [0xc0000cc6f8 0xc0000cda68 0xc002d02020] [0xc0000cc6f8 0xc0000cda68 0xc002d02020] [0xc0000cd8a8 0xc002d02010] [0x9d21f0 0x9d21f0] 0xc001f11bc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov 22 19:01:39.809: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-5393 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 19:01:40.195: INFO: rc: 1
Nov 22 19:01:40.195: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-5393 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0032e6630 exit status 1 <nil> <nil> true [0xc002d020a0 0xc002d02110 0xc002d02160] [0xc002d020a0 0xc002d02110 0xc002d02160] [0xc002d020c8 0xc002d02148] [0x9d21f0 0x9d21f0] 0xc003186360 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov 22 19:01:50.203: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-5393 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 19:01:50.641: INFO: rc: 1
Nov 22 19:01:50.641: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-5393 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0024f4330 exit status 1 <nil> <nil> true [0xc000ca4378 0xc000ca4540 0xc000ca4788] [0xc000ca4378 0xc000ca4540 0xc000ca4788] [0xc000ca44b0 0xc000ca4708] [0x9d21f0 0x9d21f0] 0xc00252f140 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov 22 19:02:00.641: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-5393 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 19:02:00.990: INFO: rc: 1
Nov 22 19:02:00.990: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-5393 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0024f4720 exit status 1 <nil> <nil> true [0xc000ca4838 0xc000ca4af0 0xc000ca4c20] [0xc000ca4838 0xc000ca4af0 0xc000ca4c20] [0xc000ca4a60 0xc000ca4bc0] [0x9d21f0 0x9d21f0] 0xc0021ac480 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov 22 19:02:10.998: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-5393 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 19:02:11.330: INFO: rc: 1
Nov 22 19:02:11.330: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-5393 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001272390 exit status 1 <nil> <nil> true [0xc0023c0048 0xc0023c0170 0xc0023c0208] [0xc0023c0048 0xc0023c0170 0xc0023c0208] [0xc0023c0108 0xc0023c01c0] [0x9d21f0 0x9d21f0] 0xc00344a300 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov 22 19:02:21.331: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-5393 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 19:02:21.704: INFO: rc: 1
Nov 22 19:02:21.705: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-5393 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001272720 exit status 1 <nil> <nil> true [0xc0023c0260 0xc0023c02f8 0xc0023c0398] [0xc0023c0260 0xc0023c02f8 0xc0023c0398] [0xc0023c0298 0xc0023c0368] [0x9d21f0 0x9d21f0] 0xc00344a6c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov 22 19:02:31.718: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-5393 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 19:02:32.085: INFO: rc: 1
Nov 22 19:02:32.085: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-5393 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc003ea4330 exit status 1 <nil> <nil> true [0xc000344c60 0xc0003454b8 0xc000345aa0] [0xc000344c60 0xc0003454b8 0xc000345aa0] [0xc000345398 0xc0003459d8] [0x9d21f0 0x9d21f0] 0xc001d00b40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov 22 19:02:42.085: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-5393 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 19:02:42.433: INFO: rc: 1
Nov 22 19:02:42.433: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-5393 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001272a50 exit status 1 <nil> <nil> true [0xc0023c03d0 0xc0023c0440 0xc0023c04d8] [0xc0023c03d0 0xc0023c0440 0xc0023c04d8] [0xc0023c0418 0xc0023c0490] [0x9d21f0 0x9d21f0] 0xc00344ac00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov 22 19:02:52.440: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-5393 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 19:02:52.783: INFO: rc: 1
Nov 22 19:02:52.783: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-5393 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0032e6990 exit status 1 <nil> <nil> true [0xc002d02178 0xc002d021b8 0xc002d02220] [0xc002d02178 0xc002d021b8 0xc002d02220] [0xc002d02188 0xc002d02208] [0x9d21f0 0x9d21f0] 0xc003186ae0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Nov 22 19:03:02.786: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-5393 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 19:03:03.126: INFO: rc: 1
Nov 22 19:03:03.126: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: 
Nov 22 19:03:03.126: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Nov 22 19:03:03.173: INFO: Deleting all statefulset in ns statefulset-5393
Nov 22 19:03:03.174: INFO: Scaling statefulset ss to 0
Nov 22 19:03:03.233: INFO: Waiting for statefulset status.replicas updated to 0
Nov 22 19:03:03.250: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:03:03.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5393" for this suite.
Nov 22 19:03:09.388: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:03:09.610: INFO: namespace statefulset-5393 deletion completed in 6.28419971s

• [SLOW TEST:380.806 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:03:09.610: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1457
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Nov 22 19:03:09.696: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-9396'
Nov 22 19:03:10.167: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Nov 22 19:03:10.167: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Nov 22 19:03:10.221: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-wd5pd]
Nov 22 19:03:10.221: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-wd5pd" in namespace "kubectl-9396" to be "running and ready"
Nov 22 19:03:10.258: INFO: Pod "e2e-test-nginx-rc-wd5pd": Phase="Pending", Reason="", readiness=false. Elapsed: 36.46573ms
Nov 22 19:03:12.260: INFO: Pod "e2e-test-nginx-rc-wd5pd": Phase="Running", Reason="", readiness=true. Elapsed: 2.038306122s
Nov 22 19:03:12.260: INFO: Pod "e2e-test-nginx-rc-wd5pd" satisfied condition "running and ready"
Nov 22 19:03:12.260: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-wd5pd]
Nov 22 19:03:12.260: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 logs rc/e2e-test-nginx-rc --namespace=kubectl-9396'
Nov 22 19:03:12.696: INFO: stderr: ""
Nov 22 19:03:12.696: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1462
Nov 22 19:03:12.697: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 delete rc e2e-test-nginx-rc --namespace=kubectl-9396'
Nov 22 19:03:13.052: INFO: stderr: ""
Nov 22 19:03:13.052: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:03:13.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9396" for this suite.
Nov 22 19:03:37.081: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:03:37.378: INFO: namespace kubectl-9396 deletion completed in 24.310881036s

• [SLOW TEST:27.768 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:03:37.378: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Nov 22 19:03:37.465: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1e10607c-86c9-4c6c-b44b-154326c88315" in namespace "projected-1517" to be "success or failure"
Nov 22 19:03:37.494: INFO: Pod "downwardapi-volume-1e10607c-86c9-4c6c-b44b-154326c88315": Phase="Pending", Reason="", readiness=false. Elapsed: 29.692848ms
Nov 22 19:03:39.515: INFO: Pod "downwardapi-volume-1e10607c-86c9-4c6c-b44b-154326c88315": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.050642342s
STEP: Saw pod success
Nov 22 19:03:39.515: INFO: Pod "downwardapi-volume-1e10607c-86c9-4c6c-b44b-154326c88315" satisfied condition "success or failure"
Nov 22 19:03:39.517: INFO: Trying to get logs from node minion pod downwardapi-volume-1e10607c-86c9-4c6c-b44b-154326c88315 container client-container: <nil>
STEP: delete the pod
Nov 22 19:03:39.572: INFO: Waiting for pod downwardapi-volume-1e10607c-86c9-4c6c-b44b-154326c88315 to disappear
Nov 22 19:03:39.573: INFO: Pod downwardapi-volume-1e10607c-86c9-4c6c-b44b-154326c88315 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:03:39.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1517" for this suite.
Nov 22 19:03:45.614: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:03:45.950: INFO: namespace projected-1517 deletion completed in 6.362944178s

• [SLOW TEST:8.572 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:03:45.951: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1211
STEP: creating the pod
Nov 22 19:03:46.035: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 create -f - --namespace=kubectl-6854'
Nov 22 19:03:46.834: INFO: stderr: ""
Nov 22 19:03:46.834: INFO: stdout: "pod/pause created\n"
Nov 22 19:03:46.834: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Nov 22 19:03:46.834: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-6854" to be "running and ready"
Nov 22 19:03:46.836: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.603959ms
Nov 22 19:03:48.838: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.004399697s
Nov 22 19:03:48.838: INFO: Pod "pause" satisfied condition "running and ready"
Nov 22 19:03:48.838: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: adding the label testing-label with value testing-label-value to a pod
Nov 22 19:03:48.838: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 label pods pause testing-label=testing-label-value --namespace=kubectl-6854'
Nov 22 19:03:49.241: INFO: stderr: ""
Nov 22 19:03:49.241: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Nov 22 19:03:49.241: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 get pod pause -L testing-label --namespace=kubectl-6854'
Nov 22 19:03:49.605: INFO: stderr: ""
Nov 22 19:03:49.605: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Nov 22 19:03:49.605: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 label pods pause testing-label- --namespace=kubectl-6854'
Nov 22 19:03:50.103: INFO: stderr: ""
Nov 22 19:03:50.103: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Nov 22 19:03:50.103: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 get pod pause -L testing-label --namespace=kubectl-6854'
Nov 22 19:03:50.451: INFO: stderr: ""
Nov 22 19:03:50.451: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1218
STEP: using delete to clean up resources
Nov 22 19:03:50.451: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 delete --grace-period=0 --force -f - --namespace=kubectl-6854'
Nov 22 19:03:50.819: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 22 19:03:50.819: INFO: stdout: "pod \"pause\" force deleted\n"
Nov 22 19:03:50.819: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 get rc,svc -l name=pause --no-headers --namespace=kubectl-6854'
Nov 22 19:03:51.205: INFO: stderr: "No resources found.\n"
Nov 22 19:03:51.205: INFO: stdout: ""
Nov 22 19:03:51.205: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 get pods -l name=pause --namespace=kubectl-6854 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov 22 19:03:51.576: INFO: stderr: ""
Nov 22 19:03:51.576: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:03:51.576: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6854" for this suite.
Nov 22 19:03:57.723: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:03:58.013: INFO: namespace kubectl-6854 deletion completed in 6.34692773s

• [SLOW TEST:12.063 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl label
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:03:58.014: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-9460fae7-85e9-40a9-a726-9e628db18f5d
STEP: Creating a pod to test consume configMaps
Nov 22 19:03:58.160: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d0cc63b1-a14e-4495-8a2b-45d454b7997c" in namespace "projected-6975" to be "success or failure"
Nov 22 19:03:58.172: INFO: Pod "pod-projected-configmaps-d0cc63b1-a14e-4495-8a2b-45d454b7997c": Phase="Pending", Reason="", readiness=false. Elapsed: 11.82241ms
Nov 22 19:04:00.176: INFO: Pod "pod-projected-configmaps-d0cc63b1-a14e-4495-8a2b-45d454b7997c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015187746s
STEP: Saw pod success
Nov 22 19:04:00.176: INFO: Pod "pod-projected-configmaps-d0cc63b1-a14e-4495-8a2b-45d454b7997c" satisfied condition "success or failure"
Nov 22 19:04:00.177: INFO: Trying to get logs from node minion pod pod-projected-configmaps-d0cc63b1-a14e-4495-8a2b-45d454b7997c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov 22 19:04:00.248: INFO: Waiting for pod pod-projected-configmaps-d0cc63b1-a14e-4495-8a2b-45d454b7997c to disappear
Nov 22 19:04:00.263: INFO: Pod pod-projected-configmaps-d0cc63b1-a14e-4495-8a2b-45d454b7997c no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:04:00.263: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6975" for this suite.
Nov 22 19:04:06.296: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:04:06.792: INFO: namespace projected-6975 deletion completed in 6.514293416s

• [SLOW TEST:8.778 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:04:06.792: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Nov 22 19:04:06.925: INFO: Waiting up to 5m0s for pod "downward-api-ed7a7c3a-564a-46cd-b113-16a2c8dd402a" in namespace "downward-api-6653" to be "success or failure"
Nov 22 19:04:06.939: INFO: Pod "downward-api-ed7a7c3a-564a-46cd-b113-16a2c8dd402a": Phase="Pending", Reason="", readiness=false. Elapsed: 14.739364ms
Nov 22 19:04:08.951: INFO: Pod "downward-api-ed7a7c3a-564a-46cd-b113-16a2c8dd402a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026640003s
Nov 22 19:04:10.956: INFO: Pod "downward-api-ed7a7c3a-564a-46cd-b113-16a2c8dd402a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031710377s
STEP: Saw pod success
Nov 22 19:04:10.957: INFO: Pod "downward-api-ed7a7c3a-564a-46cd-b113-16a2c8dd402a" satisfied condition "success or failure"
Nov 22 19:04:10.958: INFO: Trying to get logs from node minion pod downward-api-ed7a7c3a-564a-46cd-b113-16a2c8dd402a container dapi-container: <nil>
STEP: delete the pod
Nov 22 19:04:10.999: INFO: Waiting for pod downward-api-ed7a7c3a-564a-46cd-b113-16a2c8dd402a to disappear
Nov 22 19:04:11.015: INFO: Pod downward-api-ed7a7c3a-564a-46cd-b113-16a2c8dd402a no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:04:11.015: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6653" for this suite.
Nov 22 19:04:17.043: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:04:17.341: INFO: namespace downward-api-6653 deletion completed in 6.315956501s

• [SLOW TEST:10.549 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:04:17.341: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Nov 22 19:04:17.420: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fb23aa45-f535-419a-a99c-a4ed66327b5e" in namespace "downward-api-6985" to be "success or failure"
Nov 22 19:04:17.435: INFO: Pod "downwardapi-volume-fb23aa45-f535-419a-a99c-a4ed66327b5e": Phase="Pending", Reason="", readiness=false. Elapsed: 14.748642ms
Nov 22 19:04:19.443: INFO: Pod "downwardapi-volume-fb23aa45-f535-419a-a99c-a4ed66327b5e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023111884s
Nov 22 19:04:21.448: INFO: Pod "downwardapi-volume-fb23aa45-f535-419a-a99c-a4ed66327b5e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028307552s
STEP: Saw pod success
Nov 22 19:04:21.448: INFO: Pod "downwardapi-volume-fb23aa45-f535-419a-a99c-a4ed66327b5e" satisfied condition "success or failure"
Nov 22 19:04:21.450: INFO: Trying to get logs from node minion pod downwardapi-volume-fb23aa45-f535-419a-a99c-a4ed66327b5e container client-container: <nil>
STEP: delete the pod
Nov 22 19:04:21.496: INFO: Waiting for pod downwardapi-volume-fb23aa45-f535-419a-a99c-a4ed66327b5e to disappear
Nov 22 19:04:21.498: INFO: Pod downwardapi-volume-fb23aa45-f535-419a-a99c-a4ed66327b5e no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:04:21.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6985" for this suite.
Nov 22 19:04:27.531: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:04:27.817: INFO: namespace downward-api-6985 deletion completed in 6.304272398s

• [SLOW TEST:10.476 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:04:27.817: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-upd-4c2cfe31-ac33-4706-adc8-70c0b4e07d11
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-4c2cfe31-ac33-4706-adc8-70c0b4e07d11
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:04:32.027: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-720" for this suite.
Nov 22 19:04:56.072: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:04:56.426: INFO: namespace configmap-720 deletion completed in 24.372002056s

• [SLOW TEST:28.609 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:04:56.426: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-bf65af9f-4424-45c2-b265-fc10044dab0f
STEP: Creating a pod to test consume configMaps
Nov 22 19:04:56.546: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-1a69b25a-0225-41c2-9b7c-a55f4d779cd6" in namespace "projected-9445" to be "success or failure"
Nov 22 19:04:56.568: INFO: Pod "pod-projected-configmaps-1a69b25a-0225-41c2-9b7c-a55f4d779cd6": Phase="Pending", Reason="", readiness=false. Elapsed: 21.563368ms
Nov 22 19:04:58.570: INFO: Pod "pod-projected-configmaps-1a69b25a-0225-41c2-9b7c-a55f4d779cd6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023326123s
STEP: Saw pod success
Nov 22 19:04:58.570: INFO: Pod "pod-projected-configmaps-1a69b25a-0225-41c2-9b7c-a55f4d779cd6" satisfied condition "success or failure"
Nov 22 19:04:58.584: INFO: Trying to get logs from node minion pod pod-projected-configmaps-1a69b25a-0225-41c2-9b7c-a55f4d779cd6 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov 22 19:04:58.620: INFO: Waiting for pod pod-projected-configmaps-1a69b25a-0225-41c2-9b7c-a55f4d779cd6 to disappear
Nov 22 19:04:58.621: INFO: Pod pod-projected-configmaps-1a69b25a-0225-41c2-9b7c-a55f4d779cd6 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:04:58.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9445" for this suite.
Nov 22 19:05:04.677: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:05:04.946: INFO: namespace projected-9445 deletion completed in 6.305648223s

• [SLOW TEST:8.520 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:05:04.947: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Nov 22 19:05:05.048: INFO: Waiting up to 5m0s for pod "downwardapi-volume-25997405-b87c-48ec-a77c-7e2e64ea062b" in namespace "downward-api-6702" to be "success or failure"
Nov 22 19:05:05.073: INFO: Pod "downwardapi-volume-25997405-b87c-48ec-a77c-7e2e64ea062b": Phase="Pending", Reason="", readiness=false. Elapsed: 25.424304ms
Nov 22 19:05:07.075: INFO: Pod "downwardapi-volume-25997405-b87c-48ec-a77c-7e2e64ea062b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027330497s
Nov 22 19:05:09.077: INFO: Pod "downwardapi-volume-25997405-b87c-48ec-a77c-7e2e64ea062b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029371175s
STEP: Saw pod success
Nov 22 19:05:09.077: INFO: Pod "downwardapi-volume-25997405-b87c-48ec-a77c-7e2e64ea062b" satisfied condition "success or failure"
Nov 22 19:05:09.079: INFO: Trying to get logs from node minion pod downwardapi-volume-25997405-b87c-48ec-a77c-7e2e64ea062b container client-container: <nil>
STEP: delete the pod
Nov 22 19:05:09.090: INFO: Waiting for pod downwardapi-volume-25997405-b87c-48ec-a77c-7e2e64ea062b to disappear
Nov 22 19:05:09.092: INFO: Pod downwardapi-volume-25997405-b87c-48ec-a77c-7e2e64ea062b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:05:09.092: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6702" for this suite.
Nov 22 19:05:15.100: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:05:15.165: INFO: namespace downward-api-6702 deletion completed in 6.07093148s

• [SLOW TEST:10.218 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:05:15.165: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Nov 22 19:05:19.714: INFO: Successfully updated pod "labelsupdate1021d208-c30d-449c-afaf-c45c53119632"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:05:21.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6068" for this suite.
Nov 22 19:05:43.735: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:05:43.839: INFO: namespace projected-6068 deletion completed in 22.110844244s

• [SLOW TEST:28.674 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:05:43.840: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Nov 22 19:05:45.870: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-7a5e5e85-4683-40da-9217-a5b6c8857f82,GenerateName:,Namespace:events-7621,SelfLink:/api/v1/namespaces/events-7621/pods/send-events-7a5e5e85-4683-40da-9217-a5b6c8857f82,UID:88e07627-79e5-4106-978d-56aa2e368ae0,ResourceVersion:51212,Generation:0,CreationTimestamp:2019-11-22 19:05:43 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 859699828,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-z6szl {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-z6szl,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-z6szl true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0032c1e60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0032c1e80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:05:43 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:05:45 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:05:45 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:05:43 +0000 UTC  }],Message:,Reason:,HostIP:172.31.44.47,PodIP:10.251.128.8,StartTime:2019-11-22 19:05:43 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-11-22 19:05:45 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 docker-pullable://gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:bab70473a6d8ef65a22625dc9a1b0f0452e811530fdbe77e4408523460177ff1 docker://d77b901cd391066937eba4d7db0ace13f2b7829700c93d3950c12155b287d37a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Nov 22 19:05:47.873: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Nov 22 19:05:49.875: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:05:49.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-7621" for this suite.
Nov 22 19:06:33.894: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:06:34.164: INFO: namespace events-7621 deletion completed in 44.281679736s

• [SLOW TEST:50.325 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:06:34.165: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod test-webserver-191d014d-040c-4bbd-8d98-ecc6537d3677 in namespace container-probe-7322
Nov 22 19:06:38.302: INFO: Started pod test-webserver-191d014d-040c-4bbd-8d98-ecc6537d3677 in namespace container-probe-7322
STEP: checking the pod's current state and verifying that restartCount is present
Nov 22 19:06:38.304: INFO: Initial restart count of pod test-webserver-191d014d-040c-4bbd-8d98-ecc6537d3677 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:10:39.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7322" for this suite.
Nov 22 19:10:45.335: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:10:45.432: INFO: namespace container-probe-7322 deletion completed in 6.103198927s

• [SLOW TEST:251.268 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:10:45.432: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-1600
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a new StatefulSet
Nov 22 19:10:45.464: INFO: Found 0 stateful pods, waiting for 3
Nov 22 19:10:55.466: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 22 19:10:55.466: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov 22 19:10:55.466: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Nov 22 19:10:55.485: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Nov 22 19:11:05.508: INFO: Updating stateful set ss2
Nov 22 19:11:05.512: INFO: Waiting for Pod statefulset-1600/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Restoring Pods to the correct revision when they are deleted
Nov 22 19:11:15.682: INFO: Found 2 stateful pods, waiting for 3
Nov 22 19:11:25.684: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 22 19:11:25.685: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov 22 19:11:25.685: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Nov 22 19:11:25.725: INFO: Updating stateful set ss2
Nov 22 19:11:25.776: INFO: Waiting for Pod statefulset-1600/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Nov 22 19:11:35.830: INFO: Updating stateful set ss2
Nov 22 19:11:35.862: INFO: Waiting for StatefulSet statefulset-1600/ss2 to complete update
Nov 22 19:11:35.862: INFO: Waiting for Pod statefulset-1600/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Nov 22 19:11:45.879: INFO: Waiting for StatefulSet statefulset-1600/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Nov 22 19:11:55.882: INFO: Deleting all statefulset in ns statefulset-1600
Nov 22 19:11:55.908: INFO: Scaling statefulset ss2 to 0
Nov 22 19:12:25.922: INFO: Waiting for statefulset status.replicas updated to 0
Nov 22 19:12:25.947: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:12:25.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1600" for this suite.
Nov 22 19:12:34.118: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:12:34.405: INFO: namespace statefulset-1600 deletion completed in 8.373952016s

• [SLOW TEST:108.972 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:12:34.405: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Nov 22 19:12:34.493: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0483a2cd-5e96-403e-b2a6-ffc84cd8df7a" in namespace "projected-7016" to be "success or failure"
Nov 22 19:12:34.514: INFO: Pod "downwardapi-volume-0483a2cd-5e96-403e-b2a6-ffc84cd8df7a": Phase="Pending", Reason="", readiness=false. Elapsed: 20.952931ms
Nov 22 19:12:36.517: INFO: Pod "downwardapi-volume-0483a2cd-5e96-403e-b2a6-ffc84cd8df7a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024435153s
Nov 22 19:12:38.527: INFO: Pod "downwardapi-volume-0483a2cd-5e96-403e-b2a6-ffc84cd8df7a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034527933s
STEP: Saw pod success
Nov 22 19:12:38.527: INFO: Pod "downwardapi-volume-0483a2cd-5e96-403e-b2a6-ffc84cd8df7a" satisfied condition "success or failure"
Nov 22 19:12:38.529: INFO: Trying to get logs from node minion pod downwardapi-volume-0483a2cd-5e96-403e-b2a6-ffc84cd8df7a container client-container: <nil>
STEP: delete the pod
Nov 22 19:12:38.576: INFO: Waiting for pod downwardapi-volume-0483a2cd-5e96-403e-b2a6-ffc84cd8df7a to disappear
Nov 22 19:12:38.597: INFO: Pod downwardapi-volume-0483a2cd-5e96-403e-b2a6-ffc84cd8df7a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:12:38.597: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7016" for this suite.
Nov 22 19:12:44.640: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:12:45.021: INFO: namespace projected-7016 deletion completed in 6.422426532s

• [SLOW TEST:10.616 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:12:45.021: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:12:49.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6328" for this suite.
Nov 22 19:12:55.181: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:12:55.527: INFO: namespace kubelet-test-6328 deletion completed in 6.36382531s

• [SLOW TEST:10.506 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:12:55.528: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Nov 22 19:12:55.620: INFO: (0) /api/v1/nodes/minion:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 3.773701ms)
Nov 22 19:12:55.630: INFO: (1) /api/v1/nodes/minion:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 10.069658ms)
Nov 22 19:12:55.644: INFO: (2) /api/v1/nodes/minion:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 14.225723ms)
Nov 22 19:12:55.646: INFO: (3) /api/v1/nodes/minion:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.269778ms)
Nov 22 19:12:55.668: INFO: (4) /api/v1/nodes/minion:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 21.963859ms)
Nov 22 19:12:55.671: INFO: (5) /api/v1/nodes/minion:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.367083ms)
Nov 22 19:12:55.673: INFO: (6) /api/v1/nodes/minion:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.021262ms)
Nov 22 19:12:55.675: INFO: (7) /api/v1/nodes/minion:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.116063ms)
Nov 22 19:12:55.686: INFO: (8) /api/v1/nodes/minion:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 10.285253ms)
Nov 22 19:12:55.691: INFO: (9) /api/v1/nodes/minion:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 5.286733ms)
Nov 22 19:12:55.705: INFO: (10) /api/v1/nodes/minion:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 13.92784ms)
Nov 22 19:12:55.707: INFO: (11) /api/v1/nodes/minion:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.350499ms)
Nov 22 19:12:55.709: INFO: (12) /api/v1/nodes/minion:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.244376ms)
Nov 22 19:12:55.712: INFO: (13) /api/v1/nodes/minion:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.086621ms)
Nov 22 19:12:55.726: INFO: (14) /api/v1/nodes/minion:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 14.623759ms)
Nov 22 19:12:55.728: INFO: (15) /api/v1/nodes/minion:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.002954ms)
Nov 22 19:12:55.758: INFO: (16) /api/v1/nodes/minion:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 29.396185ms)
Nov 22 19:12:55.760: INFO: (17) /api/v1/nodes/minion:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 2.07849ms)
Nov 22 19:12:55.774: INFO: (18) /api/v1/nodes/minion:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 13.984771ms)
Nov 22 19:12:55.793: INFO: (19) /api/v1/nodes/minion:10250/proxy/logs/: <pre>
<a href="amazon/">amazon/</a>
<a href="apt/">apt/</a>
<a href="auth.log">auth.log</a>
<a hr... (200; 18.78523ms)
[AfterEach] version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:12:55.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-9722" for this suite.
Nov 22 19:13:01.869: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:13:02.127: INFO: namespace proxy-9722 deletion completed in 6.308531062s

• [SLOW TEST:6.599 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:13:02.127: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1686
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Nov 22 19:13:02.207: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-1664'
Nov 22 19:13:03.767: INFO: stderr: ""
Nov 22 19:13:03.767: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1691
Nov 22 19:13:03.787: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 delete pods e2e-test-nginx-pod --namespace=kubectl-1664'
Nov 22 19:13:12.781: INFO: stderr: ""
Nov 22 19:13:12.781: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:13:12.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1664" for this suite.
Nov 22 19:13:18.827: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:13:19.067: INFO: namespace kubectl-1664 deletion completed in 6.283484006s

• [SLOW TEST:16.939 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:13:19.067: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Nov 22 19:13:19.154: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:13:21.262: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4363" for this suite.
Nov 22 19:14:03.313: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:14:03.547: INFO: namespace pods-4363 deletion completed in 42.274822339s

• [SLOW TEST:44.480 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:14:03.547: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on node default medium
Nov 22 19:14:03.645: INFO: Waiting up to 5m0s for pod "pod-efe1a49b-9085-47b2-9045-0beb814d97f4" in namespace "emptydir-8925" to be "success or failure"
Nov 22 19:14:03.647: INFO: Pod "pod-efe1a49b-9085-47b2-9045-0beb814d97f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.185426ms
Nov 22 19:14:05.659: INFO: Pod "pod-efe1a49b-9085-47b2-9045-0beb814d97f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014003208s
STEP: Saw pod success
Nov 22 19:14:05.659: INFO: Pod "pod-efe1a49b-9085-47b2-9045-0beb814d97f4" satisfied condition "success or failure"
Nov 22 19:14:05.660: INFO: Trying to get logs from node minion pod pod-efe1a49b-9085-47b2-9045-0beb814d97f4 container test-container: <nil>
STEP: delete the pod
Nov 22 19:14:05.707: INFO: Waiting for pod pod-efe1a49b-9085-47b2-9045-0beb814d97f4 to disappear
Nov 22 19:14:05.719: INFO: Pod pod-efe1a49b-9085-47b2-9045-0beb814d97f4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:14:05.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8925" for this suite.
Nov 22 19:14:11.745: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:14:11.995: INFO: namespace emptydir-8925 deletion completed in 6.267132783s

• [SLOW TEST:8.448 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:14:11.998: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Nov 22 19:14:12.152: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-4083,SelfLink:/api/v1/namespaces/watch-4083/configmaps/e2e-watch-test-label-changed,UID:0aebbbd9-8a98-4321-86bc-30e5bd95d07b,ResourceVersion:52890,Generation:0,CreationTimestamp:2019-11-22 19:14:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov 22 19:14:12.152: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-4083,SelfLink:/api/v1/namespaces/watch-4083/configmaps/e2e-watch-test-label-changed,UID:0aebbbd9-8a98-4321-86bc-30e5bd95d07b,ResourceVersion:52891,Generation:0,CreationTimestamp:2019-11-22 19:14:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Nov 22 19:14:12.152: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-4083,SelfLink:/api/v1/namespaces/watch-4083/configmaps/e2e-watch-test-label-changed,UID:0aebbbd9-8a98-4321-86bc-30e5bd95d07b,ResourceVersion:52892,Generation:0,CreationTimestamp:2019-11-22 19:14:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Nov 22 19:14:22.216: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-4083,SelfLink:/api/v1/namespaces/watch-4083/configmaps/e2e-watch-test-label-changed,UID:0aebbbd9-8a98-4321-86bc-30e5bd95d07b,ResourceVersion:52919,Generation:0,CreationTimestamp:2019-11-22 19:14:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov 22 19:14:22.216: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-4083,SelfLink:/api/v1/namespaces/watch-4083/configmaps/e2e-watch-test-label-changed,UID:0aebbbd9-8a98-4321-86bc-30e5bd95d07b,ResourceVersion:52920,Generation:0,CreationTimestamp:2019-11-22 19:14:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Nov 22 19:14:22.216: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-4083,SelfLink:/api/v1/namespaces/watch-4083/configmaps/e2e-watch-test-label-changed,UID:0aebbbd9-8a98-4321-86bc-30e5bd95d07b,ResourceVersion:52921,Generation:0,CreationTimestamp:2019-11-22 19:14:12 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:14:22.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-4083" for this suite.
Nov 22 19:14:30.252: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:14:30.473: INFO: namespace watch-4083 deletion completed in 8.25507042s

• [SLOW TEST:18.475 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:14:30.473: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Nov 22 19:14:30.535: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:14:35.196: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-2671" for this suite.
Nov 22 19:14:59.259: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:14:59.921: INFO: namespace init-container-2671 deletion completed in 24.70337097s

• [SLOW TEST:29.448 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:14:59.921: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-9e345094-c1f6-4a0f-b131-5ac953f0d1f9
STEP: Creating a pod to test consume configMaps
Nov 22 19:15:00.057: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-21107b3c-2a12-41e8-a195-206321d93164" in namespace "projected-3727" to be "success or failure"
Nov 22 19:15:00.092: INFO: Pod "pod-projected-configmaps-21107b3c-2a12-41e8-a195-206321d93164": Phase="Pending", Reason="", readiness=false. Elapsed: 35.07058ms
Nov 22 19:15:02.104: INFO: Pod "pod-projected-configmaps-21107b3c-2a12-41e8-a195-206321d93164": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.047015573s
STEP: Saw pod success
Nov 22 19:15:02.104: INFO: Pod "pod-projected-configmaps-21107b3c-2a12-41e8-a195-206321d93164" satisfied condition "success or failure"
Nov 22 19:15:02.105: INFO: Trying to get logs from node minion pod pod-projected-configmaps-21107b3c-2a12-41e8-a195-206321d93164 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov 22 19:15:02.157: INFO: Waiting for pod pod-projected-configmaps-21107b3c-2a12-41e8-a195-206321d93164 to disappear
Nov 22 19:15:02.159: INFO: Pod pod-projected-configmaps-21107b3c-2a12-41e8-a195-206321d93164 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:15:02.159: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3727" for this suite.
Nov 22 19:15:08.206: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:15:08.487: INFO: namespace projected-3727 deletion completed in 6.314175973s

• [SLOW TEST:8.566 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:15:08.487: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Nov 22 19:15:10.644: INFO: Waiting up to 5m0s for pod "client-envvars-e98180b6-0c8e-4239-afa0-72473bd79b99" in namespace "pods-4060" to be "success or failure"
Nov 22 19:15:10.655: INFO: Pod "client-envvars-e98180b6-0c8e-4239-afa0-72473bd79b99": Phase="Pending", Reason="", readiness=false. Elapsed: 10.408577ms
Nov 22 19:15:12.657: INFO: Pod "client-envvars-e98180b6-0c8e-4239-afa0-72473bd79b99": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012683942s
STEP: Saw pod success
Nov 22 19:15:12.657: INFO: Pod "client-envvars-e98180b6-0c8e-4239-afa0-72473bd79b99" satisfied condition "success or failure"
Nov 22 19:15:12.658: INFO: Trying to get logs from node minion pod client-envvars-e98180b6-0c8e-4239-afa0-72473bd79b99 container env3cont: <nil>
STEP: delete the pod
Nov 22 19:15:12.670: INFO: Waiting for pod client-envvars-e98180b6-0c8e-4239-afa0-72473bd79b99 to disappear
Nov 22 19:15:12.677: INFO: Pod client-envvars-e98180b6-0c8e-4239-afa0-72473bd79b99 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:15:12.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4060" for this suite.
Nov 22 19:15:50.685: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:15:50.756: INFO: namespace pods-4060 deletion completed in 38.077238753s

• [SLOW TEST:42.269 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:15:50.757: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Nov 22 19:16:00.851: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
	[quantile=0.5] = 211
	[quantile=0.9] = 349210
	[quantile=0.99] = 700981
For garbage_collector_attempt_to_delete_work_duration:
	[quantile=0.5] = 406313
	[quantile=0.9] = 802943
	[quantile=0.99] = 843159
For garbage_collector_attempt_to_orphan_queue_latency:
	[quantile=0.5] = NaN
	[quantile=0.9] = NaN
	[quantile=0.99] = NaN
For garbage_collector_attempt_to_orphan_work_duration:
	[quantile=0.5] = NaN
	[quantile=0.9] = NaN
	[quantile=0.99] = NaN
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
	[quantile=0.5] = 6
	[quantile=0.9] = 7
	[quantile=0.99] = 22
For garbage_collector_graph_changes_work_duration:
	[quantile=0.5] = 14
	[quantile=0.9] = 24
	[quantile=0.99] = 51
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
	[quantile=0.5] = 10
	[quantile=0.9] = 18
	[quantile=0.99] = 20
For namespace_queue_latency_sum:
	[] = 8457
For namespace_queue_latency_count:
	[] = 584
For namespace_retries:
	[] = 595
For namespace_work_duration:
	[quantile=0.5] = 570949
	[quantile=0.9] = 949201
	[quantile=0.99] = 1462539
For namespace_work_duration_sum:
	[] = 239811376
For namespace_work_duration_count:
	[] = 584
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:16:00.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2426" for this suite.
Nov 22 19:16:06.860: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:16:06.944: INFO: namespace gc-2426 deletion completed in 6.090541621s

• [SLOW TEST:16.187 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:16:06.944: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Nov 22 19:16:06.965: INFO: Creating deployment "test-recreate-deployment"
Nov 22 19:16:06.967: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Nov 22 19:16:06.979: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Nov 22 19:16:08.988: INFO: Waiting deployment "test-recreate-deployment" to complete
Nov 22 19:16:08.989: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Nov 22 19:16:08.993: INFO: Updating deployment test-recreate-deployment
Nov 22 19:16:08.993: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Nov 22 19:16:09.086: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-5703,SelfLink:/apis/apps/v1/namespaces/deployment-5703/deployments/test-recreate-deployment,UID:3286e83f-0300-4a76-b641-52cee3ddd437,ResourceVersion:53558,Generation:2,CreationTimestamp:2019-11-22 19:16:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-11-22 19:16:09 +0000 UTC 2019-11-22 19:16:09 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-11-22 19:16:09 +0000 UTC 2019-11-22 19:16:06 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-5c8c9cc69d" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Nov 22 19:16:09.096: INFO: New ReplicaSet "test-recreate-deployment-5c8c9cc69d" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5c8c9cc69d,GenerateName:,Namespace:deployment-5703,SelfLink:/apis/apps/v1/namespaces/deployment-5703/replicasets/test-recreate-deployment-5c8c9cc69d,UID:ae6c6201-c430-488a-8ad5-554980778acc,ResourceVersion:53557,Generation:1,CreationTimestamp:2019-11-22 19:16:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 3286e83f-0300-4a76-b641-52cee3ddd437 0xc0026e8547 0xc0026e8548}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Nov 22 19:16:09.096: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Nov 22 19:16:09.097: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-6df85df6b9,GenerateName:,Namespace:deployment-5703,SelfLink:/apis/apps/v1/namespaces/deployment-5703/replicasets/test-recreate-deployment-6df85df6b9,UID:3e4e8a9d-05a4-44e7-b84d-b65890e75906,ResourceVersion:53547,Generation:2,CreationTimestamp:2019-11-22 19:16:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 3286e83f-0300-4a76-b641-52cee3ddd437 0xc0026e8617 0xc0026e8618}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Nov 22 19:16:09.098: INFO: Pod "test-recreate-deployment-5c8c9cc69d-9wsjw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5c8c9cc69d-9wsjw,GenerateName:test-recreate-deployment-5c8c9cc69d-,Namespace:deployment-5703,SelfLink:/api/v1/namespaces/deployment-5703/pods/test-recreate-deployment-5c8c9cc69d-9wsjw,UID:a44ce9a0-e9a0-4758-a42e-bce9cacf7118,ResourceVersion:53559,Generation:0,CreationTimestamp:2019-11-22 19:16:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-5c8c9cc69d ae6c6201-c430-488a-8ad5-554980778acc 0xc002d4ef47 0xc002d4ef48}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-bqzdf {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-bqzdf,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-bqzdf true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002d4efc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002d4efe0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:16:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:16:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:16:09 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:16:09 +0000 UTC  }],Message:,Reason:,HostIP:172.31.44.47,PodIP:,StartTime:2019-11-22 19:16:09 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:16:09.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5703" for this suite.
Nov 22 19:16:15.113: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:16:15.431: INFO: namespace deployment-5703 deletion completed in 6.331475559s

• [SLOW TEST:8.487 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:16:15.432: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4468.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-4468.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4468.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-4468.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov 22 19:16:19.573: INFO: DNS probes using dns-test-b6ed70bb-d537-4244-a36d-de152875a0c9 succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4468.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-4468.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4468.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-4468.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov 22 19:16:23.749: INFO: DNS probes using dns-test-acdd3c0f-dcbf-4e8f-90e4-fbc054d0c7be succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4468.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-4468.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4468.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-4468.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov 22 19:16:27.960: INFO: DNS probes using dns-test-f8fee642-6a9c-417f-9f36-86fa8f0547db succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:16:28.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4468" for this suite.
Nov 22 19:16:36.115: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:16:36.459: INFO: namespace dns-4468 deletion completed in 8.367581917s

• [SLOW TEST:21.027 seconds]
[sig-network] DNS
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:16:36.459: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod busybox-7dad19f1-edbc-4976-a16e-24a67993bc9e in namespace container-probe-7121
Nov 22 19:16:38.556: INFO: Started pod busybox-7dad19f1-edbc-4976-a16e-24a67993bc9e in namespace container-probe-7121
STEP: checking the pod's current state and verifying that restartCount is present
Nov 22 19:16:38.557: INFO: Initial restart count of pod busybox-7dad19f1-edbc-4976-a16e-24a67993bc9e is 0
Nov 22 19:17:28.795: INFO: Restart count of pod container-probe-7121/busybox-7dad19f1-edbc-4976-a16e-24a67993bc9e is now 1 (50.237331063s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:17:28.870: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7121" for this suite.
Nov 22 19:17:34.913: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:17:35.126: INFO: namespace container-probe-7121 deletion completed in 6.253371917s

• [SLOW TEST:58.667 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:17:35.126: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir volume type on node default medium
Nov 22 19:17:35.224: INFO: Waiting up to 5m0s for pod "pod-bdfe3b6c-a7c1-4417-bce2-171485ca866c" in namespace "emptydir-4365" to be "success or failure"
Nov 22 19:17:35.251: INFO: Pod "pod-bdfe3b6c-a7c1-4417-bce2-171485ca866c": Phase="Pending", Reason="", readiness=false. Elapsed: 26.343889ms
Nov 22 19:17:37.253: INFO: Pod "pod-bdfe3b6c-a7c1-4417-bce2-171485ca866c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028287859s
Nov 22 19:17:39.267: INFO: Pod "pod-bdfe3b6c-a7c1-4417-bce2-171485ca866c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.042429419s
STEP: Saw pod success
Nov 22 19:17:39.267: INFO: Pod "pod-bdfe3b6c-a7c1-4417-bce2-171485ca866c" satisfied condition "success or failure"
Nov 22 19:17:39.269: INFO: Trying to get logs from node minion pod pod-bdfe3b6c-a7c1-4417-bce2-171485ca866c container test-container: <nil>
STEP: delete the pod
Nov 22 19:17:39.299: INFO: Waiting for pod pod-bdfe3b6c-a7c1-4417-bce2-171485ca866c to disappear
Nov 22 19:17:39.312: INFO: Pod pod-bdfe3b6c-a7c1-4417-bce2-171485ca866c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:17:39.312: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4365" for this suite.
Nov 22 19:17:45.349: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:17:45.622: INFO: namespace emptydir-4365 deletion completed in 6.308592641s

• [SLOW TEST:10.495 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:17:45.622: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Nov 22 19:17:45.753: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-8650,SelfLink:/api/v1/namespaces/watch-8650/configmaps/e2e-watch-test-watch-closed,UID:cd43e75e-4778-4c76-ad26-9954482f563a,ResourceVersion:54003,Generation:0,CreationTimestamp:2019-11-22 19:17:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov 22 19:17:45.753: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-8650,SelfLink:/api/v1/namespaces/watch-8650/configmaps/e2e-watch-test-watch-closed,UID:cd43e75e-4778-4c76-ad26-9954482f563a,ResourceVersion:54004,Generation:0,CreationTimestamp:2019-11-22 19:17:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Nov 22 19:17:45.815: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-8650,SelfLink:/api/v1/namespaces/watch-8650/configmaps/e2e-watch-test-watch-closed,UID:cd43e75e-4778-4c76-ad26-9954482f563a,ResourceVersion:54005,Generation:0,CreationTimestamp:2019-11-22 19:17:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov 22 19:17:45.816: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-8650,SelfLink:/api/v1/namespaces/watch-8650/configmaps/e2e-watch-test-watch-closed,UID:cd43e75e-4778-4c76-ad26-9954482f563a,ResourceVersion:54006,Generation:0,CreationTimestamp:2019-11-22 19:17:45 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:17:45.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8650" for this suite.
Nov 22 19:17:51.846: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:17:52.066: INFO: namespace watch-8650 deletion completed in 6.248649801s

• [SLOW TEST:6.444 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:17:52.067: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap configmap-3060/configmap-test-799e50c0-528a-420e-b0a3-a3f1705af62a
STEP: Creating a pod to test consume configMaps
Nov 22 19:17:52.195: INFO: Waiting up to 5m0s for pod "pod-configmaps-90470941-89d5-4c75-909f-201fd46d5b6c" in namespace "configmap-3060" to be "success or failure"
Nov 22 19:17:52.197: INFO: Pod "pod-configmaps-90470941-89d5-4c75-909f-201fd46d5b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0248ms
Nov 22 19:17:54.217: INFO: Pod "pod-configmaps-90470941-89d5-4c75-909f-201fd46d5b6c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021819866s
Nov 22 19:17:56.225: INFO: Pod "pod-configmaps-90470941-89d5-4c75-909f-201fd46d5b6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030067058s
STEP: Saw pod success
Nov 22 19:17:56.225: INFO: Pod "pod-configmaps-90470941-89d5-4c75-909f-201fd46d5b6c" satisfied condition "success or failure"
Nov 22 19:17:56.226: INFO: Trying to get logs from node minion pod pod-configmaps-90470941-89d5-4c75-909f-201fd46d5b6c container env-test: <nil>
STEP: delete the pod
Nov 22 19:17:56.272: INFO: Waiting for pod pod-configmaps-90470941-89d5-4c75-909f-201fd46d5b6c to disappear
Nov 22 19:17:56.278: INFO: Pod pod-configmaps-90470941-89d5-4c75-909f-201fd46d5b6c no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:17:56.278: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3060" for this suite.
Nov 22 19:18:02.340: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:18:02.604: INFO: namespace configmap-3060 deletion completed in 6.321329447s

• [SLOW TEST:10.537 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:18:02.605: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-414db6fa-9eea-43f2-9992-f85d9cff3c1b
STEP: Creating a pod to test consume configMaps
Nov 22 19:18:02.736: INFO: Waiting up to 5m0s for pod "pod-configmaps-d7ebc234-83af-4aa2-b730-07696d6d065f" in namespace "configmap-6340" to be "success or failure"
Nov 22 19:18:02.739: INFO: Pod "pod-configmaps-d7ebc234-83af-4aa2-b730-07696d6d065f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.02257ms
Nov 22 19:18:04.751: INFO: Pod "pod-configmaps-d7ebc234-83af-4aa2-b730-07696d6d065f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015675158s
STEP: Saw pod success
Nov 22 19:18:04.751: INFO: Pod "pod-configmaps-d7ebc234-83af-4aa2-b730-07696d6d065f" satisfied condition "success or failure"
Nov 22 19:18:04.753: INFO: Trying to get logs from node minion pod pod-configmaps-d7ebc234-83af-4aa2-b730-07696d6d065f container configmap-volume-test: <nil>
STEP: delete the pod
Nov 22 19:18:04.788: INFO: Waiting for pod pod-configmaps-d7ebc234-83af-4aa2-b730-07696d6d065f to disappear
Nov 22 19:18:04.815: INFO: Pod pod-configmaps-d7ebc234-83af-4aa2-b730-07696d6d065f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:18:04.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6340" for this suite.
Nov 22 19:18:10.840: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:18:11.103: INFO: namespace configmap-6340 deletion completed in 6.285610306s

• [SLOW TEST:8.498 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:18:11.103: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Nov 22 19:18:11.213: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6ab04779-8063-4a65-86bd-25f917f00acf" in namespace "projected-7019" to be "success or failure"
Nov 22 19:18:11.216: INFO: Pod "downwardapi-volume-6ab04779-8063-4a65-86bd-25f917f00acf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.858087ms
Nov 22 19:18:13.218: INFO: Pod "downwardapi-volume-6ab04779-8063-4a65-86bd-25f917f00acf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004745975s
STEP: Saw pod success
Nov 22 19:18:13.218: INFO: Pod "downwardapi-volume-6ab04779-8063-4a65-86bd-25f917f00acf" satisfied condition "success or failure"
Nov 22 19:18:13.247: INFO: Trying to get logs from node minion pod downwardapi-volume-6ab04779-8063-4a65-86bd-25f917f00acf container client-container: <nil>
STEP: delete the pod
Nov 22 19:18:13.276: INFO: Waiting for pod downwardapi-volume-6ab04779-8063-4a65-86bd-25f917f00acf to disappear
Nov 22 19:18:13.288: INFO: Pod downwardapi-volume-6ab04779-8063-4a65-86bd-25f917f00acf no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:18:13.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7019" for this suite.
Nov 22 19:18:19.310: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:18:19.583: INFO: namespace projected-7019 deletion completed in 6.293765684s

• [SLOW TEST:8.480 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:18:19.583: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Nov 22 19:18:19.678: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 version'
Nov 22 19:18:20.027: INFO: stderr: ""
Nov 22 19:18:20.027: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.3\", GitCommit:\"2d3c76f9091b6bec110a5e63777c332469e0cba2\", GitTreeState:\"clean\", BuildDate:\"2019-08-19T11:13:54Z\", GoVersion:\"go1.12.9\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.3\", GitCommit:\"2d3c76f9091b6bec110a5e63777c332469e0cba2\", GitTreeState:\"clean\", BuildDate:\"2019-08-19T11:05:50Z\", GoVersion:\"go1.12.9\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:18:20.027: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5712" for this suite.
Nov 22 19:18:26.054: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:18:26.328: INFO: namespace kubectl-5712 deletion completed in 6.298953885s

• [SLOW TEST:6.745 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl version
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:18:26.329: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-f0fbacf2-6ef7-4eb9-9d7b-b6c91b74bbf7
STEP: Creating a pod to test consume configMaps
Nov 22 19:18:26.430: INFO: Waiting up to 5m0s for pod "pod-configmaps-f817b4c3-5fa9-4421-9e90-cb3a5a6f675f" in namespace "configmap-8353" to be "success or failure"
Nov 22 19:18:26.433: INFO: Pod "pod-configmaps-f817b4c3-5fa9-4421-9e90-cb3a5a6f675f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.412839ms
Nov 22 19:18:28.468: INFO: Pod "pod-configmaps-f817b4c3-5fa9-4421-9e90-cb3a5a6f675f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.037415744s
STEP: Saw pod success
Nov 22 19:18:28.468: INFO: Pod "pod-configmaps-f817b4c3-5fa9-4421-9e90-cb3a5a6f675f" satisfied condition "success or failure"
Nov 22 19:18:28.472: INFO: Trying to get logs from node minion pod pod-configmaps-f817b4c3-5fa9-4421-9e90-cb3a5a6f675f container configmap-volume-test: <nil>
STEP: delete the pod
Nov 22 19:18:28.532: INFO: Waiting for pod pod-configmaps-f817b4c3-5fa9-4421-9e90-cb3a5a6f675f to disappear
Nov 22 19:18:28.533: INFO: Pod pod-configmaps-f817b4c3-5fa9-4421-9e90-cb3a5a6f675f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:18:28.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8353" for this suite.
Nov 22 19:18:34.576: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:18:34.958: INFO: namespace configmap-8353 deletion completed in 6.410447944s

• [SLOW TEST:8.630 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:18:34.959: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: executing a command with run --rm and attach with stdin
Nov 22 19:18:35.089: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 --namespace=kubectl-4478 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Nov 22 19:18:37.865: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Nov 22 19:18:37.865: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:18:39.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4478" for this suite.
Nov 22 19:18:45.963: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:18:46.226: INFO: namespace kubectl-4478 deletion completed in 6.297501989s

• [SLOW TEST:11.267 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:18:46.248: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Nov 22 19:18:46.394: INFO: Waiting up to 5m0s for pod "downwardapi-volume-21d06a3d-f11c-4bbf-84cb-236ae57e5196" in namespace "projected-4596" to be "success or failure"
Nov 22 19:18:46.400: INFO: Pod "downwardapi-volume-21d06a3d-f11c-4bbf-84cb-236ae57e5196": Phase="Pending", Reason="", readiness=false. Elapsed: 6.326112ms
Nov 22 19:18:48.404: INFO: Pod "downwardapi-volume-21d06a3d-f11c-4bbf-84cb-236ae57e5196": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01015543s
Nov 22 19:18:50.408: INFO: Pod "downwardapi-volume-21d06a3d-f11c-4bbf-84cb-236ae57e5196": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01419685s
STEP: Saw pod success
Nov 22 19:18:50.408: INFO: Pod "downwardapi-volume-21d06a3d-f11c-4bbf-84cb-236ae57e5196" satisfied condition "success or failure"
Nov 22 19:18:50.409: INFO: Trying to get logs from node minion pod downwardapi-volume-21d06a3d-f11c-4bbf-84cb-236ae57e5196 container client-container: <nil>
STEP: delete the pod
Nov 22 19:18:50.453: INFO: Waiting for pod downwardapi-volume-21d06a3d-f11c-4bbf-84cb-236ae57e5196 to disappear
Nov 22 19:18:50.455: INFO: Pod downwardapi-volume-21d06a3d-f11c-4bbf-84cb-236ae57e5196 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:18:50.471: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4596" for this suite.
Nov 22 19:18:56.492: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:18:57.256: INFO: namespace projected-4596 deletion completed in 6.782888936s

• [SLOW TEST:11.008 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:18:57.256: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:19:00.478: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-3012" for this suite.
Nov 22 19:19:24.505: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:19:24.728: INFO: namespace replication-controller-3012 deletion completed in 24.248016141s

• [SLOW TEST:27.472 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:19:24.728: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Nov 22 19:19:30.935: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3447 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 22 19:19:30.935: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
Nov 22 19:19:31.082: INFO: Exec stderr: ""
Nov 22 19:19:31.082: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3447 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 22 19:19:31.082: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
Nov 22 19:19:31.191: INFO: Exec stderr: ""
Nov 22 19:19:31.191: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3447 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 22 19:19:31.191: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
Nov 22 19:19:31.300: INFO: Exec stderr: ""
Nov 22 19:19:31.300: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3447 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 22 19:19:31.300: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
Nov 22 19:19:31.423: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Nov 22 19:19:31.423: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3447 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 22 19:19:31.423: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
Nov 22 19:19:31.541: INFO: Exec stderr: ""
Nov 22 19:19:31.541: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3447 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 22 19:19:31.541: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
Nov 22 19:19:31.658: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Nov 22 19:19:31.658: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3447 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 22 19:19:31.658: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
Nov 22 19:19:31.755: INFO: Exec stderr: ""
Nov 22 19:19:31.755: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3447 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 22 19:19:31.755: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
Nov 22 19:19:31.877: INFO: Exec stderr: ""
Nov 22 19:19:31.877: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-3447 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 22 19:19:31.877: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
Nov 22 19:19:32.035: INFO: Exec stderr: ""
Nov 22 19:19:32.035: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-3447 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 22 19:19:32.035: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
Nov 22 19:19:32.145: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:19:32.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-3447" for this suite.
Nov 22 19:20:14.178: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:20:14.336: INFO: namespace e2e-kubelet-etc-hosts-3447 deletion completed in 42.188978576s

• [SLOW TEST:49.608 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:20:14.337: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on tmpfs
Nov 22 19:20:14.366: INFO: Waiting up to 5m0s for pod "pod-f1aebed0-436c-4bd3-9f14-1a5379110fa6" in namespace "emptydir-6786" to be "success or failure"
Nov 22 19:20:14.369: INFO: Pod "pod-f1aebed0-436c-4bd3-9f14-1a5379110fa6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.381038ms
Nov 22 19:20:16.370: INFO: Pod "pod-f1aebed0-436c-4bd3-9f14-1a5379110fa6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004106259s
STEP: Saw pod success
Nov 22 19:20:16.370: INFO: Pod "pod-f1aebed0-436c-4bd3-9f14-1a5379110fa6" satisfied condition "success or failure"
Nov 22 19:20:16.372: INFO: Trying to get logs from node minion pod pod-f1aebed0-436c-4bd3-9f14-1a5379110fa6 container test-container: <nil>
STEP: delete the pod
Nov 22 19:20:16.381: INFO: Waiting for pod pod-f1aebed0-436c-4bd3-9f14-1a5379110fa6 to disappear
Nov 22 19:20:16.383: INFO: Pod pod-f1aebed0-436c-4bd3-9f14-1a5379110fa6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:20:16.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6786" for this suite.
Nov 22 19:20:22.390: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:20:22.454: INFO: namespace emptydir-6786 deletion completed in 6.068921174s

• [SLOW TEST:8.118 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:20:22.455: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Nov 22 19:20:53.020: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
	[quantile=0.5] = 192
	[quantile=0.9] = 298957
	[quantile=0.99] = 700981
For garbage_collector_attempt_to_delete_work_duration:
	[quantile=0.5] = 389089
	[quantile=0.9] = 757770
	[quantile=0.99] = 843159
For garbage_collector_attempt_to_orphan_queue_latency:
	[quantile=0.5] = 20
	[quantile=0.9] = 20
	[quantile=0.99] = 20
For garbage_collector_attempt_to_orphan_work_duration:
	[quantile=0.5] = 405821
	[quantile=0.9] = 405821
	[quantile=0.99] = 405821
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
	[quantile=0.5] = 5
	[quantile=0.9] = 7
	[quantile=0.99] = 28
For garbage_collector_graph_changes_work_duration:
	[quantile=0.5] = 13
	[quantile=0.9] = 21
	[quantile=0.99] = 82
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
	[quantile=0.5] = 11
	[quantile=0.9] = 20
	[quantile=0.99] = 34
For namespace_queue_latency_sum:
	[] = 8815
For namespace_queue_latency_count:
	[] = 611
For namespace_retries:
	[] = 622
For namespace_work_duration:
	[quantile=0.5] = 577224
	[quantile=0.9] = 943288
	[quantile=0.99] = 1462539
For namespace_work_duration_sum:
	[] = 252948455
For namespace_work_duration_count:
	[] = 611
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:20:53.020: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7729" for this suite.
Nov 22 19:20:59.028: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:20:59.128: INFO: namespace gc-7729 deletion completed in 6.106615429s

• [SLOW TEST:36.674 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:20:59.129: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on node default medium
Nov 22 19:20:59.159: INFO: Waiting up to 5m0s for pod "pod-24a7ceb7-9f52-4033-bc62-18bda2c42aeb" in namespace "emptydir-1603" to be "success or failure"
Nov 22 19:20:59.162: INFO: Pod "pod-24a7ceb7-9f52-4033-bc62-18bda2c42aeb": Phase="Pending", Reason="", readiness=false. Elapsed: 3.06304ms
Nov 22 19:21:01.164: INFO: Pod "pod-24a7ceb7-9f52-4033-bc62-18bda2c42aeb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005237652s
Nov 22 19:21:03.166: INFO: Pod "pod-24a7ceb7-9f52-4033-bc62-18bda2c42aeb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007367916s
STEP: Saw pod success
Nov 22 19:21:03.166: INFO: Pod "pod-24a7ceb7-9f52-4033-bc62-18bda2c42aeb" satisfied condition "success or failure"
Nov 22 19:21:03.168: INFO: Trying to get logs from node minion pod pod-24a7ceb7-9f52-4033-bc62-18bda2c42aeb container test-container: <nil>
STEP: delete the pod
Nov 22 19:21:03.180: INFO: Waiting for pod pod-24a7ceb7-9f52-4033-bc62-18bda2c42aeb to disappear
Nov 22 19:21:03.187: INFO: Pod pod-24a7ceb7-9f52-4033-bc62-18bda2c42aeb no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:21:03.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1603" for this suite.
Nov 22 19:21:09.195: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:21:09.294: INFO: namespace emptydir-1603 deletion completed in 6.104720384s

• [SLOW TEST:10.165 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:21:09.294: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-upd-d180c3e8-809d-44d0-92aa-639e88671d9c
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:21:13.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5033" for this suite.
Nov 22 19:21:37.403: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:21:37.699: INFO: namespace configmap-5033 deletion completed in 24.31117885s

• [SLOW TEST:28.405 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:21:37.700: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test env composition
Nov 22 19:21:37.819: INFO: Waiting up to 5m0s for pod "var-expansion-47a1fbd4-7a18-4496-84c8-f58317dd7976" in namespace "var-expansion-6390" to be "success or failure"
Nov 22 19:21:37.857: INFO: Pod "var-expansion-47a1fbd4-7a18-4496-84c8-f58317dd7976": Phase="Pending", Reason="", readiness=false. Elapsed: 37.951468ms
Nov 22 19:21:39.863: INFO: Pod "var-expansion-47a1fbd4-7a18-4496-84c8-f58317dd7976": Phase="Pending", Reason="", readiness=false. Elapsed: 2.043714415s
Nov 22 19:21:41.894: INFO: Pod "var-expansion-47a1fbd4-7a18-4496-84c8-f58317dd7976": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.07520346s
STEP: Saw pod success
Nov 22 19:21:41.894: INFO: Pod "var-expansion-47a1fbd4-7a18-4496-84c8-f58317dd7976" satisfied condition "success or failure"
Nov 22 19:21:41.896: INFO: Trying to get logs from node minion pod var-expansion-47a1fbd4-7a18-4496-84c8-f58317dd7976 container dapi-container: <nil>
STEP: delete the pod
Nov 22 19:21:41.939: INFO: Waiting for pod var-expansion-47a1fbd4-7a18-4496-84c8-f58317dd7976 to disappear
Nov 22 19:21:41.942: INFO: Pod var-expansion-47a1fbd4-7a18-4496-84c8-f58317dd7976 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:21:41.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-6390" for this suite.
Nov 22 19:21:47.985: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:21:48.321: INFO: namespace var-expansion-6390 deletion completed in 6.356739449s

• [SLOW TEST:10.621 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:21:48.338: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override arguments
Nov 22 19:21:48.480: INFO: Waiting up to 5m0s for pod "client-containers-bffe247b-0c44-4695-ac4f-dc26215ead3f" in namespace "containers-8097" to be "success or failure"
Nov 22 19:21:48.524: INFO: Pod "client-containers-bffe247b-0c44-4695-ac4f-dc26215ead3f": Phase="Pending", Reason="", readiness=false. Elapsed: 43.368951ms
Nov 22 19:21:50.549: INFO: Pod "client-containers-bffe247b-0c44-4695-ac4f-dc26215ead3f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0685697s
STEP: Saw pod success
Nov 22 19:21:50.549: INFO: Pod "client-containers-bffe247b-0c44-4695-ac4f-dc26215ead3f" satisfied condition "success or failure"
Nov 22 19:21:50.550: INFO: Trying to get logs from node minion pod client-containers-bffe247b-0c44-4695-ac4f-dc26215ead3f container test-container: <nil>
STEP: delete the pod
Nov 22 19:21:50.619: INFO: Waiting for pod client-containers-bffe247b-0c44-4695-ac4f-dc26215ead3f to disappear
Nov 22 19:21:50.620: INFO: Pod client-containers-bffe247b-0c44-4695-ac4f-dc26215ead3f no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:21:50.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8097" for this suite.
Nov 22 19:21:56.650: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:21:56.945: INFO: namespace containers-8097 deletion completed in 6.323388058s

• [SLOW TEST:8.607 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:21:56.946: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
Nov 22 19:21:57.855: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
	[quantile=0.5] = 187
	[quantile=0.9] = 298957
	[quantile=0.99] = 700981
For garbage_collector_attempt_to_delete_work_duration:
	[quantile=0.5] = 362756
	[quantile=0.9] = 698960
	[quantile=0.99] = 802943
For garbage_collector_attempt_to_orphan_queue_latency:
	[quantile=0.5] = 20
	[quantile=0.9] = 20
	[quantile=0.99] = 20
For garbage_collector_attempt_to_orphan_work_duration:
	[quantile=0.5] = 405821
	[quantile=0.9] = 405821
	[quantile=0.99] = 405821
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
	[quantile=0.5] = 5
	[quantile=0.9] = 7
	[quantile=0.99] = 28
For garbage_collector_graph_changes_work_duration:
	[quantile=0.5] = 12
	[quantile=0.9] = 22
	[quantile=0.99] = 65
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
	[quantile=0.5] = 11
	[quantile=0.9] = 19
	[quantile=0.99] = 34
For namespace_queue_latency_sum:
	[] = 8895
For namespace_queue_latency_count:
	[] = 617
For namespace_retries:
	[] = 628
For namespace_work_duration:
	[quantile=0.5] = 570949
	[quantile=0.9] = 813759
	[quantile=0.99] = 1169273
For namespace_work_duration_sum:
	[] = 255915676
For namespace_work_duration_count:
	[] = 617
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:21:57.855: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8641" for this suite.
Nov 22 19:22:03.972: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:22:04.253: INFO: namespace gc-8641 deletion completed in 6.382359886s

• [SLOW TEST:7.308 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:22:04.254: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:22:09.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8071" for this suite.
Nov 22 19:22:15.914: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:22:16.348: INFO: namespace watch-8071 deletion completed in 6.549252533s

• [SLOW TEST:12.094 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:22:16.348: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-ecb708c1-9baf-4cfb-a555-85a08621eca4
STEP: Creating a pod to test consume secrets
Nov 22 19:22:16.444: INFO: Waiting up to 5m0s for pod "pod-secrets-e3e01b47-c8ad-472e-9def-de22e84dc408" in namespace "secrets-5162" to be "success or failure"
Nov 22 19:22:16.460: INFO: Pod "pod-secrets-e3e01b47-c8ad-472e-9def-de22e84dc408": Phase="Pending", Reason="", readiness=false. Elapsed: 15.792876ms
Nov 22 19:22:18.481: INFO: Pod "pod-secrets-e3e01b47-c8ad-472e-9def-de22e84dc408": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037434277s
Nov 22 19:22:20.504: INFO: Pod "pod-secrets-e3e01b47-c8ad-472e-9def-de22e84dc408": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.060209641s
STEP: Saw pod success
Nov 22 19:22:20.504: INFO: Pod "pod-secrets-e3e01b47-c8ad-472e-9def-de22e84dc408" satisfied condition "success or failure"
Nov 22 19:22:20.506: INFO: Trying to get logs from node minion pod pod-secrets-e3e01b47-c8ad-472e-9def-de22e84dc408 container secret-volume-test: <nil>
STEP: delete the pod
Nov 22 19:22:20.545: INFO: Waiting for pod pod-secrets-e3e01b47-c8ad-472e-9def-de22e84dc408 to disappear
Nov 22 19:22:20.546: INFO: Pod pod-secrets-e3e01b47-c8ad-472e-9def-de22e84dc408 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:22:20.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5162" for this suite.
Nov 22 19:22:26.584: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:22:26.838: INFO: namespace secrets-5162 deletion completed in 6.273621388s

• [SLOW TEST:10.490 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:22:26.838: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-map-76d6e1d6-b789-4a04-86cf-761f215e1298
STEP: Creating a pod to test consume secrets
Nov 22 19:22:26.966: INFO: Waiting up to 5m0s for pod "pod-secrets-7b4a1da0-97b9-4cbc-a6e6-9babc659b881" in namespace "secrets-6139" to be "success or failure"
Nov 22 19:22:26.969: INFO: Pod "pod-secrets-7b4a1da0-97b9-4cbc-a6e6-9babc659b881": Phase="Pending", Reason="", readiness=false. Elapsed: 2.882153ms
Nov 22 19:22:28.991: INFO: Pod "pod-secrets-7b4a1da0-97b9-4cbc-a6e6-9babc659b881": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.024716583s
STEP: Saw pod success
Nov 22 19:22:28.991: INFO: Pod "pod-secrets-7b4a1da0-97b9-4cbc-a6e6-9babc659b881" satisfied condition "success or failure"
Nov 22 19:22:28.992: INFO: Trying to get logs from node minion pod pod-secrets-7b4a1da0-97b9-4cbc-a6e6-9babc659b881 container secret-volume-test: <nil>
STEP: delete the pod
Nov 22 19:22:29.032: INFO: Waiting for pod pod-secrets-7b4a1da0-97b9-4cbc-a6e6-9babc659b881 to disappear
Nov 22 19:22:29.033: INFO: Pod pod-secrets-7b4a1da0-97b9-4cbc-a6e6-9babc659b881 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:22:29.033: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6139" for this suite.
Nov 22 19:22:35.074: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:22:35.410: INFO: namespace secrets-6139 deletion completed in 6.363272303s

• [SLOW TEST:8.572 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:22:35.411: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Nov 22 19:22:35.529: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8683bfaf-a6dc-40d8-a0cd-333b82f6149f" in namespace "downward-api-4237" to be "success or failure"
Nov 22 19:22:35.573: INFO: Pod "downwardapi-volume-8683bfaf-a6dc-40d8-a0cd-333b82f6149f": Phase="Pending", Reason="", readiness=false. Elapsed: 44.245496ms
Nov 22 19:22:37.577: INFO: Pod "downwardapi-volume-8683bfaf-a6dc-40d8-a0cd-333b82f6149f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.04883484s
STEP: Saw pod success
Nov 22 19:22:37.578: INFO: Pod "downwardapi-volume-8683bfaf-a6dc-40d8-a0cd-333b82f6149f" satisfied condition "success or failure"
Nov 22 19:22:37.579: INFO: Trying to get logs from node minion pod downwardapi-volume-8683bfaf-a6dc-40d8-a0cd-333b82f6149f container client-container: <nil>
STEP: delete the pod
Nov 22 19:22:37.649: INFO: Waiting for pod downwardapi-volume-8683bfaf-a6dc-40d8-a0cd-333b82f6149f to disappear
Nov 22 19:22:37.650: INFO: Pod downwardapi-volume-8683bfaf-a6dc-40d8-a0cd-333b82f6149f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:22:37.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4237" for this suite.
Nov 22 19:22:43.682: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:22:43.931: INFO: namespace downward-api-4237 deletion completed in 6.278228505s

• [SLOW TEST:8.520 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:22:43.931: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on tmpfs
Nov 22 19:22:44.061: INFO: Waiting up to 5m0s for pod "pod-6685613b-1849-484b-94ba-9375877f2359" in namespace "emptydir-1460" to be "success or failure"
Nov 22 19:22:44.078: INFO: Pod "pod-6685613b-1849-484b-94ba-9375877f2359": Phase="Pending", Reason="", readiness=false. Elapsed: 16.871071ms
Nov 22 19:22:46.093: INFO: Pod "pod-6685613b-1849-484b-94ba-9375877f2359": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.03132563s
STEP: Saw pod success
Nov 22 19:22:46.093: INFO: Pod "pod-6685613b-1849-484b-94ba-9375877f2359" satisfied condition "success or failure"
Nov 22 19:22:46.094: INFO: Trying to get logs from node minion pod pod-6685613b-1849-484b-94ba-9375877f2359 container test-container: <nil>
STEP: delete the pod
Nov 22 19:22:46.142: INFO: Waiting for pod pod-6685613b-1849-484b-94ba-9375877f2359 to disappear
Nov 22 19:22:46.143: INFO: Pod pod-6685613b-1849-484b-94ba-9375877f2359 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:22:46.144: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1460" for this suite.
Nov 22 19:22:52.198: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:22:52.512: INFO: namespace emptydir-1460 deletion completed in 6.350186732s

• [SLOW TEST:8.581 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:22:52.512: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:23:17.756: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-9972" for this suite.
Nov 22 19:23:23.789: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:23:24.492: INFO: namespace namespaces-9972 deletion completed in 6.734136417s
STEP: Destroying namespace "nsdeletetest-681" for this suite.
Nov 22 19:23:24.493: INFO: Namespace nsdeletetest-681 was already deleted
STEP: Destroying namespace "nsdeletetest-4543" for this suite.
Nov 22 19:23:30.528: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:23:30.769: INFO: namespace nsdeletetest-4543 deletion completed in 6.276347091s

• [SLOW TEST:38.258 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:23:30.770: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Nov 22 19:23:30.919: INFO: Waiting up to 5m0s for pod "downwardapi-volume-67b15676-ecaa-4463-9958-5e692df3a251" in namespace "projected-1867" to be "success or failure"
Nov 22 19:23:30.937: INFO: Pod "downwardapi-volume-67b15676-ecaa-4463-9958-5e692df3a251": Phase="Pending", Reason="", readiness=false. Elapsed: 17.686633ms
Nov 22 19:23:32.947: INFO: Pod "downwardapi-volume-67b15676-ecaa-4463-9958-5e692df3a251": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027878833s
Nov 22 19:23:34.960: INFO: Pod "downwardapi-volume-67b15676-ecaa-4463-9958-5e692df3a251": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.041212494s
STEP: Saw pod success
Nov 22 19:23:34.960: INFO: Pod "downwardapi-volume-67b15676-ecaa-4463-9958-5e692df3a251" satisfied condition "success or failure"
Nov 22 19:23:34.962: INFO: Trying to get logs from node minion pod downwardapi-volume-67b15676-ecaa-4463-9958-5e692df3a251 container client-container: <nil>
STEP: delete the pod
Nov 22 19:23:34.998: INFO: Waiting for pod downwardapi-volume-67b15676-ecaa-4463-9958-5e692df3a251 to disappear
Nov 22 19:23:35.012: INFO: Pod downwardapi-volume-67b15676-ecaa-4463-9958-5e692df3a251 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:23:35.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1867" for this suite.
Nov 22 19:23:41.059: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:23:41.312: INFO: namespace projected-1867 deletion completed in 6.297983049s

• [SLOW TEST:10.543 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:23:41.312: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Nov 22 19:23:41.414: INFO: Pod name rollover-pod: Found 0 pods out of 1
Nov 22 19:23:46.447: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Nov 22 19:23:46.447: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Nov 22 19:23:48.449: INFO: Creating deployment "test-rollover-deployment"
Nov 22 19:23:48.453: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Nov 22 19:23:50.457: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Nov 22 19:23:50.486: INFO: Ensure that both replica sets have 1 created replica
Nov 22 19:23:50.501: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Nov 22 19:23:50.513: INFO: Updating deployment test-rollover-deployment
Nov 22 19:23:50.513: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Nov 22 19:23:52.578: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Nov 22 19:23:52.601: INFO: Make sure deployment "test-rollover-deployment" is complete
Nov 22 19:23:52.604: INFO: all replica sets need to contain the pod-template-hash label
Nov 22 19:23:52.604: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710047428, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710047428, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710047430, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710047428, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 22 19:23:54.621: INFO: all replica sets need to contain the pod-template-hash label
Nov 22 19:23:54.621: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710047428, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710047428, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710047432, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710047428, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 22 19:23:56.623: INFO: all replica sets need to contain the pod-template-hash label
Nov 22 19:23:56.623: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710047428, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710047428, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710047432, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710047428, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 22 19:23:58.630: INFO: all replica sets need to contain the pod-template-hash label
Nov 22 19:23:58.630: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710047428, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710047428, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710047432, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710047428, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 22 19:24:00.628: INFO: all replica sets need to contain the pod-template-hash label
Nov 22 19:24:00.628: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710047428, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710047428, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710047432, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710047428, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 22 19:24:02.623: INFO: all replica sets need to contain the pod-template-hash label
Nov 22 19:24:02.623: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710047428, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710047428, loc:(*time.Location)(0x7ec7a20)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710047432, loc:(*time.Location)(0x7ec7a20)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710047428, loc:(*time.Location)(0x7ec7a20)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 22 19:24:04.620: INFO: 
Nov 22 19:24:04.620: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Nov 22 19:24:04.637: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-728,SelfLink:/apis/apps/v1/namespaces/deployment-728/deployments/test-rollover-deployment,UID:5316d7a7-99d7-404c-af33-e7631a193b1e,ResourceVersion:55765,Generation:2,CreationTimestamp:2019-11-22 19:23:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-11-22 19:23:48 +0000 UTC 2019-11-22 19:23:48 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-11-22 19:24:02 +0000 UTC 2019-11-22 19:23:48 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-854595fc44" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Nov 22 19:24:04.651: INFO: New ReplicaSet "test-rollover-deployment-854595fc44" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-854595fc44,GenerateName:,Namespace:deployment-728,SelfLink:/apis/apps/v1/namespaces/deployment-728/replicasets/test-rollover-deployment-854595fc44,UID:eb2bdaf2-63b3-4c1d-97a9-77de9dee357a,ResourceVersion:55754,Generation:2,CreationTimestamp:2019-11-22 19:23:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 5316d7a7-99d7-404c-af33-e7631a193b1e 0xc000055787 0xc000055788}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Nov 22 19:24:04.651: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Nov 22 19:24:04.652: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-728,SelfLink:/apis/apps/v1/namespaces/deployment-728/replicasets/test-rollover-controller,UID:bb972530-3eb0-438c-8e1c-7fa6b128dac1,ResourceVersion:55764,Generation:2,CreationTimestamp:2019-11-22 19:23:41 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 5316d7a7-99d7-404c-af33-e7631a193b1e 0xc000055627 0xc000055628}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Nov 22 19:24:04.652: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-9b8b997cf,GenerateName:,Namespace:deployment-728,SelfLink:/apis/apps/v1/namespaces/deployment-728/replicasets/test-rollover-deployment-9b8b997cf,UID:f466fc0e-4caa-4e94-982a-eac684620b7d,ResourceVersion:55714,Generation:2,CreationTimestamp:2019-11-22 19:23:48 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 5316d7a7-99d7-404c-af33-e7631a193b1e 0xc0000558b0 0xc0000558b1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Nov 22 19:24:04.653: INFO: Pod "test-rollover-deployment-854595fc44-m8d2b" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-854595fc44-m8d2b,GenerateName:test-rollover-deployment-854595fc44-,Namespace:deployment-728,SelfLink:/api/v1/namespaces/deployment-728/pods/test-rollover-deployment-854595fc44-m8d2b,UID:ad241386-291a-4ac6-b59f-0bd478e8ac80,ResourceVersion:55726,Generation:0,CreationTimestamp:2019-11-22 19:23:50 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-854595fc44 eb2bdaf2-63b3-4c1d-97a9-77de9dee357a 0xc002c426b7 0xc002c426b8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5lhm9 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5lhm9,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-5lhm9 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002c42730} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002c42750}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:23:50 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:23:52 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:23:52 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:23:50 +0000 UTC  }],Message:,Reason:,HostIP:172.31.44.47,PodIP:10.251.128.10,StartTime:2019-11-22 19:23:50 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-11-22 19:23:52 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 docker-pullable://gcr.io/kubernetes-e2e-test-images/redis@sha256:af4748d1655c08dc54d4be5182135395db9ce87aba2d4699b26b14ae197c5830 docker://a93f097ba03cd3ff2f5c9a4a0cfd74dcdb272e8667abb78d602528cbd013dbbc}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:24:04.653: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-728" for this suite.
Nov 22 19:24:12.672: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:24:12.921: INFO: namespace deployment-728 deletion completed in 8.257553956s

• [SLOW TEST:31.609 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:24:12.921: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Nov 22 19:24:13.001: INFO: Creating deployment "nginx-deployment"
Nov 22 19:24:13.016: INFO: Waiting for observed generation 1
Nov 22 19:24:15.019: INFO: Waiting for all required pods to come up
Nov 22 19:24:15.037: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Nov 22 19:24:21.073: INFO: Waiting for deployment "nginx-deployment" to complete
Nov 22 19:24:21.100: INFO: Updating deployment "nginx-deployment" with a non-existent image
Nov 22 19:24:21.105: INFO: Updating deployment nginx-deployment
Nov 22 19:24:21.105: INFO: Waiting for observed generation 2
Nov 22 19:24:23.120: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Nov 22 19:24:23.134: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Nov 22 19:24:23.135: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Nov 22 19:24:23.139: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Nov 22 19:24:23.139: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Nov 22 19:24:23.150: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Nov 22 19:24:23.153: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Nov 22 19:24:23.153: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Nov 22 19:24:23.175: INFO: Updating deployment nginx-deployment
Nov 22 19:24:23.175: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Nov 22 19:24:23.186: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Nov 22 19:24:23.200: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Nov 22 19:24:23.296: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-2086,SelfLink:/apis/apps/v1/namespaces/deployment-2086/deployments/nginx-deployment,UID:0210156d-ce5c-4391-b494-6f3682ca5e0c,ResourceVersion:56037,Generation:3,CreationTimestamp:2019-11-22 19:24:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[{Progressing True 2019-11-22 19:24:21 +0000 UTC 2019-11-22 19:24:13 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-55fb7cb77f" is progressing.} {Available False 2019-11-22 19:24:23 +0000 UTC 2019-11-22 19:24:23 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}],ReadyReplicas:8,CollisionCount:nil,},}

Nov 22 19:24:23.398: INFO: New ReplicaSet "nginx-deployment-55fb7cb77f" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f,GenerateName:,Namespace:deployment-2086,SelfLink:/apis/apps/v1/namespaces/deployment-2086/replicasets/nginx-deployment-55fb7cb77f,UID:cb849e5c-8ff3-4f75-969b-21ef3119d051,ResourceVersion:56034,Generation:3,CreationTimestamp:2019-11-22 19:24:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 0210156d-ce5c-4391-b494-6f3682ca5e0c 0xc003727887 0xc003727888}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Nov 22 19:24:23.398: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Nov 22 19:24:23.399: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498,GenerateName:,Namespace:deployment-2086,SelfLink:/apis/apps/v1/namespaces/deployment-2086/replicasets/nginx-deployment-7b8c6f4498,UID:55274022-48f5-436c-9948-fc7301f320a2,ResourceVersion:56033,Generation:3,CreationTimestamp:2019-11-22 19:24:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 0210156d-ce5c-4391-b494-6f3682ca5e0c 0xc003727957 0xc003727958}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Nov 22 19:24:23.443: INFO: Pod "nginx-deployment-55fb7cb77f-25w5l" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-25w5l,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-2086,SelfLink:/api/v1/namespaces/deployment-2086/pods/nginx-deployment-55fb7cb77f-25w5l,UID:54c0cd94-8058-423c-adb8-c30987741489,ResourceVersion:56077,Generation:0,CreationTimestamp:2019-11-22 19:24:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f cb849e5c-8ff3-4f75-969b-21ef3119d051 0xc00365c487 0xc00365c488}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kpzkg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kpzkg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-kpzkg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00365c500} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00365c520}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:23 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 22 19:24:23.444: INFO: Pod "nginx-deployment-55fb7cb77f-2c6x4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-2c6x4,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-2086,SelfLink:/api/v1/namespaces/deployment-2086/pods/nginx-deployment-55fb7cb77f-2c6x4,UID:30a3ce75-cbff-41a8-b7e1-3d6c29b72fbb,ResourceVersion:56050,Generation:0,CreationTimestamp:2019-11-22 19:24:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f cb849e5c-8ff3-4f75-969b-21ef3119d051 0xc00365c5a0 0xc00365c5a1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kpzkg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kpzkg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-kpzkg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00365c620} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00365c640}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:23 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 22 19:24:23.444: INFO: Pod "nginx-deployment-55fb7cb77f-2p2pd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-2p2pd,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-2086,SelfLink:/api/v1/namespaces/deployment-2086/pods/nginx-deployment-55fb7cb77f-2p2pd,UID:9f863c1f-a3ef-4b34-b486-8f82bd7c3b8d,ResourceVersion:56075,Generation:0,CreationTimestamp:2019-11-22 19:24:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f cb849e5c-8ff3-4f75-969b-21ef3119d051 0xc00365c6c0 0xc00365c6c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kpzkg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kpzkg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-kpzkg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00365c730} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00365c750}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 22 19:24:23.444: INFO: Pod "nginx-deployment-55fb7cb77f-56rxl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-56rxl,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-2086,SelfLink:/api/v1/namespaces/deployment-2086/pods/nginx-deployment-55fb7cb77f-56rxl,UID:d998308c-5919-4191-be40-b7966d7a945c,ResourceVersion:56024,Generation:0,CreationTimestamp:2019-11-22 19:24:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f cb849e5c-8ff3-4f75-969b-21ef3119d051 0xc00365c7b7 0xc00365c7b8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kpzkg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kpzkg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-kpzkg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00365c830} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00365c850}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:21 +0000 UTC  }],Message:,Reason:,HostIP:172.31.44.47,PodIP:,StartTime:2019-11-22 19:24:21 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 22 19:24:23.444: INFO: Pod "nginx-deployment-55fb7cb77f-5hh28" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-5hh28,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-2086,SelfLink:/api/v1/namespaces/deployment-2086/pods/nginx-deployment-55fb7cb77f-5hh28,UID:19183d58-c58c-4015-b1cf-1aad292b9820,ResourceVersion:56074,Generation:0,CreationTimestamp:2019-11-22 19:24:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f cb849e5c-8ff3-4f75-969b-21ef3119d051 0xc00365c920 0xc00365c921}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kpzkg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kpzkg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-kpzkg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00365c9a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00365c9c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:23 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 22 19:24:23.444: INFO: Pod "nginx-deployment-55fb7cb77f-5s7bf" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-5s7bf,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-2086,SelfLink:/api/v1/namespaces/deployment-2086/pods/nginx-deployment-55fb7cb77f-5s7bf,UID:42658600-0a9e-4c15-b505-1277c354398d,ResourceVersion:56007,Generation:0,CreationTimestamp:2019-11-22 19:24:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f cb849e5c-8ff3-4f75-969b-21ef3119d051 0xc00365ca40 0xc00365ca41}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kpzkg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kpzkg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-kpzkg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00365cac0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00365cae0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:21 +0000 UTC  }],Message:,Reason:,HostIP:172.31.44.47,PodIP:,StartTime:2019-11-22 19:24:21 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 22 19:24:23.444: INFO: Pod "nginx-deployment-55fb7cb77f-6cxb4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-6cxb4,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-2086,SelfLink:/api/v1/namespaces/deployment-2086/pods/nginx-deployment-55fb7cb77f-6cxb4,UID:7e923a37-0441-43b4-a642-dafb8a2a450b,ResourceVersion:56068,Generation:0,CreationTimestamp:2019-11-22 19:24:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f cb849e5c-8ff3-4f75-969b-21ef3119d051 0xc00365cbb0 0xc00365cbb1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kpzkg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kpzkg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-kpzkg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00365cc30} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00365cc50}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:23 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 22 19:24:23.444: INFO: Pod "nginx-deployment-55fb7cb77f-8rmrz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-8rmrz,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-2086,SelfLink:/api/v1/namespaces/deployment-2086/pods/nginx-deployment-55fb7cb77f-8rmrz,UID:fe0c79ef-d016-4cc6-9fd0-227015b20f96,ResourceVersion:55988,Generation:0,CreationTimestamp:2019-11-22 19:24:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f cb849e5c-8ff3-4f75-969b-21ef3119d051 0xc00365ccd0 0xc00365ccd1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kpzkg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kpzkg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-kpzkg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00365cd50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00365cd70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:21 +0000 UTC  }],Message:,Reason:,HostIP:172.31.44.47,PodIP:,StartTime:2019-11-22 19:24:21 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 22 19:24:23.445: INFO: Pod "nginx-deployment-55fb7cb77f-985q7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-985q7,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-2086,SelfLink:/api/v1/namespaces/deployment-2086/pods/nginx-deployment-55fb7cb77f-985q7,UID:fe2e4a94-0020-4460-af08-092e705c6ef2,ResourceVersion:56076,Generation:0,CreationTimestamp:2019-11-22 19:24:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f cb849e5c-8ff3-4f75-969b-21ef3119d051 0xc00365ce40 0xc00365ce41}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kpzkg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kpzkg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-kpzkg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00365cec0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00365cee0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:23 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 22 19:24:23.445: INFO: Pod "nginx-deployment-55fb7cb77f-g444r" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-g444r,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-2086,SelfLink:/api/v1/namespaces/deployment-2086/pods/nginx-deployment-55fb7cb77f-g444r,UID:147d0f8f-2cf4-4494-b6b9-99173be18988,ResourceVersion:56023,Generation:0,CreationTimestamp:2019-11-22 19:24:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f cb849e5c-8ff3-4f75-969b-21ef3119d051 0xc00365cf60 0xc00365cf61}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kpzkg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kpzkg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-kpzkg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00365cfe0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00365d000}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:21 +0000 UTC  }],Message:,Reason:,HostIP:172.31.44.47,PodIP:,StartTime:2019-11-22 19:24:21 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 22 19:24:23.445: INFO: Pod "nginx-deployment-55fb7cb77f-llpns" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-llpns,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-2086,SelfLink:/api/v1/namespaces/deployment-2086/pods/nginx-deployment-55fb7cb77f-llpns,UID:52413b9e-0ba5-4e0d-ba24-c7b12e9a76e3,ResourceVersion:56073,Generation:0,CreationTimestamp:2019-11-22 19:24:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f cb849e5c-8ff3-4f75-969b-21ef3119d051 0xc00365d0d0 0xc00365d0d1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kpzkg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kpzkg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-kpzkg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00365d150} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00365d170}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:23 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 22 19:24:23.445: INFO: Pod "nginx-deployment-55fb7cb77f-m7prj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-m7prj,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-2086,SelfLink:/api/v1/namespaces/deployment-2086/pods/nginx-deployment-55fb7cb77f-m7prj,UID:40044c99-6617-43f5-aac3-dd81f2594af7,ResourceVersion:56055,Generation:0,CreationTimestamp:2019-11-22 19:24:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f cb849e5c-8ff3-4f75-969b-21ef3119d051 0xc00365d1f0 0xc00365d1f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kpzkg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kpzkg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-kpzkg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00365d270} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00365d290}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:23 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 22 19:24:23.445: INFO: Pod "nginx-deployment-55fb7cb77f-ttrcc" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-ttrcc,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-2086,SelfLink:/api/v1/namespaces/deployment-2086/pods/nginx-deployment-55fb7cb77f-ttrcc,UID:4c4e68e8-2f42-4171-b099-09123c735022,ResourceVersion:55997,Generation:0,CreationTimestamp:2019-11-22 19:24:21 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f cb849e5c-8ff3-4f75-969b-21ef3119d051 0xc00365d310 0xc00365d311}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kpzkg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kpzkg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-kpzkg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00365d390} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00365d3b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:21 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:21 +0000 UTC  }],Message:,Reason:,HostIP:172.31.44.47,PodIP:,StartTime:2019-11-22 19:24:21 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 22 19:24:23.445: INFO: Pod "nginx-deployment-7b8c6f4498-42sd4" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-42sd4,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2086,SelfLink:/api/v1/namespaces/deployment-2086/pods/nginx-deployment-7b8c6f4498-42sd4,UID:a045667f-e803-43db-b455-27ccb0db4a1c,ResourceVersion:56064,Generation:0,CreationTimestamp:2019-11-22 19:24:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 55274022-48f5-436c-9948-fc7301f320a2 0xc00365d480 0xc00365d481}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kpzkg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kpzkg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kpzkg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00365d4f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00365d510}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:23 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:23 +0000 UTC  }],Message:,Reason:,HostIP:172.31.44.47,PodIP:,StartTime:2019-11-22 19:24:23 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 22 19:24:23.445: INFO: Pod "nginx-deployment-7b8c6f4498-4m57d" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-4m57d,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2086,SelfLink:/api/v1/namespaces/deployment-2086/pods/nginx-deployment-7b8c6f4498-4m57d,UID:7b2f34ea-3783-4fb5-93f9-7fe47b46f050,ResourceVersion:56058,Generation:0,CreationTimestamp:2019-11-22 19:24:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 55274022-48f5-436c-9948-fc7301f320a2 0xc00365d5d7 0xc00365d5d8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kpzkg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kpzkg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kpzkg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00365d650} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00365d670}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:23 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 22 19:24:23.445: INFO: Pod "nginx-deployment-7b8c6f4498-5s548" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-5s548,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2086,SelfLink:/api/v1/namespaces/deployment-2086/pods/nginx-deployment-7b8c6f4498-5s548,UID:8bb996ce-4e78-46ec-a6c7-f1cebc7316fa,ResourceVersion:55912,Generation:0,CreationTimestamp:2019-11-22 19:24:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 55274022-48f5-436c-9948-fc7301f320a2 0xc00365d6f0 0xc00365d6f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kpzkg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kpzkg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kpzkg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00365d760} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00365d780}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:15 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:15 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:13 +0000 UTC  }],Message:,Reason:,HostIP:172.31.44.47,PodIP:10.251.128.10,StartTime:2019-11-22 19:24:13 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-11-22 19:24:15 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://5e0ff5b7e70b3969d6ee45d7248d63535b56d2b73812292e08a098ab92d40a87}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 22 19:24:23.446: INFO: Pod "nginx-deployment-7b8c6f4498-64rfw" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-64rfw,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2086,SelfLink:/api/v1/namespaces/deployment-2086/pods/nginx-deployment-7b8c6f4498-64rfw,UID:183c802a-69de-40f9-9797-d6c32750c742,ResourceVersion:55956,Generation:0,CreationTimestamp:2019-11-22 19:24:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 55274022-48f5-436c-9948-fc7301f320a2 0xc00365d857 0xc00365d858}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kpzkg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kpzkg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kpzkg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00365d8d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00365d8f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:16 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:16 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:13 +0000 UTC  }],Message:,Reason:,HostIP:172.31.44.47,PodIP:10.251.128.12,StartTime:2019-11-22 19:24:13 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-11-22 19:24:15 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://e57dc6f2758e84508836355c41fff8209d9d8a6904a654c92cc11fd05e387e7a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 22 19:24:23.459: INFO: Pod "nginx-deployment-7b8c6f4498-7vtt8" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-7vtt8,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2086,SelfLink:/api/v1/namespaces/deployment-2086/pods/nginx-deployment-7b8c6f4498-7vtt8,UID:76e388fc-3ce0-42f0-b15d-b7c22754cf00,ResourceVersion:55944,Generation:0,CreationTimestamp:2019-11-22 19:24:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 55274022-48f5-436c-9948-fc7301f320a2 0xc00365d9c7 0xc00365d9c8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kpzkg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kpzkg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kpzkg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00365da40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00365da60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:16 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:16 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:13 +0000 UTC  }],Message:,Reason:,HostIP:172.31.44.47,PodIP:10.251.128.14,StartTime:2019-11-22 19:24:13 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-11-22 19:24:16 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://a019dc5f332776dc719eaf74d0ba3c2c64a3b9ef3d662f0a7c6539cfd24555e0}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 22 19:24:23.460: INFO: Pod "nginx-deployment-7b8c6f4498-8g4fp" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-8g4fp,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2086,SelfLink:/api/v1/namespaces/deployment-2086/pods/nginx-deployment-7b8c6f4498-8g4fp,UID:be7705a8-f38f-42f6-a9e1-07036130dbe2,ResourceVersion:56070,Generation:0,CreationTimestamp:2019-11-22 19:24:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 55274022-48f5-436c-9948-fc7301f320a2 0xc00365db37 0xc00365db38}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kpzkg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kpzkg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kpzkg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00365dba0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00365dbc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 22 19:24:23.460: INFO: Pod "nginx-deployment-7b8c6f4498-crgd9" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-crgd9,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2086,SelfLink:/api/v1/namespaces/deployment-2086/pods/nginx-deployment-7b8c6f4498-crgd9,UID:7c6da51b-c4dc-44aa-a93e-47e69ba5c609,ResourceVersion:55918,Generation:0,CreationTimestamp:2019-11-22 19:24:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 55274022-48f5-436c-9948-fc7301f320a2 0xc00365dc27 0xc00365dc28}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kpzkg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kpzkg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kpzkg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00365dca0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00365dcc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:15 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:15 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:13 +0000 UTC  }],Message:,Reason:,HostIP:172.31.44.47,PodIP:10.251.128.9,StartTime:2019-11-22 19:24:13 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-11-22 19:24:14 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://8bc0ce76e5def4758d2b9609f613ffcb3f7b15f24994f085ee65523ea0c61a2b}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 22 19:24:23.460: INFO: Pod "nginx-deployment-7b8c6f4498-d72nx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-d72nx,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2086,SelfLink:/api/v1/namespaces/deployment-2086/pods/nginx-deployment-7b8c6f4498-d72nx,UID:2c57f775-b2fe-4507-b517-8433d69d4ef6,ResourceVersion:56062,Generation:0,CreationTimestamp:2019-11-22 19:24:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 55274022-48f5-436c-9948-fc7301f320a2 0xc00365dda7 0xc00365dda8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kpzkg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kpzkg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kpzkg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00365de20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00365de40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:23 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 22 19:24:23.460: INFO: Pod "nginx-deployment-7b8c6f4498-dfgp8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-dfgp8,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2086,SelfLink:/api/v1/namespaces/deployment-2086/pods/nginx-deployment-7b8c6f4498-dfgp8,UID:3f9e7dcb-aae8-4cc1-b41f-7ddcb0971811,ResourceVersion:56067,Generation:0,CreationTimestamp:2019-11-22 19:24:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 55274022-48f5-436c-9948-fc7301f320a2 0xc00365dec0 0xc00365dec1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kpzkg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kpzkg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kpzkg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00365df20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00365df40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 22 19:24:23.460: INFO: Pod "nginx-deployment-7b8c6f4498-f2ccn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-f2ccn,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2086,SelfLink:/api/v1/namespaces/deployment-2086/pods/nginx-deployment-7b8c6f4498-f2ccn,UID:909460b6-1e76-41f6-a19f-4d34a4c329a9,ResourceVersion:56054,Generation:0,CreationTimestamp:2019-11-22 19:24:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 55274022-48f5-436c-9948-fc7301f320a2 0xc00365dfb7 0xc00365dfb8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kpzkg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kpzkg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kpzkg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003840030} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003840050}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:23 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 22 19:24:23.460: INFO: Pod "nginx-deployment-7b8c6f4498-flh6m" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-flh6m,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2086,SelfLink:/api/v1/namespaces/deployment-2086/pods/nginx-deployment-7b8c6f4498-flh6m,UID:f7bf2c3d-1763-4d19-9d82-c7c5c0d055b0,ResourceVersion:56069,Generation:0,CreationTimestamp:2019-11-22 19:24:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 55274022-48f5-436c-9948-fc7301f320a2 0xc0038400d0 0xc0038400d1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kpzkg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kpzkg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kpzkg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003840130} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003840150}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 22 19:24:23.460: INFO: Pod "nginx-deployment-7b8c6f4498-g8d88" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-g8d88,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2086,SelfLink:/api/v1/namespaces/deployment-2086/pods/nginx-deployment-7b8c6f4498-g8d88,UID:1a614e90-2559-4a4d-a7b5-537c51ab16eb,ResourceVersion:55925,Generation:0,CreationTimestamp:2019-11-22 19:24:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 55274022-48f5-436c-9948-fc7301f320a2 0xc0038401b7 0xc0038401b8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kpzkg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kpzkg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kpzkg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003840230} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003840250}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:15 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:15 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:13 +0000 UTC  }],Message:,Reason:,HostIP:172.31.44.47,PodIP:10.251.128.8,StartTime:2019-11-22 19:24:13 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-11-22 19:24:14 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://b0df0c3627924a4c74e65a900d7af16d8cda8b3c58b968920a85b6281d297ebb}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 22 19:24:23.460: INFO: Pod "nginx-deployment-7b8c6f4498-jlw8l" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-jlw8l,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2086,SelfLink:/api/v1/namespaces/deployment-2086/pods/nginx-deployment-7b8c6f4498-jlw8l,UID:d1458c58-42bd-4e6c-959c-6807203af3c9,ResourceVersion:56051,Generation:0,CreationTimestamp:2019-11-22 19:24:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 55274022-48f5-436c-9948-fc7301f320a2 0xc003840327 0xc003840328}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kpzkg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kpzkg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kpzkg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0038403a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0038403c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:23 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 22 19:24:23.461: INFO: Pod "nginx-deployment-7b8c6f4498-jm8bl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-jm8bl,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2086,SelfLink:/api/v1/namespaces/deployment-2086/pods/nginx-deployment-7b8c6f4498-jm8bl,UID:9822e3e1-1943-4e7c-b0e9-070ba22c78f2,ResourceVersion:56065,Generation:0,CreationTimestamp:2019-11-22 19:24:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 55274022-48f5-436c-9948-fc7301f320a2 0xc003840440 0xc003840441}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kpzkg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kpzkg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kpzkg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0038404b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0038404d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:23 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 22 19:24:23.461: INFO: Pod "nginx-deployment-7b8c6f4498-lq4lz" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-lq4lz,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2086,SelfLink:/api/v1/namespaces/deployment-2086/pods/nginx-deployment-7b8c6f4498-lq4lz,UID:495e2157-d08c-4eea-ae12-2247aaedca32,ResourceVersion:55949,Generation:0,CreationTimestamp:2019-11-22 19:24:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 55274022-48f5-436c-9948-fc7301f320a2 0xc003840550 0xc003840551}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kpzkg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kpzkg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kpzkg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0038405c0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0038405e0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:16 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:16 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:13 +0000 UTC  }],Message:,Reason:,HostIP:172.31.44.47,PodIP:10.251.128.11,StartTime:2019-11-22 19:24:13 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-11-22 19:24:15 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://f9906cde7fae7a772c3b2eb32fa110c2a74ff5a5b01cc143cceb02ca3949d07a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 22 19:24:23.461: INFO: Pod "nginx-deployment-7b8c6f4498-qb7ml" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-qb7ml,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2086,SelfLink:/api/v1/namespaces/deployment-2086/pods/nginx-deployment-7b8c6f4498-qb7ml,UID:b58109de-4870-4610-8213-050a30752653,ResourceVersion:55936,Generation:0,CreationTimestamp:2019-11-22 19:24:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 55274022-48f5-436c-9948-fc7301f320a2 0xc0038406b7 0xc0038406b8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kpzkg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kpzkg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kpzkg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003840740} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003840760}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:16 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:16 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:13 +0000 UTC  }],Message:,Reason:,HostIP:172.31.44.47,PodIP:10.251.128.15,StartTime:2019-11-22 19:24:13 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-11-22 19:24:15 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://3179d0999451b8bb5bedad44b8ad42677b412c8690995e8b146c1e6307c16966}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 22 19:24:23.461: INFO: Pod "nginx-deployment-7b8c6f4498-r2fkr" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-r2fkr,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2086,SelfLink:/api/v1/namespaces/deployment-2086/pods/nginx-deployment-7b8c6f4498-r2fkr,UID:dc7389b6-cb63-4a73-8dc7-87fa8e483f90,ResourceVersion:55960,Generation:0,CreationTimestamp:2019-11-22 19:24:13 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 55274022-48f5-436c-9948-fc7301f320a2 0xc003840837 0xc003840838}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kpzkg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kpzkg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kpzkg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0038408b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0038408d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:13 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:16 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:16 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:13 +0000 UTC  }],Message:,Reason:,HostIP:172.31.44.47,PodIP:10.251.128.17,StartTime:2019-11-22 19:24:13 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-11-22 19:24:15 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://c855205b0b70d5834547ab5cf72f3211e905b0bc5576995354cb12ff4a8e5965}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 22 19:24:23.461: INFO: Pod "nginx-deployment-7b8c6f4498-rqxzr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-rqxzr,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2086,SelfLink:/api/v1/namespaces/deployment-2086/pods/nginx-deployment-7b8c6f4498-rqxzr,UID:d0dff5af-6877-42a4-929e-5b58fbd8321c,ResourceVersion:56066,Generation:0,CreationTimestamp:2019-11-22 19:24:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 55274022-48f5-436c-9948-fc7301f320a2 0xc0038409a7 0xc0038409a8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kpzkg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kpzkg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kpzkg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003840a10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003840a30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 22 19:24:23.461: INFO: Pod "nginx-deployment-7b8c6f4498-z8g2f" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-z8g2f,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2086,SelfLink:/api/v1/namespaces/deployment-2086/pods/nginx-deployment-7b8c6f4498-z8g2f,UID:a9523ef9-6407-401a-8bab-46f7c56363b5,ResourceVersion:56056,Generation:0,CreationTimestamp:2019-11-22 19:24:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 55274022-48f5-436c-9948-fc7301f320a2 0xc003840a97 0xc003840a98}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kpzkg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kpzkg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kpzkg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003840b10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003840b30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:24:23 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Nov 22 19:24:23.461: INFO: Pod "nginx-deployment-7b8c6f4498-zh9v7" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-zh9v7,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-2086,SelfLink:/api/v1/namespaces/deployment-2086/pods/nginx-deployment-7b8c6f4498-zh9v7,UID:d1d51bbc-3a88-4596-b851-60ffa165ade4,ResourceVersion:56071,Generation:0,CreationTimestamp:2019-11-22 19:24:23 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 55274022-48f5-436c-9948-fc7301f320a2 0xc003840bb0 0xc003840bb1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kpzkg {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kpzkg,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kpzkg true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003840c10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003840c30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:24:23.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2086" for this suite.
Nov 22 19:24:33.643: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:24:33.910: INFO: namespace deployment-2086 deletion completed in 10.403016338s

• [SLOW TEST:20.989 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:24:33.940: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:24:59.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-6150" for this suite.
Nov 22 19:25:05.751: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:25:06.446: INFO: namespace container-runtime-6150 deletion completed in 6.716833985s

• [SLOW TEST:32.506 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    when starting a container that exits
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:25:06.446: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9618.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9618.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov 22 19:25:10.583: INFO: DNS probes using dns-9618/dns-test-d8d32b73-0c29-4210-b26e-bf2fbfc8ffeb succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:25:10.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9618" for this suite.
Nov 22 19:25:16.606: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:25:16.675: INFO: namespace dns-9618 deletion completed in 6.076130287s

• [SLOW TEST:10.229 seconds]
[sig-network] DNS
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:25:16.675: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Nov 22 19:25:16.706: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d58765b8-e6ff-40f2-9b6c-067412e83f94" in namespace "downward-api-9832" to be "success or failure"
Nov 22 19:25:16.715: INFO: Pod "downwardapi-volume-d58765b8-e6ff-40f2-9b6c-067412e83f94": Phase="Pending", Reason="", readiness=false. Elapsed: 8.797253ms
Nov 22 19:25:18.717: INFO: Pod "downwardapi-volume-d58765b8-e6ff-40f2-9b6c-067412e83f94": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010702347s
Nov 22 19:25:20.719: INFO: Pod "downwardapi-volume-d58765b8-e6ff-40f2-9b6c-067412e83f94": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012684145s
STEP: Saw pod success
Nov 22 19:25:20.719: INFO: Pod "downwardapi-volume-d58765b8-e6ff-40f2-9b6c-067412e83f94" satisfied condition "success or failure"
Nov 22 19:25:20.721: INFO: Trying to get logs from node minion pod downwardapi-volume-d58765b8-e6ff-40f2-9b6c-067412e83f94 container client-container: <nil>
STEP: delete the pod
Nov 22 19:25:20.735: INFO: Waiting for pod downwardapi-volume-d58765b8-e6ff-40f2-9b6c-067412e83f94 to disappear
Nov 22 19:25:20.742: INFO: Pod downwardapi-volume-d58765b8-e6ff-40f2-9b6c-067412e83f94 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:25:20.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9832" for this suite.
Nov 22 19:25:26.750: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:25:26.825: INFO: namespace downward-api-9832 deletion completed in 6.081423063s

• [SLOW TEST:10.150 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:25:26.826: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating replication controller svc-latency-rc in namespace svc-latency-2437
I1122 19:25:26.858745      19 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: svc-latency-2437, replica count: 1
I1122 19:25:27.909129      19 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1122 19:25:28.909398      19 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1122 19:25:29.909649      19 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov 22 19:25:30.074: INFO: Created: latency-svc-zx5m9
Nov 22 19:25:30.083: INFO: Got endpoints: latency-svc-zx5m9 [73.781214ms]
Nov 22 19:25:30.097: INFO: Created: latency-svc-xp8d8
Nov 22 19:25:30.116: INFO: Created: latency-svc-t25dm
Nov 22 19:25:30.116: INFO: Got endpoints: latency-svc-xp8d8 [32.653411ms]
Nov 22 19:25:30.119: INFO: Got endpoints: latency-svc-t25dm [33.801961ms]
Nov 22 19:25:30.122: INFO: Created: latency-svc-xh268
Nov 22 19:25:30.128: INFO: Got endpoints: latency-svc-xh268 [44.003428ms]
Nov 22 19:25:30.131: INFO: Created: latency-svc-2knck
Nov 22 19:25:30.139: INFO: Got endpoints: latency-svc-2knck [54.271478ms]
Nov 22 19:25:30.143: INFO: Created: latency-svc-lm7cr
Nov 22 19:25:30.151: INFO: Got endpoints: latency-svc-lm7cr [66.367405ms]
Nov 22 19:25:30.159: INFO: Created: latency-svc-clxkw
Nov 22 19:25:30.168: INFO: Got endpoints: latency-svc-clxkw [82.757648ms]
Nov 22 19:25:30.170: INFO: Created: latency-svc-tdqs5
Nov 22 19:25:30.180: INFO: Got endpoints: latency-svc-tdqs5 [95.213186ms]
Nov 22 19:25:30.197: INFO: Created: latency-svc-rldrf
Nov 22 19:25:30.199: INFO: Got endpoints: latency-svc-rldrf [114.724135ms]
Nov 22 19:25:30.204: INFO: Created: latency-svc-hvqvb
Nov 22 19:25:30.210: INFO: Got endpoints: latency-svc-hvqvb [125.14767ms]
Nov 22 19:25:30.214: INFO: Created: latency-svc-pknsb
Nov 22 19:25:30.235: INFO: Got endpoints: latency-svc-pknsb [149.525057ms]
Nov 22 19:25:30.236: INFO: Created: latency-svc-tbg6d
Nov 22 19:25:30.239: INFO: Got endpoints: latency-svc-tbg6d [153.473445ms]
Nov 22 19:25:30.252: INFO: Created: latency-svc-vrdsj
Nov 22 19:25:30.261: INFO: Got endpoints: latency-svc-vrdsj [175.802679ms]
Nov 22 19:25:30.265: INFO: Created: latency-svc-jnzjx
Nov 22 19:25:30.271: INFO: Got endpoints: latency-svc-jnzjx [186.006977ms]
Nov 22 19:25:30.277: INFO: Created: latency-svc-crnpb
Nov 22 19:25:30.284: INFO: Got endpoints: latency-svc-crnpb [198.695017ms]
Nov 22 19:25:30.290: INFO: Created: latency-svc-sbrll
Nov 22 19:25:30.295: INFO: Got endpoints: latency-svc-sbrll [209.504598ms]
Nov 22 19:25:30.303: INFO: Created: latency-svc-pxcm4
Nov 22 19:25:30.307: INFO: Got endpoints: latency-svc-pxcm4 [190.815682ms]
Nov 22 19:25:30.311: INFO: Created: latency-svc-jjj5n
Nov 22 19:25:30.319: INFO: Got endpoints: latency-svc-jjj5n [199.522547ms]
Nov 22 19:25:30.322: INFO: Created: latency-svc-mdc74
Nov 22 19:25:30.333: INFO: Got endpoints: latency-svc-mdc74 [205.326166ms]
Nov 22 19:25:30.355: INFO: Created: latency-svc-dqr5m
Nov 22 19:25:30.359: INFO: Got endpoints: latency-svc-dqr5m [220.361575ms]
Nov 22 19:25:30.368: INFO: Created: latency-svc-jtgb8
Nov 22 19:25:30.373: INFO: Got endpoints: latency-svc-jtgb8 [222.046896ms]
Nov 22 19:25:30.373: INFO: Created: latency-svc-wbdqt
Nov 22 19:25:30.380: INFO: Got endpoints: latency-svc-wbdqt [212.742612ms]
Nov 22 19:25:30.383: INFO: Created: latency-svc-5g2q8
Nov 22 19:25:30.392: INFO: Got endpoints: latency-svc-5g2q8 [212.219731ms]
Nov 22 19:25:30.394: INFO: Created: latency-svc-7dg2n
Nov 22 19:25:30.404: INFO: Got endpoints: latency-svc-7dg2n [204.196883ms]
Nov 22 19:25:30.408: INFO: Created: latency-svc-mzbcp
Nov 22 19:25:30.416: INFO: Got endpoints: latency-svc-mzbcp [206.180785ms]
Nov 22 19:25:30.420: INFO: Created: latency-svc-l6vw5
Nov 22 19:25:30.431: INFO: Got endpoints: latency-svc-l6vw5 [195.967712ms]
Nov 22 19:25:30.440: INFO: Created: latency-svc-hgdw7
Nov 22 19:25:30.450: INFO: Got endpoints: latency-svc-hgdw7 [210.974623ms]
Nov 22 19:25:30.454: INFO: Created: latency-svc-pbzqw
Nov 22 19:25:30.463: INFO: Got endpoints: latency-svc-pbzqw [201.399517ms]
Nov 22 19:25:30.464: INFO: Created: latency-svc-5lmvj
Nov 22 19:25:30.473: INFO: Got endpoints: latency-svc-5lmvj [201.880725ms]
Nov 22 19:25:30.477: INFO: Created: latency-svc-25qbm
Nov 22 19:25:30.484: INFO: Got endpoints: latency-svc-25qbm [199.980228ms]
Nov 22 19:25:30.488: INFO: Created: latency-svc-x9cv7
Nov 22 19:25:30.498: INFO: Got endpoints: latency-svc-x9cv7 [202.236567ms]
Nov 22 19:25:30.503: INFO: Created: latency-svc-bkkww
Nov 22 19:25:30.509: INFO: Got endpoints: latency-svc-bkkww [202.319658ms]
Nov 22 19:25:30.512: INFO: Created: latency-svc-qhxrs
Nov 22 19:25:30.524: INFO: Got endpoints: latency-svc-qhxrs [205.109932ms]
Nov 22 19:25:30.545: INFO: Created: latency-svc-lmd8d
Nov 22 19:25:30.554: INFO: Got endpoints: latency-svc-lmd8d [220.369382ms]
Nov 22 19:25:30.558: INFO: Created: latency-svc-snfkj
Nov 22 19:25:30.567: INFO: Got endpoints: latency-svc-snfkj [208.095473ms]
Nov 22 19:25:30.580: INFO: Created: latency-svc-cpkht
Nov 22 19:25:30.581: INFO: Got endpoints: latency-svc-cpkht [208.719907ms]
Nov 22 19:25:30.596: INFO: Created: latency-svc-ltrnq
Nov 22 19:25:30.605: INFO: Got endpoints: latency-svc-ltrnq [224.640491ms]
Nov 22 19:25:30.608: INFO: Created: latency-svc-jwjv5
Nov 22 19:25:30.616: INFO: Got endpoints: latency-svc-jwjv5 [223.980823ms]
Nov 22 19:25:30.619: INFO: Created: latency-svc-pnmdn
Nov 22 19:25:30.628: INFO: Got endpoints: latency-svc-pnmdn [224.187596ms]
Nov 22 19:25:30.635: INFO: Created: latency-svc-fp2k5
Nov 22 19:25:30.641: INFO: Got endpoints: latency-svc-fp2k5 [225.203434ms]
Nov 22 19:25:30.643: INFO: Created: latency-svc-j9chf
Nov 22 19:25:30.653: INFO: Got endpoints: latency-svc-j9chf [222.23921ms]
Nov 22 19:25:30.657: INFO: Created: latency-svc-bx7bf
Nov 22 19:25:30.679: INFO: Got endpoints: latency-svc-bx7bf [229.816561ms]
Nov 22 19:25:30.679: INFO: Created: latency-svc-8sfxc
Nov 22 19:25:30.690: INFO: Created: latency-svc-rdbs4
Nov 22 19:25:30.701: INFO: Created: latency-svc-tchvp
Nov 22 19:25:30.713: INFO: Created: latency-svc-thlzn
Nov 22 19:25:30.723: INFO: Created: latency-svc-k4z2l
Nov 22 19:25:30.732: INFO: Got endpoints: latency-svc-8sfxc [269.572314ms]
Nov 22 19:25:30.738: INFO: Created: latency-svc-6gccb
Nov 22 19:25:30.750: INFO: Created: latency-svc-f4569
Nov 22 19:25:30.760: INFO: Created: latency-svc-d26b9
Nov 22 19:25:30.770: INFO: Created: latency-svc-fp7lq
Nov 22 19:25:30.789: INFO: Got endpoints: latency-svc-rdbs4 [316.172174ms]
Nov 22 19:25:30.791: INFO: Created: latency-svc-qjbms
Nov 22 19:25:30.805: INFO: Created: latency-svc-tvbrd
Nov 22 19:25:30.815: INFO: Created: latency-svc-pwf25
Nov 22 19:25:30.826: INFO: Created: latency-svc-zxrsq
Nov 22 19:25:30.834: INFO: Got endpoints: latency-svc-tchvp [350.030231ms]
Nov 22 19:25:30.838: INFO: Created: latency-svc-2bgw2
Nov 22 19:25:30.848: INFO: Created: latency-svc-9pzrp
Nov 22 19:25:30.862: INFO: Created: latency-svc-527lv
Nov 22 19:25:30.874: INFO: Created: latency-svc-j6wjb
Nov 22 19:25:30.881: INFO: Got endpoints: latency-svc-thlzn [383.207409ms]
Nov 22 19:25:30.883: INFO: Created: latency-svc-cgp4b
Nov 22 19:25:30.904: INFO: Created: latency-svc-mhlxj
Nov 22 19:25:30.927: INFO: Got endpoints: latency-svc-k4z2l [417.671864ms]
Nov 22 19:25:30.940: INFO: Created: latency-svc-cn89f
Nov 22 19:25:30.977: INFO: Got endpoints: latency-svc-6gccb [453.318921ms]
Nov 22 19:25:30.984: INFO: Created: latency-svc-jttsb
Nov 22 19:25:31.028: INFO: Got endpoints: latency-svc-f4569 [474.103939ms]
Nov 22 19:25:31.034: INFO: Created: latency-svc-hw8d9
Nov 22 19:25:31.079: INFO: Got endpoints: latency-svc-d26b9 [512.00457ms]
Nov 22 19:25:31.090: INFO: Created: latency-svc-rlklq
Nov 22 19:25:31.128: INFO: Got endpoints: latency-svc-fp7lq [546.468931ms]
Nov 22 19:25:31.134: INFO: Created: latency-svc-4k8mj
Nov 22 19:25:31.178: INFO: Got endpoints: latency-svc-qjbms [572.646796ms]
Nov 22 19:25:31.185: INFO: Created: latency-svc-cpjl6
Nov 22 19:25:31.231: INFO: Got endpoints: latency-svc-tvbrd [614.429366ms]
Nov 22 19:25:31.246: INFO: Created: latency-svc-n5c72
Nov 22 19:25:31.277: INFO: Got endpoints: latency-svc-pwf25 [649.333782ms]
Nov 22 19:25:31.283: INFO: Created: latency-svc-8jpkc
Nov 22 19:25:31.328: INFO: Got endpoints: latency-svc-zxrsq [686.093044ms]
Nov 22 19:25:31.338: INFO: Created: latency-svc-g9x4q
Nov 22 19:25:31.379: INFO: Got endpoints: latency-svc-2bgw2 [726.068699ms]
Nov 22 19:25:31.386: INFO: Created: latency-svc-92tw4
Nov 22 19:25:31.427: INFO: Got endpoints: latency-svc-9pzrp [747.749ms]
Nov 22 19:25:31.438: INFO: Created: latency-svc-dr49h
Nov 22 19:25:31.477: INFO: Got endpoints: latency-svc-527lv [745.223198ms]
Nov 22 19:25:31.483: INFO: Created: latency-svc-l4fll
Nov 22 19:25:31.528: INFO: Got endpoints: latency-svc-j6wjb [737.991867ms]
Nov 22 19:25:31.540: INFO: Created: latency-svc-8zsxb
Nov 22 19:25:31.579: INFO: Got endpoints: latency-svc-cgp4b [745.16156ms]
Nov 22 19:25:31.586: INFO: Created: latency-svc-zcqjz
Nov 22 19:25:31.627: INFO: Got endpoints: latency-svc-mhlxj [746.370119ms]
Nov 22 19:25:31.633: INFO: Created: latency-svc-qzms2
Nov 22 19:25:31.678: INFO: Got endpoints: latency-svc-cn89f [750.510622ms]
Nov 22 19:25:31.684: INFO: Created: latency-svc-xdk45
Nov 22 19:25:31.728: INFO: Got endpoints: latency-svc-jttsb [750.444672ms]
Nov 22 19:25:31.742: INFO: Created: latency-svc-t478b
Nov 22 19:25:31.778: INFO: Got endpoints: latency-svc-hw8d9 [750.528534ms]
Nov 22 19:25:31.786: INFO: Created: latency-svc-tw26m
Nov 22 19:25:31.827: INFO: Got endpoints: latency-svc-rlklq [747.938242ms]
Nov 22 19:25:31.834: INFO: Created: latency-svc-ndh8m
Nov 22 19:25:31.878: INFO: Got endpoints: latency-svc-4k8mj [750.349177ms]
Nov 22 19:25:31.891: INFO: Created: latency-svc-phnk5
Nov 22 19:25:31.927: INFO: Got endpoints: latency-svc-cpjl6 [748.837847ms]
Nov 22 19:25:31.935: INFO: Created: latency-svc-kcpsm
Nov 22 19:25:31.977: INFO: Got endpoints: latency-svc-n5c72 [746.600743ms]
Nov 22 19:25:31.983: INFO: Created: latency-svc-rzj4s
Nov 22 19:25:32.029: INFO: Got endpoints: latency-svc-8jpkc [751.486586ms]
Nov 22 19:25:32.037: INFO: Created: latency-svc-79n2z
Nov 22 19:25:32.078: INFO: Got endpoints: latency-svc-g9x4q [749.826437ms]
Nov 22 19:25:32.084: INFO: Created: latency-svc-72zlh
Nov 22 19:25:32.131: INFO: Got endpoints: latency-svc-92tw4 [752.064083ms]
Nov 22 19:25:32.138: INFO: Created: latency-svc-n69vn
Nov 22 19:25:32.180: INFO: Got endpoints: latency-svc-dr49h [753.076316ms]
Nov 22 19:25:32.193: INFO: Created: latency-svc-k4hlp
Nov 22 19:25:32.229: INFO: Got endpoints: latency-svc-l4fll [751.250102ms]
Nov 22 19:25:32.236: INFO: Created: latency-svc-vqrfk
Nov 22 19:25:32.278: INFO: Got endpoints: latency-svc-8zsxb [750.519043ms]
Nov 22 19:25:32.289: INFO: Created: latency-svc-g84xw
Nov 22 19:25:32.328: INFO: Got endpoints: latency-svc-zcqjz [748.751783ms]
Nov 22 19:25:32.336: INFO: Created: latency-svc-vqb5f
Nov 22 19:25:32.378: INFO: Got endpoints: latency-svc-qzms2 [750.185679ms]
Nov 22 19:25:32.388: INFO: Created: latency-svc-pzgr6
Nov 22 19:25:32.428: INFO: Got endpoints: latency-svc-xdk45 [749.791092ms]
Nov 22 19:25:32.442: INFO: Created: latency-svc-qbbkx
Nov 22 19:25:32.479: INFO: Got endpoints: latency-svc-t478b [751.455708ms]
Nov 22 19:25:32.490: INFO: Created: latency-svc-fkg5c
Nov 22 19:25:32.527: INFO: Got endpoints: latency-svc-tw26m [748.652632ms]
Nov 22 19:25:32.535: INFO: Created: latency-svc-ffrxh
Nov 22 19:25:32.579: INFO: Got endpoints: latency-svc-ndh8m [752.051979ms]
Nov 22 19:25:32.587: INFO: Created: latency-svc-69msp
Nov 22 19:25:32.627: INFO: Got endpoints: latency-svc-phnk5 [748.42462ms]
Nov 22 19:25:32.641: INFO: Created: latency-svc-brk2n
Nov 22 19:25:32.682: INFO: Got endpoints: latency-svc-kcpsm [754.66897ms]
Nov 22 19:25:32.688: INFO: Created: latency-svc-bf782
Nov 22 19:25:32.728: INFO: Got endpoints: latency-svc-rzj4s [750.83045ms]
Nov 22 19:25:32.735: INFO: Created: latency-svc-gsqs6
Nov 22 19:25:32.782: INFO: Got endpoints: latency-svc-79n2z [752.813902ms]
Nov 22 19:25:32.788: INFO: Created: latency-svc-wvpbm
Nov 22 19:25:32.828: INFO: Got endpoints: latency-svc-72zlh [750.006526ms]
Nov 22 19:25:32.839: INFO: Created: latency-svc-zmpct
Nov 22 19:25:32.880: INFO: Got endpoints: latency-svc-n69vn [748.767001ms]
Nov 22 19:25:32.887: INFO: Created: latency-svc-wq6wk
Nov 22 19:25:32.934: INFO: Got endpoints: latency-svc-k4hlp [753.097395ms]
Nov 22 19:25:32.940: INFO: Created: latency-svc-ls7cc
Nov 22 19:25:32.978: INFO: Got endpoints: latency-svc-vqrfk [748.802826ms]
Nov 22 19:25:32.983: INFO: Created: latency-svc-rnnk9
Nov 22 19:25:33.028: INFO: Got endpoints: latency-svc-g84xw [749.500805ms]
Nov 22 19:25:33.034: INFO: Created: latency-svc-zgmhx
Nov 22 19:25:33.078: INFO: Got endpoints: latency-svc-vqb5f [749.95248ms]
Nov 22 19:25:33.085: INFO: Created: latency-svc-s9xgw
Nov 22 19:25:33.128: INFO: Got endpoints: latency-svc-pzgr6 [750.165139ms]
Nov 22 19:25:33.134: INFO: Created: latency-svc-sfnvh
Nov 22 19:25:33.178: INFO: Got endpoints: latency-svc-qbbkx [750.504221ms]
Nov 22 19:25:33.184: INFO: Created: latency-svc-r8fbh
Nov 22 19:25:33.227: INFO: Got endpoints: latency-svc-fkg5c [747.783058ms]
Nov 22 19:25:33.241: INFO: Created: latency-svc-9jwcj
Nov 22 19:25:33.279: INFO: Got endpoints: latency-svc-ffrxh [752.323704ms]
Nov 22 19:25:33.287: INFO: Created: latency-svc-7h7f4
Nov 22 19:25:33.327: INFO: Got endpoints: latency-svc-69msp [747.865201ms]
Nov 22 19:25:33.333: INFO: Created: latency-svc-zl2d7
Nov 22 19:25:33.378: INFO: Got endpoints: latency-svc-brk2n [751.163893ms]
Nov 22 19:25:33.392: INFO: Created: latency-svc-xbbt9
Nov 22 19:25:33.427: INFO: Got endpoints: latency-svc-bf782 [745.103714ms]
Nov 22 19:25:33.432: INFO: Created: latency-svc-c4x7q
Nov 22 19:25:33.478: INFO: Got endpoints: latency-svc-gsqs6 [749.605492ms]
Nov 22 19:25:33.483: INFO: Created: latency-svc-7cx46
Nov 22 19:25:33.527: INFO: Got endpoints: latency-svc-wvpbm [745.103988ms]
Nov 22 19:25:33.541: INFO: Created: latency-svc-dxcn9
Nov 22 19:25:33.579: INFO: Got endpoints: latency-svc-zmpct [750.831376ms]
Nov 22 19:25:33.585: INFO: Created: latency-svc-fpdfn
Nov 22 19:25:33.628: INFO: Got endpoints: latency-svc-wq6wk [748.53463ms]
Nov 22 19:25:33.636: INFO: Created: latency-svc-q7fg2
Nov 22 19:25:33.679: INFO: Got endpoints: latency-svc-ls7cc [745.121764ms]
Nov 22 19:25:33.685: INFO: Created: latency-svc-bhs5x
Nov 22 19:25:33.727: INFO: Got endpoints: latency-svc-rnnk9 [749.349633ms]
Nov 22 19:25:33.740: INFO: Created: latency-svc-sjh8n
Nov 22 19:25:33.782: INFO: Got endpoints: latency-svc-zgmhx [754.312428ms]
Nov 22 19:25:33.787: INFO: Created: latency-svc-p6wfz
Nov 22 19:25:33.828: INFO: Got endpoints: latency-svc-s9xgw [749.414597ms]
Nov 22 19:25:33.839: INFO: Created: latency-svc-xn4kk
Nov 22 19:25:33.879: INFO: Got endpoints: latency-svc-sfnvh [751.49348ms]
Nov 22 19:25:33.886: INFO: Created: latency-svc-28tp5
Nov 22 19:25:33.927: INFO: Got endpoints: latency-svc-r8fbh [748.729936ms]
Nov 22 19:25:33.934: INFO: Created: latency-svc-cz22s
Nov 22 19:25:33.981: INFO: Got endpoints: latency-svc-9jwcj [754.001669ms]
Nov 22 19:25:33.987: INFO: Created: latency-svc-x6lcz
Nov 22 19:25:34.027: INFO: Got endpoints: latency-svc-7h7f4 [747.691634ms]
Nov 22 19:25:34.040: INFO: Created: latency-svc-bf6vl
Nov 22 19:25:34.078: INFO: Got endpoints: latency-svc-zl2d7 [750.905313ms]
Nov 22 19:25:34.086: INFO: Created: latency-svc-prnzs
Nov 22 19:25:34.128: INFO: Got endpoints: latency-svc-xbbt9 [750.052363ms]
Nov 22 19:25:34.139: INFO: Created: latency-svc-rk8x6
Nov 22 19:25:34.178: INFO: Got endpoints: latency-svc-c4x7q [750.398116ms]
Nov 22 19:25:34.184: INFO: Created: latency-svc-k54zp
Nov 22 19:25:34.227: INFO: Got endpoints: latency-svc-7cx46 [749.472509ms]
Nov 22 19:25:34.237: INFO: Created: latency-svc-8wbwh
Nov 22 19:25:34.277: INFO: Got endpoints: latency-svc-dxcn9 [750.212036ms]
Nov 22 19:25:34.290: INFO: Created: latency-svc-bht5f
Nov 22 19:25:34.328: INFO: Got endpoints: latency-svc-fpdfn [748.90573ms]
Nov 22 19:25:34.340: INFO: Created: latency-svc-rwzzh
Nov 22 19:25:34.378: INFO: Got endpoints: latency-svc-q7fg2 [749.857983ms]
Nov 22 19:25:34.388: INFO: Created: latency-svc-nb86g
Nov 22 19:25:34.427: INFO: Got endpoints: latency-svc-bhs5x [748.205643ms]
Nov 22 19:25:34.443: INFO: Created: latency-svc-849lx
Nov 22 19:25:34.477: INFO: Got endpoints: latency-svc-sjh8n [750.344964ms]
Nov 22 19:25:34.484: INFO: Created: latency-svc-vk864
Nov 22 19:25:34.527: INFO: Got endpoints: latency-svc-p6wfz [745.132593ms]
Nov 22 19:25:34.535: INFO: Created: latency-svc-bk5cr
Nov 22 19:25:34.577: INFO: Got endpoints: latency-svc-xn4kk [749.673416ms]
Nov 22 19:25:34.616: INFO: Created: latency-svc-sn9l9
Nov 22 19:25:34.627: INFO: Got endpoints: latency-svc-28tp5 [747.647932ms]
Nov 22 19:25:34.633: INFO: Created: latency-svc-72hsg
Nov 22 19:25:34.678: INFO: Got endpoints: latency-svc-cz22s [750.79749ms]
Nov 22 19:25:34.684: INFO: Created: latency-svc-ptnsj
Nov 22 19:25:34.728: INFO: Got endpoints: latency-svc-x6lcz [746.963426ms]
Nov 22 19:25:34.745: INFO: Created: latency-svc-5kprs
Nov 22 19:25:34.777: INFO: Got endpoints: latency-svc-bf6vl [750.298725ms]
Nov 22 19:25:34.797: INFO: Created: latency-svc-nqv8z
Nov 22 19:25:34.828: INFO: Got endpoints: latency-svc-prnzs [749.716778ms]
Nov 22 19:25:34.846: INFO: Created: latency-svc-jxkk2
Nov 22 19:25:34.877: INFO: Got endpoints: latency-svc-rk8x6 [749.212374ms]
Nov 22 19:25:34.884: INFO: Created: latency-svc-z4q4t
Nov 22 19:25:34.935: INFO: Got endpoints: latency-svc-k54zp [757.350195ms]
Nov 22 19:25:34.943: INFO: Created: latency-svc-lqqbk
Nov 22 19:25:34.978: INFO: Got endpoints: latency-svc-8wbwh [750.141ms]
Nov 22 19:25:34.985: INFO: Created: latency-svc-k8stb
Nov 22 19:25:35.028: INFO: Got endpoints: latency-svc-bht5f [750.77551ms]
Nov 22 19:25:35.039: INFO: Created: latency-svc-lk4gm
Nov 22 19:25:35.078: INFO: Got endpoints: latency-svc-rwzzh [749.913673ms]
Nov 22 19:25:35.087: INFO: Created: latency-svc-vk7z5
Nov 22 19:25:35.129: INFO: Got endpoints: latency-svc-nb86g [750.343411ms]
Nov 22 19:25:35.144: INFO: Created: latency-svc-9dgck
Nov 22 19:25:35.177: INFO: Got endpoints: latency-svc-849lx [750.465591ms]
Nov 22 19:25:35.192: INFO: Created: latency-svc-cbdz4
Nov 22 19:25:35.227: INFO: Got endpoints: latency-svc-vk864 [749.99215ms]
Nov 22 19:25:35.235: INFO: Created: latency-svc-8q7mf
Nov 22 19:25:35.277: INFO: Got endpoints: latency-svc-bk5cr [749.896039ms]
Nov 22 19:25:35.285: INFO: Created: latency-svc-464hw
Nov 22 19:25:35.328: INFO: Got endpoints: latency-svc-sn9l9 [750.063323ms]
Nov 22 19:25:35.355: INFO: Created: latency-svc-4hxw5
Nov 22 19:25:35.378: INFO: Got endpoints: latency-svc-72hsg [750.395118ms]
Nov 22 19:25:35.383: INFO: Created: latency-svc-mjttt
Nov 22 19:25:35.428: INFO: Got endpoints: latency-svc-ptnsj [749.993758ms]
Nov 22 19:25:35.436: INFO: Created: latency-svc-8djjm
Nov 22 19:25:35.478: INFO: Got endpoints: latency-svc-5kprs [749.42799ms]
Nov 22 19:25:35.484: INFO: Created: latency-svc-qlk8h
Nov 22 19:25:35.528: INFO: Got endpoints: latency-svc-nqv8z [750.640793ms]
Nov 22 19:25:35.534: INFO: Created: latency-svc-zsc9z
Nov 22 19:25:35.578: INFO: Got endpoints: latency-svc-jxkk2 [749.597432ms]
Nov 22 19:25:35.587: INFO: Created: latency-svc-fcs8d
Nov 22 19:25:35.628: INFO: Got endpoints: latency-svc-z4q4t [750.239085ms]
Nov 22 19:25:35.634: INFO: Created: latency-svc-84pn2
Nov 22 19:25:35.677: INFO: Got endpoints: latency-svc-lqqbk [742.550498ms]
Nov 22 19:25:35.683: INFO: Created: latency-svc-m62rk
Nov 22 19:25:35.727: INFO: Got endpoints: latency-svc-k8stb [749.942505ms]
Nov 22 19:25:35.734: INFO: Created: latency-svc-ch49j
Nov 22 19:25:35.778: INFO: Got endpoints: latency-svc-lk4gm [750.35709ms]
Nov 22 19:25:35.795: INFO: Created: latency-svc-srkpq
Nov 22 19:25:35.827: INFO: Got endpoints: latency-svc-vk7z5 [749.183706ms]
Nov 22 19:25:35.834: INFO: Created: latency-svc-fbt6p
Nov 22 19:25:35.878: INFO: Got endpoints: latency-svc-9dgck [748.761779ms]
Nov 22 19:25:35.885: INFO: Created: latency-svc-qdmhs
Nov 22 19:25:35.927: INFO: Got endpoints: latency-svc-cbdz4 [749.667001ms]
Nov 22 19:25:35.934: INFO: Created: latency-svc-b7blp
Nov 22 19:25:35.979: INFO: Got endpoints: latency-svc-8q7mf [751.790299ms]
Nov 22 19:25:35.995: INFO: Created: latency-svc-tnjp7
Nov 22 19:25:36.027: INFO: Got endpoints: latency-svc-464hw [749.808672ms]
Nov 22 19:25:36.033: INFO: Created: latency-svc-tkhg2
Nov 22 19:25:36.077: INFO: Got endpoints: latency-svc-4hxw5 [749.237937ms]
Nov 22 19:25:36.086: INFO: Created: latency-svc-2rkdx
Nov 22 19:25:36.128: INFO: Got endpoints: latency-svc-mjttt [750.23968ms]
Nov 22 19:25:36.134: INFO: Created: latency-svc-2lrwl
Nov 22 19:25:36.179: INFO: Got endpoints: latency-svc-8djjm [750.985042ms]
Nov 22 19:25:36.190: INFO: Created: latency-svc-24sj5
Nov 22 19:25:36.228: INFO: Got endpoints: latency-svc-qlk8h [750.182626ms]
Nov 22 19:25:36.234: INFO: Created: latency-svc-glnw6
Nov 22 19:25:36.279: INFO: Got endpoints: latency-svc-zsc9z [750.973493ms]
Nov 22 19:25:36.286: INFO: Created: latency-svc-8tfmx
Nov 22 19:25:36.328: INFO: Got endpoints: latency-svc-fcs8d [749.882666ms]
Nov 22 19:25:36.334: INFO: Created: latency-svc-mgc2x
Nov 22 19:25:36.378: INFO: Got endpoints: latency-svc-84pn2 [749.604194ms]
Nov 22 19:25:36.385: INFO: Created: latency-svc-t6nkq
Nov 22 19:25:36.428: INFO: Got endpoints: latency-svc-m62rk [750.047414ms]
Nov 22 19:25:36.433: INFO: Created: latency-svc-kl9lx
Nov 22 19:25:36.478: INFO: Got endpoints: latency-svc-ch49j [750.278515ms]
Nov 22 19:25:36.485: INFO: Created: latency-svc-jq8r6
Nov 22 19:25:36.528: INFO: Got endpoints: latency-svc-srkpq [749.516774ms]
Nov 22 19:25:36.546: INFO: Created: latency-svc-d7hdj
Nov 22 19:25:36.578: INFO: Got endpoints: latency-svc-fbt6p [751.213449ms]
Nov 22 19:25:36.591: INFO: Created: latency-svc-prnjn
Nov 22 19:25:36.627: INFO: Got endpoints: latency-svc-qdmhs [749.847938ms]
Nov 22 19:25:36.633: INFO: Created: latency-svc-wttlg
Nov 22 19:25:36.679: INFO: Got endpoints: latency-svc-b7blp [751.734577ms]
Nov 22 19:25:36.699: INFO: Created: latency-svc-x79zk
Nov 22 19:25:36.727: INFO: Got endpoints: latency-svc-tnjp7 [747.972645ms]
Nov 22 19:25:36.735: INFO: Created: latency-svc-bhbgw
Nov 22 19:25:36.778: INFO: Got endpoints: latency-svc-tkhg2 [750.188185ms]
Nov 22 19:25:36.784: INFO: Created: latency-svc-kgmt2
Nov 22 19:25:36.829: INFO: Got endpoints: latency-svc-2rkdx [751.895047ms]
Nov 22 19:25:36.835: INFO: Created: latency-svc-wrwcf
Nov 22 19:25:36.878: INFO: Got endpoints: latency-svc-2lrwl [749.981104ms]
Nov 22 19:25:36.883: INFO: Created: latency-svc-br6zs
Nov 22 19:25:36.928: INFO: Got endpoints: latency-svc-24sj5 [749.161332ms]
Nov 22 19:25:36.935: INFO: Created: latency-svc-mdmr2
Nov 22 19:25:36.978: INFO: Got endpoints: latency-svc-glnw6 [750.323174ms]
Nov 22 19:25:36.986: INFO: Created: latency-svc-6dvvb
Nov 22 19:25:37.029: INFO: Got endpoints: latency-svc-8tfmx [749.313972ms]
Nov 22 19:25:37.034: INFO: Created: latency-svc-qlcxd
Nov 22 19:25:37.078: INFO: Got endpoints: latency-svc-mgc2x [750.469263ms]
Nov 22 19:25:37.087: INFO: Created: latency-svc-hxwz5
Nov 22 19:25:37.130: INFO: Got endpoints: latency-svc-t6nkq [751.363456ms]
Nov 22 19:25:37.136: INFO: Created: latency-svc-58nsr
Nov 22 19:25:37.180: INFO: Got endpoints: latency-svc-kl9lx [752.597653ms]
Nov 22 19:25:37.186: INFO: Created: latency-svc-zhblm
Nov 22 19:25:37.227: INFO: Got endpoints: latency-svc-jq8r6 [748.985212ms]
Nov 22 19:25:37.233: INFO: Created: latency-svc-dgcdr
Nov 22 19:25:37.278: INFO: Got endpoints: latency-svc-d7hdj [750.663608ms]
Nov 22 19:25:37.286: INFO: Created: latency-svc-vr6rs
Nov 22 19:25:37.328: INFO: Got endpoints: latency-svc-prnjn [749.371082ms]
Nov 22 19:25:37.337: INFO: Created: latency-svc-mr454
Nov 22 19:25:37.378: INFO: Got endpoints: latency-svc-wttlg [750.525816ms]
Nov 22 19:25:37.383: INFO: Created: latency-svc-qx4hc
Nov 22 19:25:37.427: INFO: Got endpoints: latency-svc-x79zk [748.307278ms]
Nov 22 19:25:37.434: INFO: Created: latency-svc-mrhqx
Nov 22 19:25:37.479: INFO: Got endpoints: latency-svc-bhbgw [751.243739ms]
Nov 22 19:25:37.485: INFO: Created: latency-svc-9vrv6
Nov 22 19:25:37.530: INFO: Got endpoints: latency-svc-kgmt2 [752.115925ms]
Nov 22 19:25:37.535: INFO: Created: latency-svc-v2v7j
Nov 22 19:25:37.577: INFO: Got endpoints: latency-svc-wrwcf [748.082093ms]
Nov 22 19:25:37.596: INFO: Created: latency-svc-5jvf9
Nov 22 19:25:37.628: INFO: Got endpoints: latency-svc-br6zs [749.558782ms]
Nov 22 19:25:37.642: INFO: Created: latency-svc-f2bm9
Nov 22 19:25:37.677: INFO: Got endpoints: latency-svc-mdmr2 [748.818808ms]
Nov 22 19:25:37.683: INFO: Created: latency-svc-r27dx
Nov 22 19:25:37.728: INFO: Got endpoints: latency-svc-6dvvb [749.693371ms]
Nov 22 19:25:37.735: INFO: Created: latency-svc-k9rsb
Nov 22 19:25:37.777: INFO: Got endpoints: latency-svc-qlcxd [748.262411ms]
Nov 22 19:25:37.783: INFO: Created: latency-svc-vk462
Nov 22 19:25:37.827: INFO: Got endpoints: latency-svc-hxwz5 [748.82045ms]
Nov 22 19:25:37.843: INFO: Created: latency-svc-r4phb
Nov 22 19:25:37.877: INFO: Got endpoints: latency-svc-58nsr [747.606698ms]
Nov 22 19:25:37.890: INFO: Created: latency-svc-49872
Nov 22 19:25:37.927: INFO: Got endpoints: latency-svc-zhblm [747.159553ms]
Nov 22 19:25:37.977: INFO: Got endpoints: latency-svc-dgcdr [749.944728ms]
Nov 22 19:25:38.028: INFO: Got endpoints: latency-svc-vr6rs [748.952242ms]
Nov 22 19:25:38.078: INFO: Got endpoints: latency-svc-mr454 [750.231925ms]
Nov 22 19:25:38.128: INFO: Got endpoints: latency-svc-qx4hc [749.847952ms]
Nov 22 19:25:38.177: INFO: Got endpoints: latency-svc-mrhqx [749.307529ms]
Nov 22 19:25:38.227: INFO: Got endpoints: latency-svc-9vrv6 [748.655687ms]
Nov 22 19:25:38.277: INFO: Got endpoints: latency-svc-v2v7j [747.221067ms]
Nov 22 19:25:38.328: INFO: Got endpoints: latency-svc-5jvf9 [750.246747ms]
Nov 22 19:25:38.378: INFO: Got endpoints: latency-svc-f2bm9 [750.421775ms]
Nov 22 19:25:38.429: INFO: Got endpoints: latency-svc-r27dx [751.689725ms]
Nov 22 19:25:38.478: INFO: Got endpoints: latency-svc-k9rsb [749.652564ms]
Nov 22 19:25:38.528: INFO: Got endpoints: latency-svc-vk462 [750.988067ms]
Nov 22 19:25:38.578: INFO: Got endpoints: latency-svc-r4phb [750.412163ms]
Nov 22 19:25:38.628: INFO: Got endpoints: latency-svc-49872 [750.621978ms]
Nov 22 19:25:38.628: INFO: Latencies: [32.653411ms 33.801961ms 44.003428ms 54.271478ms 66.367405ms 82.757648ms 95.213186ms 114.724135ms 125.14767ms 149.525057ms 153.473445ms 175.802679ms 186.006977ms 190.815682ms 195.967712ms 198.695017ms 199.522547ms 199.980228ms 201.399517ms 201.880725ms 202.236567ms 202.319658ms 204.196883ms 205.109932ms 205.326166ms 206.180785ms 208.095473ms 208.719907ms 209.504598ms 210.974623ms 212.219731ms 212.742612ms 220.361575ms 220.369382ms 222.046896ms 222.23921ms 223.980823ms 224.187596ms 224.640491ms 225.203434ms 229.816561ms 269.572314ms 316.172174ms 350.030231ms 383.207409ms 417.671864ms 453.318921ms 474.103939ms 512.00457ms 546.468931ms 572.646796ms 614.429366ms 649.333782ms 686.093044ms 726.068699ms 737.991867ms 742.550498ms 745.103714ms 745.103988ms 745.121764ms 745.132593ms 745.16156ms 745.223198ms 746.370119ms 746.600743ms 746.963426ms 747.159553ms 747.221067ms 747.606698ms 747.647932ms 747.691634ms 747.749ms 747.783058ms 747.865201ms 747.938242ms 747.972645ms 748.082093ms 748.205643ms 748.262411ms 748.307278ms 748.42462ms 748.53463ms 748.652632ms 748.655687ms 748.729936ms 748.751783ms 748.761779ms 748.767001ms 748.802826ms 748.818808ms 748.82045ms 748.837847ms 748.90573ms 748.952242ms 748.985212ms 749.161332ms 749.183706ms 749.212374ms 749.237937ms 749.307529ms 749.313972ms 749.349633ms 749.371082ms 749.414597ms 749.42799ms 749.472509ms 749.500805ms 749.516774ms 749.558782ms 749.597432ms 749.604194ms 749.605492ms 749.652564ms 749.667001ms 749.673416ms 749.693371ms 749.716778ms 749.791092ms 749.808672ms 749.826437ms 749.847938ms 749.847952ms 749.857983ms 749.882666ms 749.896039ms 749.913673ms 749.942505ms 749.944728ms 749.95248ms 749.981104ms 749.99215ms 749.993758ms 750.006526ms 750.047414ms 750.052363ms 750.063323ms 750.141ms 750.165139ms 750.182626ms 750.185679ms 750.188185ms 750.212036ms 750.231925ms 750.239085ms 750.23968ms 750.246747ms 750.278515ms 750.298725ms 750.323174ms 750.343411ms 750.344964ms 750.349177ms 750.35709ms 750.395118ms 750.398116ms 750.412163ms 750.421775ms 750.444672ms 750.465591ms 750.469263ms 750.504221ms 750.510622ms 750.519043ms 750.525816ms 750.528534ms 750.621978ms 750.640793ms 750.663608ms 750.77551ms 750.79749ms 750.83045ms 750.831376ms 750.905313ms 750.973493ms 750.985042ms 750.988067ms 751.163893ms 751.213449ms 751.243739ms 751.250102ms 751.363456ms 751.455708ms 751.486586ms 751.49348ms 751.689725ms 751.734577ms 751.790299ms 751.895047ms 752.051979ms 752.064083ms 752.115925ms 752.323704ms 752.597653ms 752.813902ms 753.076316ms 753.097395ms 754.001669ms 754.312428ms 754.66897ms 757.350195ms]
Nov 22 19:25:38.628: INFO: 50 %ile: 749.313972ms
Nov 22 19:25:38.628: INFO: 90 %ile: 751.363456ms
Nov 22 19:25:38.628: INFO: 99 %ile: 754.66897ms
Nov 22 19:25:38.628: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:25:38.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-2437" for this suite.
Nov 22 19:25:48.638: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:25:48.699: INFO: namespace svc-latency-2437 deletion completed in 10.068456832s

• [SLOW TEST:21.873 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:25:48.700: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:25:48.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5556" for this suite.
Nov 22 19:25:54.734: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:25:54.798: INFO: namespace services-5556 deletion completed in 6.069350486s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:6.099 seconds]
[sig-network] Services
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide secure master service  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:25:54.798: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Nov 22 19:25:59.344: INFO: Successfully updated pod "pod-update-dba199c2-4742-4a31-b314-e51642367d32"
STEP: verifying the updated pod is in kubernetes
Nov 22 19:25:59.348: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:25:59.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1113" for this suite.
Nov 22 19:26:21.355: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:26:21.650: INFO: namespace pods-1113 deletion completed in 22.300582349s

• [SLOW TEST:26.851 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:26:21.650: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:26:21.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1594" for this suite.
Nov 22 19:27:01.810: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:27:02.079: INFO: namespace kubelet-test-1594 deletion completed in 40.297680617s

• [SLOW TEST:40.429 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:27:02.079: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Nov 22 19:27:05.217: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:27:05.285: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-7438" for this suite.
Nov 22 19:27:11.346: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:27:11.634: INFO: namespace container-runtime-7438 deletion completed in 6.334783044s

• [SLOW TEST:9.555 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:27:11.635: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-1339
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-1339
STEP: Creating statefulset with conflicting port in namespace statefulset-1339
STEP: Waiting until pod test-pod will start running in namespace statefulset-1339
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-1339
Nov 22 19:27:15.818: INFO: Observed stateful pod in namespace: statefulset-1339, name: ss-0, uid: ef835ff0-c90a-447b-ba94-82132592273b, status phase: Pending. Waiting for statefulset controller to delete.
Nov 22 19:27:16.161: INFO: Observed stateful pod in namespace: statefulset-1339, name: ss-0, uid: ef835ff0-c90a-447b-ba94-82132592273b, status phase: Failed. Waiting for statefulset controller to delete.
Nov 22 19:27:16.199: INFO: Observed stateful pod in namespace: statefulset-1339, name: ss-0, uid: ef835ff0-c90a-447b-ba94-82132592273b, status phase: Failed. Waiting for statefulset controller to delete.
Nov 22 19:27:16.201: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-1339
STEP: Removing pod with conflicting port in namespace statefulset-1339
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-1339 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Nov 22 19:27:20.293: INFO: Deleting all statefulset in ns statefulset-1339
Nov 22 19:27:20.295: INFO: Scaling statefulset ss to 0
Nov 22 19:27:30.330: INFO: Waiting for statefulset status.replicas updated to 0
Nov 22 19:27:30.346: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:27:30.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1339" for this suite.
Nov 22 19:27:38.435: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:27:38.731: INFO: namespace statefulset-1339 deletion completed in 8.336293383s

• [SLOW TEST:27.096 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:27:38.731: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-1996
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a new StatefulSet
Nov 22 19:27:38.838: INFO: Found 0 stateful pods, waiting for 3
Nov 22 19:27:48.862: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 22 19:27:48.862: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov 22 19:27:48.862: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Nov 22 19:27:48.880: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-1996 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov 22 19:27:50.565: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Nov 22 19:27:50.565: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov 22 19:27:50.565: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Nov 22 19:28:00.609: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Nov 22 19:28:00.625: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-1996 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 19:28:01.044: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Nov 22 19:28:01.044: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov 22 19:28:01.044: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Nov 22 19:28:11.089: INFO: Waiting for StatefulSet statefulset-1996/ss2 to complete update
Nov 22 19:28:11.089: INFO: Waiting for Pod statefulset-1996/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Nov 22 19:28:11.089: INFO: Waiting for Pod statefulset-1996/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Nov 22 19:28:11.089: INFO: Waiting for Pod statefulset-1996/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Nov 22 19:28:21.109: INFO: Waiting for StatefulSet statefulset-1996/ss2 to complete update
Nov 22 19:28:21.109: INFO: Waiting for Pod statefulset-1996/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Rolling back to a previous revision
Nov 22 19:28:31.094: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-1996 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Nov 22 19:28:31.559: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Nov 22 19:28:31.559: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Nov 22 19:28:31.559: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Nov 22 19:28:41.604: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Nov 22 19:28:51.620: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 exec --namespace=statefulset-1996 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Nov 22 19:28:52.150: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Nov 22 19:28:52.150: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Nov 22 19:28:52.150: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Nov 22 19:29:02.172: INFO: Waiting for StatefulSet statefulset-1996/ss2 to complete update
Nov 22 19:29:02.172: INFO: Waiting for Pod statefulset-1996/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Nov 22 19:29:02.172: INFO: Waiting for Pod statefulset-1996/ss2-1 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Nov 22 19:29:02.172: INFO: Waiting for Pod statefulset-1996/ss2-2 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Nov 22 19:29:12.181: INFO: Waiting for StatefulSet statefulset-1996/ss2 to complete update
Nov 22 19:29:12.181: INFO: Waiting for Pod statefulset-1996/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
Nov 22 19:29:12.181: INFO: Waiting for Pod statefulset-1996/ss2-1 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Nov 22 19:29:22.184: INFO: Deleting all statefulset in ns statefulset-1996
Nov 22 19:29:22.186: INFO: Scaling statefulset ss2 to 0
Nov 22 19:30:02.224: INFO: Waiting for statefulset status.replicas updated to 0
Nov 22 19:30:02.225: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:30:02.262: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1996" for this suite.
Nov 22 19:30:10.324: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:30:10.437: INFO: namespace statefulset-1996 deletion completed in 8.16085968s

• [SLOW TEST:151.706 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:30:10.437: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Nov 22 19:30:13.480: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:30:13.504: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-6243" for this suite.
Nov 22 19:30:35.521: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:30:35.632: INFO: namespace replicaset-6243 deletion completed in 22.11791086s

• [SLOW TEST:25.195 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:30:35.633: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating all guestbook components
Nov 22 19:30:35.655: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Nov 22 19:30:35.655: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 create -f - --namespace=kubectl-6367'
Nov 22 19:30:35.854: INFO: stderr: ""
Nov 22 19:30:35.854: INFO: stdout: "service/redis-slave created\n"
Nov 22 19:30:35.854: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Nov 22 19:30:35.854: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 create -f - --namespace=kubectl-6367'
Nov 22 19:30:36.094: INFO: stderr: ""
Nov 22 19:30:36.094: INFO: stdout: "service/redis-master created\n"
Nov 22 19:30:36.094: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Nov 22 19:30:36.095: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 create -f - --namespace=kubectl-6367'
Nov 22 19:30:36.320: INFO: stderr: ""
Nov 22 19:30:36.320: INFO: stdout: "service/frontend created\n"
Nov 22 19:30:36.320: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Nov 22 19:30:36.320: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 create -f - --namespace=kubectl-6367'
Nov 22 19:30:36.587: INFO: stderr: ""
Nov 22 19:30:36.587: INFO: stdout: "deployment.apps/frontend created\n"
Nov 22 19:30:36.587: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Nov 22 19:30:36.587: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 create -f - --namespace=kubectl-6367'
Nov 22 19:30:36.782: INFO: stderr: ""
Nov 22 19:30:36.782: INFO: stdout: "deployment.apps/redis-master created\n"
Nov 22 19:30:36.782: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Nov 22 19:30:36.782: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 create -f - --namespace=kubectl-6367'
Nov 22 19:30:36.971: INFO: stderr: ""
Nov 22 19:30:36.971: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Nov 22 19:30:36.971: INFO: Waiting for all frontend pods to be Running.
Nov 22 19:30:42.021: INFO: Waiting for frontend to serve content.
Nov 22 19:30:42.033: INFO: Trying to add a new entry to the guestbook.
Nov 22 19:30:42.040: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Nov 22 19:30:42.051: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 delete --grace-period=0 --force -f - --namespace=kubectl-6367'
Nov 22 19:30:42.141: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 22 19:30:42.141: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Nov 22 19:30:42.141: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 delete --grace-period=0 --force -f - --namespace=kubectl-6367'
Nov 22 19:30:42.299: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 22 19:30:42.299: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Nov 22 19:30:42.299: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 delete --grace-period=0 --force -f - --namespace=kubectl-6367'
Nov 22 19:30:42.438: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 22 19:30:42.438: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Nov 22 19:30:42.438: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 delete --grace-period=0 --force -f - --namespace=kubectl-6367'
Nov 22 19:30:42.527: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 22 19:30:42.527: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Nov 22 19:30:42.528: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 delete --grace-period=0 --force -f - --namespace=kubectl-6367'
Nov 22 19:30:42.616: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 22 19:30:42.616: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Nov 22 19:30:42.617: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 delete --grace-period=0 --force -f - --namespace=kubectl-6367'
Nov 22 19:30:42.698: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 22 19:30:42.698: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:30:42.698: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6367" for this suite.
Nov 22 19:31:24.707: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:31:25.184: INFO: namespace kubectl-6367 deletion completed in 42.483613503s

• [SLOW TEST:49.552 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Guestbook application
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:31:25.185: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Nov 22 19:31:28.361: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:31:28.448: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-2894" for this suite.
Nov 22 19:31:34.465: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:31:34.788: INFO: namespace container-runtime-2894 deletion completed in 6.339054232s

• [SLOW TEST:9.604 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:31:34.789: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Nov 22 19:31:34.891: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Nov 22 19:31:39.901: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Nov 22 19:31:39.901: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Nov 22 19:31:39.941: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-8792,SelfLink:/apis/apps/v1/namespaces/deployment-8792/deployments/test-cleanup-deployment,UID:2b9218a7-50d8-412a-9b7b-d850a90ecd69,ResourceVersion:59633,Generation:1,CreationTimestamp:2019-11-22 19:31:39 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Nov 22 19:31:39.966: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
Nov 22 19:31:39.966: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Nov 22 19:31:39.966: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:deployment-8792,SelfLink:/apis/apps/v1/namespaces/deployment-8792/replicasets/test-cleanup-controller,UID:60c24253-f6d2-4769-a08d-41adab61b626,ResourceVersion:59634,Generation:1,CreationTimestamp:2019-11-22 19:31:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 2b9218a7-50d8-412a-9b7b-d850a90ecd69 0xc001c2da57 0xc001c2da58}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Nov 22 19:31:39.997: INFO: Pod "test-cleanup-controller-kkrcr" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-kkrcr,GenerateName:test-cleanup-controller-,Namespace:deployment-8792,SelfLink:/api/v1/namespaces/deployment-8792/pods/test-cleanup-controller-kkrcr,UID:b3431f14-46ed-4c62-9856-b633887cf9fa,ResourceVersion:59621,Generation:0,CreationTimestamp:2019-11-22 19:31:34 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller 60c24253-f6d2-4769-a08d-41adab61b626 0xc0024f0b47 0xc0024f0b48}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5zktz {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5zktz,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-5zktz true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:minion,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0024f0bc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0024f0be0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:31:34 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:31:36 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:31:36 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-22 19:31:34 +0000 UTC  }],Message:,Reason:,HostIP:172.31.44.47,PodIP:10.251.128.8,StartTime:2019-11-22 19:31:34 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-11-22 19:31:36 +0000 UTC,} nil} {nil nil nil} true 0 nginx:1.14-alpine docker-pullable://nginx@sha256:485b610fefec7ff6c463ced9623314a04ed67e3945b9c08d7e53a47f6d108dc7 docker://04c472ac3d20bd1223e82cad9ce258578304c7eca686dc527d04cc7e2b921ef8}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:31:39.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8792" for this suite.
Nov 22 19:31:46.109: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:31:47.055: INFO: namespace deployment-8792 deletion completed in 7.01986781s

• [SLOW TEST:12.267 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:31:47.056: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-9004
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Nov 22 19:31:47.168: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Nov 22 19:32:11.270: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.251.128.8:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9004 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 22 19:32:11.270: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
Nov 22 19:32:11.395: INFO: Found all expected endpoints: [netserver-0]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:32:11.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-9004" for this suite.
Nov 22 19:32:35.415: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:32:35.668: INFO: namespace pod-network-test-9004 deletion completed in 24.271279889s

• [SLOW TEST:48.613 seconds]
[sig-network] Networking
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:32:35.668: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Nov 22 19:32:38.378: INFO: Successfully updated pod "labelsupdatecec2c7d1-9644-4021-9c6b-7ffff9ac7a12"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:32:40.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4445" for this suite.
Nov 22 19:33:04.472: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:33:04.719: INFO: namespace downward-api-4445 deletion completed in 24.278717085s

• [SLOW TEST:29.051 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:33:04.720: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Nov 22 19:33:04.792: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov 22 19:33:04.816: INFO: Waiting for terminating namespaces to be deleted...
Nov 22 19:33:04.817: INFO: 
Logging pods the kubelet thinks is on node minion before test
Nov 22 19:33:04.840: INFO: nginx-proxy-minion from kube-system started at 2019-11-22 15:20:11 +0000 UTC (1 container statuses recorded)
Nov 22 19:33:04.840: INFO: 	Container nginx-proxy ready: true, restart count 0
Nov 22 19:33:04.840: INFO: rook-ceph-agent-7x8xt from rook-ceph-system started at 2019-11-22 15:23:13 +0000 UTC (1 container statuses recorded)
Nov 22 19:33:04.840: INFO: 	Container rook-ceph-agent ready: true, restart count 0
Nov 22 19:33:04.840: INFO: sonobuoy from sonobuoy started at 2019-11-22 17:53:18 +0000 UTC (1 container statuses recorded)
Nov 22 19:33:04.840: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov 22 19:33:04.840: INFO: sonobuoy-systemd-logs-daemon-set-125c3bb177a94023-5h6ln from sonobuoy started at 2019-11-22 17:53:20 +0000 UTC (2 container statuses recorded)
Nov 22 19:33:04.840: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Nov 22 19:33:04.841: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 22 19:33:04.841: INFO: tiller-deploy-7b9579457f-nz8lg from kube-system started at 2019-11-22 15:21:20 +0000 UTC (1 container statuses recorded)
Nov 22 19:33:04.841: INFO: 	Container tiller ready: true, restart count 0
Nov 22 19:33:04.841: INFO: weave-scope-agent-hw2c7 from weave started at 2019-11-22 15:22:13 +0000 UTC (1 container statuses recorded)
Nov 22 19:33:04.841: INFO: 	Container agent ready: true, restart count 0
Nov 22 19:33:04.841: INFO: nodelocaldns-k6f7w from kube-system started at 2019-11-22 15:21:08 +0000 UTC (1 container statuses recorded)
Nov 22 19:33:04.841: INFO: 	Container node-cache ready: true, restart count 0
Nov 22 19:33:04.841: INFO: weave-scope-app-599d8c957d-jn8r9 from weave started at 2019-11-22 15:22:13 +0000 UTC (1 container statuses recorded)
Nov 22 19:33:04.841: INFO: 	Container app ready: true, restart count 0
Nov 22 19:33:04.841: INFO: rook-ceph-operator-546844bb58-tn99w from rook-ceph-system started at 2019-11-22 15:22:18 +0000 UTC (1 container statuses recorded)
Nov 22 19:33:04.841: INFO: 	Container rook-ceph-operator ready: true, restart count 1
Nov 22 19:33:04.841: INFO: kube-proxy-g8j8f from kube-system started at 2019-11-22 15:20:11 +0000 UTC (1 container statuses recorded)
Nov 22 19:33:04.841: INFO: 	Container kube-proxy ready: true, restart count 0
Nov 22 19:33:04.841: INFO: weave-net-jh7zq from kube-system started at 2019-11-22 15:20:33 +0000 UTC (2 container statuses recorded)
Nov 22 19:33:04.841: INFO: 	Container weave ready: true, restart count 0
Nov 22 19:33:04.841: INFO: 	Container weave-npc ready: true, restart count 0
Nov 22 19:33:04.841: INFO: kubernetes-dashboard-7c547b4c64-hvmms from kube-system started at 2019-11-22 15:21:09 +0000 UTC (1 container statuses recorded)
Nov 22 19:33:04.841: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Nov 22 19:33:04.841: INFO: coredns-74c9d4d795-9mn9q from kube-system started at 2019-11-22 15:21:08 +0000 UTC (1 container statuses recorded)
Nov 22 19:33:04.841: INFO: 	Container coredns ready: true, restart count 0
Nov 22 19:33:04.841: INFO: rook-discover-nr6bp from rook-ceph-system started at 2019-11-22 15:23:13 +0000 UTC (1 container statuses recorded)
Nov 22 19:33:04.841: INFO: 	Container rook-discover ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: verifying the node has the label node minion
Nov 22 19:33:04.932: INFO: Pod coredns-74c9d4d795-9mn9q requesting resource cpu=100m on Node minion
Nov 22 19:33:04.932: INFO: Pod kube-proxy-g8j8f requesting resource cpu=0m on Node minion
Nov 22 19:33:04.932: INFO: Pod kubernetes-dashboard-7c547b4c64-hvmms requesting resource cpu=50m on Node minion
Nov 22 19:33:04.932: INFO: Pod nginx-proxy-minion requesting resource cpu=25m on Node minion
Nov 22 19:33:04.932: INFO: Pod nodelocaldns-k6f7w requesting resource cpu=100m on Node minion
Nov 22 19:33:04.932: INFO: Pod tiller-deploy-7b9579457f-nz8lg requesting resource cpu=0m on Node minion
Nov 22 19:33:04.932: INFO: Pod weave-net-jh7zq requesting resource cpu=20m on Node minion
Nov 22 19:33:04.932: INFO: Pod rook-ceph-agent-7x8xt requesting resource cpu=0m on Node minion
Nov 22 19:33:04.932: INFO: Pod rook-ceph-operator-546844bb58-tn99w requesting resource cpu=0m on Node minion
Nov 22 19:33:04.932: INFO: Pod rook-discover-nr6bp requesting resource cpu=0m on Node minion
Nov 22 19:33:04.932: INFO: Pod sonobuoy requesting resource cpu=0m on Node minion
Nov 22 19:33:04.932: INFO: Pod sonobuoy-systemd-logs-daemon-set-125c3bb177a94023-5h6ln requesting resource cpu=0m on Node minion
Nov 22 19:33:04.932: INFO: Pod weave-scope-agent-hw2c7 requesting resource cpu=0m on Node minion
Nov 22 19:33:04.932: INFO: Pod weave-scope-app-599d8c957d-jn8r9 requesting resource cpu=0m on Node minion
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2e5d36b2-094a-4699-897d-be03693fc1e4.15d99302cbd25c9d], Reason = [Scheduled], Message = [Successfully assigned sched-pred-1142/filler-pod-2e5d36b2-094a-4699-897d-be03693fc1e4 to minion]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2e5d36b2-094a-4699-897d-be03693fc1e4.15d9930312708801], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2e5d36b2-094a-4699-897d-be03693fc1e4.15d9930319f3e3bc], Reason = [Created], Message = [Created container filler-pod-2e5d36b2-094a-4699-897d-be03693fc1e4]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2e5d36b2-094a-4699-897d-be03693fc1e4.15d9930327df6485], Reason = [Started], Message = [Started container filler-pod-2e5d36b2-094a-4699-897d-be03693fc1e4]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15d99303bc52dd1b], Reason = [FailedScheduling], Message = [0/2 nodes are available: 1 Insufficient cpu, 1 node(s) had taints that the pod didn't tolerate.]
STEP: removing the label node off the node minion
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:33:10.079: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-1142" for this suite.
Nov 22 19:33:16.125: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:33:16.368: INFO: namespace sched-pred-1142 deletion completed in 6.269848008s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

• [SLOW TEST:11.648 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:33:16.368: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating Redis RC
Nov 22 19:33:16.473: INFO: namespace kubectl-3759
Nov 22 19:33:16.473: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 create -f - --namespace=kubectl-3759'
Nov 22 19:33:17.159: INFO: stderr: ""
Nov 22 19:33:17.159: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Nov 22 19:33:18.166: INFO: Selector matched 1 pods for map[app:redis]
Nov 22 19:33:18.166: INFO: Found 0 / 1
Nov 22 19:33:19.169: INFO: Selector matched 1 pods for map[app:redis]
Nov 22 19:33:19.169: INFO: Found 0 / 1
Nov 22 19:33:20.161: INFO: Selector matched 1 pods for map[app:redis]
Nov 22 19:33:20.161: INFO: Found 1 / 1
Nov 22 19:33:20.161: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Nov 22 19:33:20.182: INFO: Selector matched 1 pods for map[app:redis]
Nov 22 19:33:20.182: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Nov 22 19:33:20.182: INFO: wait on redis-master startup in kubectl-3759 
Nov 22 19:33:20.182: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 logs redis-master-ml6zv redis-master --namespace=kubectl-3759'
Nov 22 19:33:20.604: INFO: stderr: ""
Nov 22 19:33:20.604: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 22 Nov 19:33:18.431 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 22 Nov 19:33:18.431 # Server started, Redis version 3.2.12\n1:M 22 Nov 19:33:18.431 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 22 Nov 19:33:18.431 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Nov 22 19:33:20.604: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-3759'
Nov 22 19:33:21.116: INFO: stderr: ""
Nov 22 19:33:21.116: INFO: stdout: "service/rm2 exposed\n"
Nov 22 19:33:21.118: INFO: Service rm2 in namespace kubectl-3759 found.
STEP: exposing service
Nov 22 19:33:23.121: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-3759'
Nov 22 19:33:23.526: INFO: stderr: ""
Nov 22 19:33:23.526: INFO: stdout: "service/rm3 exposed\n"
Nov 22 19:33:23.543: INFO: Service rm3 in namespace kubectl-3759 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:33:25.563: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3759" for this suite.
Nov 22 19:33:49.590: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:33:49.887: INFO: namespace kubectl-3759 deletion completed in 24.322240141s

• [SLOW TEST:33.519 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl expose
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create services for rc  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:33:49.887: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name cm-test-opt-del-36cf2ab1-a495-4bde-a280-f6cc2bc0b6ef
STEP: Creating configMap with name cm-test-opt-upd-0dcf6732-700d-439b-bea8-dd27a157235c
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-36cf2ab1-a495-4bde-a280-f6cc2bc0b6ef
STEP: Updating configmap cm-test-opt-upd-0dcf6732-700d-439b-bea8-dd27a157235c
STEP: Creating configMap with name cm-test-opt-create-aeaab0cc-1c80-4552-a1a6-d0e43f23e72b
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:33:54.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6526" for this suite.
Nov 22 19:34:18.237: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:34:18.506: INFO: namespace projected-6526 deletion completed in 24.287917326s

• [SLOW TEST:28.618 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:34:18.506: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-projected-wklc
STEP: Creating a pod to test atomic-volume-subpath
Nov 22 19:34:18.638: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-wklc" in namespace "subpath-5600" to be "success or failure"
Nov 22 19:34:18.666: INFO: Pod "pod-subpath-test-projected-wklc": Phase="Pending", Reason="", readiness=false. Elapsed: 28.488214ms
Nov 22 19:34:20.689: INFO: Pod "pod-subpath-test-projected-wklc": Phase="Running", Reason="", readiness=true. Elapsed: 2.05129814s
Nov 22 19:34:22.691: INFO: Pod "pod-subpath-test-projected-wklc": Phase="Running", Reason="", readiness=true. Elapsed: 4.053311688s
Nov 22 19:34:24.699: INFO: Pod "pod-subpath-test-projected-wklc": Phase="Running", Reason="", readiness=true. Elapsed: 6.061039131s
Nov 22 19:34:26.701: INFO: Pod "pod-subpath-test-projected-wklc": Phase="Running", Reason="", readiness=true. Elapsed: 8.063206606s
Nov 22 19:34:28.704: INFO: Pod "pod-subpath-test-projected-wklc": Phase="Running", Reason="", readiness=true. Elapsed: 10.065952229s
Nov 22 19:34:30.714: INFO: Pod "pod-subpath-test-projected-wklc": Phase="Running", Reason="", readiness=true. Elapsed: 12.076253993s
Nov 22 19:34:32.716: INFO: Pod "pod-subpath-test-projected-wklc": Phase="Running", Reason="", readiness=true. Elapsed: 14.078352086s
Nov 22 19:34:34.731: INFO: Pod "pod-subpath-test-projected-wklc": Phase="Running", Reason="", readiness=true. Elapsed: 16.093502708s
Nov 22 19:34:36.753: INFO: Pod "pod-subpath-test-projected-wklc": Phase="Running", Reason="", readiness=true. Elapsed: 18.114728355s
Nov 22 19:34:38.763: INFO: Pod "pod-subpath-test-projected-wklc": Phase="Running", Reason="", readiness=true. Elapsed: 20.124986483s
Nov 22 19:34:40.777: INFO: Pod "pod-subpath-test-projected-wklc": Phase="Running", Reason="", readiness=true. Elapsed: 22.139656662s
Nov 22 19:34:42.799: INFO: Pod "pod-subpath-test-projected-wklc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.161512979s
STEP: Saw pod success
Nov 22 19:34:42.799: INFO: Pod "pod-subpath-test-projected-wklc" satisfied condition "success or failure"
Nov 22 19:34:42.801: INFO: Trying to get logs from node minion pod pod-subpath-test-projected-wklc container test-container-subpath-projected-wklc: <nil>
STEP: delete the pod
Nov 22 19:34:42.844: INFO: Waiting for pod pod-subpath-test-projected-wklc to disappear
Nov 22 19:34:42.846: INFO: Pod pod-subpath-test-projected-wklc no longer exists
STEP: Deleting pod pod-subpath-test-projected-wklc
Nov 22 19:34:42.846: INFO: Deleting pod "pod-subpath-test-projected-wklc" in namespace "subpath-5600"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:34:42.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5600" for this suite.
Nov 22 19:34:48.882: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:34:49.283: INFO: namespace subpath-5600 deletion completed in 6.416929479s

• [SLOW TEST:30.777 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:34:49.284: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-projected-all-test-volume-e067e989-7c85-4cb3-8f0f-2bbff20b7ab0
STEP: Creating secret with name secret-projected-all-test-volume-6a3a44ba-be62-47aa-a1c5-52dbc3410af3
STEP: Creating a pod to test Check all projections for projected volume plugin
Nov 22 19:34:49.424: INFO: Waiting up to 5m0s for pod "projected-volume-f7f40633-9dbd-4ec3-9b77-03e366571a08" in namespace "projected-394" to be "success or failure"
Nov 22 19:34:49.451: INFO: Pod "projected-volume-f7f40633-9dbd-4ec3-9b77-03e366571a08": Phase="Pending", Reason="", readiness=false. Elapsed: 26.769704ms
Nov 22 19:34:51.453: INFO: Pod "projected-volume-f7f40633-9dbd-4ec3-9b77-03e366571a08": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.029074447s
STEP: Saw pod success
Nov 22 19:34:51.453: INFO: Pod "projected-volume-f7f40633-9dbd-4ec3-9b77-03e366571a08" satisfied condition "success or failure"
Nov 22 19:34:51.455: INFO: Trying to get logs from node minion pod projected-volume-f7f40633-9dbd-4ec3-9b77-03e366571a08 container projected-all-volume-test: <nil>
STEP: delete the pod
Nov 22 19:34:51.517: INFO: Waiting for pod projected-volume-f7f40633-9dbd-4ec3-9b77-03e366571a08 to disappear
Nov 22 19:34:51.519: INFO: Pod projected-volume-f7f40633-9dbd-4ec3-9b77-03e366571a08 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:34:51.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-394" for this suite.
Nov 22 19:34:57.544: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:34:57.809: INFO: namespace projected-394 deletion completed in 6.288646875s

• [SLOW TEST:8.525 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:34:57.809: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Nov 22 19:34:57.976: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:35:01.557: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-2290" for this suite.
Nov 22 19:35:07.584: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:35:08.008: INFO: namespace init-container-2290 deletion completed in 6.448695934s

• [SLOW TEST:10.198 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:35:08.008: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating service endpoint-test2 in namespace services-8999
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8999 to expose endpoints map[]
Nov 22 19:35:08.105: INFO: Get endpoints failed (1.821633ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Nov 22 19:35:09.107: INFO: successfully validated that service endpoint-test2 in namespace services-8999 exposes endpoints map[] (1.004039056s elapsed)
STEP: Creating pod pod1 in namespace services-8999
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8999 to expose endpoints map[pod1:[80]]
Nov 22 19:35:11.121: INFO: successfully validated that service endpoint-test2 in namespace services-8999 exposes endpoints map[pod1:[80]] (2.010526329s elapsed)
STEP: Creating pod pod2 in namespace services-8999
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8999 to expose endpoints map[pod1:[80] pod2:[80]]
Nov 22 19:35:13.146: INFO: successfully validated that service endpoint-test2 in namespace services-8999 exposes endpoints map[pod1:[80] pod2:[80]] (2.022454239s elapsed)
STEP: Deleting pod pod1 in namespace services-8999
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8999 to expose endpoints map[pod2:[80]]
Nov 22 19:35:14.157: INFO: successfully validated that service endpoint-test2 in namespace services-8999 exposes endpoints map[pod2:[80]] (1.007849032s elapsed)
STEP: Deleting pod pod2 in namespace services-8999
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-8999 to expose endpoints map[]
Nov 22 19:35:15.164: INFO: successfully validated that service endpoint-test2 in namespace services-8999 exposes endpoints map[] (1.004330629s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:35:15.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8999" for this suite.
Nov 22 19:35:37.200: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:35:37.269: INFO: namespace services-8999 deletion completed in 22.084171922s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

• [SLOW TEST:29.261 seconds]
[sig-network] Services
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:35:37.269: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-2533.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-2533.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-2533.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-2533.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-2533.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-2533.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-2533.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-2533.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-2533.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-2533.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-2533.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-2533.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2533.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 233.201.241.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.241.201.233_udp@PTR;check="$$(dig +tcp +noall +answer +search 233.201.241.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.241.201.233_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-2533.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-2533.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-2533.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-2533.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-2533.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-2533.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-2533.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-2533.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-2533.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-2533.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-2533.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-2533.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2533.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 233.201.241.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.241.201.233_udp@PTR;check="$$(dig +tcp +noall +answer +search 233.201.241.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.241.201.233_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov 22 19:35:41.338: INFO: Unable to read wheezy_udp@dns-test-service.dns-2533.svc.cluster.local from pod dns-2533/dns-test-7084942d-22a0-474d-b540-a2a3a917b124: the server could not find the requested resource (get pods dns-test-7084942d-22a0-474d-b540-a2a3a917b124)
Nov 22 19:35:41.340: INFO: Unable to read wheezy_tcp@dns-test-service.dns-2533.svc.cluster.local from pod dns-2533/dns-test-7084942d-22a0-474d-b540-a2a3a917b124: the server could not find the requested resource (get pods dns-test-7084942d-22a0-474d-b540-a2a3a917b124)
Nov 22 19:35:41.342: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-2533.svc.cluster.local from pod dns-2533/dns-test-7084942d-22a0-474d-b540-a2a3a917b124: the server could not find the requested resource (get pods dns-test-7084942d-22a0-474d-b540-a2a3a917b124)
Nov 22 19:35:41.344: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-2533.svc.cluster.local from pod dns-2533/dns-test-7084942d-22a0-474d-b540-a2a3a917b124: the server could not find the requested resource (get pods dns-test-7084942d-22a0-474d-b540-a2a3a917b124)
Nov 22 19:35:41.359: INFO: Unable to read jessie_udp@dns-test-service.dns-2533.svc.cluster.local from pod dns-2533/dns-test-7084942d-22a0-474d-b540-a2a3a917b124: the server could not find the requested resource (get pods dns-test-7084942d-22a0-474d-b540-a2a3a917b124)
Nov 22 19:35:41.361: INFO: Unable to read jessie_tcp@dns-test-service.dns-2533.svc.cluster.local from pod dns-2533/dns-test-7084942d-22a0-474d-b540-a2a3a917b124: the server could not find the requested resource (get pods dns-test-7084942d-22a0-474d-b540-a2a3a917b124)
Nov 22 19:35:41.363: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-2533.svc.cluster.local from pod dns-2533/dns-test-7084942d-22a0-474d-b540-a2a3a917b124: the server could not find the requested resource (get pods dns-test-7084942d-22a0-474d-b540-a2a3a917b124)
Nov 22 19:35:41.365: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-2533.svc.cluster.local from pod dns-2533/dns-test-7084942d-22a0-474d-b540-a2a3a917b124: the server could not find the requested resource (get pods dns-test-7084942d-22a0-474d-b540-a2a3a917b124)
Nov 22 19:35:41.377: INFO: Lookups using dns-2533/dns-test-7084942d-22a0-474d-b540-a2a3a917b124 failed for: [wheezy_udp@dns-test-service.dns-2533.svc.cluster.local wheezy_tcp@dns-test-service.dns-2533.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-2533.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-2533.svc.cluster.local jessie_udp@dns-test-service.dns-2533.svc.cluster.local jessie_tcp@dns-test-service.dns-2533.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-2533.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-2533.svc.cluster.local]

Nov 22 19:35:46.419: INFO: DNS probes using dns-2533/dns-test-7084942d-22a0-474d-b540-a2a3a917b124 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:35:46.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2533" for this suite.
Nov 22 19:35:52.534: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:35:52.731: INFO: namespace dns-2533 deletion completed in 6.203962312s

• [SLOW TEST:15.462 seconds]
[sig-network] DNS
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:35:52.732: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:35:52.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2157" for this suite.
Nov 22 19:36:14.785: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:36:15.394: INFO: namespace pods-2157 deletion completed in 22.627759084s

• [SLOW TEST:22.662 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:36:15.395: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Nov 22 19:36:15.473: INFO: Creating ReplicaSet my-hostname-basic-c73e74db-ae1b-461c-8e51-11bdde755f82
Nov 22 19:36:15.498: INFO: Pod name my-hostname-basic-c73e74db-ae1b-461c-8e51-11bdde755f82: Found 0 pods out of 1
Nov 22 19:36:20.514: INFO: Pod name my-hostname-basic-c73e74db-ae1b-461c-8e51-11bdde755f82: Found 1 pods out of 1
Nov 22 19:36:20.514: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-c73e74db-ae1b-461c-8e51-11bdde755f82" is running
Nov 22 19:36:20.530: INFO: Pod "my-hostname-basic-c73e74db-ae1b-461c-8e51-11bdde755f82-nctjk" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-11-22 19:36:15 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-11-22 19:36:17 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-11-22 19:36:17 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-11-22 19:36:15 +0000 UTC Reason: Message:}])
Nov 22 19:36:20.530: INFO: Trying to dial the pod
Nov 22 19:36:25.561: INFO: Controller my-hostname-basic-c73e74db-ae1b-461c-8e51-11bdde755f82: Got expected result from replica 1 [my-hostname-basic-c73e74db-ae1b-461c-8e51-11bdde755f82-nctjk]: "my-hostname-basic-c73e74db-ae1b-461c-8e51-11bdde755f82-nctjk", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:36:25.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-8917" for this suite.
Nov 22 19:36:31.600: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:36:31.874: INFO: namespace replicaset-8917 deletion completed in 6.310648032s

• [SLOW TEST:16.479 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:36:31.876: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-downwardapi-cslq
STEP: Creating a pod to test atomic-volume-subpath
Nov 22 19:36:32.046: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-cslq" in namespace "subpath-6159" to be "success or failure"
Nov 22 19:36:32.064: INFO: Pod "pod-subpath-test-downwardapi-cslq": Phase="Pending", Reason="", readiness=false. Elapsed: 18.079686ms
Nov 22 19:36:34.066: INFO: Pod "pod-subpath-test-downwardapi-cslq": Phase="Running", Reason="", readiness=true. Elapsed: 2.019828381s
Nov 22 19:36:36.070: INFO: Pod "pod-subpath-test-downwardapi-cslq": Phase="Running", Reason="", readiness=true. Elapsed: 4.02417051s
Nov 22 19:36:38.089: INFO: Pod "pod-subpath-test-downwardapi-cslq": Phase="Running", Reason="", readiness=true. Elapsed: 6.04324244s
Nov 22 19:36:40.100: INFO: Pod "pod-subpath-test-downwardapi-cslq": Phase="Running", Reason="", readiness=true. Elapsed: 8.053937128s
Nov 22 19:36:42.152: INFO: Pod "pod-subpath-test-downwardapi-cslq": Phase="Running", Reason="", readiness=true. Elapsed: 10.106498779s
Nov 22 19:36:44.154: INFO: Pod "pod-subpath-test-downwardapi-cslq": Phase="Running", Reason="", readiness=true. Elapsed: 12.10844592s
Nov 22 19:36:46.156: INFO: Pod "pod-subpath-test-downwardapi-cslq": Phase="Running", Reason="", readiness=true. Elapsed: 14.110701572s
Nov 22 19:36:48.178: INFO: Pod "pod-subpath-test-downwardapi-cslq": Phase="Running", Reason="", readiness=true. Elapsed: 16.1322163s
Nov 22 19:36:50.181: INFO: Pod "pod-subpath-test-downwardapi-cslq": Phase="Running", Reason="", readiness=true. Elapsed: 18.134983659s
Nov 22 19:36:52.182: INFO: Pod "pod-subpath-test-downwardapi-cslq": Phase="Running", Reason="", readiness=true. Elapsed: 20.136719321s
Nov 22 19:36:54.184: INFO: Pod "pod-subpath-test-downwardapi-cslq": Phase="Running", Reason="", readiness=true. Elapsed: 22.138501017s
Nov 22 19:36:56.198: INFO: Pod "pod-subpath-test-downwardapi-cslq": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.152551052s
STEP: Saw pod success
Nov 22 19:36:56.198: INFO: Pod "pod-subpath-test-downwardapi-cslq" satisfied condition "success or failure"
Nov 22 19:36:56.200: INFO: Trying to get logs from node minion pod pod-subpath-test-downwardapi-cslq container test-container-subpath-downwardapi-cslq: <nil>
STEP: delete the pod
Nov 22 19:36:56.244: INFO: Waiting for pod pod-subpath-test-downwardapi-cslq to disappear
Nov 22 19:36:56.245: INFO: Pod pod-subpath-test-downwardapi-cslq no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-cslq
Nov 22 19:36:56.245: INFO: Deleting pod "pod-subpath-test-downwardapi-cslq" in namespace "subpath-6159"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:36:56.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6159" for this suite.
Nov 22 19:37:02.294: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:37:02.517: INFO: namespace subpath-6159 deletion completed in 6.253673235s

• [SLOW TEST:30.642 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:37:02.518: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-53023b07-1de9-4e2d-a3df-333231a1a2b5
STEP: Creating a pod to test consume secrets
Nov 22 19:37:02.666: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-92f41bb3-b1fa-4353-b6c8-8d7eb737f7b8" in namespace "projected-4805" to be "success or failure"
Nov 22 19:37:02.681: INFO: Pod "pod-projected-secrets-92f41bb3-b1fa-4353-b6c8-8d7eb737f7b8": Phase="Pending", Reason="", readiness=false. Elapsed: 14.447681ms
Nov 22 19:37:04.682: INFO: Pod "pod-projected-secrets-92f41bb3-b1fa-4353-b6c8-8d7eb737f7b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016190403s
STEP: Saw pod success
Nov 22 19:37:04.682: INFO: Pod "pod-projected-secrets-92f41bb3-b1fa-4353-b6c8-8d7eb737f7b8" satisfied condition "success or failure"
Nov 22 19:37:04.684: INFO: Trying to get logs from node minion pod pod-projected-secrets-92f41bb3-b1fa-4353-b6c8-8d7eb737f7b8 container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov 22 19:37:04.731: INFO: Waiting for pod pod-projected-secrets-92f41bb3-b1fa-4353-b6c8-8d7eb737f7b8 to disappear
Nov 22 19:37:04.733: INFO: Pod pod-projected-secrets-92f41bb3-b1fa-4353-b6c8-8d7eb737f7b8 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:37:04.733: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4805" for this suite.
Nov 22 19:37:10.770: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:37:11.064: INFO: namespace projected-4805 deletion completed in 6.316912076s

• [SLOW TEST:8.546 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:37:11.064: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: getting the auto-created API token
Nov 22 19:37:11.706: INFO: created pod pod-service-account-defaultsa
Nov 22 19:37:11.707: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Nov 22 19:37:11.747: INFO: created pod pod-service-account-mountsa
Nov 22 19:37:11.747: INFO: pod pod-service-account-mountsa service account token volume mount: true
Nov 22 19:37:11.776: INFO: created pod pod-service-account-nomountsa
Nov 22 19:37:11.776: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Nov 22 19:37:11.806: INFO: created pod pod-service-account-defaultsa-mountspec
Nov 22 19:37:11.806: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Nov 22 19:37:11.868: INFO: created pod pod-service-account-mountsa-mountspec
Nov 22 19:37:11.868: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Nov 22 19:37:11.909: INFO: created pod pod-service-account-nomountsa-mountspec
Nov 22 19:37:11.909: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Nov 22 19:37:11.936: INFO: created pod pod-service-account-defaultsa-nomountspec
Nov 22 19:37:11.936: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Nov 22 19:37:11.971: INFO: created pod pod-service-account-mountsa-nomountspec
Nov 22 19:37:11.971: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Nov 22 19:37:11.990: INFO: created pod pod-service-account-nomountsa-nomountspec
Nov 22 19:37:11.990: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:37:11.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-8142" for this suite.
Nov 22 19:37:36.041: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:37:36.307: INFO: namespace svcaccounts-8142 deletion completed in 24.30484754s

• [SLOW TEST:25.242 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:37:36.307: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: validating cluster-info
Nov 22 19:37:36.444: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 cluster-info'
Nov 22 19:37:36.774: INFO: stderr: ""
Nov 22 19:37:36.774: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.241.0.1:443\x1b[0m\n\x1b[0;32mcoredns\x1b[0m is running at \x1b[0;33mhttps://10.241.0.1:443/api/v1/namespaces/kube-system/services/coredns:dns/proxy\x1b[0m\n\x1b[0;32mkubernetes-dashboard\x1b[0m is running at \x1b[0;33mhttps://10.241.0.1:443/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy\x1b[0m\n\x1b[0;32mmetrics-server\x1b[0m is running at \x1b[0;33mhttps://10.241.0.1:443/api/v1/namespaces/kube-system/services/https:metrics-server:/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:37:36.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8311" for this suite.
Nov 22 19:37:42.811: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:37:43.078: INFO: namespace kubectl-8311 deletion completed in 6.298637546s

• [SLOW TEST:6.771 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:37:43.078: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a replication controller
Nov 22 19:37:43.162: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 create -f - --namespace=kubectl-1683'
Nov 22 19:37:44.008: INFO: stderr: ""
Nov 22 19:37:44.008: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov 22 19:37:44.009: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1683'
Nov 22 19:37:44.422: INFO: stderr: ""
Nov 22 19:37:44.422: INFO: stdout: "update-demo-nautilus-jfh7x update-demo-nautilus-xvf2w "
Nov 22 19:37:44.422: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 get pods update-demo-nautilus-jfh7x -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1683'
Nov 22 19:37:44.785: INFO: stderr: ""
Nov 22 19:37:44.785: INFO: stdout: ""
Nov 22 19:37:44.785: INFO: update-demo-nautilus-jfh7x is created but not running
Nov 22 19:37:49.788: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1683'
Nov 22 19:37:51.364: INFO: stderr: ""
Nov 22 19:37:51.364: INFO: stdout: "update-demo-nautilus-jfh7x update-demo-nautilus-xvf2w "
Nov 22 19:37:51.364: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 get pods update-demo-nautilus-jfh7x -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1683'
Nov 22 19:37:51.707: INFO: stderr: ""
Nov 22 19:37:51.707: INFO: stdout: "true"
Nov 22 19:37:51.707: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 get pods update-demo-nautilus-jfh7x -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1683'
Nov 22 19:37:52.122: INFO: stderr: ""
Nov 22 19:37:52.122: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov 22 19:37:52.122: INFO: validating pod update-demo-nautilus-jfh7x
Nov 22 19:37:52.126: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 22 19:37:52.126: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 22 19:37:52.126: INFO: update-demo-nautilus-jfh7x is verified up and running
Nov 22 19:37:52.126: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 get pods update-demo-nautilus-xvf2w -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1683'
Nov 22 19:37:52.444: INFO: stderr: ""
Nov 22 19:37:52.444: INFO: stdout: "true"
Nov 22 19:37:52.444: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 get pods update-demo-nautilus-xvf2w -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1683'
Nov 22 19:37:52.828: INFO: stderr: ""
Nov 22 19:37:52.828: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov 22 19:37:52.828: INFO: validating pod update-demo-nautilus-xvf2w
Nov 22 19:37:52.856: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 22 19:37:52.856: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 22 19:37:52.856: INFO: update-demo-nautilus-xvf2w is verified up and running
STEP: scaling down the replication controller
Nov 22 19:37:52.857: INFO: scanned /root for discovery docs: <nil>
Nov 22 19:37:52.857: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-1683'
Nov 22 19:37:53.328: INFO: stderr: ""
Nov 22 19:37:53.328: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov 22 19:37:53.328: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1683'
Nov 22 19:37:53.734: INFO: stderr: ""
Nov 22 19:37:53.734: INFO: stdout: "update-demo-nautilus-jfh7x update-demo-nautilus-xvf2w "
STEP: Replicas for name=update-demo: expected=1 actual=2
Nov 22 19:37:58.734: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1683'
Nov 22 19:37:59.108: INFO: stderr: ""
Nov 22 19:37:59.108: INFO: stdout: "update-demo-nautilus-jfh7x update-demo-nautilus-xvf2w "
STEP: Replicas for name=update-demo: expected=1 actual=2
Nov 22 19:38:04.113: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1683'
Nov 22 19:38:04.474: INFO: stderr: ""
Nov 22 19:38:04.474: INFO: stdout: "update-demo-nautilus-xvf2w "
Nov 22 19:38:04.474: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 get pods update-demo-nautilus-xvf2w -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1683'
Nov 22 19:38:04.850: INFO: stderr: ""
Nov 22 19:38:04.850: INFO: stdout: "true"
Nov 22 19:38:04.850: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 get pods update-demo-nautilus-xvf2w -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1683'
Nov 22 19:38:05.241: INFO: stderr: ""
Nov 22 19:38:05.241: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov 22 19:38:05.241: INFO: validating pod update-demo-nautilus-xvf2w
Nov 22 19:38:05.245: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 22 19:38:05.245: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 22 19:38:05.245: INFO: update-demo-nautilus-xvf2w is verified up and running
STEP: scaling up the replication controller
Nov 22 19:38:05.246: INFO: scanned /root for discovery docs: <nil>
Nov 22 19:38:05.246: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-1683'
Nov 22 19:38:06.726: INFO: stderr: ""
Nov 22 19:38:06.726: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov 22 19:38:06.726: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1683'
Nov 22 19:38:07.129: INFO: stderr: ""
Nov 22 19:38:07.129: INFO: stdout: "update-demo-nautilus-nwwb5 update-demo-nautilus-xvf2w "
Nov 22 19:38:07.130: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 get pods update-demo-nautilus-nwwb5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1683'
Nov 22 19:38:07.492: INFO: stderr: ""
Nov 22 19:38:07.492: INFO: stdout: ""
Nov 22 19:38:07.492: INFO: update-demo-nautilus-nwwb5 is created but not running
Nov 22 19:38:12.492: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1683'
Nov 22 19:38:12.835: INFO: stderr: ""
Nov 22 19:38:12.835: INFO: stdout: "update-demo-nautilus-nwwb5 update-demo-nautilus-xvf2w "
Nov 22 19:38:12.835: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 get pods update-demo-nautilus-nwwb5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1683'
Nov 22 19:38:13.180: INFO: stderr: ""
Nov 22 19:38:13.180: INFO: stdout: "true"
Nov 22 19:38:13.180: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 get pods update-demo-nautilus-nwwb5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1683'
Nov 22 19:38:13.512: INFO: stderr: ""
Nov 22 19:38:13.512: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov 22 19:38:13.512: INFO: validating pod update-demo-nautilus-nwwb5
Nov 22 19:38:13.528: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 22 19:38:13.528: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 22 19:38:13.528: INFO: update-demo-nautilus-nwwb5 is verified up and running
Nov 22 19:38:13.528: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 get pods update-demo-nautilus-xvf2w -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1683'
Nov 22 19:38:13.918: INFO: stderr: ""
Nov 22 19:38:13.918: INFO: stdout: "true"
Nov 22 19:38:13.918: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 get pods update-demo-nautilus-xvf2w -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1683'
Nov 22 19:38:14.299: INFO: stderr: ""
Nov 22 19:38:14.299: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov 22 19:38:14.299: INFO: validating pod update-demo-nautilus-xvf2w
Nov 22 19:38:14.301: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 22 19:38:14.301: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 22 19:38:14.301: INFO: update-demo-nautilus-xvf2w is verified up and running
STEP: using delete to clean up resources
Nov 22 19:38:14.301: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 delete --grace-period=0 --force -f - --namespace=kubectl-1683'
Nov 22 19:38:14.708: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 22 19:38:14.708: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Nov 22 19:38:14.708: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-1683'
Nov 22 19:38:15.155: INFO: stderr: "No resources found.\n"
Nov 22 19:38:15.156: INFO: stdout: ""
Nov 22 19:38:15.156: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 get pods -l name=update-demo --namespace=kubectl-1683 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov 22 19:38:15.563: INFO: stderr: ""
Nov 22 19:38:15.564: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:38:15.564: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1683" for this suite.
Nov 22 19:38:39.593: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:38:39.892: INFO: namespace kubectl-1683 deletion completed in 24.313825118s

• [SLOW TEST:56.814 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:38:39.892: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Nov 22 19:38:39.985: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7b531127-e72d-446f-b1a0-5e57dda23fad" in namespace "downward-api-2470" to be "success or failure"
Nov 22 19:38:40.002: INFO: Pod "downwardapi-volume-7b531127-e72d-446f-b1a0-5e57dda23fad": Phase="Pending", Reason="", readiness=false. Elapsed: 17.073819ms
Nov 22 19:38:42.046: INFO: Pod "downwardapi-volume-7b531127-e72d-446f-b1a0-5e57dda23fad": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.060712885s
STEP: Saw pod success
Nov 22 19:38:42.046: INFO: Pod "downwardapi-volume-7b531127-e72d-446f-b1a0-5e57dda23fad" satisfied condition "success or failure"
Nov 22 19:38:42.075: INFO: Trying to get logs from node minion pod downwardapi-volume-7b531127-e72d-446f-b1a0-5e57dda23fad container client-container: <nil>
STEP: delete the pod
Nov 22 19:38:42.157: INFO: Waiting for pod downwardapi-volume-7b531127-e72d-446f-b1a0-5e57dda23fad to disappear
Nov 22 19:38:42.193: INFO: Pod downwardapi-volume-7b531127-e72d-446f-b1a0-5e57dda23fad no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:38:42.193: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2470" for this suite.
Nov 22 19:38:48.230: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:38:48.561: INFO: namespace downward-api-2470 deletion completed in 6.347490172s

• [SLOW TEST:8.682 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:38:48.574: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-map-9af7a74c-5ff4-4478-af41-0dcee6645255
STEP: Creating a pod to test consume secrets
Nov 22 19:38:48.719: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-24cfabe7-b454-44af-9bb0-7fc9db5bf077" in namespace "projected-3673" to be "success or failure"
Nov 22 19:38:48.734: INFO: Pod "pod-projected-secrets-24cfabe7-b454-44af-9bb0-7fc9db5bf077": Phase="Pending", Reason="", readiness=false. Elapsed: 15.173935ms
Nov 22 19:38:50.736: INFO: Pod "pod-projected-secrets-24cfabe7-b454-44af-9bb0-7fc9db5bf077": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017151202s
Nov 22 19:38:52.738: INFO: Pod "pod-projected-secrets-24cfabe7-b454-44af-9bb0-7fc9db5bf077": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019208383s
STEP: Saw pod success
Nov 22 19:38:52.738: INFO: Pod "pod-projected-secrets-24cfabe7-b454-44af-9bb0-7fc9db5bf077" satisfied condition "success or failure"
Nov 22 19:38:52.751: INFO: Trying to get logs from node minion pod pod-projected-secrets-24cfabe7-b454-44af-9bb0-7fc9db5bf077 container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov 22 19:38:52.817: INFO: Waiting for pod pod-projected-secrets-24cfabe7-b454-44af-9bb0-7fc9db5bf077 to disappear
Nov 22 19:38:52.819: INFO: Pod pod-projected-secrets-24cfabe7-b454-44af-9bb0-7fc9db5bf077 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:38:52.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3673" for this suite.
Nov 22 19:38:58.837: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:38:59.113: INFO: namespace projected-3673 deletion completed in 6.282199799s

• [SLOW TEST:10.538 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:38:59.126: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Nov 22 19:38:59.243: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7d8f8108-f766-4369-ba1d-63a89651c872" in namespace "projected-3394" to be "success or failure"
Nov 22 19:38:59.255: INFO: Pod "downwardapi-volume-7d8f8108-f766-4369-ba1d-63a89651c872": Phase="Pending", Reason="", readiness=false. Elapsed: 12.106919ms
Nov 22 19:39:01.267: INFO: Pod "downwardapi-volume-7d8f8108-f766-4369-ba1d-63a89651c872": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.024356901s
STEP: Saw pod success
Nov 22 19:39:01.267: INFO: Pod "downwardapi-volume-7d8f8108-f766-4369-ba1d-63a89651c872" satisfied condition "success or failure"
Nov 22 19:39:01.269: INFO: Trying to get logs from node minion pod downwardapi-volume-7d8f8108-f766-4369-ba1d-63a89651c872 container client-container: <nil>
STEP: delete the pod
Nov 22 19:39:01.310: INFO: Waiting for pod downwardapi-volume-7d8f8108-f766-4369-ba1d-63a89651c872 to disappear
Nov 22 19:39:01.324: INFO: Pod downwardapi-volume-7d8f8108-f766-4369-ba1d-63a89651c872 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:39:01.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3394" for this suite.
Nov 22 19:39:07.372: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:39:07.632: INFO: namespace projected-3394 deletion completed in 6.293791862s

• [SLOW TEST:8.506 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Nov 22 19:39:07.632: INFO: >>> kubeConfig: /tmp/kubeconfig-880417063
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a replication controller
Nov 22 19:39:07.712: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 create -f - --namespace=kubectl-4432'
Nov 22 19:39:08.405: INFO: stderr: ""
Nov 22 19:39:08.405: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov 22 19:39:08.405: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4432'
Nov 22 19:39:08.827: INFO: stderr: ""
Nov 22 19:39:08.840: INFO: stdout: "update-demo-nautilus-lpmsr update-demo-nautilus-w25qf "
Nov 22 19:39:08.840: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 get pods update-demo-nautilus-lpmsr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4432'
Nov 22 19:39:09.254: INFO: stderr: ""
Nov 22 19:39:09.254: INFO: stdout: ""
Nov 22 19:39:09.254: INFO: update-demo-nautilus-lpmsr is created but not running
Nov 22 19:39:14.255: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4432'
Nov 22 19:39:14.622: INFO: stderr: ""
Nov 22 19:39:14.622: INFO: stdout: "update-demo-nautilus-lpmsr update-demo-nautilus-w25qf "
Nov 22 19:39:14.622: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 get pods update-demo-nautilus-lpmsr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4432'
Nov 22 19:39:15.091: INFO: stderr: ""
Nov 22 19:39:15.091: INFO: stdout: "true"
Nov 22 19:39:15.091: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 get pods update-demo-nautilus-lpmsr -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4432'
Nov 22 19:39:15.467: INFO: stderr: ""
Nov 22 19:39:15.467: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov 22 19:39:15.467: INFO: validating pod update-demo-nautilus-lpmsr
Nov 22 19:39:15.749: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 22 19:39:15.749: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 22 19:39:15.749: INFO: update-demo-nautilus-lpmsr is verified up and running
Nov 22 19:39:15.749: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 get pods update-demo-nautilus-w25qf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4432'
Nov 22 19:39:16.109: INFO: stderr: ""
Nov 22 19:39:16.109: INFO: stdout: "true"
Nov 22 19:39:16.109: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 get pods update-demo-nautilus-w25qf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4432'
Nov 22 19:39:16.556: INFO: stderr: ""
Nov 22 19:39:16.556: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov 22 19:39:16.556: INFO: validating pod update-demo-nautilus-w25qf
Nov 22 19:39:16.560: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 22 19:39:16.560: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 22 19:39:16.560: INFO: update-demo-nautilus-w25qf is verified up and running
STEP: using delete to clean up resources
Nov 22 19:39:16.560: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 delete --grace-period=0 --force -f - --namespace=kubectl-4432'
Nov 22 19:39:16.951: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 22 19:39:16.951: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Nov 22 19:39:16.951: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-4432'
Nov 22 19:39:17.363: INFO: stderr: "No resources found.\n"
Nov 22 19:39:17.363: INFO: stdout: ""
Nov 22 19:39:17.363: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-880417063 get pods -l name=update-demo --namespace=kubectl-4432 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov 22 19:39:17.750: INFO: stderr: ""
Nov 22 19:39:17.750: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Nov 22 19:39:17.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4432" for this suite.
Nov 22 19:39:23.775: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 22 19:39:24.517: INFO: namespace kubectl-4432 deletion completed in 6.765027673s

• [SLOW TEST:16.885 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.15.3-beta.0.68+2d3c76f9091b6b/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSNov 22 19:39:24.518: INFO: Running AfterSuite actions on all nodes
Nov 22 19:39:24.526: INFO: Running AfterSuite actions on node 1
Nov 22 19:39:24.530: INFO: Skipping dumping logs from cluster

Ran 210 of 4413 Specs in 6352.101 seconds
SUCCESS! -- 210 Passed | 0 Failed | 0 Pending | 4203 Skipped
PASS

Ginkgo ran 1 suite in 1h45m59.830938935s
Test Suite Passed
