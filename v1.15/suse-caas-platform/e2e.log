I0912 12:15:20.673581      18 test_context.go:406] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-268668657
I0912 12:15:20.673691      18 e2e.go:241] Starting e2e run "7e793f64-50ee-40aa-bb42-1aebaf2b0988" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1568290518 - Will randomize all specs
Will run 215 of 4413 specs

Sep 12 12:15:20.909: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
Sep 12 12:15:20.912: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Sep 12 12:15:20.926: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Sep 12 12:15:20.958: INFO: 30 / 30 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Sep 12 12:15:20.958: INFO: expected 5 pod replicas in namespace 'kube-system', 5 are Running and Ready.
Sep 12 12:15:20.958: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Sep 12 12:15:20.966: INFO: 7 / 7 pods ready in namespace 'kube-system' in daemonset 'cilium' (0 seconds elapsed)
Sep 12 12:15:20.966: INFO: 7 / 7 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Sep 12 12:15:20.966: INFO: 7 / 7 pods ready in namespace 'kube-system' in daemonset 'kured' (0 seconds elapsed)
Sep 12 12:15:20.966: INFO: e2e test version: v1.15.2
Sep 12 12:15:20.967: INFO: kube-apiserver version: v1.15.2
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:15:20.967: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename pod-network-test
Sep 12 12:15:21.018: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Sep 12 12:15:21.036: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-4067
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-4067
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep 12 12:15:21.151: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Sep 12 12:15:53.295: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.4.41 8081 | grep -v '^\s*$'] Namespace:pod-network-test-4067 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 12 12:15:53.295: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
Sep 12 12:15:54.365: INFO: Found all expected endpoints: [netserver-0]
Sep 12 12:15:54.367: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.2.254 8081 | grep -v '^\s*$'] Namespace:pod-network-test-4067 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 12 12:15:54.368: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
Sep 12 12:15:55.437: INFO: Found all expected endpoints: [netserver-1]
Sep 12 12:15:55.439: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.5.155 8081 | grep -v '^\s*$'] Namespace:pod-network-test-4067 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 12 12:15:55.439: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
Sep 12 12:15:56.511: INFO: Found all expected endpoints: [netserver-2]
Sep 12 12:15:56.513: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.6.245 8081 | grep -v '^\s*$'] Namespace:pod-network-test-4067 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 12 12:15:56.513: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
Sep 12 12:15:57.577: INFO: Found all expected endpoints: [netserver-3]
Sep 12 12:15:57.580: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.1.146 8081 | grep -v '^\s*$'] Namespace:pod-network-test-4067 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 12 12:15:57.580: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
Sep 12 12:15:58.650: INFO: Found all expected endpoints: [netserver-4]
Sep 12 12:15:58.652: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.3.4 8081 | grep -v '^\s*$'] Namespace:pod-network-test-4067 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 12 12:15:58.652: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
Sep 12 12:15:59.717: INFO: Found all expected endpoints: [netserver-5]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:15:59.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-4067" for this suite.
Sep 12 12:16:21.735: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:16:21.808: INFO: namespace pod-network-test-4067 deletion completed in 22.087432813s

â€¢ [SLOW TEST:60.841 seconds]
[sig-network] Networking
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:16:21.808: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5217
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep 12 12:16:22.030: INFO: Waiting up to 5m0s for pod "downwardapi-volume-12346baf-31f7-4021-a19c-f51b32684a2e" in namespace "projected-5217" to be "success or failure"
Sep 12 12:16:22.045: INFO: Pod "downwardapi-volume-12346baf-31f7-4021-a19c-f51b32684a2e": Phase="Pending", Reason="", readiness=false. Elapsed: 14.189031ms
Sep 12 12:16:24.047: INFO: Pod "downwardapi-volume-12346baf-31f7-4021-a19c-f51b32684a2e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016697841s
Sep 12 12:16:26.049: INFO: Pod "downwardapi-volume-12346baf-31f7-4021-a19c-f51b32684a2e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.019116987s
Sep 12 12:16:28.052: INFO: Pod "downwardapi-volume-12346baf-31f7-4021-a19c-f51b32684a2e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.021455324s
Sep 12 12:16:30.054: INFO: Pod "downwardapi-volume-12346baf-31f7-4021-a19c-f51b32684a2e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.023776446s
STEP: Saw pod success
Sep 12 12:16:30.054: INFO: Pod "downwardapi-volume-12346baf-31f7-4021-a19c-f51b32684a2e" satisfied condition "success or failure"
Sep 12 12:16:30.056: INFO: Trying to get logs from node caasp-worker-thehejik-3 pod downwardapi-volume-12346baf-31f7-4021-a19c-f51b32684a2e container client-container: <nil>
STEP: delete the pod
Sep 12 12:16:30.090: INFO: Waiting for pod downwardapi-volume-12346baf-31f7-4021-a19c-f51b32684a2e to disappear
Sep 12 12:16:30.099: INFO: Pod downwardapi-volume-12346baf-31f7-4021-a19c-f51b32684a2e no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:16:30.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5217" for this suite.
Sep 12 12:16:36.164: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:16:36.229: INFO: namespace projected-5217 deletion completed in 6.127303252s

â€¢ [SLOW TEST:14.421 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:16:36.229: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-7232
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 12 12:16:36.474: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"0ccfdaab-d4c8-4345-96fe-ceeda875ca32", Controller:(*bool)(0xc001d653ca), BlockOwnerDeletion:(*bool)(0xc001d653cb)}}
Sep 12 12:16:36.482: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"a7d133d8-7133-4b6e-8523-0c5d4970a9eb", Controller:(*bool)(0xc001e5baba), BlockOwnerDeletion:(*bool)(0xc001e5babb)}}
Sep 12 12:16:36.492: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"febab00c-8507-4f34-bd4a-6577e794f479", Controller:(*bool)(0xc001f2c116), BlockOwnerDeletion:(*bool)(0xc001f2c117)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:16:41.504: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7232" for this suite.
Sep 12 12:16:47.523: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:16:47.595: INFO: namespace gc-7232 deletion completed in 6.08850576s

â€¢ [SLOW TEST:11.366 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:16:47.596: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-259
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name projected-secret-test-6a9f3b39-0d9f-4e92-958e-6eae1a9ba5fb
STEP: Creating a pod to test consume secrets
Sep 12 12:16:47.763: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f922b888-f91e-4b7f-9fda-af7fb506472c" in namespace "projected-259" to be "success or failure"
Sep 12 12:16:47.772: INFO: Pod "pod-projected-secrets-f922b888-f91e-4b7f-9fda-af7fb506472c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.971263ms
Sep 12 12:16:49.774: INFO: Pod "pod-projected-secrets-f922b888-f91e-4b7f-9fda-af7fb506472c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011463155s
Sep 12 12:16:51.777: INFO: Pod "pod-projected-secrets-f922b888-f91e-4b7f-9fda-af7fb506472c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013714275s
Sep 12 12:16:53.779: INFO: Pod "pod-projected-secrets-f922b888-f91e-4b7f-9fda-af7fb506472c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.016263936s
Sep 12 12:16:55.781: INFO: Pod "pod-projected-secrets-f922b888-f91e-4b7f-9fda-af7fb506472c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.018345458s
STEP: Saw pod success
Sep 12 12:16:55.781: INFO: Pod "pod-projected-secrets-f922b888-f91e-4b7f-9fda-af7fb506472c" satisfied condition "success or failure"
Sep 12 12:16:55.783: INFO: Trying to get logs from node caasp-worker-thehejik-1 pod pod-projected-secrets-f922b888-f91e-4b7f-9fda-af7fb506472c container secret-volume-test: <nil>
STEP: delete the pod
Sep 12 12:16:55.813: INFO: Waiting for pod pod-projected-secrets-f922b888-f91e-4b7f-9fda-af7fb506472c to disappear
Sep 12 12:16:55.823: INFO: Pod pod-projected-secrets-f922b888-f91e-4b7f-9fda-af7fb506472c no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:16:55.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-259" for this suite.
Sep 12 12:17:01.841: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:17:01.908: INFO: namespace projected-259 deletion completed in 6.082893172s

â€¢ [SLOW TEST:14.313 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:17:01.909: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8520
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting the proxy server
Sep 12 12:17:02.066: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-268668657 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:17:02.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8520" for this suite.
Sep 12 12:17:08.252: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:17:08.314: INFO: namespace kubectl-8520 deletion completed in 6.075395728s

â€¢ [SLOW TEST:6.406 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:17:08.315: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-2693
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-eb0dedec-c80e-4c4c-8d82-5a874815c1a4
STEP: Creating a pod to test consume secrets
Sep 12 12:17:08.486: INFO: Waiting up to 5m0s for pod "pod-secrets-4962d4f4-feb4-409c-92b6-5159fdadf1f1" in namespace "secrets-2693" to be "success or failure"
Sep 12 12:17:08.509: INFO: Pod "pod-secrets-4962d4f4-feb4-409c-92b6-5159fdadf1f1": Phase="Pending", Reason="", readiness=false. Elapsed: 23.470965ms
Sep 12 12:17:10.511: INFO: Pod "pod-secrets-4962d4f4-feb4-409c-92b6-5159fdadf1f1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025646326s
Sep 12 12:17:12.514: INFO: Pod "pod-secrets-4962d4f4-feb4-409c-92b6-5159fdadf1f1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.028403005s
Sep 12 12:17:14.516: INFO: Pod "pod-secrets-4962d4f4-feb4-409c-92b6-5159fdadf1f1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.030656352s
Sep 12 12:17:16.519: INFO: Pod "pod-secrets-4962d4f4-feb4-409c-92b6-5159fdadf1f1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.032948519s
STEP: Saw pod success
Sep 12 12:17:16.519: INFO: Pod "pod-secrets-4962d4f4-feb4-409c-92b6-5159fdadf1f1" satisfied condition "success or failure"
Sep 12 12:17:16.520: INFO: Trying to get logs from node caasp-worker-thehejik-5 pod pod-secrets-4962d4f4-feb4-409c-92b6-5159fdadf1f1 container secret-volume-test: <nil>
STEP: delete the pod
Sep 12 12:17:16.549: INFO: Waiting for pod pod-secrets-4962d4f4-feb4-409c-92b6-5159fdadf1f1 to disappear
Sep 12 12:17:16.560: INFO: Pod pod-secrets-4962d4f4-feb4-409c-92b6-5159fdadf1f1 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:17:16.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2693" for this suite.
Sep 12 12:17:22.599: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:17:22.664: INFO: namespace secrets-2693 deletion completed in 6.101109928s

â€¢ [SLOW TEST:14.349 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:17:22.664: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-3704
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Sep 12 12:17:33.340: INFO: Successfully updated pod "pod-update-activedeadlineseconds-0bb55abc-469f-4308-ad1f-891d670ccedf"
Sep 12 12:17:33.341: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-0bb55abc-469f-4308-ad1f-891d670ccedf" in namespace "pods-3704" to be "terminated due to deadline exceeded"
Sep 12 12:17:33.453: INFO: Pod "pod-update-activedeadlineseconds-0bb55abc-469f-4308-ad1f-891d670ccedf": Phase="Running", Reason="", readiness=true. Elapsed: 112.394656ms
Sep 12 12:17:35.455: INFO: Pod "pod-update-activedeadlineseconds-0bb55abc-469f-4308-ad1f-891d670ccedf": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.114496663s
Sep 12 12:17:35.455: INFO: Pod "pod-update-activedeadlineseconds-0bb55abc-469f-4308-ad1f-891d670ccedf" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:17:35.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3704" for this suite.
Sep 12 12:17:41.476: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:17:41.543: INFO: namespace pods-3704 deletion completed in 6.085082397s

â€¢ [SLOW TEST:18.880 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:17:41.544: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-2071
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 12 12:17:41.732: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Sep 12 12:17:41.743: INFO: Number of nodes with available pods: 0
Sep 12 12:17:41.743: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Sep 12 12:17:41.773: INFO: Number of nodes with available pods: 0
Sep 12 12:17:41.773: INFO: Node caasp-worker-thehejik-0 is running more than one daemon pod
Sep 12 12:17:42.775: INFO: Number of nodes with available pods: 0
Sep 12 12:17:42.775: INFO: Node caasp-worker-thehejik-0 is running more than one daemon pod
Sep 12 12:17:43.775: INFO: Number of nodes with available pods: 0
Sep 12 12:17:43.775: INFO: Node caasp-worker-thehejik-0 is running more than one daemon pod
Sep 12 12:17:44.775: INFO: Number of nodes with available pods: 1
Sep 12 12:17:44.775: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Sep 12 12:17:44.789: INFO: Number of nodes with available pods: 1
Sep 12 12:17:44.789: INFO: Number of running nodes: 0, number of available pods: 1
Sep 12 12:17:45.791: INFO: Number of nodes with available pods: 0
Sep 12 12:17:45.791: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Sep 12 12:17:45.805: INFO: Number of nodes with available pods: 0
Sep 12 12:17:45.806: INFO: Node caasp-worker-thehejik-0 is running more than one daemon pod
Sep 12 12:17:46.808: INFO: Number of nodes with available pods: 0
Sep 12 12:17:46.808: INFO: Node caasp-worker-thehejik-0 is running more than one daemon pod
Sep 12 12:17:47.808: INFO: Number of nodes with available pods: 0
Sep 12 12:17:47.808: INFO: Node caasp-worker-thehejik-0 is running more than one daemon pod
Sep 12 12:17:48.808: INFO: Number of nodes with available pods: 0
Sep 12 12:17:48.808: INFO: Node caasp-worker-thehejik-0 is running more than one daemon pod
Sep 12 12:17:49.808: INFO: Number of nodes with available pods: 0
Sep 12 12:17:49.808: INFO: Node caasp-worker-thehejik-0 is running more than one daemon pod
Sep 12 12:17:50.808: INFO: Number of nodes with available pods: 0
Sep 12 12:17:50.808: INFO: Node caasp-worker-thehejik-0 is running more than one daemon pod
Sep 12 12:17:51.808: INFO: Number of nodes with available pods: 0
Sep 12 12:17:51.808: INFO: Node caasp-worker-thehejik-0 is running more than one daemon pod
Sep 12 12:17:52.808: INFO: Number of nodes with available pods: 0
Sep 12 12:17:52.808: INFO: Node caasp-worker-thehejik-0 is running more than one daemon pod
Sep 12 12:17:53.808: INFO: Number of nodes with available pods: 0
Sep 12 12:17:53.808: INFO: Node caasp-worker-thehejik-0 is running more than one daemon pod
Sep 12 12:17:54.808: INFO: Number of nodes with available pods: 0
Sep 12 12:17:54.808: INFO: Node caasp-worker-thehejik-0 is running more than one daemon pod
Sep 12 12:17:55.808: INFO: Number of nodes with available pods: 0
Sep 12 12:17:55.808: INFO: Node caasp-worker-thehejik-0 is running more than one daemon pod
Sep 12 12:17:56.808: INFO: Number of nodes with available pods: 0
Sep 12 12:17:56.808: INFO: Node caasp-worker-thehejik-0 is running more than one daemon pod
Sep 12 12:17:57.808: INFO: Number of nodes with available pods: 0
Sep 12 12:17:57.808: INFO: Node caasp-worker-thehejik-0 is running more than one daemon pod
Sep 12 12:17:58.808: INFO: Number of nodes with available pods: 0
Sep 12 12:17:58.808: INFO: Node caasp-worker-thehejik-0 is running more than one daemon pod
Sep 12 12:17:59.808: INFO: Number of nodes with available pods: 0
Sep 12 12:17:59.808: INFO: Node caasp-worker-thehejik-0 is running more than one daemon pod
Sep 12 12:18:00.807: INFO: Number of nodes with available pods: 1
Sep 12 12:18:00.808: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2071, will wait for the garbage collector to delete the pods
Sep 12 12:18:00.866: INFO: Deleting DaemonSet.extensions daemon-set took: 3.399655ms
Sep 12 12:18:01.266: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.171229ms
Sep 12 12:18:07.669: INFO: Number of nodes with available pods: 0
Sep 12 12:18:07.669: INFO: Number of running nodes: 0, number of available pods: 0
Sep 12 12:18:07.672: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-2071/daemonsets","resourceVersion":"7090"},"items":null}

Sep 12 12:18:07.674: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-2071/pods","resourceVersion":"7090"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:18:07.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2071" for this suite.
Sep 12 12:18:13.726: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:18:13.811: INFO: namespace daemonsets-2071 deletion completed in 6.103713328s

â€¢ [SLOW TEST:32.267 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:18:13.812: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-8152
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Sep 12 12:18:26.016: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep 12 12:18:26.029: INFO: Pod pod-with-prestop-http-hook still exists
Sep 12 12:18:28.029: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep 12 12:18:28.031: INFO: Pod pod-with-prestop-http-hook still exists
Sep 12 12:18:30.029: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Sep 12 12:18:30.031: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:18:30.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8152" for this suite.
Sep 12 12:18:52.066: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:18:52.134: INFO: namespace container-lifecycle-hook-8152 deletion completed in 22.083821466s

â€¢ [SLOW TEST:38.322 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:18:52.134: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3622
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with configMap that has name projected-configmap-test-upd-b3dfcd12-79a6-40f8-91a7-3d8677136a8a
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-b3dfcd12-79a6-40f8-91a7-3d8677136a8a
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:20:02.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3622" for this suite.
Sep 12 12:20:24.759: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:20:24.832: INFO: namespace projected-3622 deletion completed in 22.087863221s

â€¢ [SLOW TEST:92.699 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:20:24.833: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-8038
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test substitution in container's args
Sep 12 12:20:25.022: INFO: Waiting up to 5m0s for pod "var-expansion-ebdc964a-a8c7-4677-a926-09e676416a63" in namespace "var-expansion-8038" to be "success or failure"
Sep 12 12:20:25.095: INFO: Pod "var-expansion-ebdc964a-a8c7-4677-a926-09e676416a63": Phase="Pending", Reason="", readiness=false. Elapsed: 73.076397ms
Sep 12 12:20:27.098: INFO: Pod "var-expansion-ebdc964a-a8c7-4677-a926-09e676416a63": Phase="Pending", Reason="", readiness=false. Elapsed: 2.075532417s
Sep 12 12:20:29.101: INFO: Pod "var-expansion-ebdc964a-a8c7-4677-a926-09e676416a63": Phase="Pending", Reason="", readiness=false. Elapsed: 4.078297819s
Sep 12 12:20:31.103: INFO: Pod "var-expansion-ebdc964a-a8c7-4677-a926-09e676416a63": Phase="Pending", Reason="", readiness=false. Elapsed: 6.080513055s
Sep 12 12:20:33.122: INFO: Pod "var-expansion-ebdc964a-a8c7-4677-a926-09e676416a63": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.100191359s
STEP: Saw pod success
Sep 12 12:20:33.123: INFO: Pod "var-expansion-ebdc964a-a8c7-4677-a926-09e676416a63" satisfied condition "success or failure"
Sep 12 12:20:33.131: INFO: Trying to get logs from node caasp-worker-thehejik-1 pod var-expansion-ebdc964a-a8c7-4677-a926-09e676416a63 container dapi-container: <nil>
STEP: delete the pod
Sep 12 12:20:33.186: INFO: Waiting for pod var-expansion-ebdc964a-a8c7-4677-a926-09e676416a63 to disappear
Sep 12 12:20:33.187: INFO: Pod var-expansion-ebdc964a-a8c7-4677-a926-09e676416a63 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:20:33.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-8038" for this suite.
Sep 12 12:20:39.204: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:20:39.270: INFO: namespace var-expansion-8038 deletion completed in 6.079914121s

â€¢ [SLOW TEST:14.437 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:20:39.270: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-2079
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Sep 12 12:20:48.466: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:20:48.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-2079" for this suite.
Sep 12 12:20:54.510: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:20:54.575: INFO: namespace container-runtime-2079 deletion completed in 6.081382731s

â€¢ [SLOW TEST:15.305 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:20:54.575: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5316
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-projected-all-test-volume-e188461c-2a2d-4565-a5db-629a0cd927e3
STEP: Creating secret with name secret-projected-all-test-volume-71f9c782-f403-4192-9cec-523bf0e7c705
STEP: Creating a pod to test Check all projections for projected volume plugin
Sep 12 12:20:54.770: INFO: Waiting up to 5m0s for pod "projected-volume-e2691532-61d8-4915-938c-0202462e99ea" in namespace "projected-5316" to be "success or failure"
Sep 12 12:20:54.787: INFO: Pod "projected-volume-e2691532-61d8-4915-938c-0202462e99ea": Phase="Pending", Reason="", readiness=false. Elapsed: 16.587734ms
Sep 12 12:20:56.790: INFO: Pod "projected-volume-e2691532-61d8-4915-938c-0202462e99ea": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019120446s
Sep 12 12:20:58.792: INFO: Pod "projected-volume-e2691532-61d8-4915-938c-0202462e99ea": Phase="Pending", Reason="", readiness=false. Elapsed: 4.021629862s
Sep 12 12:21:00.851: INFO: Pod "projected-volume-e2691532-61d8-4915-938c-0202462e99ea": Phase="Pending", Reason="", readiness=false. Elapsed: 6.080457356s
Sep 12 12:21:02.853: INFO: Pod "projected-volume-e2691532-61d8-4915-938c-0202462e99ea": Phase="Pending", Reason="", readiness=false. Elapsed: 8.082706217s
Sep 12 12:21:04.856: INFO: Pod "projected-volume-e2691532-61d8-4915-938c-0202462e99ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.08520405s
STEP: Saw pod success
Sep 12 12:21:04.856: INFO: Pod "projected-volume-e2691532-61d8-4915-938c-0202462e99ea" satisfied condition "success or failure"
Sep 12 12:21:04.857: INFO: Trying to get logs from node caasp-worker-thehejik-3 pod projected-volume-e2691532-61d8-4915-938c-0202462e99ea container projected-all-volume-test: <nil>
STEP: delete the pod
Sep 12 12:21:04.876: INFO: Waiting for pod projected-volume-e2691532-61d8-4915-938c-0202462e99ea to disappear
Sep 12 12:21:04.884: INFO: Pod projected-volume-e2691532-61d8-4915-938c-0202462e99ea no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:21:04.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5316" for this suite.
Sep 12 12:21:10.899: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:21:10.962: INFO: namespace projected-5316 deletion completed in 6.075747594s

â€¢ [SLOW TEST:16.387 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:31
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:21:10.964: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1096
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep 12 12:21:11.145: INFO: Waiting up to 5m0s for pod "downwardapi-volume-20e883c1-8fdb-418a-86a6-9b66209b8a0b" in namespace "projected-1096" to be "success or failure"
Sep 12 12:21:11.170: INFO: Pod "downwardapi-volume-20e883c1-8fdb-418a-86a6-9b66209b8a0b": Phase="Pending", Reason="", readiness=false. Elapsed: 25.942398ms
Sep 12 12:21:13.173: INFO: Pod "downwardapi-volume-20e883c1-8fdb-418a-86a6-9b66209b8a0b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028311747s
Sep 12 12:21:15.175: INFO: Pod "downwardapi-volume-20e883c1-8fdb-418a-86a6-9b66209b8a0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030626409s
STEP: Saw pod success
Sep 12 12:21:15.175: INFO: Pod "downwardapi-volume-20e883c1-8fdb-418a-86a6-9b66209b8a0b" satisfied condition "success or failure"
Sep 12 12:21:15.177: INFO: Trying to get logs from node caasp-worker-thehejik-1 pod downwardapi-volume-20e883c1-8fdb-418a-86a6-9b66209b8a0b container client-container: <nil>
STEP: delete the pod
Sep 12 12:21:15.198: INFO: Waiting for pod downwardapi-volume-20e883c1-8fdb-418a-86a6-9b66209b8a0b to disappear
Sep 12 12:21:15.209: INFO: Pod downwardapi-volume-20e883c1-8fdb-418a-86a6-9b66209b8a0b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:21:15.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1096" for this suite.
Sep 12 12:21:21.226: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:21:21.292: INFO: namespace projected-1096 deletion completed in 6.079978096s

â€¢ [SLOW TEST:10.328 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:21:21.294: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-4918
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:21:21.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4918" for this suite.
Sep 12 12:21:27.482: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:21:27.562: INFO: namespace services-4918 deletion completed in 6.09547201s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

â€¢ [SLOW TEST:6.268 seconds]
[sig-network] Services
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide secure master service  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:21:27.565: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-9135
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod liveness-5339a66c-ded0-4667-907b-a1e473a70995 in namespace container-probe-9135
Sep 12 12:21:35.755: INFO: Started pod liveness-5339a66c-ded0-4667-907b-a1e473a70995 in namespace container-probe-9135
STEP: checking the pod's current state and verifying that restartCount is present
Sep 12 12:21:35.757: INFO: Initial restart count of pod liveness-5339a66c-ded0-4667-907b-a1e473a70995 is 0
Sep 12 12:21:55.782: INFO: Restart count of pod container-probe-9135/liveness-5339a66c-ded0-4667-907b-a1e473a70995 is now 1 (20.025355973s elapsed)
Sep 12 12:22:15.869: INFO: Restart count of pod container-probe-9135/liveness-5339a66c-ded0-4667-907b-a1e473a70995 is now 2 (40.112889858s elapsed)
Sep 12 12:22:35.937: INFO: Restart count of pod container-probe-9135/liveness-5339a66c-ded0-4667-907b-a1e473a70995 is now 3 (1m0.18010855s elapsed)
Sep 12 12:22:55.960: INFO: Restart count of pod container-probe-9135/liveness-5339a66c-ded0-4667-907b-a1e473a70995 is now 4 (1m20.20352463s elapsed)
Sep 12 12:23:58.125: INFO: Restart count of pod container-probe-9135/liveness-5339a66c-ded0-4667-907b-a1e473a70995 is now 5 (2m22.368064646s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:23:58.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9135" for this suite.
Sep 12 12:24:04.172: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:24:04.239: INFO: namespace container-probe-9135 deletion completed in 6.079105503s

â€¢ [SLOW TEST:156.674 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:24:04.239: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-1551
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod busybox-48773864-8caf-4e84-941d-fd1c8f4fb7aa in namespace container-probe-1551
Sep 12 12:24:12.412: INFO: Started pod busybox-48773864-8caf-4e84-941d-fd1c8f4fb7aa in namespace container-probe-1551
STEP: checking the pod's current state and verifying that restartCount is present
Sep 12 12:24:12.414: INFO: Initial restart count of pod busybox-48773864-8caf-4e84-941d-fd1c8f4fb7aa is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:28:12.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1551" for this suite.
Sep 12 12:28:18.944: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:28:19.054: INFO: namespace container-probe-1551 deletion completed in 6.130155447s

â€¢ [SLOW TEST:254.815 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:28:19.055: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-3895
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:28:23.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3895" for this suite.
Sep 12 12:29:01.368: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:29:01.431: INFO: namespace kubelet-test-3895 deletion completed in 38.16919137s

â€¢ [SLOW TEST:42.376 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command in a pod
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:29:01.436: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5458
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep 12 12:29:01.591: INFO: Waiting up to 5m0s for pod "downwardapi-volume-692b9ac4-822e-492d-8778-185d21277911" in namespace "projected-5458" to be "success or failure"
Sep 12 12:29:01.601: INFO: Pod "downwardapi-volume-692b9ac4-822e-492d-8778-185d21277911": Phase="Pending", Reason="", readiness=false. Elapsed: 9.158847ms
Sep 12 12:29:03.603: INFO: Pod "downwardapi-volume-692b9ac4-822e-492d-8778-185d21277911": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011904605s
Sep 12 12:29:05.606: INFO: Pod "downwardapi-volume-692b9ac4-822e-492d-8778-185d21277911": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014085436s
STEP: Saw pod success
Sep 12 12:29:05.606: INFO: Pod "downwardapi-volume-692b9ac4-822e-492d-8778-185d21277911" satisfied condition "success or failure"
Sep 12 12:29:05.607: INFO: Trying to get logs from node caasp-worker-thehejik-5 pod downwardapi-volume-692b9ac4-822e-492d-8778-185d21277911 container client-container: <nil>
STEP: delete the pod
Sep 12 12:29:05.628: INFO: Waiting for pod downwardapi-volume-692b9ac4-822e-492d-8778-185d21277911 to disappear
Sep 12 12:29:05.640: INFO: Pod downwardapi-volume-692b9ac4-822e-492d-8778-185d21277911 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:29:05.640: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5458" for this suite.
Sep 12 12:29:11.662: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:29:11.727: INFO: namespace projected-5458 deletion completed in 6.083673246s

â€¢ [SLOW TEST:10.291 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:29:11.728: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-8394
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-8394, will wait for the garbage collector to delete the pods
Sep 12 12:29:21.945: INFO: Deleting Job.batch foo took: 3.191995ms
Sep 12 12:29:22.345: INFO: Terminating Job.batch foo pods took: 400.178525ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:29:56.848: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-8394" for this suite.
Sep 12 12:30:02.875: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:30:02.936: INFO: namespace job-8394 deletion completed in 6.085641354s

â€¢ [SLOW TEST:51.208 seconds]
[sig-apps] Job
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:30:02.936: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6797
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1558
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep 12 12:30:03.094: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --generator=deployment/apps.v1 --namespace=kubectl-6797'
Sep 12 12:30:03.470: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep 12 12:30:03.470: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the deployment e2e-test-nginx-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-nginx-deployment was created
[AfterEach] [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1563
Sep 12 12:30:05.523: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 delete deployment e2e-test-nginx-deployment --namespace=kubectl-6797'
Sep 12 12:30:05.613: INFO: stderr: ""
Sep 12 12:30:05.613: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:30:05.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6797" for this suite.
Sep 12 12:30:43.635: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:30:43.707: INFO: namespace kubectl-6797 deletion completed in 38.090793007s

â€¢ [SLOW TEST:40.771 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:30:43.708: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-6043
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod test-webserver-b5819e31-c12c-44db-a89e-a97c57060396 in namespace container-probe-6043
Sep 12 12:30:51.884: INFO: Started pod test-webserver-b5819e31-c12c-44db-a89e-a97c57060396 in namespace container-probe-6043
STEP: checking the pod's current state and verifying that restartCount is present
Sep 12 12:30:51.886: INFO: Initial restart count of pod test-webserver-b5819e31-c12c-44db-a89e-a97c57060396 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:34:52.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6043" for this suite.
Sep 12 12:34:58.242: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:34:58.309: INFO: namespace container-probe-6043 deletion completed in 6.087382743s

â€¢ [SLOW TEST:254.602 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:34:58.310: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-917
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod liveness-4cec1f6c-0607-448f-9e11-1a9223fa80b4 in namespace container-probe-917
Sep 12 12:35:06.480: INFO: Started pod liveness-4cec1f6c-0607-448f-9e11-1a9223fa80b4 in namespace container-probe-917
STEP: checking the pod's current state and verifying that restartCount is present
Sep 12 12:35:06.481: INFO: Initial restart count of pod liveness-4cec1f6c-0607-448f-9e11-1a9223fa80b4 is 0
Sep 12 12:35:26.507: INFO: Restart count of pod container-probe-917/liveness-4cec1f6c-0607-448f-9e11-1a9223fa80b4 is now 1 (20.025964323s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:35:26.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-917" for this suite.
Sep 12 12:35:32.568: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:35:32.634: INFO: namespace container-probe-917 deletion completed in 6.090826329s

â€¢ [SLOW TEST:34.324 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:35:32.636: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-7097
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7097.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-7097.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7097.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-7097.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 12 12:35:58.820: INFO: DNS probes using dns-test-de076d52-ff33-42b6-a47b-ebdec9feb7c7 succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7097.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-7097.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7097.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-7097.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 12 12:36:34.886: INFO: DNS probes using dns-test-4d9c30c3-733c-4183-a8e2-d5201c2fa34a succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7097.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-7097.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7097.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-7097.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 12 12:37:00.977: INFO: DNS probes using dns-test-8867af6b-3542-4271-a2f8-9a8830a78190 succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:37:01.064: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7097" for this suite.
Sep 12 12:37:09.094: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:37:09.160: INFO: namespace dns-7097 deletion completed in 8.080618809s

â€¢ [SLOW TEST:96.524 seconds]
[sig-network] DNS
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:37:09.160: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-9382
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override command
Sep 12 12:37:09.486: INFO: Waiting up to 5m0s for pod "client-containers-cd785772-6540-4996-941f-4bb9e99ec187" in namespace "containers-9382" to be "success or failure"
Sep 12 12:37:09.502: INFO: Pod "client-containers-cd785772-6540-4996-941f-4bb9e99ec187": Phase="Pending", Reason="", readiness=false. Elapsed: 15.473605ms
Sep 12 12:37:11.504: INFO: Pod "client-containers-cd785772-6540-4996-941f-4bb9e99ec187": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017622076s
Sep 12 12:37:13.507: INFO: Pod "client-containers-cd785772-6540-4996-941f-4bb9e99ec187": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020582908s
Sep 12 12:37:15.509: INFO: Pod "client-containers-cd785772-6540-4996-941f-4bb9e99ec187": Phase="Pending", Reason="", readiness=false. Elapsed: 6.022704869s
Sep 12 12:37:17.512: INFO: Pod "client-containers-cd785772-6540-4996-941f-4bb9e99ec187": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.025482758s
STEP: Saw pod success
Sep 12 12:37:17.512: INFO: Pod "client-containers-cd785772-6540-4996-941f-4bb9e99ec187" satisfied condition "success or failure"
Sep 12 12:37:17.513: INFO: Trying to get logs from node caasp-worker-thehejik-2 pod client-containers-cd785772-6540-4996-941f-4bb9e99ec187 container test-container: <nil>
STEP: delete the pod
Sep 12 12:37:17.650: INFO: Waiting for pod client-containers-cd785772-6540-4996-941f-4bb9e99ec187 to disappear
Sep 12 12:37:17.652: INFO: Pod client-containers-cd785772-6540-4996-941f-4bb9e99ec187 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:37:17.652: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-9382" for this suite.
Sep 12 12:37:23.767: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:37:23.833: INFO: namespace containers-9382 deletion completed in 6.178055565s

â€¢ [SLOW TEST:14.673 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:37:23.834: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9321
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on tmpfs
Sep 12 12:37:23.987: INFO: Waiting up to 5m0s for pod "pod-2130582b-612e-47dd-8235-3bb707f8f84c" in namespace "emptydir-9321" to be "success or failure"
Sep 12 12:37:23.996: INFO: Pod "pod-2130582b-612e-47dd-8235-3bb707f8f84c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.218083ms
Sep 12 12:37:26.002: INFO: Pod "pod-2130582b-612e-47dd-8235-3bb707f8f84c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014363255s
Sep 12 12:37:28.004: INFO: Pod "pod-2130582b-612e-47dd-8235-3bb707f8f84c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016725408s
Sep 12 12:37:30.007: INFO: Pod "pod-2130582b-612e-47dd-8235-3bb707f8f84c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.019065064s
Sep 12 12:37:32.009: INFO: Pod "pod-2130582b-612e-47dd-8235-3bb707f8f84c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.021808972s
STEP: Saw pod success
Sep 12 12:37:32.009: INFO: Pod "pod-2130582b-612e-47dd-8235-3bb707f8f84c" satisfied condition "success or failure"
Sep 12 12:37:32.011: INFO: Trying to get logs from node caasp-worker-thehejik-4 pod pod-2130582b-612e-47dd-8235-3bb707f8f84c container test-container: <nil>
STEP: delete the pod
Sep 12 12:37:32.033: INFO: Waiting for pod pod-2130582b-612e-47dd-8235-3bb707f8f84c to disappear
Sep 12 12:37:32.043: INFO: Pod pod-2130582b-612e-47dd-8235-3bb707f8f84c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:37:32.043: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9321" for this suite.
Sep 12 12:37:38.058: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:37:38.124: INFO: namespace emptydir-9321 deletion completed in 6.078216271s

â€¢ [SLOW TEST:14.290 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:37:38.125: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2228
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Sep 12 12:37:42.809: INFO: Successfully updated pod "labelsupdatec794afaa-ae66-4529-b489-23bbce8b820e"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:37:44.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2228" for this suite.
Sep 12 12:38:06.869: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:38:06.937: INFO: namespace downward-api-2228 deletion completed in 22.098925961s

â€¢ [SLOW TEST:28.812 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:38:06.937: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-7038
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating service endpoint-test2 in namespace services-7038
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7038 to expose endpoints map[]
Sep 12 12:38:07.109: INFO: Get endpoints failed (9.342782ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Sep 12 12:38:08.112: INFO: successfully validated that service endpoint-test2 in namespace services-7038 exposes endpoints map[] (1.011619189s elapsed)
STEP: Creating pod pod1 in namespace services-7038
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7038 to expose endpoints map[pod1:[80]]
Sep 12 12:38:12.163: INFO: Unexpected endpoints: found map[], expected map[pod1:[80]] (4.04660883s elapsed, will retry)
Sep 12 12:38:15.173: INFO: successfully validated that service endpoint-test2 in namespace services-7038 exposes endpoints map[pod1:[80]] (7.057145374s elapsed)
STEP: Creating pod pod2 in namespace services-7038
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7038 to expose endpoints map[pod1:[80] pod2:[80]]
Sep 12 12:38:19.225: INFO: Unexpected endpoints: found map[94bd8d7d-c898-4644-bcb2-4153eb084818:[80]], expected map[pod1:[80] pod2:[80]] (4.048220782s elapsed, will retry)
Sep 12 12:38:22.240: INFO: successfully validated that service endpoint-test2 in namespace services-7038 exposes endpoints map[pod1:[80] pod2:[80]] (7.06401383s elapsed)
STEP: Deleting pod pod1 in namespace services-7038
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7038 to expose endpoints map[pod2:[80]]
Sep 12 12:38:23.279: INFO: successfully validated that service endpoint-test2 in namespace services-7038 exposes endpoints map[pod2:[80]] (1.035321395s elapsed)
STEP: Deleting pod pod2 in namespace services-7038
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7038 to expose endpoints map[]
Sep 12 12:38:24.293: INFO: successfully validated that service endpoint-test2 in namespace services-7038 exposes endpoints map[] (1.011462825s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:38:24.342: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7038" for this suite.
Sep 12 12:38:30.379: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:38:30.448: INFO: namespace services-7038 deletion completed in 6.093879776s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

â€¢ [SLOW TEST:23.511 seconds]
[sig-network] Services
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:38:30.448: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-7765
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 12 12:38:30.628: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Sep 12 12:38:30.640: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:38:30.646: INFO: Number of nodes with available pods: 0
Sep 12 12:38:30.646: INFO: Node caasp-worker-thehejik-0 is running more than one daemon pod
Sep 12 12:38:31.652: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:38:31.655: INFO: Number of nodes with available pods: 0
Sep 12 12:38:31.655: INFO: Node caasp-worker-thehejik-0 is running more than one daemon pod
Sep 12 12:38:32.649: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:38:32.656: INFO: Number of nodes with available pods: 0
Sep 12 12:38:32.656: INFO: Node caasp-worker-thehejik-0 is running more than one daemon pod
Sep 12 12:38:33.650: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:38:33.653: INFO: Number of nodes with available pods: 2
Sep 12 12:38:33.653: INFO: Node caasp-worker-thehejik-1 is running more than one daemon pod
Sep 12 12:38:34.649: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:38:34.652: INFO: Number of nodes with available pods: 4
Sep 12 12:38:34.652: INFO: Node caasp-worker-thehejik-1 is running more than one daemon pod
Sep 12 12:38:35.650: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:38:35.652: INFO: Number of nodes with available pods: 4
Sep 12 12:38:35.652: INFO: Node caasp-worker-thehejik-1 is running more than one daemon pod
Sep 12 12:38:36.649: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:38:36.652: INFO: Number of nodes with available pods: 4
Sep 12 12:38:36.652: INFO: Node caasp-worker-thehejik-1 is running more than one daemon pod
Sep 12 12:38:37.650: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:38:37.652: INFO: Number of nodes with available pods: 4
Sep 12 12:38:37.652: INFO: Node caasp-worker-thehejik-1 is running more than one daemon pod
Sep 12 12:38:38.650: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:38:38.652: INFO: Number of nodes with available pods: 4
Sep 12 12:38:38.653: INFO: Node caasp-worker-thehejik-1 is running more than one daemon pod
Sep 12 12:38:39.650: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:38:39.652: INFO: Number of nodes with available pods: 5
Sep 12 12:38:39.652: INFO: Node caasp-worker-thehejik-5 is running more than one daemon pod
Sep 12 12:38:40.650: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:38:40.652: INFO: Number of nodes with available pods: 6
Sep 12 12:38:40.652: INFO: Number of running nodes: 6, number of available pods: 6
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Sep 12 12:38:40.685: INFO: Wrong image for pod: daemon-set-66rc5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:40.685: INFO: Wrong image for pod: daemon-set-clpcc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:40.685: INFO: Wrong image for pod: daemon-set-gjkg2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:40.685: INFO: Wrong image for pod: daemon-set-hrxjj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:40.685: INFO: Wrong image for pod: daemon-set-q6m4s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:40.685: INFO: Wrong image for pod: daemon-set-wkqs8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:40.696: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:38:41.699: INFO: Wrong image for pod: daemon-set-66rc5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:41.699: INFO: Wrong image for pod: daemon-set-clpcc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:41.699: INFO: Wrong image for pod: daemon-set-gjkg2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:41.699: INFO: Wrong image for pod: daemon-set-hrxjj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:41.699: INFO: Wrong image for pod: daemon-set-q6m4s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:41.699: INFO: Wrong image for pod: daemon-set-wkqs8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:41.702: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:38:42.700: INFO: Wrong image for pod: daemon-set-66rc5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:42.700: INFO: Wrong image for pod: daemon-set-clpcc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:42.700: INFO: Pod daemon-set-clpcc is not available
Sep 12 12:38:42.700: INFO: Wrong image for pod: daemon-set-gjkg2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:42.700: INFO: Wrong image for pod: daemon-set-hrxjj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:42.700: INFO: Wrong image for pod: daemon-set-q6m4s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:42.700: INFO: Wrong image for pod: daemon-set-wkqs8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:42.703: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:38:43.700: INFO: Wrong image for pod: daemon-set-66rc5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:43.700: INFO: Wrong image for pod: daemon-set-clpcc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:43.700: INFO: Pod daemon-set-clpcc is not available
Sep 12 12:38:43.700: INFO: Wrong image for pod: daemon-set-gjkg2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:43.700: INFO: Wrong image for pod: daemon-set-hrxjj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:43.700: INFO: Wrong image for pod: daemon-set-q6m4s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:43.700: INFO: Wrong image for pod: daemon-set-wkqs8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:43.703: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:38:44.699: INFO: Wrong image for pod: daemon-set-66rc5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:44.699: INFO: Wrong image for pod: daemon-set-clpcc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:44.699: INFO: Pod daemon-set-clpcc is not available
Sep 12 12:38:44.699: INFO: Wrong image for pod: daemon-set-gjkg2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:44.699: INFO: Wrong image for pod: daemon-set-hrxjj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:44.699: INFO: Wrong image for pod: daemon-set-q6m4s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:44.699: INFO: Wrong image for pod: daemon-set-wkqs8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:44.702: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:38:45.700: INFO: Wrong image for pod: daemon-set-66rc5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:45.700: INFO: Wrong image for pod: daemon-set-clpcc. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:45.700: INFO: Pod daemon-set-clpcc is not available
Sep 12 12:38:45.700: INFO: Wrong image for pod: daemon-set-gjkg2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:45.700: INFO: Wrong image for pod: daemon-set-hrxjj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:45.700: INFO: Wrong image for pod: daemon-set-q6m4s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:45.700: INFO: Wrong image for pod: daemon-set-wkqs8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:45.702: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:38:46.699: INFO: Wrong image for pod: daemon-set-66rc5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:46.699: INFO: Pod daemon-set-6fv5l is not available
Sep 12 12:38:46.699: INFO: Wrong image for pod: daemon-set-gjkg2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:46.699: INFO: Wrong image for pod: daemon-set-hrxjj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:46.699: INFO: Wrong image for pod: daemon-set-q6m4s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:46.699: INFO: Wrong image for pod: daemon-set-wkqs8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:46.702: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:38:47.700: INFO: Wrong image for pod: daemon-set-66rc5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:47.700: INFO: Pod daemon-set-6fv5l is not available
Sep 12 12:38:47.700: INFO: Wrong image for pod: daemon-set-gjkg2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:47.700: INFO: Wrong image for pod: daemon-set-hrxjj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:47.700: INFO: Wrong image for pod: daemon-set-q6m4s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:47.700: INFO: Wrong image for pod: daemon-set-wkqs8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:47.704: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:38:48.700: INFO: Wrong image for pod: daemon-set-66rc5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:48.700: INFO: Pod daemon-set-6fv5l is not available
Sep 12 12:38:48.700: INFO: Wrong image for pod: daemon-set-gjkg2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:48.700: INFO: Wrong image for pod: daemon-set-hrxjj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:48.700: INFO: Wrong image for pod: daemon-set-q6m4s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:48.700: INFO: Wrong image for pod: daemon-set-wkqs8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:48.703: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:38:49.700: INFO: Wrong image for pod: daemon-set-66rc5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:49.700: INFO: Pod daemon-set-6fv5l is not available
Sep 12 12:38:49.700: INFO: Wrong image for pod: daemon-set-gjkg2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:49.700: INFO: Wrong image for pod: daemon-set-hrxjj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:49.700: INFO: Wrong image for pod: daemon-set-q6m4s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:49.700: INFO: Wrong image for pod: daemon-set-wkqs8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:49.703: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:38:50.699: INFO: Wrong image for pod: daemon-set-66rc5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:50.699: INFO: Pod daemon-set-6fv5l is not available
Sep 12 12:38:50.699: INFO: Wrong image for pod: daemon-set-gjkg2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:50.699: INFO: Wrong image for pod: daemon-set-hrxjj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:50.699: INFO: Wrong image for pod: daemon-set-q6m4s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:50.699: INFO: Wrong image for pod: daemon-set-wkqs8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:50.702: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:38:51.699: INFO: Wrong image for pod: daemon-set-66rc5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:51.700: INFO: Pod daemon-set-6fv5l is not available
Sep 12 12:38:51.700: INFO: Wrong image for pod: daemon-set-gjkg2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:51.700: INFO: Wrong image for pod: daemon-set-hrxjj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:51.700: INFO: Wrong image for pod: daemon-set-q6m4s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:51.700: INFO: Wrong image for pod: daemon-set-wkqs8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:51.702: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:38:52.701: INFO: Wrong image for pod: daemon-set-66rc5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:52.701: INFO: Pod daemon-set-6fv5l is not available
Sep 12 12:38:52.701: INFO: Wrong image for pod: daemon-set-gjkg2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:52.701: INFO: Wrong image for pod: daemon-set-hrxjj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:52.701: INFO: Wrong image for pod: daemon-set-q6m4s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:52.701: INFO: Wrong image for pod: daemon-set-wkqs8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:52.704: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:38:53.700: INFO: Wrong image for pod: daemon-set-66rc5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:53.700: INFO: Wrong image for pod: daemon-set-gjkg2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:53.700: INFO: Wrong image for pod: daemon-set-hrxjj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:53.700: INFO: Wrong image for pod: daemon-set-q6m4s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:53.700: INFO: Wrong image for pod: daemon-set-wkqs8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:53.703: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:38:54.699: INFO: Wrong image for pod: daemon-set-66rc5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:54.699: INFO: Wrong image for pod: daemon-set-gjkg2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:54.699: INFO: Wrong image for pod: daemon-set-hrxjj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:54.699: INFO: Wrong image for pod: daemon-set-q6m4s. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:54.699: INFO: Pod daemon-set-q6m4s is not available
Sep 12 12:38:54.699: INFO: Wrong image for pod: daemon-set-wkqs8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:54.702: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:38:55.699: INFO: Wrong image for pod: daemon-set-66rc5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:55.700: INFO: Pod daemon-set-ctzb7 is not available
Sep 12 12:38:55.700: INFO: Wrong image for pod: daemon-set-gjkg2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:55.700: INFO: Wrong image for pod: daemon-set-hrxjj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:55.700: INFO: Wrong image for pod: daemon-set-wkqs8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:55.702: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:38:56.699: INFO: Wrong image for pod: daemon-set-66rc5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:56.699: INFO: Pod daemon-set-ctzb7 is not available
Sep 12 12:38:56.699: INFO: Wrong image for pod: daemon-set-gjkg2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:56.699: INFO: Wrong image for pod: daemon-set-hrxjj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:56.699: INFO: Wrong image for pod: daemon-set-wkqs8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:56.702: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:38:57.708: INFO: Wrong image for pod: daemon-set-66rc5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:57.708: INFO: Pod daemon-set-ctzb7 is not available
Sep 12 12:38:57.708: INFO: Wrong image for pod: daemon-set-gjkg2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:57.708: INFO: Wrong image for pod: daemon-set-hrxjj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:57.708: INFO: Wrong image for pod: daemon-set-wkqs8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:57.711: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:38:58.699: INFO: Wrong image for pod: daemon-set-66rc5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:58.700: INFO: Pod daemon-set-ctzb7 is not available
Sep 12 12:38:58.700: INFO: Wrong image for pod: daemon-set-gjkg2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:58.700: INFO: Wrong image for pod: daemon-set-hrxjj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:58.700: INFO: Wrong image for pod: daemon-set-wkqs8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:58.703: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:38:59.700: INFO: Wrong image for pod: daemon-set-66rc5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:59.700: INFO: Pod daemon-set-ctzb7 is not available
Sep 12 12:38:59.700: INFO: Wrong image for pod: daemon-set-gjkg2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:59.700: INFO: Wrong image for pod: daemon-set-hrxjj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:59.700: INFO: Wrong image for pod: daemon-set-wkqs8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:38:59.703: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:39:00.699: INFO: Wrong image for pod: daemon-set-66rc5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:00.700: INFO: Pod daemon-set-ctzb7 is not available
Sep 12 12:39:00.700: INFO: Wrong image for pod: daemon-set-gjkg2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:00.700: INFO: Wrong image for pod: daemon-set-hrxjj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:00.700: INFO: Wrong image for pod: daemon-set-wkqs8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:00.703: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:39:01.699: INFO: Wrong image for pod: daemon-set-66rc5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:01.699: INFO: Pod daemon-set-ctzb7 is not available
Sep 12 12:39:01.699: INFO: Wrong image for pod: daemon-set-gjkg2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:01.699: INFO: Wrong image for pod: daemon-set-hrxjj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:01.699: INFO: Wrong image for pod: daemon-set-wkqs8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:01.702: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:39:02.702: INFO: Wrong image for pod: daemon-set-66rc5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:02.702: INFO: Wrong image for pod: daemon-set-gjkg2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:02.702: INFO: Wrong image for pod: daemon-set-hrxjj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:02.702: INFO: Wrong image for pod: daemon-set-wkqs8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:02.705: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:39:03.700: INFO: Wrong image for pod: daemon-set-66rc5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:03.700: INFO: Wrong image for pod: daemon-set-gjkg2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:03.700: INFO: Wrong image for pod: daemon-set-hrxjj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:03.700: INFO: Wrong image for pod: daemon-set-wkqs8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:03.700: INFO: Pod daemon-set-wkqs8 is not available
Sep 12 12:39:03.703: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:39:04.699: INFO: Wrong image for pod: daemon-set-66rc5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:04.699: INFO: Wrong image for pod: daemon-set-gjkg2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:04.699: INFO: Wrong image for pod: daemon-set-hrxjj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:04.699: INFO: Wrong image for pod: daemon-set-wkqs8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:04.699: INFO: Pod daemon-set-wkqs8 is not available
Sep 12 12:39:04.702: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:39:05.700: INFO: Wrong image for pod: daemon-set-66rc5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:05.700: INFO: Wrong image for pod: daemon-set-gjkg2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:05.700: INFO: Wrong image for pod: daemon-set-hrxjj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:05.700: INFO: Wrong image for pod: daemon-set-wkqs8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:05.700: INFO: Pod daemon-set-wkqs8 is not available
Sep 12 12:39:05.703: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:39:06.708: INFO: Wrong image for pod: daemon-set-66rc5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:06.708: INFO: Wrong image for pod: daemon-set-gjkg2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:06.708: INFO: Wrong image for pod: daemon-set-hrxjj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:06.708: INFO: Wrong image for pod: daemon-set-wkqs8. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:06.708: INFO: Pod daemon-set-wkqs8 is not available
Sep 12 12:39:06.724: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:39:07.700: INFO: Wrong image for pod: daemon-set-66rc5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:07.700: INFO: Pod daemon-set-dzwsx is not available
Sep 12 12:39:07.700: INFO: Wrong image for pod: daemon-set-gjkg2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:07.700: INFO: Wrong image for pod: daemon-set-hrxjj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:07.703: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:39:08.700: INFO: Wrong image for pod: daemon-set-66rc5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:08.700: INFO: Pod daemon-set-dzwsx is not available
Sep 12 12:39:08.700: INFO: Wrong image for pod: daemon-set-gjkg2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:08.700: INFO: Wrong image for pod: daemon-set-hrxjj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:08.703: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:39:09.700: INFO: Wrong image for pod: daemon-set-66rc5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:09.700: INFO: Pod daemon-set-dzwsx is not available
Sep 12 12:39:09.700: INFO: Wrong image for pod: daemon-set-gjkg2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:09.700: INFO: Wrong image for pod: daemon-set-hrxjj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:09.703: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:39:10.699: INFO: Wrong image for pod: daemon-set-66rc5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:10.700: INFO: Pod daemon-set-dzwsx is not available
Sep 12 12:39:10.700: INFO: Wrong image for pod: daemon-set-gjkg2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:10.700: INFO: Wrong image for pod: daemon-set-hrxjj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:10.702: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:39:11.700: INFO: Wrong image for pod: daemon-set-66rc5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:11.700: INFO: Pod daemon-set-dzwsx is not available
Sep 12 12:39:11.700: INFO: Wrong image for pod: daemon-set-gjkg2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:11.700: INFO: Wrong image for pod: daemon-set-hrxjj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:11.703: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:39:12.700: INFO: Wrong image for pod: daemon-set-66rc5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:12.700: INFO: Pod daemon-set-dzwsx is not available
Sep 12 12:39:12.700: INFO: Wrong image for pod: daemon-set-gjkg2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:12.700: INFO: Wrong image for pod: daemon-set-hrxjj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:12.703: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:39:13.744: INFO: Wrong image for pod: daemon-set-66rc5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:13.744: INFO: Wrong image for pod: daemon-set-gjkg2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:13.744: INFO: Wrong image for pod: daemon-set-hrxjj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:13.755: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:39:14.699: INFO: Wrong image for pod: daemon-set-66rc5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:14.699: INFO: Wrong image for pod: daemon-set-gjkg2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:14.700: INFO: Wrong image for pod: daemon-set-hrxjj. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:14.700: INFO: Pod daemon-set-hrxjj is not available
Sep 12 12:39:14.702: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:39:15.699: INFO: Wrong image for pod: daemon-set-66rc5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:15.699: INFO: Pod daemon-set-8gs5h is not available
Sep 12 12:39:15.699: INFO: Wrong image for pod: daemon-set-gjkg2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:15.702: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:39:16.705: INFO: Wrong image for pod: daemon-set-66rc5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:16.705: INFO: Pod daemon-set-8gs5h is not available
Sep 12 12:39:16.705: INFO: Wrong image for pod: daemon-set-gjkg2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:16.708: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:39:17.710: INFO: Wrong image for pod: daemon-set-66rc5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:17.710: INFO: Pod daemon-set-8gs5h is not available
Sep 12 12:39:17.710: INFO: Wrong image for pod: daemon-set-gjkg2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:17.713: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:39:18.710: INFO: Wrong image for pod: daemon-set-66rc5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:18.710: INFO: Pod daemon-set-8gs5h is not available
Sep 12 12:39:18.710: INFO: Wrong image for pod: daemon-set-gjkg2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:18.713: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:39:19.700: INFO: Wrong image for pod: daemon-set-66rc5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:19.700: INFO: Pod daemon-set-8gs5h is not available
Sep 12 12:39:19.700: INFO: Wrong image for pod: daemon-set-gjkg2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:19.703: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:39:20.700: INFO: Wrong image for pod: daemon-set-66rc5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:20.700: INFO: Pod daemon-set-8gs5h is not available
Sep 12 12:39:20.700: INFO: Wrong image for pod: daemon-set-gjkg2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:20.704: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:39:21.699: INFO: Wrong image for pod: daemon-set-66rc5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:21.699: INFO: Pod daemon-set-8gs5h is not available
Sep 12 12:39:21.699: INFO: Wrong image for pod: daemon-set-gjkg2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:21.702: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:39:22.700: INFO: Wrong image for pod: daemon-set-66rc5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:22.700: INFO: Pod daemon-set-8gs5h is not available
Sep 12 12:39:22.700: INFO: Wrong image for pod: daemon-set-gjkg2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:22.702: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:39:23.700: INFO: Wrong image for pod: daemon-set-66rc5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:23.700: INFO: Wrong image for pod: daemon-set-gjkg2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:23.703: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:39:24.700: INFO: Wrong image for pod: daemon-set-66rc5. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:24.700: INFO: Pod daemon-set-66rc5 is not available
Sep 12 12:39:24.700: INFO: Wrong image for pod: daemon-set-gjkg2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:24.702: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:39:25.700: INFO: Pod daemon-set-2mxd6 is not available
Sep 12 12:39:25.700: INFO: Wrong image for pod: daemon-set-gjkg2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:25.703: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:39:26.700: INFO: Pod daemon-set-2mxd6 is not available
Sep 12 12:39:26.700: INFO: Wrong image for pod: daemon-set-gjkg2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:26.703: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:39:27.700: INFO: Pod daemon-set-2mxd6 is not available
Sep 12 12:39:27.700: INFO: Wrong image for pod: daemon-set-gjkg2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:27.703: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:39:28.700: INFO: Pod daemon-set-2mxd6 is not available
Sep 12 12:39:28.700: INFO: Wrong image for pod: daemon-set-gjkg2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:28.704: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:39:29.700: INFO: Pod daemon-set-2mxd6 is not available
Sep 12 12:39:29.700: INFO: Wrong image for pod: daemon-set-gjkg2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:29.703: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:39:30.699: INFO: Pod daemon-set-2mxd6 is not available
Sep 12 12:39:30.699: INFO: Wrong image for pod: daemon-set-gjkg2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:30.703: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:39:31.700: INFO: Pod daemon-set-2mxd6 is not available
Sep 12 12:39:31.700: INFO: Wrong image for pod: daemon-set-gjkg2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:31.703: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:39:32.700: INFO: Pod daemon-set-2mxd6 is not available
Sep 12 12:39:32.700: INFO: Wrong image for pod: daemon-set-gjkg2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:32.703: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:39:33.700: INFO: Wrong image for pod: daemon-set-gjkg2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:33.702: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:39:34.700: INFO: Wrong image for pod: daemon-set-gjkg2. Expected: gcr.io/kubernetes-e2e-test-images/redis:1.0, got: docker.io/library/nginx:1.14-alpine.
Sep 12 12:39:34.700: INFO: Pod daemon-set-gjkg2 is not available
Sep 12 12:39:34.703: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:39:35.699: INFO: Pod daemon-set-25cnw is not available
Sep 12 12:39:35.702: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Sep 12 12:39:35.705: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:39:35.708: INFO: Number of nodes with available pods: 5
Sep 12 12:39:35.708: INFO: Node caasp-worker-thehejik-5 is running more than one daemon pod
Sep 12 12:39:36.711: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:39:36.714: INFO: Number of nodes with available pods: 5
Sep 12 12:39:36.714: INFO: Node caasp-worker-thehejik-5 is running more than one daemon pod
Sep 12 12:39:37.712: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:39:37.714: INFO: Number of nodes with available pods: 5
Sep 12 12:39:37.714: INFO: Node caasp-worker-thehejik-5 is running more than one daemon pod
Sep 12 12:39:38.711: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:39:38.714: INFO: Number of nodes with available pods: 5
Sep 12 12:39:38.714: INFO: Node caasp-worker-thehejik-5 is running more than one daemon pod
Sep 12 12:39:39.712: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:39:39.714: INFO: Number of nodes with available pods: 5
Sep 12 12:39:39.714: INFO: Node caasp-worker-thehejik-5 is running more than one daemon pod
Sep 12 12:39:40.711: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:39:40.713: INFO: Number of nodes with available pods: 5
Sep 12 12:39:40.713: INFO: Node caasp-worker-thehejik-5 is running more than one daemon pod
Sep 12 12:39:41.711: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:39:41.713: INFO: Number of nodes with available pods: 5
Sep 12 12:39:41.713: INFO: Node caasp-worker-thehejik-5 is running more than one daemon pod
Sep 12 12:39:42.712: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:39:42.724: INFO: Number of nodes with available pods: 5
Sep 12 12:39:42.724: INFO: Node caasp-worker-thehejik-5 is running more than one daemon pod
Sep 12 12:39:43.712: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 12:39:43.714: INFO: Number of nodes with available pods: 6
Sep 12 12:39:43.714: INFO: Number of running nodes: 6, number of available pods: 6
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7765, will wait for the garbage collector to delete the pods
Sep 12 12:39:43.780: INFO: Deleting DaemonSet.extensions daemon-set took: 4.79672ms
Sep 12 12:39:44.180: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.152022ms
Sep 12 12:39:56.782: INFO: Number of nodes with available pods: 0
Sep 12 12:39:56.782: INFO: Number of running nodes: 0, number of available pods: 0
Sep 12 12:39:56.783: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7765/daemonsets","resourceVersion":"11685"},"items":null}

Sep 12 12:39:56.785: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7765/pods","resourceVersion":"11685"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:39:56.808: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7765" for this suite.
Sep 12 12:40:04.832: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:40:04.918: INFO: namespace daemonsets-7765 deletion completed in 8.10830269s

â€¢ [SLOW TEST:94.470 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:40:04.919: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8385
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap configmap-8385/configmap-test-5f1c6a77-935d-4ba4-a925-29ebc421a81f
STEP: Creating a pod to test consume configMaps
Sep 12 12:40:05.084: INFO: Waiting up to 5m0s for pod "pod-configmaps-132b7190-d15f-496e-8f25-d35df6f9f47b" in namespace "configmap-8385" to be "success or failure"
Sep 12 12:40:05.106: INFO: Pod "pod-configmaps-132b7190-d15f-496e-8f25-d35df6f9f47b": Phase="Pending", Reason="", readiness=false. Elapsed: 21.562271ms
Sep 12 12:40:07.108: INFO: Pod "pod-configmaps-132b7190-d15f-496e-8f25-d35df6f9f47b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023877595s
Sep 12 12:40:09.110: INFO: Pod "pod-configmaps-132b7190-d15f-496e-8f25-d35df6f9f47b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.026444384s
STEP: Saw pod success
Sep 12 12:40:09.111: INFO: Pod "pod-configmaps-132b7190-d15f-496e-8f25-d35df6f9f47b" satisfied condition "success or failure"
Sep 12 12:40:09.112: INFO: Trying to get logs from node caasp-worker-thehejik-3 pod pod-configmaps-132b7190-d15f-496e-8f25-d35df6f9f47b container env-test: <nil>
STEP: delete the pod
Sep 12 12:40:09.142: INFO: Waiting for pod pod-configmaps-132b7190-d15f-496e-8f25-d35df6f9f47b to disappear
Sep 12 12:40:09.159: INFO: Pod pod-configmaps-132b7190-d15f-496e-8f25-d35df6f9f47b no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:40:09.159: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8385" for this suite.
Sep 12 12:40:15.177: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:40:15.243: INFO: namespace configmap-8385 deletion completed in 6.080021728s

â€¢ [SLOW TEST:10.324 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:40:15.244: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-10
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secret-namespace-1733
STEP: Creating secret with name secret-test-073b909a-93ae-4bb3-b5b1-6758aed4e412
STEP: Creating a pod to test consume secrets
Sep 12 12:40:15.568: INFO: Waiting up to 5m0s for pod "pod-secrets-fcb1543e-6cf3-436b-bbc5-98a3af9d1261" in namespace "secrets-10" to be "success or failure"
Sep 12 12:40:15.577: INFO: Pod "pod-secrets-fcb1543e-6cf3-436b-bbc5-98a3af9d1261": Phase="Pending", Reason="", readiness=false. Elapsed: 8.971441ms
Sep 12 12:40:17.580: INFO: Pod "pod-secrets-fcb1543e-6cf3-436b-bbc5-98a3af9d1261": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011797378s
Sep 12 12:40:19.583: INFO: Pod "pod-secrets-fcb1543e-6cf3-436b-bbc5-98a3af9d1261": Phase="Pending", Reason="", readiness=false. Elapsed: 4.014299288s
Sep 12 12:40:21.585: INFO: Pod "pod-secrets-fcb1543e-6cf3-436b-bbc5-98a3af9d1261": Phase="Pending", Reason="", readiness=false. Elapsed: 6.016411996s
Sep 12 12:40:23.588: INFO: Pod "pod-secrets-fcb1543e-6cf3-436b-bbc5-98a3af9d1261": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.019408552s
STEP: Saw pod success
Sep 12 12:40:23.588: INFO: Pod "pod-secrets-fcb1543e-6cf3-436b-bbc5-98a3af9d1261" satisfied condition "success or failure"
Sep 12 12:40:23.590: INFO: Trying to get logs from node caasp-worker-thehejik-2 pod pod-secrets-fcb1543e-6cf3-436b-bbc5-98a3af9d1261 container secret-volume-test: <nil>
STEP: delete the pod
Sep 12 12:40:23.612: INFO: Waiting for pod pod-secrets-fcb1543e-6cf3-436b-bbc5-98a3af9d1261 to disappear
Sep 12 12:40:23.642: INFO: Pod pod-secrets-fcb1543e-6cf3-436b-bbc5-98a3af9d1261 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:40:23.642: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-10" for this suite.
Sep 12 12:40:29.659: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:40:29.724: INFO: namespace secrets-10 deletion completed in 6.079382328s
STEP: Destroying namespace "secret-namespace-1733" for this suite.
Sep 12 12:40:35.740: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:40:35.806: INFO: namespace secret-namespace-1733 deletion completed in 6.081674106s

â€¢ [SLOW TEST:20.562 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:40:35.808: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-2076
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 12 12:40:35.960: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:40:37.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-2076" for this suite.
Sep 12 12:40:43.089: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:40:43.179: INFO: namespace custom-resource-definition-2076 deletion completed in 6.112697109s

â€¢ [SLOW TEST:7.371 seconds]
[sig-api-machinery] CustomResourceDefinition resources
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:35
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:40:43.180: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-5693
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:40:47.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-5693" for this suite.
Sep 12 12:41:25.382: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:41:25.448: INFO: namespace kubelet-test-5693 deletion completed in 38.08059783s

â€¢ [SLOW TEST:42.268 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a read only busybox container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:41:25.449: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-7166
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:41:25.654: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7166" for this suite.
Sep 12 12:41:31.687: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:41:31.759: INFO: namespace kubelet-test-7166 deletion completed in 6.091195003s

â€¢ [SLOW TEST:6.310 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:41:31.760: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-kubelet-etc-hosts-6241
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Sep 12 12:41:37.956: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6241 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 12 12:41:37.956: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
Sep 12 12:41:38.019: INFO: Exec stderr: ""
Sep 12 12:41:38.019: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6241 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 12 12:41:38.019: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
Sep 12 12:41:38.085: INFO: Exec stderr: ""
Sep 12 12:41:38.085: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6241 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 12 12:41:38.085: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
Sep 12 12:41:38.142: INFO: Exec stderr: ""
Sep 12 12:41:38.142: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6241 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 12 12:41:38.142: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
Sep 12 12:41:38.200: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Sep 12 12:41:38.200: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6241 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 12 12:41:38.200: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
Sep 12 12:41:38.258: INFO: Exec stderr: ""
Sep 12 12:41:38.258: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6241 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 12 12:41:38.258: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
Sep 12 12:41:38.314: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Sep 12 12:41:38.314: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6241 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 12 12:41:38.314: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
Sep 12 12:41:38.405: INFO: Exec stderr: ""
Sep 12 12:41:38.405: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6241 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 12 12:41:38.405: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
Sep 12 12:41:38.495: INFO: Exec stderr: ""
Sep 12 12:41:38.495: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6241 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 12 12:41:38.495: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
Sep 12 12:41:38.589: INFO: Exec stderr: ""
Sep 12 12:41:38.589: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6241 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 12 12:41:38.589: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
Sep 12 12:41:38.681: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:41:38.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-6241" for this suite.
Sep 12 12:42:16.700: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:42:16.765: INFO: namespace e2e-kubelet-etc-hosts-6241 deletion completed in 38.080643093s

â€¢ [SLOW TEST:45.005 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:42:16.765: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5519
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on tmpfs
Sep 12 12:42:16.921: INFO: Waiting up to 5m0s for pod "pod-98410c93-114e-41a9-b332-1b2917d6a1a6" in namespace "emptydir-5519" to be "success or failure"
Sep 12 12:42:16.931: INFO: Pod "pod-98410c93-114e-41a9-b332-1b2917d6a1a6": Phase="Pending", Reason="", readiness=false. Elapsed: 9.523445ms
Sep 12 12:42:18.933: INFO: Pod "pod-98410c93-114e-41a9-b332-1b2917d6a1a6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012020136s
Sep 12 12:42:20.936: INFO: Pod "pod-98410c93-114e-41a9-b332-1b2917d6a1a6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01468789s
Sep 12 12:42:22.938: INFO: Pod "pod-98410c93-114e-41a9-b332-1b2917d6a1a6": Phase="Pending", Reason="", readiness=false. Elapsed: 6.017267881s
Sep 12 12:42:24.941: INFO: Pod "pod-98410c93-114e-41a9-b332-1b2917d6a1a6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.019334189s
STEP: Saw pod success
Sep 12 12:42:24.941: INFO: Pod "pod-98410c93-114e-41a9-b332-1b2917d6a1a6" satisfied condition "success or failure"
Sep 12 12:42:24.942: INFO: Trying to get logs from node caasp-worker-thehejik-0 pod pod-98410c93-114e-41a9-b332-1b2917d6a1a6 container test-container: <nil>
STEP: delete the pod
Sep 12 12:42:24.961: INFO: Waiting for pod pod-98410c93-114e-41a9-b332-1b2917d6a1a6 to disappear
Sep 12 12:42:24.969: INFO: Pod pod-98410c93-114e-41a9-b332-1b2917d6a1a6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:42:24.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5519" for this suite.
Sep 12 12:42:30.985: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:42:31.052: INFO: namespace emptydir-5519 deletion completed in 6.079533482s

â€¢ [SLOW TEST:14.286 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:42:31.052: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-4959
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override arguments
Sep 12 12:42:31.222: INFO: Waiting up to 5m0s for pod "client-containers-e9f90edd-694b-4c87-b1c9-39a2a5e5e0a1" in namespace "containers-4959" to be "success or failure"
Sep 12 12:42:31.231: INFO: Pod "client-containers-e9f90edd-694b-4c87-b1c9-39a2a5e5e0a1": Phase="Pending", Reason="", readiness=false. Elapsed: 8.913925ms
Sep 12 12:42:33.233: INFO: Pod "client-containers-e9f90edd-694b-4c87-b1c9-39a2a5e5e0a1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011056327s
Sep 12 12:42:35.235: INFO: Pod "client-containers-e9f90edd-694b-4c87-b1c9-39a2a5e5e0a1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01356271s
STEP: Saw pod success
Sep 12 12:42:35.236: INFO: Pod "client-containers-e9f90edd-694b-4c87-b1c9-39a2a5e5e0a1" satisfied condition "success or failure"
Sep 12 12:42:35.237: INFO: Trying to get logs from node caasp-worker-thehejik-2 pod client-containers-e9f90edd-694b-4c87-b1c9-39a2a5e5e0a1 container test-container: <nil>
STEP: delete the pod
Sep 12 12:42:35.257: INFO: Waiting for pod client-containers-e9f90edd-694b-4c87-b1c9-39a2a5e5e0a1 to disappear
Sep 12 12:42:35.270: INFO: Pod client-containers-e9f90edd-694b-4c87-b1c9-39a2a5e5e0a1 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:42:35.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-4959" for this suite.
Sep 12 12:42:41.286: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:42:41.351: INFO: namespace containers-4959 deletion completed in 6.078559293s

â€¢ [SLOW TEST:10.299 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:42:41.352: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5225
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name cm-test-opt-del-ee345038-4894-45ce-85d8-397cc7ba9a22
STEP: Creating configMap with name cm-test-opt-upd-07b475f7-4421-4861-8ea3-b3b7662a6852
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-ee345038-4894-45ce-85d8-397cc7ba9a22
STEP: Updating configmap cm-test-opt-upd-07b475f7-4421-4861-8ea3-b3b7662a6852
STEP: Creating configMap with name cm-test-opt-create-60455ec0-deb0-4688-ac7d-0f8dc6ee6d5c
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:42:49.627: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5225" for this suite.
Sep 12 12:43:11.643: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:43:11.727: INFO: namespace projected-5225 deletion completed in 22.097258661s

â€¢ [SLOW TEST:30.375 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:43:11.729: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-7474
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 12 12:43:11.885: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:43:15.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7474" for this suite.
Sep 12 12:43:55.933: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:43:56.015: INFO: namespace pods-7474 deletion completed in 40.096226932s

â€¢ [SLOW TEST:44.286 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:43:56.015: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-1571
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:44:01.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1571" for this suite.
Sep 12 12:44:07.870: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:44:07.936: INFO: namespace watch-1571 deletion completed in 6.166971363s

â€¢ [SLOW TEST:11.922 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:44:07.937: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9057
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 12 12:44:08.089: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 version'
Sep 12 12:44:08.173: INFO: stderr: ""
Sep 12 12:44:08.173: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.2\", GitCommit:\"f6278300bebbb750328ac16ee6dd3aa7d3549568\", GitTreeState:\"clean\", BuildDate:\"2019-08-05T09:23:26Z\", GoVersion:\"go1.12.5\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"15\", GitVersion:\"v1.15.2\", GitCommit:\"f6278300bebbb750328ac16ee6dd3aa7d3549568\", GitTreeState:\"clean\", BuildDate:\"2019-08-28T12:00:00Z\", GoVersion:\"go1.12.9\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:44:08.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9057" for this suite.
Sep 12 12:44:14.192: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:44:14.260: INFO: namespace kubectl-9057 deletion completed in 6.082868971s

â€¢ [SLOW TEST:6.323 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl version
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:44:14.260: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-3376
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-3376
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep 12 12:44:14.558: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Sep 12 12:44:40.721: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.5.126:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3376 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 12 12:44:40.721: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
Sep 12 12:44:40.837: INFO: Found all expected endpoints: [netserver-0]
Sep 12 12:44:40.839: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.4.253:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3376 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 12 12:44:40.839: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
Sep 12 12:44:40.902: INFO: Found all expected endpoints: [netserver-1]
Sep 12 12:44:40.904: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.1.140:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3376 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 12 12:44:40.904: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
Sep 12 12:44:40.967: INFO: Found all expected endpoints: [netserver-2]
Sep 12 12:44:40.968: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.2.239:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3376 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 12 12:44:40.968: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
Sep 12 12:44:41.032: INFO: Found all expected endpoints: [netserver-3]
Sep 12 12:44:41.034: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.6.80:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3376 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 12 12:44:41.034: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
Sep 12 12:44:41.100: INFO: Found all expected endpoints: [netserver-4]
Sep 12 12:44:41.102: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.3.17:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3376 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 12 12:44:41.102: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
Sep 12 12:44:41.167: INFO: Found all expected endpoints: [netserver-5]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:44:41.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3376" for this suite.
Sep 12 12:45:05.185: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:45:05.255: INFO: namespace pod-network-test-3376 deletion completed in 24.085133877s

â€¢ [SLOW TEST:50.995 seconds]
[sig-network] Networking
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:45:05.256: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-8716
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Sep 12 12:45:05.413: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep 12 12:45:05.419: INFO: Waiting for terminating namespaces to be deleted...
Sep 12 12:45:05.420: INFO: 
Logging pods the kubelet thinks is on node caasp-worker-thehejik-0 before test
Sep 12 12:45:05.424: INFO: cilium-vk48l from kube-system started at 2019-09-12 11:43:57 +0000 UTC (1 container statuses recorded)
Sep 12 12:45:05.424: INFO: 	Container cilium-agent ready: true, restart count 0
Sep 12 12:45:05.424: INFO: kured-9wsvq from kube-system started at 2019-09-12 11:46:48 +0000 UTC (1 container statuses recorded)
Sep 12 12:45:05.424: INFO: 	Container kured ready: true, restart count 0
Sep 12 12:45:05.424: INFO: kube-proxy-qdt88 from kube-system started at 2019-09-12 11:43:47 +0000 UTC (1 container statuses recorded)
Sep 12 12:45:05.424: INFO: 	Container kube-proxy ready: true, restart count 0
Sep 12 12:45:05.424: INFO: 
Logging pods the kubelet thinks is on node caasp-worker-thehejik-1 before test
Sep 12 12:45:05.428: INFO: kube-proxy-k72dc from kube-system started at 2019-09-12 11:43:45 +0000 UTC (1 container statuses recorded)
Sep 12 12:45:05.428: INFO: 	Container kube-proxy ready: true, restart count 0
Sep 12 12:45:05.428: INFO: cilium-xtjhr from kube-system started at 2019-09-12 11:43:56 +0000 UTC (1 container statuses recorded)
Sep 12 12:45:05.428: INFO: 	Container cilium-agent ready: true, restart count 0
Sep 12 12:45:05.428: INFO: kured-2pwbw from kube-system started at 2019-09-12 11:46:46 +0000 UTC (1 container statuses recorded)
Sep 12 12:45:05.428: INFO: 	Container kured ready: true, restart count 0
Sep 12 12:45:05.428: INFO: 
Logging pods the kubelet thinks is on node caasp-worker-thehejik-2 before test
Sep 12 12:45:05.433: INFO: cilium-xpjlr from kube-system started at 2019-09-12 11:43:53 +0000 UTC (1 container statuses recorded)
Sep 12 12:45:05.433: INFO: 	Container cilium-agent ready: true, restart count 0
Sep 12 12:45:05.433: INFO: kured-2pbx6 from kube-system started at 2019-09-12 11:46:36 +0000 UTC (1 container statuses recorded)
Sep 12 12:45:05.433: INFO: 	Container kured ready: true, restart count 0
Sep 12 12:45:05.433: INFO: sonobuoy from heptio-sonobuoy started at 2019-09-12 12:14:35 +0000 UTC (1 container statuses recorded)
Sep 12 12:45:05.433: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Sep 12 12:45:05.433: INFO: kube-proxy-tbns9 from kube-system started at 2019-09-12 11:43:45 +0000 UTC (1 container statuses recorded)
Sep 12 12:45:05.433: INFO: 	Container kube-proxy ready: true, restart count 0
Sep 12 12:45:05.433: INFO: 
Logging pods the kubelet thinks is on node caasp-worker-thehejik-3 before test
Sep 12 12:45:05.436: INFO: kube-proxy-czhcd from kube-system started at 2019-09-12 11:43:46 +0000 UTC (1 container statuses recorded)
Sep 12 12:45:05.436: INFO: 	Container kube-proxy ready: true, restart count 0
Sep 12 12:45:05.436: INFO: cilium-pn77w from kube-system started at 2019-09-12 11:43:56 +0000 UTC (1 container statuses recorded)
Sep 12 12:45:05.436: INFO: 	Container cilium-agent ready: true, restart count 0
Sep 12 12:45:05.436: INFO: kured-ltm4s from kube-system started at 2019-09-12 11:46:27 +0000 UTC (1 container statuses recorded)
Sep 12 12:45:05.436: INFO: 	Container kured ready: true, restart count 0
Sep 12 12:45:05.436: INFO: 
Logging pods the kubelet thinks is on node caasp-worker-thehejik-4 before test
Sep 12 12:45:05.441: INFO: kube-proxy-8gpcv from kube-system started at 2019-09-12 11:43:45 +0000 UTC (1 container statuses recorded)
Sep 12 12:45:05.441: INFO: 	Container kube-proxy ready: true, restart count 0
Sep 12 12:45:05.441: INFO: cilium-l8mbk from kube-system started at 2019-09-12 11:43:53 +0000 UTC (1 container statuses recorded)
Sep 12 12:45:05.441: INFO: 	Container cilium-agent ready: true, restart count 0
Sep 12 12:45:05.441: INFO: kured-7t64n from kube-system started at 2019-09-12 11:46:35 +0000 UTC (1 container statuses recorded)
Sep 12 12:45:05.441: INFO: 	Container kured ready: true, restart count 0
Sep 12 12:45:05.441: INFO: sonobuoy-e2e-job-8e9197d567844860 from heptio-sonobuoy started at 2019-09-12 12:14:48 +0000 UTC (2 container statuses recorded)
Sep 12 12:45:05.441: INFO: 	Container e2e ready: true, restart count 0
Sep 12 12:45:05.441: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 12 12:45:05.441: INFO: 
Logging pods the kubelet thinks is on node caasp-worker-thehejik-5 before test
Sep 12 12:45:05.447: INFO: kube-proxy-22pqk from kube-system started at 2019-09-12 11:43:46 +0000 UTC (1 container statuses recorded)
Sep 12 12:45:05.447: INFO: 	Container kube-proxy ready: true, restart count 0
Sep 12 12:45:05.447: INFO: cilium-r4htl from kube-system started at 2019-09-12 11:43:56 +0000 UTC (1 container statuses recorded)
Sep 12 12:45:05.447: INFO: 	Container cilium-agent ready: true, restart count 0
Sep 12 12:45:05.447: INFO: oidc-gangway-7b7fbbdbdf-z6hhw from kube-system started at 2019-09-12 11:46:18 +0000 UTC (1 container statuses recorded)
Sep 12 12:45:05.447: INFO: 	Container oidc-gangway ready: true, restart count 0
Sep 12 12:45:05.447: INFO: kured-xqr4h from kube-system started at 2019-09-12 11:46:18 +0000 UTC (1 container statuses recorded)
Sep 12 12:45:05.447: INFO: 	Container kured ready: true, restart count 0
Sep 12 12:45:05.447: INFO: cilium-operator-7d6ddddbf5-qzx8w from kube-system started at 2019-09-12 11:46:19 +0000 UTC (1 container statuses recorded)
Sep 12 12:45:05.447: INFO: 	Container cilium-operator ready: true, restart count 0
Sep 12 12:45:05.447: INFO: oidc-dex-55fc689dc-6xcgj from kube-system started at 2019-09-12 11:46:19 +0000 UTC (1 container statuses recorded)
Sep 12 12:45:05.447: INFO: 	Container oidc-dex ready: true, restart count 1
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15c3b18aeae24f7f], Reason = [FailedScheduling], Message = [0/7 nodes are available: 7 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:45:06.462: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-8716" for this suite.
Sep 12 12:45:12.480: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:45:12.554: INFO: namespace sched-pred-8716 deletion completed in 6.089225333s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

â€¢ [SLOW TEST:7.298 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:45:12.555: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8513
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a replication controller
Sep 12 12:45:12.715: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 create -f - --namespace=kubectl-8513'
Sep 12 12:45:13.963: INFO: stderr: ""
Sep 12 12:45:13.963: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep 12 12:45:13.963: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8513'
Sep 12 12:45:14.073: INFO: stderr: ""
Sep 12 12:45:14.073: INFO: stdout: "update-demo-nautilus-p82km update-demo-nautilus-vt9xv "
Sep 12 12:45:14.073: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get pods update-demo-nautilus-p82km -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8513'
Sep 12 12:45:14.163: INFO: stderr: ""
Sep 12 12:45:14.163: INFO: stdout: ""
Sep 12 12:45:14.163: INFO: update-demo-nautilus-p82km is created but not running
Sep 12 12:45:19.163: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8513'
Sep 12 12:45:19.252: INFO: stderr: ""
Sep 12 12:45:19.252: INFO: stdout: "update-demo-nautilus-p82km update-demo-nautilus-vt9xv "
Sep 12 12:45:19.252: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get pods update-demo-nautilus-p82km -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8513'
Sep 12 12:45:19.335: INFO: stderr: ""
Sep 12 12:45:19.335: INFO: stdout: ""
Sep 12 12:45:19.335: INFO: update-demo-nautilus-p82km is created but not running
Sep 12 12:45:24.335: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8513'
Sep 12 12:45:24.419: INFO: stderr: ""
Sep 12 12:45:24.420: INFO: stdout: "update-demo-nautilus-p82km update-demo-nautilus-vt9xv "
Sep 12 12:45:24.420: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get pods update-demo-nautilus-p82km -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8513'
Sep 12 12:45:24.505: INFO: stderr: ""
Sep 12 12:45:24.505: INFO: stdout: "true"
Sep 12 12:45:24.505: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get pods update-demo-nautilus-p82km -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8513'
Sep 12 12:45:24.583: INFO: stderr: ""
Sep 12 12:45:24.583: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 12 12:45:24.583: INFO: validating pod update-demo-nautilus-p82km
Sep 12 12:45:24.586: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 12 12:45:24.586: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 12 12:45:24.586: INFO: update-demo-nautilus-p82km is verified up and running
Sep 12 12:45:24.586: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get pods update-demo-nautilus-vt9xv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8513'
Sep 12 12:45:24.672: INFO: stderr: ""
Sep 12 12:45:24.672: INFO: stdout: ""
Sep 12 12:45:24.672: INFO: update-demo-nautilus-vt9xv is created but not running
Sep 12 12:45:29.672: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8513'
Sep 12 12:45:29.753: INFO: stderr: ""
Sep 12 12:45:29.753: INFO: stdout: "update-demo-nautilus-p82km update-demo-nautilus-vt9xv "
Sep 12 12:45:29.753: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get pods update-demo-nautilus-p82km -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8513'
Sep 12 12:45:29.838: INFO: stderr: ""
Sep 12 12:45:29.838: INFO: stdout: "true"
Sep 12 12:45:29.838: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get pods update-demo-nautilus-p82km -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8513'
Sep 12 12:45:29.921: INFO: stderr: ""
Sep 12 12:45:29.921: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 12 12:45:29.921: INFO: validating pod update-demo-nautilus-p82km
Sep 12 12:45:29.923: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 12 12:45:29.923: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 12 12:45:29.923: INFO: update-demo-nautilus-p82km is verified up and running
Sep 12 12:45:29.923: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get pods update-demo-nautilus-vt9xv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8513'
Sep 12 12:45:30.010: INFO: stderr: ""
Sep 12 12:45:30.010: INFO: stdout: ""
Sep 12 12:45:30.010: INFO: update-demo-nautilus-vt9xv is created but not running
Sep 12 12:45:35.010: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8513'
Sep 12 12:45:35.089: INFO: stderr: ""
Sep 12 12:45:35.089: INFO: stdout: "update-demo-nautilus-p82km update-demo-nautilus-vt9xv "
Sep 12 12:45:35.089: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get pods update-demo-nautilus-p82km -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8513'
Sep 12 12:45:35.167: INFO: stderr: ""
Sep 12 12:45:35.167: INFO: stdout: "true"
Sep 12 12:45:35.167: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get pods update-demo-nautilus-p82km -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8513'
Sep 12 12:45:35.250: INFO: stderr: ""
Sep 12 12:45:35.250: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 12 12:45:35.250: INFO: validating pod update-demo-nautilus-p82km
Sep 12 12:45:35.253: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 12 12:45:35.253: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 12 12:45:35.253: INFO: update-demo-nautilus-p82km is verified up and running
Sep 12 12:45:35.253: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get pods update-demo-nautilus-vt9xv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8513'
Sep 12 12:45:35.340: INFO: stderr: ""
Sep 12 12:45:35.340: INFO: stdout: ""
Sep 12 12:45:35.340: INFO: update-demo-nautilus-vt9xv is created but not running
Sep 12 12:45:40.341: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8513'
Sep 12 12:45:40.428: INFO: stderr: ""
Sep 12 12:45:40.428: INFO: stdout: "update-demo-nautilus-p82km update-demo-nautilus-vt9xv "
Sep 12 12:45:40.428: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get pods update-demo-nautilus-p82km -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8513'
Sep 12 12:45:40.508: INFO: stderr: ""
Sep 12 12:45:40.508: INFO: stdout: "true"
Sep 12 12:45:40.509: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get pods update-demo-nautilus-p82km -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8513'
Sep 12 12:45:40.589: INFO: stderr: ""
Sep 12 12:45:40.589: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 12 12:45:40.589: INFO: validating pod update-demo-nautilus-p82km
Sep 12 12:45:40.591: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 12 12:45:40.591: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 12 12:45:40.591: INFO: update-demo-nautilus-p82km is verified up and running
Sep 12 12:45:40.592: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get pods update-demo-nautilus-vt9xv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8513'
Sep 12 12:45:40.673: INFO: stderr: ""
Sep 12 12:45:40.673: INFO: stdout: "true"
Sep 12 12:45:40.673: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get pods update-demo-nautilus-vt9xv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8513'
Sep 12 12:45:40.752: INFO: stderr: ""
Sep 12 12:45:40.752: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 12 12:45:40.752: INFO: validating pod update-demo-nautilus-vt9xv
Sep 12 12:45:40.755: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 12 12:45:40.755: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 12 12:45:40.755: INFO: update-demo-nautilus-vt9xv is verified up and running
STEP: scaling down the replication controller
Sep 12 12:45:40.757: INFO: scanned /root for discovery docs: <nil>
Sep 12 12:45:40.757: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-8513'
Sep 12 12:45:41.863: INFO: stderr: ""
Sep 12 12:45:41.863: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep 12 12:45:41.863: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8513'
Sep 12 12:45:41.954: INFO: stderr: ""
Sep 12 12:45:41.954: INFO: stdout: "update-demo-nautilus-p82km update-demo-nautilus-vt9xv "
STEP: Replicas for name=update-demo: expected=1 actual=2
Sep 12 12:45:46.955: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8513'
Sep 12 12:45:47.036: INFO: stderr: ""
Sep 12 12:45:47.036: INFO: stdout: "update-demo-nautilus-p82km "
Sep 12 12:45:47.036: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get pods update-demo-nautilus-p82km -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8513'
Sep 12 12:45:47.122: INFO: stderr: ""
Sep 12 12:45:47.122: INFO: stdout: "true"
Sep 12 12:45:47.122: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get pods update-demo-nautilus-p82km -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8513'
Sep 12 12:45:47.206: INFO: stderr: ""
Sep 12 12:45:47.206: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 12 12:45:47.206: INFO: validating pod update-demo-nautilus-p82km
Sep 12 12:45:47.208: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 12 12:45:47.208: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 12 12:45:47.208: INFO: update-demo-nautilus-p82km is verified up and running
STEP: scaling up the replication controller
Sep 12 12:45:47.210: INFO: scanned /root for discovery docs: <nil>
Sep 12 12:45:47.210: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-8513'
Sep 12 12:45:48.332: INFO: stderr: ""
Sep 12 12:45:48.332: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep 12 12:45:48.332: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8513'
Sep 12 12:45:48.419: INFO: stderr: ""
Sep 12 12:45:48.419: INFO: stdout: "update-demo-nautilus-9vkwf update-demo-nautilus-p82km "
Sep 12 12:45:48.419: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get pods update-demo-nautilus-9vkwf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8513'
Sep 12 12:45:48.506: INFO: stderr: ""
Sep 12 12:45:48.507: INFO: stdout: ""
Sep 12 12:45:48.507: INFO: update-demo-nautilus-9vkwf is created but not running
Sep 12 12:45:53.507: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8513'
Sep 12 12:45:53.589: INFO: stderr: ""
Sep 12 12:45:53.589: INFO: stdout: "update-demo-nautilus-9vkwf update-demo-nautilus-p82km "
Sep 12 12:45:53.589: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get pods update-demo-nautilus-9vkwf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8513'
Sep 12 12:45:53.675: INFO: stderr: ""
Sep 12 12:45:53.675: INFO: stdout: ""
Sep 12 12:45:53.675: INFO: update-demo-nautilus-9vkwf is created but not running
Sep 12 12:45:58.676: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8513'
Sep 12 12:45:58.763: INFO: stderr: ""
Sep 12 12:45:58.763: INFO: stdout: "update-demo-nautilus-9vkwf update-demo-nautilus-p82km "
Sep 12 12:45:58.763: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get pods update-demo-nautilus-9vkwf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8513'
Sep 12 12:45:58.849: INFO: stderr: ""
Sep 12 12:45:58.849: INFO: stdout: "true"
Sep 12 12:45:58.849: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get pods update-demo-nautilus-9vkwf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8513'
Sep 12 12:45:58.932: INFO: stderr: ""
Sep 12 12:45:58.932: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 12 12:45:58.932: INFO: validating pod update-demo-nautilus-9vkwf
Sep 12 12:45:58.935: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 12 12:45:58.935: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 12 12:45:58.935: INFO: update-demo-nautilus-9vkwf is verified up and running
Sep 12 12:45:58.935: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get pods update-demo-nautilus-p82km -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8513'
Sep 12 12:45:59.030: INFO: stderr: ""
Sep 12 12:45:59.030: INFO: stdout: "true"
Sep 12 12:45:59.030: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get pods update-demo-nautilus-p82km -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8513'
Sep 12 12:45:59.114: INFO: stderr: ""
Sep 12 12:45:59.114: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 12 12:45:59.114: INFO: validating pod update-demo-nautilus-p82km
Sep 12 12:45:59.116: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 12 12:45:59.116: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 12 12:45:59.116: INFO: update-demo-nautilus-p82km is verified up and running
STEP: using delete to clean up resources
Sep 12 12:45:59.116: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 delete --grace-period=0 --force -f - --namespace=kubectl-8513'
Sep 12 12:45:59.211: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 12 12:45:59.211: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Sep 12 12:45:59.211: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-8513'
Sep 12 12:45:59.297: INFO: stderr: "No resources found.\n"
Sep 12 12:45:59.297: INFO: stdout: ""
Sep 12 12:45:59.297: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get pods -l name=update-demo --namespace=kubectl-8513 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep 12 12:45:59.384: INFO: stderr: ""
Sep 12 12:45:59.384: INFO: stdout: "update-demo-nautilus-9vkwf\nupdate-demo-nautilus-p82km\n"
Sep 12 12:45:59.884: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-8513'
Sep 12 12:45:59.974: INFO: stderr: "No resources found.\n"
Sep 12 12:45:59.974: INFO: stdout: ""
Sep 12 12:45:59.974: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get pods -l name=update-demo --namespace=kubectl-8513 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep 12 12:46:00.058: INFO: stderr: ""
Sep 12 12:46:00.059: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:46:00.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8513" for this suite.
Sep 12 12:46:22.075: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:46:22.141: INFO: namespace kubectl-8513 deletion completed in 22.079124454s

â€¢ [SLOW TEST:69.585 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:46:22.141: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-576
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test use defaults
Sep 12 12:46:22.303: INFO: Waiting up to 5m0s for pod "client-containers-20289d82-c1b0-4dde-9ae0-1114a711d6ce" in namespace "containers-576" to be "success or failure"
Sep 12 12:46:22.312: INFO: Pod "client-containers-20289d82-c1b0-4dde-9ae0-1114a711d6ce": Phase="Pending", Reason="", readiness=false. Elapsed: 8.922422ms
Sep 12 12:46:24.314: INFO: Pod "client-containers-20289d82-c1b0-4dde-9ae0-1114a711d6ce": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011201221s
Sep 12 12:46:26.316: INFO: Pod "client-containers-20289d82-c1b0-4dde-9ae0-1114a711d6ce": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013176363s
Sep 12 12:46:28.318: INFO: Pod "client-containers-20289d82-c1b0-4dde-9ae0-1114a711d6ce": Phase="Pending", Reason="", readiness=false. Elapsed: 6.015277236s
Sep 12 12:46:30.320: INFO: Pod "client-containers-20289d82-c1b0-4dde-9ae0-1114a711d6ce": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.017217804s
STEP: Saw pod success
Sep 12 12:46:30.320: INFO: Pod "client-containers-20289d82-c1b0-4dde-9ae0-1114a711d6ce" satisfied condition "success or failure"
Sep 12 12:46:30.322: INFO: Trying to get logs from node caasp-worker-thehejik-1 pod client-containers-20289d82-c1b0-4dde-9ae0-1114a711d6ce container test-container: <nil>
STEP: delete the pod
Sep 12 12:46:30.416: INFO: Waiting for pod client-containers-20289d82-c1b0-4dde-9ae0-1114a711d6ce to disappear
Sep 12 12:46:30.426: INFO: Pod client-containers-20289d82-c1b0-4dde-9ae0-1114a711d6ce no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:46:30.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-576" for this suite.
Sep 12 12:46:36.443: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:46:36.511: INFO: namespace containers-576 deletion completed in 6.081941766s

â€¢ [SLOW TEST:14.371 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:46:36.514: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in events-7178
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Sep 12 12:46:44.682: INFO: &Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:send-events-60da3e74-e63a-4245-b587-5190999b565a,GenerateName:,Namespace:events-7178,SelfLink:/api/v1/namespaces/events-7178/pods/send-events-60da3e74-e63a-4245-b587-5190999b565a,UID:504c8676-20ea-41c0-bbe8-ca1d9042211b,ResourceVersion:13673,Generation:0,CreationTimestamp:2019-09-12 12:46:36 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: foo,time: 662653440,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-5lxgp {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-5lxgp,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{p gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 [] []  [{ 0 80 TCP }] [] [] {map[] map[]} [{default-token-5lxgp true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:caasp-worker-thehejik-5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0022f0310} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0022f0330}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 12:46:36 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 12:46:43 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 12:46:43 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 12:46:36 +0000 UTC  }],Message:,Reason:,HostIP:10.84.73.41,PodIP:10.244.4.160,StartTime:2019-09-12 12:46:36 +0000 UTC,ContainerStatuses:[{p {nil ContainerStateRunning{StartedAt:2019-09-12 12:46:43 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/serve-hostname:1.1 gcr.io/kubernetes-e2e-test-images/serve-hostname@sha256:53c28beabd3509fb5b1d1185b2962e8204384cef7562982d8b216b71292aabf9 cri-o://e3987ffe896548cb802844a3544b1f3b2cd87a405b95d820e9c54bc1b064cfe8}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}

STEP: checking for scheduler event about the pod
Sep 12 12:46:46.684: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Sep 12 12:46:48.687: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:46:48.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-7178" for this suite.
Sep 12 12:47:26.719: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:47:26.784: INFO: namespace events-7178 deletion completed in 38.081982849s

â€¢ [SLOW TEST:50.270 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:47:26.785: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4202
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-0bc55c00-a863-46c2-80fb-df27396f6aed
STEP: Creating a pod to test consume configMaps
Sep 12 12:47:26.950: INFO: Waiting up to 5m0s for pod "pod-configmaps-0559c8c3-777f-4cd6-869e-b0b8827c6b2f" in namespace "configmap-4202" to be "success or failure"
Sep 12 12:47:26.958: INFO: Pod "pod-configmaps-0559c8c3-777f-4cd6-869e-b0b8827c6b2f": Phase="Pending", Reason="", readiness=false. Elapsed: 7.533337ms
Sep 12 12:47:28.960: INFO: Pod "pod-configmaps-0559c8c3-777f-4cd6-869e-b0b8827c6b2f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009902624s
Sep 12 12:47:30.962: INFO: Pod "pod-configmaps-0559c8c3-777f-4cd6-869e-b0b8827c6b2f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012011143s
STEP: Saw pod success
Sep 12 12:47:30.962: INFO: Pod "pod-configmaps-0559c8c3-777f-4cd6-869e-b0b8827c6b2f" satisfied condition "success or failure"
Sep 12 12:47:30.964: INFO: Trying to get logs from node caasp-worker-thehejik-3 pod pod-configmaps-0559c8c3-777f-4cd6-869e-b0b8827c6b2f container configmap-volume-test: <nil>
STEP: delete the pod
Sep 12 12:47:30.985: INFO: Waiting for pod pod-configmaps-0559c8c3-777f-4cd6-869e-b0b8827c6b2f to disappear
Sep 12 12:47:30.995: INFO: Pod pod-configmaps-0559c8c3-777f-4cd6-869e-b0b8827c6b2f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:47:30.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4202" for this suite.
Sep 12 12:47:37.012: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:47:37.080: INFO: namespace configmap-4202 deletion completed in 6.082128716s

â€¢ [SLOW TEST:10.295 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:47:37.080: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-202
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Sep 12 12:47:37.256: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-202,SelfLink:/api/v1/namespaces/watch-202/configmaps/e2e-watch-test-label-changed,UID:c9850759-9c31-434a-b230-4c7bed88ee08,ResourceVersion:13946,Generation:0,CreationTimestamp:2019-09-12 12:47:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep 12 12:47:37.256: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-202,SelfLink:/api/v1/namespaces/watch-202/configmaps/e2e-watch-test-label-changed,UID:c9850759-9c31-434a-b230-4c7bed88ee08,ResourceVersion:13947,Generation:0,CreationTimestamp:2019-09-12 12:47:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Sep 12 12:47:37.256: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-202,SelfLink:/api/v1/namespaces/watch-202/configmaps/e2e-watch-test-label-changed,UID:c9850759-9c31-434a-b230-4c7bed88ee08,ResourceVersion:13948,Generation:0,CreationTimestamp:2019-09-12 12:47:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Sep 12 12:47:47.293: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-202,SelfLink:/api/v1/namespaces/watch-202/configmaps/e2e-watch-test-label-changed,UID:c9850759-9c31-434a-b230-4c7bed88ee08,ResourceVersion:13968,Generation:0,CreationTimestamp:2019-09-12 12:47:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep 12 12:47:47.293: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-202,SelfLink:/api/v1/namespaces/watch-202/configmaps/e2e-watch-test-label-changed,UID:c9850759-9c31-434a-b230-4c7bed88ee08,ResourceVersion:13969,Generation:0,CreationTimestamp:2019-09-12 12:47:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Sep 12 12:47:47.293: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-label-changed,GenerateName:,Namespace:watch-202,SelfLink:/api/v1/namespaces/watch-202/configmaps/e2e-watch-test-label-changed,UID:c9850759-9c31-434a-b230-4c7bed88ee08,ResourceVersion:13970,Generation:0,CreationTimestamp:2019-09-12 12:47:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: label-changed-and-restored,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:47:47.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-202" for this suite.
Sep 12 12:47:53.315: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:47:53.382: INFO: namespace watch-202 deletion completed in 6.080346472s

â€¢ [SLOW TEST:16.302 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:47:53.382: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-5185
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Sep 12 12:47:53.541: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:48:03.795: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-5185" for this suite.
Sep 12 12:48:25.822: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:48:25.886: INFO: namespace init-container-5185 deletion completed in 22.077566708s

â€¢ [SLOW TEST:32.504 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:48:25.886: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5353
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating Redis RC
Sep 12 12:48:26.052: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 create -f - --namespace=kubectl-5353'
Sep 12 12:48:26.243: INFO: stderr: ""
Sep 12 12:48:26.243: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Sep 12 12:48:27.246: INFO: Selector matched 1 pods for map[app:redis]
Sep 12 12:48:27.246: INFO: Found 0 / 1
Sep 12 12:48:28.246: INFO: Selector matched 1 pods for map[app:redis]
Sep 12 12:48:28.246: INFO: Found 0 / 1
Sep 12 12:48:29.245: INFO: Selector matched 1 pods for map[app:redis]
Sep 12 12:48:29.245: INFO: Found 0 / 1
Sep 12 12:48:30.245: INFO: Selector matched 1 pods for map[app:redis]
Sep 12 12:48:30.245: INFO: Found 1 / 1
Sep 12 12:48:30.245: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Sep 12 12:48:30.247: INFO: Selector matched 1 pods for map[app:redis]
Sep 12 12:48:30.247: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Sep 12 12:48:30.247: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 patch pod redis-master-w24bt --namespace=kubectl-5353 -p {"metadata":{"annotations":{"x":"y"}}}'
Sep 12 12:48:30.333: INFO: stderr: ""
Sep 12 12:48:30.333: INFO: stdout: "pod/redis-master-w24bt patched\n"
STEP: checking annotations
Sep 12 12:48:30.351: INFO: Selector matched 1 pods for map[app:redis]
Sep 12 12:48:30.351: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:48:30.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5353" for this suite.
Sep 12 12:48:52.368: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:48:52.441: INFO: namespace kubectl-5353 deletion completed in 22.087006267s

â€¢ [SLOW TEST:26.555 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl patch
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:48:52.441: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-5279
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 12 12:49:18.610: INFO: Container started at 2019-09-12 12:48:59 +0000 UTC, pod became ready at 2019-09-12 12:49:17 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:49:18.610: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5279" for this suite.
Sep 12 12:49:40.627: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:49:40.695: INFO: namespace container-probe-5279 deletion completed in 22.081305033s

â€¢ [SLOW TEST:48.253 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:49:40.695: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-3511
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Sep 12 12:49:41.307: INFO: Pod name wrapped-volume-race-391fe83f-a491-435e-b87f-88aa979ea6df: Found 0 pods out of 5
Sep 12 12:49:46.311: INFO: Pod name wrapped-volume-race-391fe83f-a491-435e-b87f-88aa979ea6df: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-391fe83f-a491-435e-b87f-88aa979ea6df in namespace emptydir-wrapper-3511, will wait for the garbage collector to delete the pods
Sep 12 12:50:04.400: INFO: Deleting ReplicationController wrapped-volume-race-391fe83f-a491-435e-b87f-88aa979ea6df took: 5.188464ms
Sep 12 12:50:04.901: INFO: Terminating ReplicationController wrapped-volume-race-391fe83f-a491-435e-b87f-88aa979ea6df pods took: 500.240951ms
STEP: Creating RC which spawns configmap-volume pods
Sep 12 12:50:48.636: INFO: Pod name wrapped-volume-race-8dbb3089-10ff-491a-bcbc-bb09ace0acff: Found 0 pods out of 5
Sep 12 12:50:53.646: INFO: Pod name wrapped-volume-race-8dbb3089-10ff-491a-bcbc-bb09ace0acff: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-8dbb3089-10ff-491a-bcbc-bb09ace0acff in namespace emptydir-wrapper-3511, will wait for the garbage collector to delete the pods
Sep 12 12:51:09.739: INFO: Deleting ReplicationController wrapped-volume-race-8dbb3089-10ff-491a-bcbc-bb09ace0acff took: 20.242164ms
Sep 12 12:51:10.139: INFO: Terminating ReplicationController wrapped-volume-race-8dbb3089-10ff-491a-bcbc-bb09ace0acff pods took: 400.170793ms
STEP: Creating RC which spawns configmap-volume pods
Sep 12 12:51:47.841: INFO: Pod name wrapped-volume-race-4ccb8f56-2f74-46f3-a57a-2f9488cee0a8: Found 0 pods out of 5
Sep 12 12:51:52.845: INFO: Pod name wrapped-volume-race-4ccb8f56-2f74-46f3-a57a-2f9488cee0a8: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-4ccb8f56-2f74-46f3-a57a-2f9488cee0a8 in namespace emptydir-wrapper-3511, will wait for the garbage collector to delete the pods
Sep 12 12:52:08.963: INFO: Deleting ReplicationController wrapped-volume-race-4ccb8f56-2f74-46f3-a57a-2f9488cee0a8 took: 4.38648ms
Sep 12 12:52:09.363: INFO: Terminating ReplicationController wrapped-volume-race-4ccb8f56-2f74-46f3-a57a-2f9488cee0a8 pods took: 400.206283ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:52:49.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-3511" for this suite.
Sep 12 12:52:57.191: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:52:57.258: INFO: namespace emptydir-wrapper-3511 deletion completed in 8.079246111s

â€¢ [SLOW TEST:196.563 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:52:57.260: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-660
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-5b126134-11b8-48d4-95cc-a53f448a5f50
STEP: Creating a pod to test consume configMaps
Sep 12 12:52:57.420: INFO: Waiting up to 5m0s for pod "pod-configmaps-0e8a45a6-8046-400b-b7c1-0d109473483a" in namespace "configmap-660" to be "success or failure"
Sep 12 12:52:57.441: INFO: Pod "pod-configmaps-0e8a45a6-8046-400b-b7c1-0d109473483a": Phase="Pending", Reason="", readiness=false. Elapsed: 20.340472ms
Sep 12 12:52:59.444: INFO: Pod "pod-configmaps-0e8a45a6-8046-400b-b7c1-0d109473483a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02326295s
Sep 12 12:53:01.446: INFO: Pod "pod-configmaps-0e8a45a6-8046-400b-b7c1-0d109473483a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025427689s
STEP: Saw pod success
Sep 12 12:53:01.446: INFO: Pod "pod-configmaps-0e8a45a6-8046-400b-b7c1-0d109473483a" satisfied condition "success or failure"
Sep 12 12:53:01.448: INFO: Trying to get logs from node caasp-worker-thehejik-1 pod pod-configmaps-0e8a45a6-8046-400b-b7c1-0d109473483a container configmap-volume-test: <nil>
STEP: delete the pod
Sep 12 12:53:01.467: INFO: Waiting for pod pod-configmaps-0e8a45a6-8046-400b-b7c1-0d109473483a to disappear
Sep 12 12:53:01.476: INFO: Pod pod-configmaps-0e8a45a6-8046-400b-b7c1-0d109473483a no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:53:01.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-660" for this suite.
Sep 12 12:53:07.493: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:53:07.562: INFO: namespace configmap-660 deletion completed in 6.083732804s

â€¢ [SLOW TEST:10.303 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:53:07.564: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8274
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Sep 12 12:53:07.740: INFO: Waiting up to 5m0s for pod "downward-api-dc4395ed-28e8-430d-a9cf-8507211e2388" in namespace "downward-api-8274" to be "success or failure"
Sep 12 12:53:07.749: INFO: Pod "downward-api-dc4395ed-28e8-430d-a9cf-8507211e2388": Phase="Pending", Reason="", readiness=false. Elapsed: 8.877941ms
Sep 12 12:53:09.752: INFO: Pod "downward-api-dc4395ed-28e8-430d-a9cf-8507211e2388": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011508866s
Sep 12 12:53:11.754: INFO: Pod "downward-api-dc4395ed-28e8-430d-a9cf-8507211e2388": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013811502s
STEP: Saw pod success
Sep 12 12:53:11.754: INFO: Pod "downward-api-dc4395ed-28e8-430d-a9cf-8507211e2388" satisfied condition "success or failure"
Sep 12 12:53:11.757: INFO: Trying to get logs from node caasp-worker-thehejik-1 pod downward-api-dc4395ed-28e8-430d-a9cf-8507211e2388 container dapi-container: <nil>
STEP: delete the pod
Sep 12 12:53:11.780: INFO: Waiting for pod downward-api-dc4395ed-28e8-430d-a9cf-8507211e2388 to disappear
Sep 12 12:53:11.789: INFO: Pod downward-api-dc4395ed-28e8-430d-a9cf-8507211e2388 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:53:11.789: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8274" for this suite.
Sep 12 12:53:17.805: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:53:17.870: INFO: namespace downward-api-8274 deletion completed in 6.077937283s

â€¢ [SLOW TEST:10.306 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:53:17.870: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-8202
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: getting the auto-created API token
STEP: reading a file in the container
Sep 12 12:53:22.628: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-8202 pod-service-account-d4db9b7d-4926-442b-8737-347cd7360ab8 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Sep 12 12:53:22.784: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-8202 pod-service-account-d4db9b7d-4926-442b-8737-347cd7360ab8 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Sep 12 12:53:22.928: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-8202 pod-service-account-d4db9b7d-4926-442b-8737-347cd7360ab8 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:53:23.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-8202" for this suite.
Sep 12 12:53:29.095: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:53:29.158: INFO: namespace svcaccounts-8202 deletion completed in 6.079541771s

â€¢ [SLOW TEST:11.288 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:53:29.158: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-617
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Sep 12 12:53:33.338: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 exec pod-sharedvolume-5b0ecf8c-7955-4931-a76e-5e70404d9d67 -c busybox-main-container --namespace=emptydir-617 -- cat /usr/share/volumeshare/shareddata.txt'
Sep 12 12:53:33.487: INFO: stderr: ""
Sep 12 12:53:33.487: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:53:33.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-617" for this suite.
Sep 12 12:53:39.506: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:53:39.572: INFO: namespace emptydir-617 deletion completed in 6.080573301s

â€¢ [SLOW TEST:10.413 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:53:39.572: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-5855
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-602
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-4675
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:54:06.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-5855" for this suite.
Sep 12 12:54:12.081: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:54:12.144: INFO: namespace namespaces-5855 deletion completed in 6.077014551s
STEP: Destroying namespace "nsdeletetest-602" for this suite.
Sep 12 12:54:12.146: INFO: Namespace nsdeletetest-602 was already deleted
STEP: Destroying namespace "nsdeletetest-4675" for this suite.
Sep 12 12:54:18.173: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:54:18.240: INFO: namespace nsdeletetest-4675 deletion completed in 6.09398484s

â€¢ [SLOW TEST:38.668 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:54:18.240: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6900
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep 12 12:54:18.413: INFO: Waiting up to 5m0s for pod "downwardapi-volume-756c4186-d09b-4bc8-ac14-db2cca495f93" in namespace "downward-api-6900" to be "success or failure"
Sep 12 12:54:18.425: INFO: Pod "downwardapi-volume-756c4186-d09b-4bc8-ac14-db2cca495f93": Phase="Pending", Reason="", readiness=false. Elapsed: 11.755586ms
Sep 12 12:54:20.427: INFO: Pod "downwardapi-volume-756c4186-d09b-4bc8-ac14-db2cca495f93": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013988993s
Sep 12 12:54:22.429: INFO: Pod "downwardapi-volume-756c4186-d09b-4bc8-ac14-db2cca495f93": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016267955s
STEP: Saw pod success
Sep 12 12:54:22.429: INFO: Pod "downwardapi-volume-756c4186-d09b-4bc8-ac14-db2cca495f93" satisfied condition "success or failure"
Sep 12 12:54:22.431: INFO: Trying to get logs from node caasp-worker-thehejik-4 pod downwardapi-volume-756c4186-d09b-4bc8-ac14-db2cca495f93 container client-container: <nil>
STEP: delete the pod
Sep 12 12:54:22.452: INFO: Waiting for pod downwardapi-volume-756c4186-d09b-4bc8-ac14-db2cca495f93 to disappear
Sep 12 12:54:22.462: INFO: Pod downwardapi-volume-756c4186-d09b-4bc8-ac14-db2cca495f93 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:54:22.462: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6900" for this suite.
Sep 12 12:54:28.479: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:54:28.546: INFO: namespace downward-api-6900 deletion completed in 6.080722763s

â€¢ [SLOW TEST:10.306 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:54:28.546: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-5939
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-5939
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep 12 12:54:28.713: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Sep 12 12:54:54.869: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.3.102:8080/dial?request=hostName&protocol=http&host=10.244.1.73&port=8080&tries=1'] Namespace:pod-network-test-5939 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 12 12:54:54.870: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
Sep 12 12:54:55.098: INFO: Waiting for endpoints: map[]
Sep 12 12:54:55.100: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.3.102:8080/dial?request=hostName&protocol=http&host=10.244.6.103&port=8080&tries=1'] Namespace:pod-network-test-5939 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 12 12:54:55.100: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
Sep 12 12:54:55.165: INFO: Waiting for endpoints: map[]
Sep 12 12:54:55.166: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.3.102:8080/dial?request=hostName&protocol=http&host=10.244.4.247&port=8080&tries=1'] Namespace:pod-network-test-5939 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 12 12:54:55.166: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
Sep 12 12:54:55.236: INFO: Waiting for endpoints: map[]
Sep 12 12:54:55.237: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.3.102:8080/dial?request=hostName&protocol=http&host=10.244.3.5&port=8080&tries=1'] Namespace:pod-network-test-5939 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 12 12:54:55.237: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
Sep 12 12:54:55.300: INFO: Waiting for endpoints: map[]
Sep 12 12:54:55.301: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.3.102:8080/dial?request=hostName&protocol=http&host=10.244.5.166&port=8080&tries=1'] Namespace:pod-network-test-5939 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 12 12:54:55.301: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
Sep 12 12:54:55.364: INFO: Waiting for endpoints: map[]
Sep 12 12:54:55.365: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.3.102:8080/dial?request=hostName&protocol=http&host=10.244.2.134&port=8080&tries=1'] Namespace:pod-network-test-5939 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 12 12:54:55.365: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
Sep 12 12:54:55.431: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:54:55.431: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5939" for this suite.
Sep 12 12:55:19.451: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:55:19.521: INFO: namespace pod-network-test-5939 deletion completed in 24.087038765s

â€¢ [SLOW TEST:50.975 seconds]
[sig-network] Networking
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:55:19.522: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5084
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-19f7aad8-92af-40e7-9e3a-16272db3bc8e
STEP: Creating a pod to test consume secrets
Sep 12 12:55:19.686: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a8f64a49-124b-4bfc-ac2f-a9c646506e0b" in namespace "projected-5084" to be "success or failure"
Sep 12 12:55:19.694: INFO: Pod "pod-projected-secrets-a8f64a49-124b-4bfc-ac2f-a9c646506e0b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.384695ms
Sep 12 12:55:21.697: INFO: Pod "pod-projected-secrets-a8f64a49-124b-4bfc-ac2f-a9c646506e0b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010543276s
Sep 12 12:55:23.699: INFO: Pod "pod-projected-secrets-a8f64a49-124b-4bfc-ac2f-a9c646506e0b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012662959s
STEP: Saw pod success
Sep 12 12:55:23.699: INFO: Pod "pod-projected-secrets-a8f64a49-124b-4bfc-ac2f-a9c646506e0b" satisfied condition "success or failure"
Sep 12 12:55:23.701: INFO: Trying to get logs from node caasp-worker-thehejik-3 pod pod-projected-secrets-a8f64a49-124b-4bfc-ac2f-a9c646506e0b container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep 12 12:55:23.719: INFO: Waiting for pod pod-projected-secrets-a8f64a49-124b-4bfc-ac2f-a9c646506e0b to disappear
Sep 12 12:55:23.728: INFO: Pod pod-projected-secrets-a8f64a49-124b-4bfc-ac2f-a9c646506e0b no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:55:23.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5084" for this suite.
Sep 12 12:55:29.744: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:55:29.831: INFO: namespace projected-5084 deletion completed in 6.100084503s

â€¢ [SLOW TEST:10.309 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:55:29.834: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-6928
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-6928
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-6928
STEP: Creating statefulset with conflicting port in namespace statefulset-6928
STEP: Waiting until pod test-pod will start running in namespace statefulset-6928
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-6928
Sep 12 12:55:34.045: INFO: Observed stateful pod in namespace: statefulset-6928, name: ss-0, uid: a05321e1-bfc6-4d82-9264-21120c108ec2, status phase: Pending. Waiting for statefulset controller to delete.
Sep 12 12:55:37.551: INFO: Observed stateful pod in namespace: statefulset-6928, name: ss-0, uid: a05321e1-bfc6-4d82-9264-21120c108ec2, status phase: Failed. Waiting for statefulset controller to delete.
Sep 12 12:55:37.655: INFO: Observed stateful pod in namespace: statefulset-6928, name: ss-0, uid: a05321e1-bfc6-4d82-9264-21120c108ec2, status phase: Failed. Waiting for statefulset controller to delete.
Sep 12 12:55:37.676: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-6928
STEP: Removing pod with conflicting port in namespace statefulset-6928
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-6928 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Sep 12 12:55:51.822: INFO: Deleting all statefulset in ns statefulset-6928
Sep 12 12:55:51.824: INFO: Scaling statefulset ss to 0
Sep 12 12:56:01.840: INFO: Waiting for statefulset status.replicas updated to 0
Sep 12 12:56:01.843: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:56:01.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6928" for this suite.
Sep 12 12:56:07.879: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:56:08.069: INFO: namespace statefulset-6928 deletion completed in 6.206659321s

â€¢ [SLOW TEST:38.235 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:56:08.069: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-8362
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Sep 12 12:56:11.293: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:56:11.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-8362" for this suite.
Sep 12 12:56:17.331: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:56:17.399: INFO: namespace container-runtime-8362 deletion completed in 6.0811007s

â€¢ [SLOW TEST:9.329 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:56:17.399: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6604
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep 12 12:56:17.574: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e2da864f-263a-4157-9f75-342878a65016" in namespace "projected-6604" to be "success or failure"
Sep 12 12:56:17.582: INFO: Pod "downwardapi-volume-e2da864f-263a-4157-9f75-342878a65016": Phase="Pending", Reason="", readiness=false. Elapsed: 8.488661ms
Sep 12 12:56:19.585: INFO: Pod "downwardapi-volume-e2da864f-263a-4157-9f75-342878a65016": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011307822s
Sep 12 12:56:21.588: INFO: Pod "downwardapi-volume-e2da864f-263a-4157-9f75-342878a65016": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014048086s
STEP: Saw pod success
Sep 12 12:56:21.588: INFO: Pod "downwardapi-volume-e2da864f-263a-4157-9f75-342878a65016" satisfied condition "success or failure"
Sep 12 12:56:21.590: INFO: Trying to get logs from node caasp-worker-thehejik-1 pod downwardapi-volume-e2da864f-263a-4157-9f75-342878a65016 container client-container: <nil>
STEP: delete the pod
Sep 12 12:56:21.613: INFO: Waiting for pod downwardapi-volume-e2da864f-263a-4157-9f75-342878a65016 to disappear
Sep 12 12:56:21.623: INFO: Pod downwardapi-volume-e2da864f-263a-4157-9f75-342878a65016 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:56:21.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6604" for this suite.
Sep 12 12:56:27.648: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:56:27.717: INFO: namespace projected-6604 deletion completed in 6.091395094s

â€¢ [SLOW TEST:10.318 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:56:27.718: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7531
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-map-9da1fd61-9d50-4e17-b54b-cea6176977a9
STEP: Creating a pod to test consume secrets
Sep 12 12:56:27.884: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-fa87cd28-8d66-4b31-b48c-7391dfc4f93d" in namespace "projected-7531" to be "success or failure"
Sep 12 12:56:27.895: INFO: Pod "pod-projected-secrets-fa87cd28-8d66-4b31-b48c-7391dfc4f93d": Phase="Pending", Reason="", readiness=false. Elapsed: 10.55614ms
Sep 12 12:56:29.897: INFO: Pod "pod-projected-secrets-fa87cd28-8d66-4b31-b48c-7391dfc4f93d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012634478s
Sep 12 12:56:31.900: INFO: Pod "pod-projected-secrets-fa87cd28-8d66-4b31-b48c-7391dfc4f93d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014990663s
STEP: Saw pod success
Sep 12 12:56:31.900: INFO: Pod "pod-projected-secrets-fa87cd28-8d66-4b31-b48c-7391dfc4f93d" satisfied condition "success or failure"
Sep 12 12:56:31.901: INFO: Trying to get logs from node caasp-worker-thehejik-4 pod pod-projected-secrets-fa87cd28-8d66-4b31-b48c-7391dfc4f93d container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep 12 12:56:31.919: INFO: Waiting for pod pod-projected-secrets-fa87cd28-8d66-4b31-b48c-7391dfc4f93d to disappear
Sep 12 12:56:31.927: INFO: Pod pod-projected-secrets-fa87cd28-8d66-4b31-b48c-7391dfc4f93d no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:56:31.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7531" for this suite.
Sep 12 12:56:38.011: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:56:38.109: INFO: namespace projected-7531 deletion completed in 6.178202825s

â€¢ [SLOW TEST:10.390 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:56:38.109: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svc-latency-3508
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating replication controller svc-latency-rc in namespace svc-latency-3508
I0912 12:56:38.266184      18 runners.go:180] Created replication controller with name: svc-latency-rc, namespace: svc-latency-3508, replica count: 1
I0912 12:56:39.316548      18 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0912 12:56:40.316743      18 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0912 12:56:41.317026      18 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0912 12:56:42.317222      18 runners.go:180] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Sep 12 12:56:42.432: INFO: Created: latency-svc-qfrzt
Sep 12 12:56:42.440: INFO: Got endpoints: latency-svc-qfrzt [22.735453ms]
Sep 12 12:56:42.479: INFO: Created: latency-svc-t86cg
Sep 12 12:56:42.491: INFO: Got endpoints: latency-svc-t86cg [51.675959ms]
Sep 12 12:56:42.503: INFO: Created: latency-svc-btshk
Sep 12 12:56:42.516: INFO: Got endpoints: latency-svc-btshk [75.863456ms]
Sep 12 12:56:42.531: INFO: Created: latency-svc-fqnz6
Sep 12 12:56:42.543: INFO: Got endpoints: latency-svc-fqnz6 [103.232409ms]
Sep 12 12:56:42.556: INFO: Created: latency-svc-4jf2l
Sep 12 12:56:42.571: INFO: Got endpoints: latency-svc-4jf2l [131.284856ms]
Sep 12 12:56:42.592: INFO: Created: latency-svc-qflx7
Sep 12 12:56:42.603: INFO: Got endpoints: latency-svc-qflx7 [163.214283ms]
Sep 12 12:56:42.677: INFO: Created: latency-svc-j447c
Sep 12 12:56:42.782: INFO: Got endpoints: latency-svc-j447c [342.221259ms]
Sep 12 12:56:42.787: INFO: Created: latency-svc-fbt8j
Sep 12 12:56:42.795: INFO: Got endpoints: latency-svc-fbt8j [354.735921ms]
Sep 12 12:56:42.806: INFO: Created: latency-svc-w7wmh
Sep 12 12:56:42.812: INFO: Got endpoints: latency-svc-w7wmh [371.69314ms]
Sep 12 12:56:42.821: INFO: Created: latency-svc-2rvjg
Sep 12 12:56:42.830: INFO: Got endpoints: latency-svc-2rvjg [389.854661ms]
Sep 12 12:56:42.840: INFO: Created: latency-svc-vpmb5
Sep 12 12:56:42.850: INFO: Got endpoints: latency-svc-vpmb5 [409.765461ms]
Sep 12 12:56:42.864: INFO: Created: latency-svc-btpdh
Sep 12 12:56:42.868: INFO: Got endpoints: latency-svc-btpdh [428.362413ms]
Sep 12 12:56:42.883: INFO: Created: latency-svc-flcsh
Sep 12 12:56:43.000: INFO: Got endpoints: latency-svc-flcsh [559.986129ms]
Sep 12 12:56:43.092: INFO: Created: latency-svc-6fz49
Sep 12 12:56:43.117: INFO: Got endpoints: latency-svc-6fz49 [677.355996ms]
Sep 12 12:56:43.210: INFO: Created: latency-svc-v5j6w
Sep 12 12:56:43.232: INFO: Got endpoints: latency-svc-v5j6w [791.715354ms]
Sep 12 12:56:43.292: INFO: Created: latency-svc-8xd2h
Sep 12 12:56:43.302: INFO: Got endpoints: latency-svc-8xd2h [862.287522ms]
Sep 12 12:56:43.316: INFO: Created: latency-svc-g6qfs
Sep 12 12:56:43.328: INFO: Got endpoints: latency-svc-g6qfs [836.268008ms]
Sep 12 12:56:43.371: INFO: Created: latency-svc-dhggl
Sep 12 12:56:43.372: INFO: Got endpoints: latency-svc-dhggl [855.88731ms]
Sep 12 12:56:43.391: INFO: Created: latency-svc-64s7z
Sep 12 12:56:43.400: INFO: Got endpoints: latency-svc-64s7z [857.322994ms]
Sep 12 12:56:43.412: INFO: Created: latency-svc-m2cp8
Sep 12 12:56:43.424: INFO: Got endpoints: latency-svc-m2cp8 [852.445215ms]
Sep 12 12:56:43.440: INFO: Created: latency-svc-ncdr2
Sep 12 12:56:43.450: INFO: Got endpoints: latency-svc-ncdr2 [847.254295ms]
Sep 12 12:56:43.462: INFO: Created: latency-svc-m5gh5
Sep 12 12:56:43.572: INFO: Got endpoints: latency-svc-m5gh5 [789.7051ms]
Sep 12 12:56:43.580: INFO: Created: latency-svc-g7hpv
Sep 12 12:56:43.601: INFO: Got endpoints: latency-svc-g7hpv [805.980673ms]
Sep 12 12:56:43.694: INFO: Created: latency-svc-bnhml
Sep 12 12:56:43.702: INFO: Got endpoints: latency-svc-bnhml [890.467412ms]
Sep 12 12:56:43.714: INFO: Created: latency-svc-mjxtp
Sep 12 12:56:43.723: INFO: Got endpoints: latency-svc-mjxtp [893.181276ms]
Sep 12 12:56:43.738: INFO: Created: latency-svc-wg6bk
Sep 12 12:56:43.741: INFO: Got endpoints: latency-svc-wg6bk [890.98019ms]
Sep 12 12:56:43.753: INFO: Created: latency-svc-9s86w
Sep 12 12:56:43.758: INFO: Got endpoints: latency-svc-9s86w [889.71939ms]
Sep 12 12:56:43.770: INFO: Created: latency-svc-8f82q
Sep 12 12:56:43.776: INFO: Got endpoints: latency-svc-8f82q [776.064043ms]
Sep 12 12:56:43.788: INFO: Created: latency-svc-9db88
Sep 12 12:56:43.904: INFO: Got endpoints: latency-svc-9db88 [786.335107ms]
Sep 12 12:56:43.916: INFO: Created: latency-svc-c4n4r
Sep 12 12:56:43.928: INFO: Got endpoints: latency-svc-c4n4r [696.233508ms]
Sep 12 12:56:43.930: INFO: Created: latency-svc-92m4j
Sep 12 12:56:43.937: INFO: Got endpoints: latency-svc-92m4j [33.236501ms]
Sep 12 12:56:43.993: INFO: Created: latency-svc-qbzcn
Sep 12 12:56:44.022: INFO: Got endpoints: latency-svc-qbzcn [719.445293ms]
Sep 12 12:56:44.036: INFO: Created: latency-svc-nbf8l
Sep 12 12:56:44.043: INFO: Got endpoints: latency-svc-nbf8l [715.514701ms]
Sep 12 12:56:44.056: INFO: Created: latency-svc-mprws
Sep 12 12:56:44.066: INFO: Got endpoints: latency-svc-mprws [694.473307ms]
Sep 12 12:56:44.078: INFO: Created: latency-svc-j6q2m
Sep 12 12:56:44.084: INFO: Got endpoints: latency-svc-j6q2m [683.712631ms]
Sep 12 12:56:44.096: INFO: Created: latency-svc-9c746
Sep 12 12:56:44.109: INFO: Got endpoints: latency-svc-9c746 [685.505276ms]
Sep 12 12:56:44.121: INFO: Created: latency-svc-f9vt7
Sep 12 12:56:44.201: INFO: Got endpoints: latency-svc-f9vt7 [750.553816ms]
Sep 12 12:56:44.213: INFO: Created: latency-svc-n442f
Sep 12 12:56:44.226: INFO: Got endpoints: latency-svc-n442f [653.777494ms]
Sep 12 12:56:44.237: INFO: Created: latency-svc-v4xk6
Sep 12 12:56:44.260: INFO: Got endpoints: latency-svc-v4xk6 [659.555961ms]
Sep 12 12:56:44.288: INFO: Created: latency-svc-9kgz7
Sep 12 12:56:44.297: INFO: Got endpoints: latency-svc-9kgz7 [595.165625ms]
Sep 12 12:56:44.325: INFO: Created: latency-svc-59xds
Sep 12 12:56:44.333: INFO: Got endpoints: latency-svc-59xds [609.643709ms]
Sep 12 12:56:44.346: INFO: Created: latency-svc-8dj25
Sep 12 12:56:44.355: INFO: Got endpoints: latency-svc-8dj25 [613.605451ms]
Sep 12 12:56:44.367: INFO: Created: latency-svc-t69nv
Sep 12 12:56:44.378: INFO: Got endpoints: latency-svc-t69nv [619.564467ms]
Sep 12 12:56:44.394: INFO: Created: latency-svc-xdb5p
Sep 12 12:56:44.405: INFO: Got endpoints: latency-svc-xdb5p [629.099664ms]
Sep 12 12:56:44.418: INFO: Created: latency-svc-zgjj6
Sep 12 12:56:44.502: INFO: Got endpoints: latency-svc-zgjj6 [574.269734ms]
Sep 12 12:56:44.515: INFO: Created: latency-svc-tbttl
Sep 12 12:56:44.528: INFO: Got endpoints: latency-svc-tbttl [590.782904ms]
Sep 12 12:56:44.532: INFO: Created: latency-svc-zmb5s
Sep 12 12:56:44.542: INFO: Got endpoints: latency-svc-zmb5s [519.891421ms]
Sep 12 12:56:44.558: INFO: Created: latency-svc-b4nd5
Sep 12 12:56:44.592: INFO: Got endpoints: latency-svc-b4nd5 [548.367794ms]
Sep 12 12:56:44.602: INFO: Created: latency-svc-7955p
Sep 12 12:56:44.622: INFO: Got endpoints: latency-svc-7955p [556.365133ms]
Sep 12 12:56:44.643: INFO: Created: latency-svc-vh694
Sep 12 12:56:44.654: INFO: Got endpoints: latency-svc-vh694 [569.452427ms]
Sep 12 12:56:44.664: INFO: Created: latency-svc-xk2dp
Sep 12 12:56:44.674: INFO: Got endpoints: latency-svc-xk2dp [564.916375ms]
Sep 12 12:56:44.687: INFO: Created: latency-svc-tqcsc
Sep 12 12:56:44.696: INFO: Got endpoints: latency-svc-tqcsc [495.133031ms]
Sep 12 12:56:44.750: INFO: Created: latency-svc-b5bsp
Sep 12 12:56:44.752: INFO: Got endpoints: latency-svc-b5bsp [525.577893ms]
Sep 12 12:56:44.804: INFO: Created: latency-svc-9wp2p
Sep 12 12:56:44.813: INFO: Got endpoints: latency-svc-9wp2p [552.770851ms]
Sep 12 12:56:44.825: INFO: Created: latency-svc-8fkpl
Sep 12 12:56:44.833: INFO: Got endpoints: latency-svc-8fkpl [535.436799ms]
Sep 12 12:56:44.868: INFO: Created: latency-svc-flmls
Sep 12 12:56:44.906: INFO: Got endpoints: latency-svc-flmls [573.108884ms]
Sep 12 12:56:44.919: INFO: Created: latency-svc-dqxgn
Sep 12 12:56:45.018: INFO: Got endpoints: latency-svc-dqxgn [662.933862ms]
Sep 12 12:56:45.025: INFO: Created: latency-svc-pmt22
Sep 12 12:56:45.037: INFO: Got endpoints: latency-svc-pmt22 [659.066257ms]
Sep 12 12:56:45.050: INFO: Created: latency-svc-tjftl
Sep 12 12:56:45.059: INFO: Got endpoints: latency-svc-tjftl [653.342186ms]
Sep 12 12:56:45.068: INFO: Created: latency-svc-c9z5w
Sep 12 12:56:45.081: INFO: Got endpoints: latency-svc-c9z5w [578.44153ms]
Sep 12 12:56:45.095: INFO: Created: latency-svc-whhq5
Sep 12 12:56:45.104: INFO: Got endpoints: latency-svc-whhq5 [576.234849ms]
Sep 12 12:56:45.189: INFO: Created: latency-svc-wmjpt
Sep 12 12:56:45.194: INFO: Got endpoints: latency-svc-wmjpt [651.768906ms]
Sep 12 12:56:45.213: INFO: Created: latency-svc-qn5nv
Sep 12 12:56:45.231: INFO: Got endpoints: latency-svc-qn5nv [638.79316ms]
Sep 12 12:56:45.249: INFO: Created: latency-svc-6s7x4
Sep 12 12:56:45.257: INFO: Got endpoints: latency-svc-6s7x4 [634.068677ms]
Sep 12 12:56:45.295: INFO: Created: latency-svc-gv4zf
Sep 12 12:56:45.316: INFO: Got endpoints: latency-svc-gv4zf [662.562998ms]
Sep 12 12:56:45.370: INFO: Created: latency-svc-6l4n4
Sep 12 12:56:45.378: INFO: Got endpoints: latency-svc-6l4n4 [703.218671ms]
Sep 12 12:56:45.388: INFO: Created: latency-svc-m678q
Sep 12 12:56:45.489: INFO: Got endpoints: latency-svc-m678q [793.147417ms]
Sep 12 12:56:45.521: INFO: Created: latency-svc-6j68z
Sep 12 12:56:45.530: INFO: Got endpoints: latency-svc-6j68z [778.741974ms]
Sep 12 12:56:45.543: INFO: Created: latency-svc-k7k8p
Sep 12 12:56:45.551: INFO: Got endpoints: latency-svc-k7k8p [737.288614ms]
Sep 12 12:56:45.579: INFO: Created: latency-svc-4tqd7
Sep 12 12:56:45.609: INFO: Got endpoints: latency-svc-4tqd7 [776.131244ms]
Sep 12 12:56:45.613: INFO: Created: latency-svc-ffkk9
Sep 12 12:56:45.625: INFO: Got endpoints: latency-svc-ffkk9 [719.385427ms]
Sep 12 12:56:45.726: INFO: Created: latency-svc-z4dzg
Sep 12 12:56:45.731: INFO: Got endpoints: latency-svc-z4dzg [712.953036ms]
Sep 12 12:56:45.743: INFO: Created: latency-svc-42kqj
Sep 12 12:56:45.758: INFO: Got endpoints: latency-svc-42kqj [720.641551ms]
Sep 12 12:56:45.770: INFO: Created: latency-svc-svcgj
Sep 12 12:56:45.781: INFO: Got endpoints: latency-svc-svcgj [721.801821ms]
Sep 12 12:56:45.795: INFO: Created: latency-svc-zf29q
Sep 12 12:56:45.803: INFO: Got endpoints: latency-svc-zf29q [721.664235ms]
Sep 12 12:56:45.812: INFO: Created: latency-svc-fhqf9
Sep 12 12:56:45.821: INFO: Got endpoints: latency-svc-fhqf9 [716.82639ms]
Sep 12 12:56:45.958: INFO: Created: latency-svc-8r68w
Sep 12 12:56:45.972: INFO: Got endpoints: latency-svc-8r68w [778.288065ms]
Sep 12 12:56:45.975: INFO: Created: latency-svc-qfwz8
Sep 12 12:56:46.094: INFO: Got endpoints: latency-svc-qfwz8 [863.206681ms]
Sep 12 12:56:46.100: INFO: Created: latency-svc-98l8x
Sep 12 12:56:46.113: INFO: Got endpoints: latency-svc-98l8x [856.596638ms]
Sep 12 12:56:46.245: INFO: Created: latency-svc-chdsd
Sep 12 12:56:46.259: INFO: Got endpoints: latency-svc-chdsd [942.341386ms]
Sep 12 12:56:46.271: INFO: Created: latency-svc-szqlc
Sep 12 12:56:46.290: INFO: Got endpoints: latency-svc-szqlc [912.772686ms]
Sep 12 12:56:46.315: INFO: Created: latency-svc-2dtqn
Sep 12 12:56:46.328: INFO: Got endpoints: latency-svc-2dtqn [838.272717ms]
Sep 12 12:56:46.339: INFO: Created: latency-svc-hnvj9
Sep 12 12:56:46.446: INFO: Got endpoints: latency-svc-hnvj9 [915.773658ms]
Sep 12 12:56:46.452: INFO: Created: latency-svc-l2jbk
Sep 12 12:56:46.464: INFO: Got endpoints: latency-svc-l2jbk [913.586947ms]
Sep 12 12:56:46.478: INFO: Created: latency-svc-vhnt7
Sep 12 12:56:46.488: INFO: Got endpoints: latency-svc-vhnt7 [879.038681ms]
Sep 12 12:56:46.501: INFO: Created: latency-svc-rp4rr
Sep 12 12:56:46.515: INFO: Got endpoints: latency-svc-rp4rr [889.169541ms]
Sep 12 12:56:46.530: INFO: Created: latency-svc-pnngl
Sep 12 12:56:46.568: INFO: Got endpoints: latency-svc-pnngl [837.043391ms]
Sep 12 12:56:46.576: INFO: Created: latency-svc-8rqtv
Sep 12 12:56:46.589: INFO: Got endpoints: latency-svc-8rqtv [831.04697ms]
Sep 12 12:56:46.609: INFO: Created: latency-svc-fth42
Sep 12 12:56:46.618: INFO: Got endpoints: latency-svc-fth42 [836.950732ms]
Sep 12 12:56:46.634: INFO: Created: latency-svc-hq9h6
Sep 12 12:56:46.642: INFO: Got endpoints: latency-svc-hq9h6 [839.288196ms]
Sep 12 12:56:46.653: INFO: Created: latency-svc-g8l8f
Sep 12 12:56:46.659: INFO: Got endpoints: latency-svc-g8l8f [838.18543ms]
Sep 12 12:56:46.723: INFO: Created: latency-svc-5mcd7
Sep 12 12:56:46.726: INFO: Got endpoints: latency-svc-5mcd7 [754.017779ms]
Sep 12 12:56:46.749: INFO: Created: latency-svc-zhlhs
Sep 12 12:56:46.762: INFO: Got endpoints: latency-svc-zhlhs [667.930881ms]
Sep 12 12:56:46.776: INFO: Created: latency-svc-7dmlq
Sep 12 12:56:46.785: INFO: Got endpoints: latency-svc-7dmlq [671.614953ms]
Sep 12 12:56:46.796: INFO: Created: latency-svc-gvkq4
Sep 12 12:56:46.808: INFO: Got endpoints: latency-svc-gvkq4 [549.021902ms]
Sep 12 12:56:46.849: INFO: Created: latency-svc-sjwsg
Sep 12 12:56:46.859: INFO: Got endpoints: latency-svc-sjwsg [568.741916ms]
Sep 12 12:56:46.871: INFO: Created: latency-svc-d9hjg
Sep 12 12:56:46.925: INFO: Got endpoints: latency-svc-d9hjg [596.995104ms]
Sep 12 12:56:46.936: INFO: Created: latency-svc-n7w9c
Sep 12 12:56:47.055: INFO: Got endpoints: latency-svc-n7w9c [608.373213ms]
Sep 12 12:56:47.067: INFO: Created: latency-svc-b9wbg
Sep 12 12:56:47.076: INFO: Got endpoints: latency-svc-b9wbg [611.306997ms]
Sep 12 12:56:47.088: INFO: Created: latency-svc-6phts
Sep 12 12:56:47.170: INFO: Got endpoints: latency-svc-6phts [681.292336ms]
Sep 12 12:56:47.185: INFO: Created: latency-svc-sgjgq
Sep 12 12:56:47.196: INFO: Got endpoints: latency-svc-sgjgq [681.59887ms]
Sep 12 12:56:47.218: INFO: Created: latency-svc-dppsj
Sep 12 12:56:47.226: INFO: Got endpoints: latency-svc-dppsj [657.937044ms]
Sep 12 12:56:47.253: INFO: Created: latency-svc-fdjxn
Sep 12 12:56:47.265: INFO: Got endpoints: latency-svc-fdjxn [676.294161ms]
Sep 12 12:56:47.352: INFO: Created: latency-svc-5rq4t
Sep 12 12:56:47.363: INFO: Got endpoints: latency-svc-5rq4t [745.042887ms]
Sep 12 12:56:47.376: INFO: Created: latency-svc-zrtxj
Sep 12 12:56:47.386: INFO: Got endpoints: latency-svc-zrtxj [744.204404ms]
Sep 12 12:56:47.395: INFO: Created: latency-svc-qmfkl
Sep 12 12:56:47.412: INFO: Got endpoints: latency-svc-qmfkl [752.44734ms]
Sep 12 12:56:47.425: INFO: Created: latency-svc-gpkfz
Sep 12 12:56:47.433: INFO: Got endpoints: latency-svc-gpkfz [707.33521ms]
Sep 12 12:56:47.443: INFO: Created: latency-svc-82f4n
Sep 12 12:56:47.452: INFO: Got endpoints: latency-svc-82f4n [689.751328ms]
Sep 12 12:56:47.576: INFO: Created: latency-svc-7644z
Sep 12 12:56:47.583: INFO: Got endpoints: latency-svc-7644z [797.780018ms]
Sep 12 12:56:47.609: INFO: Created: latency-svc-8nqgv
Sep 12 12:56:47.630: INFO: Got endpoints: latency-svc-8nqgv [822.382326ms]
Sep 12 12:56:47.639: INFO: Created: latency-svc-x9wgk
Sep 12 12:56:47.649: INFO: Got endpoints: latency-svc-x9wgk [789.359764ms]
Sep 12 12:56:47.731: INFO: Created: latency-svc-m4wmh
Sep 12 12:56:47.741: INFO: Got endpoints: latency-svc-m4wmh [816.590206ms]
Sep 12 12:56:47.752: INFO: Created: latency-svc-m8tpq
Sep 12 12:56:47.763: INFO: Got endpoints: latency-svc-m8tpq [708.033025ms]
Sep 12 12:56:47.774: INFO: Created: latency-svc-ccqdl
Sep 12 12:56:47.786: INFO: Got endpoints: latency-svc-ccqdl [710.821604ms]
Sep 12 12:56:47.796: INFO: Created: latency-svc-z5k26
Sep 12 12:56:47.807: INFO: Got endpoints: latency-svc-z5k26 [637.23316ms]
Sep 12 12:56:47.817: INFO: Created: latency-svc-zvflt
Sep 12 12:56:47.830: INFO: Got endpoints: latency-svc-zvflt [633.957578ms]
Sep 12 12:56:47.857: INFO: Created: latency-svc-tq4xw
Sep 12 12:56:47.868: INFO: Got endpoints: latency-svc-tq4xw [642.67878ms]
Sep 12 12:56:47.881: INFO: Created: latency-svc-6mmzn
Sep 12 12:56:47.892: INFO: Got endpoints: latency-svc-6mmzn [626.096971ms]
Sep 12 12:56:47.905: INFO: Created: latency-svc-mslmz
Sep 12 12:56:47.981: INFO: Got endpoints: latency-svc-mslmz [618.85951ms]
Sep 12 12:56:47.990: INFO: Created: latency-svc-xg2kl
Sep 12 12:56:48.003: INFO: Got endpoints: latency-svc-xg2kl [616.561556ms]
Sep 12 12:56:48.018: INFO: Created: latency-svc-tbzz9
Sep 12 12:56:48.021: INFO: Got endpoints: latency-svc-tbzz9 [609.501526ms]
Sep 12 12:56:48.034: INFO: Created: latency-svc-5gjrb
Sep 12 12:56:48.045: INFO: Got endpoints: latency-svc-5gjrb [611.09967ms]
Sep 12 12:56:48.057: INFO: Created: latency-svc-26g7r
Sep 12 12:56:48.067: INFO: Got endpoints: latency-svc-26g7r [615.743015ms]
Sep 12 12:56:48.271: INFO: Created: latency-svc-fjpwh
Sep 12 12:56:48.283: INFO: Got endpoints: latency-svc-fjpwh [699.763168ms]
Sep 12 12:56:48.296: INFO: Created: latency-svc-z86zp
Sep 12 12:56:48.307: INFO: Got endpoints: latency-svc-z86zp [676.991709ms]
Sep 12 12:56:48.327: INFO: Created: latency-svc-sxk85
Sep 12 12:56:48.337: INFO: Got endpoints: latency-svc-sxk85 [688.040411ms]
Sep 12 12:56:48.361: INFO: Created: latency-svc-tmr2h
Sep 12 12:56:48.391: INFO: Got endpoints: latency-svc-tmr2h [649.438933ms]
Sep 12 12:56:48.400: INFO: Created: latency-svc-gv6jt
Sep 12 12:56:48.411: INFO: Got endpoints: latency-svc-gv6jt [647.922292ms]
Sep 12 12:56:48.603: INFO: Created: latency-svc-2x2n5
Sep 12 12:56:48.607: INFO: Got endpoints: latency-svc-2x2n5 [820.864859ms]
Sep 12 12:56:48.729: INFO: Created: latency-svc-nt4sx
Sep 12 12:56:48.824: INFO: Got endpoints: latency-svc-nt4sx [1.016760354s]
Sep 12 12:56:48.849: INFO: Created: latency-svc-dw46k
Sep 12 12:56:48.857: INFO: Got endpoints: latency-svc-dw46k [1.027164687s]
Sep 12 12:56:48.967: INFO: Created: latency-svc-9l98f
Sep 12 12:56:48.971: INFO: Got endpoints: latency-svc-9l98f [1.102092074s]
Sep 12 12:56:49.018: INFO: Created: latency-svc-mr92r
Sep 12 12:56:49.028: INFO: Got endpoints: latency-svc-mr92r [1.13633754s]
Sep 12 12:56:49.037: INFO: Created: latency-svc-pltd9
Sep 12 12:56:49.046: INFO: Got endpoints: latency-svc-pltd9 [1.064859768s]
Sep 12 12:56:49.063: INFO: Created: latency-svc-78x4d
Sep 12 12:56:49.086: INFO: Got endpoints: latency-svc-78x4d [1.082727832s]
Sep 12 12:56:49.165: INFO: Created: latency-svc-sktxx
Sep 12 12:56:49.180: INFO: Got endpoints: latency-svc-sktxx [1.158334889s]
Sep 12 12:56:49.206: INFO: Created: latency-svc-smrfg
Sep 12 12:56:49.280: INFO: Got endpoints: latency-svc-smrfg [1.234992821s]
Sep 12 12:56:49.292: INFO: Created: latency-svc-zbqpn
Sep 12 12:56:49.301: INFO: Got endpoints: latency-svc-zbqpn [1.233572783s]
Sep 12 12:56:49.400: INFO: Created: latency-svc-kxkbk
Sep 12 12:56:49.410: INFO: Got endpoints: latency-svc-kxkbk [1.127385017s]
Sep 12 12:56:49.421: INFO: Created: latency-svc-shh66
Sep 12 12:56:49.430: INFO: Got endpoints: latency-svc-shh66 [1.123073548s]
Sep 12 12:56:49.442: INFO: Created: latency-svc-sd9z2
Sep 12 12:56:49.450: INFO: Got endpoints: latency-svc-sd9z2 [1.112858308s]
Sep 12 12:56:49.460: INFO: Created: latency-svc-b9b95
Sep 12 12:56:49.469: INFO: Got endpoints: latency-svc-b9b95 [1.077676685s]
Sep 12 12:56:49.487: INFO: Created: latency-svc-9sc7r
Sep 12 12:56:49.686: INFO: Got endpoints: latency-svc-9sc7r [1.274766507s]
Sep 12 12:56:49.694: INFO: Created: latency-svc-5v2hv
Sep 12 12:56:49.707: INFO: Got endpoints: latency-svc-5v2hv [1.09906279s]
Sep 12 12:56:49.776: INFO: Created: latency-svc-978np
Sep 12 12:56:49.858: INFO: Got endpoints: latency-svc-978np [1.034761603s]
Sep 12 12:56:49.873: INFO: Created: latency-svc-8vz2t
Sep 12 12:56:50.002: INFO: Got endpoints: latency-svc-8vz2t [1.144555363s]
Sep 12 12:56:50.013: INFO: Created: latency-svc-jcql5
Sep 12 12:56:50.024: INFO: Got endpoints: latency-svc-jcql5 [1.053502453s]
Sep 12 12:56:50.084: INFO: Created: latency-svc-n4w5q
Sep 12 12:56:50.093: INFO: Got endpoints: latency-svc-n4w5q [1.064637879s]
Sep 12 12:56:50.103: INFO: Created: latency-svc-8lqt6
Sep 12 12:56:50.183: INFO: Got endpoints: latency-svc-8lqt6 [1.13601386s]
Sep 12 12:56:50.196: INFO: Created: latency-svc-424fr
Sep 12 12:56:50.207: INFO: Got endpoints: latency-svc-424fr [1.12125247s]
Sep 12 12:56:50.218: INFO: Created: latency-svc-tdx8n
Sep 12 12:56:50.226: INFO: Got endpoints: latency-svc-tdx8n [1.04676122s]
Sep 12 12:56:50.241: INFO: Created: latency-svc-7tk58
Sep 12 12:56:50.249: INFO: Got endpoints: latency-svc-7tk58 [969.840257ms]
Sep 12 12:56:50.306: INFO: Created: latency-svc-lt4cf
Sep 12 12:56:50.397: INFO: Got endpoints: latency-svc-lt4cf [1.09577454s]
Sep 12 12:56:50.504: INFO: Created: latency-svc-gp8v5
Sep 12 12:56:50.513: INFO: Got endpoints: latency-svc-gp8v5 [1.102241409s]
Sep 12 12:56:50.523: INFO: Created: latency-svc-xskf2
Sep 12 12:56:50.537: INFO: Got endpoints: latency-svc-xskf2 [1.106387747s]
Sep 12 12:56:50.595: INFO: Created: latency-svc-zlvk6
Sep 12 12:56:50.631: INFO: Got endpoints: latency-svc-zlvk6 [1.181256486s]
Sep 12 12:56:50.644: INFO: Created: latency-svc-8hbft
Sep 12 12:56:50.655: INFO: Got endpoints: latency-svc-8hbft [1.18657868s]
Sep 12 12:56:50.667: INFO: Created: latency-svc-jpffq
Sep 12 12:56:50.676: INFO: Got endpoints: latency-svc-jpffq [989.949295ms]
Sep 12 12:56:50.688: INFO: Created: latency-svc-wx422
Sep 12 12:56:50.699: INFO: Got endpoints: latency-svc-wx422 [992.784117ms]
Sep 12 12:56:50.718: INFO: Created: latency-svc-hrwm6
Sep 12 12:56:50.755: INFO: Got endpoints: latency-svc-hrwm6 [896.993334ms]
Sep 12 12:56:50.768: INFO: Created: latency-svc-dv266
Sep 12 12:56:50.779: INFO: Got endpoints: latency-svc-dv266 [776.933962ms]
Sep 12 12:56:50.803: INFO: Created: latency-svc-ltmjm
Sep 12 12:56:50.815: INFO: Got endpoints: latency-svc-ltmjm [790.774733ms]
Sep 12 12:56:50.827: INFO: Created: latency-svc-zz958
Sep 12 12:56:50.847: INFO: Got endpoints: latency-svc-zz958 [753.783721ms]
Sep 12 12:56:50.852: INFO: Created: latency-svc-l9pdf
Sep 12 12:56:50.966: INFO: Got endpoints: latency-svc-l9pdf [782.982359ms]
Sep 12 12:56:50.975: INFO: Created: latency-svc-jjmgq
Sep 12 12:56:50.986: INFO: Got endpoints: latency-svc-jjmgq [779.012344ms]
Sep 12 12:56:50.996: INFO: Created: latency-svc-tl4j5
Sep 12 12:56:51.008: INFO: Got endpoints: latency-svc-tl4j5 [781.056373ms]
Sep 12 12:56:51.021: INFO: Created: latency-svc-5ndnp
Sep 12 12:56:51.028: INFO: Got endpoints: latency-svc-5ndnp [778.573948ms]
Sep 12 12:56:51.043: INFO: Created: latency-svc-9khcq
Sep 12 12:56:51.052: INFO: Got endpoints: latency-svc-9khcq [654.720323ms]
Sep 12 12:56:51.065: INFO: Created: latency-svc-j8td4
Sep 12 12:56:51.168: INFO: Got endpoints: latency-svc-j8td4 [655.412069ms]
Sep 12 12:56:51.179: INFO: Created: latency-svc-n46rc
Sep 12 12:56:51.187: INFO: Got endpoints: latency-svc-n46rc [650.587705ms]
Sep 12 12:56:51.199: INFO: Created: latency-svc-vbjrg
Sep 12 12:56:51.210: INFO: Got endpoints: latency-svc-vbjrg [578.715216ms]
Sep 12 12:56:51.221: INFO: Created: latency-svc-9cvz6
Sep 12 12:56:51.228: INFO: Got endpoints: latency-svc-9cvz6 [572.362548ms]
Sep 12 12:56:51.242: INFO: Created: latency-svc-pjbwp
Sep 12 12:56:51.251: INFO: Got endpoints: latency-svc-pjbwp [575.24882ms]
Sep 12 12:56:51.289: INFO: Created: latency-svc-6p98x
Sep 12 12:56:51.291: INFO: Got endpoints: latency-svc-6p98x [591.312424ms]
Sep 12 12:56:51.316: INFO: Created: latency-svc-27qxr
Sep 12 12:56:51.327: INFO: Got endpoints: latency-svc-27qxr [571.192567ms]
Sep 12 12:56:51.361: INFO: Created: latency-svc-6s24q
Sep 12 12:56:51.378: INFO: Got endpoints: latency-svc-6s24q [598.699717ms]
Sep 12 12:56:51.471: INFO: Created: latency-svc-6rcnp
Sep 12 12:56:51.484: INFO: Got endpoints: latency-svc-6rcnp [669.322356ms]
Sep 12 12:56:51.488: INFO: Created: latency-svc-fsrzq
Sep 12 12:56:51.498: INFO: Got endpoints: latency-svc-fsrzq [650.986444ms]
Sep 12 12:56:51.512: INFO: Created: latency-svc-5zjql
Sep 12 12:56:51.518: INFO: Got endpoints: latency-svc-5zjql [552.625901ms]
Sep 12 12:56:51.528: INFO: Created: latency-svc-8pc6c
Sep 12 12:56:51.537: INFO: Got endpoints: latency-svc-8pc6c [551.453666ms]
Sep 12 12:56:51.551: INFO: Created: latency-svc-8fj9h
Sep 12 12:56:51.559: INFO: Got endpoints: latency-svc-8fj9h [551.709941ms]
Sep 12 12:56:51.571: INFO: Created: latency-svc-gw6vb
Sep 12 12:56:51.589: INFO: Got endpoints: latency-svc-gw6vb [560.52645ms]
Sep 12 12:56:51.596: INFO: Created: latency-svc-ws776
Sep 12 12:56:51.604: INFO: Got endpoints: latency-svc-ws776 [551.544335ms]
Sep 12 12:56:51.668: INFO: Created: latency-svc-c8s4d
Sep 12 12:56:51.678: INFO: Got endpoints: latency-svc-c8s4d [510.048984ms]
Sep 12 12:56:51.772: INFO: Created: latency-svc-xmsc5
Sep 12 12:56:51.786: INFO: Got endpoints: latency-svc-xmsc5 [598.555796ms]
Sep 12 12:56:51.789: INFO: Created: latency-svc-d4xqp
Sep 12 12:56:51.793: INFO: Got endpoints: latency-svc-d4xqp [583.629696ms]
Sep 12 12:56:51.804: INFO: Created: latency-svc-strkt
Sep 12 12:56:51.812: INFO: Got endpoints: latency-svc-strkt [584.068261ms]
Sep 12 12:56:51.821: INFO: Created: latency-svc-48shw
Sep 12 12:56:51.831: INFO: Got endpoints: latency-svc-48shw [579.908913ms]
Sep 12 12:56:51.842: INFO: Created: latency-svc-hzvpt
Sep 12 12:56:51.853: INFO: Got endpoints: latency-svc-hzvpt [562.357764ms]
Sep 12 12:56:51.864: INFO: Created: latency-svc-vmnjw
Sep 12 12:56:51.889: INFO: Got endpoints: latency-svc-vmnjw [562.359789ms]
Sep 12 12:56:51.896: INFO: Created: latency-svc-g4wvn
Sep 12 12:56:51.909: INFO: Got endpoints: latency-svc-g4wvn [530.970414ms]
Sep 12 12:56:51.925: INFO: Created: latency-svc-mmzr6
Sep 12 12:56:51.936: INFO: Got endpoints: latency-svc-mmzr6 [451.164793ms]
Sep 12 12:56:51.965: INFO: Created: latency-svc-5tbf2
Sep 12 12:56:51.972: INFO: Got endpoints: latency-svc-5tbf2 [474.398191ms]
Sep 12 12:56:51.985: INFO: Created: latency-svc-ltvp7
Sep 12 12:56:52.028: INFO: Got endpoints: latency-svc-ltvp7 [510.039579ms]
Sep 12 12:56:52.042: INFO: Created: latency-svc-4trxg
Sep 12 12:56:52.052: INFO: Got endpoints: latency-svc-4trxg [514.515509ms]
Sep 12 12:56:52.062: INFO: Created: latency-svc-8stfp
Sep 12 12:56:52.074: INFO: Got endpoints: latency-svc-8stfp [514.458922ms]
Sep 12 12:56:52.084: INFO: Created: latency-svc-k654t
Sep 12 12:56:52.095: INFO: Got endpoints: latency-svc-k654t [506.649414ms]
Sep 12 12:56:52.107: INFO: Created: latency-svc-llzs5
Sep 12 12:56:52.114: INFO: Got endpoints: latency-svc-llzs5 [510.926277ms]
Sep 12 12:56:52.167: INFO: Created: latency-svc-pbfqr
Sep 12 12:56:52.179: INFO: Got endpoints: latency-svc-pbfqr [500.510765ms]
Sep 12 12:56:52.193: INFO: Created: latency-svc-sfzs8
Sep 12 12:56:52.202: INFO: Got endpoints: latency-svc-sfzs8 [416.090421ms]
Sep 12 12:56:52.215: INFO: Created: latency-svc-88bkv
Sep 12 12:56:52.223: INFO: Got endpoints: latency-svc-88bkv [429.420348ms]
Sep 12 12:56:52.223: INFO: Latencies: [33.236501ms 51.675959ms 75.863456ms 103.232409ms 131.284856ms 163.214283ms 342.221259ms 354.735921ms 371.69314ms 389.854661ms 409.765461ms 416.090421ms 428.362413ms 429.420348ms 451.164793ms 474.398191ms 495.133031ms 500.510765ms 506.649414ms 510.039579ms 510.048984ms 510.926277ms 514.458922ms 514.515509ms 519.891421ms 525.577893ms 530.970414ms 535.436799ms 548.367794ms 549.021902ms 551.453666ms 551.544335ms 551.709941ms 552.625901ms 552.770851ms 556.365133ms 559.986129ms 560.52645ms 562.357764ms 562.359789ms 564.916375ms 568.741916ms 569.452427ms 571.192567ms 572.362548ms 573.108884ms 574.269734ms 575.24882ms 576.234849ms 578.44153ms 578.715216ms 579.908913ms 583.629696ms 584.068261ms 590.782904ms 591.312424ms 595.165625ms 596.995104ms 598.555796ms 598.699717ms 608.373213ms 609.501526ms 609.643709ms 611.09967ms 611.306997ms 613.605451ms 615.743015ms 616.561556ms 618.85951ms 619.564467ms 626.096971ms 629.099664ms 633.957578ms 634.068677ms 637.23316ms 638.79316ms 642.67878ms 647.922292ms 649.438933ms 650.587705ms 650.986444ms 651.768906ms 653.342186ms 653.777494ms 654.720323ms 655.412069ms 657.937044ms 659.066257ms 659.555961ms 662.562998ms 662.933862ms 667.930881ms 669.322356ms 671.614953ms 676.294161ms 676.991709ms 677.355996ms 681.292336ms 681.59887ms 683.712631ms 685.505276ms 688.040411ms 689.751328ms 694.473307ms 696.233508ms 699.763168ms 703.218671ms 707.33521ms 708.033025ms 710.821604ms 712.953036ms 715.514701ms 716.82639ms 719.385427ms 719.445293ms 720.641551ms 721.664235ms 721.801821ms 737.288614ms 744.204404ms 745.042887ms 750.553816ms 752.44734ms 753.783721ms 754.017779ms 776.064043ms 776.131244ms 776.933962ms 778.288065ms 778.573948ms 778.741974ms 779.012344ms 781.056373ms 782.982359ms 786.335107ms 789.359764ms 789.7051ms 790.774733ms 791.715354ms 793.147417ms 797.780018ms 805.980673ms 816.590206ms 820.864859ms 822.382326ms 831.04697ms 836.268008ms 836.950732ms 837.043391ms 838.18543ms 838.272717ms 839.288196ms 847.254295ms 852.445215ms 855.88731ms 856.596638ms 857.322994ms 862.287522ms 863.206681ms 879.038681ms 889.169541ms 889.71939ms 890.467412ms 890.98019ms 893.181276ms 896.993334ms 912.772686ms 913.586947ms 915.773658ms 942.341386ms 969.840257ms 989.949295ms 992.784117ms 1.016760354s 1.027164687s 1.034761603s 1.04676122s 1.053502453s 1.064637879s 1.064859768s 1.077676685s 1.082727832s 1.09577454s 1.09906279s 1.102092074s 1.102241409s 1.106387747s 1.112858308s 1.12125247s 1.123073548s 1.127385017s 1.13601386s 1.13633754s 1.144555363s 1.158334889s 1.181256486s 1.18657868s 1.233572783s 1.234992821s 1.274766507s]
Sep 12 12:56:52.223: INFO: 50 %ile: 685.505276ms
Sep 12 12:56:52.223: INFO: 90 %ile: 1.077676685s
Sep 12 12:56:52.223: INFO: 99 %ile: 1.234992821s
Sep 12 12:56:52.223: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:56:52.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-3508" for this suite.
Sep 12 12:57:18.252: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:57:18.315: INFO: namespace svc-latency-3508 deletion completed in 26.082891129s

â€¢ [SLOW TEST:40.206 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:57:18.318: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-6367
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:57:23.038: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6367" for this suite.
Sep 12 12:58:09.055: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:58:09.122: INFO: namespace kubelet-test-6367 deletion completed in 46.081402826s

â€¢ [SLOW TEST:50.804 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:58:09.122: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-2504
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-map-bf34c0ca-e3c0-46e5-b9de-ec1a48d11741
STEP: Creating a pod to test consume secrets
Sep 12 12:58:09.301: INFO: Waiting up to 5m0s for pod "pod-secrets-ae8fff8b-8522-4424-a872-308e604c8c63" in namespace "secrets-2504" to be "success or failure"
Sep 12 12:58:09.310: INFO: Pod "pod-secrets-ae8fff8b-8522-4424-a872-308e604c8c63": Phase="Pending", Reason="", readiness=false. Elapsed: 8.377507ms
Sep 12 12:58:11.313: INFO: Pod "pod-secrets-ae8fff8b-8522-4424-a872-308e604c8c63": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010975066s
Sep 12 12:58:13.315: INFO: Pod "pod-secrets-ae8fff8b-8522-4424-a872-308e604c8c63": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013344254s
STEP: Saw pod success
Sep 12 12:58:13.315: INFO: Pod "pod-secrets-ae8fff8b-8522-4424-a872-308e604c8c63" satisfied condition "success or failure"
Sep 12 12:58:13.316: INFO: Trying to get logs from node caasp-worker-thehejik-0 pod pod-secrets-ae8fff8b-8522-4424-a872-308e604c8c63 container secret-volume-test: <nil>
STEP: delete the pod
Sep 12 12:58:13.337: INFO: Waiting for pod pod-secrets-ae8fff8b-8522-4424-a872-308e604c8c63 to disappear
Sep 12 12:58:13.345: INFO: Pod pod-secrets-ae8fff8b-8522-4424-a872-308e604c8c63 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:58:13.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2504" for this suite.
Sep 12 12:58:19.361: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:58:19.433: INFO: namespace secrets-2504 deletion completed in 6.084094787s

â€¢ [SLOW TEST:10.310 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:58:19.434: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6701
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1421
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep 12 12:58:19.596: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 run e2e-test-nginx-deployment --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-6701'
Sep 12 12:58:20.473: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep 12 12:58:20.473: INFO: stdout: "deployment.apps/e2e-test-nginx-deployment created\n"
STEP: verifying the pod controlled by e2e-test-nginx-deployment gets created
[AfterEach] [k8s.io] Kubectl run default
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1427
Sep 12 12:58:22.495: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 delete deployment e2e-test-nginx-deployment --namespace=kubectl-6701'
Sep 12 12:58:22.585: INFO: stderr: ""
Sep 12 12:58:22.585: INFO: stdout: "deployment.extensions \"e2e-test-nginx-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:58:22.585: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6701" for this suite.
Sep 12 12:58:28.604: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:58:28.671: INFO: namespace kubectl-6701 deletion completed in 6.082455584s

â€¢ [SLOW TEST:9.237 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run default
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:58:28.671: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7590
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep 12 12:58:28.825: INFO: Waiting up to 5m0s for pod "downwardapi-volume-95d578a5-4c8b-444e-80e9-72426bd36b5a" in namespace "projected-7590" to be "success or failure"
Sep 12 12:58:28.836: INFO: Pod "downwardapi-volume-95d578a5-4c8b-444e-80e9-72426bd36b5a": Phase="Pending", Reason="", readiness=false. Elapsed: 10.616637ms
Sep 12 12:58:30.838: INFO: Pod "downwardapi-volume-95d578a5-4c8b-444e-80e9-72426bd36b5a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012863038s
Sep 12 12:58:32.841: INFO: Pod "downwardapi-volume-95d578a5-4c8b-444e-80e9-72426bd36b5a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015733435s
STEP: Saw pod success
Sep 12 12:58:32.841: INFO: Pod "downwardapi-volume-95d578a5-4c8b-444e-80e9-72426bd36b5a" satisfied condition "success or failure"
Sep 12 12:58:32.842: INFO: Trying to get logs from node caasp-worker-thehejik-1 pod downwardapi-volume-95d578a5-4c8b-444e-80e9-72426bd36b5a container client-container: <nil>
STEP: delete the pod
Sep 12 12:58:32.862: INFO: Waiting for pod downwardapi-volume-95d578a5-4c8b-444e-80e9-72426bd36b5a to disappear
Sep 12 12:58:32.872: INFO: Pod downwardapi-volume-95d578a5-4c8b-444e-80e9-72426bd36b5a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:58:32.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7590" for this suite.
Sep 12 12:58:38.888: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:58:38.951: INFO: namespace projected-7590 deletion completed in 6.077079116s

â€¢ [SLOW TEST:10.280 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:58:38.953: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-1539
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Sep 12 12:59:09.634: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0912 12:59:09.634133      18 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:59:09.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1539" for this suite.
Sep 12 12:59:15.659: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:59:15.728: INFO: namespace gc-1539 deletion completed in 6.091623075s

â€¢ [SLOW TEST:36.776 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:59:15.728: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4798
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name cm-test-opt-del-1e1e949b-e0a9-4904-afd0-38f5eca13f0b
STEP: Creating configMap with name cm-test-opt-upd-22ca8b31-e589-489c-8cdd-e96a6b684343
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-1e1e949b-e0a9-4904-afd0-38f5eca13f0b
STEP: Updating configmap cm-test-opt-upd-22ca8b31-e589-489c-8cdd-e96a6b684343
STEP: Creating configMap with name cm-test-opt-create-c6b78b7c-a601-4e37-84e3-c0fce9a7ddf9
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:59:24.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4798" for this suite.
Sep 12 12:59:46.058: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:59:46.139: INFO: namespace configmap-4798 deletion completed in 22.104043642s

â€¢ [SLOW TEST:30.411 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:59:46.140: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7280
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-1a5cb2ba-0d9d-4154-bd27-8e7644d821ba
STEP: Creating a pod to test consume secrets
Sep 12 12:59:46.309: INFO: Waiting up to 5m0s for pod "pod-secrets-5be071aa-5a80-4ac3-8f4d-d22b1e888ec6" in namespace "secrets-7280" to be "success or failure"
Sep 12 12:59:46.322: INFO: Pod "pod-secrets-5be071aa-5a80-4ac3-8f4d-d22b1e888ec6": Phase="Pending", Reason="", readiness=false. Elapsed: 13.458622ms
Sep 12 12:59:48.324: INFO: Pod "pod-secrets-5be071aa-5a80-4ac3-8f4d-d22b1e888ec6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015449513s
Sep 12 12:59:50.327: INFO: Pod "pod-secrets-5be071aa-5a80-4ac3-8f4d-d22b1e888ec6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018040461s
STEP: Saw pod success
Sep 12 12:59:50.327: INFO: Pod "pod-secrets-5be071aa-5a80-4ac3-8f4d-d22b1e888ec6" satisfied condition "success or failure"
Sep 12 12:59:50.328: INFO: Trying to get logs from node caasp-worker-thehejik-3 pod pod-secrets-5be071aa-5a80-4ac3-8f4d-d22b1e888ec6 container secret-env-test: <nil>
STEP: delete the pod
Sep 12 12:59:50.350: INFO: Waiting for pod pod-secrets-5be071aa-5a80-4ac3-8f4d-d22b1e888ec6 to disappear
Sep 12 12:59:50.358: INFO: Pod pod-secrets-5be071aa-5a80-4ac3-8f4d-d22b1e888ec6 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 12:59:50.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7280" for this suite.
Sep 12 12:59:56.374: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 12:59:56.441: INFO: namespace secrets-7280 deletion completed in 6.08030098s

â€¢ [SLOW TEST:10.301 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 12:59:56.441: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3239
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on node default medium
Sep 12 12:59:56.610: INFO: Waiting up to 5m0s for pod "pod-b6d4cf40-8609-407a-af20-8a06f5ecb641" in namespace "emptydir-3239" to be "success or failure"
Sep 12 12:59:56.621: INFO: Pod "pod-b6d4cf40-8609-407a-af20-8a06f5ecb641": Phase="Pending", Reason="", readiness=false. Elapsed: 10.850024ms
Sep 12 12:59:58.624: INFO: Pod "pod-b6d4cf40-8609-407a-af20-8a06f5ecb641": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013790515s
Sep 12 13:00:00.626: INFO: Pod "pod-b6d4cf40-8609-407a-af20-8a06f5ecb641": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015874928s
Sep 12 13:00:02.629: INFO: Pod "pod-b6d4cf40-8609-407a-af20-8a06f5ecb641": Phase="Pending", Reason="", readiness=false. Elapsed: 6.018638503s
Sep 12 13:00:04.632: INFO: Pod "pod-b6d4cf40-8609-407a-af20-8a06f5ecb641": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.021417882s
STEP: Saw pod success
Sep 12 13:00:04.632: INFO: Pod "pod-b6d4cf40-8609-407a-af20-8a06f5ecb641" satisfied condition "success or failure"
Sep 12 13:00:04.634: INFO: Trying to get logs from node caasp-worker-thehejik-0 pod pod-b6d4cf40-8609-407a-af20-8a06f5ecb641 container test-container: <nil>
STEP: delete the pod
Sep 12 13:00:04.652: INFO: Waiting for pod pod-b6d4cf40-8609-407a-af20-8a06f5ecb641 to disappear
Sep 12 13:00:04.711: INFO: Pod pod-b6d4cf40-8609-407a-af20-8a06f5ecb641 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:00:04.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3239" for this suite.
Sep 12 13:00:10.730: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:00:10.793: INFO: namespace emptydir-3239 deletion completed in 6.079050041s

â€¢ [SLOW TEST:14.352 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:00:10.794: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-9877
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-9877.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-9877.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9877.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-9877.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-9877.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9877.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 12 13:00:34.987: INFO: DNS probes using dns-9877/dns-test-342269b2-09a8-48c4-98ba-921b9e1cf5a3 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:00:35.004: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9877" for this suite.
Sep 12 13:00:41.038: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:00:41.107: INFO: namespace dns-9877 deletion completed in 6.094895229s

â€¢ [SLOW TEST:30.312 seconds]
[sig-network] DNS
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:00:41.107: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6917
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: validating cluster-info
Sep 12 13:00:41.258: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 cluster-info'
Sep 12 13:00:41.336: INFO: stderr: ""
Sep 12 13:00:41.336: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:00:41.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6917" for this suite.
Sep 12 13:00:47.353: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:00:47.425: INFO: namespace kubectl-6917 deletion completed in 6.085116242s

â€¢ [SLOW TEST:6.317 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl cluster-info
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:00:47.427: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-8950
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 12 13:00:47.607: INFO: (0) /api/v1/nodes/caasp-worker-thehejik-0/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="btmp">... (200; 4.477332ms)
Sep 12 13:00:47.609: INFO: (1) /api/v1/nodes/caasp-worker-thehejik-0/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="btmp">... (200; 2.185863ms)
Sep 12 13:00:47.611: INFO: (2) /api/v1/nodes/caasp-worker-thehejik-0/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="btmp">... (200; 2.254942ms)
Sep 12 13:00:47.614: INFO: (3) /api/v1/nodes/caasp-worker-thehejik-0/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="btmp">... (200; 2.314804ms)
Sep 12 13:00:47.616: INFO: (4) /api/v1/nodes/caasp-worker-thehejik-0/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="btmp">... (200; 2.096151ms)
Sep 12 13:00:47.618: INFO: (5) /api/v1/nodes/caasp-worker-thehejik-0/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="btmp">... (200; 2.159722ms)
Sep 12 13:00:47.620: INFO: (6) /api/v1/nodes/caasp-worker-thehejik-0/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="btmp">... (200; 2.173277ms)
Sep 12 13:00:47.622: INFO: (7) /api/v1/nodes/caasp-worker-thehejik-0/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="btmp">... (200; 2.146646ms)
Sep 12 13:00:47.625: INFO: (8) /api/v1/nodes/caasp-worker-thehejik-0/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="btmp">... (200; 2.235828ms)
Sep 12 13:00:47.627: INFO: (9) /api/v1/nodes/caasp-worker-thehejik-0/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="btmp">... (200; 2.118974ms)
Sep 12 13:00:47.629: INFO: (10) /api/v1/nodes/caasp-worker-thehejik-0/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="btmp">... (200; 2.033314ms)
Sep 12 13:00:47.631: INFO: (11) /api/v1/nodes/caasp-worker-thehejik-0/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="btmp">... (200; 2.043784ms)
Sep 12 13:00:47.633: INFO: (12) /api/v1/nodes/caasp-worker-thehejik-0/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="btmp">... (200; 2.090047ms)
Sep 12 13:00:47.637: INFO: (13) /api/v1/nodes/caasp-worker-thehejik-0/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="btmp">... (200; 4.334741ms)
Sep 12 13:00:47.640: INFO: (14) /api/v1/nodes/caasp-worker-thehejik-0/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="btmp">... (200; 2.215324ms)
Sep 12 13:00:47.642: INFO: (15) /api/v1/nodes/caasp-worker-thehejik-0/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="btmp">... (200; 2.059851ms)
Sep 12 13:00:47.644: INFO: (16) /api/v1/nodes/caasp-worker-thehejik-0/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="btmp">... (200; 2.031394ms)
Sep 12 13:00:47.646: INFO: (17) /api/v1/nodes/caasp-worker-thehejik-0/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="btmp">... (200; 2.208341ms)
Sep 12 13:00:47.648: INFO: (18) /api/v1/nodes/caasp-worker-thehejik-0/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="btmp">... (200; 2.12904ms)
Sep 12 13:00:47.650: INFO: (19) /api/v1/nodes/caasp-worker-thehejik-0/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="btmp">... (200; 2.329534ms)
[AfterEach] version v1
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:00:47.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-8950" for this suite.
Sep 12 13:00:53.667: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:00:53.747: INFO: namespace proxy-8950 deletion completed in 6.094323723s

â€¢ [SLOW TEST:6.320 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:00:53.748: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1454
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep 12 13:00:53.905: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fddf4771-bbd3-4cbe-81eb-c27bd3d8acaf" in namespace "downward-api-1454" to be "success or failure"
Sep 12 13:00:53.915: INFO: Pod "downwardapi-volume-fddf4771-bbd3-4cbe-81eb-c27bd3d8acaf": Phase="Pending", Reason="", readiness=false. Elapsed: 9.626706ms
Sep 12 13:00:55.917: INFO: Pod "downwardapi-volume-fddf4771-bbd3-4cbe-81eb-c27bd3d8acaf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011742448s
Sep 12 13:00:57.920: INFO: Pod "downwardapi-volume-fddf4771-bbd3-4cbe-81eb-c27bd3d8acaf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014089561s
STEP: Saw pod success
Sep 12 13:00:57.920: INFO: Pod "downwardapi-volume-fddf4771-bbd3-4cbe-81eb-c27bd3d8acaf" satisfied condition "success or failure"
Sep 12 13:00:57.921: INFO: Trying to get logs from node caasp-worker-thehejik-4 pod downwardapi-volume-fddf4771-bbd3-4cbe-81eb-c27bd3d8acaf container client-container: <nil>
STEP: delete the pod
Sep 12 13:00:57.940: INFO: Waiting for pod downwardapi-volume-fddf4771-bbd3-4cbe-81eb-c27bd3d8acaf to disappear
Sep 12 13:00:57.975: INFO: Pod downwardapi-volume-fddf4771-bbd3-4cbe-81eb-c27bd3d8acaf no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:00:57.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1454" for this suite.
Sep 12 13:01:03.990: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:01:04.053: INFO: namespace downward-api-1454 deletion completed in 6.075635546s

â€¢ [SLOW TEST:10.305 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be submitted and removed  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:01:04.056: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-7789
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be submitted and removed  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:01:04.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7789" for this suite.
Sep 12 13:01:26.264: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:01:26.334: INFO: namespace pods-7789 deletion completed in 22.105091171s

â€¢ [SLOW TEST:22.278 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be submitted and removed  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:01:26.334: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4795
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1613
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep 12 13:01:26.516: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 run e2e-test-nginx-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-4795'
Sep 12 13:01:26.616: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep 12 13:01:26.616: INFO: stdout: "job.batch/e2e-test-nginx-job created\n"
STEP: verifying the job e2e-test-nginx-job was created
[AfterEach] [k8s.io] Kubectl run job
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1618
Sep 12 13:01:26.628: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 delete jobs e2e-test-nginx-job --namespace=kubectl-4795'
Sep 12 13:01:26.728: INFO: stderr: ""
Sep 12 13:01:26.728: INFO: stdout: "job.batch \"e2e-test-nginx-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:01:26.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4795" for this suite.
Sep 12 13:01:48.750: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:01:48.816: INFO: namespace kubectl-4795 deletion completed in 22.082924001s

â€¢ [SLOW TEST:22.482 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run job
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:01:48.816: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5530
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-5f27136d-5906-44b3-b76d-c656ef2a325d
STEP: Creating a pod to test consume secrets
Sep 12 13:01:48.988: INFO: Waiting up to 5m0s for pod "pod-secrets-83d4adbb-7a2d-4dbf-a1ab-05ef24d35221" in namespace "secrets-5530" to be "success or failure"
Sep 12 13:01:49.000: INFO: Pod "pod-secrets-83d4adbb-7a2d-4dbf-a1ab-05ef24d35221": Phase="Pending", Reason="", readiness=false. Elapsed: 11.285092ms
Sep 12 13:01:51.002: INFO: Pod "pod-secrets-83d4adbb-7a2d-4dbf-a1ab-05ef24d35221": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01355435s
Sep 12 13:01:53.004: INFO: Pod "pod-secrets-83d4adbb-7a2d-4dbf-a1ab-05ef24d35221": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015812027s
STEP: Saw pod success
Sep 12 13:01:53.004: INFO: Pod "pod-secrets-83d4adbb-7a2d-4dbf-a1ab-05ef24d35221" satisfied condition "success or failure"
Sep 12 13:01:53.006: INFO: Trying to get logs from node caasp-worker-thehejik-3 pod pod-secrets-83d4adbb-7a2d-4dbf-a1ab-05ef24d35221 container secret-volume-test: <nil>
STEP: delete the pod
Sep 12 13:01:53.026: INFO: Waiting for pod pod-secrets-83d4adbb-7a2d-4dbf-a1ab-05ef24d35221 to disappear
Sep 12 13:01:53.036: INFO: Pod pod-secrets-83d4adbb-7a2d-4dbf-a1ab-05ef24d35221 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:01:53.036: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5530" for this suite.
Sep 12 13:01:59.058: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:01:59.125: INFO: namespace secrets-5530 deletion completed in 6.086479075s

â€¢ [SLOW TEST:10.309 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:01:59.126: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3272
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the initial replication controller
Sep 12 13:01:59.289: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 create -f - --namespace=kubectl-3272'
Sep 12 13:01:59.626: INFO: stderr: ""
Sep 12 13:01:59.626: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep 12 13:01:59.626: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3272'
Sep 12 13:01:59.709: INFO: stderr: ""
Sep 12 13:01:59.709: INFO: stdout: "update-demo-nautilus-2rg7r update-demo-nautilus-scksd "
Sep 12 13:01:59.709: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get pods update-demo-nautilus-2rg7r -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3272'
Sep 12 13:01:59.801: INFO: stderr: ""
Sep 12 13:01:59.801: INFO: stdout: ""
Sep 12 13:01:59.801: INFO: update-demo-nautilus-2rg7r is created but not running
Sep 12 13:02:04.801: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3272'
Sep 12 13:02:04.886: INFO: stderr: ""
Sep 12 13:02:04.886: INFO: stdout: "update-demo-nautilus-2rg7r update-demo-nautilus-scksd "
Sep 12 13:02:04.886: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get pods update-demo-nautilus-2rg7r -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3272'
Sep 12 13:02:04.973: INFO: stderr: ""
Sep 12 13:02:04.973: INFO: stdout: "true"
Sep 12 13:02:04.973: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get pods update-demo-nautilus-2rg7r -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3272'
Sep 12 13:02:05.054: INFO: stderr: ""
Sep 12 13:02:05.054: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 12 13:02:05.055: INFO: validating pod update-demo-nautilus-2rg7r
Sep 12 13:02:05.058: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 12 13:02:05.058: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 12 13:02:05.058: INFO: update-demo-nautilus-2rg7r is verified up and running
Sep 12 13:02:05.058: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get pods update-demo-nautilus-scksd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3272'
Sep 12 13:02:05.144: INFO: stderr: ""
Sep 12 13:02:05.144: INFO: stdout: "true"
Sep 12 13:02:05.144: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get pods update-demo-nautilus-scksd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3272'
Sep 12 13:02:05.222: INFO: stderr: ""
Sep 12 13:02:05.222: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 12 13:02:05.222: INFO: validating pod update-demo-nautilus-scksd
Sep 12 13:02:05.225: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 12 13:02:05.225: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 12 13:02:05.225: INFO: update-demo-nautilus-scksd is verified up and running
STEP: rolling-update to new replication controller
Sep 12 13:02:05.227: INFO: scanned /root for discovery docs: <nil>
Sep 12 13:02:05.227: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-3272'
Sep 12 13:02:34.720: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Sep 12 13:02:34.720: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep 12 13:02:34.720: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3272'
Sep 12 13:02:34.806: INFO: stderr: ""
Sep 12 13:02:34.806: INFO: stdout: "update-demo-kitten-874bv update-demo-kitten-prkhm "
Sep 12 13:02:34.806: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get pods update-demo-kitten-874bv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3272'
Sep 12 13:02:34.892: INFO: stderr: ""
Sep 12 13:02:34.892: INFO: stdout: "true"
Sep 12 13:02:34.892: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get pods update-demo-kitten-874bv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3272'
Sep 12 13:02:34.972: INFO: stderr: ""
Sep 12 13:02:34.972: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Sep 12 13:02:34.972: INFO: validating pod update-demo-kitten-874bv
Sep 12 13:02:34.975: INFO: got data: {
  "image": "kitten.jpg"
}

Sep 12 13:02:34.976: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Sep 12 13:02:34.976: INFO: update-demo-kitten-874bv is verified up and running
Sep 12 13:02:34.976: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get pods update-demo-kitten-prkhm -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3272'
Sep 12 13:02:35.062: INFO: stderr: ""
Sep 12 13:02:35.062: INFO: stdout: "true"
Sep 12 13:02:35.062: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get pods update-demo-kitten-prkhm -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3272'
Sep 12 13:02:35.141: INFO: stderr: ""
Sep 12 13:02:35.141: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Sep 12 13:02:35.141: INFO: validating pod update-demo-kitten-prkhm
Sep 12 13:02:35.144: INFO: got data: {
  "image": "kitten.jpg"
}

Sep 12 13:02:35.144: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Sep 12 13:02:35.144: INFO: update-demo-kitten-prkhm is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:02:35.144: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3272" for this suite.
Sep 12 13:02:57.161: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:02:57.227: INFO: namespace kubectl-3272 deletion completed in 22.079688366s

â€¢ [SLOW TEST:58.101 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:02:57.227: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-3682
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Sep 12 13:02:57.386: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3682,SelfLink:/api/v1/namespaces/watch-3682/configmaps/e2e-watch-test-configmap-a,UID:ba8c13ca-1cd8-47aa-93cd-bdb52a0e92a5,ResourceVersion:20102,Generation:0,CreationTimestamp:2019-09-12 13:02:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep 12 13:02:57.386: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3682,SelfLink:/api/v1/namespaces/watch-3682/configmaps/e2e-watch-test-configmap-a,UID:ba8c13ca-1cd8-47aa-93cd-bdb52a0e92a5,ResourceVersion:20102,Generation:0,CreationTimestamp:2019-09-12 13:02:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Sep 12 13:03:07.392: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3682,SelfLink:/api/v1/namespaces/watch-3682/configmaps/e2e-watch-test-configmap-a,UID:ba8c13ca-1cd8-47aa-93cd-bdb52a0e92a5,ResourceVersion:20124,Generation:0,CreationTimestamp:2019-09-12 13:02:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Sep 12 13:03:07.392: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3682,SelfLink:/api/v1/namespaces/watch-3682/configmaps/e2e-watch-test-configmap-a,UID:ba8c13ca-1cd8-47aa-93cd-bdb52a0e92a5,ResourceVersion:20124,Generation:0,CreationTimestamp:2019-09-12 13:02:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Sep 12 13:03:17.397: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3682,SelfLink:/api/v1/namespaces/watch-3682/configmaps/e2e-watch-test-configmap-a,UID:ba8c13ca-1cd8-47aa-93cd-bdb52a0e92a5,ResourceVersion:20145,Generation:0,CreationTimestamp:2019-09-12 13:02:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep 12 13:03:17.397: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3682,SelfLink:/api/v1/namespaces/watch-3682/configmaps/e2e-watch-test-configmap-a,UID:ba8c13ca-1cd8-47aa-93cd-bdb52a0e92a5,ResourceVersion:20145,Generation:0,CreationTimestamp:2019-09-12 13:02:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Sep 12 13:03:27.401: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3682,SelfLink:/api/v1/namespaces/watch-3682/configmaps/e2e-watch-test-configmap-a,UID:ba8c13ca-1cd8-47aa-93cd-bdb52a0e92a5,ResourceVersion:20170,Generation:0,CreationTimestamp:2019-09-12 13:02:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep 12 13:03:27.401: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-a,GenerateName:,Namespace:watch-3682,SelfLink:/api/v1/namespaces/watch-3682/configmaps/e2e-watch-test-configmap-a,UID:ba8c13ca-1cd8-47aa-93cd-bdb52a0e92a5,ResourceVersion:20170,Generation:0,CreationTimestamp:2019-09-12 13:02:57 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-A,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Sep 12 13:03:37.406: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-3682,SelfLink:/api/v1/namespaces/watch-3682/configmaps/e2e-watch-test-configmap-b,UID:e891aab9-ab0d-4f5f-b285-e13d170b5f39,ResourceVersion:20193,Generation:0,CreationTimestamp:2019-09-12 13:03:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep 12 13:03:37.406: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-3682,SelfLink:/api/v1/namespaces/watch-3682/configmaps/e2e-watch-test-configmap-b,UID:e891aab9-ab0d-4f5f-b285-e13d170b5f39,ResourceVersion:20193,Generation:0,CreationTimestamp:2019-09-12 13:03:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Sep 12 13:03:47.411: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-3682,SelfLink:/api/v1/namespaces/watch-3682/configmaps/e2e-watch-test-configmap-b,UID:e891aab9-ab0d-4f5f-b285-e13d170b5f39,ResourceVersion:20220,Generation:0,CreationTimestamp:2019-09-12 13:03:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep 12 13:03:47.411: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-configmap-b,GenerateName:,Namespace:watch-3682,SelfLink:/api/v1/namespaces/watch-3682/configmaps/e2e-watch-test-configmap-b,UID:e891aab9-ab0d-4f5f-b285-e13d170b5f39,ResourceVersion:20220,Generation:0,CreationTimestamp:2019-09-12 13:03:37 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: multiple-watchers-B,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:03:57.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3682" for this suite.
Sep 12 13:04:03.443: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:04:03.512: INFO: namespace watch-3682 deletion completed in 6.097558647s

â€¢ [SLOW TEST:66.285 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:04:03.514: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8595
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir volume type on tmpfs
Sep 12 13:04:03.825: INFO: Waiting up to 5m0s for pod "pod-9a590a97-8926-4c38-a66a-df6d039d3a02" in namespace "emptydir-8595" to be "success or failure"
Sep 12 13:04:03.833: INFO: Pod "pod-9a590a97-8926-4c38-a66a-df6d039d3a02": Phase="Pending", Reason="", readiness=false. Elapsed: 8.788237ms
Sep 12 13:04:05.836: INFO: Pod "pod-9a590a97-8926-4c38-a66a-df6d039d3a02": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011326104s
Sep 12 13:04:07.839: INFO: Pod "pod-9a590a97-8926-4c38-a66a-df6d039d3a02": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013956097s
STEP: Saw pod success
Sep 12 13:04:07.839: INFO: Pod "pod-9a590a97-8926-4c38-a66a-df6d039d3a02" satisfied condition "success or failure"
Sep 12 13:04:07.841: INFO: Trying to get logs from node caasp-worker-thehejik-5 pod pod-9a590a97-8926-4c38-a66a-df6d039d3a02 container test-container: <nil>
STEP: delete the pod
Sep 12 13:04:07.862: INFO: Waiting for pod pod-9a590a97-8926-4c38-a66a-df6d039d3a02 to disappear
Sep 12 13:04:07.871: INFO: Pod pod-9a590a97-8926-4c38-a66a-df6d039d3a02 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:04:07.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8595" for this suite.
Sep 12 13:04:13.888: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:04:13.951: INFO: namespace emptydir-8595 deletion completed in 6.077327238s

â€¢ [SLOW TEST:10.438 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:04:13.952: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-7385
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test substitution in container's command
Sep 12 13:04:14.111: INFO: Waiting up to 5m0s for pod "var-expansion-205b17e2-df1d-46d9-8ab2-a421295c780f" in namespace "var-expansion-7385" to be "success or failure"
Sep 12 13:04:14.120: INFO: Pod "var-expansion-205b17e2-df1d-46d9-8ab2-a421295c780f": Phase="Pending", Reason="", readiness=false. Elapsed: 8.754706ms
Sep 12 13:04:16.122: INFO: Pod "var-expansion-205b17e2-df1d-46d9-8ab2-a421295c780f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010875943s
Sep 12 13:04:18.124: INFO: Pod "var-expansion-205b17e2-df1d-46d9-8ab2-a421295c780f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013157371s
STEP: Saw pod success
Sep 12 13:04:18.124: INFO: Pod "var-expansion-205b17e2-df1d-46d9-8ab2-a421295c780f" satisfied condition "success or failure"
Sep 12 13:04:18.126: INFO: Trying to get logs from node caasp-worker-thehejik-3 pod var-expansion-205b17e2-df1d-46d9-8ab2-a421295c780f container dapi-container: <nil>
STEP: delete the pod
Sep 12 13:04:18.210: INFO: Waiting for pod var-expansion-205b17e2-df1d-46d9-8ab2-a421295c780f to disappear
Sep 12 13:04:18.225: INFO: Pod var-expansion-205b17e2-df1d-46d9-8ab2-a421295c780f no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:04:18.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7385" for this suite.
Sep 12 13:04:24.289: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:04:24.368: INFO: namespace var-expansion-7385 deletion completed in 6.139731337s

â€¢ [SLOW TEST:10.416 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:04:24.370: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-9622
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: getting the auto-created API token
Sep 12 13:04:25.110: INFO: created pod pod-service-account-defaultsa
Sep 12 13:04:25.110: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Sep 12 13:04:25.122: INFO: created pod pod-service-account-mountsa
Sep 12 13:04:25.122: INFO: pod pod-service-account-mountsa service account token volume mount: true
Sep 12 13:04:25.133: INFO: created pod pod-service-account-nomountsa
Sep 12 13:04:25.133: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Sep 12 13:04:25.143: INFO: created pod pod-service-account-defaultsa-mountspec
Sep 12 13:04:25.143: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Sep 12 13:04:25.154: INFO: created pod pod-service-account-mountsa-mountspec
Sep 12 13:04:25.154: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Sep 12 13:04:25.168: INFO: created pod pod-service-account-nomountsa-mountspec
Sep 12 13:04:25.168: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Sep 12 13:04:25.248: INFO: created pod pod-service-account-defaultsa-nomountspec
Sep 12 13:04:25.248: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Sep 12 13:04:25.261: INFO: created pod pod-service-account-mountsa-nomountspec
Sep 12 13:04:25.261: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Sep 12 13:04:25.306: INFO: created pod pod-service-account-nomountsa-nomountspec
Sep 12 13:04:25.306: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:04:25.306: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-9622" for this suite.
Sep 12 13:04:31.367: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:04:31.431: INFO: namespace svcaccounts-9622 deletion completed in 6.110880633s

â€¢ [SLOW TEST:7.061 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:04:31.433: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-9588
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Sep 12 13:04:36.640: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:04:36.656: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-9588" for this suite.
Sep 12 13:04:58.731: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:04:58.796: INFO: namespace replicaset-9588 deletion completed in 22.12269289s

â€¢ [SLOW TEST:27.363 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:04:58.796: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5209
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-9d339a84-7583-4cec-ab2f-85396a432613
STEP: Creating a pod to test consume configMaps
Sep 12 13:04:58.970: INFO: Waiting up to 5m0s for pod "pod-configmaps-def87850-0104-48ed-a772-9bfd5d4c6232" in namespace "configmap-5209" to be "success or failure"
Sep 12 13:04:58.984: INFO: Pod "pod-configmaps-def87850-0104-48ed-a772-9bfd5d4c6232": Phase="Pending", Reason="", readiness=false. Elapsed: 13.680598ms
Sep 12 13:05:00.986: INFO: Pod "pod-configmaps-def87850-0104-48ed-a772-9bfd5d4c6232": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015874237s
Sep 12 13:05:02.988: INFO: Pod "pod-configmaps-def87850-0104-48ed-a772-9bfd5d4c6232": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018365433s
STEP: Saw pod success
Sep 12 13:05:02.988: INFO: Pod "pod-configmaps-def87850-0104-48ed-a772-9bfd5d4c6232" satisfied condition "success or failure"
Sep 12 13:05:02.990: INFO: Trying to get logs from node caasp-worker-thehejik-3 pod pod-configmaps-def87850-0104-48ed-a772-9bfd5d4c6232 container configmap-volume-test: <nil>
STEP: delete the pod
Sep 12 13:05:03.008: INFO: Waiting for pod pod-configmaps-def87850-0104-48ed-a772-9bfd5d4c6232 to disappear
Sep 12 13:05:03.021: INFO: Pod pod-configmaps-def87850-0104-48ed-a772-9bfd5d4c6232 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:05:03.021: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5209" for this suite.
Sep 12 13:05:09.044: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:05:09.107: INFO: namespace configmap-5209 deletion completed in 6.082482167s

â€¢ [SLOW TEST:10.311 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:05:09.108: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-7346
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:05:13.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7346" for this suite.
Sep 12 13:05:19.378: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:05:19.443: INFO: namespace kubelet-test-7346 deletion completed in 6.079929802s

â€¢ [SLOW TEST:10.335 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:05:19.443: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in hostpath-975
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test hostPath mode
Sep 12 13:05:19.618: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-975" to be "success or failure"
Sep 12 13:05:19.630: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 11.511963ms
Sep 12 13:05:21.633: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013949393s
Sep 12 13:05:23.635: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016135699s
STEP: Saw pod success
Sep 12 13:05:23.635: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Sep 12 13:05:23.636: INFO: Trying to get logs from node caasp-worker-thehejik-1 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Sep 12 13:05:23.660: INFO: Waiting for pod pod-host-path-test to disappear
Sep 12 13:05:23.674: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:05:23.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-975" for this suite.
Sep 12 13:05:29.692: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:05:29.755: INFO: namespace hostpath-975 deletion completed in 6.078110592s

â€¢ [SLOW TEST:10.313 seconds]
[sig-storage] HostPath
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:05:29.756: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-1054
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Sep 12 13:05:30.009: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep 12 13:05:30.014: INFO: Waiting for terminating namespaces to be deleted...
Sep 12 13:05:30.016: INFO: 
Logging pods the kubelet thinks is on node caasp-worker-thehejik-0 before test
Sep 12 13:05:30.022: INFO: kured-9wsvq from kube-system started at 2019-09-12 11:46:48 +0000 UTC (1 container statuses recorded)
Sep 12 13:05:30.022: INFO: 	Container kured ready: true, restart count 0
Sep 12 13:05:30.022: INFO: kube-proxy-qdt88 from kube-system started at 2019-09-12 11:43:47 +0000 UTC (1 container statuses recorded)
Sep 12 13:05:30.022: INFO: 	Container kube-proxy ready: true, restart count 0
Sep 12 13:05:30.022: INFO: cilium-vk48l from kube-system started at 2019-09-12 11:43:57 +0000 UTC (1 container statuses recorded)
Sep 12 13:05:30.022: INFO: 	Container cilium-agent ready: true, restart count 0
Sep 12 13:05:30.022: INFO: 
Logging pods the kubelet thinks is on node caasp-worker-thehejik-1 before test
Sep 12 13:05:30.026: INFO: kube-proxy-k72dc from kube-system started at 2019-09-12 11:43:45 +0000 UTC (1 container statuses recorded)
Sep 12 13:05:30.026: INFO: 	Container kube-proxy ready: true, restart count 0
Sep 12 13:05:30.026: INFO: cilium-xtjhr from kube-system started at 2019-09-12 11:43:56 +0000 UTC (1 container statuses recorded)
Sep 12 13:05:30.026: INFO: 	Container cilium-agent ready: true, restart count 0
Sep 12 13:05:30.026: INFO: kured-2pwbw from kube-system started at 2019-09-12 11:46:46 +0000 UTC (1 container statuses recorded)
Sep 12 13:05:30.026: INFO: 	Container kured ready: true, restart count 0
Sep 12 13:05:30.026: INFO: 
Logging pods the kubelet thinks is on node caasp-worker-thehejik-2 before test
Sep 12 13:05:30.032: INFO: kube-proxy-tbns9 from kube-system started at 2019-09-12 11:43:45 +0000 UTC (1 container statuses recorded)
Sep 12 13:05:30.032: INFO: 	Container kube-proxy ready: true, restart count 0
Sep 12 13:05:30.032: INFO: cilium-xpjlr from kube-system started at 2019-09-12 11:43:53 +0000 UTC (1 container statuses recorded)
Sep 12 13:05:30.032: INFO: 	Container cilium-agent ready: true, restart count 0
Sep 12 13:05:30.032: INFO: kured-2pbx6 from kube-system started at 2019-09-12 11:46:36 +0000 UTC (1 container statuses recorded)
Sep 12 13:05:30.032: INFO: 	Container kured ready: true, restart count 0
Sep 12 13:05:30.032: INFO: sonobuoy from heptio-sonobuoy started at 2019-09-12 12:14:35 +0000 UTC (1 container statuses recorded)
Sep 12 13:05:30.032: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Sep 12 13:05:30.032: INFO: 
Logging pods the kubelet thinks is on node caasp-worker-thehejik-3 before test
Sep 12 13:05:30.035: INFO: kube-proxy-czhcd from kube-system started at 2019-09-12 11:43:46 +0000 UTC (1 container statuses recorded)
Sep 12 13:05:30.036: INFO: 	Container kube-proxy ready: true, restart count 0
Sep 12 13:05:30.036: INFO: cilium-pn77w from kube-system started at 2019-09-12 11:43:56 +0000 UTC (1 container statuses recorded)
Sep 12 13:05:30.036: INFO: 	Container cilium-agent ready: true, restart count 0
Sep 12 13:05:30.036: INFO: kured-ltm4s from kube-system started at 2019-09-12 11:46:27 +0000 UTC (1 container statuses recorded)
Sep 12 13:05:30.036: INFO: 	Container kured ready: true, restart count 0
Sep 12 13:05:30.036: INFO: 
Logging pods the kubelet thinks is on node caasp-worker-thehejik-4 before test
Sep 12 13:05:30.040: INFO: sonobuoy-e2e-job-8e9197d567844860 from heptio-sonobuoy started at 2019-09-12 12:14:48 +0000 UTC (2 container statuses recorded)
Sep 12 13:05:30.040: INFO: 	Container e2e ready: true, restart count 0
Sep 12 13:05:30.040: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 12 13:05:30.040: INFO: kube-proxy-8gpcv from kube-system started at 2019-09-12 11:43:45 +0000 UTC (1 container statuses recorded)
Sep 12 13:05:30.040: INFO: 	Container kube-proxy ready: true, restart count 0
Sep 12 13:05:30.040: INFO: cilium-l8mbk from kube-system started at 2019-09-12 11:43:53 +0000 UTC (1 container statuses recorded)
Sep 12 13:05:30.040: INFO: 	Container cilium-agent ready: true, restart count 0
Sep 12 13:05:30.040: INFO: kured-7t64n from kube-system started at 2019-09-12 11:46:35 +0000 UTC (1 container statuses recorded)
Sep 12 13:05:30.040: INFO: 	Container kured ready: true, restart count 0
Sep 12 13:05:30.040: INFO: 
Logging pods the kubelet thinks is on node caasp-worker-thehejik-5 before test
Sep 12 13:05:30.044: INFO: oidc-gangway-7b7fbbdbdf-z6hhw from kube-system started at 2019-09-12 11:46:18 +0000 UTC (1 container statuses recorded)
Sep 12 13:05:30.044: INFO: 	Container oidc-gangway ready: true, restart count 0
Sep 12 13:05:30.044: INFO: kured-xqr4h from kube-system started at 2019-09-12 11:46:18 +0000 UTC (1 container statuses recorded)
Sep 12 13:05:30.044: INFO: 	Container kured ready: true, restart count 0
Sep 12 13:05:30.044: INFO: cilium-operator-7d6ddddbf5-qzx8w from kube-system started at 2019-09-12 11:46:19 +0000 UTC (1 container statuses recorded)
Sep 12 13:05:30.044: INFO: 	Container cilium-operator ready: true, restart count 0
Sep 12 13:05:30.044: INFO: oidc-dex-55fc689dc-6xcgj from kube-system started at 2019-09-12 11:46:19 +0000 UTC (1 container statuses recorded)
Sep 12 13:05:30.044: INFO: 	Container oidc-dex ready: true, restart count 1
Sep 12 13:05:30.044: INFO: kube-proxy-22pqk from kube-system started at 2019-09-12 11:43:46 +0000 UTC (1 container statuses recorded)
Sep 12 13:05:30.044: INFO: 	Container kube-proxy ready: true, restart count 0
Sep 12 13:05:30.044: INFO: cilium-r4htl from kube-system started at 2019-09-12 11:43:56 +0000 UTC (1 container statuses recorded)
Sep 12 13:05:30.044: INFO: 	Container cilium-agent ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-a8224309-d775-4436-9408-03d403602935 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-a8224309-d775-4436-9408-03d403602935 off the node caasp-worker-thehejik-4
STEP: verifying the node doesn't have the label kubernetes.io/e2e-a8224309-d775-4436-9408-03d403602935
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:05:42.140: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-1054" for this suite.
Sep 12 13:05:50.158: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:05:50.230: INFO: namespace sched-pred-1054 deletion completed in 8.086698189s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

â€¢ [SLOW TEST:20.474 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:05:50.230: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6679
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Sep 12 13:05:54.926: INFO: Successfully updated pod "annotationupdate37638fbb-5ccd-46b7-aaee-7a65f7a53275"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:05:56.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6679" for this suite.
Sep 12 13:06:19.033: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:06:19.101: INFO: namespace projected-6679 deletion completed in 22.140298548s

â€¢ [SLOW TEST:28.871 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:06:19.101: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-5515
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Sep 12 13:06:25.284: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:06:25.284: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W0912 13:06:25.284333      18 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-5515" for this suite.
Sep 12 13:06:31.303: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:06:31.389: INFO: namespace gc-5515 deletion completed in 6.101914199s

â€¢ [SLOW TEST:12.288 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:06:31.389: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9532
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 12 13:06:31.550: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 create -f - --namespace=kubectl-9532'
Sep 12 13:06:31.757: INFO: stderr: ""
Sep 12 13:06:31.757: INFO: stdout: "replicationcontroller/redis-master created\n"
Sep 12 13:06:31.757: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 create -f - --namespace=kubectl-9532'
Sep 12 13:06:31.959: INFO: stderr: ""
Sep 12 13:06:31.959: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Sep 12 13:06:32.962: INFO: Selector matched 1 pods for map[app:redis]
Sep 12 13:06:32.962: INFO: Found 0 / 1
Sep 12 13:06:33.961: INFO: Selector matched 1 pods for map[app:redis]
Sep 12 13:06:33.961: INFO: Found 0 / 1
Sep 12 13:06:34.961: INFO: Selector matched 1 pods for map[app:redis]
Sep 12 13:06:34.961: INFO: Found 1 / 1
Sep 12 13:06:34.961: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Sep 12 13:06:34.963: INFO: Selector matched 1 pods for map[app:redis]
Sep 12 13:06:34.963: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Sep 12 13:06:34.963: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 describe pod redis-master-whjwq --namespace=kubectl-9532'
Sep 12 13:06:35.054: INFO: stderr: ""
Sep 12 13:06:35.054: INFO: stdout: "Name:           redis-master-whjwq\nNamespace:      kubectl-9532\nPriority:       0\nNode:           caasp-worker-thehejik-4/10.84.72.31\nStart Time:     Thu, 12 Sep 2019 13:06:31 +0000\nLabels:         app=redis\n                role=master\nAnnotations:    kubernetes.io/psp: e2e-test-privileged-psp\nStatus:         Running\nIP:             10.244.2.73\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   cri-o://882a9c89e7da7af7119f87337d870dc073d71ff0af1592838d6273167ab85336\n    Image:          gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Image ID:       gcr.io/kubernetes-e2e-test-images/redis@sha256:2238f5a02d2648d41cc94a88f084060fbfa860890220328eb92696bf2ac649c9\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Thu, 12 Sep 2019 13:06:34 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-6rk6s (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-6rk6s:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-6rk6s\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                              Message\n  ----    ------     ----  ----                              -------\n  Normal  Scheduled  4s    default-scheduler                 Successfully assigned kubectl-9532/redis-master-whjwq to caasp-worker-thehejik-4\n  Normal  Pulled     2s    kubelet, caasp-worker-thehejik-4  Container image \"gcr.io/kubernetes-e2e-test-images/redis:1.0\" already present on machine\n  Normal  Created    1s    kubelet, caasp-worker-thehejik-4  Created container redis-master\n  Normal  Started    1s    kubelet, caasp-worker-thehejik-4  Started container redis-master\n"
Sep 12 13:06:35.054: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 describe rc redis-master --namespace=kubectl-9532'
Sep 12 13:06:35.165: INFO: stderr: ""
Sep 12 13:06:35.165: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-9532\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        gcr.io/kubernetes-e2e-test-images/redis:1.0\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  4s    replication-controller  Created pod: redis-master-whjwq\n"
Sep 12 13:06:35.165: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 describe service redis-master --namespace=kubectl-9532'
Sep 12 13:06:35.257: INFO: stderr: ""
Sep 12 13:06:35.257: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-9532\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.99.0.149\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.244.2.73:6379\nSession Affinity:  None\nEvents:            <none>\n"
Sep 12 13:06:35.260: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 describe node caasp-master-thehejik-0'
Sep 12 13:06:35.378: INFO: stderr: ""
Sep 12 13:06:35.378: INFO: stdout: "Name:               caasp-master-thehejik-0\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=caasp-master-thehejik-0\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/master=\nAnnotations:        io.cilium.network.ipv4-cilium-host: 10.244.0.1\n                    io.cilium.network.ipv4-health-ip: 10.244.0.66\n                    io.cilium.network.ipv4-pod-cidr: 10.244.0.0/24\n                    io.cilium.network.ipv6-cilium-host: f00d::af4:0:0:1\n                    io.cilium.network.ipv6-health-ip: f00d::af4:0:0:eda4\n                    io.cilium.network.ipv6-pod-cidr: f00d::af4:0:0:0/96\n                    kubeadm.alpha.kubernetes.io/cri-socket: /var/run/crio/crio.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Thu, 12 Sep 2019 11:41:23 +0000\nTaints:             node-role.kubernetes.io/master:NoSchedule\nUnschedulable:      false\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Thu, 12 Sep 2019 11:44:00 +0000   Thu, 12 Sep 2019 11:44:00 +0000   CiliumIsUp                   Cilium is running on this node\n  MemoryPressure       False   Thu, 12 Sep 2019 13:06:01 +0000   Thu, 12 Sep 2019 11:41:20 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Thu, 12 Sep 2019 13:06:01 +0000   Thu, 12 Sep 2019 11:41:20 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Thu, 12 Sep 2019 13:06:01 +0000   Thu, 12 Sep 2019 11:41:20 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Thu, 12 Sep 2019 13:06:01 +0000   Thu, 12 Sep 2019 11:42:53 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  10.84.73.253\n  Hostname:    caasp-master-thehejik-0\nCapacity:\n cpu:                4\n ephemeral-storage:  52391916Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             8159876Ki\n pods:               110\nAllocatable:\n cpu:                4\n ephemeral-storage:  48284389706\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             8057476Ki\n pods:               110\nSystem Info:\n Machine ID:                 a27a156d52894d9d9a13617d01eb8ef0\n System UUID:                4bfa2742-127b-9a17-13fb-ec5c93074b7a\n Boot ID:                    d2ab58a1-30e8-4b2b-b122-e9bcd1b9181d\n Kernel Version:             4.12.14-197.15-default\n OS Image:                   SUSE Linux Enterprise Server 15 SP1\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  cri-o://1.15.0\n Kubelet Version:            v1.15.2\n Kube-Proxy Version:         v1.15.2\nPodCIDR:                     10.244.0.0/24\nNon-terminated Pods:         (9 in total)\n  Namespace                  Name                                               CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                               ------------  ----------  ---------------  -------------  ---\n  kube-system                cilium-wjcw2                                       0 (0%)        0 (0%)      0 (0%)           0 (0%)         82m\n  kube-system                coredns-69c4947958-5wqff                           100m (2%)     0 (0%)      70Mi (0%)        170Mi (2%)     84m\n  kube-system                coredns-69c4947958-rcdvj                           100m (2%)     0 (0%)      70Mi (0%)        170Mi (2%)     84m\n  kube-system                etcd-caasp-master-thehejik-0                       0 (0%)        0 (0%)      0 (0%)           0 (0%)         84m\n  kube-system                kube-apiserver-caasp-master-thehejik-0             250m (6%)     0 (0%)      0 (0%)           0 (0%)         83m\n  kube-system                kube-controller-manager-caasp-master-thehejik-0    200m (5%)     0 (0%)      0 (0%)           0 (0%)         84m\n  kube-system                kube-proxy-k6rk6                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         84m\n  kube-system                kube-scheduler-caasp-master-thehejik-0             100m (2%)     0 (0%)      0 (0%)           0 (0%)         84m\n  kube-system                kured-fldwf                                        0 (0%)        0 (0%)      0 (0%)           0 (0%)         83m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                750m (18%)  0 (0%)\n  memory             140Mi (1%)  340Mi (4%)\n  ephemeral-storage  0 (0%)      0 (0%)\nEvents:              <none>\n"
Sep 12 13:06:35.378: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 describe namespace kubectl-9532'
Sep 12 13:06:35.474: INFO: stderr: ""
Sep 12 13:06:35.474: INFO: stdout: "Name:         kubectl-9532\nLabels:       e2e-framework=kubectl\n              e2e-run=7e793f64-50ee-40aa-bb42-1aebaf2b0988\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:06:35.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9532" for this suite.
Sep 12 13:06:57.491: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:06:57.644: INFO: namespace kubectl-9532 deletion completed in 22.167622309s

â€¢ [SLOW TEST:26.255 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl describe
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:06:57.645: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-1105
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Sep 12 13:06:57.802: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:07:02.602: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1105" for this suite.
Sep 12 13:07:08.628: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:07:08.696: INFO: namespace init-container-1105 deletion completed in 6.082381025s

â€¢ [SLOW TEST:11.051 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:07:08.697: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-8266
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Sep 12 13:07:16.902: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 12 13:07:16.913: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 12 13:07:18.913: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 12 13:07:18.916: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 12 13:07:20.913: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 12 13:07:20.915: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 12 13:07:22.913: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 12 13:07:22.915: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 12 13:07:24.913: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 12 13:07:24.915: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 12 13:07:26.913: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 12 13:07:26.916: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 12 13:07:28.913: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 12 13:07:28.922: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 12 13:07:30.913: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 12 13:07:30.924: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 12 13:07:32.913: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 12 13:07:32.922: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 12 13:07:34.913: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 12 13:07:34.916: INFO: Pod pod-with-prestop-exec-hook still exists
Sep 12 13:07:36.913: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Sep 12 13:07:36.919: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:07:36.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8266" for this suite.
Sep 12 13:07:58.941: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:07:59.027: INFO: namespace container-lifecycle-hook-8266 deletion completed in 22.101082213s

â€¢ [SLOW TEST:50.330 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:07:59.027: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-9616
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:88
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating service multi-endpoint-test in namespace services-9616
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9616 to expose endpoints map[]
Sep 12 13:07:59.220: INFO: Get endpoints failed (9.55849ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Sep 12 13:08:00.222: INFO: successfully validated that service multi-endpoint-test in namespace services-9616 exposes endpoints map[] (1.0115356s elapsed)
STEP: Creating pod pod1 in namespace services-9616
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9616 to expose endpoints map[pod1:[100]]
Sep 12 13:08:04.263: INFO: successfully validated that service multi-endpoint-test in namespace services-9616 exposes endpoints map[pod1:[100]] (4.036528462s elapsed)
STEP: Creating pod pod2 in namespace services-9616
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9616 to expose endpoints map[pod1:[100] pod2:[101]]
Sep 12 13:08:08.325: INFO: successfully validated that service multi-endpoint-test in namespace services-9616 exposes endpoints map[pod1:[100] pod2:[101]] (4.059182171s elapsed)
STEP: Deleting pod pod1 in namespace services-9616
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9616 to expose endpoints map[pod2:[101]]
Sep 12 13:08:09.362: INFO: successfully validated that service multi-endpoint-test in namespace services-9616 exposes endpoints map[pod2:[101]] (1.034160077s elapsed)
STEP: Deleting pod pod2 in namespace services-9616
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9616 to expose endpoints map[]
Sep 12 13:08:10.381: INFO: successfully validated that service multi-endpoint-test in namespace services-9616 exposes endpoints map[] (1.015092071s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:08:10.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9616" for this suite.
Sep 12 13:08:26.457: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:08:26.524: INFO: namespace services-9616 deletion completed in 16.080177122s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:92

â€¢ [SLOW TEST:27.498 seconds]
[sig-network] Services
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:08:26.526: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4611
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Sep 12 13:08:31.220: INFO: Successfully updated pod "labelsupdate92ca9df7-f9b5-4235-8d1c-490752ba50bd"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:08:33.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4611" for this suite.
Sep 12 13:08:55.263: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:08:55.330: INFO: namespace projected-4611 deletion completed in 22.081253194s

â€¢ [SLOW TEST:28.805 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:08:55.331: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-3952
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test override all
Sep 12 13:08:55.510: INFO: Waiting up to 5m0s for pod "client-containers-7eacba7e-7a1e-4b78-8021-94e49f4311be" in namespace "containers-3952" to be "success or failure"
Sep 12 13:08:55.519: INFO: Pod "client-containers-7eacba7e-7a1e-4b78-8021-94e49f4311be": Phase="Pending", Reason="", readiness=false. Elapsed: 9.163278ms
Sep 12 13:08:57.523: INFO: Pod "client-containers-7eacba7e-7a1e-4b78-8021-94e49f4311be": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012354192s
Sep 12 13:08:59.525: INFO: Pod "client-containers-7eacba7e-7a1e-4b78-8021-94e49f4311be": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01507828s
STEP: Saw pod success
Sep 12 13:08:59.526: INFO: Pod "client-containers-7eacba7e-7a1e-4b78-8021-94e49f4311be" satisfied condition "success or failure"
Sep 12 13:08:59.527: INFO: Trying to get logs from node caasp-worker-thehejik-1 pod client-containers-7eacba7e-7a1e-4b78-8021-94e49f4311be container test-container: <nil>
STEP: delete the pod
Sep 12 13:08:59.545: INFO: Waiting for pod client-containers-7eacba7e-7a1e-4b78-8021-94e49f4311be to disappear
Sep 12 13:08:59.552: INFO: Pod client-containers-7eacba7e-7a1e-4b78-8021-94e49f4311be no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:08:59.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3952" for this suite.
Sep 12 13:09:05.571: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:09:05.637: INFO: namespace containers-3952 deletion completed in 6.08222193s

â€¢ [SLOW TEST:10.307 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:09:05.637: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4904
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap that has name configmap-test-emptyKey-4dbf1ba2-7b74-4a33-98f8-bbdc2441646e
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:09:05.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4904" for this suite.
Sep 12 13:09:11.834: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:09:11.899: INFO: namespace configmap-4904 deletion completed in 6.080544847s

â€¢ [SLOW TEST:6.262 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:09:11.899: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6638
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on tmpfs
Sep 12 13:09:12.067: INFO: Waiting up to 5m0s for pod "pod-6b19bbd8-280f-4267-942d-5fbaa19e9a77" in namespace "emptydir-6638" to be "success or failure"
Sep 12 13:09:12.135: INFO: Pod "pod-6b19bbd8-280f-4267-942d-5fbaa19e9a77": Phase="Pending", Reason="", readiness=false. Elapsed: 67.96033ms
Sep 12 13:09:14.138: INFO: Pod "pod-6b19bbd8-280f-4267-942d-5fbaa19e9a77": Phase="Pending", Reason="", readiness=false. Elapsed: 2.070423949s
Sep 12 13:09:16.147: INFO: Pod "pod-6b19bbd8-280f-4267-942d-5fbaa19e9a77": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.080127538s
STEP: Saw pod success
Sep 12 13:09:16.147: INFO: Pod "pod-6b19bbd8-280f-4267-942d-5fbaa19e9a77" satisfied condition "success or failure"
Sep 12 13:09:16.149: INFO: Trying to get logs from node caasp-worker-thehejik-5 pod pod-6b19bbd8-280f-4267-942d-5fbaa19e9a77 container test-container: <nil>
STEP: delete the pod
Sep 12 13:09:16.171: INFO: Waiting for pod pod-6b19bbd8-280f-4267-942d-5fbaa19e9a77 to disappear
Sep 12 13:09:16.181: INFO: Pod pod-6b19bbd8-280f-4267-942d-5fbaa19e9a77 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:09:16.181: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6638" for this suite.
Sep 12 13:09:22.207: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:09:22.280: INFO: namespace emptydir-6638 deletion completed in 6.095513646s

â€¢ [SLOW TEST:10.380 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:09:22.281: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6497
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on node default medium
Sep 12 13:09:22.446: INFO: Waiting up to 5m0s for pod "pod-980c1cb2-4520-4998-b479-46872e91f0d0" in namespace "emptydir-6497" to be "success or failure"
Sep 12 13:09:22.525: INFO: Pod "pod-980c1cb2-4520-4998-b479-46872e91f0d0": Phase="Pending", Reason="", readiness=false. Elapsed: 79.403939ms
Sep 12 13:09:24.528: INFO: Pod "pod-980c1cb2-4520-4998-b479-46872e91f0d0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.082075951s
Sep 12 13:09:26.530: INFO: Pod "pod-980c1cb2-4520-4998-b479-46872e91f0d0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.084557965s
STEP: Saw pod success
Sep 12 13:09:26.530: INFO: Pod "pod-980c1cb2-4520-4998-b479-46872e91f0d0" satisfied condition "success or failure"
Sep 12 13:09:26.532: INFO: Trying to get logs from node caasp-worker-thehejik-3 pod pod-980c1cb2-4520-4998-b479-46872e91f0d0 container test-container: <nil>
STEP: delete the pod
Sep 12 13:09:26.556: INFO: Waiting for pod pod-980c1cb2-4520-4998-b479-46872e91f0d0 to disappear
Sep 12 13:09:26.567: INFO: Pod pod-980c1cb2-4520-4998-b479-46872e91f0d0 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:09:26.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6497" for this suite.
Sep 12 13:09:32.583: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:09:32.654: INFO: namespace emptydir-6497 deletion completed in 6.084609978s

â€¢ [SLOW TEST:10.374 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:09:32.655: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-3570
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Sep 12 13:09:32.817: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:09:47.649: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3570" for this suite.
Sep 12 13:09:53.665: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:09:53.728: INFO: namespace pods-3570 deletion completed in 6.075935847s

â€¢ [SLOW TEST:21.073 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:09:53.728: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-3104
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
Sep 12 13:09:54.922: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0912 13:09:54.922552      18 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:09:54.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3104" for this suite.
Sep 12 13:10:00.943: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:10:01.011: INFO: namespace gc-3104 deletion completed in 6.085424658s

â€¢ [SLOW TEST:7.283 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:10:01.011: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6530
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-upd-80486518-7f1a-4f55-abf2-865df05510f5
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-80486518-7f1a-4f55-abf2-865df05510f5
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:11:21.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6530" for this suite.
Sep 12 13:11:43.446: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:11:43.521: INFO: namespace configmap-6530 deletion completed in 22.088212518s

â€¢ [SLOW TEST:102.510 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:11:43.521: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-4772
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:81
Sep 12 13:11:43.788: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Sep 12 13:11:43.794: INFO: Waiting for terminating namespaces to be deleted...
Sep 12 13:11:43.795: INFO: 
Logging pods the kubelet thinks is on node caasp-worker-thehejik-0 before test
Sep 12 13:11:43.801: INFO: kube-proxy-qdt88 from kube-system started at 2019-09-12 11:43:47 +0000 UTC (1 container statuses recorded)
Sep 12 13:11:43.801: INFO: 	Container kube-proxy ready: true, restart count 0
Sep 12 13:11:43.801: INFO: cilium-vk48l from kube-system started at 2019-09-12 11:43:57 +0000 UTC (1 container statuses recorded)
Sep 12 13:11:43.801: INFO: 	Container cilium-agent ready: true, restart count 0
Sep 12 13:11:43.801: INFO: kured-9wsvq from kube-system started at 2019-09-12 11:46:48 +0000 UTC (1 container statuses recorded)
Sep 12 13:11:43.801: INFO: 	Container kured ready: true, restart count 0
Sep 12 13:11:43.801: INFO: 
Logging pods the kubelet thinks is on node caasp-worker-thehejik-1 before test
Sep 12 13:11:43.804: INFO: kube-proxy-k72dc from kube-system started at 2019-09-12 11:43:45 +0000 UTC (1 container statuses recorded)
Sep 12 13:11:43.804: INFO: 	Container kube-proxy ready: true, restart count 0
Sep 12 13:11:43.804: INFO: cilium-xtjhr from kube-system started at 2019-09-12 11:43:56 +0000 UTC (1 container statuses recorded)
Sep 12 13:11:43.804: INFO: 	Container cilium-agent ready: true, restart count 0
Sep 12 13:11:43.804: INFO: kured-2pwbw from kube-system started at 2019-09-12 11:46:46 +0000 UTC (1 container statuses recorded)
Sep 12 13:11:43.805: INFO: 	Container kured ready: true, restart count 0
Sep 12 13:11:43.805: INFO: 
Logging pods the kubelet thinks is on node caasp-worker-thehejik-2 before test
Sep 12 13:11:43.811: INFO: kube-proxy-tbns9 from kube-system started at 2019-09-12 11:43:45 +0000 UTC (1 container statuses recorded)
Sep 12 13:11:43.811: INFO: 	Container kube-proxy ready: true, restart count 0
Sep 12 13:11:43.811: INFO: cilium-xpjlr from kube-system started at 2019-09-12 11:43:53 +0000 UTC (1 container statuses recorded)
Sep 12 13:11:43.811: INFO: 	Container cilium-agent ready: true, restart count 0
Sep 12 13:11:43.811: INFO: kured-2pbx6 from kube-system started at 2019-09-12 11:46:36 +0000 UTC (1 container statuses recorded)
Sep 12 13:11:43.811: INFO: 	Container kured ready: true, restart count 0
Sep 12 13:11:43.811: INFO: sonobuoy from heptio-sonobuoy started at 2019-09-12 12:14:35 +0000 UTC (1 container statuses recorded)
Sep 12 13:11:43.811: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Sep 12 13:11:43.811: INFO: 
Logging pods the kubelet thinks is on node caasp-worker-thehejik-3 before test
Sep 12 13:11:43.815: INFO: kured-ltm4s from kube-system started at 2019-09-12 11:46:27 +0000 UTC (1 container statuses recorded)
Sep 12 13:11:43.815: INFO: 	Container kured ready: true, restart count 0
Sep 12 13:11:43.815: INFO: kube-proxy-czhcd from kube-system started at 2019-09-12 11:43:46 +0000 UTC (1 container statuses recorded)
Sep 12 13:11:43.815: INFO: 	Container kube-proxy ready: true, restart count 0
Sep 12 13:11:43.815: INFO: cilium-pn77w from kube-system started at 2019-09-12 11:43:56 +0000 UTC (1 container statuses recorded)
Sep 12 13:11:43.815: INFO: 	Container cilium-agent ready: true, restart count 0
Sep 12 13:11:43.815: INFO: 
Logging pods the kubelet thinks is on node caasp-worker-thehejik-4 before test
Sep 12 13:11:43.820: INFO: kured-7t64n from kube-system started at 2019-09-12 11:46:35 +0000 UTC (1 container statuses recorded)
Sep 12 13:11:43.820: INFO: 	Container kured ready: true, restart count 0
Sep 12 13:11:43.820: INFO: sonobuoy-e2e-job-8e9197d567844860 from heptio-sonobuoy started at 2019-09-12 12:14:48 +0000 UTC (2 container statuses recorded)
Sep 12 13:11:43.820: INFO: 	Container e2e ready: true, restart count 0
Sep 12 13:11:43.820: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Sep 12 13:11:43.820: INFO: kube-proxy-8gpcv from kube-system started at 2019-09-12 11:43:45 +0000 UTC (1 container statuses recorded)
Sep 12 13:11:43.820: INFO: 	Container kube-proxy ready: true, restart count 0
Sep 12 13:11:43.820: INFO: cilium-l8mbk from kube-system started at 2019-09-12 11:43:53 +0000 UTC (1 container statuses recorded)
Sep 12 13:11:43.820: INFO: 	Container cilium-agent ready: true, restart count 0
Sep 12 13:11:43.820: INFO: 
Logging pods the kubelet thinks is on node caasp-worker-thehejik-5 before test
Sep 12 13:11:43.825: INFO: kube-proxy-22pqk from kube-system started at 2019-09-12 11:43:46 +0000 UTC (1 container statuses recorded)
Sep 12 13:11:43.825: INFO: 	Container kube-proxy ready: true, restart count 0
Sep 12 13:11:43.825: INFO: cilium-r4htl from kube-system started at 2019-09-12 11:43:56 +0000 UTC (1 container statuses recorded)
Sep 12 13:11:43.825: INFO: 	Container cilium-agent ready: true, restart count 0
Sep 12 13:11:43.825: INFO: oidc-gangway-7b7fbbdbdf-z6hhw from kube-system started at 2019-09-12 11:46:18 +0000 UTC (1 container statuses recorded)
Sep 12 13:11:43.825: INFO: 	Container oidc-gangway ready: true, restart count 0
Sep 12 13:11:43.825: INFO: kured-xqr4h from kube-system started at 2019-09-12 11:46:18 +0000 UTC (1 container statuses recorded)
Sep 12 13:11:43.825: INFO: 	Container kured ready: true, restart count 0
Sep 12 13:11:43.825: INFO: cilium-operator-7d6ddddbf5-qzx8w from kube-system started at 2019-09-12 11:46:19 +0000 UTC (1 container statuses recorded)
Sep 12 13:11:43.825: INFO: 	Container cilium-operator ready: true, restart count 0
Sep 12 13:11:43.825: INFO: oidc-dex-55fc689dc-6xcgj from kube-system started at 2019-09-12 11:46:19 +0000 UTC (1 container statuses recorded)
Sep 12 13:11:43.825: INFO: 	Container oidc-dex ready: true, restart count 1
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: verifying the node has the label node caasp-worker-thehejik-0
STEP: verifying the node has the label node caasp-worker-thehejik-1
STEP: verifying the node has the label node caasp-worker-thehejik-2
STEP: verifying the node has the label node caasp-worker-thehejik-3
STEP: verifying the node has the label node caasp-worker-thehejik-4
STEP: verifying the node has the label node caasp-worker-thehejik-5
Sep 12 13:11:43.920: INFO: Pod sonobuoy requesting resource cpu=0m on Node caasp-worker-thehejik-2
Sep 12 13:11:43.920: INFO: Pod sonobuoy-e2e-job-8e9197d567844860 requesting resource cpu=0m on Node caasp-worker-thehejik-4
Sep 12 13:11:43.920: INFO: Pod cilium-l8mbk requesting resource cpu=0m on Node caasp-worker-thehejik-4
Sep 12 13:11:43.920: INFO: Pod cilium-operator-7d6ddddbf5-qzx8w requesting resource cpu=0m on Node caasp-worker-thehejik-5
Sep 12 13:11:43.920: INFO: Pod cilium-pn77w requesting resource cpu=0m on Node caasp-worker-thehejik-3
Sep 12 13:11:43.920: INFO: Pod cilium-r4htl requesting resource cpu=0m on Node caasp-worker-thehejik-5
Sep 12 13:11:43.920: INFO: Pod cilium-vk48l requesting resource cpu=0m on Node caasp-worker-thehejik-0
Sep 12 13:11:43.920: INFO: Pod cilium-xpjlr requesting resource cpu=0m on Node caasp-worker-thehejik-2
Sep 12 13:11:43.920: INFO: Pod cilium-xtjhr requesting resource cpu=0m on Node caasp-worker-thehejik-1
Sep 12 13:11:43.920: INFO: Pod kube-proxy-22pqk requesting resource cpu=0m on Node caasp-worker-thehejik-5
Sep 12 13:11:43.920: INFO: Pod kube-proxy-8gpcv requesting resource cpu=0m on Node caasp-worker-thehejik-4
Sep 12 13:11:43.920: INFO: Pod kube-proxy-czhcd requesting resource cpu=0m on Node caasp-worker-thehejik-3
Sep 12 13:11:43.920: INFO: Pod kube-proxy-k72dc requesting resource cpu=0m on Node caasp-worker-thehejik-1
Sep 12 13:11:43.920: INFO: Pod kube-proxy-qdt88 requesting resource cpu=0m on Node caasp-worker-thehejik-0
Sep 12 13:11:43.920: INFO: Pod kube-proxy-tbns9 requesting resource cpu=0m on Node caasp-worker-thehejik-2
Sep 12 13:11:43.920: INFO: Pod kured-2pbx6 requesting resource cpu=0m on Node caasp-worker-thehejik-2
Sep 12 13:11:43.920: INFO: Pod kured-2pwbw requesting resource cpu=0m on Node caasp-worker-thehejik-1
Sep 12 13:11:43.920: INFO: Pod kured-7t64n requesting resource cpu=0m on Node caasp-worker-thehejik-4
Sep 12 13:11:43.920: INFO: Pod kured-9wsvq requesting resource cpu=0m on Node caasp-worker-thehejik-0
Sep 12 13:11:43.920: INFO: Pod kured-ltm4s requesting resource cpu=0m on Node caasp-worker-thehejik-3
Sep 12 13:11:43.920: INFO: Pod kured-xqr4h requesting resource cpu=0m on Node caasp-worker-thehejik-5
Sep 12 13:11:43.920: INFO: Pod oidc-dex-55fc689dc-6xcgj requesting resource cpu=0m on Node caasp-worker-thehejik-5
Sep 12 13:11:43.920: INFO: Pod oidc-gangway-7b7fbbdbdf-z6hhw requesting resource cpu=0m on Node caasp-worker-thehejik-5
STEP: Starting Pods to consume most of the cluster CPU.
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0b61972d-337c-4ffc-8a4c-45ada56c3912.15c3b2ff1acd8d3c], Reason = [Scheduled], Message = [Successfully assigned sched-pred-4772/filler-pod-0b61972d-337c-4ffc-8a4c-45ada56c3912 to caasp-worker-thehejik-4]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0b61972d-337c-4ffc-8a4c-45ada56c3912.15c3b2ff9cd09c11], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0b61972d-337c-4ffc-8a4c-45ada56c3912.15c3b2ffa3d673e2], Reason = [Created], Message = [Created container filler-pod-0b61972d-337c-4ffc-8a4c-45ada56c3912]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-0b61972d-337c-4ffc-8a4c-45ada56c3912.15c3b2ffa6d9a13d], Reason = [Started], Message = [Started container filler-pod-0b61972d-337c-4ffc-8a4c-45ada56c3912]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3c76b271-e37d-4ec9-82f2-c7d25ee9dabf.15c3b2ff19d795e4], Reason = [Scheduled], Message = [Successfully assigned sched-pred-4772/filler-pod-3c76b271-e37d-4ec9-82f2-c7d25ee9dabf to caasp-worker-thehejik-3]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3c76b271-e37d-4ec9-82f2-c7d25ee9dabf.15c3b2ff9b00d7c4], Reason = [Pulling], Message = [Pulling image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3c76b271-e37d-4ec9-82f2-c7d25ee9dabf.15c3b30088e013ec], Reason = [Pulled], Message = [Successfully pulled image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3c76b271-e37d-4ec9-82f2-c7d25ee9dabf.15c3b3008e5236f9], Reason = [Created], Message = [Created container filler-pod-3c76b271-e37d-4ec9-82f2-c7d25ee9dabf]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3c76b271-e37d-4ec9-82f2-c7d25ee9dabf.15c3b3008fdf7e0e], Reason = [Started], Message = [Started container filler-pod-3c76b271-e37d-4ec9-82f2-c7d25ee9dabf]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-61ef26df-e48f-4778-9f04-54838d51f78b.15c3b2ff18cc15cc], Reason = [Scheduled], Message = [Successfully assigned sched-pred-4772/filler-pod-61ef26df-e48f-4778-9f04-54838d51f78b to caasp-worker-thehejik-1]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-61ef26df-e48f-4778-9f04-54838d51f78b.15c3b2ff9df42c3b], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-61ef26df-e48f-4778-9f04-54838d51f78b.15c3b2ffa41aed07], Reason = [Created], Message = [Created container filler-pod-61ef26df-e48f-4778-9f04-54838d51f78b]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-61ef26df-e48f-4778-9f04-54838d51f78b.15c3b2ffab2cc2ac], Reason = [Started], Message = [Started container filler-pod-61ef26df-e48f-4778-9f04-54838d51f78b]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-84a6fc55-fa96-409a-ba87-81eb6d45e24a.15c3b2ff1752b9f3], Reason = [Scheduled], Message = [Successfully assigned sched-pred-4772/filler-pod-84a6fc55-fa96-409a-ba87-81eb6d45e24a to caasp-worker-thehejik-5]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-84a6fc55-fa96-409a-ba87-81eb6d45e24a.15c3b2ff9345826d], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-84a6fc55-fa96-409a-ba87-81eb6d45e24a.15c3b2ff9956b9be], Reason = [Created], Message = [Created container filler-pod-84a6fc55-fa96-409a-ba87-81eb6d45e24a]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-84a6fc55-fa96-409a-ba87-81eb6d45e24a.15c3b2ffa1911c19], Reason = [Started], Message = [Started container filler-pod-84a6fc55-fa96-409a-ba87-81eb6d45e24a]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c8ce12f1-0a30-470c-bce9-f114d230e756.15c3b2ff1828e9b1], Reason = [Scheduled], Message = [Successfully assigned sched-pred-4772/filler-pod-c8ce12f1-0a30-470c-bce9-f114d230e756 to caasp-worker-thehejik-0]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c8ce12f1-0a30-470c-bce9-f114d230e756.15c3b2ff968e8b61], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c8ce12f1-0a30-470c-bce9-f114d230e756.15c3b2ff9bf99fd9], Reason = [Created], Message = [Created container filler-pod-c8ce12f1-0a30-470c-bce9-f114d230e756]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c8ce12f1-0a30-470c-bce9-f114d230e756.15c3b2ff9dc03e52], Reason = [Started], Message = [Started container filler-pod-c8ce12f1-0a30-470c-bce9-f114d230e756]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e04f9d5d-5286-4d42-991d-ac390b829706.15c3b2ff196ab8d1], Reason = [Scheduled], Message = [Successfully assigned sched-pred-4772/filler-pod-e04f9d5d-5286-4d42-991d-ac390b829706 to caasp-worker-thehejik-2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e04f9d5d-5286-4d42-991d-ac390b829706.15c3b2ffa822606f], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e04f9d5d-5286-4d42-991d-ac390b829706.15c3b2ffb3306ef1], Reason = [Created], Message = [Created container filler-pod-e04f9d5d-5286-4d42-991d-ac390b829706]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e04f9d5d-5286-4d42-991d-ac390b829706.15c3b2ffb576c92c], Reason = [Started], Message = [Started container filler-pod-e04f9d5d-5286-4d42-991d-ac390b829706]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15c3b300f8c7abc1], Reason = [FailedScheduling], Message = [0/7 nodes are available: 1 node(s) had taints that the pod didn't tolerate, 6 Insufficient cpu.]
STEP: removing the label node off the node caasp-worker-thehejik-5
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node caasp-worker-thehejik-0
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node caasp-worker-thehejik-1
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node caasp-worker-thehejik-2
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node caasp-worker-thehejik-3
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node caasp-worker-thehejik-4
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:11:53.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4772" for this suite.
Sep 12 13:11:59.241: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:11:59.308: INFO: namespace sched-pred-4772 deletion completed in 6.081146768s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:72

â€¢ [SLOW TEST:15.787 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:11:59.309: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1040
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-dba149bd-bbdf-4312-b4d4-30330c6c1b2a
STEP: Creating a pod to test consume secrets
Sep 12 13:11:59.476: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-eddcae71-5c71-43a3-a74b-951670096154" in namespace "projected-1040" to be "success or failure"
Sep 12 13:11:59.488: INFO: Pod "pod-projected-secrets-eddcae71-5c71-43a3-a74b-951670096154": Phase="Pending", Reason="", readiness=false. Elapsed: 12.353771ms
Sep 12 13:12:01.493: INFO: Pod "pod-projected-secrets-eddcae71-5c71-43a3-a74b-951670096154": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017412897s
Sep 12 13:12:03.496: INFO: Pod "pod-projected-secrets-eddcae71-5c71-43a3-a74b-951670096154": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01988413s
STEP: Saw pod success
Sep 12 13:12:03.496: INFO: Pod "pod-projected-secrets-eddcae71-5c71-43a3-a74b-951670096154" satisfied condition "success or failure"
Sep 12 13:12:03.498: INFO: Trying to get logs from node caasp-worker-thehejik-4 pod pod-projected-secrets-eddcae71-5c71-43a3-a74b-951670096154 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep 12 13:12:03.621: INFO: Waiting for pod pod-projected-secrets-eddcae71-5c71-43a3-a74b-951670096154 to disappear
Sep 12 13:12:03.695: INFO: Pod pod-projected-secrets-eddcae71-5c71-43a3-a74b-951670096154 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:12:03.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1040" for this suite.
Sep 12 13:12:09.712: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:12:09.779: INFO: namespace projected-1040 deletion completed in 6.080968859s

â€¢ [SLOW TEST:10.471 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:12:09.780: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7832
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep 12 13:12:09.960: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5d5222ad-2cc6-4a7a-b578-5cfd2fd5159b" in namespace "projected-7832" to be "success or failure"
Sep 12 13:12:09.972: INFO: Pod "downwardapi-volume-5d5222ad-2cc6-4a7a-b578-5cfd2fd5159b": Phase="Pending", Reason="", readiness=false. Elapsed: 12.015884ms
Sep 12 13:12:11.974: INFO: Pod "downwardapi-volume-5d5222ad-2cc6-4a7a-b578-5cfd2fd5159b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014065476s
Sep 12 13:12:13.977: INFO: Pod "downwardapi-volume-5d5222ad-2cc6-4a7a-b578-5cfd2fd5159b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016498036s
STEP: Saw pod success
Sep 12 13:12:13.977: INFO: Pod "downwardapi-volume-5d5222ad-2cc6-4a7a-b578-5cfd2fd5159b" satisfied condition "success or failure"
Sep 12 13:12:13.978: INFO: Trying to get logs from node caasp-worker-thehejik-3 pod downwardapi-volume-5d5222ad-2cc6-4a7a-b578-5cfd2fd5159b container client-container: <nil>
STEP: delete the pod
Sep 12 13:12:13.996: INFO: Waiting for pod downwardapi-volume-5d5222ad-2cc6-4a7a-b578-5cfd2fd5159b to disappear
Sep 12 13:12:14.008: INFO: Pod downwardapi-volume-5d5222ad-2cc6-4a7a-b578-5cfd2fd5159b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:12:14.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7832" for this suite.
Sep 12 13:12:20.057: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:12:20.121: INFO: namespace projected-7832 deletion completed in 6.110579067s

â€¢ [SLOW TEST:10.341 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:12:20.122: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-4720
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4720.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-4720.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4720.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-4720.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4720.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-4720.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4720.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-4720.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4720.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-4720.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4720.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-4720.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4720.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 146.147.111.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.111.147.146_udp@PTR;check="$$(dig +tcp +noall +answer +search 146.147.111.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.111.147.146_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4720.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-4720.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4720.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-4720.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4720.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-4720.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4720.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-4720.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4720.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-4720.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4720.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-4720.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4720.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 146.147.111.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.111.147.146_udp@PTR;check="$$(dig +tcp +noall +answer +search 146.147.111.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.111.147.146_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 12 13:12:24.440: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4720.svc.cluster.local from pod dns-4720/dns-test-f897adb4-efa2-4b71-a7af-74db43dc76e5: the server could not find the requested resource (get pods dns-test-f897adb4-efa2-4b71-a7af-74db43dc76e5)
Sep 12 13:12:24.456: INFO: Unable to read jessie_tcp@dns-test-service.dns-4720.svc.cluster.local from pod dns-4720/dns-test-f897adb4-efa2-4b71-a7af-74db43dc76e5: the server could not find the requested resource (get pods dns-test-f897adb4-efa2-4b71-a7af-74db43dc76e5)
Sep 12 13:12:24.458: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4720.svc.cluster.local from pod dns-4720/dns-test-f897adb4-efa2-4b71-a7af-74db43dc76e5: the server could not find the requested resource (get pods dns-test-f897adb4-efa2-4b71-a7af-74db43dc76e5)
Sep 12 13:12:24.460: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4720.svc.cluster.local from pod dns-4720/dns-test-f897adb4-efa2-4b71-a7af-74db43dc76e5: the server could not find the requested resource (get pods dns-test-f897adb4-efa2-4b71-a7af-74db43dc76e5)
Sep 12 13:12:24.473: INFO: Lookups using dns-4720/dns-test-f897adb4-efa2-4b71-a7af-74db43dc76e5 failed for: [wheezy_tcp@_http._tcp.dns-test-service.dns-4720.svc.cluster.local jessie_tcp@dns-test-service.dns-4720.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4720.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4720.svc.cluster.local]

Sep 12 13:12:29.519: INFO: DNS probes using dns-4720/dns-test-f897adb4-efa2-4b71-a7af-74db43dc76e5 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:12:29.925: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4720" for this suite.
Sep 12 13:12:35.955: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:12:36.032: INFO: namespace dns-4720 deletion completed in 6.097365018s

â€¢ [SLOW TEST:15.911 seconds]
[sig-network] DNS
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:12:36.032: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-5478
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-7bqpd in namespace proxy-5478
I0912 13:12:36.208992      18 runners.go:180] Created replication controller with name: proxy-service-7bqpd, namespace: proxy-5478, replica count: 1
I0912 13:12:37.259398      18 runners.go:180] proxy-service-7bqpd Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0912 13:12:38.259627      18 runners.go:180] proxy-service-7bqpd Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0912 13:12:39.259854      18 runners.go:180] proxy-service-7bqpd Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0912 13:12:40.260068      18 runners.go:180] proxy-service-7bqpd Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0912 13:12:41.260290      18 runners.go:180] proxy-service-7bqpd Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0912 13:12:42.260526      18 runners.go:180] proxy-service-7bqpd Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0912 13:12:43.260731      18 runners.go:180] proxy-service-7bqpd Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0912 13:12:44.260915      18 runners.go:180] proxy-service-7bqpd Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0912 13:12:45.261101      18 runners.go:180] proxy-service-7bqpd Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0912 13:12:46.261285      18 runners.go:180] proxy-service-7bqpd Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Sep 12 13:12:46.263: INFO: setup took 10.079810097s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Sep 12 13:12:46.268: INFO: (0) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:160/proxy/: foo (200; 4.241378ms)
Sep 12 13:12:46.269: INFO: (0) /api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:160/proxy/: foo (200; 5.617289ms)
Sep 12 13:12:46.270: INFO: (0) /api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:162/proxy/: bar (200; 7.06129ms)
Sep 12 13:12:46.271: INFO: (0) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:1080/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:1080/proxy/rewriteme">test<... (200; 7.570202ms)
Sep 12 13:12:46.271: INFO: (0) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:162/proxy/: bar (200; 7.704641ms)
Sep 12 13:12:46.274: INFO: (0) /api/v1/namespaces/proxy-5478/services/http:proxy-service-7bqpd:portname2/proxy/: bar (200; 10.641423ms)
Sep 12 13:12:46.274: INFO: (0) /api/v1/namespaces/proxy-5478/services/proxy-service-7bqpd:portname1/proxy/: foo (200; 10.661588ms)
Sep 12 13:12:46.277: INFO: (0) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5/proxy/rewriteme">test</a> (200; 13.383052ms)
Sep 12 13:12:46.277: INFO: (0) /api/v1/namespaces/proxy-5478/services/http:proxy-service-7bqpd:portname1/proxy/: foo (200; 13.442536ms)
Sep 12 13:12:46.277: INFO: (0) /api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:1080/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:1080/proxy/rewriteme">... (200; 13.784526ms)
Sep 12 13:12:46.283: INFO: (0) /api/v1/namespaces/proxy-5478/services/proxy-service-7bqpd:portname2/proxy/: bar (200; 19.560679ms)
Sep 12 13:12:46.286: INFO: (0) /api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:462/proxy/: tls qux (200; 22.707213ms)
Sep 12 13:12:46.286: INFO: (0) /api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:443/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:443/proxy/tlsrewritem... (200; 22.773863ms)
Sep 12 13:12:46.286: INFO: (0) /api/v1/namespaces/proxy-5478/services/https:proxy-service-7bqpd:tlsportname1/proxy/: tls baz (200; 23.054718ms)
Sep 12 13:12:46.286: INFO: (0) /api/v1/namespaces/proxy-5478/services/https:proxy-service-7bqpd:tlsportname2/proxy/: tls qux (200; 23.258763ms)
Sep 12 13:12:46.289: INFO: (0) /api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:460/proxy/: tls baz (200; 25.907879ms)
Sep 12 13:12:46.293: INFO: (1) /api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:162/proxy/: bar (200; 3.529481ms)
Sep 12 13:12:46.294: INFO: (1) /api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:1080/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:1080/proxy/rewriteme">... (200; 3.987226ms)
Sep 12 13:12:46.294: INFO: (1) /api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:160/proxy/: foo (200; 3.736578ms)
Sep 12 13:12:46.294: INFO: (1) /api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:462/proxy/: tls qux (200; 3.203564ms)
Sep 12 13:12:46.294: INFO: (1) /api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:460/proxy/: tls baz (200; 4.601701ms)
Sep 12 13:12:46.294: INFO: (1) /api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:443/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:443/proxy/tlsrewritem... (200; 3.62896ms)
Sep 12 13:12:46.294: INFO: (1) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:162/proxy/: bar (200; 3.197311ms)
Sep 12 13:12:46.294: INFO: (1) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5/proxy/rewriteme">test</a> (200; 3.94857ms)
Sep 12 13:12:46.295: INFO: (1) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:160/proxy/: foo (200; 4.715386ms)
Sep 12 13:12:46.295: INFO: (1) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:1080/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:1080/proxy/rewriteme">test<... (200; 3.760419ms)
Sep 12 13:12:46.298: INFO: (1) /api/v1/namespaces/proxy-5478/services/http:proxy-service-7bqpd:portname2/proxy/: bar (200; 7.728845ms)
Sep 12 13:12:46.299: INFO: (1) /api/v1/namespaces/proxy-5478/services/https:proxy-service-7bqpd:tlsportname2/proxy/: tls qux (200; 7.747428ms)
Sep 12 13:12:46.299: INFO: (1) /api/v1/namespaces/proxy-5478/services/proxy-service-7bqpd:portname2/proxy/: bar (200; 8.53364ms)
Sep 12 13:12:46.299: INFO: (1) /api/v1/namespaces/proxy-5478/services/http:proxy-service-7bqpd:portname1/proxy/: foo (200; 8.75232ms)
Sep 12 13:12:46.299: INFO: (1) /api/v1/namespaces/proxy-5478/services/https:proxy-service-7bqpd:tlsportname1/proxy/: tls baz (200; 9.651123ms)
Sep 12 13:12:46.299: INFO: (1) /api/v1/namespaces/proxy-5478/services/proxy-service-7bqpd:portname1/proxy/: foo (200; 9.152969ms)
Sep 12 13:12:46.302: INFO: (2) /api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:462/proxy/: tls qux (200; 2.456994ms)
Sep 12 13:12:46.305: INFO: (2) /api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:443/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:443/proxy/tlsrewritem... (200; 3.884757ms)
Sep 12 13:12:46.305: INFO: (2) /api/v1/namespaces/proxy-5478/services/https:proxy-service-7bqpd:tlsportname1/proxy/: tls baz (200; 5.652804ms)
Sep 12 13:12:46.306: INFO: (2) /api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:460/proxy/: tls baz (200; 6.397561ms)
Sep 12 13:12:46.306: INFO: (2) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:1080/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:1080/proxy/rewriteme">test<... (200; 5.203706ms)
Sep 12 13:12:46.306: INFO: (2) /api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:1080/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:1080/proxy/rewriteme">... (200; 6.553544ms)
Sep 12 13:12:46.306: INFO: (2) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:162/proxy/: bar (200; 5.479763ms)
Sep 12 13:12:46.307: INFO: (2) /api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:160/proxy/: foo (200; 6.085344ms)
Sep 12 13:12:46.307: INFO: (2) /api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:162/proxy/: bar (200; 6.863272ms)
Sep 12 13:12:46.308: INFO: (2) /api/v1/namespaces/proxy-5478/services/http:proxy-service-7bqpd:portname2/proxy/: bar (200; 6.968658ms)
Sep 12 13:12:46.308: INFO: (2) /api/v1/namespaces/proxy-5478/services/http:proxy-service-7bqpd:portname1/proxy/: foo (200; 7.525312ms)
Sep 12 13:12:46.308: INFO: (2) /api/v1/namespaces/proxy-5478/services/proxy-service-7bqpd:portname1/proxy/: foo (200; 7.656086ms)
Sep 12 13:12:46.308: INFO: (2) /api/v1/namespaces/proxy-5478/services/proxy-service-7bqpd:portname2/proxy/: bar (200; 7.461096ms)
Sep 12 13:12:46.308: INFO: (2) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:160/proxy/: foo (200; 7.254316ms)
Sep 12 13:12:46.308: INFO: (2) /api/v1/namespaces/proxy-5478/services/https:proxy-service-7bqpd:tlsportname2/proxy/: tls qux (200; 7.125353ms)
Sep 12 13:12:46.309: INFO: (2) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5/proxy/rewriteme">test</a> (200; 8.407729ms)
Sep 12 13:12:46.313: INFO: (3) /api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:1080/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:1080/proxy/rewriteme">... (200; 4.586774ms)
Sep 12 13:12:46.313: INFO: (3) /api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:160/proxy/: foo (200; 4.710044ms)
Sep 12 13:12:46.314: INFO: (3) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:1080/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:1080/proxy/rewriteme">test<... (200; 5.348558ms)
Sep 12 13:12:46.314: INFO: (3) /api/v1/namespaces/proxy-5478/services/http:proxy-service-7bqpd:portname2/proxy/: bar (200; 5.389868ms)
Sep 12 13:12:46.315: INFO: (3) /api/v1/namespaces/proxy-5478/services/proxy-service-7bqpd:portname1/proxy/: foo (200; 5.655127ms)
Sep 12 13:12:46.316: INFO: (3) /api/v1/namespaces/proxy-5478/services/proxy-service-7bqpd:portname2/proxy/: bar (200; 7.210123ms)
Sep 12 13:12:46.316: INFO: (3) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5/proxy/rewriteme">test</a> (200; 7.20692ms)
Sep 12 13:12:46.316: INFO: (3) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:162/proxy/: bar (200; 7.443579ms)
Sep 12 13:12:46.316: INFO: (3) /api/v1/namespaces/proxy-5478/services/http:proxy-service-7bqpd:portname1/proxy/: foo (200; 7.303039ms)
Sep 12 13:12:46.316: INFO: (3) /api/v1/namespaces/proxy-5478/services/https:proxy-service-7bqpd:tlsportname1/proxy/: tls baz (200; 7.480064ms)
Sep 12 13:12:46.316: INFO: (3) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:160/proxy/: foo (200; 7.248582ms)
Sep 12 13:12:46.316: INFO: (3) /api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:162/proxy/: bar (200; 7.405733ms)
Sep 12 13:12:46.316: INFO: (3) /api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:460/proxy/: tls baz (200; 7.265968ms)
Sep 12 13:12:46.316: INFO: (3) /api/v1/namespaces/proxy-5478/services/https:proxy-service-7bqpd:tlsportname2/proxy/: tls qux (200; 7.545767ms)
Sep 12 13:12:46.316: INFO: (3) /api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:443/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:443/proxy/tlsrewritem... (200; 7.315743ms)
Sep 12 13:12:46.317: INFO: (3) /api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:462/proxy/: tls qux (200; 8.278159ms)
Sep 12 13:12:46.320: INFO: (4) /api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:460/proxy/: tls baz (200; 2.911414ms)
Sep 12 13:12:46.323: INFO: (4) /api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:160/proxy/: foo (200; 5.191537ms)
Sep 12 13:12:46.323: INFO: (4) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5/proxy/rewriteme">test</a> (200; 5.588687ms)
Sep 12 13:12:46.323: INFO: (4) /api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:1080/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:1080/proxy/rewriteme">... (200; 5.404902ms)
Sep 12 13:12:46.323: INFO: (4) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:162/proxy/: bar (200; 5.606294ms)
Sep 12 13:12:46.323: INFO: (4) /api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:443/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:443/proxy/tlsrewritem... (200; 5.58828ms)
Sep 12 13:12:46.323: INFO: (4) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:160/proxy/: foo (200; 5.821143ms)
Sep 12 13:12:46.323: INFO: (4) /api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:462/proxy/: tls qux (200; 5.904201ms)
Sep 12 13:12:46.323: INFO: (4) /api/v1/namespaces/proxy-5478/services/https:proxy-service-7bqpd:tlsportname1/proxy/: tls baz (200; 6.027601ms)
Sep 12 13:12:46.323: INFO: (4) /api/v1/namespaces/proxy-5478/services/proxy-service-7bqpd:portname2/proxy/: bar (200; 5.830041ms)
Sep 12 13:12:46.324: INFO: (4) /api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:162/proxy/: bar (200; 6.141251ms)
Sep 12 13:12:46.324: INFO: (4) /api/v1/namespaces/proxy-5478/services/http:proxy-service-7bqpd:portname1/proxy/: foo (200; 6.206458ms)
Sep 12 13:12:46.325: INFO: (4) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:1080/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:1080/proxy/rewriteme">test<... (200; 7.730085ms)
Sep 12 13:12:46.325: INFO: (4) /api/v1/namespaces/proxy-5478/services/proxy-service-7bqpd:portname1/proxy/: foo (200; 7.701699ms)
Sep 12 13:12:46.325: INFO: (4) /api/v1/namespaces/proxy-5478/services/http:proxy-service-7bqpd:portname2/proxy/: bar (200; 7.780769ms)
Sep 12 13:12:46.326: INFO: (4) /api/v1/namespaces/proxy-5478/services/https:proxy-service-7bqpd:tlsportname2/proxy/: tls qux (200; 8.126561ms)
Sep 12 13:12:46.330: INFO: (5) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5/proxy/rewriteme">test</a> (200; 3.690348ms)
Sep 12 13:12:46.330: INFO: (5) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:162/proxy/: bar (200; 3.880746ms)
Sep 12 13:12:46.330: INFO: (5) /api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:160/proxy/: foo (200; 3.973535ms)
Sep 12 13:12:46.330: INFO: (5) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:160/proxy/: foo (200; 3.881822ms)
Sep 12 13:12:46.330: INFO: (5) /api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:462/proxy/: tls qux (200; 4.276069ms)
Sep 12 13:12:46.331: INFO: (5) /api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:443/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:443/proxy/tlsrewritem... (200; 4.631149ms)
Sep 12 13:12:46.332: INFO: (5) /api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:162/proxy/: bar (200; 5.850065ms)
Sep 12 13:12:46.332: INFO: (5) /api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:1080/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:1080/proxy/rewriteme">... (200; 6.356425ms)
Sep 12 13:12:46.332: INFO: (5) /api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:460/proxy/: tls baz (200; 6.304308ms)
Sep 12 13:12:46.332: INFO: (5) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:1080/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:1080/proxy/rewriteme">test<... (200; 6.395417ms)
Sep 12 13:12:46.332: INFO: (5) /api/v1/namespaces/proxy-5478/services/http:proxy-service-7bqpd:portname2/proxy/: bar (200; 6.515482ms)
Sep 12 13:12:46.332: INFO: (5) /api/v1/namespaces/proxy-5478/services/http:proxy-service-7bqpd:portname1/proxy/: foo (200; 6.671016ms)
Sep 12 13:12:46.333: INFO: (5) /api/v1/namespaces/proxy-5478/services/proxy-service-7bqpd:portname1/proxy/: foo (200; 6.721969ms)
Sep 12 13:12:46.333: INFO: (5) /api/v1/namespaces/proxy-5478/services/proxy-service-7bqpd:portname2/proxy/: bar (200; 6.760848ms)
Sep 12 13:12:46.333: INFO: (5) /api/v1/namespaces/proxy-5478/services/https:proxy-service-7bqpd:tlsportname1/proxy/: tls baz (200; 7.115724ms)
Sep 12 13:12:46.333: INFO: (5) /api/v1/namespaces/proxy-5478/services/https:proxy-service-7bqpd:tlsportname2/proxy/: tls qux (200; 7.038841ms)
Sep 12 13:12:46.339: INFO: (6) /api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:162/proxy/: bar (200; 6.35622ms)
Sep 12 13:12:46.340: INFO: (6) /api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:443/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:443/proxy/tlsrewritem... (200; 6.490731ms)
Sep 12 13:12:46.340: INFO: (6) /api/v1/namespaces/proxy-5478/services/http:proxy-service-7bqpd:portname1/proxy/: foo (200; 6.870157ms)
Sep 12 13:12:46.340: INFO: (6) /api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:160/proxy/: foo (200; 6.927302ms)
Sep 12 13:12:46.340: INFO: (6) /api/v1/namespaces/proxy-5478/services/https:proxy-service-7bqpd:tlsportname2/proxy/: tls qux (200; 7.04155ms)
Sep 12 13:12:46.340: INFO: (6) /api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:1080/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:1080/proxy/rewriteme">... (200; 7.125336ms)
Sep 12 13:12:46.340: INFO: (6) /api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:460/proxy/: tls baz (200; 7.249986ms)
Sep 12 13:12:46.340: INFO: (6) /api/v1/namespaces/proxy-5478/services/http:proxy-service-7bqpd:portname2/proxy/: bar (200; 7.083079ms)
Sep 12 13:12:46.340: INFO: (6) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5/proxy/rewriteme">test</a> (200; 7.217155ms)
Sep 12 13:12:46.340: INFO: (6) /api/v1/namespaces/proxy-5478/services/proxy-service-7bqpd:portname2/proxy/: bar (200; 7.25711ms)
Sep 12 13:12:46.341: INFO: (6) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:160/proxy/: foo (200; 7.651675ms)
Sep 12 13:12:46.341: INFO: (6) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:1080/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:1080/proxy/rewriteme">test<... (200; 7.640628ms)
Sep 12 13:12:46.341: INFO: (6) /api/v1/namespaces/proxy-5478/services/https:proxy-service-7bqpd:tlsportname1/proxy/: tls baz (200; 7.706596ms)
Sep 12 13:12:46.341: INFO: (6) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:162/proxy/: bar (200; 7.815426ms)
Sep 12 13:12:46.341: INFO: (6) /api/v1/namespaces/proxy-5478/services/proxy-service-7bqpd:portname1/proxy/: foo (200; 8.097562ms)
Sep 12 13:12:46.341: INFO: (6) /api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:462/proxy/: tls qux (200; 8.17948ms)
Sep 12 13:12:46.344: INFO: (7) /api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:1080/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:1080/proxy/rewriteme">... (200; 2.667093ms)
Sep 12 13:12:46.345: INFO: (7) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5/proxy/rewriteme">test</a> (200; 3.0807ms)
Sep 12 13:12:46.345: INFO: (7) /api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:162/proxy/: bar (200; 3.171225ms)
Sep 12 13:12:46.349: INFO: (7) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:1080/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:1080/proxy/rewriteme">test<... (200; 7.598163ms)
Sep 12 13:12:46.349: INFO: (7) /api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:462/proxy/: tls qux (200; 7.615186ms)
Sep 12 13:12:46.349: INFO: (7) /api/v1/namespaces/proxy-5478/services/https:proxy-service-7bqpd:tlsportname1/proxy/: tls baz (200; 7.78ms)
Sep 12 13:12:46.349: INFO: (7) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:160/proxy/: foo (200; 7.90323ms)
Sep 12 13:12:46.349: INFO: (7) /api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:443/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:443/proxy/tlsrewritem... (200; 7.926911ms)
Sep 12 13:12:46.350: INFO: (7) /api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:160/proxy/: foo (200; 8.082722ms)
Sep 12 13:12:46.350: INFO: (7) /api/v1/namespaces/proxy-5478/services/http:proxy-service-7bqpd:portname2/proxy/: bar (200; 8.047337ms)
Sep 12 13:12:46.350: INFO: (7) /api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:460/proxy/: tls baz (200; 8.726118ms)
Sep 12 13:12:46.350: INFO: (7) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:162/proxy/: bar (200; 8.732461ms)
Sep 12 13:12:46.350: INFO: (7) /api/v1/namespaces/proxy-5478/services/http:proxy-service-7bqpd:portname1/proxy/: foo (200; 8.76287ms)
Sep 12 13:12:46.350: INFO: (7) /api/v1/namespaces/proxy-5478/services/proxy-service-7bqpd:portname1/proxy/: foo (200; 8.88568ms)
Sep 12 13:12:46.351: INFO: (7) /api/v1/namespaces/proxy-5478/services/proxy-service-7bqpd:portname2/proxy/: bar (200; 9.342037ms)
Sep 12 13:12:46.351: INFO: (7) /api/v1/namespaces/proxy-5478/services/https:proxy-service-7bqpd:tlsportname2/proxy/: tls qux (200; 9.687097ms)
Sep 12 13:12:46.353: INFO: (8) /api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:160/proxy/: foo (200; 1.984368ms)
Sep 12 13:12:46.356: INFO: (8) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:1080/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:1080/proxy/rewriteme">test<... (200; 4.204459ms)
Sep 12 13:12:46.356: INFO: (8) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:160/proxy/: foo (200; 4.270531ms)
Sep 12 13:12:46.356: INFO: (8) /api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:462/proxy/: tls qux (200; 4.305753ms)
Sep 12 13:12:46.358: INFO: (8) /api/v1/namespaces/proxy-5478/services/https:proxy-service-7bqpd:tlsportname2/proxy/: tls qux (200; 7.0492ms)
Sep 12 13:12:46.359: INFO: (8) /api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:443/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:443/proxy/tlsrewritem... (200; 7.161842ms)
Sep 12 13:12:46.359: INFO: (8) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5/proxy/rewriteme">test</a> (200; 7.25128ms)
Sep 12 13:12:46.359: INFO: (8) /api/v1/namespaces/proxy-5478/services/https:proxy-service-7bqpd:tlsportname1/proxy/: tls baz (200; 7.161246ms)
Sep 12 13:12:46.359: INFO: (8) /api/v1/namespaces/proxy-5478/services/proxy-service-7bqpd:portname1/proxy/: foo (200; 7.209263ms)
Sep 12 13:12:46.359: INFO: (8) /api/v1/namespaces/proxy-5478/services/http:proxy-service-7bqpd:portname2/proxy/: bar (200; 7.530943ms)
Sep 12 13:12:46.359: INFO: (8) /api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:162/proxy/: bar (200; 7.270285ms)
Sep 12 13:12:46.359: INFO: (8) /api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:460/proxy/: tls baz (200; 7.219065ms)
Sep 12 13:12:46.359: INFO: (8) /api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:1080/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:1080/proxy/rewriteme">... (200; 7.364805ms)
Sep 12 13:12:46.359: INFO: (8) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:162/proxy/: bar (200; 7.313302ms)
Sep 12 13:12:46.359: INFO: (8) /api/v1/namespaces/proxy-5478/services/http:proxy-service-7bqpd:portname1/proxy/: foo (200; 7.365634ms)
Sep 12 13:12:46.359: INFO: (8) /api/v1/namespaces/proxy-5478/services/proxy-service-7bqpd:portname2/proxy/: bar (200; 7.636387ms)
Sep 12 13:12:46.366: INFO: (9) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:162/proxy/: bar (200; 6.337437ms)
Sep 12 13:12:46.366: INFO: (9) /api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:160/proxy/: foo (200; 6.22858ms)
Sep 12 13:12:46.366: INFO: (9) /api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:462/proxy/: tls qux (200; 5.797164ms)
Sep 12 13:12:46.366: INFO: (9) /api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:460/proxy/: tls baz (200; 6.809818ms)
Sep 12 13:12:46.366: INFO: (9) /api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:1080/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:1080/proxy/rewriteme">... (200; 6.694571ms)
Sep 12 13:12:46.366: INFO: (9) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:160/proxy/: foo (200; 6.568762ms)
Sep 12 13:12:46.366: INFO: (9) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5/proxy/rewriteme">test</a> (200; 6.258892ms)
Sep 12 13:12:46.366: INFO: (9) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:1080/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:1080/proxy/rewriteme">test<... (200; 5.884338ms)
Sep 12 13:12:46.366: INFO: (9) /api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:162/proxy/: bar (200; 6.770224ms)
Sep 12 13:12:46.366: INFO: (9) /api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:443/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:443/proxy/tlsrewritem... (200; 6.239519ms)
Sep 12 13:12:46.370: INFO: (9) /api/v1/namespaces/proxy-5478/services/https:proxy-service-7bqpd:tlsportname1/proxy/: tls baz (200; 10.201366ms)
Sep 12 13:12:46.370: INFO: (9) /api/v1/namespaces/proxy-5478/services/proxy-service-7bqpd:portname1/proxy/: foo (200; 10.004347ms)
Sep 12 13:12:46.370: INFO: (9) /api/v1/namespaces/proxy-5478/services/http:proxy-service-7bqpd:portname2/proxy/: bar (200; 9.829689ms)
Sep 12 13:12:46.370: INFO: (9) /api/v1/namespaces/proxy-5478/services/proxy-service-7bqpd:portname2/proxy/: bar (200; 10.171034ms)
Sep 12 13:12:46.370: INFO: (9) /api/v1/namespaces/proxy-5478/services/http:proxy-service-7bqpd:portname1/proxy/: foo (200; 10.272625ms)
Sep 12 13:12:46.371: INFO: (9) /api/v1/namespaces/proxy-5478/services/https:proxy-service-7bqpd:tlsportname2/proxy/: tls qux (200; 10.139987ms)
Sep 12 13:12:46.377: INFO: (10) /api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:160/proxy/: foo (200; 5.423455ms)
Sep 12 13:12:46.377: INFO: (10) /api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:460/proxy/: tls baz (200; 6.583039ms)
Sep 12 13:12:46.378: INFO: (10) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5/proxy/rewriteme">test</a> (200; 6.410888ms)
Sep 12 13:12:46.378: INFO: (10) /api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:1080/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:1080/proxy/rewriteme">... (200; 6.917013ms)
Sep 12 13:12:46.378: INFO: (10) /api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:162/proxy/: bar (200; 7.041865ms)
Sep 12 13:12:46.378: INFO: (10) /api/v1/namespaces/proxy-5478/services/https:proxy-service-7bqpd:tlsportname1/proxy/: tls baz (200; 7.146291ms)
Sep 12 13:12:46.378: INFO: (10) /api/v1/namespaces/proxy-5478/services/http:proxy-service-7bqpd:portname1/proxy/: foo (200; 7.288478ms)
Sep 12 13:12:46.379: INFO: (10) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:1080/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:1080/proxy/rewriteme">test<... (200; 7.105682ms)
Sep 12 13:12:46.379: INFO: (10) /api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:443/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:443/proxy/tlsrewritem... (200; 7.143929ms)
Sep 12 13:12:46.379: INFO: (10) /api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:462/proxy/: tls qux (200; 7.094916ms)
Sep 12 13:12:46.379: INFO: (10) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:160/proxy/: foo (200; 7.458694ms)
Sep 12 13:12:46.379: INFO: (10) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:162/proxy/: bar (200; 7.268872ms)
Sep 12 13:12:46.380: INFO: (10) /api/v1/namespaces/proxy-5478/services/http:proxy-service-7bqpd:portname2/proxy/: bar (200; 8.900755ms)
Sep 12 13:12:46.380: INFO: (10) /api/v1/namespaces/proxy-5478/services/proxy-service-7bqpd:portname2/proxy/: bar (200; 8.766941ms)
Sep 12 13:12:46.380: INFO: (10) /api/v1/namespaces/proxy-5478/services/https:proxy-service-7bqpd:tlsportname2/proxy/: tls qux (200; 8.73483ms)
Sep 12 13:12:46.380: INFO: (10) /api/v1/namespaces/proxy-5478/services/proxy-service-7bqpd:portname1/proxy/: foo (200; 8.891617ms)
Sep 12 13:12:46.384: INFO: (11) /api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:462/proxy/: tls qux (200; 3.13093ms)
Sep 12 13:12:46.388: INFO: (11) /api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:1080/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:1080/proxy/rewriteme">... (200; 7.58102ms)
Sep 12 13:12:46.388: INFO: (11) /api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:162/proxy/: bar (200; 7.525209ms)
Sep 12 13:12:46.389: INFO: (11) /api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:460/proxy/: tls baz (200; 8.124706ms)
Sep 12 13:12:46.391: INFO: (11) /api/v1/namespaces/proxy-5478/services/https:proxy-service-7bqpd:tlsportname2/proxy/: tls qux (200; 9.826353ms)
Sep 12 13:12:46.392: INFO: (11) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:1080/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:1080/proxy/rewriteme">test<... (200; 10.501314ms)
Sep 12 13:12:46.392: INFO: (11) /api/v1/namespaces/proxy-5478/services/http:proxy-service-7bqpd:portname2/proxy/: bar (200; 10.916788ms)
Sep 12 13:12:46.392: INFO: (11) /api/v1/namespaces/proxy-5478/services/proxy-service-7bqpd:portname2/proxy/: bar (200; 11.307483ms)
Sep 12 13:12:46.392: INFO: (11) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:160/proxy/: foo (200; 11.183515ms)
Sep 12 13:12:46.393: INFO: (11) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5/proxy/rewriteme">test</a> (200; 11.574705ms)
Sep 12 13:12:46.393: INFO: (11) /api/v1/namespaces/proxy-5478/services/http:proxy-service-7bqpd:portname1/proxy/: foo (200; 11.756699ms)
Sep 12 13:12:46.393: INFO: (11) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:162/proxy/: bar (200; 11.403434ms)
Sep 12 13:12:46.393: INFO: (11) /api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:443/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:443/proxy/tlsrewritem... (200; 11.355941ms)
Sep 12 13:12:46.393: INFO: (11) /api/v1/namespaces/proxy-5478/services/https:proxy-service-7bqpd:tlsportname1/proxy/: tls baz (200; 12.419173ms)
Sep 12 13:12:46.393: INFO: (11) /api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:160/proxy/: foo (200; 11.832769ms)
Sep 12 13:12:46.393: INFO: (11) /api/v1/namespaces/proxy-5478/services/proxy-service-7bqpd:portname1/proxy/: foo (200; 12.252118ms)
Sep 12 13:12:46.397: INFO: (12) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:1080/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:1080/proxy/rewriteme">test<... (200; 3.771489ms)
Sep 12 13:12:46.398: INFO: (12) /api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:1080/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:1080/proxy/rewriteme">... (200; 4.320194ms)
Sep 12 13:12:46.398: INFO: (12) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5/proxy/rewriteme">test</a> (200; 4.324747ms)
Sep 12 13:12:46.398: INFO: (12) /api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:162/proxy/: bar (200; 4.540185ms)
Sep 12 13:12:46.398: INFO: (12) /api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:460/proxy/: tls baz (200; 4.824588ms)
Sep 12 13:12:46.400: INFO: (12) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:160/proxy/: foo (200; 5.991383ms)
Sep 12 13:12:46.400: INFO: (12) /api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:160/proxy/: foo (200; 6.42731ms)
Sep 12 13:12:46.400: INFO: (12) /api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:462/proxy/: tls qux (200; 5.986378ms)
Sep 12 13:12:46.400: INFO: (12) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:162/proxy/: bar (200; 6.253304ms)
Sep 12 13:12:46.401: INFO: (12) /api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:443/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:443/proxy/tlsrewritem... (200; 6.491523ms)
Sep 12 13:12:46.401: INFO: (12) /api/v1/namespaces/proxy-5478/services/https:proxy-service-7bqpd:tlsportname1/proxy/: tls baz (200; 7.525675ms)
Sep 12 13:12:46.403: INFO: (12) /api/v1/namespaces/proxy-5478/services/http:proxy-service-7bqpd:portname1/proxy/: foo (200; 8.795301ms)
Sep 12 13:12:46.403: INFO: (12) /api/v1/namespaces/proxy-5478/services/https:proxy-service-7bqpd:tlsportname2/proxy/: tls qux (200; 8.476402ms)
Sep 12 13:12:46.403: INFO: (12) /api/v1/namespaces/proxy-5478/services/proxy-service-7bqpd:portname1/proxy/: foo (200; 9.26742ms)
Sep 12 13:12:46.403: INFO: (12) /api/v1/namespaces/proxy-5478/services/http:proxy-service-7bqpd:portname2/proxy/: bar (200; 9.060201ms)
Sep 12 13:12:46.403: INFO: (12) /api/v1/namespaces/proxy-5478/services/proxy-service-7bqpd:portname2/proxy/: bar (200; 9.435887ms)
Sep 12 13:12:46.407: INFO: (13) /api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:162/proxy/: bar (200; 3.077669ms)
Sep 12 13:12:46.408: INFO: (13) /api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:160/proxy/: foo (200; 4.307981ms)
Sep 12 13:12:46.408: INFO: (13) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:160/proxy/: foo (200; 4.441339ms)
Sep 12 13:12:46.408: INFO: (13) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5/proxy/rewriteme">test</a> (200; 4.591064ms)
Sep 12 13:12:46.409: INFO: (13) /api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:462/proxy/: tls qux (200; 5.148924ms)
Sep 12 13:12:46.409: INFO: (13) /api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:460/proxy/: tls baz (200; 4.901736ms)
Sep 12 13:12:46.410: INFO: (13) /api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:1080/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:1080/proxy/rewriteme">... (200; 5.18873ms)
Sep 12 13:12:46.410: INFO: (13) /api/v1/namespaces/proxy-5478/services/http:proxy-service-7bqpd:portname1/proxy/: foo (200; 6.064612ms)
Sep 12 13:12:46.410: INFO: (13) /api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:443/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:443/proxy/tlsrewritem... (200; 5.90819ms)
Sep 12 13:12:46.410: INFO: (13) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:1080/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:1080/proxy/rewriteme">test<... (200; 5.824797ms)
Sep 12 13:12:46.410: INFO: (13) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:162/proxy/: bar (200; 6.246935ms)
Sep 12 13:12:46.410: INFO: (13) /api/v1/namespaces/proxy-5478/services/proxy-service-7bqpd:portname1/proxy/: foo (200; 6.598593ms)
Sep 12 13:12:46.412: INFO: (13) /api/v1/namespaces/proxy-5478/services/http:proxy-service-7bqpd:portname2/proxy/: bar (200; 7.211483ms)
Sep 12 13:12:46.412: INFO: (13) /api/v1/namespaces/proxy-5478/services/https:proxy-service-7bqpd:tlsportname1/proxy/: tls baz (200; 7.160208ms)
Sep 12 13:12:46.412: INFO: (13) /api/v1/namespaces/proxy-5478/services/proxy-service-7bqpd:portname2/proxy/: bar (200; 7.987076ms)
Sep 12 13:12:46.412: INFO: (13) /api/v1/namespaces/proxy-5478/services/https:proxy-service-7bqpd:tlsportname2/proxy/: tls qux (200; 7.567042ms)
Sep 12 13:12:46.419: INFO: (14) /api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:160/proxy/: foo (200; 5.765459ms)
Sep 12 13:12:46.419: INFO: (14) /api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:443/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:443/proxy/tlsrewritem... (200; 7.346038ms)
Sep 12 13:12:46.419: INFO: (14) /api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:162/proxy/: bar (200; 6.651591ms)
Sep 12 13:12:46.420: INFO: (14) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:162/proxy/: bar (200; 6.98068ms)
Sep 12 13:12:46.420: INFO: (14) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:1080/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:1080/proxy/rewriteme">test<... (200; 7.064509ms)
Sep 12 13:12:46.420: INFO: (14) /api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:1080/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:1080/proxy/rewriteme">... (200; 6.754691ms)
Sep 12 13:12:46.420: INFO: (14) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5/proxy/rewriteme">test</a> (200; 8.041883ms)
Sep 12 13:12:46.420: INFO: (14) /api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:462/proxy/: tls qux (200; 7.865542ms)
Sep 12 13:12:46.420: INFO: (14) /api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:460/proxy/: tls baz (200; 7.697879ms)
Sep 12 13:12:46.420: INFO: (14) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:160/proxy/: foo (200; 7.429145ms)
Sep 12 13:12:46.421: INFO: (14) /api/v1/namespaces/proxy-5478/services/http:proxy-service-7bqpd:portname2/proxy/: bar (200; 9.058073ms)
Sep 12 13:12:46.423: INFO: (14) /api/v1/namespaces/proxy-5478/services/proxy-service-7bqpd:portname2/proxy/: bar (200; 9.802444ms)
Sep 12 13:12:46.423: INFO: (14) /api/v1/namespaces/proxy-5478/services/http:proxy-service-7bqpd:portname1/proxy/: foo (200; 9.881425ms)
Sep 12 13:12:46.423: INFO: (14) /api/v1/namespaces/proxy-5478/services/proxy-service-7bqpd:portname1/proxy/: foo (200; 9.860586ms)
Sep 12 13:12:46.424: INFO: (14) /api/v1/namespaces/proxy-5478/services/https:proxy-service-7bqpd:tlsportname2/proxy/: tls qux (200; 11.236699ms)
Sep 12 13:12:46.425: INFO: (14) /api/v1/namespaces/proxy-5478/services/https:proxy-service-7bqpd:tlsportname1/proxy/: tls baz (200; 11.871293ms)
Sep 12 13:12:46.435: INFO: (15) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:162/proxy/: bar (200; 9.676537ms)
Sep 12 13:12:46.435: INFO: (15) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:1080/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:1080/proxy/rewriteme">test<... (200; 9.797987ms)
Sep 12 13:12:46.435: INFO: (15) /api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:162/proxy/: bar (200; 10.778784ms)
Sep 12 13:12:46.435: INFO: (15) /api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:160/proxy/: foo (200; 10.246404ms)
Sep 12 13:12:46.436: INFO: (15) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:160/proxy/: foo (200; 10.369921ms)
Sep 12 13:12:46.436: INFO: (15) /api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:443/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:443/proxy/tlsrewritem... (200; 10.100915ms)
Sep 12 13:12:46.436: INFO: (15) /api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:460/proxy/: tls baz (200; 9.972281ms)
Sep 12 13:12:46.436: INFO: (15) /api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:1080/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:1080/proxy/rewriteme">... (200; 9.770209ms)
Sep 12 13:12:46.436: INFO: (15) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5/proxy/rewriteme">test</a> (200; 10.89084ms)
Sep 12 13:12:46.437: INFO: (15) /api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:462/proxy/: tls qux (200; 10.64966ms)
Sep 12 13:12:46.437: INFO: (15) /api/v1/namespaces/proxy-5478/services/http:proxy-service-7bqpd:portname2/proxy/: bar (200; 12.13182ms)
Sep 12 13:12:46.438: INFO: (15) /api/v1/namespaces/proxy-5478/services/proxy-service-7bqpd:portname2/proxy/: bar (200; 12.915381ms)
Sep 12 13:12:46.438: INFO: (15) /api/v1/namespaces/proxy-5478/services/http:proxy-service-7bqpd:portname1/proxy/: foo (200; 13.055903ms)
Sep 12 13:12:46.438: INFO: (15) /api/v1/namespaces/proxy-5478/services/https:proxy-service-7bqpd:tlsportname1/proxy/: tls baz (200; 11.825255ms)
Sep 12 13:12:46.438: INFO: (15) /api/v1/namespaces/proxy-5478/services/https:proxy-service-7bqpd:tlsportname2/proxy/: tls qux (200; 12.456432ms)
Sep 12 13:12:46.438: INFO: (15) /api/v1/namespaces/proxy-5478/services/proxy-service-7bqpd:portname1/proxy/: foo (200; 13.210074ms)
Sep 12 13:12:46.440: INFO: (16) /api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:162/proxy/: bar (200; 2.210484ms)
Sep 12 13:12:46.441: INFO: (16) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5/proxy/rewriteme">test</a> (200; 2.5634ms)
Sep 12 13:12:46.441: INFO: (16) /api/v1/namespaces/proxy-5478/services/proxy-service-7bqpd:portname1/proxy/: foo (200; 3.066444ms)
Sep 12 13:12:46.445: INFO: (16) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:162/proxy/: bar (200; 6.607997ms)
Sep 12 13:12:46.445: INFO: (16) /api/v1/namespaces/proxy-5478/services/http:proxy-service-7bqpd:portname1/proxy/: foo (200; 6.77137ms)
Sep 12 13:12:46.445: INFO: (16) /api/v1/namespaces/proxy-5478/services/https:proxy-service-7bqpd:tlsportname2/proxy/: tls qux (200; 6.845275ms)
Sep 12 13:12:46.445: INFO: (16) /api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:460/proxy/: tls baz (200; 6.680912ms)
Sep 12 13:12:46.445: INFO: (16) /api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:462/proxy/: tls qux (200; 6.765021ms)
Sep 12 13:12:46.445: INFO: (16) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:1080/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:1080/proxy/rewriteme">test<... (200; 6.725973ms)
Sep 12 13:12:46.445: INFO: (16) /api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:160/proxy/: foo (200; 6.850776ms)
Sep 12 13:12:46.445: INFO: (16) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:160/proxy/: foo (200; 7.001005ms)
Sep 12 13:12:46.445: INFO: (16) /api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:443/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:443/proxy/tlsrewritem... (200; 6.970385ms)
Sep 12 13:12:46.445: INFO: (16) /api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:1080/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:1080/proxy/rewriteme">... (200; 6.952631ms)
Sep 12 13:12:46.446: INFO: (16) /api/v1/namespaces/proxy-5478/services/http:proxy-service-7bqpd:portname2/proxy/: bar (200; 7.197599ms)
Sep 12 13:12:46.446: INFO: (16) /api/v1/namespaces/proxy-5478/services/proxy-service-7bqpd:portname2/proxy/: bar (200; 7.575992ms)
Sep 12 13:12:46.446: INFO: (16) /api/v1/namespaces/proxy-5478/services/https:proxy-service-7bqpd:tlsportname1/proxy/: tls baz (200; 7.536401ms)
Sep 12 13:12:46.448: INFO: (17) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:160/proxy/: foo (200; 2.190454ms)
Sep 12 13:12:46.450: INFO: (17) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:1080/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:1080/proxy/rewriteme">test<... (200; 3.800643ms)
Sep 12 13:12:46.450: INFO: (17) /api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:443/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:443/proxy/tlsrewritem... (200; 3.609188ms)
Sep 12 13:12:46.450: INFO: (17) /api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:462/proxy/: tls qux (200; 4.137495ms)
Sep 12 13:12:46.451: INFO: (17) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5/proxy/rewriteme">test</a> (200; 3.059324ms)
Sep 12 13:12:46.451: INFO: (17) /api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:1080/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:1080/proxy/rewriteme">... (200; 4.187276ms)
Sep 12 13:12:46.451: INFO: (17) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:162/proxy/: bar (200; 4.686969ms)
Sep 12 13:12:46.451: INFO: (17) /api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:162/proxy/: bar (200; 4.133552ms)
Sep 12 13:12:46.451: INFO: (17) /api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:160/proxy/: foo (200; 4.059958ms)
Sep 12 13:12:46.451: INFO: (17) /api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:460/proxy/: tls baz (200; 4.499546ms)
Sep 12 13:12:46.452: INFO: (17) /api/v1/namespaces/proxy-5478/services/http:proxy-service-7bqpd:portname2/proxy/: bar (200; 6.364843ms)
Sep 12 13:12:46.453: INFO: (17) /api/v1/namespaces/proxy-5478/services/proxy-service-7bqpd:portname1/proxy/: foo (200; 5.55324ms)
Sep 12 13:12:46.453: INFO: (17) /api/v1/namespaces/proxy-5478/services/http:proxy-service-7bqpd:portname1/proxy/: foo (200; 5.460323ms)
Sep 12 13:12:46.453: INFO: (17) /api/v1/namespaces/proxy-5478/services/https:proxy-service-7bqpd:tlsportname2/proxy/: tls qux (200; 6.524745ms)
Sep 12 13:12:46.453: INFO: (17) /api/v1/namespaces/proxy-5478/services/proxy-service-7bqpd:portname2/proxy/: bar (200; 5.395254ms)
Sep 12 13:12:46.453: INFO: (17) /api/v1/namespaces/proxy-5478/services/https:proxy-service-7bqpd:tlsportname1/proxy/: tls baz (200; 6.017931ms)
Sep 12 13:12:46.456: INFO: (18) /api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:162/proxy/: bar (200; 3.128535ms)
Sep 12 13:12:46.460: INFO: (18) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:1080/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:1080/proxy/rewriteme">test<... (200; 5.773254ms)
Sep 12 13:12:46.460: INFO: (18) /api/v1/namespaces/proxy-5478/services/http:proxy-service-7bqpd:portname1/proxy/: foo (200; 6.507645ms)
Sep 12 13:12:46.460: INFO: (18) /api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:1080/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:1080/proxy/rewriteme">... (200; 5.233801ms)
Sep 12 13:12:46.460: INFO: (18) /api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:460/proxy/: tls baz (200; 5.435103ms)
Sep 12 13:12:46.460: INFO: (18) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:160/proxy/: foo (200; 6.248939ms)
Sep 12 13:12:46.460: INFO: (18) /api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:443/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:443/proxy/tlsrewritem... (200; 5.638169ms)
Sep 12 13:12:46.460: INFO: (18) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:162/proxy/: bar (200; 5.9296ms)
Sep 12 13:12:46.460: INFO: (18) /api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:160/proxy/: foo (200; 6.429463ms)
Sep 12 13:12:46.460: INFO: (18) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5/proxy/rewriteme">test</a> (200; 6.628763ms)
Sep 12 13:12:46.460: INFO: (18) /api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:462/proxy/: tls qux (200; 5.901496ms)
Sep 12 13:12:46.460: INFO: (18) /api/v1/namespaces/proxy-5478/services/http:proxy-service-7bqpd:portname2/proxy/: bar (200; 6.408783ms)
Sep 12 13:12:46.460: INFO: (18) /api/v1/namespaces/proxy-5478/services/proxy-service-7bqpd:portname1/proxy/: foo (200; 7.051409ms)
Sep 12 13:12:46.460: INFO: (18) /api/v1/namespaces/proxy-5478/services/proxy-service-7bqpd:portname2/proxy/: bar (200; 6.821449ms)
Sep 12 13:12:46.461: INFO: (18) /api/v1/namespaces/proxy-5478/services/https:proxy-service-7bqpd:tlsportname2/proxy/: tls qux (200; 7.808005ms)
Sep 12 13:12:46.462: INFO: (18) /api/v1/namespaces/proxy-5478/services/https:proxy-service-7bqpd:tlsportname1/proxy/: tls baz (200; 7.397817ms)
Sep 12 13:12:46.465: INFO: (19) /api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:460/proxy/: tls baz (200; 3.228278ms)
Sep 12 13:12:46.467: INFO: (19) /api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:1080/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:1080/proxy/rewriteme">... (200; 5.28067ms)
Sep 12 13:12:46.468: INFO: (19) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:162/proxy/: bar (200; 4.551572ms)
Sep 12 13:12:46.468: INFO: (19) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:1080/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:1080/proxy/rewriteme">test<... (200; 4.668593ms)
Sep 12 13:12:46.468: INFO: (19) /api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:462/proxy/: tls qux (200; 4.925351ms)
Sep 12 13:12:46.468: INFO: (19) /api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:162/proxy/: bar (200; 5.730336ms)
Sep 12 13:12:46.468: INFO: (19) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5:160/proxy/: foo (200; 5.673098ms)
Sep 12 13:12:46.468: INFO: (19) /api/v1/namespaces/proxy-5478/pods/http:proxy-service-7bqpd-2t9h5:160/proxy/: foo (200; 5.609945ms)
Sep 12 13:12:46.468: INFO: (19) /api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:443/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/https:proxy-service-7bqpd-2t9h5:443/proxy/tlsrewritem... (200; 5.191927ms)
Sep 12 13:12:46.468: INFO: (19) /api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5/proxy/: <a href="/api/v1/namespaces/proxy-5478/pods/proxy-service-7bqpd-2t9h5/proxy/rewriteme">test</a> (200; 5.28801ms)
Sep 12 13:12:46.469: INFO: (19) /api/v1/namespaces/proxy-5478/services/http:proxy-service-7bqpd:portname1/proxy/: foo (200; 7.046306ms)
Sep 12 13:12:46.469: INFO: (19) /api/v1/namespaces/proxy-5478/services/proxy-service-7bqpd:portname1/proxy/: foo (200; 7.135672ms)
Sep 12 13:12:46.469: INFO: (19) /api/v1/namespaces/proxy-5478/services/http:proxy-service-7bqpd:portname2/proxy/: bar (200; 6.673535ms)
Sep 12 13:12:46.469: INFO: (19) /api/v1/namespaces/proxy-5478/services/proxy-service-7bqpd:portname2/proxy/: bar (200; 7.018269ms)
Sep 12 13:12:46.470: INFO: (19) /api/v1/namespaces/proxy-5478/services/https:proxy-service-7bqpd:tlsportname2/proxy/: tls qux (200; 6.700938ms)
Sep 12 13:12:46.470: INFO: (19) /api/v1/namespaces/proxy-5478/services/https:proxy-service-7bqpd:tlsportname1/proxy/: tls baz (200; 7.826105ms)
STEP: deleting ReplicationController proxy-service-7bqpd in namespace proxy-5478, will wait for the garbage collector to delete the pods
Sep 12 13:12:46.525: INFO: Deleting ReplicationController proxy-service-7bqpd took: 3.696168ms
Sep 12 13:12:46.925: INFO: Terminating ReplicationController proxy-service-7bqpd pods took: 400.178125ms
[AfterEach] version v1
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:12:49.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-5478" for this suite.
Sep 12 13:12:55.055: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:12:55.121: INFO: namespace proxy-5478 deletion completed in 6.092047508s

â€¢ [SLOW TEST:19.088 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:12:55.122: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-165
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating secret secrets-165/secret-test-285b2bed-fcaf-41bf-9b27-7dfaf8494fde
STEP: Creating a pod to test consume secrets
Sep 12 13:12:55.348: INFO: Waiting up to 5m0s for pod "pod-configmaps-fbcd6a68-afdc-45b6-b749-e6298834700c" in namespace "secrets-165" to be "success or failure"
Sep 12 13:12:55.356: INFO: Pod "pod-configmaps-fbcd6a68-afdc-45b6-b749-e6298834700c": Phase="Pending", Reason="", readiness=false. Elapsed: 7.805563ms
Sep 12 13:12:57.358: INFO: Pod "pod-configmaps-fbcd6a68-afdc-45b6-b749-e6298834700c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010281738s
Sep 12 13:12:59.360: INFO: Pod "pod-configmaps-fbcd6a68-afdc-45b6-b749-e6298834700c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012549272s
STEP: Saw pod success
Sep 12 13:12:59.361: INFO: Pod "pod-configmaps-fbcd6a68-afdc-45b6-b749-e6298834700c" satisfied condition "success or failure"
Sep 12 13:12:59.362: INFO: Trying to get logs from node caasp-worker-thehejik-4 pod pod-configmaps-fbcd6a68-afdc-45b6-b749-e6298834700c container env-test: <nil>
STEP: delete the pod
Sep 12 13:12:59.385: INFO: Waiting for pod pod-configmaps-fbcd6a68-afdc-45b6-b749-e6298834700c to disappear
Sep 12 13:12:59.397: INFO: Pod pod-configmaps-fbcd6a68-afdc-45b6-b749-e6298834700c no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:12:59.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-165" for this suite.
Sep 12 13:13:05.414: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:13:05.491: INFO: namespace secrets-165 deletion completed in 6.091114177s

â€¢ [SLOW TEST:10.369 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:13:05.491: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2731
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-ecc647c5-07b2-43f1-bfc8-46ce01931241
STEP: Creating a pod to test consume configMaps
Sep 12 13:13:05.668: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-8c121473-c6ab-4b59-a8b4-ba32b3f7e2da" in namespace "projected-2731" to be "success or failure"
Sep 12 13:13:05.695: INFO: Pod "pod-projected-configmaps-8c121473-c6ab-4b59-a8b4-ba32b3f7e2da": Phase="Pending", Reason="", readiness=false. Elapsed: 26.878285ms
Sep 12 13:13:07.698: INFO: Pod "pod-projected-configmaps-8c121473-c6ab-4b59-a8b4-ba32b3f7e2da": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029696512s
Sep 12 13:13:09.700: INFO: Pod "pod-projected-configmaps-8c121473-c6ab-4b59-a8b4-ba32b3f7e2da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03207705s
STEP: Saw pod success
Sep 12 13:13:09.700: INFO: Pod "pod-projected-configmaps-8c121473-c6ab-4b59-a8b4-ba32b3f7e2da" satisfied condition "success or failure"
Sep 12 13:13:09.702: INFO: Trying to get logs from node caasp-worker-thehejik-1 pod pod-projected-configmaps-8c121473-c6ab-4b59-a8b4-ba32b3f7e2da container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 12 13:13:09.810: INFO: Waiting for pod pod-projected-configmaps-8c121473-c6ab-4b59-a8b4-ba32b3f7e2da to disappear
Sep 12 13:13:09.825: INFO: Pod pod-projected-configmaps-8c121473-c6ab-4b59-a8b4-ba32b3f7e2da no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:13:09.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2731" for this suite.
Sep 12 13:13:15.841: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:13:15.909: INFO: namespace projected-2731 deletion completed in 6.080592176s

â€¢ [SLOW TEST:10.418 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:13:15.909: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-1809
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating replication controller my-hostname-basic-a7fd23b6-9f6a-4502-9685-1ffd68c71f93
Sep 12 13:13:16.072: INFO: Pod name my-hostname-basic-a7fd23b6-9f6a-4502-9685-1ffd68c71f93: Found 0 pods out of 1
Sep 12 13:13:21.074: INFO: Pod name my-hostname-basic-a7fd23b6-9f6a-4502-9685-1ffd68c71f93: Found 1 pods out of 1
Sep 12 13:13:21.074: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-a7fd23b6-9f6a-4502-9685-1ffd68c71f93" are running
Sep 12 13:13:21.076: INFO: Pod "my-hostname-basic-a7fd23b6-9f6a-4502-9685-1ffd68c71f93-5wbx4" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-12 13:13:16 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-12 13:13:19 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-12 13:13:19 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-12 13:13:16 +0000 UTC Reason: Message:}])
Sep 12 13:13:21.076: INFO: Trying to dial the pod
Sep 12 13:13:26.082: INFO: Controller my-hostname-basic-a7fd23b6-9f6a-4502-9685-1ffd68c71f93: Got expected result from replica 1 [my-hostname-basic-a7fd23b6-9f6a-4502-9685-1ffd68c71f93-5wbx4]: "my-hostname-basic-a7fd23b6-9f6a-4502-9685-1ffd68c71f93-5wbx4", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:13:26.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-1809" for this suite.
Sep 12 13:13:32.100: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:13:32.164: INFO: namespace replication-controller-1809 deletion completed in 6.078890337s

â€¢ [SLOW TEST:16.255 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:13:32.165: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6379
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: executing a command with run --rm and attach with stdin
Sep 12 13:13:32.329: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 --namespace=kubectl-6379 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Sep 12 13:13:36.043: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Sep 12 13:13:36.043: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:13:38.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6379" for this suite.
Sep 12 13:13:48.083: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:13:48.165: INFO: namespace kubectl-6379 deletion completed in 10.112906913s

â€¢ [SLOW TEST:16.000 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run --rm job
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:13:48.167: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3143
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-515dcecb-e562-41c8-b1fb-7b034564e526
STEP: Creating a pod to test consume configMaps
Sep 12 13:13:48.330: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-26890b06-481f-4b19-96d1-31be0be905f0" in namespace "projected-3143" to be "success or failure"
Sep 12 13:13:48.339: INFO: Pod "pod-projected-configmaps-26890b06-481f-4b19-96d1-31be0be905f0": Phase="Pending", Reason="", readiness=false. Elapsed: 9.174571ms
Sep 12 13:13:50.342: INFO: Pod "pod-projected-configmaps-26890b06-481f-4b19-96d1-31be0be905f0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011565093s
Sep 12 13:13:52.344: INFO: Pod "pod-projected-configmaps-26890b06-481f-4b19-96d1-31be0be905f0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013735461s
STEP: Saw pod success
Sep 12 13:13:52.344: INFO: Pod "pod-projected-configmaps-26890b06-481f-4b19-96d1-31be0be905f0" satisfied condition "success or failure"
Sep 12 13:13:52.346: INFO: Trying to get logs from node caasp-worker-thehejik-5 pod pod-projected-configmaps-26890b06-481f-4b19-96d1-31be0be905f0 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 12 13:13:52.365: INFO: Waiting for pod pod-projected-configmaps-26890b06-481f-4b19-96d1-31be0be905f0 to disappear
Sep 12 13:13:52.460: INFO: Pod pod-projected-configmaps-26890b06-481f-4b19-96d1-31be0be905f0 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:13:52.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3143" for this suite.
Sep 12 13:13:58.478: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:13:58.555: INFO: namespace projected-3143 deletion completed in 6.092071427s

â€¢ [SLOW TEST:10.389 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:13:58.555: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-3023
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:14:02.869: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-3023" for this suite.
Sep 12 13:14:08.897: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:14:08.986: INFO: namespace emptydir-wrapper-3023 deletion completed in 6.107308334s

â€¢ [SLOW TEST:10.431 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  should not conflict [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:14:08.986: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8520
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-cc0e6334-6c6c-4b4d-8107-f01b60b788cf
STEP: Creating a pod to test consume configMaps
Sep 12 13:14:09.229: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a2795371-9106-4449-a31d-e8270c6345d6" in namespace "projected-8520" to be "success or failure"
Sep 12 13:14:09.239: INFO: Pod "pod-projected-configmaps-a2795371-9106-4449-a31d-e8270c6345d6": Phase="Pending", Reason="", readiness=false. Elapsed: 10.047003ms
Sep 12 13:14:11.243: INFO: Pod "pod-projected-configmaps-a2795371-9106-4449-a31d-e8270c6345d6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014827576s
Sep 12 13:14:13.246: INFO: Pod "pod-projected-configmaps-a2795371-9106-4449-a31d-e8270c6345d6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017417208s
STEP: Saw pod success
Sep 12 13:14:13.246: INFO: Pod "pod-projected-configmaps-a2795371-9106-4449-a31d-e8270c6345d6" satisfied condition "success or failure"
Sep 12 13:14:13.248: INFO: Trying to get logs from node caasp-worker-thehejik-4 pod pod-projected-configmaps-a2795371-9106-4449-a31d-e8270c6345d6 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 12 13:14:13.459: INFO: Waiting for pod pod-projected-configmaps-a2795371-9106-4449-a31d-e8270c6345d6 to disappear
Sep 12 13:14:13.467: INFO: Pod pod-projected-configmaps-a2795371-9106-4449-a31d-e8270c6345d6 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:14:13.467: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8520" for this suite.
Sep 12 13:14:19.485: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:14:19.555: INFO: namespace projected-8520 deletion completed in 6.085011548s

â€¢ [SLOW TEST:10.569 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:14:19.556: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8501
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep 12 13:14:19.782: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cff14821-6beb-401a-9b7c-1c6bd8faa8a7" in namespace "projected-8501" to be "success or failure"
Sep 12 13:14:19.806: INFO: Pod "downwardapi-volume-cff14821-6beb-401a-9b7c-1c6bd8faa8a7": Phase="Pending", Reason="", readiness=false. Elapsed: 24.675981ms
Sep 12 13:14:21.809: INFO: Pod "downwardapi-volume-cff14821-6beb-401a-9b7c-1c6bd8faa8a7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027101283s
Sep 12 13:14:23.811: INFO: Pod "downwardapi-volume-cff14821-6beb-401a-9b7c-1c6bd8faa8a7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029205382s
STEP: Saw pod success
Sep 12 13:14:23.811: INFO: Pod "downwardapi-volume-cff14821-6beb-401a-9b7c-1c6bd8faa8a7" satisfied condition "success or failure"
Sep 12 13:14:23.812: INFO: Trying to get logs from node caasp-worker-thehejik-3 pod downwardapi-volume-cff14821-6beb-401a-9b7c-1c6bd8faa8a7 container client-container: <nil>
STEP: delete the pod
Sep 12 13:14:23.833: INFO: Waiting for pod downwardapi-volume-cff14821-6beb-401a-9b7c-1c6bd8faa8a7 to disappear
Sep 12 13:14:23.840: INFO: Pod downwardapi-volume-cff14821-6beb-401a-9b7c-1c6bd8faa8a7 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:14:23.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8501" for this suite.
Sep 12 13:14:29.939: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:14:30.002: INFO: namespace projected-8501 deletion completed in 6.158441289s

â€¢ [SLOW TEST:10.446 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:14:30.003: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4249
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Sep 12 13:14:30.161: INFO: Waiting up to 5m0s for pod "downward-api-16353079-0388-42d3-8bcc-0492afd64abc" in namespace "downward-api-4249" to be "success or failure"
Sep 12 13:14:30.172: INFO: Pod "downward-api-16353079-0388-42d3-8bcc-0492afd64abc": Phase="Pending", Reason="", readiness=false. Elapsed: 11.204256ms
Sep 12 13:14:32.175: INFO: Pod "downward-api-16353079-0388-42d3-8bcc-0492afd64abc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013544943s
Sep 12 13:14:34.177: INFO: Pod "downward-api-16353079-0388-42d3-8bcc-0492afd64abc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016343427s
Sep 12 13:14:36.180: INFO: Pod "downward-api-16353079-0388-42d3-8bcc-0492afd64abc": Phase="Pending", Reason="", readiness=false. Elapsed: 6.018497325s
Sep 12 13:14:38.182: INFO: Pod "downward-api-16353079-0388-42d3-8bcc-0492afd64abc": Phase="Pending", Reason="", readiness=false. Elapsed: 8.02085311s
Sep 12 13:14:40.184: INFO: Pod "downward-api-16353079-0388-42d3-8bcc-0492afd64abc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 10.023027079s
STEP: Saw pod success
Sep 12 13:14:40.184: INFO: Pod "downward-api-16353079-0388-42d3-8bcc-0492afd64abc" satisfied condition "success or failure"
Sep 12 13:14:40.186: INFO: Trying to get logs from node caasp-worker-thehejik-2 pod downward-api-16353079-0388-42d3-8bcc-0492afd64abc container dapi-container: <nil>
STEP: delete the pod
Sep 12 13:14:40.207: INFO: Waiting for pod downward-api-16353079-0388-42d3-8bcc-0492afd64abc to disappear
Sep 12 13:14:40.216: INFO: Pod downward-api-16353079-0388-42d3-8bcc-0492afd64abc no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:14:40.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4249" for this suite.
Sep 12 13:14:46.232: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:14:46.326: INFO: namespace downward-api-4249 deletion completed in 6.1067468s

â€¢ [SLOW TEST:16.323 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:14:46.328: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-822
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-projected-8nsf
STEP: Creating a pod to test atomic-volume-subpath
Sep 12 13:14:46.502: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-8nsf" in namespace "subpath-822" to be "success or failure"
Sep 12 13:14:46.521: INFO: Pod "pod-subpath-test-projected-8nsf": Phase="Pending", Reason="", readiness=false. Elapsed: 18.915992ms
Sep 12 13:14:48.524: INFO: Pod "pod-subpath-test-projected-8nsf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021700839s
Sep 12 13:14:50.526: INFO: Pod "pod-subpath-test-projected-8nsf": Phase="Running", Reason="", readiness=true. Elapsed: 4.024059804s
Sep 12 13:14:52.529: INFO: Pod "pod-subpath-test-projected-8nsf": Phase="Running", Reason="", readiness=true. Elapsed: 6.026836903s
Sep 12 13:14:54.531: INFO: Pod "pod-subpath-test-projected-8nsf": Phase="Running", Reason="", readiness=true. Elapsed: 8.029142875s
Sep 12 13:14:56.534: INFO: Pod "pod-subpath-test-projected-8nsf": Phase="Running", Reason="", readiness=true. Elapsed: 10.031490931s
Sep 12 13:14:58.536: INFO: Pod "pod-subpath-test-projected-8nsf": Phase="Running", Reason="", readiness=true. Elapsed: 12.034198355s
Sep 12 13:15:00.539: INFO: Pod "pod-subpath-test-projected-8nsf": Phase="Running", Reason="", readiness=true. Elapsed: 14.03640617s
Sep 12 13:15:02.545: INFO: Pod "pod-subpath-test-projected-8nsf": Phase="Running", Reason="", readiness=true. Elapsed: 16.042515931s
Sep 12 13:15:04.547: INFO: Pod "pod-subpath-test-projected-8nsf": Phase="Running", Reason="", readiness=true. Elapsed: 18.044728225s
Sep 12 13:15:06.549: INFO: Pod "pod-subpath-test-projected-8nsf": Phase="Running", Reason="", readiness=true. Elapsed: 20.046988128s
Sep 12 13:15:08.552: INFO: Pod "pod-subpath-test-projected-8nsf": Phase="Running", Reason="", readiness=true. Elapsed: 22.049900115s
Sep 12 13:15:10.554: INFO: Pod "pod-subpath-test-projected-8nsf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.051983615s
STEP: Saw pod success
Sep 12 13:15:10.554: INFO: Pod "pod-subpath-test-projected-8nsf" satisfied condition "success or failure"
Sep 12 13:15:10.556: INFO: Trying to get logs from node caasp-worker-thehejik-3 pod pod-subpath-test-projected-8nsf container test-container-subpath-projected-8nsf: <nil>
STEP: delete the pod
Sep 12 13:15:10.574: INFO: Waiting for pod pod-subpath-test-projected-8nsf to disappear
Sep 12 13:15:10.584: INFO: Pod pod-subpath-test-projected-8nsf no longer exists
STEP: Deleting pod pod-subpath-test-projected-8nsf
Sep 12 13:15:10.584: INFO: Deleting pod "pod-subpath-test-projected-8nsf" in namespace "subpath-822"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:15:10.586: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-822" for this suite.
Sep 12 13:15:16.601: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:15:16.668: INFO: namespace subpath-822 deletion completed in 6.079754435s

â€¢ [SLOW TEST:30.340 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:15:16.668: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7225
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-0e60caed-1e3d-4328-aef0-b4ab9401bad6
STEP: Creating a pod to test consume configMaps
Sep 12 13:15:16.902: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-cdf96d79-0db7-4263-bd6f-6962e32f7b55" in namespace "projected-7225" to be "success or failure"
Sep 12 13:15:16.911: INFO: Pod "pod-projected-configmaps-cdf96d79-0db7-4263-bd6f-6962e32f7b55": Phase="Pending", Reason="", readiness=false. Elapsed: 8.567197ms
Sep 12 13:15:18.914: INFO: Pod "pod-projected-configmaps-cdf96d79-0db7-4263-bd6f-6962e32f7b55": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011308083s
Sep 12 13:15:20.916: INFO: Pod "pod-projected-configmaps-cdf96d79-0db7-4263-bd6f-6962e32f7b55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013553813s
STEP: Saw pod success
Sep 12 13:15:20.916: INFO: Pod "pod-projected-configmaps-cdf96d79-0db7-4263-bd6f-6962e32f7b55" satisfied condition "success or failure"
Sep 12 13:15:20.917: INFO: Trying to get logs from node caasp-worker-thehejik-0 pod pod-projected-configmaps-cdf96d79-0db7-4263-bd6f-6962e32f7b55 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 12 13:15:20.937: INFO: Waiting for pod pod-projected-configmaps-cdf96d79-0db7-4263-bd6f-6962e32f7b55 to disappear
Sep 12 13:15:20.947: INFO: Pod pod-projected-configmaps-cdf96d79-0db7-4263-bd6f-6962e32f7b55 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:15:20.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7225" for this suite.
Sep 12 13:15:26.967: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:15:27.031: INFO: namespace projected-7225 deletion completed in 6.080703365s

â€¢ [SLOW TEST:10.363 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:15:27.031: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6112
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-9231f246-dd49-428a-bbb0-ab20e5e89fae
STEP: Creating a pod to test consume configMaps
Sep 12 13:15:27.201: INFO: Waiting up to 5m0s for pod "pod-configmaps-4fbd480e-b4b7-4475-a72e-2443c27dcb14" in namespace "configmap-6112" to be "success or failure"
Sep 12 13:15:27.213: INFO: Pod "pod-configmaps-4fbd480e-b4b7-4475-a72e-2443c27dcb14": Phase="Pending", Reason="", readiness=false. Elapsed: 11.262548ms
Sep 12 13:15:29.216: INFO: Pod "pod-configmaps-4fbd480e-b4b7-4475-a72e-2443c27dcb14": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014258515s
Sep 12 13:15:31.218: INFO: Pod "pod-configmaps-4fbd480e-b4b7-4475-a72e-2443c27dcb14": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016850704s
STEP: Saw pod success
Sep 12 13:15:31.218: INFO: Pod "pod-configmaps-4fbd480e-b4b7-4475-a72e-2443c27dcb14" satisfied condition "success or failure"
Sep 12 13:15:31.220: INFO: Trying to get logs from node caasp-worker-thehejik-2 pod pod-configmaps-4fbd480e-b4b7-4475-a72e-2443c27dcb14 container configmap-volume-test: <nil>
STEP: delete the pod
Sep 12 13:15:31.243: INFO: Waiting for pod pod-configmaps-4fbd480e-b4b7-4475-a72e-2443c27dcb14 to disappear
Sep 12 13:15:31.267: INFO: Pod pod-configmaps-4fbd480e-b4b7-4475-a72e-2443c27dcb14 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:15:31.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6112" for this suite.
Sep 12 13:15:37.285: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:15:37.353: INFO: namespace configmap-6112 deletion completed in 6.083927571s

â€¢ [SLOW TEST:10.322 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:15:37.354: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7988
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-upd-df326b1c-7b4a-4ce9-966e-46a9ab173591
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:15:41.642: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7988" for this suite.
Sep 12 13:16:03.662: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:16:03.726: INFO: namespace configmap-7988 deletion completed in 22.080417939s

â€¢ [SLOW TEST:26.373 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:16:03.726: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-347
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-86ddca6a-9566-43d8-99ab-fe58f8aa696c
STEP: Creating a pod to test consume configMaps
Sep 12 13:16:03.940: INFO: Waiting up to 5m0s for pod "pod-configmaps-9dacaf44-4a0d-4b48-b930-476b6416205d" in namespace "configmap-347" to be "success or failure"
Sep 12 13:16:03.947: INFO: Pod "pod-configmaps-9dacaf44-4a0d-4b48-b930-476b6416205d": Phase="Pending", Reason="", readiness=false. Elapsed: 7.155616ms
Sep 12 13:16:05.949: INFO: Pod "pod-configmaps-9dacaf44-4a0d-4b48-b930-476b6416205d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00957045s
Sep 12 13:16:07.952: INFO: Pod "pod-configmaps-9dacaf44-4a0d-4b48-b930-476b6416205d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012226281s
STEP: Saw pod success
Sep 12 13:16:07.952: INFO: Pod "pod-configmaps-9dacaf44-4a0d-4b48-b930-476b6416205d" satisfied condition "success or failure"
Sep 12 13:16:07.953: INFO: Trying to get logs from node caasp-worker-thehejik-1 pod pod-configmaps-9dacaf44-4a0d-4b48-b930-476b6416205d container configmap-volume-test: <nil>
STEP: delete the pod
Sep 12 13:16:08.081: INFO: Waiting for pod pod-configmaps-9dacaf44-4a0d-4b48-b930-476b6416205d to disappear
Sep 12 13:16:08.178: INFO: Pod pod-configmaps-9dacaf44-4a0d-4b48-b930-476b6416205d no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:16:08.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-347" for this suite.
Sep 12 13:16:14.304: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:16:14.377: INFO: namespace configmap-347 deletion completed in 6.099244831s

â€¢ [SLOW TEST:10.651 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:16:14.381: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2703
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1457
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep 12 13:16:14.540: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-2703'
Sep 12 13:16:14.627: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep 12 13:16:14.627: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
STEP: verifying the pod controlled by rc e2e-test-nginx-rc was created
STEP: confirm that you can get logs from an rc
Sep 12 13:16:14.640: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-nginx-rc-x6r5f]
Sep 12 13:16:14.640: INFO: Waiting up to 5m0s for pod "e2e-test-nginx-rc-x6r5f" in namespace "kubectl-2703" to be "running and ready"
Sep 12 13:16:14.661: INFO: Pod "e2e-test-nginx-rc-x6r5f": Phase="Pending", Reason="", readiness=false. Elapsed: 21.53522ms
Sep 12 13:16:16.664: INFO: Pod "e2e-test-nginx-rc-x6r5f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023849417s
Sep 12 13:16:18.666: INFO: Pod "e2e-test-nginx-rc-x6r5f": Phase="Running", Reason="", readiness=true. Elapsed: 4.026623411s
Sep 12 13:16:18.667: INFO: Pod "e2e-test-nginx-rc-x6r5f" satisfied condition "running and ready"
Sep 12 13:16:18.667: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-nginx-rc-x6r5f]
Sep 12 13:16:18.667: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 logs rc/e2e-test-nginx-rc --namespace=kubectl-2703'
Sep 12 13:16:18.768: INFO: stderr: ""
Sep 12 13:16:18.768: INFO: stdout: ""
[AfterEach] [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1462
Sep 12 13:16:18.768: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 delete rc e2e-test-nginx-rc --namespace=kubectl-2703'
Sep 12 13:16:18.874: INFO: stderr: ""
Sep 12 13:16:18.874: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:16:18.874: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2703" for this suite.
Sep 12 13:16:40.891: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:16:40.961: INFO: namespace kubectl-2703 deletion completed in 22.084076002s

â€¢ [SLOW TEST:26.580 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run rc
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:16:40.961: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8410
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on tmpfs
Sep 12 13:16:41.125: INFO: Waiting up to 5m0s for pod "pod-2b62694d-4ebd-43a5-b31f-535cbdcf90d3" in namespace "emptydir-8410" to be "success or failure"
Sep 12 13:16:41.135: INFO: Pod "pod-2b62694d-4ebd-43a5-b31f-535cbdcf90d3": Phase="Pending", Reason="", readiness=false. Elapsed: 9.842141ms
Sep 12 13:16:43.137: INFO: Pod "pod-2b62694d-4ebd-43a5-b31f-535cbdcf90d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011864768s
Sep 12 13:16:45.139: INFO: Pod "pod-2b62694d-4ebd-43a5-b31f-535cbdcf90d3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013980828s
Sep 12 13:16:47.141: INFO: Pod "pod-2b62694d-4ebd-43a5-b31f-535cbdcf90d3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.01607051s
Sep 12 13:16:49.143: INFO: Pod "pod-2b62694d-4ebd-43a5-b31f-535cbdcf90d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.018138217s
STEP: Saw pod success
Sep 12 13:16:49.143: INFO: Pod "pod-2b62694d-4ebd-43a5-b31f-535cbdcf90d3" satisfied condition "success or failure"
Sep 12 13:16:49.145: INFO: Trying to get logs from node caasp-worker-thehejik-3 pod pod-2b62694d-4ebd-43a5-b31f-535cbdcf90d3 container test-container: <nil>
STEP: delete the pod
Sep 12 13:16:49.163: INFO: Waiting for pod pod-2b62694d-4ebd-43a5-b31f-535cbdcf90d3 to disappear
Sep 12 13:16:49.172: INFO: Pod pod-2b62694d-4ebd-43a5-b31f-535cbdcf90d3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:16:49.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8410" for this suite.
Sep 12 13:16:55.191: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:16:55.260: INFO: namespace emptydir-8410 deletion completed in 6.084465845s

â€¢ [SLOW TEST:14.299 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:16:55.263: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4536
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-map-00292bbb-6bf9-4cc4-b9bf-136593c4ddef
STEP: Creating a pod to test consume configMaps
Sep 12 13:16:55.444: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ae372c88-cafe-4753-8de1-aa84a5e20b9d" in namespace "projected-4536" to be "success or failure"
Sep 12 13:16:55.453: INFO: Pod "pod-projected-configmaps-ae372c88-cafe-4753-8de1-aa84a5e20b9d": Phase="Pending", Reason="", readiness=false. Elapsed: 8.63596ms
Sep 12 13:16:57.456: INFO: Pod "pod-projected-configmaps-ae372c88-cafe-4753-8de1-aa84a5e20b9d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011336409s
Sep 12 13:16:59.459: INFO: Pod "pod-projected-configmaps-ae372c88-cafe-4753-8de1-aa84a5e20b9d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014206858s
STEP: Saw pod success
Sep 12 13:16:59.459: INFO: Pod "pod-projected-configmaps-ae372c88-cafe-4753-8de1-aa84a5e20b9d" satisfied condition "success or failure"
Sep 12 13:16:59.460: INFO: Trying to get logs from node caasp-worker-thehejik-0 pod pod-projected-configmaps-ae372c88-cafe-4753-8de1-aa84a5e20b9d container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 12 13:16:59.502: INFO: Waiting for pod pod-projected-configmaps-ae372c88-cafe-4753-8de1-aa84a5e20b9d to disappear
Sep 12 13:16:59.516: INFO: Pod pod-projected-configmaps-ae372c88-cafe-4753-8de1-aa84a5e20b9d no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:16:59.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4536" for this suite.
Sep 12 13:17:05.533: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:17:05.600: INFO: namespace projected-4536 deletion completed in 6.080997699s

â€¢ [SLOW TEST:10.337 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:17:05.600: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8586
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-b1b651a6-35fc-48a2-abcf-4b8ebdcc175b
STEP: Creating a pod to test consume secrets
Sep 12 13:17:05.768: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-04c0add5-fb74-446c-bc12-a5d6f163b46c" in namespace "projected-8586" to be "success or failure"
Sep 12 13:17:05.776: INFO: Pod "pod-projected-secrets-04c0add5-fb74-446c-bc12-a5d6f163b46c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.318393ms
Sep 12 13:17:07.781: INFO: Pod "pod-projected-secrets-04c0add5-fb74-446c-bc12-a5d6f163b46c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012956895s
Sep 12 13:17:09.783: INFO: Pod "pod-projected-secrets-04c0add5-fb74-446c-bc12-a5d6f163b46c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015334267s
STEP: Saw pod success
Sep 12 13:17:09.783: INFO: Pod "pod-projected-secrets-04c0add5-fb74-446c-bc12-a5d6f163b46c" satisfied condition "success or failure"
Sep 12 13:17:09.785: INFO: Trying to get logs from node caasp-worker-thehejik-2 pod pod-projected-secrets-04c0add5-fb74-446c-bc12-a5d6f163b46c container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep 12 13:17:09.815: INFO: Waiting for pod pod-projected-secrets-04c0add5-fb74-446c-bc12-a5d6f163b46c to disappear
Sep 12 13:17:09.827: INFO: Pod pod-projected-secrets-04c0add5-fb74-446c-bc12-a5d6f163b46c no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:17:09.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8586" for this suite.
Sep 12 13:17:15.846: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:17:15.930: INFO: namespace projected-8586 deletion completed in 6.100327995s

â€¢ [SLOW TEST:10.330 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:17:15.930: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-2868
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-3320
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-7380
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:17:22.636: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-2868" for this suite.
Sep 12 13:17:28.654: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:17:28.720: INFO: namespace namespaces-2868 deletion completed in 6.08077296s
STEP: Destroying namespace "nsdeletetest-3320" for this suite.
Sep 12 13:17:28.722: INFO: Namespace nsdeletetest-3320 was already deleted
STEP: Destroying namespace "nsdeletetest-7380" for this suite.
Sep 12 13:17:34.776: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:17:34.840: INFO: namespace nsdeletetest-7380 deletion completed in 6.118227928s

â€¢ [SLOW TEST:18.910 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:17:34.840: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-1300
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:18:00.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1300" for this suite.
Sep 12 13:18:06.510: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:18:06.577: INFO: namespace container-runtime-1300 deletion completed in 6.082815524s

â€¢ [SLOW TEST:31.737 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    when starting a container that exits
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:18:06.578: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-1105
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test env composition
Sep 12 13:18:06.786: INFO: Waiting up to 5m0s for pod "var-expansion-e6bbf979-ef91-4e44-96b9-9c4701487b9d" in namespace "var-expansion-1105" to be "success or failure"
Sep 12 13:18:06.852: INFO: Pod "var-expansion-e6bbf979-ef91-4e44-96b9-9c4701487b9d": Phase="Pending", Reason="", readiness=false. Elapsed: 66.370775ms
Sep 12 13:18:08.862: INFO: Pod "var-expansion-e6bbf979-ef91-4e44-96b9-9c4701487b9d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.075934231s
Sep 12 13:18:10.864: INFO: Pod "var-expansion-e6bbf979-ef91-4e44-96b9-9c4701487b9d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.078330076s
STEP: Saw pod success
Sep 12 13:18:10.865: INFO: Pod "var-expansion-e6bbf979-ef91-4e44-96b9-9c4701487b9d" satisfied condition "success or failure"
Sep 12 13:18:10.866: INFO: Trying to get logs from node caasp-worker-thehejik-4 pod var-expansion-e6bbf979-ef91-4e44-96b9-9c4701487b9d container dapi-container: <nil>
STEP: delete the pod
Sep 12 13:18:10.887: INFO: Waiting for pod var-expansion-e6bbf979-ef91-4e44-96b9-9c4701487b9d to disappear
Sep 12 13:18:10.895: INFO: Pod var-expansion-e6bbf979-ef91-4e44-96b9-9c4701487b9d no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:18:10.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-1105" for this suite.
Sep 12 13:18:16.911: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:18:16.977: INFO: namespace var-expansion-1105 deletion completed in 6.07877499s

â€¢ [SLOW TEST:10.400 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:18:16.977: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-9005
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Sep 12 13:18:21.659: INFO: Successfully updated pod "pod-update-909307ba-9ac4-4efe-9e2e-123a16656620"
STEP: verifying the updated pod is in kubernetes
Sep 12 13:18:21.679: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:18:21.679: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9005" for this suite.
Sep 12 13:18:43.824: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:18:43.893: INFO: namespace pods-9005 deletion completed in 22.201014805s

â€¢ [SLOW TEST:26.916 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:18:43.893: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2613
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep 12 13:18:44.134: INFO: Waiting up to 5m0s for pod "downwardapi-volume-26af8461-a1a5-445e-a48b-278a335ceecf" in namespace "downward-api-2613" to be "success or failure"
Sep 12 13:18:44.144: INFO: Pod "downwardapi-volume-26af8461-a1a5-445e-a48b-278a335ceecf": Phase="Pending", Reason="", readiness=false. Elapsed: 9.411856ms
Sep 12 13:18:46.146: INFO: Pod "downwardapi-volume-26af8461-a1a5-445e-a48b-278a335ceecf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011676465s
Sep 12 13:18:48.148: INFO: Pod "downwardapi-volume-26af8461-a1a5-445e-a48b-278a335ceecf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013915049s
STEP: Saw pod success
Sep 12 13:18:48.148: INFO: Pod "downwardapi-volume-26af8461-a1a5-445e-a48b-278a335ceecf" satisfied condition "success or failure"
Sep 12 13:18:48.150: INFO: Trying to get logs from node caasp-worker-thehejik-2 pod downwardapi-volume-26af8461-a1a5-445e-a48b-278a335ceecf container client-container: <nil>
STEP: delete the pod
Sep 12 13:18:48.170: INFO: Waiting for pod downwardapi-volume-26af8461-a1a5-445e-a48b-278a335ceecf to disappear
Sep 12 13:18:48.178: INFO: Pod downwardapi-volume-26af8461-a1a5-445e-a48b-278a335ceecf no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:18:48.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2613" for this suite.
Sep 12 13:18:54.193: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:18:54.257: INFO: namespace downward-api-2613 deletion completed in 6.07666043s

â€¢ [SLOW TEST:10.364 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:18:54.258: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-6988
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 12 13:18:54.424: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Sep 12 13:18:56.472: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:18:56.482: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-6988" for this suite.
Sep 12 13:19:02.526: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:19:02.610: INFO: namespace replication-controller-6988 deletion completed in 6.119347372s

â€¢ [SLOW TEST:8.352 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:19:02.610: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9814
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl label
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1211
STEP: creating the pod
Sep 12 13:19:02.774: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 create -f - --namespace=kubectl-9814'
Sep 12 13:19:02.965: INFO: stderr: ""
Sep 12 13:19:02.965: INFO: stdout: "pod/pause created\n"
Sep 12 13:19:02.965: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Sep 12 13:19:02.965: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-9814" to be "running and ready"
Sep 12 13:19:02.987: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 22.153795ms
Sep 12 13:19:04.990: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024697082s
Sep 12 13:19:06.998: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.032734247s
Sep 12 13:19:06.998: INFO: Pod "pause" satisfied condition "running and ready"
Sep 12 13:19:06.998: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: adding the label testing-label with value testing-label-value to a pod
Sep 12 13:19:06.998: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 label pods pause testing-label=testing-label-value --namespace=kubectl-9814'
Sep 12 13:19:07.091: INFO: stderr: ""
Sep 12 13:19:07.091: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Sep 12 13:19:07.091: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get pod pause -L testing-label --namespace=kubectl-9814'
Sep 12 13:19:07.174: INFO: stderr: ""
Sep 12 13:19:07.175: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Sep 12 13:19:07.175: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 label pods pause testing-label- --namespace=kubectl-9814'
Sep 12 13:19:07.265: INFO: stderr: ""
Sep 12 13:19:07.265: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Sep 12 13:19:07.265: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get pod pause -L testing-label --namespace=kubectl-9814'
Sep 12 13:19:07.408: INFO: stderr: ""
Sep 12 13:19:07.408: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    \n"
[AfterEach] [k8s.io] Kubectl label
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1218
STEP: using delete to clean up resources
Sep 12 13:19:07.408: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 delete --grace-period=0 --force -f - --namespace=kubectl-9814'
Sep 12 13:19:07.516: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 12 13:19:07.516: INFO: stdout: "pod \"pause\" force deleted\n"
Sep 12 13:19:07.516: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get rc,svc -l name=pause --no-headers --namespace=kubectl-9814'
Sep 12 13:19:07.602: INFO: stderr: "No resources found.\n"
Sep 12 13:19:07.602: INFO: stdout: ""
Sep 12 13:19:07.602: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get pods -l name=pause --namespace=kubectl-9814 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep 12 13:19:07.701: INFO: stderr: ""
Sep 12 13:19:07.701: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:19:07.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9814" for this suite.
Sep 12 13:19:13.777: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:19:13.840: INFO: namespace kubectl-9814 deletion completed in 6.13191109s

â€¢ [SLOW TEST:11.230 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl label
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:19:13.841: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2431
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on tmpfs
Sep 12 13:19:14.050: INFO: Waiting up to 5m0s for pod "pod-a865efc7-c7ee-4c2c-a055-58e2bb6ad8d8" in namespace "emptydir-2431" to be "success or failure"
Sep 12 13:19:14.060: INFO: Pod "pod-a865efc7-c7ee-4c2c-a055-58e2bb6ad8d8": Phase="Pending", Reason="", readiness=false. Elapsed: 10.096526ms
Sep 12 13:19:16.062: INFO: Pod "pod-a865efc7-c7ee-4c2c-a055-58e2bb6ad8d8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012005829s
Sep 12 13:19:18.072: INFO: Pod "pod-a865efc7-c7ee-4c2c-a055-58e2bb6ad8d8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021487686s
STEP: Saw pod success
Sep 12 13:19:18.072: INFO: Pod "pod-a865efc7-c7ee-4c2c-a055-58e2bb6ad8d8" satisfied condition "success or failure"
Sep 12 13:19:18.076: INFO: Trying to get logs from node caasp-worker-thehejik-3 pod pod-a865efc7-c7ee-4c2c-a055-58e2bb6ad8d8 container test-container: <nil>
STEP: delete the pod
Sep 12 13:19:18.108: INFO: Waiting for pod pod-a865efc7-c7ee-4c2c-a055-58e2bb6ad8d8 to disappear
Sep 12 13:19:18.120: INFO: Pod pod-a865efc7-c7ee-4c2c-a055-58e2bb6ad8d8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:19:18.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2431" for this suite.
Sep 12 13:19:24.135: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:19:24.202: INFO: namespace emptydir-2431 deletion completed in 6.080136763s

â€¢ [SLOW TEST:10.362 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:19:24.203: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-5225
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-configmap-jzfw
STEP: Creating a pod to test atomic-volume-subpath
Sep 12 13:19:24.507: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-jzfw" in namespace "subpath-5225" to be "success or failure"
Sep 12 13:19:24.522: INFO: Pod "pod-subpath-test-configmap-jzfw": Phase="Pending", Reason="", readiness=false. Elapsed: 15.237524ms
Sep 12 13:19:26.525: INFO: Pod "pod-subpath-test-configmap-jzfw": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017836674s
Sep 12 13:19:28.529: INFO: Pod "pod-subpath-test-configmap-jzfw": Phase="Running", Reason="", readiness=true. Elapsed: 4.021591058s
Sep 12 13:19:30.531: INFO: Pod "pod-subpath-test-configmap-jzfw": Phase="Running", Reason="", readiness=true. Elapsed: 6.024030726s
Sep 12 13:19:32.534: INFO: Pod "pod-subpath-test-configmap-jzfw": Phase="Running", Reason="", readiness=true. Elapsed: 8.026785315s
Sep 12 13:19:34.536: INFO: Pod "pod-subpath-test-configmap-jzfw": Phase="Running", Reason="", readiness=true. Elapsed: 10.029264821s
Sep 12 13:19:36.539: INFO: Pod "pod-subpath-test-configmap-jzfw": Phase="Running", Reason="", readiness=true. Elapsed: 12.031753398s
Sep 12 13:19:38.542: INFO: Pod "pod-subpath-test-configmap-jzfw": Phase="Running", Reason="", readiness=true. Elapsed: 14.034727521s
Sep 12 13:19:40.544: INFO: Pod "pod-subpath-test-configmap-jzfw": Phase="Running", Reason="", readiness=true. Elapsed: 16.036834793s
Sep 12 13:19:42.546: INFO: Pod "pod-subpath-test-configmap-jzfw": Phase="Running", Reason="", readiness=true. Elapsed: 18.039430941s
Sep 12 13:19:44.549: INFO: Pod "pod-subpath-test-configmap-jzfw": Phase="Running", Reason="", readiness=true. Elapsed: 20.042044199s
Sep 12 13:19:46.552: INFO: Pod "pod-subpath-test-configmap-jzfw": Phase="Running", Reason="", readiness=true. Elapsed: 22.044752696s
Sep 12 13:19:48.555: INFO: Pod "pod-subpath-test-configmap-jzfw": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.047764308s
STEP: Saw pod success
Sep 12 13:19:48.555: INFO: Pod "pod-subpath-test-configmap-jzfw" satisfied condition "success or failure"
Sep 12 13:19:48.556: INFO: Trying to get logs from node caasp-worker-thehejik-0 pod pod-subpath-test-configmap-jzfw container test-container-subpath-configmap-jzfw: <nil>
STEP: delete the pod
Sep 12 13:19:48.583: INFO: Waiting for pod pod-subpath-test-configmap-jzfw to disappear
Sep 12 13:19:48.590: INFO: Pod pod-subpath-test-configmap-jzfw no longer exists
STEP: Deleting pod pod-subpath-test-configmap-jzfw
Sep 12 13:19:48.590: INFO: Deleting pod "pod-subpath-test-configmap-jzfw" in namespace "subpath-5225"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:19:48.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5225" for this suite.
Sep 12 13:19:54.609: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:19:54.674: INFO: namespace subpath-5225 deletion completed in 6.078884769s

â€¢ [SLOW TEST:30.471 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:19:54.675: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-38
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 12 13:19:54.924: INFO: Creating deployment "test-recreate-deployment"
Sep 12 13:19:54.927: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Sep 12 13:19:54.945: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Sep 12 13:19:56.949: INFO: Waiting deployment "test-recreate-deployment" to complete
Sep 12 13:19:56.951: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703891194, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703891194, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703891194, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703891194, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-6df85df6b9\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 12 13:19:59.032: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Sep 12 13:19:59.036: INFO: Updating deployment test-recreate-deployment
Sep 12 13:19:59.037: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Sep 12 13:19:59.354: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment,GenerateName:,Namespace:deployment-38,SelfLink:/apis/apps/v1/namespaces/deployment-38/deployments/test-recreate-deployment,UID:2fcf3741-4687-4e48-a11d-753a0c2a6fa0,ResourceVersion:25844,Generation:2,CreationTimestamp:2019-09-12 13:19:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[{Available False 2019-09-12 13:19:59 +0000 UTC 2019-09-12 13:19:59 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-09-12 13:19:59 +0000 UTC 2019-09-12 13:19:54 +0000 UTC ReplicaSetUpdated ReplicaSet "test-recreate-deployment-5c8c9cc69d" is progressing.}],ReadyReplicas:0,CollisionCount:nil,},}

Sep 12 13:19:59.356: INFO: New ReplicaSet "test-recreate-deployment-5c8c9cc69d" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5c8c9cc69d,GenerateName:,Namespace:deployment-38,SelfLink:/apis/apps/v1/namespaces/deployment-38/replicasets/test-recreate-deployment-5c8c9cc69d,UID:5e4fcdaa-3fa1-4627-9b02-3e95abbbd719,ResourceVersion:25840,Generation:1,CreationTimestamp:2019-09-12 13:19:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 2fcf3741-4687-4e48-a11d-753a0c2a6fa0 0xc001e5b9b7 0xc001e5b9b8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep 12 13:19:59.356: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Sep 12 13:19:59.356: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-6df85df6b9,GenerateName:,Namespace:deployment-38,SelfLink:/apis/apps/v1/namespaces/deployment-38/replicasets/test-recreate-deployment-6df85df6b9,UID:0f7f3881-dd5d-426c-8688-25861a987667,ResourceVersion:25831,Generation:2,CreationTimestamp:2019-09-12 13:19:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 1,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-recreate-deployment 2fcf3741-4687-4e48-a11d-753a0c2a6fa0 0xc001e5bb67 0xc001e5bb68}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 6df85df6b9,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep 12 13:19:59.358: INFO: Pod "test-recreate-deployment-5c8c9cc69d-6xl8s" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-recreate-deployment-5c8c9cc69d-6xl8s,GenerateName:test-recreate-deployment-5c8c9cc69d-,Namespace:deployment-38,SelfLink:/api/v1/namespaces/deployment-38/pods/test-recreate-deployment-5c8c9cc69d-6xl8s,UID:d8e4d19b-4797-4fe2-995b-6283131f144c,ResourceVersion:25842,Generation:0,CreationTimestamp:2019-09-12 13:19:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod-3,pod-template-hash: 5c8c9cc69d,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-recreate-deployment-5c8c9cc69d 5e4fcdaa-3fa1-4627-9b02-3e95abbbd719 0xc002326e17 0xc002326e18}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-kcdd8 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-kcdd8,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-kcdd8 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:caasp-worker-thehejik-4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc002326f50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc002326f70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:19:59 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:19:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:19:59 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:19:59 +0000 UTC  }],Message:,Reason:,HostIP:10.84.72.31,PodIP:,StartTime:2019-09-12 13:19:59 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:19:59.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-38" for this suite.
Sep 12 13:20:05.376: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:20:05.448: INFO: namespace deployment-38 deletion completed in 6.087193284s

â€¢ [SLOW TEST:10.774 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:20:05.448: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1574
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep 12 13:20:05.618: INFO: Waiting up to 5m0s for pod "downwardapi-volume-be35a111-e386-43cc-bbb9-db3c339eff30" in namespace "projected-1574" to be "success or failure"
Sep 12 13:20:05.628: INFO: Pod "downwardapi-volume-be35a111-e386-43cc-bbb9-db3c339eff30": Phase="Pending", Reason="", readiness=false. Elapsed: 9.4574ms
Sep 12 13:20:07.670: INFO: Pod "downwardapi-volume-be35a111-e386-43cc-bbb9-db3c339eff30": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051194063s
Sep 12 13:20:09.672: INFO: Pod "downwardapi-volume-be35a111-e386-43cc-bbb9-db3c339eff30": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.053547235s
STEP: Saw pod success
Sep 12 13:20:09.672: INFO: Pod "downwardapi-volume-be35a111-e386-43cc-bbb9-db3c339eff30" satisfied condition "success or failure"
Sep 12 13:20:09.674: INFO: Trying to get logs from node caasp-worker-thehejik-0 pod downwardapi-volume-be35a111-e386-43cc-bbb9-db3c339eff30 container client-container: <nil>
STEP: delete the pod
Sep 12 13:20:09.693: INFO: Waiting for pod downwardapi-volume-be35a111-e386-43cc-bbb9-db3c339eff30 to disappear
Sep 12 13:20:09.701: INFO: Pod downwardapi-volume-be35a111-e386-43cc-bbb9-db3c339eff30 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:20:09.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1574" for this suite.
Sep 12 13:20:15.760: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:20:15.843: INFO: namespace projected-1574 deletion completed in 6.139088944s

â€¢ [SLOW TEST:10.395 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:20:15.845: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-8516
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8516.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8516.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Sep 12 13:20:20.036: INFO: DNS probes using dns-8516/dns-test-b0a340c5-1e41-46c7-99fc-fffc23c8f723 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:20:20.123: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8516" for this suite.
Sep 12 13:20:26.166: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:20:26.240: INFO: namespace dns-8516 deletion completed in 6.104857941s

â€¢ [SLOW TEST:10.395 seconds]
[sig-network] DNS
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:20:26.243: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-3827
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-downwardapi-nxj9
STEP: Creating a pod to test atomic-volume-subpath
Sep 12 13:20:26.520: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-nxj9" in namespace "subpath-3827" to be "success or failure"
Sep 12 13:20:26.527: INFO: Pod "pod-subpath-test-downwardapi-nxj9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.895068ms
Sep 12 13:20:28.530: INFO: Pod "pod-subpath-test-downwardapi-nxj9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009664627s
Sep 12 13:20:30.533: INFO: Pod "pod-subpath-test-downwardapi-nxj9": Phase="Running", Reason="", readiness=true. Elapsed: 4.01213293s
Sep 12 13:20:32.535: INFO: Pod "pod-subpath-test-downwardapi-nxj9": Phase="Running", Reason="", readiness=true. Elapsed: 6.014952147s
Sep 12 13:20:34.538: INFO: Pod "pod-subpath-test-downwardapi-nxj9": Phase="Running", Reason="", readiness=true. Elapsed: 8.017398047s
Sep 12 13:20:36.541: INFO: Pod "pod-subpath-test-downwardapi-nxj9": Phase="Running", Reason="", readiness=true. Elapsed: 10.020091673s
Sep 12 13:20:38.545: INFO: Pod "pod-subpath-test-downwardapi-nxj9": Phase="Running", Reason="", readiness=true. Elapsed: 12.024325535s
Sep 12 13:20:40.547: INFO: Pod "pod-subpath-test-downwardapi-nxj9": Phase="Running", Reason="", readiness=true. Elapsed: 14.026932188s
Sep 12 13:20:42.550: INFO: Pod "pod-subpath-test-downwardapi-nxj9": Phase="Running", Reason="", readiness=true. Elapsed: 16.029670899s
Sep 12 13:20:44.552: INFO: Pod "pod-subpath-test-downwardapi-nxj9": Phase="Running", Reason="", readiness=true. Elapsed: 18.031988356s
Sep 12 13:20:46.555: INFO: Pod "pod-subpath-test-downwardapi-nxj9": Phase="Running", Reason="", readiness=true. Elapsed: 20.034867868s
Sep 12 13:20:48.558: INFO: Pod "pod-subpath-test-downwardapi-nxj9": Phase="Running", Reason="", readiness=true. Elapsed: 22.037566418s
Sep 12 13:20:50.561: INFO: Pod "pod-subpath-test-downwardapi-nxj9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.040319638s
STEP: Saw pod success
Sep 12 13:20:50.561: INFO: Pod "pod-subpath-test-downwardapi-nxj9" satisfied condition "success or failure"
Sep 12 13:20:50.562: INFO: Trying to get logs from node caasp-worker-thehejik-3 pod pod-subpath-test-downwardapi-nxj9 container test-container-subpath-downwardapi-nxj9: <nil>
STEP: delete the pod
Sep 12 13:20:50.588: INFO: Waiting for pod pod-subpath-test-downwardapi-nxj9 to disappear
Sep 12 13:20:50.600: INFO: Pod pod-subpath-test-downwardapi-nxj9 no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-nxj9
Sep 12 13:20:50.600: INFO: Deleting pod "pod-subpath-test-downwardapi-nxj9" in namespace "subpath-3827"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:20:50.602: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-3827" for this suite.
Sep 12 13:20:56.619: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:20:56.712: INFO: namespace subpath-3827 deletion completed in 6.106495341s

â€¢ [SLOW TEST:30.469 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:20:56.712: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4523
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1517
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep 12 13:20:56.870: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 run e2e-test-nginx-rc --image=docker.io/library/nginx:1.14-alpine --generator=run/v1 --namespace=kubectl-4523'
Sep 12 13:20:56.961: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Sep 12 13:20:56.961: INFO: stdout: "replicationcontroller/e2e-test-nginx-rc created\n"
STEP: verifying the rc e2e-test-nginx-rc was created
Sep 12 13:20:56.971: INFO: Waiting for rc e2e-test-nginx-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Sep 12 13:20:56.979: INFO: scanned /root for discovery docs: <nil>
Sep 12 13:20:56.979: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 rolling-update e2e-test-nginx-rc --update-period=1s --image=docker.io/library/nginx:1.14-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-4523'
Sep 12 13:21:12.780: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Sep 12 13:21:12.781: INFO: stdout: "Created e2e-test-nginx-rc-92208850cbfbc805e2887c636fac2913\nScaling up e2e-test-nginx-rc-92208850cbfbc805e2887c636fac2913 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-92208850cbfbc805e2887c636fac2913 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-92208850cbfbc805e2887c636fac2913 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
Sep 12 13:21:12.781: INFO: stdout: "Created e2e-test-nginx-rc-92208850cbfbc805e2887c636fac2913\nScaling up e2e-test-nginx-rc-92208850cbfbc805e2887c636fac2913 from 0 to 1, scaling down e2e-test-nginx-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-nginx-rc-92208850cbfbc805e2887c636fac2913 up to 1\nScaling e2e-test-nginx-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-nginx-rc\nRenaming e2e-test-nginx-rc-92208850cbfbc805e2887c636fac2913 to e2e-test-nginx-rc\nreplicationcontroller/e2e-test-nginx-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-nginx-rc pods to come up.
Sep 12 13:21:12.781: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-nginx-rc --namespace=kubectl-4523'
Sep 12 13:21:12.869: INFO: stderr: ""
Sep 12 13:21:12.869: INFO: stdout: "e2e-test-nginx-rc-92208850cbfbc805e2887c636fac2913-2v42r "
Sep 12 13:21:12.869: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get pods e2e-test-nginx-rc-92208850cbfbc805e2887c636fac2913-2v42r -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-nginx-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4523'
Sep 12 13:21:12.954: INFO: stderr: ""
Sep 12 13:21:12.954: INFO: stdout: "true"
Sep 12 13:21:12.954: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get pods e2e-test-nginx-rc-92208850cbfbc805e2887c636fac2913-2v42r -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-nginx-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4523'
Sep 12 13:21:13.032: INFO: stderr: ""
Sep 12 13:21:13.032: INFO: stdout: "docker.io/library/nginx:1.14-alpine"
Sep 12 13:21:13.032: INFO: e2e-test-nginx-rc-92208850cbfbc805e2887c636fac2913-2v42r is verified up and running
[AfterEach] [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1523
Sep 12 13:21:13.032: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 delete rc e2e-test-nginx-rc --namespace=kubectl-4523'
Sep 12 13:21:13.132: INFO: stderr: ""
Sep 12 13:21:13.132: INFO: stdout: "replicationcontroller \"e2e-test-nginx-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:21:13.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4523" for this suite.
Sep 12 13:21:35.154: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:21:35.220: INFO: namespace kubectl-4523 deletion completed in 22.084567344s

â€¢ [SLOW TEST:38.508 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl rolling-update
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:21:35.223: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-5515
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 12 13:21:43.436: INFO: Waiting up to 5m0s for pod "client-envvars-6e32a573-5c0a-45ba-85d8-b964a6dbb1cc" in namespace "pods-5515" to be "success or failure"
Sep 12 13:21:43.447: INFO: Pod "client-envvars-6e32a573-5c0a-45ba-85d8-b964a6dbb1cc": Phase="Pending", Reason="", readiness=false. Elapsed: 10.632689ms
Sep 12 13:21:45.449: INFO: Pod "client-envvars-6e32a573-5c0a-45ba-85d8-b964a6dbb1cc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013039697s
Sep 12 13:21:47.452: INFO: Pod "client-envvars-6e32a573-5c0a-45ba-85d8-b964a6dbb1cc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015501686s
STEP: Saw pod success
Sep 12 13:21:47.452: INFO: Pod "client-envvars-6e32a573-5c0a-45ba-85d8-b964a6dbb1cc" satisfied condition "success or failure"
Sep 12 13:21:47.454: INFO: Trying to get logs from node caasp-worker-thehejik-1 pod client-envvars-6e32a573-5c0a-45ba-85d8-b964a6dbb1cc container env3cont: <nil>
STEP: delete the pod
Sep 12 13:21:47.481: INFO: Waiting for pod client-envvars-6e32a573-5c0a-45ba-85d8-b964a6dbb1cc to disappear
Sep 12 13:21:47.491: INFO: Pod client-envvars-6e32a573-5c0a-45ba-85d8-b964a6dbb1cc no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:21:47.492: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5515" for this suite.
Sep 12 13:22:37.512: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:22:37.581: INFO: namespace pods-5515 deletion completed in 50.086924522s

â€¢ [SLOW TEST:62.358 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:22:37.583: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-8354
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0912 13:22:47.856605      18 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep 12 13:22:47.856: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:22:47.856: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8354" for this suite.
Sep 12 13:22:55.885: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:22:55.960: INFO: namespace gc-8354 deletion completed in 8.097315789s

â€¢ [SLOW TEST:18.376 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:22:55.960: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-489
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-configmap-4kwh
STEP: Creating a pod to test atomic-volume-subpath
Sep 12 13:22:56.141: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-4kwh" in namespace "subpath-489" to be "success or failure"
Sep 12 13:22:56.149: INFO: Pod "pod-subpath-test-configmap-4kwh": Phase="Pending", Reason="", readiness=false. Elapsed: 8.389248ms
Sep 12 13:22:58.152: INFO: Pod "pod-subpath-test-configmap-4kwh": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010858384s
Sep 12 13:23:00.154: INFO: Pod "pod-subpath-test-configmap-4kwh": Phase="Running", Reason="", readiness=true. Elapsed: 4.013009284s
Sep 12 13:23:02.156: INFO: Pod "pod-subpath-test-configmap-4kwh": Phase="Running", Reason="", readiness=true. Elapsed: 6.015162468s
Sep 12 13:23:04.158: INFO: Pod "pod-subpath-test-configmap-4kwh": Phase="Running", Reason="", readiness=true. Elapsed: 8.017406851s
Sep 12 13:23:06.160: INFO: Pod "pod-subpath-test-configmap-4kwh": Phase="Running", Reason="", readiness=true. Elapsed: 10.019397171s
Sep 12 13:23:08.170: INFO: Pod "pod-subpath-test-configmap-4kwh": Phase="Running", Reason="", readiness=true. Elapsed: 12.029608451s
Sep 12 13:23:10.173: INFO: Pod "pod-subpath-test-configmap-4kwh": Phase="Running", Reason="", readiness=true. Elapsed: 14.031805279s
Sep 12 13:23:12.175: INFO: Pod "pod-subpath-test-configmap-4kwh": Phase="Running", Reason="", readiness=true. Elapsed: 16.034349129s
Sep 12 13:23:14.177: INFO: Pod "pod-subpath-test-configmap-4kwh": Phase="Running", Reason="", readiness=true. Elapsed: 18.03649129s
Sep 12 13:23:16.180: INFO: Pod "pod-subpath-test-configmap-4kwh": Phase="Running", Reason="", readiness=true. Elapsed: 20.038789091s
Sep 12 13:23:18.182: INFO: Pod "pod-subpath-test-configmap-4kwh": Phase="Running", Reason="", readiness=true. Elapsed: 22.041151428s
Sep 12 13:23:20.184: INFO: Pod "pod-subpath-test-configmap-4kwh": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.043167878s
STEP: Saw pod success
Sep 12 13:23:20.184: INFO: Pod "pod-subpath-test-configmap-4kwh" satisfied condition "success or failure"
Sep 12 13:23:20.186: INFO: Trying to get logs from node caasp-worker-thehejik-4 pod pod-subpath-test-configmap-4kwh container test-container-subpath-configmap-4kwh: <nil>
STEP: delete the pod
Sep 12 13:23:20.206: INFO: Waiting for pod pod-subpath-test-configmap-4kwh to disappear
Sep 12 13:23:20.217: INFO: Pod pod-subpath-test-configmap-4kwh no longer exists
STEP: Deleting pod pod-subpath-test-configmap-4kwh
Sep 12 13:23:20.217: INFO: Deleting pod "pod-subpath-test-configmap-4kwh" in namespace "subpath-489"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:23:20.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-489" for this suite.
Sep 12 13:23:26.243: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:23:26.326: INFO: namespace subpath-489 deletion completed in 6.105316042s

â€¢ [SLOW TEST:30.366 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:23:26.329: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4153
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on node default medium
Sep 12 13:23:26.488: INFO: Waiting up to 5m0s for pod "pod-f9b8c865-24c3-44d5-9c5c-4cc70a8b8824" in namespace "emptydir-4153" to be "success or failure"
Sep 12 13:23:26.498: INFO: Pod "pod-f9b8c865-24c3-44d5-9c5c-4cc70a8b8824": Phase="Pending", Reason="", readiness=false. Elapsed: 10.092779ms
Sep 12 13:23:28.504: INFO: Pod "pod-f9b8c865-24c3-44d5-9c5c-4cc70a8b8824": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016394323s
Sep 12 13:23:30.507: INFO: Pod "pod-f9b8c865-24c3-44d5-9c5c-4cc70a8b8824": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01887054s
STEP: Saw pod success
Sep 12 13:23:30.507: INFO: Pod "pod-f9b8c865-24c3-44d5-9c5c-4cc70a8b8824" satisfied condition "success or failure"
Sep 12 13:23:30.508: INFO: Trying to get logs from node caasp-worker-thehejik-1 pod pod-f9b8c865-24c3-44d5-9c5c-4cc70a8b8824 container test-container: <nil>
STEP: delete the pod
Sep 12 13:23:30.531: INFO: Waiting for pod pod-f9b8c865-24c3-44d5-9c5c-4cc70a8b8824 to disappear
Sep 12 13:23:30.541: INFO: Pod pod-f9b8c865-24c3-44d5-9c5c-4cc70a8b8824 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:23:30.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4153" for this suite.
Sep 12 13:23:36.557: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:23:36.620: INFO: namespace emptydir-4153 deletion completed in 6.076442829s

â€¢ [SLOW TEST:10.291 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:23:36.621: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6074
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Sep 12 13:23:36.782: INFO: Waiting up to 5m0s for pod "downward-api-fc8c22cb-a703-4b38-a356-ed6c9c4b014b" in namespace "downward-api-6074" to be "success or failure"
Sep 12 13:23:36.802: INFO: Pod "downward-api-fc8c22cb-a703-4b38-a356-ed6c9c4b014b": Phase="Pending", Reason="", readiness=false. Elapsed: 20.798365ms
Sep 12 13:23:38.808: INFO: Pod "downward-api-fc8c22cb-a703-4b38-a356-ed6c9c4b014b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026783823s
Sep 12 13:23:40.811: INFO: Pod "downward-api-fc8c22cb-a703-4b38-a356-ed6c9c4b014b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029147177s
STEP: Saw pod success
Sep 12 13:23:40.811: INFO: Pod "downward-api-fc8c22cb-a703-4b38-a356-ed6c9c4b014b" satisfied condition "success or failure"
Sep 12 13:23:40.812: INFO: Trying to get logs from node caasp-worker-thehejik-5 pod downward-api-fc8c22cb-a703-4b38-a356-ed6c9c4b014b container dapi-container: <nil>
STEP: delete the pod
Sep 12 13:23:40.835: INFO: Waiting for pod downward-api-fc8c22cb-a703-4b38-a356-ed6c9c4b014b to disappear
Sep 12 13:23:40.844: INFO: Pod downward-api-fc8c22cb-a703-4b38-a356-ed6c9c4b014b no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:23:40.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6074" for this suite.
Sep 12 13:23:46.860: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:23:46.927: INFO: namespace downward-api-6074 deletion completed in 6.080357115s

â€¢ [SLOW TEST:10.306 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:23:46.927: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-7547
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Sep 12 13:23:47.133: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 13:23:47.148: INFO: Number of nodes with available pods: 0
Sep 12 13:23:47.148: INFO: Node caasp-worker-thehejik-0 is running more than one daemon pod
Sep 12 13:23:48.151: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 13:23:48.154: INFO: Number of nodes with available pods: 0
Sep 12 13:23:48.154: INFO: Node caasp-worker-thehejik-0 is running more than one daemon pod
Sep 12 13:23:49.151: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 13:23:49.153: INFO: Number of nodes with available pods: 0
Sep 12 13:23:49.153: INFO: Node caasp-worker-thehejik-0 is running more than one daemon pod
Sep 12 13:23:50.151: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 13:23:50.154: INFO: Number of nodes with available pods: 3
Sep 12 13:23:50.154: INFO: Node caasp-worker-thehejik-0 is running more than one daemon pod
Sep 12 13:23:51.152: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 13:23:51.154: INFO: Number of nodes with available pods: 6
Sep 12 13:23:51.154: INFO: Number of running nodes: 6, number of available pods: 6
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Sep 12 13:23:51.174: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 13:23:51.182: INFO: Number of nodes with available pods: 6
Sep 12 13:23:51.182: INFO: Number of running nodes: 6, number of available pods: 6
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7547, will wait for the garbage collector to delete the pods
Sep 12 13:23:52.259: INFO: Deleting DaemonSet.extensions daemon-set took: 4.49665ms
Sep 12 13:23:52.659: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.221455ms
Sep 12 13:24:04.861: INFO: Number of nodes with available pods: 0
Sep 12 13:24:04.861: INFO: Number of running nodes: 0, number of available pods: 0
Sep 12 13:24:04.862: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7547/daemonsets","resourceVersion":"27415"},"items":null}

Sep 12 13:24:04.864: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7547/pods","resourceVersion":"27415"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:24:04.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7547" for this suite.
Sep 12 13:24:10.892: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:24:10.957: INFO: namespace daemonsets-7547 deletion completed in 6.078450358s

â€¢ [SLOW TEST:24.030 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:24:10.960: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-223
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:24:16.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-223" for this suite.
Sep 12 13:24:38.173: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:24:38.251: INFO: namespace replication-controller-223 deletion completed in 22.091582866s

â€¢ [SLOW TEST:27.291 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:24:38.251: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-5304
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Sep 12 13:24:41.454: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:24:41.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5304" for this suite.
Sep 12 13:24:47.495: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:24:47.567: INFO: namespace container-runtime-5304 deletion completed in 6.086680261s

â€¢ [SLOW TEST:9.316 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:24:47.567: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4180
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: validating api versions
Sep 12 13:24:47.719: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 api-versions'
Sep 12 13:24:47.819: INFO: stderr: ""
Sep 12 13:24:47.819: INFO: stdout: "admissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\napps/v1beta1\napps/v1beta2\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncilium.io/v2\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\ndex.coreos.com/v1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:24:47.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4180" for this suite.
Sep 12 13:24:53.836: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:24:53.903: INFO: namespace kubectl-4180 deletion completed in 6.081277454s

â€¢ [SLOW TEST:6.337 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl api-versions
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:24:53.906: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-1022
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 12 13:24:54.068: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Sep 12 13:24:54.140: INFO: Pod name sample-pod: Found 0 pods out of 1
Sep 12 13:24:59.143: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Sep 12 13:24:59.144: INFO: Creating deployment "test-rolling-update-deployment"
Sep 12 13:24:59.150: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Sep 12 13:24:59.174: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Sep 12 13:25:01.182: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Sep 12 13:25:01.183: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703891499, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703891499, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703891499, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703891499, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-79f6b9d75c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 12 13:25:03.186: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Sep 12 13:25:03.192: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment,GenerateName:,Namespace:deployment-1022,SelfLink:/apis/apps/v1/namespaces/deployment-1022/deployments/test-rolling-update-deployment,UID:d16e178c-26d9-4992-9623-554c5b45345a,ResourceVersion:27747,Generation:1,CreationTimestamp:2019-09-12 13:24:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-09-12 13:24:59 +0000 UTC 2019-09-12 13:24:59 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-09-12 13:25:02 +0000 UTC 2019-09-12 13:24:59 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rolling-update-deployment-79f6b9d75c" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Sep 12 13:25:03.194: INFO: New ReplicaSet "test-rolling-update-deployment-79f6b9d75c" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79f6b9d75c,GenerateName:,Namespace:deployment-1022,SelfLink:/apis/apps/v1/namespaces/deployment-1022/replicasets/test-rolling-update-deployment-79f6b9d75c,UID:46ed2034-cf6c-48a1-ba9a-b6cac6beedfb,ResourceVersion:27736,Generation:1,CreationTimestamp:2019-09-12 13:24:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305833,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment d16e178c-26d9-4992-9623-554c5b45345a 0xc003b38be7 0xc003b38be8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Sep 12 13:25:03.194: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Sep 12 13:25:03.194: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-controller,GenerateName:,Namespace:deployment-1022,SelfLink:/apis/apps/v1/namespaces/deployment-1022/replicasets/test-rolling-update-controller,UID:b0e03848-7705-4ac6-b190-e2b922713ddb,ResourceVersion:27745,Generation:2,CreationTimestamp:2019-09-12 13:24:54 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 3546343826724305832,},OwnerReferences:[{apps/v1 Deployment test-rolling-update-deployment d16e178c-26d9-4992-9623-554c5b45345a 0xc003b38b17 0xc003b38b18}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep 12 13:25:03.196: INFO: Pod "test-rolling-update-deployment-79f6b9d75c-pbtz6" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rolling-update-deployment-79f6b9d75c-pbtz6,GenerateName:test-rolling-update-deployment-79f6b9d75c-,Namespace:deployment-1022,SelfLink:/api/v1/namespaces/deployment-1022/pods/test-rolling-update-deployment-79f6b9d75c-pbtz6,UID:238e3d35-ec39-48b1-a710-f165d50a3463,ResourceVersion:27735,Generation:0,CreationTimestamp:2019-09-12 13:24:59 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: sample-pod,pod-template-hash: 79f6b9d75c,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rolling-update-deployment-79f6b9d75c 46ed2034-cf6c-48a1-ba9a-b6cac6beedfb 0xc003b2a197 0xc003b2a198}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-sc67h {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-sc67h,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-sc67h true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:caasp-worker-thehejik-4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003b2a200} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003b2a220}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:24:59 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:25:02 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:25:02 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:24:59 +0000 UTC  }],Message:,Reason:,HostIP:10.84.72.31,PodIP:10.244.2.222,StartTime:2019-09-12 13:24:59 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-09-12 13:25:01 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 gcr.io/kubernetes-e2e-test-images/redis@sha256:2238f5a02d2648d41cc94a88f084060fbfa860890220328eb92696bf2ac649c9 cri-o://fbfd48c5152ccbb6f49daeba514516ee78575c3efe15e4793094d7e720042e14}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:25:03.196: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1022" for this suite.
Sep 12 13:25:09.214: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:25:09.279: INFO: namespace deployment-1022 deletion completed in 6.079816251s

â€¢ [SLOW TEST:15.373 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:25:09.279: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8929
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0644 on tmpfs
Sep 12 13:25:09.450: INFO: Waiting up to 5m0s for pod "pod-93008cf0-e71d-4359-8700-39190b938ad1" in namespace "emptydir-8929" to be "success or failure"
Sep 12 13:25:09.461: INFO: Pod "pod-93008cf0-e71d-4359-8700-39190b938ad1": Phase="Pending", Reason="", readiness=false. Elapsed: 10.166401ms
Sep 12 13:25:11.463: INFO: Pod "pod-93008cf0-e71d-4359-8700-39190b938ad1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012204404s
Sep 12 13:25:13.465: INFO: Pod "pod-93008cf0-e71d-4359-8700-39190b938ad1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014355555s
STEP: Saw pod success
Sep 12 13:25:13.465: INFO: Pod "pod-93008cf0-e71d-4359-8700-39190b938ad1" satisfied condition "success or failure"
Sep 12 13:25:13.466: INFO: Trying to get logs from node caasp-worker-thehejik-1 pod pod-93008cf0-e71d-4359-8700-39190b938ad1 container test-container: <nil>
STEP: delete the pod
Sep 12 13:25:13.490: INFO: Waiting for pod pod-93008cf0-e71d-4359-8700-39190b938ad1 to disappear
Sep 12 13:25:13.496: INFO: Pod pod-93008cf0-e71d-4359-8700-39190b938ad1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:25:13.496: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8929" for this suite.
Sep 12 13:25:19.513: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:25:19.662: INFO: namespace emptydir-8929 deletion completed in 6.163619185s

â€¢ [SLOW TEST:10.383 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:25:19.662: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-4424
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-4424
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-4424
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-4424
Sep 12 13:25:19.853: INFO: Found 0 stateful pods, waiting for 1
Sep 12 13:25:29.856: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Sep 12 13:25:29.857: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 exec --namespace=statefulset-4424 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep 12 13:25:30.855: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep 12 13:25:30.855: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep 12 13:25:30.855: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep 12 13:25:30.857: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Sep 12 13:25:40.860: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep 12 13:25:40.860: INFO: Waiting for statefulset status.replicas updated to 0
Sep 12 13:25:40.895: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999748s
Sep 12 13:25:41.898: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.970871364s
Sep 12 13:25:42.900: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.968455213s
Sep 12 13:25:43.902: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.966199264s
Sep 12 13:25:44.905: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.963783548s
Sep 12 13:25:45.907: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.961526165s
Sep 12 13:25:46.910: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.959062617s
Sep 12 13:25:47.912: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.956593858s
Sep 12 13:25:48.915: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.953720354s
Sep 12 13:25:49.917: INFO: Verifying statefulset ss doesn't scale past 1 for another 951.411362ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-4424
Sep 12 13:25:50.920: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 exec --namespace=statefulset-4424 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 12 13:25:51.070: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep 12 13:25:51.070: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep 12 13:25:51.070: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep 12 13:25:51.072: INFO: Found 1 stateful pods, waiting for 3
Sep 12 13:26:01.075: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Sep 12 13:26:01.075: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Sep 12 13:26:01.075: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Sep 12 13:26:01.079: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 exec --namespace=statefulset-4424 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep 12 13:26:01.243: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep 12 13:26:01.243: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep 12 13:26:01.243: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep 12 13:26:01.243: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 exec --namespace=statefulset-4424 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep 12 13:26:01.552: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep 12 13:26:01.552: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep 12 13:26:01.552: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep 12 13:26:01.552: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 exec --namespace=statefulset-4424 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep 12 13:26:01.767: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep 12 13:26:01.767: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep 12 13:26:01.767: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep 12 13:26:01.767: INFO: Waiting for statefulset status.replicas updated to 0
Sep 12 13:26:01.769: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Sep 12 13:26:11.773: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep 12 13:26:11.773: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Sep 12 13:26:11.773: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Sep 12 13:26:11.789: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999739s
Sep 12 13:26:12.792: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.988008072s
Sep 12 13:26:13.795: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.985114796s
Sep 12 13:26:14.797: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.982253231s
Sep 12 13:26:15.800: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.979590449s
Sep 12 13:26:16.803: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.976838088s
Sep 12 13:26:17.805: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.974282285s
Sep 12 13:26:18.808: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.971505991s
Sep 12 13:26:19.812: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.968472572s
Sep 12 13:26:20.814: INFO: Verifying statefulset ss doesn't scale past 3 for another 965.228991ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-4424
Sep 12 13:26:21.817: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 exec --namespace=statefulset-4424 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 12 13:26:21.958: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep 12 13:26:21.958: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep 12 13:26:21.958: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep 12 13:26:21.959: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 exec --namespace=statefulset-4424 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 12 13:26:22.190: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep 12 13:26:22.190: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep 12 13:26:22.190: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep 12 13:26:22.190: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 exec --namespace=statefulset-4424 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 12 13:26:22.336: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep 12 13:26:22.336: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep 12 13:26:22.336: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep 12 13:26:22.336: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Sep 12 13:26:42.346: INFO: Deleting all statefulset in ns statefulset-4424
Sep 12 13:26:42.348: INFO: Scaling statefulset ss to 0
Sep 12 13:26:42.353: INFO: Waiting for statefulset status.replicas updated to 0
Sep 12 13:26:42.354: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:26:42.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4424" for this suite.
Sep 12 13:26:48.390: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:26:48.457: INFO: namespace statefulset-4424 deletion completed in 6.081089105s

â€¢ [SLOW TEST:88.795 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:26:48.458: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5920
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating all guestbook components
Sep 12 13:26:48.726: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Sep 12 13:26:48.726: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 create -f - --namespace=kubectl-5920'
Sep 12 13:26:48.947: INFO: stderr: ""
Sep 12 13:26:48.947: INFO: stdout: "service/redis-slave created\n"
Sep 12 13:26:48.947: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Sep 12 13:26:48.947: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 create -f - --namespace=kubectl-5920'
Sep 12 13:26:49.164: INFO: stderr: ""
Sep 12 13:26:49.164: INFO: stdout: "service/redis-master created\n"
Sep 12 13:26:49.164: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Sep 12 13:26:49.164: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 create -f - --namespace=kubectl-5920'
Sep 12 13:26:49.372: INFO: stderr: ""
Sep 12 13:26:49.372: INFO: stdout: "service/frontend created\n"
Sep 12 13:26:49.372: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Sep 12 13:26:49.372: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 create -f - --namespace=kubectl-5920'
Sep 12 13:26:49.565: INFO: stderr: ""
Sep 12 13:26:49.565: INFO: stdout: "deployment.apps/frontend created\n"
Sep 12 13:26:49.565: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: gcr.io/kubernetes-e2e-test-images/redis:1.0
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Sep 12 13:26:49.565: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 create -f - --namespace=kubectl-5920'
Sep 12 13:26:49.746: INFO: stderr: ""
Sep 12 13:26:49.746: INFO: stdout: "deployment.apps/redis-master created\n"
Sep 12 13:26:49.747: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: gcr.io/google-samples/gb-redisslave:v3
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Sep 12 13:26:49.747: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 create -f - --namespace=kubectl-5920'
Sep 12 13:26:50.033: INFO: stderr: ""
Sep 12 13:26:50.033: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Sep 12 13:26:50.033: INFO: Waiting for all frontend pods to be Running.
Sep 12 13:27:25.085: INFO: Waiting for frontend to serve content.
Sep 12 13:27:25.248: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Network is unreachable [tcp://redis-slave:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Network is unre...', 101)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-sla...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\St in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Sep 12 13:27:30.258: INFO: Trying to add a new entry to the guestbook.
Sep 12 13:27:30.268: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Sep 12 13:27:30.334: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 delete --grace-period=0 --force -f - --namespace=kubectl-5920'
Sep 12 13:27:30.558: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 12 13:27:30.558: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Sep 12 13:27:30.558: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 delete --grace-period=0 --force -f - --namespace=kubectl-5920'
Sep 12 13:27:30.685: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 12 13:27:30.685: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Sep 12 13:27:30.685: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 delete --grace-period=0 --force -f - --namespace=kubectl-5920'
Sep 12 13:27:30.838: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 12 13:27:30.838: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Sep 12 13:27:30.838: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 delete --grace-period=0 --force -f - --namespace=kubectl-5920'
Sep 12 13:27:30.924: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 12 13:27:30.924: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Sep 12 13:27:30.924: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 delete --grace-period=0 --force -f - --namespace=kubectl-5920'
Sep 12 13:27:31.018: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 12 13:27:31.018: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Sep 12 13:27:31.019: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 delete --grace-period=0 --force -f - --namespace=kubectl-5920'
Sep 12 13:27:31.116: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 12 13:27:31.116: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:27:31.116: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5920" for this suite.
Sep 12 13:28:09.141: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:28:09.222: INFO: namespace kubectl-5920 deletion completed in 38.094451877s

â€¢ [SLOW TEST:80.764 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Guestbook application
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:28:09.222: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-2550
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 12 13:28:09.405: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Sep 12 13:28:14.408: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Sep 12 13:28:14.408: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Sep 12 13:28:14.463: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment,GenerateName:,Namespace:deployment-2550,SelfLink:/apis/apps/v1/namespaces/deployment-2550/deployments/test-cleanup-deployment,UID:9c059cf4-3229-49ee-ae0f-3b8a4e69c1c8,ResourceVersion:28961,Generation:1,CreationTimestamp:2019-09-12 13:28:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[],ReadyReplicas:0,CollisionCount:nil,},}

Sep 12 13:28:14.495: INFO: New ReplicaSet "test-cleanup-deployment-55bbcbc84c" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55bbcbc84c,GenerateName:,Namespace:deployment-2550,SelfLink:/apis/apps/v1/namespaces/deployment-2550/replicasets/test-cleanup-deployment-55bbcbc84c,UID:46e0e43f-6409-4459-b203-9c275d8fa5f8,ResourceVersion:28963,Generation:1,CreationTimestamp:2019-09-12 13:28:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 9c059cf4-3229-49ee-ae0f-3b8a4e69c1c8 0xc003220327 0xc003220328}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep 12 13:28:14.495: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Sep 12 13:28:14.495: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller,GenerateName:,Namespace:deployment-2550,SelfLink:/apis/apps/v1/namespaces/deployment-2550/replicasets/test-cleanup-controller,UID:4b17fc3f-33c4-4b75-bae8-e339a5e944bc,ResourceVersion:28962,Generation:1,CreationTimestamp:2019-09-12 13:28:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[{apps/v1 Deployment test-cleanup-deployment 9c059cf4-3229-49ee-ae0f-3b8a4e69c1c8 0xc003220247 0xc003220248}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Sep 12 13:28:14.522: INFO: Pod "test-cleanup-controller-5lv7s" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-controller-5lv7s,GenerateName:test-cleanup-controller-,Namespace:deployment-2550,SelfLink:/api/v1/namespaces/deployment-2550/pods/test-cleanup-controller-5lv7s,UID:c07cfcaa-f3f3-4bbb-ae14-7e502adbe1c0,ResourceVersion:28956,Generation:0,CreationTimestamp:2019-09-12 13:28:09 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod: nginx,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-controller 4b17fc3f-33c4-4b75-bae8-e339a5e944bc 0xc003220be7 0xc003220be8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4v4gb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4v4gb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-4v4gb true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:caasp-worker-thehejik-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003220c50} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003220c70}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:28:09 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:28:12 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:28:12 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:28:09 +0000 UTC  }],Message:,Reason:,HostIP:10.84.73.79,PodIP:10.244.1.21,StartTime:2019-09-12 13:28:09 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-12 13:28:11 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:a3a0c4126587884f8d3090efca87f5af075d7e7ac8308cffc09a5a082d5f4760 cri-o://900eaab67508e5a4a61fb4c74e6f9b3e97391baf9b95108765b59308b4f28b3a}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 12 13:28:14.522: INFO: Pod "test-cleanup-deployment-55bbcbc84c-wlmtt" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-cleanup-deployment-55bbcbc84c-wlmtt,GenerateName:test-cleanup-deployment-55bbcbc84c-,Namespace:deployment-2550,SelfLink:/api/v1/namespaces/deployment-2550/pods/test-cleanup-deployment-55bbcbc84c-wlmtt,UID:441b7ba7-b610-4c0a-af54-bb1733a56add,ResourceVersion:28967,Generation:0,CreationTimestamp:2019-09-12 13:28:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: cleanup-pod,pod-template-hash: 55bbcbc84c,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-cleanup-deployment-55bbcbc84c 46e0e43f-6409-4459-b203-9c275d8fa5f8 0xc003220d47 0xc003220d48}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-4v4gb {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-4v4gb,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-4v4gb true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:caasp-worker-thehejik-4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc003220db0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc003220dd0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:28:14 +0000 UTC  }],Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:28:14.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2550" for this suite.
Sep 12 13:28:20.561: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:28:20.628: INFO: namespace deployment-2550 deletion completed in 6.088629804s

â€¢ [SLOW TEST:11.406 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:28:20.629: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-1888
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 12 13:28:20.810: INFO: Create a RollingUpdate DaemonSet
Sep 12 13:28:20.813: INFO: Check that daemon pods launch on every node of the cluster
Sep 12 13:28:20.823: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 13:28:20.832: INFO: Number of nodes with available pods: 0
Sep 12 13:28:20.832: INFO: Node caasp-worker-thehejik-0 is running more than one daemon pod
Sep 12 13:28:21.835: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 13:28:21.838: INFO: Number of nodes with available pods: 0
Sep 12 13:28:21.838: INFO: Node caasp-worker-thehejik-0 is running more than one daemon pod
Sep 12 13:28:22.836: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 13:28:22.850: INFO: Number of nodes with available pods: 0
Sep 12 13:28:22.850: INFO: Node caasp-worker-thehejik-0 is running more than one daemon pod
Sep 12 13:28:23.835: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 13:28:23.838: INFO: Number of nodes with available pods: 4
Sep 12 13:28:23.838: INFO: Node caasp-worker-thehejik-2 is running more than one daemon pod
Sep 12 13:28:24.838: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 13:28:24.841: INFO: Number of nodes with available pods: 6
Sep 12 13:28:24.841: INFO: Number of running nodes: 6, number of available pods: 6
Sep 12 13:28:24.841: INFO: Update the DaemonSet to trigger a rollout
Sep 12 13:28:24.845: INFO: Updating DaemonSet daemon-set
Sep 12 13:28:36.867: INFO: Roll back the DaemonSet before rollout is complete
Sep 12 13:28:36.871: INFO: Updating DaemonSet daemon-set
Sep 12 13:28:36.871: INFO: Make sure DaemonSet rollback is complete
Sep 12 13:28:36.880: INFO: Wrong image for pod: daemon-set-rr5sr. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Sep 12 13:28:36.880: INFO: Pod daemon-set-rr5sr is not available
Sep 12 13:28:36.890: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 13:28:37.893: INFO: Wrong image for pod: daemon-set-rr5sr. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Sep 12 13:28:37.893: INFO: Pod daemon-set-rr5sr is not available
Sep 12 13:28:37.895: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 13:28:38.893: INFO: Wrong image for pod: daemon-set-rr5sr. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Sep 12 13:28:38.893: INFO: Pod daemon-set-rr5sr is not available
Sep 12 13:28:38.896: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 13:28:39.893: INFO: Wrong image for pod: daemon-set-rr5sr. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Sep 12 13:28:39.893: INFO: Pod daemon-set-rr5sr is not available
Sep 12 13:28:39.896: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 13:28:40.893: INFO: Wrong image for pod: daemon-set-rr5sr. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Sep 12 13:28:40.893: INFO: Pod daemon-set-rr5sr is not available
Sep 12 13:28:40.895: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 13:28:41.893: INFO: Wrong image for pod: daemon-set-rr5sr. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Sep 12 13:28:41.893: INFO: Pod daemon-set-rr5sr is not available
Sep 12 13:28:41.896: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 13:28:42.893: INFO: Wrong image for pod: daemon-set-rr5sr. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Sep 12 13:28:42.893: INFO: Pod daemon-set-rr5sr is not available
Sep 12 13:28:42.896: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 13:28:43.893: INFO: Wrong image for pod: daemon-set-rr5sr. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Sep 12 13:28:43.893: INFO: Pod daemon-set-rr5sr is not available
Sep 12 13:28:43.896: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 13:28:44.892: INFO: Wrong image for pod: daemon-set-rr5sr. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Sep 12 13:28:44.893: INFO: Pod daemon-set-rr5sr is not available
Sep 12 13:28:44.896: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 13:28:45.893: INFO: Wrong image for pod: daemon-set-rr5sr. Expected: docker.io/library/nginx:1.14-alpine, got: foo:non-existent.
Sep 12 13:28:45.893: INFO: Pod daemon-set-rr5sr is not available
Sep 12 13:28:45.896: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 13:28:46.893: INFO: Pod daemon-set-bfqp2 is not available
Sep 12 13:28:46.896: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1888, will wait for the garbage collector to delete the pods
Sep 12 13:28:46.956: INFO: Deleting DaemonSet.extensions daemon-set took: 4.048788ms
Sep 12 13:28:47.356: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.269105ms
Sep 12 13:28:57.658: INFO: Number of nodes with available pods: 0
Sep 12 13:28:57.658: INFO: Number of running nodes: 0, number of available pods: 0
Sep 12 13:28:57.660: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1888/daemonsets","resourceVersion":"29350"},"items":null}

Sep 12 13:28:57.661: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1888/pods","resourceVersion":"29350"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:28:57.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1888" for this suite.
Sep 12 13:29:05.691: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:29:05.763: INFO: namespace daemonsets-1888 deletion completed in 8.086446802s

â€¢ [SLOW TEST:45.135 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:29:05.764: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-9125
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Sep 12 13:29:09.963: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-268668657 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Sep 12 13:29:15.042: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:29:15.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9125" for this suite.
Sep 12 13:29:21.067: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:29:21.132: INFO: namespace pods-9125 deletion completed in 6.084793288s

â€¢ [SLOW TEST:15.368 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be submitted and removed [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:29:21.134: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5944
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating Redis RC
Sep 12 13:29:21.329: INFO: namespace kubectl-5944
Sep 12 13:29:21.329: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 create -f - --namespace=kubectl-5944'
Sep 12 13:29:21.616: INFO: stderr: ""
Sep 12 13:29:21.616: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Sep 12 13:29:22.619: INFO: Selector matched 1 pods for map[app:redis]
Sep 12 13:29:22.619: INFO: Found 0 / 1
Sep 12 13:29:23.620: INFO: Selector matched 1 pods for map[app:redis]
Sep 12 13:29:23.620: INFO: Found 0 / 1
Sep 12 13:29:24.618: INFO: Selector matched 1 pods for map[app:redis]
Sep 12 13:29:24.618: INFO: Found 0 / 1
Sep 12 13:29:25.618: INFO: Selector matched 1 pods for map[app:redis]
Sep 12 13:29:25.618: INFO: Found 1 / 1
Sep 12 13:29:25.618: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Sep 12 13:29:25.620: INFO: Selector matched 1 pods for map[app:redis]
Sep 12 13:29:25.620: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Sep 12 13:29:25.620: INFO: wait on redis-master startup in kubectl-5944 
Sep 12 13:29:25.620: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 logs redis-master-jzpzw redis-master --namespace=kubectl-5944'
Sep 12 13:29:25.718: INFO: stderr: ""
Sep 12 13:29:25.718: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 12 Sep 13:29:23.830 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 12 Sep 13:29:23.830 # Server started, Redis version 3.2.12\n1:M 12 Sep 13:29:23.830 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 12 Sep 13:29:23.830 * The server is now ready to accept connections on port 6379\n"
STEP: exposing RC
Sep 12 13:29:25.718: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-5944'
Sep 12 13:29:25.823: INFO: stderr: ""
Sep 12 13:29:25.823: INFO: stdout: "service/rm2 exposed\n"
Sep 12 13:29:25.832: INFO: Service rm2 in namespace kubectl-5944 found.
STEP: exposing service
Sep 12 13:29:27.837: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-5944'
Sep 12 13:29:27.966: INFO: stderr: ""
Sep 12 13:29:27.966: INFO: stdout: "service/rm3 exposed\n"
Sep 12 13:29:27.975: INFO: Service rm3 in namespace kubectl-5944 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:29:29.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5944" for this suite.
Sep 12 13:29:51.996: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:29:52.060: INFO: namespace kubectl-5944 deletion completed in 22.079247203s

â€¢ [SLOW TEST:30.926 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl expose
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create services for rc  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:29:52.060: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-8192
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:30:52.222: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8192" for this suite.
Sep 12 13:31:14.241: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:31:14.308: INFO: namespace container-probe-8192 deletion completed in 22.083111779s

â€¢ [SLOW TEST:82.248 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:31:14.310: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-4814
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Sep 12 13:31:14.508: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-4814,SelfLink:/api/v1/namespaces/watch-4814/configmaps/e2e-watch-test-resource-version,UID:d5d64df4-03d4-4d97-a1e7-3b2fdd0c913d,ResourceVersion:29867,Generation:0,CreationTimestamp:2019-09-12 13:31:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep 12 13:31:14.508: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-resource-version,GenerateName:,Namespace:watch-4814,SelfLink:/api/v1/namespaces/watch-4814/configmaps/e2e-watch-test-resource-version,UID:d5d64df4-03d4-4d97-a1e7-3b2fdd0c913d,ResourceVersion:29868,Generation:0,CreationTimestamp:2019-09-12 13:31:14 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: from-resource-version,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:31:14.508: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-4814" for this suite.
Sep 12 13:31:20.530: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:31:20.601: INFO: namespace watch-4814 deletion completed in 6.084905956s

â€¢ [SLOW TEST:6.291 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:31:20.601: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-2308
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod pod-subpath-test-secret-nvb8
STEP: Creating a pod to test atomic-volume-subpath
Sep 12 13:31:20.775: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-nvb8" in namespace "subpath-2308" to be "success or failure"
Sep 12 13:31:20.783: INFO: Pod "pod-subpath-test-secret-nvb8": Phase="Pending", Reason="", readiness=false. Elapsed: 8.01592ms
Sep 12 13:31:22.786: INFO: Pod "pod-subpath-test-secret-nvb8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010941717s
Sep 12 13:31:24.788: INFO: Pod "pod-subpath-test-secret-nvb8": Phase="Running", Reason="", readiness=true. Elapsed: 4.013151144s
Sep 12 13:31:26.791: INFO: Pod "pod-subpath-test-secret-nvb8": Phase="Running", Reason="", readiness=true. Elapsed: 6.015645395s
Sep 12 13:31:28.793: INFO: Pod "pod-subpath-test-secret-nvb8": Phase="Running", Reason="", readiness=true. Elapsed: 8.018331332s
Sep 12 13:31:30.795: INFO: Pod "pod-subpath-test-secret-nvb8": Phase="Running", Reason="", readiness=true. Elapsed: 10.020534738s
Sep 12 13:31:32.798: INFO: Pod "pod-subpath-test-secret-nvb8": Phase="Running", Reason="", readiness=true. Elapsed: 12.023153445s
Sep 12 13:31:34.801: INFO: Pod "pod-subpath-test-secret-nvb8": Phase="Running", Reason="", readiness=true. Elapsed: 14.025839792s
Sep 12 13:31:36.803: INFO: Pod "pod-subpath-test-secret-nvb8": Phase="Running", Reason="", readiness=true. Elapsed: 16.028328912s
Sep 12 13:31:38.806: INFO: Pod "pod-subpath-test-secret-nvb8": Phase="Running", Reason="", readiness=true. Elapsed: 18.030628558s
Sep 12 13:31:40.808: INFO: Pod "pod-subpath-test-secret-nvb8": Phase="Running", Reason="", readiness=true. Elapsed: 20.032886416s
Sep 12 13:31:42.810: INFO: Pod "pod-subpath-test-secret-nvb8": Phase="Running", Reason="", readiness=true. Elapsed: 22.03520099s
Sep 12 13:31:44.813: INFO: Pod "pod-subpath-test-secret-nvb8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.03759759s
STEP: Saw pod success
Sep 12 13:31:44.813: INFO: Pod "pod-subpath-test-secret-nvb8" satisfied condition "success or failure"
Sep 12 13:31:44.814: INFO: Trying to get logs from node caasp-worker-thehejik-0 pod pod-subpath-test-secret-nvb8 container test-container-subpath-secret-nvb8: <nil>
STEP: delete the pod
Sep 12 13:31:44.837: INFO: Waiting for pod pod-subpath-test-secret-nvb8 to disappear
Sep 12 13:31:44.853: INFO: Pod pod-subpath-test-secret-nvb8 no longer exists
STEP: Deleting pod pod-subpath-test-secret-nvb8
Sep 12 13:31:44.853: INFO: Deleting pod "pod-subpath-test-secret-nvb8" in namespace "subpath-2308"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:31:44.855: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2308" for this suite.
Sep 12 13:31:50.871: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:31:50.934: INFO: namespace subpath-2308 deletion completed in 6.076303628s

â€¢ [SLOW TEST:30.333 seconds]
[sig-storage] Subpath
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:22
  Atomic writer volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:31:50.935: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-1513
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Sep 12 13:31:59.134: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep 12 13:31:59.147: INFO: Pod pod-with-poststart-http-hook still exists
Sep 12 13:32:01.147: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep 12 13:32:01.150: INFO: Pod pod-with-poststart-http-hook still exists
Sep 12 13:32:03.147: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Sep 12 13:32:03.149: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:32:03.150: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-1513" for this suite.
Sep 12 13:32:25.198: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:32:25.267: INFO: namespace container-lifecycle-hook-1513 deletion completed in 22.114510037s

â€¢ [SLOW TEST:34.332 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:32:25.267: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-3626
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Sep 12 13:32:25.465: INFO: Got : ADDED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-3626,SelfLink:/api/v1/namespaces/watch-3626/configmaps/e2e-watch-test-watch-closed,UID:1ee142ce-358c-4caf-88ae-ad8cf0acccf3,ResourceVersion:30151,Generation:0,CreationTimestamp:2019-09-12 13:32:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{},BinaryData:map[string][]byte{},}
Sep 12 13:32:25.465: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-3626,SelfLink:/api/v1/namespaces/watch-3626/configmaps/e2e-watch-test-watch-closed,UID:1ee142ce-358c-4caf-88ae-ad8cf0acccf3,ResourceVersion:30152,Generation:0,CreationTimestamp:2019-09-12 13:32:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Sep 12 13:32:25.562: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-3626,SelfLink:/api/v1/namespaces/watch-3626/configmaps/e2e-watch-test-watch-closed,UID:1ee142ce-358c-4caf-88ae-ad8cf0acccf3,ResourceVersion:30153,Generation:0,CreationTimestamp:2019-09-12 13:32:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Sep 12 13:32:25.562: INFO: Got : DELETED &ConfigMap{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:e2e-watch-test-watch-closed,GenerateName:,Namespace:watch-3626,SelfLink:/api/v1/namespaces/watch-3626/configmaps/e2e-watch-test-watch-closed,UID:1ee142ce-358c-4caf-88ae-ad8cf0acccf3,ResourceVersion:30154,Generation:0,CreationTimestamp:2019-09-12 13:32:25 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{watch-this-configmap: watch-closed-and-restarted,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:32:25.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3626" for this suite.
Sep 12 13:32:31.589: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:32:31.654: INFO: namespace watch-3626 deletion completed in 6.082217345s

â€¢ [SLOW TEST:6.386 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:32:31.654: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9060
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1686
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep 12 13:32:31.882: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 run e2e-test-nginx-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --namespace=kubectl-9060'
Sep 12 13:32:31.976: INFO: stderr: ""
Sep 12 13:32:31.976: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod was created
[AfterEach] [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1691
Sep 12 13:32:31.986: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 delete pods e2e-test-nginx-pod --namespace=kubectl-9060'
Sep 12 13:32:54.592: INFO: stderr: ""
Sep 12 13:32:54.592: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:32:54.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9060" for this suite.
Sep 12 13:33:00.614: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:33:00.682: INFO: namespace kubectl-9060 deletion completed in 6.082776428s

â€¢ [SLOW TEST:29.028 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl run pod
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:33:00.682: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8374
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0666 on node default medium
Sep 12 13:33:00.842: INFO: Waiting up to 5m0s for pod "pod-bb1027b9-6ecd-4a21-803d-710c28953065" in namespace "emptydir-8374" to be "success or failure"
Sep 12 13:33:00.850: INFO: Pod "pod-bb1027b9-6ecd-4a21-803d-710c28953065": Phase="Pending", Reason="", readiness=false. Elapsed: 8.502803ms
Sep 12 13:33:02.853: INFO: Pod "pod-bb1027b9-6ecd-4a21-803d-710c28953065": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010965678s
Sep 12 13:33:04.855: INFO: Pod "pod-bb1027b9-6ecd-4a21-803d-710c28953065": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013456555s
Sep 12 13:33:06.857: INFO: Pod "pod-bb1027b9-6ecd-4a21-803d-710c28953065": Phase="Pending", Reason="", readiness=false. Elapsed: 6.015668696s
Sep 12 13:33:08.860: INFO: Pod "pod-bb1027b9-6ecd-4a21-803d-710c28953065": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.017880236s
STEP: Saw pod success
Sep 12 13:33:08.860: INFO: Pod "pod-bb1027b9-6ecd-4a21-803d-710c28953065" satisfied condition "success or failure"
Sep 12 13:33:08.861: INFO: Trying to get logs from node caasp-worker-thehejik-5 pod pod-bb1027b9-6ecd-4a21-803d-710c28953065 container test-container: <nil>
STEP: delete the pod
Sep 12 13:33:08.936: INFO: Waiting for pod pod-bb1027b9-6ecd-4a21-803d-710c28953065 to disappear
Sep 12 13:33:08.945: INFO: Pod pod-bb1027b9-6ecd-4a21-803d-710c28953065 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:33:08.945: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8374" for this suite.
Sep 12 13:33:14.960: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:33:15.033: INFO: namespace emptydir-8374 deletion completed in 6.084715997s

â€¢ [SLOW TEST:14.351 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:33:15.033: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-5312
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 12 13:33:15.197: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:33:19.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5312" for this suite.
Sep 12 13:33:57.289: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:33:57.354: INFO: namespace pods-5312 deletion completed in 38.081947488s

â€¢ [SLOW TEST:42.322 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:33:57.356: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5064
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Sep 12 13:33:57.524: INFO: Waiting up to 5m0s for pod "downward-api-9283c2e1-f4fa-4593-8032-c28ad4cff652" in namespace "downward-api-5064" to be "success or failure"
Sep 12 13:33:57.531: INFO: Pod "downward-api-9283c2e1-f4fa-4593-8032-c28ad4cff652": Phase="Pending", Reason="", readiness=false. Elapsed: 6.788345ms
Sep 12 13:33:59.535: INFO: Pod "downward-api-9283c2e1-f4fa-4593-8032-c28ad4cff652": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010396778s
Sep 12 13:34:01.538: INFO: Pod "downward-api-9283c2e1-f4fa-4593-8032-c28ad4cff652": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013205573s
STEP: Saw pod success
Sep 12 13:34:01.538: INFO: Pod "downward-api-9283c2e1-f4fa-4593-8032-c28ad4cff652" satisfied condition "success or failure"
Sep 12 13:34:01.539: INFO: Trying to get logs from node caasp-worker-thehejik-0 pod downward-api-9283c2e1-f4fa-4593-8032-c28ad4cff652 container dapi-container: <nil>
STEP: delete the pod
Sep 12 13:34:01.561: INFO: Waiting for pod downward-api-9283c2e1-f4fa-4593-8032-c28ad4cff652 to disappear
Sep 12 13:34:01.571: INFO: Pod downward-api-9283c2e1-f4fa-4593-8032-c28ad4cff652 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:34:01.571: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5064" for this suite.
Sep 12 13:34:07.594: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:34:07.660: INFO: namespace downward-api-5064 deletion completed in 6.085547544s

â€¢ [SLOW TEST:10.304 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:34:07.661: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4045
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating the pod
Sep 12 13:34:12.384: INFO: Successfully updated pod "annotationupdate212e698e-0b4a-4a91-9bcb-b4c6993d6108"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:34:16.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4045" for this suite.
Sep 12 13:34:38.429: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:34:38.515: INFO: namespace downward-api-4045 deletion completed in 22.099899807s

â€¢ [SLOW TEST:30.854 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:34:38.515: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3907
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name secret-emptykey-test-bf4ce775-ab02-4849-adf1-b0d19c68de5a
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:34:38.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3907" for this suite.
Sep 12 13:34:44.733: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:34:44.798: INFO: namespace secrets-3907 deletion completed in 6.078031227s

â€¢ [SLOW TEST:6.283 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:31
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:34:44.808: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7177
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on node default medium
Sep 12 13:34:44.964: INFO: Waiting up to 5m0s for pod "pod-bfed07cd-2ad6-4305-add0-a6fcb0898d7f" in namespace "emptydir-7177" to be "success or failure"
Sep 12 13:34:44.974: INFO: Pod "pod-bfed07cd-2ad6-4305-add0-a6fcb0898d7f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.287199ms
Sep 12 13:34:46.976: INFO: Pod "pod-bfed07cd-2ad6-4305-add0-a6fcb0898d7f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012383089s
Sep 12 13:34:48.979: INFO: Pod "pod-bfed07cd-2ad6-4305-add0-a6fcb0898d7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015019483s
STEP: Saw pod success
Sep 12 13:34:48.979: INFO: Pod "pod-bfed07cd-2ad6-4305-add0-a6fcb0898d7f" satisfied condition "success or failure"
Sep 12 13:34:48.980: INFO: Trying to get logs from node caasp-worker-thehejik-4 pod pod-bfed07cd-2ad6-4305-add0-a6fcb0898d7f container test-container: <nil>
STEP: delete the pod
Sep 12 13:34:49.002: INFO: Waiting for pod pod-bfed07cd-2ad6-4305-add0-a6fcb0898d7f to disappear
Sep 12 13:34:49.073: INFO: Pod pod-bfed07cd-2ad6-4305-add0-a6fcb0898d7f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:34:49.073: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7177" for this suite.
Sep 12 13:34:55.090: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:34:55.158: INFO: namespace emptydir-7177 deletion completed in 6.082041706s

â€¢ [SLOW TEST:10.350 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:34:55.158: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-641
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Sep 12 13:34:55.308: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:35:00.114: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-641" for this suite.
Sep 12 13:35:06.146: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:35:06.234: INFO: namespace init-container-641 deletion completed in 6.104403795s

â€¢ [SLOW TEST:11.076 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:35:06.235: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6595
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep 12 13:35:06.545: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bc71de8a-44dc-4fd2-9d15-728bf1361fe1" in namespace "downward-api-6595" to be "success or failure"
Sep 12 13:35:06.554: INFO: Pod "downwardapi-volume-bc71de8a-44dc-4fd2-9d15-728bf1361fe1": Phase="Pending", Reason="", readiness=false. Elapsed: 9.566482ms
Sep 12 13:35:08.557: INFO: Pod "downwardapi-volume-bc71de8a-44dc-4fd2-9d15-728bf1361fe1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012283612s
Sep 12 13:35:10.560: INFO: Pod "downwardapi-volume-bc71de8a-44dc-4fd2-9d15-728bf1361fe1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01461985s
STEP: Saw pod success
Sep 12 13:35:10.560: INFO: Pod "downwardapi-volume-bc71de8a-44dc-4fd2-9d15-728bf1361fe1" satisfied condition "success or failure"
Sep 12 13:35:10.561: INFO: Trying to get logs from node caasp-worker-thehejik-5 pod downwardapi-volume-bc71de8a-44dc-4fd2-9d15-728bf1361fe1 container client-container: <nil>
STEP: delete the pod
Sep 12 13:35:10.581: INFO: Waiting for pod downwardapi-volume-bc71de8a-44dc-4fd2-9d15-728bf1361fe1 to disappear
Sep 12 13:35:10.589: INFO: Pod downwardapi-volume-bc71de8a-44dc-4fd2-9d15-728bf1361fe1 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:35:10.589: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6595" for this suite.
Sep 12 13:35:16.617: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:35:16.683: INFO: namespace downward-api-6595 deletion completed in 6.090282966s

â€¢ [SLOW TEST:10.448 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:35:16.683: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1995
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-3eea0893-6f4e-461d-a08c-5df0f19409e6
STEP: Creating a pod to test consume configMaps
Sep 12 13:35:16.990: INFO: Waiting up to 5m0s for pod "pod-configmaps-635c928e-8ce3-4cb9-9972-17dc31cdb4f8" in namespace "configmap-1995" to be "success or failure"
Sep 12 13:35:17.009: INFO: Pod "pod-configmaps-635c928e-8ce3-4cb9-9972-17dc31cdb4f8": Phase="Pending", Reason="", readiness=false. Elapsed: 19.721285ms
Sep 12 13:35:19.012: INFO: Pod "pod-configmaps-635c928e-8ce3-4cb9-9972-17dc31cdb4f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022100024s
Sep 12 13:35:21.014: INFO: Pod "pod-configmaps-635c928e-8ce3-4cb9-9972-17dc31cdb4f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024395967s
STEP: Saw pod success
Sep 12 13:35:21.014: INFO: Pod "pod-configmaps-635c928e-8ce3-4cb9-9972-17dc31cdb4f8" satisfied condition "success or failure"
Sep 12 13:35:21.016: INFO: Trying to get logs from node caasp-worker-thehejik-3 pod pod-configmaps-635c928e-8ce3-4cb9-9972-17dc31cdb4f8 container configmap-volume-test: <nil>
STEP: delete the pod
Sep 12 13:35:21.102: INFO: Waiting for pod pod-configmaps-635c928e-8ce3-4cb9-9972-17dc31cdb4f8 to disappear
Sep 12 13:35:21.115: INFO: Pod pod-configmaps-635c928e-8ce3-4cb9-9972-17dc31cdb4f8 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:35:21.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1995" for this suite.
Sep 12 13:35:27.132: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:35:27.200: INFO: namespace configmap-1995 deletion completed in 6.082210558s

â€¢ [SLOW TEST:10.517 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:35:27.200: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-1453
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:103
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Sep 12 13:35:27.537: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 13:35:27.547: INFO: Number of nodes with available pods: 0
Sep 12 13:35:27.547: INFO: Node caasp-worker-thehejik-0 is running more than one daemon pod
Sep 12 13:35:28.552: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 13:35:28.554: INFO: Number of nodes with available pods: 0
Sep 12 13:35:28.554: INFO: Node caasp-worker-thehejik-0 is running more than one daemon pod
Sep 12 13:35:29.551: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 13:35:29.553: INFO: Number of nodes with available pods: 0
Sep 12 13:35:29.553: INFO: Node caasp-worker-thehejik-0 is running more than one daemon pod
Sep 12 13:35:30.551: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 13:35:30.553: INFO: Number of nodes with available pods: 2
Sep 12 13:35:30.553: INFO: Node caasp-worker-thehejik-1 is running more than one daemon pod
Sep 12 13:35:31.551: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 13:35:31.553: INFO: Number of nodes with available pods: 6
Sep 12 13:35:31.553: INFO: Number of running nodes: 6, number of available pods: 6
STEP: Stop a daemon pod, check that the daemon pod is revived.
Sep 12 13:35:31.575: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 13:35:31.577: INFO: Number of nodes with available pods: 5
Sep 12 13:35:31.577: INFO: Node caasp-worker-thehejik-3 is running more than one daemon pod
Sep 12 13:35:32.581: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 13:35:32.583: INFO: Number of nodes with available pods: 5
Sep 12 13:35:32.583: INFO: Node caasp-worker-thehejik-3 is running more than one daemon pod
Sep 12 13:35:33.582: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 13:35:33.585: INFO: Number of nodes with available pods: 5
Sep 12 13:35:33.585: INFO: Node caasp-worker-thehejik-3 is running more than one daemon pod
Sep 12 13:35:34.581: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 13:35:34.583: INFO: Number of nodes with available pods: 5
Sep 12 13:35:34.583: INFO: Node caasp-worker-thehejik-3 is running more than one daemon pod
Sep 12 13:35:35.581: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 13:35:35.584: INFO: Number of nodes with available pods: 5
Sep 12 13:35:35.584: INFO: Node caasp-worker-thehejik-3 is running more than one daemon pod
Sep 12 13:35:36.580: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 13:35:36.583: INFO: Number of nodes with available pods: 5
Sep 12 13:35:36.583: INFO: Node caasp-worker-thehejik-3 is running more than one daemon pod
Sep 12 13:35:37.581: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 13:35:37.583: INFO: Number of nodes with available pods: 5
Sep 12 13:35:37.584: INFO: Node caasp-worker-thehejik-3 is running more than one daemon pod
Sep 12 13:35:38.580: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 13:35:38.583: INFO: Number of nodes with available pods: 5
Sep 12 13:35:38.583: INFO: Node caasp-worker-thehejik-3 is running more than one daemon pod
Sep 12 13:35:39.581: INFO: DaemonSet pods can't tolerate node caasp-master-thehejik-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Sep 12 13:35:39.584: INFO: Number of nodes with available pods: 6
Sep 12 13:35:39.584: INFO: Number of running nodes: 6, number of available pods: 6
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:69
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1453, will wait for the garbage collector to delete the pods
Sep 12 13:35:39.641: INFO: Deleting DaemonSet.extensions daemon-set took: 3.448703ms
Sep 12 13:35:40.041: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.242385ms
Sep 12 13:35:46.443: INFO: Number of nodes with available pods: 0
Sep 12 13:35:46.443: INFO: Number of running nodes: 0, number of available pods: 0
Sep 12 13:35:46.445: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1453/daemonsets","resourceVersion":"31171"},"items":null}

Sep 12 13:35:46.447: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1453/pods","resourceVersion":"31171"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:35:46.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1453" for this suite.
Sep 12 13:35:52.479: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:35:52.551: INFO: namespace daemonsets-1453 deletion completed in 6.08672368s

â€¢ [SLOW TEST:25.350 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:35:52.551: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-5744
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 12 13:35:52.728: INFO: Creating ReplicaSet my-hostname-basic-05de5006-71ec-45c7-a02b-ffd1d6e3c0f0
Sep 12 13:35:52.749: INFO: Pod name my-hostname-basic-05de5006-71ec-45c7-a02b-ffd1d6e3c0f0: Found 0 pods out of 1
Sep 12 13:35:57.752: INFO: Pod name my-hostname-basic-05de5006-71ec-45c7-a02b-ffd1d6e3c0f0: Found 1 pods out of 1
Sep 12 13:35:57.752: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-05de5006-71ec-45c7-a02b-ffd1d6e3c0f0" is running
Sep 12 13:36:01.756: INFO: Pod "my-hostname-basic-05de5006-71ec-45c7-a02b-ffd1d6e3c0f0-nkf4z" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-12 13:35:52 +0000 UTC Reason: Message:} {Type:Ready Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-12 13:35:52 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-05de5006-71ec-45c7-a02b-ffd1d6e3c0f0]} {Type:ContainersReady Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-12 13:35:52 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-05de5006-71ec-45c7-a02b-ffd1d6e3c0f0]} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-09-12 13:35:52 +0000 UTC Reason: Message:}])
Sep 12 13:36:01.756: INFO: Trying to dial the pod
Sep 12 13:36:06.762: INFO: Controller my-hostname-basic-05de5006-71ec-45c7-a02b-ffd1d6e3c0f0: Got expected result from replica 1 [my-hostname-basic-05de5006-71ec-45c7-a02b-ffd1d6e3c0f0-nkf4z]: "my-hostname-basic-05de5006-71ec-45c7-a02b-ffd1d6e3c0f0-nkf4z", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:36:06.762: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-5744" for this suite.
Sep 12 13:36:12.781: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:36:12.856: INFO: namespace replicaset-5744 deletion completed in 6.089643912s

â€¢ [SLOW TEST:20.305 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:36:12.856: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5855
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating projection with secret that has name projected-secret-test-map-4cc615c5-4e21-4032-8acf-8ed48c072523
STEP: Creating a pod to test consume secrets
Sep 12 13:36:13.028: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-79ffea5d-7278-4f4d-9b40-52a4af756cd9" in namespace "projected-5855" to be "success or failure"
Sep 12 13:36:13.055: INFO: Pod "pod-projected-secrets-79ffea5d-7278-4f4d-9b40-52a4af756cd9": Phase="Pending", Reason="", readiness=false. Elapsed: 26.919819ms
Sep 12 13:36:15.057: INFO: Pod "pod-projected-secrets-79ffea5d-7278-4f4d-9b40-52a4af756cd9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029023145s
Sep 12 13:36:17.060: INFO: Pod "pod-projected-secrets-79ffea5d-7278-4f4d-9b40-52a4af756cd9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031444309s
STEP: Saw pod success
Sep 12 13:36:17.060: INFO: Pod "pod-projected-secrets-79ffea5d-7278-4f4d-9b40-52a4af756cd9" satisfied condition "success or failure"
Sep 12 13:36:17.062: INFO: Trying to get logs from node caasp-worker-thehejik-2 pod pod-projected-secrets-79ffea5d-7278-4f4d-9b40-52a4af756cd9 container projected-secret-volume-test: <nil>
STEP: delete the pod
Sep 12 13:36:17.082: INFO: Waiting for pod pod-projected-secrets-79ffea5d-7278-4f4d-9b40-52a4af756cd9 to disappear
Sep 12 13:36:17.089: INFO: Pod pod-projected-secrets-79ffea5d-7278-4f4d-9b40-52a4af756cd9 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:36:17.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5855" for this suite.
Sep 12 13:36:23.105: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:36:23.174: INFO: namespace projected-5855 deletion completed in 6.082380423s

â€¢ [SLOW TEST:10.318 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:36:23.174: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6020
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:39
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep 12 13:36:23.339: INFO: Waiting up to 5m0s for pod "downwardapi-volume-98e5b860-7cae-4c33-a5c2-9dc421262a07" in namespace "projected-6020" to be "success or failure"
Sep 12 13:36:23.350: INFO: Pod "downwardapi-volume-98e5b860-7cae-4c33-a5c2-9dc421262a07": Phase="Pending", Reason="", readiness=false. Elapsed: 11.350024ms
Sep 12 13:36:25.354: INFO: Pod "downwardapi-volume-98e5b860-7cae-4c33-a5c2-9dc421262a07": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015217653s
Sep 12 13:36:27.357: INFO: Pod "downwardapi-volume-98e5b860-7cae-4c33-a5c2-9dc421262a07": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017376306s
STEP: Saw pod success
Sep 12 13:36:27.357: INFO: Pod "downwardapi-volume-98e5b860-7cae-4c33-a5c2-9dc421262a07" satisfied condition "success or failure"
Sep 12 13:36:27.358: INFO: Trying to get logs from node caasp-worker-thehejik-4 pod downwardapi-volume-98e5b860-7cae-4c33-a5c2-9dc421262a07 container client-container: <nil>
STEP: delete the pod
Sep 12 13:36:27.378: INFO: Waiting for pod downwardapi-volume-98e5b860-7cae-4c33-a5c2-9dc421262a07 to disappear
Sep 12 13:36:27.387: INFO: Pod downwardapi-volume-98e5b860-7cae-4c33-a5c2-9dc421262a07 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:36:27.387: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6020" for this suite.
Sep 12 13:36:33.405: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:36:33.471: INFO: namespace projected-6020 deletion completed in 6.081013319s

â€¢ [SLOW TEST:10.297 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:33
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:36:33.472: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3460
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1293
STEP: creating an rc
Sep 12 13:36:33.652: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 create -f - --namespace=kubectl-3460'
Sep 12 13:36:34.114: INFO: stderr: ""
Sep 12 13:36:34.114: INFO: stdout: "replicationcontroller/redis-master created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Waiting for Redis master to start.
Sep 12 13:36:35.117: INFO: Selector matched 1 pods for map[app:redis]
Sep 12 13:36:35.117: INFO: Found 0 / 1
Sep 12 13:36:36.117: INFO: Selector matched 1 pods for map[app:redis]
Sep 12 13:36:36.117: INFO: Found 0 / 1
Sep 12 13:36:37.117: INFO: Selector matched 1 pods for map[app:redis]
Sep 12 13:36:37.117: INFO: Found 1 / 1
Sep 12 13:36:37.117: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Sep 12 13:36:37.119: INFO: Selector matched 1 pods for map[app:redis]
Sep 12 13:36:37.119: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
STEP: checking for a matching strings
Sep 12 13:36:37.119: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 logs redis-master-npp8t redis-master --namespace=kubectl-3460'
Sep 12 13:36:37.248: INFO: stderr: ""
Sep 12 13:36:37.248: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 12 Sep 13:36:36.584 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 12 Sep 13:36:36.584 # Server started, Redis version 3.2.12\n1:M 12 Sep 13:36:36.584 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 12 Sep 13:36:36.584 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log lines
Sep 12 13:36:37.248: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 log redis-master-npp8t redis-master --namespace=kubectl-3460 --tail=1'
Sep 12 13:36:37.347: INFO: stderr: ""
Sep 12 13:36:37.347: INFO: stdout: "1:M 12 Sep 13:36:36.584 * The server is now ready to accept connections on port 6379\n"
STEP: limiting log bytes
Sep 12 13:36:37.347: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 log redis-master-npp8t redis-master --namespace=kubectl-3460 --limit-bytes=1'
Sep 12 13:36:37.433: INFO: stderr: ""
Sep 12 13:36:37.433: INFO: stdout: " "
STEP: exposing timestamps
Sep 12 13:36:37.433: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 log redis-master-npp8t redis-master --namespace=kubectl-3460 --tail=1 --timestamps'
Sep 12 13:36:37.523: INFO: stderr: ""
Sep 12 13:36:37.523: INFO: stdout: "2019-09-12T13:36:36.584900876Z 1:M 12 Sep 13:36:36.584 * The server is now ready to accept connections on port 6379\n"
STEP: restricting to a time range
Sep 12 13:36:40.023: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 log redis-master-npp8t redis-master --namespace=kubectl-3460 --since=1s'
Sep 12 13:36:40.108: INFO: stderr: ""
Sep 12 13:36:40.108: INFO: stdout: ""
Sep 12 13:36:40.109: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 log redis-master-npp8t redis-master --namespace=kubectl-3460 --since=24h'
Sep 12 13:36:40.194: INFO: stderr: ""
Sep 12 13:36:40.194: INFO: stdout: "                _._                                                  \n           _.-``__ ''-._                                             \n      _.-``    `.  `_.  ''-._           Redis 3.2.12 (35a5711f/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ ''-._                                   \n (    '      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379\n |    `-._   `._    /     _.-'    |     PID: 1\n  `-._    `-._  `-./  _.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |           http://redis.io        \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n |`-._`-._    `-.__.-'    _.-'_.-'|                                  \n |    `-._`-._        _.-'_.-'    |                                  \n  `-._    `-._`-.__.-'_.-'    _.-'                                   \n      `-._    `-.__.-'    _.-'                                       \n          `-._        _.-'                                           \n              `-.__.-'                                               \n\n1:M 12 Sep 13:36:36.584 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 12 Sep 13:36:36.584 # Server started, Redis version 3.2.12\n1:M 12 Sep 13:36:36.584 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 12 Sep 13:36:36.584 * The server is now ready to accept connections on port 6379\n"
[AfterEach] [k8s.io] Kubectl logs
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1299
STEP: using delete to clean up resources
Sep 12 13:36:40.194: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 delete --grace-period=0 --force -f - --namespace=kubectl-3460'
Sep 12 13:36:40.289: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 12 13:36:40.289: INFO: stdout: "replicationcontroller \"redis-master\" force deleted\n"
Sep 12 13:36:40.289: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get rc,svc -l name=nginx --no-headers --namespace=kubectl-3460'
Sep 12 13:36:40.384: INFO: stderr: "No resources found.\n"
Sep 12 13:36:40.384: INFO: stdout: ""
Sep 12 13:36:40.384: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get pods -l name=nginx --namespace=kubectl-3460 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep 12 13:36:40.466: INFO: stderr: ""
Sep 12 13:36:40.466: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:36:40.466: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3460" for this suite.
Sep 12 13:37:02.485: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:37:02.554: INFO: namespace kubectl-3460 deletion completed in 22.084372323s

â€¢ [SLOW TEST:29.082 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl logs
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:37:02.554: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3751
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-map-78e7cb07-7b33-4a4e-b5dd-a133b37b97b4
STEP: Creating a pod to test consume secrets
Sep 12 13:37:02.722: INFO: Waiting up to 5m0s for pod "pod-secrets-27b7a60f-fd88-47df-8f22-50b5a3448b73" in namespace "secrets-3751" to be "success or failure"
Sep 12 13:37:02.736: INFO: Pod "pod-secrets-27b7a60f-fd88-47df-8f22-50b5a3448b73": Phase="Pending", Reason="", readiness=false. Elapsed: 13.996149ms
Sep 12 13:37:04.794: INFO: Pod "pod-secrets-27b7a60f-fd88-47df-8f22-50b5a3448b73": Phase="Pending", Reason="", readiness=false. Elapsed: 2.072168187s
Sep 12 13:37:06.796: INFO: Pod "pod-secrets-27b7a60f-fd88-47df-8f22-50b5a3448b73": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.074440398s
STEP: Saw pod success
Sep 12 13:37:06.796: INFO: Pod "pod-secrets-27b7a60f-fd88-47df-8f22-50b5a3448b73" satisfied condition "success or failure"
Sep 12 13:37:06.798: INFO: Trying to get logs from node caasp-worker-thehejik-3 pod pod-secrets-27b7a60f-fd88-47df-8f22-50b5a3448b73 container secret-volume-test: <nil>
STEP: delete the pod
Sep 12 13:37:06.825: INFO: Waiting for pod pod-secrets-27b7a60f-fd88-47df-8f22-50b5a3448b73 to disappear
Sep 12 13:37:06.833: INFO: Pod pod-secrets-27b7a60f-fd88-47df-8f22-50b5a3448b73 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:37:06.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3751" for this suite.
Sep 12 13:37:12.860: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:37:12.926: INFO: namespace secrets-3751 deletion completed in 6.089026334s

â€¢ [SLOW TEST:10.371 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:37:12.926: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-9877
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-2e080b8f-7f25-4659-93dc-b2b89e471382
STEP: Creating a pod to test consume secrets
Sep 12 13:37:13.104: INFO: Waiting up to 5m0s for pod "pod-secrets-6fa615aa-7b28-4b37-8fa2-1bbc78fc0ef8" in namespace "secrets-9877" to be "success or failure"
Sep 12 13:37:13.116: INFO: Pod "pod-secrets-6fa615aa-7b28-4b37-8fa2-1bbc78fc0ef8": Phase="Pending", Reason="", readiness=false. Elapsed: 11.981007ms
Sep 12 13:37:15.138: INFO: Pod "pod-secrets-6fa615aa-7b28-4b37-8fa2-1bbc78fc0ef8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033998521s
Sep 12 13:37:17.140: INFO: Pod "pod-secrets-6fa615aa-7b28-4b37-8fa2-1bbc78fc0ef8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036604778s
STEP: Saw pod success
Sep 12 13:37:17.140: INFO: Pod "pod-secrets-6fa615aa-7b28-4b37-8fa2-1bbc78fc0ef8" satisfied condition "success or failure"
Sep 12 13:37:17.142: INFO: Trying to get logs from node caasp-worker-thehejik-3 pod pod-secrets-6fa615aa-7b28-4b37-8fa2-1bbc78fc0ef8 container secret-volume-test: <nil>
STEP: delete the pod
Sep 12 13:37:17.162: INFO: Waiting for pod pod-secrets-6fa615aa-7b28-4b37-8fa2-1bbc78fc0ef8 to disappear
Sep 12 13:37:17.180: INFO: Pod pod-secrets-6fa615aa-7b28-4b37-8fa2-1bbc78fc0ef8 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:37:17.180: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9877" for this suite.
Sep 12 13:37:23.198: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:37:23.262: INFO: namespace secrets-9877 deletion completed in 6.078374102s

â€¢ [SLOW TEST:10.337 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:37:23.264: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5153
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep 12 13:37:23.422: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9f63c0fb-0e03-4267-87e4-35b3034dcc29" in namespace "downward-api-5153" to be "success or failure"
Sep 12 13:37:23.431: INFO: Pod "downwardapi-volume-9f63c0fb-0e03-4267-87e4-35b3034dcc29": Phase="Pending", Reason="", readiness=false. Elapsed: 9.576956ms
Sep 12 13:37:25.438: INFO: Pod "downwardapi-volume-9f63c0fb-0e03-4267-87e4-35b3034dcc29": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015846134s
Sep 12 13:37:27.440: INFO: Pod "downwardapi-volume-9f63c0fb-0e03-4267-87e4-35b3034dcc29": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018196551s
STEP: Saw pod success
Sep 12 13:37:27.440: INFO: Pod "downwardapi-volume-9f63c0fb-0e03-4267-87e4-35b3034dcc29" satisfied condition "success or failure"
Sep 12 13:37:27.441: INFO: Trying to get logs from node caasp-worker-thehejik-4 pod downwardapi-volume-9f63c0fb-0e03-4267-87e4-35b3034dcc29 container client-container: <nil>
STEP: delete the pod
Sep 12 13:37:27.460: INFO: Waiting for pod downwardapi-volume-9f63c0fb-0e03-4267-87e4-35b3034dcc29 to disappear
Sep 12 13:37:27.472: INFO: Pod downwardapi-volume-9f63c0fb-0e03-4267-87e4-35b3034dcc29 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:37:27.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5153" for this suite.
Sep 12 13:37:33.654: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:37:33.717: INFO: namespace downward-api-5153 deletion completed in 6.242286695s

â€¢ [SLOW TEST:10.454 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:37:33.718: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-7279
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Performing setup for networking test in namespace pod-network-test-7279
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Sep 12 13:37:33.878: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Sep 12 13:38:04.072: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.3.45:8080/dial?request=hostName&protocol=udp&host=10.244.5.239&port=8081&tries=1'] Namespace:pod-network-test-7279 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 12 13:38:04.072: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
Sep 12 13:38:04.197: INFO: Waiting for endpoints: map[]
Sep 12 13:38:04.199: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.3.45:8080/dial?request=hostName&protocol=udp&host=10.244.1.69&port=8081&tries=1'] Namespace:pod-network-test-7279 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 12 13:38:04.199: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
Sep 12 13:38:04.261: INFO: Waiting for endpoints: map[]
Sep 12 13:38:04.263: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.3.45:8080/dial?request=hostName&protocol=udp&host=10.244.6.109&port=8081&tries=1'] Namespace:pod-network-test-7279 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 12 13:38:04.263: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
Sep 12 13:38:04.329: INFO: Waiting for endpoints: map[]
Sep 12 13:38:04.338: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.3.45:8080/dial?request=hostName&protocol=udp&host=10.244.3.197&port=8081&tries=1'] Namespace:pod-network-test-7279 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 12 13:38:04.338: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
Sep 12 13:38:04.398: INFO: Waiting for endpoints: map[]
Sep 12 13:38:04.401: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.3.45:8080/dial?request=hostName&protocol=udp&host=10.244.2.25&port=8081&tries=1'] Namespace:pod-network-test-7279 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 12 13:38:04.401: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
Sep 12 13:38:04.462: INFO: Waiting for endpoints: map[]
Sep 12 13:38:04.464: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.3.45:8080/dial?request=hostName&protocol=udp&host=10.244.4.44&port=8081&tries=1'] Namespace:pod-network-test-7279 PodName:host-test-container-pod ContainerName:hostexec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Sep 12 13:38:04.464: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
Sep 12 13:38:04.528: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:38:04.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7279" for this suite.
Sep 12 13:38:26.548: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:38:26.635: INFO: namespace pod-network-test-7279 deletion completed in 22.104148255s

â€¢ [SLOW TEST:52.918 seconds]
[sig-network] Networking
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:38:26.639: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name s-test-opt-del-feb1ce09-e9c7-4964-b336-74b914502ed4
STEP: Creating secret with name s-test-opt-upd-6f03f5f9-4abb-49a6-805f-ebc365886571
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-feb1ce09-e9c7-4964-b336-74b914502ed4
STEP: Updating secret s-test-opt-upd-6f03f5f9-4abb-49a6-805f-ebc365886571
STEP: Creating secret with name s-test-opt-create-80305c7b-91d9-4991-a370-9620695f221e
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:38:35.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3" for this suite.
Sep 12 13:38:57.185: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:38:57.273: INFO: namespace secrets-3 deletion completed in 22.103489344s

â€¢ [SLOW TEST:30.635 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-cli] Kubectl client [k8s.io] Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:38:57.273: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3000
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Starting the proxy
Sep 12 13:38:57.432: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-268668657 proxy --unix-socket=/tmp/kubectl-proxy-unix038970268/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:38:57.497: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3000" for this suite.
Sep 12 13:39:03.553: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:39:03.719: INFO: namespace kubectl-3000 deletion completed in 6.217871758s

â€¢ [SLOW TEST:6.445 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Proxy server
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:39:03.719: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6449
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name s-test-opt-del-62fdd5f3-ed28-4a75-8f65-c740b30e3d9a
STEP: Creating secret with name s-test-opt-upd-605c2b8e-f51a-4bee-9b48-85f61a1e5b24
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-62fdd5f3-ed28-4a75-8f65-c740b30e3d9a
STEP: Updating secret s-test-opt-upd-605c2b8e-f51a-4bee-9b48-85f61a1e5b24
STEP: Creating secret with name s-test-opt-create-ec6b872e-9233-4699-bce7-639a5bace124
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:39:09.999: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6449" for this suite.
Sep 12 13:39:32.018: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:39:32.087: INFO: namespace projected-6449 deletion completed in 22.085706055s

â€¢ [SLOW TEST:28.368 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:33
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:39:32.089: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in prestop-3412
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:167
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating server pod server in namespace prestop-3412
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-3412
STEP: Deleting pre-stop pod
Sep 12 13:39:49.398: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:39:49.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-3412" for this suite.
Sep 12 13:40:27.534: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:40:27.605: INFO: namespace prestop-3412 deletion completed in 38.178013787s

â€¢ [SLOW TEST:55.516 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:40:27.605: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3180
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep 12 13:40:27.846: INFO: Waiting up to 5m0s for pod "downwardapi-volume-52825b2e-bac0-4612-85c8-faa702e65013" in namespace "downward-api-3180" to be "success or failure"
Sep 12 13:40:27.855: INFO: Pod "downwardapi-volume-52825b2e-bac0-4612-85c8-faa702e65013": Phase="Pending", Reason="", readiness=false. Elapsed: 9.047043ms
Sep 12 13:40:29.867: INFO: Pod "downwardapi-volume-52825b2e-bac0-4612-85c8-faa702e65013": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02134209s
Sep 12 13:40:31.869: INFO: Pod "downwardapi-volume-52825b2e-bac0-4612-85c8-faa702e65013": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023478642s
STEP: Saw pod success
Sep 12 13:40:31.870: INFO: Pod "downwardapi-volume-52825b2e-bac0-4612-85c8-faa702e65013" satisfied condition "success or failure"
Sep 12 13:40:31.871: INFO: Trying to get logs from node caasp-worker-thehejik-3 pod downwardapi-volume-52825b2e-bac0-4612-85c8-faa702e65013 container client-container: <nil>
STEP: delete the pod
Sep 12 13:40:31.896: INFO: Waiting for pod downwardapi-volume-52825b2e-bac0-4612-85c8-faa702e65013 to disappear
Sep 12 13:40:31.905: INFO: Pod downwardapi-volume-52825b2e-bac0-4612-85c8-faa702e65013 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:40:31.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3180" for this suite.
Sep 12 13:40:37.922: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:40:37.987: INFO: namespace downward-api-3180 deletion completed in 6.078245902s

â€¢ [SLOW TEST:10.382 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:40:37.987: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6110
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir 0777 on node default medium
Sep 12 13:40:38.147: INFO: Waiting up to 5m0s for pod "pod-c75ddbb5-fff4-4470-9f0a-83db6f7a2371" in namespace "emptydir-6110" to be "success or failure"
Sep 12 13:40:38.156: INFO: Pod "pod-c75ddbb5-fff4-4470-9f0a-83db6f7a2371": Phase="Pending", Reason="", readiness=false. Elapsed: 8.947308ms
Sep 12 13:40:40.158: INFO: Pod "pod-c75ddbb5-fff4-4470-9f0a-83db6f7a2371": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010958732s
Sep 12 13:40:42.160: INFO: Pod "pod-c75ddbb5-fff4-4470-9f0a-83db6f7a2371": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013115556s
STEP: Saw pod success
Sep 12 13:40:42.160: INFO: Pod "pod-c75ddbb5-fff4-4470-9f0a-83db6f7a2371" satisfied condition "success or failure"
Sep 12 13:40:42.161: INFO: Trying to get logs from node caasp-worker-thehejik-4 pod pod-c75ddbb5-fff4-4470-9f0a-83db6f7a2371 container test-container: <nil>
STEP: delete the pod
Sep 12 13:40:42.182: INFO: Waiting for pod pod-c75ddbb5-fff4-4470-9f0a-83db6f7a2371 to disappear
Sep 12 13:40:42.191: INFO: Pod pod-c75ddbb5-fff4-4470-9f0a-83db6f7a2371 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:40:42.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6110" for this suite.
Sep 12 13:40:48.209: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:40:48.273: INFO: namespace emptydir-6110 deletion completed in 6.078938813s

â€¢ [SLOW TEST:10.286 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:40:48.274: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1978
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap configmap-1978/configmap-test-ed832d80-110c-4854-a52c-d33d7d9df884
STEP: Creating a pod to test consume configMaps
Sep 12 13:40:48.450: INFO: Waiting up to 5m0s for pod "pod-configmaps-37a8b44d-95e7-429f-a32a-c0739326a5dd" in namespace "configmap-1978" to be "success or failure"
Sep 12 13:40:48.459: INFO: Pod "pod-configmaps-37a8b44d-95e7-429f-a32a-c0739326a5dd": Phase="Pending", Reason="", readiness=false. Elapsed: 8.442979ms
Sep 12 13:40:50.461: INFO: Pod "pod-configmaps-37a8b44d-95e7-429f-a32a-c0739326a5dd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010522019s
Sep 12 13:40:52.463: INFO: Pod "pod-configmaps-37a8b44d-95e7-429f-a32a-c0739326a5dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012886295s
STEP: Saw pod success
Sep 12 13:40:52.463: INFO: Pod "pod-configmaps-37a8b44d-95e7-429f-a32a-c0739326a5dd" satisfied condition "success or failure"
Sep 12 13:40:52.465: INFO: Trying to get logs from node caasp-worker-thehejik-1 pod pod-configmaps-37a8b44d-95e7-429f-a32a-c0739326a5dd container env-test: <nil>
STEP: delete the pod
Sep 12 13:40:52.486: INFO: Waiting for pod pod-configmaps-37a8b44d-95e7-429f-a32a-c0739326a5dd to disappear
Sep 12 13:40:52.493: INFO: Pod pod-configmaps-37a8b44d-95e7-429f-a32a-c0739326a5dd no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:40:52.493: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1978" for this suite.
Sep 12 13:40:58.511: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:40:58.589: INFO: namespace configmap-1978 deletion completed in 6.093222269s

â€¢ [SLOW TEST:10.315 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:31
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:40:58.589: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename aggregator
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in aggregator-5314
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:76
Sep 12 13:40:58.754: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Registering the sample API server.
Sep 12 13:40:59.364: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Sep 12 13:41:01.433: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892459, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892459, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892459, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892459, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 12 13:41:03.435: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892459, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892459, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892459, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892459, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 12 13:41:05.436: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892459, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892459, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892459, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892459, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 12 13:41:07.436: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892459, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892459, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892459, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892459, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 12 13:41:09.435: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892459, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892459, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892459, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892459, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 12 13:41:11.435: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892459, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892459, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892459, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892459, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 12 13:41:13.441: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892459, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892459, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892459, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892459, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 12 13:41:15.435: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892459, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892459, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892459, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892459, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 12 13:41:17.436: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892459, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892459, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892459, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892459, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 12 13:41:19.436: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892459, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892459, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892459, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892459, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 12 13:41:21.435: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892459, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892459, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892459, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892459, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 12 13:41:23.444: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892459, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892459, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892459, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892459, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-7c4bdb86cc\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 12 13:41:26.376: INFO: Waited 920.155823ms for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:67
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:41:26.864: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-5314" for this suite.
Sep 12 13:41:33.020: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:41:33.088: INFO: namespace aggregator-5314 deletion completed in 6.173782236s

â€¢ [SLOW TEST:34.498 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:41:33.088: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-8306
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Sep 12 13:42:13.263: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:42:13.263: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W0912 13:42:13.263329      18 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-8306" for this suite.
Sep 12 13:42:21.290: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:42:21.360: INFO: namespace gc-8306 deletion completed in 8.091222132s

â€¢ [SLOW TEST:48.272 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:42:21.360: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4021
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating secret with name secret-test-b34be42a-7474-4955-921e-3921ecff8e32
STEP: Creating a pod to test consume secrets
Sep 12 13:42:21.533: INFO: Waiting up to 5m0s for pod "pod-secrets-f45d376c-89f9-4cb4-884d-d710a2f35854" in namespace "secrets-4021" to be "success or failure"
Sep 12 13:42:21.542: INFO: Pod "pod-secrets-f45d376c-89f9-4cb4-884d-d710a2f35854": Phase="Pending", Reason="", readiness=false. Elapsed: 8.577626ms
Sep 12 13:42:23.545: INFO: Pod "pod-secrets-f45d376c-89f9-4cb4-884d-d710a2f35854": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011346886s
Sep 12 13:42:25.548: INFO: Pod "pod-secrets-f45d376c-89f9-4cb4-884d-d710a2f35854": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014022925s
STEP: Saw pod success
Sep 12 13:42:25.548: INFO: Pod "pod-secrets-f45d376c-89f9-4cb4-884d-d710a2f35854" satisfied condition "success or failure"
Sep 12 13:42:25.549: INFO: Trying to get logs from node caasp-worker-thehejik-1 pod pod-secrets-f45d376c-89f9-4cb4-884d-d710a2f35854 container secret-volume-test: <nil>
STEP: delete the pod
Sep 12 13:42:25.570: INFO: Waiting for pod pod-secrets-f45d376c-89f9-4cb4-884d-d710a2f35854 to disappear
Sep 12 13:42:25.580: INFO: Pod pod-secrets-f45d376c-89f9-4cb4-884d-d710a2f35854 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:42:25.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4021" for this suite.
Sep 12 13:42:31.605: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:42:31.666: INFO: namespace secrets-4021 deletion completed in 6.076088653s

â€¢ [SLOW TEST:10.307 seconds]
[sig-storage] Secrets
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:33
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] version v1
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:42:31.667: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-3390
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 12 13:42:31.838: INFO: (0) /api/v1/nodes/caasp-worker-thehejik-0:10250/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="btmp">... (200; 3.91464ms)
Sep 12 13:42:31.841: INFO: (1) /api/v1/nodes/caasp-worker-thehejik-0:10250/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="btmp">... (200; 2.575336ms)
Sep 12 13:42:31.843: INFO: (2) /api/v1/nodes/caasp-worker-thehejik-0:10250/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="btmp">... (200; 2.171493ms)
Sep 12 13:42:31.845: INFO: (3) /api/v1/nodes/caasp-worker-thehejik-0:10250/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="btmp">... (200; 2.135261ms)
Sep 12 13:42:31.848: INFO: (4) /api/v1/nodes/caasp-worker-thehejik-0:10250/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="btmp">... (200; 2.207385ms)
Sep 12 13:42:31.850: INFO: (5) /api/v1/nodes/caasp-worker-thehejik-0:10250/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="btmp">... (200; 2.157217ms)
Sep 12 13:42:31.852: INFO: (6) /api/v1/nodes/caasp-worker-thehejik-0:10250/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="btmp">... (200; 2.283111ms)
Sep 12 13:42:31.854: INFO: (7) /api/v1/nodes/caasp-worker-thehejik-0:10250/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="btmp">... (200; 1.962526ms)
Sep 12 13:42:31.857: INFO: (8) /api/v1/nodes/caasp-worker-thehejik-0:10250/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="btmp">... (200; 2.104402ms)
Sep 12 13:42:31.859: INFO: (9) /api/v1/nodes/caasp-worker-thehejik-0:10250/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="btmp">... (200; 2.218084ms)
Sep 12 13:42:31.871: INFO: (10) /api/v1/nodes/caasp-worker-thehejik-0:10250/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="btmp">... (200; 12.622128ms)
Sep 12 13:42:31.874: INFO: (11) /api/v1/nodes/caasp-worker-thehejik-0:10250/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="btmp">... (200; 2.753467ms)
Sep 12 13:42:31.877: INFO: (12) /api/v1/nodes/caasp-worker-thehejik-0:10250/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="btmp">... (200; 2.693901ms)
Sep 12 13:42:31.879: INFO: (13) /api/v1/nodes/caasp-worker-thehejik-0:10250/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="btmp">... (200; 2.058283ms)
Sep 12 13:42:31.881: INFO: (14) /api/v1/nodes/caasp-worker-thehejik-0:10250/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="btmp">... (200; 2.291717ms)
Sep 12 13:42:31.883: INFO: (15) /api/v1/nodes/caasp-worker-thehejik-0:10250/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="btmp">... (200; 2.151477ms)
Sep 12 13:42:31.886: INFO: (16) /api/v1/nodes/caasp-worker-thehejik-0:10250/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="btmp">... (200; 2.095236ms)
Sep 12 13:42:31.888: INFO: (17) /api/v1/nodes/caasp-worker-thehejik-0:10250/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="btmp">... (200; 2.120147ms)
Sep 12 13:42:31.890: INFO: (18) /api/v1/nodes/caasp-worker-thehejik-0:10250/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="btmp">... (200; 2.237081ms)
Sep 12 13:42:31.892: INFO: (19) /api/v1/nodes/caasp-worker-thehejik-0:10250/proxy/logs/: <pre>
<a href="YaST2/">YaST2/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="btmp">... (200; 2.141852ms)
[AfterEach] version v1
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:42:31.892: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-3390" for this suite.
Sep 12 13:42:37.909: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:42:37.988: INFO: namespace proxy-3390 deletion completed in 6.093467343s

â€¢ [SLOW TEST:6.322 seconds]
[sig-network] Proxy
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:58
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:42:37.988: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-4501
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0912 13:42:48.246073      18 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Sep 12 13:42:48.246: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:42:48.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4501" for this suite.
Sep 12 13:42:54.263: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:42:54.325: INFO: namespace gc-4501 deletion completed in 6.075696526s

â€¢ [SLOW TEST:16.336 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:42:54.325: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-9303
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-9303
[It] Burst scaling should run to completion even with unhealthy pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating stateful set ss in namespace statefulset-9303
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-9303
Sep 12 13:42:54.612: INFO: Found 0 stateful pods, waiting for 1
Sep 12 13:43:04.615: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Sep 12 13:43:04.617: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 exec --namespace=statefulset-9303 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep 12 13:43:04.782: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep 12 13:43:04.782: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep 12 13:43:04.782: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep 12 13:43:04.784: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Sep 12 13:43:14.787: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep 12 13:43:14.787: INFO: Waiting for statefulset status.replicas updated to 0
Sep 12 13:43:14.804: INFO: POD   NODE                     PHASE    GRACE  CONDITIONS
Sep 12 13:43:14.804: INFO: ss-0  caasp-worker-thehejik-0  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:42:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:43:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:43:05 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:42:54 +0000 UTC  }]
Sep 12 13:43:14.804: INFO: 
Sep 12 13:43:14.804: INFO: StatefulSet ss has not reached scale 3, at 1
Sep 12 13:43:15.808: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.988417267s
Sep 12 13:43:16.811: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.98530254s
Sep 12 13:43:17.814: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.982000126s
Sep 12 13:43:18.817: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.978810629s
Sep 12 13:43:19.819: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.976252982s
Sep 12 13:43:20.822: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.973643584s
Sep 12 13:43:21.825: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.970821934s
Sep 12 13:43:22.828: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.968053305s
Sep 12 13:43:23.832: INFO: Verifying statefulset ss doesn't scale past 3 for another 965.258009ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-9303
Sep 12 13:43:24.834: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 exec --namespace=statefulset-9303 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 12 13:43:24.987: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep 12 13:43:24.987: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep 12 13:43:24.987: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-0: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep 12 13:43:24.987: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 exec --namespace=statefulset-9303 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 12 13:43:25.156: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Sep 12 13:43:25.156: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep 12 13:43:25.156: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep 12 13:43:25.156: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 exec --namespace=statefulset-9303 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 12 13:43:25.319: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Sep 12 13:43:25.319: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep 12 13:43:25.319: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss-2: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep 12 13:43:25.322: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Sep 12 13:43:35.324: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Sep 12 13:43:35.324: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Sep 12 13:43:35.324: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Sep 12 13:43:35.326: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 exec --namespace=statefulset-9303 ss-0 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep 12 13:43:35.493: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep 12 13:43:35.493: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep 12 13:43:35.493: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-0: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep 12 13:43:35.493: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 exec --namespace=statefulset-9303 ss-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep 12 13:43:35.640: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep 12 13:43:35.640: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep 12 13:43:35.640: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep 12 13:43:35.640: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 exec --namespace=statefulset-9303 ss-2 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep 12 13:43:35.793: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep 12 13:43:35.793: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep 12 13:43:35.793: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss-2: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep 12 13:43:35.793: INFO: Waiting for statefulset status.replicas updated to 0
Sep 12 13:43:35.805: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Sep 12 13:43:45.810: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Sep 12 13:43:45.810: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Sep 12 13:43:45.810: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Sep 12 13:43:45.826: INFO: POD   NODE                     PHASE    GRACE  CONDITIONS
Sep 12 13:43:45.826: INFO: ss-0  caasp-worker-thehejik-0  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:42:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:43:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:43:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:42:54 +0000 UTC  }]
Sep 12 13:43:45.826: INFO: ss-1  caasp-worker-thehejik-4  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:43:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:43:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:43:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:43:14 +0000 UTC  }]
Sep 12 13:43:45.826: INFO: ss-2  caasp-worker-thehejik-3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:43:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:43:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:43:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:43:14 +0000 UTC  }]
Sep 12 13:43:45.826: INFO: 
Sep 12 13:43:45.826: INFO: StatefulSet ss has not reached scale 0, at 3
Sep 12 13:43:46.837: INFO: POD   NODE                     PHASE    GRACE  CONDITIONS
Sep 12 13:43:46.837: INFO: ss-0  caasp-worker-thehejik-0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:42:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:43:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:43:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:42:54 +0000 UTC  }]
Sep 12 13:43:46.837: INFO: ss-1  caasp-worker-thehejik-4  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:43:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:43:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:43:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:43:14 +0000 UTC  }]
Sep 12 13:43:46.837: INFO: ss-2  caasp-worker-thehejik-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:43:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:43:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:43:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:43:14 +0000 UTC  }]
Sep 12 13:43:46.837: INFO: 
Sep 12 13:43:46.837: INFO: StatefulSet ss has not reached scale 0, at 3
Sep 12 13:43:47.843: INFO: POD   NODE                     PHASE    GRACE  CONDITIONS
Sep 12 13:43:47.843: INFO: ss-0  caasp-worker-thehejik-0  Running  0s     [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:42:54 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:43:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:43:35 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:42:54 +0000 UTC  }]
Sep 12 13:43:47.843: INFO: ss-1  caasp-worker-thehejik-4  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:43:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:43:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:43:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:43:14 +0000 UTC  }]
Sep 12 13:43:47.843: INFO: 
Sep 12 13:43:47.843: INFO: StatefulSet ss has not reached scale 0, at 2
Sep 12 13:43:48.846: INFO: POD   NODE                     PHASE    GRACE  CONDITIONS
Sep 12 13:43:48.846: INFO: ss-1  caasp-worker-thehejik-4  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:43:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:43:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:43:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:43:14 +0000 UTC  }]
Sep 12 13:43:48.846: INFO: 
Sep 12 13:43:48.846: INFO: StatefulSet ss has not reached scale 0, at 1
Sep 12 13:43:49.848: INFO: POD   NODE                     PHASE    GRACE  CONDITIONS
Sep 12 13:43:49.848: INFO: ss-1  caasp-worker-thehejik-4  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:43:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:43:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:43:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:43:14 +0000 UTC  }]
Sep 12 13:43:49.848: INFO: 
Sep 12 13:43:49.848: INFO: StatefulSet ss has not reached scale 0, at 1
Sep 12 13:43:50.851: INFO: POD   NODE                     PHASE    GRACE  CONDITIONS
Sep 12 13:43:50.851: INFO: ss-1  caasp-worker-thehejik-4  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:43:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:43:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:43:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:43:14 +0000 UTC  }]
Sep 12 13:43:50.851: INFO: 
Sep 12 13:43:50.851: INFO: StatefulSet ss has not reached scale 0, at 1
Sep 12 13:43:51.854: INFO: POD   NODE                     PHASE    GRACE  CONDITIONS
Sep 12 13:43:51.854: INFO: ss-1  caasp-worker-thehejik-4  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:43:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:43:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:43:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:43:14 +0000 UTC  }]
Sep 12 13:43:51.854: INFO: 
Sep 12 13:43:51.854: INFO: StatefulSet ss has not reached scale 0, at 1
Sep 12 13:43:52.856: INFO: POD   NODE                     PHASE    GRACE  CONDITIONS
Sep 12 13:43:52.856: INFO: ss-1  caasp-worker-thehejik-4  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:43:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:43:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:43:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:43:14 +0000 UTC  }]
Sep 12 13:43:52.856: INFO: 
Sep 12 13:43:52.856: INFO: StatefulSet ss has not reached scale 0, at 1
Sep 12 13:43:53.859: INFO: POD   NODE                     PHASE    GRACE  CONDITIONS
Sep 12 13:43:53.859: INFO: ss-1  caasp-worker-thehejik-4  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:43:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:43:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:43:36 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:43:14 +0000 UTC  }]
Sep 12 13:43:53.859: INFO: 
Sep 12 13:43:53.859: INFO: StatefulSet ss has not reached scale 0, at 1
Sep 12 13:43:54.869: INFO: Verifying statefulset ss doesn't scale past 0 for another 955.722012ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-9303
Sep 12 13:43:55.871: INFO: Scaling statefulset ss to 0
Sep 12 13:43:55.877: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Sep 12 13:43:55.878: INFO: Deleting all statefulset in ns statefulset-9303
Sep 12 13:43:55.880: INFO: Scaling statefulset ss to 0
Sep 12 13:43:55.885: INFO: Waiting for statefulset status.replicas updated to 0
Sep 12 13:43:55.887: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:43:55.904: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9303" for this suite.
Sep 12 13:44:01.924: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:44:01.991: INFO: namespace statefulset-9303 deletion completed in 6.08384107s

â€¢ [SLOW TEST:67.666 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    Burst scaling should run to completion even with unhealthy pods [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:44:01.991: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6270
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1722
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: running the image docker.io/library/nginx:1.14-alpine
Sep 12 13:44:02.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 run e2e-test-nginx-pod --generator=run-pod/v1 --image=docker.io/library/nginx:1.14-alpine --labels=run=e2e-test-nginx-pod --namespace=kubectl-6270'
Sep 12 13:44:02.246: INFO: stderr: ""
Sep 12 13:44:02.246: INFO: stdout: "pod/e2e-test-nginx-pod created\n"
STEP: verifying the pod e2e-test-nginx-pod is running
STEP: verifying the pod e2e-test-nginx-pod was created
Sep 12 13:44:07.296: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get pod e2e-test-nginx-pod --namespace=kubectl-6270 -o json'
Sep 12 13:44:07.378: INFO: stderr: ""
Sep 12 13:44:07.378: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"kubernetes.io/psp\": \"e2e-test-privileged-psp\"\n        },\n        \"creationTimestamp\": \"2019-09-12T13:44:02Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-nginx-pod\"\n        },\n        \"name\": \"e2e-test-nginx-pod\",\n        \"namespace\": \"kubectl-6270\",\n        \"resourceVersion\": \"34070\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-6270/pods/e2e-test-nginx-pod\",\n        \"uid\": \"4d8e7471-e9b2-4d4c-967f-b097f36ed997\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-nginx-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-bp6tl\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"caasp-worker-thehejik-1\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-bp6tl\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-bp6tl\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-09-12T13:44:02Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-09-12T13:44:05Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-09-12T13:44:05Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-09-12T13:44:02Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"cri-o://5cca1366c2de65c1271e123fa0fa1769912143672ca40ba3e5956cd70aaa76b1\",\n                \"image\": \"docker.io/library/nginx:1.14-alpine\",\n                \"imageID\": \"docker.io/library/nginx@sha256:a3a0c4126587884f8d3090efca87f5af075d7e7ac8308cffc09a5a082d5f4760\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-nginx-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-09-12T13:44:04Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.84.73.97\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.244.3.155\",\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-09-12T13:44:02Z\"\n    }\n}\n"
STEP: replace the image in the pod
Sep 12 13:44:07.378: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 replace -f - --namespace=kubectl-6270'
Sep 12 13:44:07.735: INFO: stderr: ""
Sep 12 13:44:07.736: INFO: stdout: "pod/e2e-test-nginx-pod replaced\n"
STEP: verifying the pod e2e-test-nginx-pod has the right image docker.io/library/busybox:1.29
[AfterEach] [k8s.io] Kubectl replace
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1727
Sep 12 13:44:07.744: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 delete pods e2e-test-nginx-pod --namespace=kubectl-6270'
Sep 12 13:44:15.807: INFO: stderr: ""
Sep 12 13:44:15.807: INFO: stdout: "pod \"e2e-test-nginx-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:44:15.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6270" for this suite.
Sep 12 13:44:21.830: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:44:21.897: INFO: namespace kubectl-6270 deletion completed in 6.08125187s

â€¢ [SLOW TEST:19.906 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Kubectl replace
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:44:21.897: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7252
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep 12 13:44:22.062: INFO: Waiting up to 5m0s for pod "downwardapi-volume-18439110-cdd4-4d28-bc49-bed6a1c45957" in namespace "downward-api-7252" to be "success or failure"
Sep 12 13:44:22.070: INFO: Pod "downwardapi-volume-18439110-cdd4-4d28-bc49-bed6a1c45957": Phase="Pending", Reason="", readiness=false. Elapsed: 8.423127ms
Sep 12 13:44:24.072: INFO: Pod "downwardapi-volume-18439110-cdd4-4d28-bc49-bed6a1c45957": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010453065s
Sep 12 13:44:26.074: INFO: Pod "downwardapi-volume-18439110-cdd4-4d28-bc49-bed6a1c45957": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012405359s
STEP: Saw pod success
Sep 12 13:44:26.074: INFO: Pod "downwardapi-volume-18439110-cdd4-4d28-bc49-bed6a1c45957" satisfied condition "success or failure"
Sep 12 13:44:26.076: INFO: Trying to get logs from node caasp-worker-thehejik-5 pod downwardapi-volume-18439110-cdd4-4d28-bc49-bed6a1c45957 container client-container: <nil>
STEP: delete the pod
Sep 12 13:44:26.097: INFO: Waiting for pod downwardapi-volume-18439110-cdd4-4d28-bc49-bed6a1c45957 to disappear
Sep 12 13:44:26.107: INFO: Pod downwardapi-volume-18439110-cdd4-4d28-bc49-bed6a1c45957 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:44:26.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7252" for this suite.
Sep 12 13:44:32.126: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:44:32.208: INFO: namespace downward-api-7252 deletion completed in 6.097943413s

â€¢ [SLOW TEST:10.310 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:44:32.208: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-1936
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Sep 12 13:44:35.383: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:44:35.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1936" for this suite.
Sep 12 13:44:41.422: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:44:41.491: INFO: namespace container-runtime-1936 deletion completed in 6.081752927s

â€¢ [SLOW TEST:9.283 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  blackbox test
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:38
    on terminated container
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:129
      should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:44:41.491: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8443
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-e514743a-5300-43b4-bffa-99cbbd8241a1
STEP: Creating a pod to test consume configMaps
Sep 12 13:44:41.661: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-7466f75d-fdd7-4be2-8ce0-c7e67a7f9977" in namespace "projected-8443" to be "success or failure"
Sep 12 13:44:41.684: INFO: Pod "pod-projected-configmaps-7466f75d-fdd7-4be2-8ce0-c7e67a7f9977": Phase="Pending", Reason="", readiness=false. Elapsed: 23.018116ms
Sep 12 13:44:43.687: INFO: Pod "pod-projected-configmaps-7466f75d-fdd7-4be2-8ce0-c7e67a7f9977": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025599562s
Sep 12 13:44:45.689: INFO: Pod "pod-projected-configmaps-7466f75d-fdd7-4be2-8ce0-c7e67a7f9977": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027975244s
STEP: Saw pod success
Sep 12 13:44:45.689: INFO: Pod "pod-projected-configmaps-7466f75d-fdd7-4be2-8ce0-c7e67a7f9977" satisfied condition "success or failure"
Sep 12 13:44:45.691: INFO: Trying to get logs from node caasp-worker-thehejik-0 pod pod-projected-configmaps-7466f75d-fdd7-4be2-8ce0-c7e67a7f9977 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 12 13:44:45.722: INFO: Waiting for pod pod-projected-configmaps-7466f75d-fdd7-4be2-8ce0-c7e67a7f9977 to disappear
Sep 12 13:44:45.730: INFO: Pod pod-projected-configmaps-7466f75d-fdd7-4be2-8ce0-c7e67a7f9977 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:44:45.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8443" for this suite.
Sep 12 13:44:51.748: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:44:51.813: INFO: namespace projected-8443 deletion completed in 6.080268737s

â€¢ [SLOW TEST:10.322 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:44:51.814: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-4320
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-4320
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a new StatefulSet
Sep 12 13:44:52.082: INFO: Found 0 stateful pods, waiting for 3
Sep 12 13:45:02.084: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Sep 12 13:45:02.085: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Sep 12 13:45:02.085: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Sep 12 13:45:02.104: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Sep 12 13:45:12.143: INFO: Updating stateful set ss2
Sep 12 13:45:12.177: INFO: Waiting for Pod statefulset-4320/ss2-2 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Restoring Pods to the correct revision when they are deleted
Sep 12 13:45:22.276: INFO: Found 2 stateful pods, waiting for 3
Sep 12 13:45:32.279: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Sep 12 13:45:32.279: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Sep 12 13:45:32.279: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Sep 12 13:45:42.279: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Sep 12 13:45:42.279: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Sep 12 13:45:42.279: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Sep 12 13:45:42.298: INFO: Updating stateful set ss2
Sep 12 13:45:42.323: INFO: Waiting for Pod statefulset-4320/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Sep 12 13:45:52.341: INFO: Updating stateful set ss2
Sep 12 13:45:52.362: INFO: Waiting for StatefulSet statefulset-4320/ss2 to complete update
Sep 12 13:45:52.362: INFO: Waiting for Pod statefulset-4320/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Sep 12 13:46:02.367: INFO: Waiting for StatefulSet statefulset-4320/ss2 to complete update
Sep 12 13:46:02.367: INFO: Waiting for Pod statefulset-4320/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Sep 12 13:46:12.366: INFO: Waiting for StatefulSet statefulset-4320/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Sep 12 13:46:22.366: INFO: Deleting all statefulset in ns statefulset-4320
Sep 12 13:46:22.368: INFO: Scaling statefulset ss2 to 0
Sep 12 13:46:52.386: INFO: Waiting for statefulset status.replicas updated to 0
Sep 12 13:46:52.388: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:46:52.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4320" for this suite.
Sep 12 13:46:58.428: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:46:58.507: INFO: namespace statefulset-4320 deletion completed in 6.092343911s

â€¢ [SLOW TEST:126.693 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:46:58.507: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-8978
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Sep 12 13:46:59.033: INFO: Pod name pod-release: Found 0 pods out of 1
Sep 12 13:47:04.036: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:47:05.056: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-8978" for this suite.
Sep 12 13:47:11.075: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:47:11.143: INFO: namespace replication-controller-8978 deletion completed in 6.082452602s

â€¢ [SLOW TEST:12.635 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:47:11.143: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-5490
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:164
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating pod
Sep 12 13:47:15.337: INFO: Pod pod-hostip-153cc61f-d942-4509-8479-53567544eee4 has hostIP: 10.84.73.78
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:47:15.337: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5490" for this suite.
Sep 12 13:47:37.355: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:47:37.432: INFO: namespace pods-5490 deletion completed in 22.092044945s

â€¢ [SLOW TEST:26.289 seconds]
[k8s.io] Pods
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:47:37.432: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-8302
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:51
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating pod busybox-8232d397-cb7b-4751-9459-52707f0dabf5 in namespace container-probe-8302
Sep 12 13:47:41.635: INFO: Started pod busybox-8232d397-cb7b-4751-9459-52707f0dabf5 in namespace container-probe-8302
STEP: checking the pod's current state and verifying that restartCount is present
Sep 12 13:47:41.637: INFO: Initial restart count of pod busybox-8232d397-cb7b-4751-9459-52707f0dabf5 is 0
Sep 12 13:48:31.736: INFO: Restart count of pod container-probe-8302/busybox-8232d397-cb7b-4751-9459-52707f0dabf5 is now 1 (50.099830012s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:48:31.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8302" for this suite.
Sep 12 13:48:37.780: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:48:37.849: INFO: namespace container-probe-8302 deletion completed in 6.087394035s

â€¢ [SLOW TEST:60.417 seconds]
[k8s.io] Probing container
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:48:37.849: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1447
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name configmap-test-volume-map-6bc2305c-5e64-4ff4-97c8-e7621ca39089
STEP: Creating a pod to test consume configMaps
Sep 12 13:48:38.019: INFO: Waiting up to 5m0s for pod "pod-configmaps-c50f52e7-5a13-48be-8205-f698ecbb21de" in namespace "configmap-1447" to be "success or failure"
Sep 12 13:48:38.029: INFO: Pod "pod-configmaps-c50f52e7-5a13-48be-8205-f698ecbb21de": Phase="Pending", Reason="", readiness=false. Elapsed: 10.323069ms
Sep 12 13:48:40.031: INFO: Pod "pod-configmaps-c50f52e7-5a13-48be-8205-f698ecbb21de": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012607973s
Sep 12 13:48:42.033: INFO: Pod "pod-configmaps-c50f52e7-5a13-48be-8205-f698ecbb21de": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014600064s
STEP: Saw pod success
Sep 12 13:48:42.033: INFO: Pod "pod-configmaps-c50f52e7-5a13-48be-8205-f698ecbb21de" satisfied condition "success or failure"
Sep 12 13:48:42.035: INFO: Trying to get logs from node caasp-worker-thehejik-2 pod pod-configmaps-c50f52e7-5a13-48be-8205-f698ecbb21de container configmap-volume-test: <nil>
STEP: delete the pod
Sep 12 13:48:42.068: INFO: Waiting for pod pod-configmaps-c50f52e7-5a13-48be-8205-f698ecbb21de to disappear
Sep 12 13:48:42.075: INFO: Pod pod-configmaps-c50f52e7-5a13-48be-8205-f698ecbb21de no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:48:42.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1447" for this suite.
Sep 12 13:48:48.172: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:48:48.254: INFO: namespace configmap-1447 deletion completed in 6.175271769s

â€¢ [SLOW TEST:10.405 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:32
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:48:48.256: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8579
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep 12 13:48:48.420: INFO: Waiting up to 5m0s for pod "downwardapi-volume-89a6dc02-d3f8-464b-ae5e-5cb301cac4f3" in namespace "downward-api-8579" to be "success or failure"
Sep 12 13:48:48.431: INFO: Pod "downwardapi-volume-89a6dc02-d3f8-464b-ae5e-5cb301cac4f3": Phase="Pending", Reason="", readiness=false. Elapsed: 10.285368ms
Sep 12 13:48:50.434: INFO: Pod "downwardapi-volume-89a6dc02-d3f8-464b-ae5e-5cb301cac4f3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013185456s
Sep 12 13:48:52.436: INFO: Pod "downwardapi-volume-89a6dc02-d3f8-464b-ae5e-5cb301cac4f3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015557928s
STEP: Saw pod success
Sep 12 13:48:52.436: INFO: Pod "downwardapi-volume-89a6dc02-d3f8-464b-ae5e-5cb301cac4f3" satisfied condition "success or failure"
Sep 12 13:48:52.438: INFO: Trying to get logs from node caasp-worker-thehejik-2 pod downwardapi-volume-89a6dc02-d3f8-464b-ae5e-5cb301cac4f3 container client-container: <nil>
STEP: delete the pod
Sep 12 13:48:52.459: INFO: Waiting for pod downwardapi-volume-89a6dc02-d3f8-464b-ae5e-5cb301cac4f3 to disappear
Sep 12 13:48:52.476: INFO: Pod downwardapi-volume-89a6dc02-d3f8-464b-ae5e-5cb301cac4f3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:48:52.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8579" for this suite.
Sep 12 13:48:58.496: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:48:58.575: INFO: namespace downward-api-8579 deletion completed in 6.095730973s

â€¢ [SLOW TEST:10.319 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:48:58.575: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3106
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:39
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward API volume plugin
Sep 12 13:48:58.762: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d57ed03d-944d-4e1d-88e9-1f3c7a047daa" in namespace "downward-api-3106" to be "success or failure"
Sep 12 13:48:58.772: INFO: Pod "downwardapi-volume-d57ed03d-944d-4e1d-88e9-1f3c7a047daa": Phase="Pending", Reason="", readiness=false. Elapsed: 10.615054ms
Sep 12 13:49:00.775: INFO: Pod "downwardapi-volume-d57ed03d-944d-4e1d-88e9-1f3c7a047daa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013561607s
Sep 12 13:49:02.778: INFO: Pod "downwardapi-volume-d57ed03d-944d-4e1d-88e9-1f3c7a047daa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016427957s
STEP: Saw pod success
Sep 12 13:49:02.778: INFO: Pod "downwardapi-volume-d57ed03d-944d-4e1d-88e9-1f3c7a047daa" satisfied condition "success or failure"
Sep 12 13:49:02.780: INFO: Trying to get logs from node caasp-worker-thehejik-1 pod downwardapi-volume-d57ed03d-944d-4e1d-88e9-1f3c7a047daa container client-container: <nil>
STEP: delete the pod
Sep 12 13:49:02.803: INFO: Waiting for pod downwardapi-volume-d57ed03d-944d-4e1d-88e9-1f3c7a047daa to disappear
Sep 12 13:49:02.811: INFO: Pod downwardapi-volume-d57ed03d-944d-4e1d-88e9-1f3c7a047daa no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:49:02.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3106" for this suite.
Sep 12 13:49:08.827: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:49:08.896: INFO: namespace downward-api-3106 deletion completed in 6.0825212s

â€¢ [SLOW TEST:10.321 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:49:08.897: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9808
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test emptydir volume type on node default medium
Sep 12 13:49:09.058: INFO: Waiting up to 5m0s for pod "pod-9cd46be5-c8de-4f42-aba2-f0be2a70936d" in namespace "emptydir-9808" to be "success or failure"
Sep 12 13:49:09.067: INFO: Pod "pod-9cd46be5-c8de-4f42-aba2-f0be2a70936d": Phase="Pending", Reason="", readiness=false. Elapsed: 8.833264ms
Sep 12 13:49:11.069: INFO: Pod "pod-9cd46be5-c8de-4f42-aba2-f0be2a70936d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011066662s
Sep 12 13:49:13.072: INFO: Pod "pod-9cd46be5-c8de-4f42-aba2-f0be2a70936d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013718564s
STEP: Saw pod success
Sep 12 13:49:13.072: INFO: Pod "pod-9cd46be5-c8de-4f42-aba2-f0be2a70936d" satisfied condition "success or failure"
Sep 12 13:49:13.074: INFO: Trying to get logs from node caasp-worker-thehejik-5 pod pod-9cd46be5-c8de-4f42-aba2-f0be2a70936d container test-container: <nil>
STEP: delete the pod
Sep 12 13:49:13.095: INFO: Waiting for pod pod-9cd46be5-c8de-4f42-aba2-f0be2a70936d to disappear
Sep 12 13:49:13.103: INFO: Pod pod-9cd46be5-c8de-4f42-aba2-f0be2a70936d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:49:13.104: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9808" for this suite.
Sep 12 13:49:19.129: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:49:19.221: INFO: namespace emptydir-9808 deletion completed in 6.114359764s

â€¢ [SLOW TEST:10.325 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:49:19.222: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-2820
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 12 13:49:19.431: INFO: Pod name rollover-pod: Found 0 pods out of 1
Sep 12 13:49:24.434: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Sep 12 13:49:24.434: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Sep 12 13:49:26.436: INFO: Creating deployment "test-rollover-deployment"
Sep 12 13:49:26.448: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Sep 12 13:49:28.452: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Sep 12 13:49:28.455: INFO: Ensure that both replica sets have 1 created replica
Sep 12 13:49:28.458: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Sep 12 13:49:28.462: INFO: Updating deployment test-rollover-deployment
Sep 12 13:49:28.462: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Sep 12 13:49:30.475: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Sep 12 13:49:30.479: INFO: Make sure deployment "test-rollover-deployment" is complete
Sep 12 13:49:30.482: INFO: all replica sets need to contain the pod-template-hash label
Sep 12 13:49:30.482: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892966, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892966, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892968, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892966, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 12 13:49:32.487: INFO: all replica sets need to contain the pod-template-hash label
Sep 12 13:49:32.487: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892966, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892966, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892971, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892966, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 12 13:49:34.494: INFO: all replica sets need to contain the pod-template-hash label
Sep 12 13:49:34.494: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892966, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892966, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892971, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892966, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 12 13:49:36.487: INFO: all replica sets need to contain the pod-template-hash label
Sep 12 13:49:36.487: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892966, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892966, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892971, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892966, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 12 13:49:38.487: INFO: all replica sets need to contain the pod-template-hash label
Sep 12 13:49:38.487: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892966, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892966, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892971, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892966, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 12 13:49:40.486: INFO: all replica sets need to contain the pod-template-hash label
Sep 12 13:49:40.487: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892966, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892966, loc:(*time.Location)(0x80bfa40)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892971, loc:(*time.Location)(0x80bfa40)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703892966, loc:(*time.Location)(0x80bfa40)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-854595fc44\" is progressing."}}, CollisionCount:(*int32)(nil)}
Sep 12 13:49:42.487: INFO: 
Sep 12 13:49:42.487: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Sep 12 13:49:42.492: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment,GenerateName:,Namespace:deployment-2820,SelfLink:/apis/apps/v1/namespaces/deployment-2820/deployments/test-rollover-deployment,UID:5cbc9475-5cbf-463d-93b2-c002f20c3640,ResourceVersion:35879,Generation:2,CreationTimestamp:2019-09-12 13:49:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[{Available True 2019-09-12 13:49:26 +0000 UTC 2019-09-12 13:49:26 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2019-09-12 13:49:41 +0000 UTC 2019-09-12 13:49:26 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-rollover-deployment-854595fc44" has successfully progressed.}],ReadyReplicas:1,CollisionCount:nil,},}

Sep 12 13:49:42.494: INFO: New ReplicaSet "test-rollover-deployment-854595fc44" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-854595fc44,GenerateName:,Namespace:deployment-2820,SelfLink:/apis/apps/v1/namespaces/deployment-2820/replicasets/test-rollover-deployment-854595fc44,UID:c0081723-8032-4936-9d28-fb44e63e51e2,ResourceVersion:35868,Generation:2,CreationTimestamp:2019-09-12 13:49:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 5cbc9475-5cbf-463d-93b2-c002f20c3640 0xc0023e8ba7 0xc0023e8ba8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*1,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[],},}
Sep 12 13:49:42.495: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Sep 12 13:49:42.495: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-controller,GenerateName:,Namespace:deployment-2820,SelfLink:/apis/apps/v1/namespaces/deployment-2820/replicasets/test-rollover-controller,UID:3e89ddba-73f9-4adf-820a-1800c2fbdbcd,ResourceVersion:35878,Generation:2,CreationTimestamp:2019-09-12 13:49:19 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 5cbc9475-5cbf-463d-93b2-c002f20c3640 0xc0023e8ad7 0xc0023e8ad8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent nil false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep 12 13:49:42.495: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-9b8b997cf,GenerateName:,Namespace:deployment-2820,SelfLink:/apis/apps/v1/namespaces/deployment-2820/replicasets/test-rollover-deployment-9b8b997cf,UID:a36087da-dc5c-48e0-87fa-8014f5e9e653,ResourceVersion:35814,Generation:2,CreationTimestamp:2019-09-12 13:49:26 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 1,deployment.kubernetes.io/max-replicas: 2,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment test-rollover-deployment 5cbc9475-5cbf-463d-93b2-c002f20c3640 0xc0023e8c70 0xc0023e8c71}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*0,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 9b8b997cf,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep 12 13:49:42.497: INFO: Pod "test-rollover-deployment-854595fc44-nh6qm" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:test-rollover-deployment-854595fc44-nh6qm,GenerateName:test-rollover-deployment-854595fc44-,Namespace:deployment-2820,SelfLink:/api/v1/namespaces/deployment-2820/pods/test-rollover-deployment-854595fc44-nh6qm,UID:f4f27454-6596-4bca-ac29-cfd11a76a38d,ResourceVersion:35842,Generation:0,CreationTimestamp:2019-09-12 13:49:28 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: rollover-pod,pod-template-hash: 854595fc44,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet test-rollover-deployment-854595fc44 c0081723-8032-4936-9d28-fb44e63e51e2 0xc0033c5307 0xc0033c5308}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-9v7z7 {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-9v7z7,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{redis gcr.io/kubernetes-e2e-test-images/redis:1.0 [] []  [] [] [] {map[] map[]} [{default-token-9v7z7 true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:caasp-worker-thehejik-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0033c5430} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0033c5450}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:49:28 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:49:31 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:49:31 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:49:28 +0000 UTC  }],Message:,Reason:,HostIP:10.84.73.79,PodIP:10.244.1.9,StartTime:2019-09-12 13:49:28 +0000 UTC,ContainerStatuses:[{redis {nil ContainerStateRunning{StartedAt:2019-09-12 13:49:31 +0000 UTC,} nil} {nil nil nil} true 0 gcr.io/kubernetes-e2e-test-images/redis:1.0 gcr.io/kubernetes-e2e-test-images/redis@sha256:2238f5a02d2648d41cc94a88f084060fbfa860890220328eb92696bf2ac649c9 cri-o://c68390454bfdcc4f84804f84e423955d0b72897a0cefe7d88b0803321ed4887d}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:49:42.497: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2820" for this suite.
Sep 12 13:49:48.518: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:49:48.589: INFO: namespace deployment-2820 deletion completed in 6.089125483s

â€¢ [SLOW TEST:29.367 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:49:48.589: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-7233
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:63
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Sep 12 13:50:00.804: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 12 13:50:00.815: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 12 13:50:02.816: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 12 13:50:02.818: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 12 13:50:04.816: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 12 13:50:04.818: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 12 13:50:06.816: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 12 13:50:06.818: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 12 13:50:08.816: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 12 13:50:08.818: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 12 13:50:10.816: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 12 13:50:10.818: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 12 13:50:12.816: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 12 13:50:12.818: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 12 13:50:14.816: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 12 13:50:14.818: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 12 13:50:16.816: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 12 13:50:16.818: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 12 13:50:18.816: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 12 13:50:18.818: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 12 13:50:20.816: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 12 13:50:20.818: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 12 13:50:22.816: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 12 13:50:22.818: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 12 13:50:24.816: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 12 13:50:24.819: INFO: Pod pod-with-poststart-exec-hook still exists
Sep 12 13:50:26.816: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Sep 12 13:50:26.818: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:50:26.818: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-7233" for this suite.
Sep 12 13:50:48.839: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:50:48.906: INFO: namespace container-lifecycle-hook-7233 deletion completed in 22.084873161s

â€¢ [SLOW TEST:60.317 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  when create a pod with lifecycle hook
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:50:48.907: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3599
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a pod to test downward api env vars
Sep 12 13:50:49.078: INFO: Waiting up to 5m0s for pod "downward-api-8e5f603e-3627-43fc-b1cf-08c2424077d2" in namespace "downward-api-3599" to be "success or failure"
Sep 12 13:50:49.086: INFO: Pod "downward-api-8e5f603e-3627-43fc-b1cf-08c2424077d2": Phase="Pending", Reason="", readiness=false. Elapsed: 7.913273ms
Sep 12 13:50:51.088: INFO: Pod "downward-api-8e5f603e-3627-43fc-b1cf-08c2424077d2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010434738s
Sep 12 13:50:53.091: INFO: Pod "downward-api-8e5f603e-3627-43fc-b1cf-08c2424077d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013120053s
STEP: Saw pod success
Sep 12 13:50:53.091: INFO: Pod "downward-api-8e5f603e-3627-43fc-b1cf-08c2424077d2" satisfied condition "success or failure"
Sep 12 13:50:53.092: INFO: Trying to get logs from node caasp-worker-thehejik-3 pod downward-api-8e5f603e-3627-43fc-b1cf-08c2424077d2 container dapi-container: <nil>
STEP: delete the pod
Sep 12 13:50:53.127: INFO: Waiting for pod downward-api-8e5f603e-3627-43fc-b1cf-08c2424077d2 to disappear
Sep 12 13:50:53.129: INFO: Pod downward-api-8e5f603e-3627-43fc-b1cf-08c2424077d2 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:50:53.129: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3599" for this suite.
Sep 12 13:50:59.146: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:50:59.214: INFO: namespace downward-api-3599 deletion completed in 6.08166566s

â€¢ [SLOW TEST:10.307 seconds]
[sig-node] Downward API
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:50:59.214: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1291
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating configMap with name projected-configmap-test-volume-9b27997b-2195-4fe1-b4fb-de917054b0ac
STEP: Creating a pod to test consume configMaps
Sep 12 13:50:59.381: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5299398c-8b13-4f1d-ac67-cb30672a7c97" in namespace "projected-1291" to be "success or failure"
Sep 12 13:50:59.391: INFO: Pod "pod-projected-configmaps-5299398c-8b13-4f1d-ac67-cb30672a7c97": Phase="Pending", Reason="", readiness=false. Elapsed: 10.455031ms
Sep 12 13:51:01.394: INFO: Pod "pod-projected-configmaps-5299398c-8b13-4f1d-ac67-cb30672a7c97": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012934215s
Sep 12 13:51:03.397: INFO: Pod "pod-projected-configmaps-5299398c-8b13-4f1d-ac67-cb30672a7c97": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015697561s
STEP: Saw pod success
Sep 12 13:51:03.397: INFO: Pod "pod-projected-configmaps-5299398c-8b13-4f1d-ac67-cb30672a7c97" satisfied condition "success or failure"
Sep 12 13:51:03.398: INFO: Trying to get logs from node caasp-worker-thehejik-3 pod pod-projected-configmaps-5299398c-8b13-4f1d-ac67-cb30672a7c97 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Sep 12 13:51:03.419: INFO: Waiting for pod pod-projected-configmaps-5299398c-8b13-4f1d-ac67-cb30672a7c97 to disappear
Sep 12 13:51:03.428: INFO: Pod pod-projected-configmaps-5299398c-8b13-4f1d-ac67-cb30672a7c97 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:51:03.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1291" for this suite.
Sep 12 13:51:09.445: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:51:09.529: INFO: namespace projected-1291 deletion completed in 6.097832826s

â€¢ [SLOW TEST:10.315 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:33
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:51:09.529: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-7879
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating the pod
Sep 12 13:51:09.684: INFO: PodSpec: initContainers in spec.initContainers
Sep 12 13:51:58.510: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-a70bddf0-99e1-466a-bed8-81fe69443c1c", GenerateName:"", Namespace:"init-container-7879", SelfLink:"/api/v1/namespaces/init-container-7879/pods/pod-init-a70bddf0-99e1-466a-bed8-81fe69443c1c", UID:"e3df2073-ed37-425d-8061-c6afe88af64a", ResourceVersion:"36427", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63703893069, loc:(*time.Location)(0x80bfa40)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"684705452"}, Annotations:map[string]string{"kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Initializers:(*v1.Initializers)(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-hnbm7", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0033ee000), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-hnbm7", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-hnbm7", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-hnbm7", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc002f4e088), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"caasp-worker-thehejik-0", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc003a0a000), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002f4e100)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002f4e120)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc002f4e128), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc002f4e12c), PreemptionPolicy:(*v1.PreemptionPolicy)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703893069, loc:(*time.Location)(0x80bfa40)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703893069, loc:(*time.Location)(0x80bfa40)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703893069, loc:(*time.Location)(0x80bfa40)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63703893069, loc:(*time.Location)(0x80bfa40)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.84.73.243", PodIP:"10.244.6.98", StartTime:(*v1.Time)(0xc002bec060), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000cba070)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000cba0e0)}, Ready:false, RestartCount:3, Image:"docker.io/library/busybox:1.29", ImageID:"docker.io/library/busybox@sha256:e004c2cc521c95383aebb1fb5893719aa7a8eae2e7a71f316a4410784edb00a9", ContainerID:"cri-o://dfe0664d3ac311abed14cbf51611d200ece2ca97cd9ae49466c2c4ecca4ddb76"}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002bec0a0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:""}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002bec080), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:""}}, QOSClass:"Guaranteed"}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:51:58.511: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-7879" for this suite.
Sep 12 13:52:20.548: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:52:20.614: INFO: namespace init-container-7879 deletion completed in 22.090122009s

â€¢ [SLOW TEST:71.085 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:52:20.614: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-5439
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:60
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:75
STEP: Creating service test in namespace statefulset-5439
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: Creating a new StatefulSet
Sep 12 13:52:20.797: INFO: Found 0 stateful pods, waiting for 3
Sep 12 13:52:30.800: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Sep 12 13:52:30.800: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Sep 12 13:52:30.800: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Sep 12 13:52:40.800: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Sep 12 13:52:40.800: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Sep 12 13:52:40.800: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Sep 12 13:52:40.806: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 exec --namespace=statefulset-5439 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep 12 13:52:41.384: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep 12 13:52:41.384: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep 12 13:52:41.384: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/nginx:1.14-alpine to docker.io/library/nginx:1.15-alpine
Sep 12 13:52:51.406: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Sep 12 13:53:01.436: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 exec --namespace=statefulset-5439 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 12 13:53:01.594: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep 12 13:53:01.594: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep 12 13:53:01.594: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep 12 13:53:11.606: INFO: Waiting for StatefulSet statefulset-5439/ss2 to complete update
Sep 12 13:53:11.607: INFO: Waiting for Pod statefulset-5439/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Sep 12 13:53:11.607: INFO: Waiting for Pod statefulset-5439/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Sep 12 13:53:21.626: INFO: Waiting for StatefulSet statefulset-5439/ss2 to complete update
Sep 12 13:53:21.626: INFO: Waiting for Pod statefulset-5439/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Sep 12 13:53:21.627: INFO: Waiting for Pod statefulset-5439/ss2-1 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
Sep 12 13:53:31.611: INFO: Waiting for StatefulSet statefulset-5439/ss2 to complete update
Sep 12 13:53:31.611: INFO: Waiting for Pod statefulset-5439/ss2-0 to have revision ss2-6c5cd755cd update revision ss2-7c9b54fd4c
STEP: Rolling back to a previous revision
Sep 12 13:53:41.611: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 exec --namespace=statefulset-5439 ss2-1 -- /bin/sh -x -c mv -v /usr/share/nginx/html/index.html /tmp/ || true'
Sep 12 13:53:41.796: INFO: stderr: "+ mv -v /usr/share/nginx/html/index.html /tmp/\n"
Sep 12 13:53:41.796: INFO: stdout: "'/usr/share/nginx/html/index.html' -> '/tmp/index.html'\n"
Sep 12 13:53:41.796: INFO: stdout of mv -v /usr/share/nginx/html/index.html /tmp/ || true on ss2-1: '/usr/share/nginx/html/index.html' -> '/tmp/index.html'

Sep 12 13:53:51.818: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Sep 12 13:54:01.845: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 exec --namespace=statefulset-5439 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/share/nginx/html/ || true'
Sep 12 13:54:02.004: INFO: stderr: "+ mv -v /tmp/index.html /usr/share/nginx/html/\n"
Sep 12 13:54:02.004: INFO: stdout: "'/tmp/index.html' -> '/usr/share/nginx/html/index.html'\n"
Sep 12 13:54:02.004: INFO: stdout of mv -v /tmp/index.html /usr/share/nginx/html/ || true on ss2-1: '/tmp/index.html' -> '/usr/share/nginx/html/index.html'

Sep 12 13:54:22.022: INFO: Waiting for StatefulSet statefulset-5439/ss2 to complete update
Sep 12 13:54:22.022: INFO: Waiting for Pod statefulset-5439/ss2-0 to have revision ss2-7c9b54fd4c update revision ss2-6c5cd755cd
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:86
Sep 12 13:54:32.027: INFO: Deleting all statefulset in ns statefulset-5439
Sep 12 13:54:32.029: INFO: Scaling statefulset ss2 to 0
Sep 12 13:54:52.054: INFO: Waiting for statefulset status.replicas updated to 0
Sep 12 13:54:52.056: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:54:52.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5439" for this suite.
Sep 12 13:54:58.091: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:54:58.189: INFO: namespace statefulset-5439 deletion completed in 6.113315595s

â€¢ [SLOW TEST:157.575 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:54:58.190: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-8886
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:72
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
Sep 12 13:54:58.341: INFO: Creating deployment "nginx-deployment"
Sep 12 13:54:58.344: INFO: Waiting for observed generation 1
Sep 12 13:55:00.373: INFO: Waiting for all required pods to come up
Sep 12 13:55:00.375: INFO: Pod name nginx: Found 10 pods out of 10
STEP: ensuring each pod is running
Sep 12 13:55:06.382: INFO: Waiting for deployment "nginx-deployment" to complete
Sep 12 13:55:06.386: INFO: Updating deployment "nginx-deployment" with a non-existent image
Sep 12 13:55:06.394: INFO: Updating deployment nginx-deployment
Sep 12 13:55:06.394: INFO: Waiting for observed generation 2
Sep 12 13:55:08.405: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Sep 12 13:55:08.406: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Sep 12 13:55:08.408: INFO: Waiting for the first rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Sep 12 13:55:08.413: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Sep 12 13:55:08.413: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Sep 12 13:55:08.414: INFO: Waiting for the second rollout's replicaset of deployment "nginx-deployment" to have desired number of replicas
Sep 12 13:55:08.417: INFO: Verifying that deployment "nginx-deployment" has minimum required number of available replicas
Sep 12 13:55:08.417: INFO: Scaling up the deployment "nginx-deployment" from 10 to 30
Sep 12 13:55:08.422: INFO: Updating deployment nginx-deployment
Sep 12 13:55:08.422: INFO: Waiting for the replicasets of deployment "nginx-deployment" to have desired number of replicas
Sep 12 13:55:08.442: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Sep 12 13:55:08.451: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:66
Sep 12 13:55:10.498: INFO: Deployment "nginx-deployment":
&Deployment{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment,GenerateName:,Namespace:deployment-8886,SelfLink:/apis/apps/v1/namespaces/deployment-8886/deployments/nginx-deployment,UID:8cd1e42d-ee98-4c6d-a776-b378772db367,ResourceVersion:37652,Generation:3,CreationTimestamp:2019-09-12 13:54:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{deployment.kubernetes.io/revision: 2,},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:DeploymentSpec{Replicas:*30,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[{Available False 2019-09-12 13:55:08 +0000 UTC 2019-09-12 13:55:08 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.} {Progressing True 2019-09-12 13:55:08 +0000 UTC 2019-09-12 13:54:58 +0000 UTC ReplicaSetUpdated ReplicaSet "nginx-deployment-55fb7cb77f" is progressing.}],ReadyReplicas:8,CollisionCount:nil,},}

Sep 12 13:55:10.501: INFO: New ReplicaSet "nginx-deployment-55fb7cb77f" of Deployment "nginx-deployment":
&ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f,GenerateName:,Namespace:deployment-8886,SelfLink:/apis/apps/v1/namespaces/deployment-8886/replicasets/nginx-deployment-55fb7cb77f,UID:9b295f4f-e789-4d51-b4f0-d861f41d97bd,ResourceVersion:37636,Generation:3,CreationTimestamp:2019-09-12 13:55:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 2,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 8cd1e42d-ee98-4c6d-a776-b378772db367 0xc0033b70c7 0xc0033b70c8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*13,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[],},}
Sep 12 13:55:10.501: INFO: All old ReplicaSets of Deployment "nginx-deployment":
Sep 12 13:55:10.501: INFO: &ReplicaSet{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498,GenerateName:,Namespace:deployment-8886,SelfLink:/apis/apps/v1/namespaces/deployment-8886/replicasets/nginx-deployment-7b8c6f4498,UID:8450686d-1245-4a39-8ab4-2609d41929d3,ResourceVersion:37647,Generation:3,CreationTimestamp:2019-09-12 13:54:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{deployment.kubernetes.io/desired-replicas: 30,deployment.kubernetes.io/max-replicas: 33,deployment.kubernetes.io/revision: 1,},OwnerReferences:[{apps/v1 Deployment nginx-deployment 8cd1e42d-ee98-4c6d-a776-b378772db367 0xc0033b7197 0xc0033b7198}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:ReplicaSetSpec{Replicas:*20,Selector:&k8s_io_apimachinery_pkg_apis_meta_v1.LabelSelector{MatchLabels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},MatchExpressions:[],},Template:k8s_io_api_core_v1.PodTemplateSpec{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:,GenerateName:,Namespace:,SelfLink:,UID:,ResourceVersion:,Generation:0,CreationTimestamp:0001-01-01 00:00:00 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{},OwnerReferences:[],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:,DeprecatedServiceAccount:,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[],HostAliases:[],PriorityClassName:,Priority:nil,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:nil,PreemptionPolicy:nil,},},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[],},}
Sep 12 13:55:10.505: INFO: Pod "nginx-deployment-55fb7cb77f-7fnsk" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-7fnsk,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-8886,SelfLink:/api/v1/namespaces/deployment-8886/pods/nginx-deployment-55fb7cb77f-7fnsk,UID:37515759-8f97-4d7a-bfe8-957d7e06630d,ResourceVersion:37786,Generation:0,CreationTimestamp:2019-09-12 13:55:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 9b295f4f-e789-4d51-b4f0-d861f41d97bd 0xc0033b7af7 0xc0033b7af8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tbz4x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tbz4x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tbz4x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:caasp-worker-thehejik-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0033b7b60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0033b7b80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:06 +0000 UTC  }],Message:,Reason:,HostIP:10.84.73.79,PodIP:10.244.1.248,StartTime:2019-09-12 13:55:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error reading manifest 404 in docker.io/library/nginx: manifest unknown: manifest unknown,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 12 13:55:10.506: INFO: Pod "nginx-deployment-55fb7cb77f-7ql7k" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-7ql7k,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-8886,SelfLink:/api/v1/namespaces/deployment-8886/pods/nginx-deployment-55fb7cb77f-7ql7k,UID:65ceda76-8c09-4d55-9101-f50747374746,ResourceVersion:37666,Generation:0,CreationTimestamp:2019-09-12 13:55:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 9b295f4f-e789-4d51-b4f0-d861f41d97bd 0xc0033b7c70 0xc0033b7c71}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tbz4x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tbz4x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tbz4x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:caasp-worker-thehejik-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0033b7ce0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0033b7d00}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC  }],Message:,Reason:,HostIP:10.84.73.97,PodIP:,StartTime:2019-09-12 13:55:08 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 12 13:55:10.506: INFO: Pod "nginx-deployment-55fb7cb77f-b2dvj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-b2dvj,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-8886,SelfLink:/api/v1/namespaces/deployment-8886/pods/nginx-deployment-55fb7cb77f-b2dvj,UID:b890aef3-a78c-4e7d-ba73-ae5faf7f3bc2,ResourceVersion:37776,Generation:0,CreationTimestamp:2019-09-12 13:55:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 9b295f4f-e789-4d51-b4f0-d861f41d97bd 0xc0033b7dd0 0xc0033b7dd1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tbz4x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tbz4x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tbz4x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:caasp-worker-thehejik-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0033b7e40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0033b7e60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:06 +0000 UTC  }],Message:,Reason:,HostIP:10.84.73.78,PodIP:10.244.5.226,StartTime:2019-09-12 13:55:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error reading manifest 404 in docker.io/library/nginx: manifest unknown: manifest unknown,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 12 13:55:10.507: INFO: Pod "nginx-deployment-55fb7cb77f-gsjw8" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-gsjw8,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-8886,SelfLink:/api/v1/namespaces/deployment-8886/pods/nginx-deployment-55fb7cb77f-gsjw8,UID:872f2db6-5712-463f-b92e-8503e93319ec,ResourceVersion:37773,Generation:0,CreationTimestamp:2019-09-12 13:55:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 9b295f4f-e789-4d51-b4f0-d861f41d97bd 0xc0033b7f50 0xc0033b7f51}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tbz4x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tbz4x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tbz4x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:caasp-worker-thehejik-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc0033b7fc0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc0033b7fe0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:06 +0000 UTC  }],Message:,Reason:,HostIP:10.84.73.97,PodIP:10.244.3.88,StartTime:2019-09-12 13:55:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error reading manifest 404 in docker.io/library/nginx: manifest unknown: manifest unknown,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 12 13:55:10.507: INFO: Pod "nginx-deployment-55fb7cb77f-k67nz" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-k67nz,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-8886,SelfLink:/api/v1/namespaces/deployment-8886/pods/nginx-deployment-55fb7cb77f-k67nz,UID:ad05f9a6-d7ad-4bba-820d-f7290b1f4f9f,ResourceVersion:37628,Generation:0,CreationTimestamp:2019-09-12 13:55:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 9b295f4f-e789-4d51-b4f0-d861f41d97bd 0xc00390e0d0 0xc00390e0d1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tbz4x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tbz4x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tbz4x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:caasp-worker-thehejik-4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00390e140} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00390e160}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC  }],Message:,Reason:,HostIP:10.84.72.31,PodIP:,StartTime:2019-09-12 13:55:08 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 12 13:55:10.507: INFO: Pod "nginx-deployment-55fb7cb77f-mzn8d" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-mzn8d,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-8886,SelfLink:/api/v1/namespaces/deployment-8886/pods/nginx-deployment-55fb7cb77f-mzn8d,UID:5e724e3c-013d-482a-bf86-ccc6c6c66c2a,ResourceVersion:37661,Generation:0,CreationTimestamp:2019-09-12 13:55:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 9b295f4f-e789-4d51-b4f0-d861f41d97bd 0xc00390e230 0xc00390e231}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tbz4x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tbz4x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tbz4x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:caasp-worker-thehejik-5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00390e2a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00390e2c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC  }],Message:,Reason:,HostIP:10.84.73.41,PodIP:,StartTime:2019-09-12 13:55:08 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 12 13:55:10.508: INFO: Pod "nginx-deployment-55fb7cb77f-r8jkd" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-r8jkd,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-8886,SelfLink:/api/v1/namespaces/deployment-8886/pods/nginx-deployment-55fb7cb77f-r8jkd,UID:f363f287-6f3f-4a34-9cd5-575f66135156,ResourceVersion:37654,Generation:0,CreationTimestamp:2019-09-12 13:55:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 9b295f4f-e789-4d51-b4f0-d861f41d97bd 0xc00390e390 0xc00390e391}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tbz4x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tbz4x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tbz4x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:caasp-worker-thehejik-4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00390e400} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00390e420}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC  }],Message:,Reason:,HostIP:10.84.72.31,PodIP:,StartTime:2019-09-12 13:55:08 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 12 13:55:10.508: INFO: Pod "nginx-deployment-55fb7cb77f-rrkdr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-rrkdr,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-8886,SelfLink:/api/v1/namespaces/deployment-8886/pods/nginx-deployment-55fb7cb77f-rrkdr,UID:efe79142-896a-4f6d-9af9-ecc3b2e5ca3f,ResourceVersion:37645,Generation:0,CreationTimestamp:2019-09-12 13:55:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 9b295f4f-e789-4d51-b4f0-d861f41d97bd 0xc00390e4f0 0xc00390e4f1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tbz4x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tbz4x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tbz4x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:caasp-worker-thehejik-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00390e560} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00390e580}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC  }],Message:,Reason:,HostIP:10.84.73.79,PodIP:,StartTime:2019-09-12 13:55:08 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 12 13:55:10.508: INFO: Pod "nginx-deployment-55fb7cb77f-scqkx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-scqkx,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-8886,SelfLink:/api/v1/namespaces/deployment-8886/pods/nginx-deployment-55fb7cb77f-scqkx,UID:a0acdaa1-5e0c-4a86-a322-a4d9476031e9,ResourceVersion:37543,Generation:0,CreationTimestamp:2019-09-12 13:55:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 9b295f4f-e789-4d51-b4f0-d861f41d97bd 0xc00390e660 0xc00390e661}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tbz4x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tbz4x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tbz4x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:caasp-worker-thehejik-5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00390e6d0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00390e6f0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:06 +0000 UTC  }],Message:,Reason:,HostIP:10.84.73.41,PodIP:,StartTime:2019-09-12 13:55:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 12 13:55:10.508: INFO: Pod "nginx-deployment-55fb7cb77f-t2hgl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-t2hgl,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-8886,SelfLink:/api/v1/namespaces/deployment-8886/pods/nginx-deployment-55fb7cb77f-t2hgl,UID:85669482-5682-4e5e-b4cf-c143c22d0ad8,ResourceVersion:37669,Generation:0,CreationTimestamp:2019-09-12 13:55:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 9b295f4f-e789-4d51-b4f0-d861f41d97bd 0xc00390e7c0 0xc00390e7c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tbz4x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tbz4x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tbz4x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:caasp-worker-thehejik-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00390e830} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00390e860}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC  }],Message:,Reason:,HostIP:10.84.73.243,PodIP:,StartTime:2019-09-12 13:55:08 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 12 13:55:10.509: INFO: Pod "nginx-deployment-55fb7cb77f-tm9zm" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-tm9zm,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-8886,SelfLink:/api/v1/namespaces/deployment-8886/pods/nginx-deployment-55fb7cb77f-tm9zm,UID:91474b62-3ddf-42a0-b392-e272817d6768,ResourceVersion:37784,Generation:0,CreationTimestamp:2019-09-12 13:55:06 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 9b295f4f-e789-4d51-b4f0-d861f41d97bd 0xc00390e930 0xc00390e931}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tbz4x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tbz4x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tbz4x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:caasp-worker-thehejik-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00390e9a0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00390e9c0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:06 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:06 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:06 +0000 UTC  }],Message:,Reason:,HostIP:10.84.73.243,PodIP:10.244.6.71,StartTime:2019-09-12 13:55:06 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error reading manifest 404 in docker.io/library/nginx: manifest unknown: manifest unknown,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 12 13:55:10.509: INFO: Pod "nginx-deployment-55fb7cb77f-w8kkx" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-w8kkx,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-8886,SelfLink:/api/v1/namespaces/deployment-8886/pods/nginx-deployment-55fb7cb77f-w8kkx,UID:d3a56c73-898c-4d87-a98b-61d5d93492f4,ResourceVersion:37644,Generation:0,CreationTimestamp:2019-09-12 13:55:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 9b295f4f-e789-4d51-b4f0-d861f41d97bd 0xc00390eab0 0xc00390eab1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tbz4x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tbz4x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tbz4x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:caasp-worker-thehejik-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00390eb40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00390eb60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC  }],Message:,Reason:,HostIP:10.84.73.78,PodIP:,StartTime:2019-09-12 13:55:08 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 12 13:55:10.509: INFO: Pod "nginx-deployment-55fb7cb77f-xfhzg" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-55fb7cb77f-xfhzg,GenerateName:nginx-deployment-55fb7cb77f-,Namespace:deployment-8886,SelfLink:/api/v1/namespaces/deployment-8886/pods/nginx-deployment-55fb7cb77f-xfhzg,UID:461141be-dcfc-4420-a0bd-48bc91b151f1,ResourceVersion:37650,Generation:0,CreationTimestamp:2019-09-12 13:55:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 55fb7cb77f,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-55fb7cb77f 9b295f4f-e789-4d51-b4f0-d861f41d97bd 0xc00390ec30 0xc00390ec31}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tbz4x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tbz4x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx nginx:404 [] []  [] [] [] {map[] map[]} [{default-token-tbz4x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:caasp-worker-thehejik-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00390eca0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00390ecc0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC  }],Message:,Reason:,HostIP:10.84.73.243,PodIP:,StartTime:2019-09-12 13:55:08 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 nginx:404  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 12 13:55:10.510: INFO: Pod "nginx-deployment-7b8c6f4498-24gkp" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-24gkp,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-8886,SelfLink:/api/v1/namespaces/deployment-8886/pods/nginx-deployment-7b8c6f4498-24gkp,UID:c5d204e0-9afe-446d-9a13-8429bfb290f5,ResourceVersion:37472,Generation:0,CreationTimestamp:2019-09-12 13:54:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 8450686d-1245-4a39-8ab4-2609d41929d3 0xc00390ed90 0xc00390ed91}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tbz4x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tbz4x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tbz4x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:caasp-worker-thehejik-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00390edf0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00390ee10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:54:58 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:03 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:03 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:54:58 +0000 UTC  }],Message:,Reason:,HostIP:10.84.73.243,PodIP:10.244.6.6,StartTime:2019-09-12 13:54:58 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-12 13:55:02 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:a3a0c4126587884f8d3090efca87f5af075d7e7ac8308cffc09a5a082d5f4760 cri-o://6755206872f930182876d45987cad94c1f472ec9928405b765a09cf8ba2854da}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 12 13:55:10.510: INFO: Pod "nginx-deployment-7b8c6f4498-5sqtg" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-5sqtg,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-8886,SelfLink:/api/v1/namespaces/deployment-8886/pods/nginx-deployment-7b8c6f4498-5sqtg,UID:dff10bb9-0a21-41b7-8be1-9343b290ae4a,ResourceVersion:37475,Generation:0,CreationTimestamp:2019-09-12 13:54:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 8450686d-1245-4a39-8ab4-2609d41929d3 0xc00390eee0 0xc00390eee1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tbz4x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tbz4x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tbz4x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:caasp-worker-thehejik-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00390ef40} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00390ef60}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:54:58 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:03 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:03 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:54:58 +0000 UTC  }],Message:,Reason:,HostIP:10.84.73.79,PodIP:10.244.1.59,StartTime:2019-09-12 13:54:58 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-12 13:55:02 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:a3a0c4126587884f8d3090efca87f5af075d7e7ac8308cffc09a5a082d5f4760 cri-o://347cebb40b8b134ed3c45dd4aa0edbc38635e875734242d1fba5e5abad578d89}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 12 13:55:10.510: INFO: Pod "nginx-deployment-7b8c6f4498-5vb98" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-5vb98,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-8886,SelfLink:/api/v1/namespaces/deployment-8886/pods/nginx-deployment-7b8c6f4498-5vb98,UID:8b199473-be67-4510-aba3-5953b0fd3341,ResourceVersion:37431,Generation:0,CreationTimestamp:2019-09-12 13:54:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 8450686d-1245-4a39-8ab4-2609d41929d3 0xc00390f030 0xc00390f031}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tbz4x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tbz4x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tbz4x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:caasp-worker-thehejik-5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00390f090} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00390f0b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:54:58 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:00 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:00 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:54:58 +0000 UTC  }],Message:,Reason:,HostIP:10.84.73.41,PodIP:10.244.4.188,StartTime:2019-09-12 13:54:58 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-12 13:55:00 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:a3a0c4126587884f8d3090efca87f5af075d7e7ac8308cffc09a5a082d5f4760 cri-o://9996047ca72e559963659f8cd25dc7f75218ab4f5f97557fdf3669fcb1fbf3f4}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 12 13:55:10.511: INFO: Pod "nginx-deployment-7b8c6f4498-77vt8" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-77vt8,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-8886,SelfLink:/api/v1/namespaces/deployment-8886/pods/nginx-deployment-7b8c6f4498-77vt8,UID:1fa774ce-7460-4b1a-a3b3-3d30e41e04d1,ResourceVersion:37459,Generation:0,CreationTimestamp:2019-09-12 13:54:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 8450686d-1245-4a39-8ab4-2609d41929d3 0xc00390f180 0xc00390f181}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tbz4x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tbz4x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tbz4x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:caasp-worker-thehejik-4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00390f1e0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00390f200}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:54:58 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:02 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:02 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:54:58 +0000 UTC  }],Message:,Reason:,HostIP:10.84.72.31,PodIP:10.244.2.202,StartTime:2019-09-12 13:54:58 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-12 13:55:02 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:a3a0c4126587884f8d3090efca87f5af075d7e7ac8308cffc09a5a082d5f4760 cri-o://597331453e938e14db10239e898d43e30229a92f2d697e980328979d1bc8b3a0}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 12 13:55:10.511: INFO: Pod "nginx-deployment-7b8c6f4498-7sxrr" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-7sxrr,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-8886,SelfLink:/api/v1/namespaces/deployment-8886/pods/nginx-deployment-7b8c6f4498-7sxrr,UID:94b191a3-adda-437b-9c0b-dc23fab1b7ed,ResourceVersion:37653,Generation:0,CreationTimestamp:2019-09-12 13:55:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 8450686d-1245-4a39-8ab4-2609d41929d3 0xc00390f2d0 0xc00390f2d1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tbz4x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tbz4x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tbz4x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:caasp-worker-thehejik-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00390f330} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00390f350}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC  }],Message:,Reason:,HostIP:10.84.73.78,PodIP:,StartTime:2019-09-12 13:55:08 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 12 13:55:10.511: INFO: Pod "nginx-deployment-7b8c6f4498-cnx2h" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-cnx2h,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-8886,SelfLink:/api/v1/namespaces/deployment-8886/pods/nginx-deployment-7b8c6f4498-cnx2h,UID:9fe20055-a7af-4b23-b643-1cb307c22267,ResourceVersion:37656,Generation:0,CreationTimestamp:2019-09-12 13:55:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 8450686d-1245-4a39-8ab4-2609d41929d3 0xc00390f410 0xc00390f411}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tbz4x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tbz4x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tbz4x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:caasp-worker-thehejik-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00390f470} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00390f490}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC  }],Message:,Reason:,HostIP:10.84.73.79,PodIP:,StartTime:2019-09-12 13:55:08 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 12 13:55:10.512: INFO: Pod "nginx-deployment-7b8c6f4498-d44mv" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-d44mv,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-8886,SelfLink:/api/v1/namespaces/deployment-8886/pods/nginx-deployment-7b8c6f4498-d44mv,UID:c3aab263-57c8-4358-b489-51741a59db81,ResourceVersion:37630,Generation:0,CreationTimestamp:2019-09-12 13:55:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 8450686d-1245-4a39-8ab4-2609d41929d3 0xc00390f550 0xc00390f551}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tbz4x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tbz4x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tbz4x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:caasp-worker-thehejik-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00390f5b0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00390f5d0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC  }],Message:,Reason:,HostIP:10.84.73.78,PodIP:,StartTime:2019-09-12 13:55:08 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 12 13:55:10.512: INFO: Pod "nginx-deployment-7b8c6f4498-dvpzp" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-dvpzp,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-8886,SelfLink:/api/v1/namespaces/deployment-8886/pods/nginx-deployment-7b8c6f4498-dvpzp,UID:205f4c79-73dc-49e6-8c1e-456767a9ecbc,ResourceVersion:37435,Generation:0,CreationTimestamp:2019-09-12 13:54:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 8450686d-1245-4a39-8ab4-2609d41929d3 0xc00390f690 0xc00390f691}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tbz4x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tbz4x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tbz4x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:caasp-worker-thehejik-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00390f6f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00390f710}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:54:58 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:01 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:01 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:54:58 +0000 UTC  }],Message:,Reason:,HostIP:10.84.73.78,PodIP:10.244.5.57,StartTime:2019-09-12 13:54:58 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-12 13:55:00 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:a3a0c4126587884f8d3090efca87f5af075d7e7ac8308cffc09a5a082d5f4760 cri-o://fb251b2b7beaf6e9b79d552e1c817749c3b5ed6b6b95969fc0ca7f4a9bf75d36}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 12 13:55:10.512: INFO: Pod "nginx-deployment-7b8c6f4498-f55ht" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-f55ht,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-8886,SelfLink:/api/v1/namespaces/deployment-8886/pods/nginx-deployment-7b8c6f4498-f55ht,UID:73579eaa-9428-47f9-aa0b-7c6ea2897c0c,ResourceVersion:37627,Generation:0,CreationTimestamp:2019-09-12 13:55:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 8450686d-1245-4a39-8ab4-2609d41929d3 0xc00390f7e0 0xc00390f7e1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tbz4x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tbz4x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tbz4x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:caasp-worker-thehejik-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00390f840} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00390f860}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC  }],Message:,Reason:,HostIP:10.84.73.97,PodIP:,StartTime:2019-09-12 13:55:08 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 12 13:55:10.512: INFO: Pod "nginx-deployment-7b8c6f4498-hjghl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-hjghl,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-8886,SelfLink:/api/v1/namespaces/deployment-8886/pods/nginx-deployment-7b8c6f4498-hjghl,UID:7b907b51-fdea-48f8-a150-30651c7d80b6,ResourceVersion:37643,Generation:0,CreationTimestamp:2019-09-12 13:55:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 8450686d-1245-4a39-8ab4-2609d41929d3 0xc00390f920 0xc00390f921}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tbz4x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tbz4x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tbz4x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:caasp-worker-thehejik-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00390f980} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00390f9a0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC  }],Message:,Reason:,HostIP:10.84.73.97,PodIP:,StartTime:2019-09-12 13:55:08 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 12 13:55:10.513: INFO: Pod "nginx-deployment-7b8c6f4498-lk97w" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-lk97w,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-8886,SelfLink:/api/v1/namespaces/deployment-8886/pods/nginx-deployment-7b8c6f4498-lk97w,UID:3eb1943a-9fb9-4e11-9474-773224267a8f,ResourceVersion:37663,Generation:0,CreationTimestamp:2019-09-12 13:55:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 8450686d-1245-4a39-8ab4-2609d41929d3 0xc00390fa70 0xc00390fa71}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tbz4x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tbz4x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tbz4x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:caasp-worker-thehejik-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00390fad0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00390faf0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC  }],Message:,Reason:,HostIP:10.84.73.243,PodIP:,StartTime:2019-09-12 13:55:08 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 12 13:55:10.513: INFO: Pod "nginx-deployment-7b8c6f4498-lmvsl" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-lmvsl,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-8886,SelfLink:/api/v1/namespaces/deployment-8886/pods/nginx-deployment-7b8c6f4498-lmvsl,UID:5a30c0be-b9f6-470c-8061-7cd7de3332b0,ResourceVersion:37648,Generation:0,CreationTimestamp:2019-09-12 13:55:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 8450686d-1245-4a39-8ab4-2609d41929d3 0xc00390fbb7 0xc00390fbb8}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tbz4x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tbz4x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tbz4x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:caasp-worker-thehejik-5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00390fc20} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00390fc40}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC  }],Message:,Reason:,HostIP:10.84.73.41,PodIP:,StartTime:2019-09-12 13:55:08 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 12 13:55:10.513: INFO: Pod "nginx-deployment-7b8c6f4498-m422z" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-m422z,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-8886,SelfLink:/api/v1/namespaces/deployment-8886/pods/nginx-deployment-7b8c6f4498-m422z,UID:2faed405-d948-44d1-be04-401489315971,ResourceVersion:37480,Generation:0,CreationTimestamp:2019-09-12 13:54:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 8450686d-1245-4a39-8ab4-2609d41929d3 0xc00390fd20 0xc00390fd21}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tbz4x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tbz4x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tbz4x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:caasp-worker-thehejik-4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00390fd80} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00390fda0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:54:58 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:03 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:03 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:54:58 +0000 UTC  }],Message:,Reason:,HostIP:10.84.72.31,PodIP:10.244.2.241,StartTime:2019-09-12 13:54:58 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-12 13:55:02 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:a3a0c4126587884f8d3090efca87f5af075d7e7ac8308cffc09a5a082d5f4760 cri-o://07a10fb351428708eb602eff800fadf8ce83ae23e6003b1754b6cbb61edc9623}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 12 13:55:10.513: INFO: Pod "nginx-deployment-7b8c6f4498-mqppw" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-mqppw,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-8886,SelfLink:/api/v1/namespaces/deployment-8886/pods/nginx-deployment-7b8c6f4498-mqppw,UID:fbbc03e6-cd19-4e19-b225-3200c071c2f7,ResourceVersion:37665,Generation:0,CreationTimestamp:2019-09-12 13:55:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 8450686d-1245-4a39-8ab4-2609d41929d3 0xc00390fe90 0xc00390fe91}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tbz4x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tbz4x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tbz4x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:caasp-worker-thehejik-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc00390fef0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc00390ff10}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC  }],Message:,Reason:,HostIP:10.84.73.78,PodIP:,StartTime:2019-09-12 13:55:08 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 12 13:55:10.514: INFO: Pod "nginx-deployment-7b8c6f4498-mwszn" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-mwszn,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-8886,SelfLink:/api/v1/namespaces/deployment-8886/pods/nginx-deployment-7b8c6f4498-mwszn,UID:74705aef-a9c0-4665-bd6f-378d36e50e1e,ResourceVersion:37642,Generation:0,CreationTimestamp:2019-09-12 13:55:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 8450686d-1245-4a39-8ab4-2609d41929d3 0xc00390ffd0 0xc00390ffd1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tbz4x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tbz4x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tbz4x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:caasp-worker-thehejik-4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001c34090} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001c340b0}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC  }],Message:,Reason:,HostIP:10.84.72.31,PodIP:,StartTime:2019-09-12 13:55:08 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 12 13:55:10.514: INFO: Pod "nginx-deployment-7b8c6f4498-pgbfj" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-pgbfj,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-8886,SelfLink:/api/v1/namespaces/deployment-8886/pods/nginx-deployment-7b8c6f4498-pgbfj,UID:b1df3f2f-473c-4932-848b-6ae983c4f55a,ResourceVersion:37655,Generation:0,CreationTimestamp:2019-09-12 13:55:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 8450686d-1245-4a39-8ab4-2609d41929d3 0xc001c34250 0xc001c34251}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tbz4x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tbz4x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tbz4x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:caasp-worker-thehejik-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001c34360} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001c34380}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC  }],Message:,Reason:,HostIP:10.84.73.97,PodIP:,StartTime:2019-09-12 13:55:08 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 12 13:55:10.514: INFO: Pod "nginx-deployment-7b8c6f4498-pkbc6" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-pkbc6,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-8886,SelfLink:/api/v1/namespaces/deployment-8886/pods/nginx-deployment-7b8c6f4498-pkbc6,UID:c3018bb8-0c40-4b2a-a657-5b8ca8249227,ResourceVersion:37477,Generation:0,CreationTimestamp:2019-09-12 13:54:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 8450686d-1245-4a39-8ab4-2609d41929d3 0xc001c345c0 0xc001c345c1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tbz4x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tbz4x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tbz4x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:caasp-worker-thehejik-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001c34670} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001c34690}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:54:58 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:03 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:03 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:54:58 +0000 UTC  }],Message:,Reason:,HostIP:10.84.73.243,PodIP:10.244.6.240,StartTime:2019-09-12 13:54:58 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-12 13:55:02 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:a3a0c4126587884f8d3090efca87f5af075d7e7ac8308cffc09a5a082d5f4760 cri-o://8a17adad7959062a1024f815798cdd84bfd30ee853c71a3e4b0a1d4e051488dd}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 12 13:55:10.515: INFO: Pod "nginx-deployment-7b8c6f4498-q8sc9" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-q8sc9,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-8886,SelfLink:/api/v1/namespaces/deployment-8886/pods/nginx-deployment-7b8c6f4498-q8sc9,UID:3e10ec2e-a7e9-4171-a5a6-4795882ef50f,ResourceVersion:37635,Generation:0,CreationTimestamp:2019-09-12 13:55:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 8450686d-1245-4a39-8ab4-2609d41929d3 0xc001c34887 0xc001c34888}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tbz4x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tbz4x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tbz4x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:caasp-worker-thehejik-5,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001c348f0} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001c34980}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC  }],Message:,Reason:,HostIP:10.84.73.41,PodIP:,StartTime:2019-09-12 13:55:08 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 12 13:55:10.515: INFO: Pod "nginx-deployment-7b8c6f4498-qwbhg" is available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-qwbhg,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-8886,SelfLink:/api/v1/namespaces/deployment-8886/pods/nginx-deployment-7b8c6f4498-qwbhg,UID:436d00c9-1353-4254-9558-278205f2f60e,ResourceVersion:37464,Generation:0,CreationTimestamp:2019-09-12 13:54:58 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 8450686d-1245-4a39-8ab4-2609d41929d3 0xc001c34ab0 0xc001c34ab1}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tbz4x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tbz4x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tbz4x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:caasp-worker-thehejik-1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001c34b10} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001c34b30}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Running,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:54:58 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:03 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:03 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:54:58 +0000 UTC  }],Message:,Reason:,HostIP:10.84.73.97,PodIP:10.244.3.177,StartTime:2019-09-12 13:54:58 +0000 UTC,ContainerStatuses:[{nginx {nil ContainerStateRunning{StartedAt:2019-09-12 13:55:02 +0000 UTC,} nil} {nil nil nil} true 0 docker.io/library/nginx:1.14-alpine docker.io/library/nginx@sha256:a3a0c4126587884f8d3090efca87f5af075d7e7ac8308cffc09a5a082d5f4760 cri-o://d38c9de963374b04d11d82899d2a348264f22f950275aebfd7e790b69a6e37c4}],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
Sep 12 13:55:10.515: INFO: Pod "nginx-deployment-7b8c6f4498-xhw92" is not available:
&Pod{ObjectMeta:k8s_io_apimachinery_pkg_apis_meta_v1.ObjectMeta{Name:nginx-deployment-7b8c6f4498-xhw92,GenerateName:nginx-deployment-7b8c6f4498-,Namespace:deployment-8886,SelfLink:/api/v1/namespaces/deployment-8886/pods/nginx-deployment-7b8c6f4498-xhw92,UID:f8b85c14-0ab8-43ad-9158-2976e6e9e71e,ResourceVersion:37629,Generation:0,CreationTimestamp:2019-09-12 13:55:08 +0000 UTC,DeletionTimestamp:<nil>,DeletionGracePeriodSeconds:nil,Labels:map[string]string{name: nginx,pod-template-hash: 7b8c6f4498,},Annotations:map[string]string{kubernetes.io/psp: e2e-test-privileged-psp,},OwnerReferences:[{apps/v1 ReplicaSet nginx-deployment-7b8c6f4498 8450686d-1245-4a39-8ab4-2609d41929d3 0xc001c34c00 0xc001c34c01}],Finalizers:[],ClusterName:,Initializers:nil,ManagedFields:[],},Spec:PodSpec{Volumes:[{default-token-tbz4x {nil nil nil nil nil SecretVolumeSource{SecretName:default-token-tbz4x,Items:[],DefaultMode:*420,Optional:nil,} nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil nil}}],Containers:[{nginx docker.io/library/nginx:1.14-alpine [] []  [] [] [] {map[] map[]} [{default-token-tbz4x true /var/run/secrets/kubernetes.io/serviceaccount  <nil> }] [] nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}],RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:caasp-worker-thehejik-2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[],WindowsOptions:nil,},ImagePullSecrets:[],Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[],AutomountServiceAccountToken:nil,Tolerations:[{node.kubernetes.io/not-ready Exists  NoExecute 0xc001c34c60} {node.kubernetes.io/unreachable Exists  NoExecute 0xc001c34c80}],HostAliases:[],PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[],RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,},Status:PodStatus{Phase:Pending,Conditions:[{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC ContainersNotReady containers with unready status: [nginx]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-09-12 13:55:08 +0000 UTC  }],Message:,Reason:,HostIP:10.84.73.79,PodIP:,StartTime:2019-09-12 13:55:08 +0000 UTC,ContainerStatuses:[{nginx {ContainerStateWaiting{Reason:ContainerCreating,Message:,} nil nil} {nil nil nil} false 0 docker.io/library/nginx:1.14-alpine  }],QOSClass:BestEffort,InitContainerStatuses:[],NominatedNodeName:,},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:55:10.515: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8886" for this suite.
Sep 12 13:55:18.534: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:55:18.604: INFO: namespace deployment-8886 deletion completed in 8.085833957s

â€¢ [SLOW TEST:20.415 seconds]
[sig-apps] Deployment
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client [k8s.io] Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:150
STEP: Creating a kubernetes client
Sep 12 13:55:18.605: INFO: >>> kubeConfig: /tmp/kubeconfig-268668657
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1342
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:221
[BeforeEach] [k8s.io] Update Demo
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:273
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
STEP: creating a replication controller
Sep 12 13:55:18.770: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 create -f - --namespace=kubectl-1342'
Sep 12 13:55:19.164: INFO: stderr: ""
Sep 12 13:55:19.164: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Sep 12 13:55:19.164: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1342'
Sep 12 13:55:19.249: INFO: stderr: ""
Sep 12 13:55:19.249: INFO: stdout: "update-demo-nautilus-54f6m update-demo-nautilus-cxwpk "
Sep 12 13:55:19.250: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get pods update-demo-nautilus-54f6m -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1342'
Sep 12 13:55:19.327: INFO: stderr: ""
Sep 12 13:55:19.327: INFO: stdout: ""
Sep 12 13:55:19.327: INFO: update-demo-nautilus-54f6m is created but not running
Sep 12 13:55:24.327: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1342'
Sep 12 13:55:24.445: INFO: stderr: ""
Sep 12 13:55:24.445: INFO: stdout: "update-demo-nautilus-54f6m update-demo-nautilus-cxwpk "
Sep 12 13:55:24.445: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get pods update-demo-nautilus-54f6m -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1342'
Sep 12 13:55:24.534: INFO: stderr: ""
Sep 12 13:55:24.534: INFO: stdout: ""
Sep 12 13:55:24.534: INFO: update-demo-nautilus-54f6m is created but not running
Sep 12 13:55:29.534: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1342'
Sep 12 13:55:29.625: INFO: stderr: ""
Sep 12 13:55:29.625: INFO: stdout: "update-demo-nautilus-54f6m update-demo-nautilus-cxwpk "
Sep 12 13:55:29.625: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get pods update-demo-nautilus-54f6m -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1342'
Sep 12 13:55:29.704: INFO: stderr: ""
Sep 12 13:55:29.704: INFO: stdout: "true"
Sep 12 13:55:29.704: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get pods update-demo-nautilus-54f6m -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1342'
Sep 12 13:55:29.792: INFO: stderr: ""
Sep 12 13:55:29.793: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 12 13:55:29.793: INFO: validating pod update-demo-nautilus-54f6m
Sep 12 13:55:29.796: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 12 13:55:29.796: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 12 13:55:29.796: INFO: update-demo-nautilus-54f6m is verified up and running
Sep 12 13:55:29.796: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get pods update-demo-nautilus-cxwpk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1342'
Sep 12 13:55:29.876: INFO: stderr: ""
Sep 12 13:55:29.876: INFO: stdout: "true"
Sep 12 13:55:29.876: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get pods update-demo-nautilus-cxwpk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1342'
Sep 12 13:55:29.959: INFO: stderr: ""
Sep 12 13:55:29.959: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Sep 12 13:55:29.959: INFO: validating pod update-demo-nautilus-cxwpk
Sep 12 13:55:29.962: INFO: got data: {
  "image": "nautilus.jpg"
}

Sep 12 13:55:29.962: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Sep 12 13:55:29.962: INFO: update-demo-nautilus-cxwpk is verified up and running
STEP: using delete to clean up resources
Sep 12 13:55:29.962: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 delete --grace-period=0 --force -f - --namespace=kubectl-1342'
Sep 12 13:55:30.063: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Sep 12 13:55:30.063: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Sep 12 13:55:30.063: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-1342'
Sep 12 13:55:30.154: INFO: stderr: "No resources found.\n"
Sep 12 13:55:30.154: INFO: stdout: ""
Sep 12 13:55:30.154: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-268668657 get pods -l name=update-demo --namespace=kubectl-1342 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Sep 12 13:55:30.245: INFO: stderr: ""
Sep 12 13:55:30.245: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
Sep 12 13:55:30.245: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1342" for this suite.
Sep 12 13:55:36.270: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Sep 12 13:55:36.341: INFO: namespace kubectl-1342 deletion completed in 6.088987658s

â€¢ [SLOW TEST:17.736 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  [k8s.io] Update Demo
  /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:692
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.15.2-beta.0.7+f6278300bebbb7/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:697
------------------------------
SSSSSSSSSep 12 13:55:36.341: INFO: Running AfterSuite actions on all nodes
Sep 12 13:55:36.341: INFO: Running AfterSuite actions on node 1
Sep 12 13:55:36.341: INFO: Skipping dumping logs from cluster

Ran 215 of 4413 Specs in 6015.438 seconds
SUCCESS! -- 215 Passed | 0 Failed | 0 Pending | 4198 Skipped
PASS

Ginkgo ran 1 suite in 1h40m17.580937393s
Test Suite Passed
