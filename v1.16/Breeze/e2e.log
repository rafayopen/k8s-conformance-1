I0302 09:09:39.648879      24 test_context.go:414] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-956629573
I0302 09:09:39.649219      24 e2e.go:92] Starting e2e run "a8c81237-777b-4b10-b1f0-cd6cebfe6741" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1583140176 - Will randomize all specs
Will run 274 of 4731 specs

Mar  2 09:09:39.798: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
Mar  2 09:09:39.804: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Mar  2 09:09:39.843: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Mar  2 09:09:39.933: INFO: 22 / 22 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Mar  2 09:09:39.933: INFO: expected 3 pod replicas in namespace 'kube-system', 3 are Running and Ready.
Mar  2 09:09:39.933: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Mar  2 09:09:39.956: INFO: 5 / 5 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds-amd64' (0 seconds elapsed)
Mar  2 09:09:39.956: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds-arm' (0 seconds elapsed)
Mar  2 09:09:39.956: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds-arm64' (0 seconds elapsed)
Mar  2 09:09:39.956: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds-ppc64le' (0 seconds elapsed)
Mar  2 09:09:39.956: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds-s390x' (0 seconds elapsed)
Mar  2 09:09:39.956: INFO: 5 / 5 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Mar  2 09:09:39.956: INFO: e2e test version: v1.16.7
Mar  2 09:09:39.959: INFO: kube-apiserver version: v1.16.7
Mar  2 09:09:39.959: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
Mar  2 09:09:40.055: INFO: Cluster IP family: ipv4
SSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:09:40.055: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename projected
Mar  2 09:09:40.347: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Mar  2 09:09:40.386: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2371
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-18ccc571-6fb5-400f-b208-c8f922493abd
STEP: Creating a pod to test consume secrets
Mar  2 09:09:40.651: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-7722192f-1a2c-42c0-89be-57bcd1e270b8" in namespace "projected-2371" to be "success or failure"
Mar  2 09:09:40.689: INFO: Pod "pod-projected-secrets-7722192f-1a2c-42c0-89be-57bcd1e270b8": Phase="Pending", Reason="", readiness=false. Elapsed: 37.97907ms
Mar  2 09:09:42.697: INFO: Pod "pod-projected-secrets-7722192f-1a2c-42c0-89be-57bcd1e270b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.046589653s
Mar  2 09:09:44.705: INFO: Pod "pod-projected-secrets-7722192f-1a2c-42c0-89be-57bcd1e270b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.054631963s
STEP: Saw pod success
Mar  2 09:09:44.706: INFO: Pod "pod-projected-secrets-7722192f-1a2c-42c0-89be-57bcd1e270b8" satisfied condition "success or failure"
Mar  2 09:09:44.711: INFO: Trying to get logs from node worker1 pod pod-projected-secrets-7722192f-1a2c-42c0-89be-57bcd1e270b8 container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar  2 09:09:44.948: INFO: Waiting for pod pod-projected-secrets-7722192f-1a2c-42c0-89be-57bcd1e270b8 to disappear
Mar  2 09:09:44.954: INFO: Pod pod-projected-secrets-7722192f-1a2c-42c0-89be-57bcd1e270b8 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:09:44.954: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2371" for this suite.
Mar  2 09:09:53.013: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:09:53.440: INFO: namespace projected-2371 deletion completed in 8.474068976s

• [SLOW TEST:13.385 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:09:53.441: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-5395
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override command
Mar  2 09:09:53.923: INFO: Waiting up to 5m0s for pod "client-containers-41863dfc-10a0-42b0-bce0-0c7f78b664ac" in namespace "containers-5395" to be "success or failure"
Mar  2 09:09:53.931: INFO: Pod "client-containers-41863dfc-10a0-42b0-bce0-0c7f78b664ac": Phase="Pending", Reason="", readiness=false. Elapsed: 7.002452ms
Mar  2 09:09:55.939: INFO: Pod "client-containers-41863dfc-10a0-42b0-bce0-0c7f78b664ac": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015141611s
Mar  2 09:09:57.947: INFO: Pod "client-containers-41863dfc-10a0-42b0-bce0-0c7f78b664ac": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023556478s
STEP: Saw pod success
Mar  2 09:09:57.947: INFO: Pod "client-containers-41863dfc-10a0-42b0-bce0-0c7f78b664ac" satisfied condition "success or failure"
Mar  2 09:09:57.955: INFO: Trying to get logs from node worker1 pod client-containers-41863dfc-10a0-42b0-bce0-0c7f78b664ac container test-container: <nil>
STEP: delete the pod
Mar  2 09:09:58.053: INFO: Waiting for pod client-containers-41863dfc-10a0-42b0-bce0-0c7f78b664ac to disappear
Mar  2 09:09:58.084: INFO: Pod client-containers-41863dfc-10a0-42b0-bce0-0c7f78b664ac no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:09:58.085: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-5395" for this suite.
Mar  2 09:10:06.273: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:10:06.439: INFO: namespace containers-5395 deletion completed in 8.344312618s

• [SLOW TEST:12.998 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:10:06.439: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-5961
STEP: Waiting for a default service account to be provisioned in namespace
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  2 09:10:06.844: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:10:12.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-5961" for this suite.
Mar  2 09:10:18.800: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:10:19.045: INFO: namespace custom-resource-definition-5961 deletion completed in 6.396519018s

• [SLOW TEST:12.606 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    getting/updating/patching custom resource definition status sub-resource works  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:10:19.045: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1313
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap that has name configmap-test-emptyKey-91832efc-5a18-417f-bc10-8327c0fe6fa4
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:10:19.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1313" for this suite.
Mar  2 09:10:25.818: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:10:25.992: INFO: namespace configmap-1313 deletion completed in 6.245192992s

• [SLOW TEST:6.947 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:10:25.994: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2634
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Mar  2 09:10:26.411: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 create -f - --namespace=kubectl-2634'
Mar  2 09:10:29.263: INFO: stderr: ""
Mar  2 09:10:29.263: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Mar  2 09:10:30.271: INFO: Selector matched 1 pods for map[app:redis]
Mar  2 09:10:30.271: INFO: Found 0 / 1
Mar  2 09:10:31.275: INFO: Selector matched 1 pods for map[app:redis]
Mar  2 09:10:31.275: INFO: Found 0 / 1
Mar  2 09:10:32.273: INFO: Selector matched 1 pods for map[app:redis]
Mar  2 09:10:32.273: INFO: Found 1 / 1
Mar  2 09:10:32.273: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Mar  2 09:10:32.309: INFO: Selector matched 1 pods for map[app:redis]
Mar  2 09:10:32.309: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Mar  2 09:10:32.309: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 patch pod redis-master-qdkv2 --namespace=kubectl-2634 -p {"metadata":{"annotations":{"x":"y"}}}'
Mar  2 09:10:32.550: INFO: stderr: ""
Mar  2 09:10:32.550: INFO: stdout: "pod/redis-master-qdkv2 patched\n"
STEP: checking annotations
Mar  2 09:10:32.558: INFO: Selector matched 1 pods for map[app:redis]
Mar  2 09:10:32.558: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:10:32.558: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2634" for this suite.
Mar  2 09:10:46.641: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:10:46.858: INFO: namespace kubectl-2634 deletion completed in 14.288123716s

• [SLOW TEST:20.864 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl patch
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1346
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:10:46.859: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1014
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Mar  2 09:10:47.628: INFO: Waiting up to 5m0s for pod "downwardapi-volume-df6eb07f-82b2-42d2-864d-86ce84e75f1d" in namespace "projected-1014" to be "success or failure"
Mar  2 09:10:47.767: INFO: Pod "downwardapi-volume-df6eb07f-82b2-42d2-864d-86ce84e75f1d": Phase="Pending", Reason="", readiness=false. Elapsed: 138.894358ms
Mar  2 09:10:49.905: INFO: Pod "downwardapi-volume-df6eb07f-82b2-42d2-864d-86ce84e75f1d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.276791889s
Mar  2 09:10:51.913: INFO: Pod "downwardapi-volume-df6eb07f-82b2-42d2-864d-86ce84e75f1d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.285167603s
STEP: Saw pod success
Mar  2 09:10:51.913: INFO: Pod "downwardapi-volume-df6eb07f-82b2-42d2-864d-86ce84e75f1d" satisfied condition "success or failure"
Mar  2 09:10:51.920: INFO: Trying to get logs from node worker1 pod downwardapi-volume-df6eb07f-82b2-42d2-864d-86ce84e75f1d container client-container: <nil>
STEP: delete the pod
Mar  2 09:10:52.004: INFO: Waiting for pod downwardapi-volume-df6eb07f-82b2-42d2-864d-86ce84e75f1d to disappear
Mar  2 09:10:52.009: INFO: Pod downwardapi-volume-df6eb07f-82b2-42d2-864d-86ce84e75f1d no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:10:52.009: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1014" for this suite.
Mar  2 09:11:00.225: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:11:00.469: INFO: namespace projected-1014 deletion completed in 8.336321513s

• [SLOW TEST:13.610 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:11:00.469: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-9627
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  2 09:11:00.902: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: client-side validation (kubectl create and apply) allows request with known and required properties
Mar  2 09:11:10.824: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 --namespace=crd-publish-openapi-9627 create -f -'
Mar  2 09:11:13.208: INFO: stderr: ""
Mar  2 09:11:13.208: INFO: stdout: "e2e-test-crd-publish-openapi-9645-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Mar  2 09:11:13.208: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 --namespace=crd-publish-openapi-9627 delete e2e-test-crd-publish-openapi-9645-crds test-foo'
Mar  2 09:11:13.521: INFO: stderr: ""
Mar  2 09:11:13.521: INFO: stdout: "e2e-test-crd-publish-openapi-9645-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Mar  2 09:11:13.521: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 --namespace=crd-publish-openapi-9627 apply -f -'
Mar  2 09:11:14.591: INFO: stderr: ""
Mar  2 09:11:14.591: INFO: stdout: "e2e-test-crd-publish-openapi-9645-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Mar  2 09:11:14.592: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 --namespace=crd-publish-openapi-9627 delete e2e-test-crd-publish-openapi-9645-crds test-foo'
Mar  2 09:11:14.839: INFO: stderr: ""
Mar  2 09:11:14.840: INFO: stdout: "e2e-test-crd-publish-openapi-9645-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: client-side validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema
Mar  2 09:11:14.840: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 --namespace=crd-publish-openapi-9627 create -f -'
Mar  2 09:11:15.661: INFO: rc: 1
Mar  2 09:11:15.661: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 --namespace=crd-publish-openapi-9627 apply -f -'
Mar  2 09:11:16.508: INFO: rc: 1
STEP: client-side validation (kubectl create and apply) rejects request without required properties
Mar  2 09:11:16.508: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 --namespace=crd-publish-openapi-9627 create -f -'
Mar  2 09:11:17.101: INFO: rc: 1
Mar  2 09:11:17.101: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 --namespace=crd-publish-openapi-9627 apply -f -'
Mar  2 09:11:17.837: INFO: rc: 1
STEP: kubectl explain works to explain CR properties
Mar  2 09:11:17.837: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 explain e2e-test-crd-publish-openapi-9645-crds'
Mar  2 09:11:18.551: INFO: stderr: ""
Mar  2 09:11:18.551: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-9645-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively
Mar  2 09:11:18.551: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 explain e2e-test-crd-publish-openapi-9645-crds.metadata'
Mar  2 09:11:19.204: INFO: stderr: ""
Mar  2 09:11:19.204: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-9645-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   clusterName\t<string>\n     The name of the cluster which the object belongs to. This is used to\n     distinguish resources with same name and namespace in different clusters.\n     This field is not set anywhere right now and apiserver is going to ignore\n     it if set in create or update request.\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC. Populated by the system.\n     Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested. Populated by the system when a graceful deletion is\n     requested. Read-only. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server. If this field is specified and the generated name exists, the\n     server will NOT return a 409 - instead, it will either return 201 Created\n     or 500 with Reason ServerTimeout indicating a unique name could not be\n     found in the time allotted, and the client should retry (optionally after\n     the time indicated in the Retry-After header). Applied only if Name is not\n     specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty. Must\n     be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources. Populated by the system.\n     Read-only. Value must be treated as opaque by clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     SelfLink is a URL representing this object. Populated by the system.\n     Read-only. DEPRECATED Kubernetes will stop propagating this field in 1.20\n     release and the field is planned to be removed in 1.21 release.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations. Populated by the system. Read-only.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Mar  2 09:11:19.205: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 explain e2e-test-crd-publish-openapi-9645-crds.spec'
Mar  2 09:11:19.943: INFO: stderr: ""
Mar  2 09:11:19.943: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-9645-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Mar  2 09:11:19.944: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 explain e2e-test-crd-publish-openapi-9645-crds.spec.bars'
Mar  2 09:11:20.661: INFO: stderr: ""
Mar  2 09:11:20.661: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-9645-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist
Mar  2 09:11:20.661: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 explain e2e-test-crd-publish-openapi-9645-crds.spec.bars2'
Mar  2 09:11:21.259: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:11:26.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-9627" for this suite.
Mar  2 09:11:32.461: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:11:32.757: INFO: namespace crd-publish-openapi-9627 deletion completed in 6.350258259s

• [SLOW TEST:32.288 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:11:32.757: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-377
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar  2 09:11:34.509: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Mar  2 09:11:36.530: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718737094, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718737094, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718737094, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718737094, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7794d7ccd5\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar  2 09:11:39.641: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  2 09:11:39.719: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-8099-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:11:46.116: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-377" for this suite.
Mar  2 09:11:54.192: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:11:54.603: INFO: namespace webhook-377 deletion completed in 8.477165447s
STEP: Destroying namespace "webhook-377-markers" for this suite.
Mar  2 09:12:02.635: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:12:02.853: INFO: namespace webhook-377-markers deletion completed in 8.249486298s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:30.151 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:12:02.908: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5953
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-a3a90814-cf27-4b4c-af05-5f6550a836a3
STEP: Creating a pod to test consume secrets
Mar  2 09:12:03.485: INFO: Waiting up to 5m0s for pod "pod-secrets-402e53e0-8d98-4486-9085-dc21cd7b9512" in namespace "secrets-5953" to be "success or failure"
Mar  2 09:12:03.512: INFO: Pod "pod-secrets-402e53e0-8d98-4486-9085-dc21cd7b9512": Phase="Pending", Reason="", readiness=false. Elapsed: 27.144503ms
Mar  2 09:12:05.521: INFO: Pod "pod-secrets-402e53e0-8d98-4486-9085-dc21cd7b9512": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036457747s
Mar  2 09:12:07.542: INFO: Pod "pod-secrets-402e53e0-8d98-4486-9085-dc21cd7b9512": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.057108964s
STEP: Saw pod success
Mar  2 09:12:07.542: INFO: Pod "pod-secrets-402e53e0-8d98-4486-9085-dc21cd7b9512" satisfied condition "success or failure"
Mar  2 09:12:07.549: INFO: Trying to get logs from node worker1 pod pod-secrets-402e53e0-8d98-4486-9085-dc21cd7b9512 container secret-env-test: <nil>
STEP: delete the pod
Mar  2 09:12:07.746: INFO: Waiting for pod pod-secrets-402e53e0-8d98-4486-9085-dc21cd7b9512 to disappear
Mar  2 09:12:07.762: INFO: Pod pod-secrets-402e53e0-8d98-4486-9085-dc21cd7b9512 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:12:07.762: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5953" for this suite.
Mar  2 09:12:15.879: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:12:16.112: INFO: namespace secrets-5953 deletion completed in 8.340200972s

• [SLOW TEST:13.204 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:12:16.113: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2775
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on tmpfs
Mar  2 09:12:16.578: INFO: Waiting up to 5m0s for pod "pod-39a24d8a-401c-4374-95c5-b21bc27e91c5" in namespace "emptydir-2775" to be "success or failure"
Mar  2 09:12:16.585: INFO: Pod "pod-39a24d8a-401c-4374-95c5-b21bc27e91c5": Phase="Pending", Reason="", readiness=false. Elapsed: 7.040922ms
Mar  2 09:12:18.613: INFO: Pod "pod-39a24d8a-401c-4374-95c5-b21bc27e91c5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035344419s
Mar  2 09:12:20.621: INFO: Pod "pod-39a24d8a-401c-4374-95c5-b21bc27e91c5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.043135511s
STEP: Saw pod success
Mar  2 09:12:20.621: INFO: Pod "pod-39a24d8a-401c-4374-95c5-b21bc27e91c5" satisfied condition "success or failure"
Mar  2 09:12:20.627: INFO: Trying to get logs from node worker1 pod pod-39a24d8a-401c-4374-95c5-b21bc27e91c5 container test-container: <nil>
STEP: delete the pod
Mar  2 09:12:20.696: INFO: Waiting for pod pod-39a24d8a-401c-4374-95c5-b21bc27e91c5 to disappear
Mar  2 09:12:20.716: INFO: Pod pod-39a24d8a-401c-4374-95c5-b21bc27e91c5 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:12:20.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2775" for this suite.
Mar  2 09:12:28.777: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:12:28.976: INFO: namespace emptydir-2775 deletion completed in 8.249031162s

• [SLOW TEST:12.863 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:12:28.977: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-1679
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar  2 09:12:31.129: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718737151, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718737151, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718737151, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718737150, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7794d7ccd5\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  2 09:12:33.182: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718737151, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718737151, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718737151, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718737150, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7794d7ccd5\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar  2 09:12:36.244: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/admissionregistration.k8s.io discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:12:36.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1679" for this suite.
Mar  2 09:12:44.387: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:12:44.568: INFO: namespace webhook-1679 deletion completed in 8.301500193s
STEP: Destroying namespace "webhook-1679-markers" for this suite.
Mar  2 09:12:50.630: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:12:50.813: INFO: namespace webhook-1679-markers deletion completed in 6.244584684s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:21.917 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation 
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:12:50.895: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename tables
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in tables-4478
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:47
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:12:51.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-4478" for this suite.
Mar  2 09:12:57.335: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:12:57.736: INFO: namespace tables-4478 deletion completed in 6.439026556s

• [SLOW TEST:6.841 seconds]
[sig-api-machinery] Servers with support for Table transformation
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:12:57.736: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7154
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting the proxy server
Mar  2 09:12:58.121: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-956629573 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:12:58.285: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7154" for this suite.
Mar  2 09:13:04.332: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:13:04.621: INFO: namespace kubectl-7154 deletion completed in 6.323702658s

• [SLOW TEST:6.885 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Proxy server
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1782
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch 
  watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:13:04.621: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename crd-watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-watch-9328
STEP: Waiting for a default service account to be provisioned in namespace
[It] watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  2 09:13:05.068: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Creating first CR 
Mar  2 09:13:10.967: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-03-02T09:13:10Z generation:1 name:name1 resourceVersion:78602 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:4db95c30-5f00-4e01-b8ac-cfa1287b2ddd] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR
Mar  2 09:13:20.992: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-03-02T09:13:20Z generation:1 name:name2 resourceVersion:78622 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:cdf9b3bf-1bff-40c9-9385-5a371970e621] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR
Mar  2 09:13:31.021: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-03-02T09:13:10Z generation:2 name:name1 resourceVersion:78641 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:4db95c30-5f00-4e01-b8ac-cfa1287b2ddd] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR
Mar  2 09:13:41.061: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-03-02T09:13:20Z generation:2 name:name2 resourceVersion:78659 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:cdf9b3bf-1bff-40c9-9385-5a371970e621] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR
Mar  2 09:13:51.089: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-03-02T09:13:10Z generation:2 name:name1 resourceVersion:78678 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:4db95c30-5f00-4e01-b8ac-cfa1287b2ddd] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR
Mar  2 09:14:01.135: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-03-02T09:13:20Z generation:2 name:name2 resourceVersion:78698 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:cdf9b3bf-1bff-40c9-9385-5a371970e621] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:14:11.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-9328" for this suite.
Mar  2 09:14:19.905: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:14:20.329: INFO: namespace crd-watch-9328 deletion completed in 8.577251353s

• [SLOW TEST:75.708 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:42
    watch on custom resource definition objects [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:14:20.330: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-3985
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3985.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-3985.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3985.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-3985.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-3985.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-3985.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-3985.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-3985.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-3985.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-3985.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-3985.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-3985.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3985.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 195.228.104.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.104.228.195_udp@PTR;check="$$(dig +tcp +noall +answer +search 195.228.104.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.104.228.195_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3985.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-3985.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3985.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-3985.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-3985.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-3985.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-3985.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-3985.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-3985.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-3985.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-3985.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-3985.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3985.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 195.228.104.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.104.228.195_udp@PTR;check="$$(dig +tcp +noall +answer +search 195.228.104.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.104.228.195_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar  2 09:14:27.324: INFO: Unable to read wheezy_udp@dns-test-service.dns-3985.svc.cluster.local from pod dns-3985/dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50: the server could not find the requested resource (get pods dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50)
Mar  2 09:14:27.350: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3985.svc.cluster.local from pod dns-3985/dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50: the server could not find the requested resource (get pods dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50)
Mar  2 09:14:27.359: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3985.svc.cluster.local from pod dns-3985/dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50: the server could not find the requested resource (get pods dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50)
Mar  2 09:14:27.366: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3985.svc.cluster.local from pod dns-3985/dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50: the server could not find the requested resource (get pods dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50)
Mar  2 09:14:27.422: INFO: Unable to read jessie_udp@dns-test-service.dns-3985.svc.cluster.local from pod dns-3985/dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50: the server could not find the requested resource (get pods dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50)
Mar  2 09:14:27.431: INFO: Unable to read jessie_tcp@dns-test-service.dns-3985.svc.cluster.local from pod dns-3985/dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50: the server could not find the requested resource (get pods dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50)
Mar  2 09:14:27.439: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3985.svc.cluster.local from pod dns-3985/dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50: the server could not find the requested resource (get pods dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50)
Mar  2 09:14:27.446: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3985.svc.cluster.local from pod dns-3985/dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50: the server could not find the requested resource (get pods dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50)
Mar  2 09:14:27.487: INFO: Lookups using dns-3985/dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50 failed for: [wheezy_udp@dns-test-service.dns-3985.svc.cluster.local wheezy_tcp@dns-test-service.dns-3985.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-3985.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-3985.svc.cluster.local jessie_udp@dns-test-service.dns-3985.svc.cluster.local jessie_tcp@dns-test-service.dns-3985.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-3985.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-3985.svc.cluster.local]

Mar  2 09:14:32.498: INFO: Unable to read wheezy_udp@dns-test-service.dns-3985.svc.cluster.local from pod dns-3985/dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50: the server could not find the requested resource (get pods dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50)
Mar  2 09:14:32.504: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3985.svc.cluster.local from pod dns-3985/dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50: the server could not find the requested resource (get pods dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50)
Mar  2 09:14:32.810: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3985.svc.cluster.local from pod dns-3985/dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50: the server could not find the requested resource (get pods dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50)
Mar  2 09:14:32.837: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3985.svc.cluster.local from pod dns-3985/dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50: the server could not find the requested resource (get pods dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50)
Mar  2 09:14:32.980: INFO: Unable to read jessie_udp@dns-test-service.dns-3985.svc.cluster.local from pod dns-3985/dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50: the server could not find the requested resource (get pods dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50)
Mar  2 09:14:32.988: INFO: Unable to read jessie_tcp@dns-test-service.dns-3985.svc.cluster.local from pod dns-3985/dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50: the server could not find the requested resource (get pods dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50)
Mar  2 09:14:32.997: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3985.svc.cluster.local from pod dns-3985/dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50: the server could not find the requested resource (get pods dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50)
Mar  2 09:14:33.006: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3985.svc.cluster.local from pod dns-3985/dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50: the server could not find the requested resource (get pods dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50)
Mar  2 09:14:33.131: INFO: Lookups using dns-3985/dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50 failed for: [wheezy_udp@dns-test-service.dns-3985.svc.cluster.local wheezy_tcp@dns-test-service.dns-3985.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-3985.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-3985.svc.cluster.local jessie_udp@dns-test-service.dns-3985.svc.cluster.local jessie_tcp@dns-test-service.dns-3985.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-3985.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-3985.svc.cluster.local]

Mar  2 09:14:37.497: INFO: Unable to read wheezy_udp@dns-test-service.dns-3985.svc.cluster.local from pod dns-3985/dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50: the server could not find the requested resource (get pods dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50)
Mar  2 09:14:37.505: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3985.svc.cluster.local from pod dns-3985/dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50: the server could not find the requested resource (get pods dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50)
Mar  2 09:14:37.512: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3985.svc.cluster.local from pod dns-3985/dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50: the server could not find the requested resource (get pods dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50)
Mar  2 09:14:37.519: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3985.svc.cluster.local from pod dns-3985/dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50: the server could not find the requested resource (get pods dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50)
Mar  2 09:14:37.569: INFO: Unable to read jessie_udp@dns-test-service.dns-3985.svc.cluster.local from pod dns-3985/dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50: the server could not find the requested resource (get pods dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50)
Mar  2 09:14:37.575: INFO: Unable to read jessie_tcp@dns-test-service.dns-3985.svc.cluster.local from pod dns-3985/dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50: the server could not find the requested resource (get pods dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50)
Mar  2 09:14:37.582: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3985.svc.cluster.local from pod dns-3985/dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50: the server could not find the requested resource (get pods dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50)
Mar  2 09:14:37.590: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3985.svc.cluster.local from pod dns-3985/dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50: the server could not find the requested resource (get pods dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50)
Mar  2 09:14:37.637: INFO: Lookups using dns-3985/dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50 failed for: [wheezy_udp@dns-test-service.dns-3985.svc.cluster.local wheezy_tcp@dns-test-service.dns-3985.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-3985.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-3985.svc.cluster.local jessie_udp@dns-test-service.dns-3985.svc.cluster.local jessie_tcp@dns-test-service.dns-3985.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-3985.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-3985.svc.cluster.local]

Mar  2 09:14:42.496: INFO: Unable to read wheezy_udp@dns-test-service.dns-3985.svc.cluster.local from pod dns-3985/dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50: the server could not find the requested resource (get pods dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50)
Mar  2 09:14:42.505: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3985.svc.cluster.local from pod dns-3985/dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50: the server could not find the requested resource (get pods dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50)
Mar  2 09:14:42.513: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3985.svc.cluster.local from pod dns-3985/dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50: the server could not find the requested resource (get pods dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50)
Mar  2 09:14:42.520: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3985.svc.cluster.local from pod dns-3985/dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50: the server could not find the requested resource (get pods dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50)
Mar  2 09:14:42.576: INFO: Unable to read jessie_udp@dns-test-service.dns-3985.svc.cluster.local from pod dns-3985/dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50: the server could not find the requested resource (get pods dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50)
Mar  2 09:14:42.585: INFO: Unable to read jessie_tcp@dns-test-service.dns-3985.svc.cluster.local from pod dns-3985/dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50: the server could not find the requested resource (get pods dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50)
Mar  2 09:14:42.594: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3985.svc.cluster.local from pod dns-3985/dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50: the server could not find the requested resource (get pods dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50)
Mar  2 09:14:42.603: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3985.svc.cluster.local from pod dns-3985/dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50: the server could not find the requested resource (get pods dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50)
Mar  2 09:14:42.844: INFO: Lookups using dns-3985/dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50 failed for: [wheezy_udp@dns-test-service.dns-3985.svc.cluster.local wheezy_tcp@dns-test-service.dns-3985.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-3985.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-3985.svc.cluster.local jessie_udp@dns-test-service.dns-3985.svc.cluster.local jessie_tcp@dns-test-service.dns-3985.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-3985.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-3985.svc.cluster.local]

Mar  2 09:14:47.496: INFO: Unable to read wheezy_udp@dns-test-service.dns-3985.svc.cluster.local from pod dns-3985/dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50: the server could not find the requested resource (get pods dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50)
Mar  2 09:14:47.505: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3985.svc.cluster.local from pod dns-3985/dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50: the server could not find the requested resource (get pods dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50)
Mar  2 09:14:47.512: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3985.svc.cluster.local from pod dns-3985/dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50: the server could not find the requested resource (get pods dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50)
Mar  2 09:14:47.520: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3985.svc.cluster.local from pod dns-3985/dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50: the server could not find the requested resource (get pods dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50)
Mar  2 09:14:47.572: INFO: Unable to read jessie_udp@dns-test-service.dns-3985.svc.cluster.local from pod dns-3985/dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50: the server could not find the requested resource (get pods dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50)
Mar  2 09:14:47.580: INFO: Unable to read jessie_tcp@dns-test-service.dns-3985.svc.cluster.local from pod dns-3985/dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50: the server could not find the requested resource (get pods dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50)
Mar  2 09:14:47.587: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3985.svc.cluster.local from pod dns-3985/dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50: the server could not find the requested resource (get pods dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50)
Mar  2 09:14:47.594: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3985.svc.cluster.local from pod dns-3985/dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50: the server could not find the requested resource (get pods dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50)
Mar  2 09:14:47.634: INFO: Lookups using dns-3985/dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50 failed for: [wheezy_udp@dns-test-service.dns-3985.svc.cluster.local wheezy_tcp@dns-test-service.dns-3985.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-3985.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-3985.svc.cluster.local jessie_udp@dns-test-service.dns-3985.svc.cluster.local jessie_tcp@dns-test-service.dns-3985.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-3985.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-3985.svc.cluster.local]

Mar  2 09:14:52.497: INFO: Unable to read wheezy_udp@dns-test-service.dns-3985.svc.cluster.local from pod dns-3985/dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50: the server could not find the requested resource (get pods dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50)
Mar  2 09:14:52.507: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3985.svc.cluster.local from pod dns-3985/dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50: the server could not find the requested resource (get pods dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50)
Mar  2 09:14:52.514: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3985.svc.cluster.local from pod dns-3985/dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50: the server could not find the requested resource (get pods dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50)
Mar  2 09:14:52.522: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3985.svc.cluster.local from pod dns-3985/dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50: the server could not find the requested resource (get pods dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50)
Mar  2 09:14:52.568: INFO: Unable to read jessie_udp@dns-test-service.dns-3985.svc.cluster.local from pod dns-3985/dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50: the server could not find the requested resource (get pods dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50)
Mar  2 09:14:52.575: INFO: Unable to read jessie_tcp@dns-test-service.dns-3985.svc.cluster.local from pod dns-3985/dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50: the server could not find the requested resource (get pods dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50)
Mar  2 09:14:52.582: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3985.svc.cluster.local from pod dns-3985/dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50: the server could not find the requested resource (get pods dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50)
Mar  2 09:14:52.589: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3985.svc.cluster.local from pod dns-3985/dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50: the server could not find the requested resource (get pods dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50)
Mar  2 09:14:52.629: INFO: Lookups using dns-3985/dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50 failed for: [wheezy_udp@dns-test-service.dns-3985.svc.cluster.local wheezy_tcp@dns-test-service.dns-3985.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-3985.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-3985.svc.cluster.local jessie_udp@dns-test-service.dns-3985.svc.cluster.local jessie_tcp@dns-test-service.dns-3985.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-3985.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-3985.svc.cluster.local]

Mar  2 09:14:58.024: INFO: DNS probes using dns-3985/dns-test-81c7ec0d-6d51-4763-9f8c-f5d150e82b50 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:15:00.407: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3985" for this suite.
Mar  2 09:15:10.479: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:15:10.651: INFO: namespace dns-3985 deletion completed in 10.229545273s

• [SLOW TEST:50.321 seconds]
[sig-network] DNS
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:15:10.652: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-2410
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  2 09:15:11.197: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:15:18.077: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-2410" for this suite.
Mar  2 09:15:26.602: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:15:28.363: INFO: namespace custom-resource-definition-2410 deletion completed in 9.952166353s

• [SLOW TEST:17.712 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:15:28.364: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-9206
STEP: Waiting for a default service account to be provisioned in namespace
[It] should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/apiextensions.k8s.io discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:15:29.601: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-9206" for this suite.
Mar  2 09:15:37.876: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:15:38.049: INFO: namespace custom-resource-definition-9206 deletion completed in 8.437985493s

• [SLOW TEST:9.685 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:15:38.049: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-5465
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar  2 09:15:42.301: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Mar  2 09:15:44.633: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718737342, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718737342, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718737342, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718737342, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7794d7ccd5\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar  2 09:15:47.793: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
Mar  2 09:15:47.904: INFO: Waiting for webhook configuration to be ready...
STEP: create a pod
STEP: 'kubectl attach' the pod, should be denied by the webhook
Mar  2 09:15:52.145: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 attach --namespace=webhook-5465 to-be-attached-pod -i -c=container1'
Mar  2 09:15:52.395: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:15:52.671: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5465" for this suite.
Mar  2 09:16:06.852: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:16:07.290: INFO: namespace webhook-5465 deletion completed in 14.60893095s
STEP: Destroying namespace "webhook-5465-markers" for this suite.
Mar  2 09:16:15.430: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:16:15.617: INFO: namespace webhook-5465-markers deletion completed in 8.327267411s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:37.610 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:16:15.660: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4878
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name projected-secret-test-cd3d4e62-6c2d-46b7-9125-ab75aef18eab
STEP: Creating a pod to test consume secrets
Mar  2 09:16:17.895: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-4f9c74bd-27c0-4c31-baab-ef74a65884a9" in namespace "projected-4878" to be "success or failure"
Mar  2 09:16:17.910: INFO: Pod "pod-projected-secrets-4f9c74bd-27c0-4c31-baab-ef74a65884a9": Phase="Pending", Reason="", readiness=false. Elapsed: 15.025136ms
Mar  2 09:16:19.938: INFO: Pod "pod-projected-secrets-4f9c74bd-27c0-4c31-baab-ef74a65884a9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.04307146s
Mar  2 09:16:21.946: INFO: Pod "pod-projected-secrets-4f9c74bd-27c0-4c31-baab-ef74a65884a9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.05089885s
STEP: Saw pod success
Mar  2 09:16:21.946: INFO: Pod "pod-projected-secrets-4f9c74bd-27c0-4c31-baab-ef74a65884a9" satisfied condition "success or failure"
Mar  2 09:16:21.952: INFO: Trying to get logs from node worker1 pod pod-projected-secrets-4f9c74bd-27c0-4c31-baab-ef74a65884a9 container secret-volume-test: <nil>
STEP: delete the pod
Mar  2 09:16:22.445: INFO: Waiting for pod pod-projected-secrets-4f9c74bd-27c0-4c31-baab-ef74a65884a9 to disappear
Mar  2 09:16:22.451: INFO: Pod pod-projected-secrets-4f9c74bd-27c0-4c31-baab-ef74a65884a9 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:16:22.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4878" for this suite.
Mar  2 09:16:36.562: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:16:36.806: INFO: namespace projected-4878 deletion completed in 14.344970632s

• [SLOW TEST:21.146 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:16:36.806: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3177
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run rc
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1439
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image 172.20.8.7/library/httpd:2.4.38-alpine
Mar  2 09:16:40.617: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 run e2e-test-httpd-rc --image=172.20.8.7/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-3177'
Mar  2 09:16:41.183: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Mar  2 09:16:41.183: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
STEP: verifying the pod controlled by rc e2e-test-httpd-rc was created
STEP: confirm that you can get logs from an rc
Mar  2 09:16:41.197: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-httpd-rc-292gh]
Mar  2 09:16:41.197: INFO: Waiting up to 5m0s for pod "e2e-test-httpd-rc-292gh" in namespace "kubectl-3177" to be "running and ready"
Mar  2 09:16:41.203: INFO: Pod "e2e-test-httpd-rc-292gh": Phase="Pending", Reason="", readiness=false. Elapsed: 5.462729ms
Mar  2 09:16:43.289: INFO: Pod "e2e-test-httpd-rc-292gh": Phase="Pending", Reason="", readiness=false. Elapsed: 2.091164539s
Mar  2 09:16:45.319: INFO: Pod "e2e-test-httpd-rc-292gh": Phase="Running", Reason="", readiness=true. Elapsed: 4.121342967s
Mar  2 09:16:45.319: INFO: Pod "e2e-test-httpd-rc-292gh" satisfied condition "running and ready"
Mar  2 09:16:45.319: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-httpd-rc-292gh]
Mar  2 09:16:45.319: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 logs rc/e2e-test-httpd-rc --namespace=kubectl-3177'
Mar  2 09:16:45.592: INFO: stderr: ""
Mar  2 09:16:45.592: INFO: stdout: "AH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 10.244.4.135. Set the 'ServerName' directive globally to suppress this message\nAH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 10.244.4.135. Set the 'ServerName' directive globally to suppress this message\n[Mon Mar 02 09:16:43.521154 2020] [mpm_event:notice] [pid 1:tid 139925277191016] AH00489: Apache/2.4.38 (Unix) configured -- resuming normal operations\n[Mon Mar 02 09:16:43.521249 2020] [core:notice] [pid 1:tid 139925277191016] AH00094: Command line: 'httpd -D FOREGROUND'\n"
[AfterEach] Kubectl run rc
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1444
Mar  2 09:16:45.592: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 delete rc e2e-test-httpd-rc --namespace=kubectl-3177'
Mar  2 09:16:45.811: INFO: stderr: ""
Mar  2 09:16:45.811: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:16:45.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3177" for this suite.
Mar  2 09:17:00.310: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:17:01.672: INFO: namespace kubectl-3177 deletion completed in 15.851359475s

• [SLOW TEST:24.866 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run rc
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1435
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:17:01.674: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-9198
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-af7fb77b-3869-4a20-9c1b-86eb864e8762
STEP: Creating secret with name s-test-opt-upd-88bc1397-2686-43a1-a242-c56884e7212c
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-af7fb77b-3869-4a20-9c1b-86eb864e8762
STEP: Updating secret s-test-opt-upd-88bc1397-2686-43a1-a242-c56884e7212c
STEP: Creating secret with name s-test-opt-create-d37b045f-f234-44bf-9c9b-cc2be3bde055
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:17:13.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9198" for this suite.
Mar  2 09:17:45.945: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:17:46.140: INFO: namespace secrets-9198 deletion completed in 32.587159853s

• [SLOW TEST:44.466 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:17:46.140: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-8699
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-d6de71f8-6f10-4c30-b910-c4cb2f73aca6 in namespace container-probe-8699
Mar  2 09:17:50.980: INFO: Started pod busybox-d6de71f8-6f10-4c30-b910-c4cb2f73aca6 in namespace container-probe-8699
STEP: checking the pod's current state and verifying that restartCount is present
Mar  2 09:17:51.015: INFO: Initial restart count of pod busybox-d6de71f8-6f10-4c30-b910-c4cb2f73aca6 is 0
Mar  2 09:18:37.904: INFO: Restart count of pod container-probe-8699/busybox-d6de71f8-6f10-4c30-b910-c4cb2f73aca6 is now 1 (46.888725398s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:18:38.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8699" for this suite.
Mar  2 09:18:48.383: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:18:48.900: INFO: namespace container-probe-8699 deletion completed in 10.769757684s

• [SLOW TEST:62.759 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:18:48.900: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-7996
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  2 09:19:11.912: INFO: Container started at 2020-03-02 09:18:51 +0000 UTC, pod became ready at 2020-03-02 09:19:11 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:19:11.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7996" for this suite.
Mar  2 09:19:42.164: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:19:42.622: INFO: namespace container-probe-7996 deletion completed in 30.702215194s

• [SLOW TEST:53.723 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:19:42.623: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4425
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-a925e0aa-76e1-4642-8937-3206efa92b6d
STEP: Creating a pod to test consume configMaps
Mar  2 09:19:43.449: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-149de0b3-9af9-49d8-92ad-14bb77872e21" in namespace "projected-4425" to be "success or failure"
Mar  2 09:19:43.455: INFO: Pod "pod-projected-configmaps-149de0b3-9af9-49d8-92ad-14bb77872e21": Phase="Pending", Reason="", readiness=false. Elapsed: 5.870643ms
Mar  2 09:19:45.463: INFO: Pod "pod-projected-configmaps-149de0b3-9af9-49d8-92ad-14bb77872e21": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014158437s
Mar  2 09:19:47.504: INFO: Pod "pod-projected-configmaps-149de0b3-9af9-49d8-92ad-14bb77872e21": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.054978729s
STEP: Saw pod success
Mar  2 09:19:47.504: INFO: Pod "pod-projected-configmaps-149de0b3-9af9-49d8-92ad-14bb77872e21" satisfied condition "success or failure"
Mar  2 09:19:47.517: INFO: Trying to get logs from node worker1 pod pod-projected-configmaps-149de0b3-9af9-49d8-92ad-14bb77872e21 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar  2 09:19:48.797: INFO: Waiting for pod pod-projected-configmaps-149de0b3-9af9-49d8-92ad-14bb77872e21 to disappear
Mar  2 09:19:48.827: INFO: Pod pod-projected-configmaps-149de0b3-9af9-49d8-92ad-14bb77872e21 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:19:48.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4425" for this suite.
Mar  2 09:19:57.005: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:19:57.540: INFO: namespace projected-4425 deletion completed in 8.695737045s

• [SLOW TEST:14.917 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:19:57.540: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-6154
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Mar  2 09:20:07.074: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar  2 09:20:07.082: INFO: Pod pod-with-prestop-http-hook still exists
Mar  2 09:20:09.082: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar  2 09:20:09.096: INFO: Pod pod-with-prestop-http-hook still exists
Mar  2 09:20:11.082: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar  2 09:20:11.091: INFO: Pod pod-with-prestop-http-hook still exists
Mar  2 09:20:13.082: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Mar  2 09:20:13.091: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:20:13.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-6154" for this suite.
Mar  2 09:20:29.392: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:20:29.855: INFO: namespace container-lifecycle-hook-6154 deletion completed in 16.607644044s

• [SLOW TEST:32.315 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:20:29.855: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-6619
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Mar  2 09:20:31.244: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-6619 /api/v1/namespaces/watch-6619/configmaps/e2e-watch-test-resource-version 6db4e5c7-8453-4f38-8b4d-66e1456aac12 79850 0 2020-03-02 09:20:30 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar  2 09:20:31.245: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-6619 /api/v1/namespaces/watch-6619/configmaps/e2e-watch-test-resource-version 6db4e5c7-8453-4f38-8b4d-66e1456aac12 79851 0 2020-03-02 09:20:30 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:20:31.245: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6619" for this suite.
Mar  2 09:20:37.734: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:20:37.951: INFO: namespace watch-6619 deletion completed in 6.696837224s

• [SLOW TEST:8.095 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:20:37.951: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-283
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Mar  2 09:20:38.427: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:20:43.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-283" for this suite.
Mar  2 09:20:51.663: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:20:51.988: INFO: namespace init-container-283 deletion completed in 8.388806362s

• [SLOW TEST:14.037 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:20:51.988: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-5586
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Mar  2 09:20:52.424: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: rename a version
STEP: check the new version name is served
STEP: check the old version name is removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:21:30.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5586" for this suite.
Mar  2 09:21:38.551: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:21:38.803: INFO: namespace crd-publish-openapi-5586 deletion completed in 8.555978737s

• [SLOW TEST:46.815 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:21:38.804: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-4857
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-4857.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-4857.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4857.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-4857.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-4857.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4857.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar  2 09:21:43.675: INFO: DNS probes using dns-4857/dns-test-0c59aea0-8641-4d1e-a367-2b786faf757e succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:21:43.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4857" for this suite.
Mar  2 09:21:52.291: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:21:52.539: INFO: namespace dns-4857 deletion completed in 8.400191311s

• [SLOW TEST:13.735 seconds]
[sig-network] DNS
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:21:52.539: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-8135
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-8135
STEP: changing the ExternalName service to type=ClusterIP
STEP: creating replication controller externalname-service in namespace services-8135
I0302 09:21:53.349650      24 runners.go:184] Created replication controller with name: externalname-service, namespace: services-8135, replica count: 2
I0302 09:21:56.400543      24 runners.go:184] externalname-service Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Mar  2 09:21:59.401: INFO: Creating new exec pod
I0302 09:21:59.400983      24 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Mar  2 09:22:04.532: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 exec --namespace=services-8135 execpodvtlxg -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Mar  2 09:22:06.355: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Mar  2 09:22:06.355: INFO: stdout: ""
Mar  2 09:22:06.356: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 exec --namespace=services-8135 execpodvtlxg -- /bin/sh -x -c nc -zv -t -w 2 10.111.16.113 80'
Mar  2 09:22:06.795: INFO: stderr: "+ nc -zv -t -w 2 10.111.16.113 80\nConnection to 10.111.16.113 80 port [tcp/http] succeeded!\n"
Mar  2 09:22:06.795: INFO: stdout: ""
Mar  2 09:22:06.795: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:22:07.081: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8135" for this suite.
Mar  2 09:22:17.400: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:22:17.702: INFO: namespace services-8135 deletion completed in 10.611241581s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:25.163 seconds]
[sig-network] Services
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:22:17.703: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-4033
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  2 09:22:18.886: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"30b9863d-449b-4f67-9b58-c4291f57a84c", Controller:(*bool)(0xc0048f8276), BlockOwnerDeletion:(*bool)(0xc0048f8277)}}
Mar  2 09:22:18.914: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"00f2a2d0-d56a-4d31-97be-7d98566ea10d", Controller:(*bool)(0xc004a0029a), BlockOwnerDeletion:(*bool)(0xc004a0029b)}}
Mar  2 09:22:19.055: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"60acaff1-546e-409a-b5e3-99659abf66b7", Controller:(*bool)(0xc004a00496), BlockOwnerDeletion:(*bool)(0xc004a00497)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:22:24.116: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4033" for this suite.
Mar  2 09:22:32.249: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:22:32.608: INFO: namespace gc-4033 deletion completed in 8.483871547s

• [SLOW TEST:14.905 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:22:32.608: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-1819
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
STEP: reading a file in the container
Mar  2 09:22:38.479: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-1819 pod-service-account-014746f7-3635-4006-9ef7-fb6aeefc223b -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Mar  2 09:22:38.996: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-1819 pod-service-account-014746f7-3635-4006-9ef7-fb6aeefc223b -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Mar  2 09:22:39.436: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-1819 pod-service-account-014746f7-3635-4006-9ef7-fb6aeefc223b -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:22:40.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-1819" for this suite.
Mar  2 09:22:48.256: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:22:49.320: INFO: namespace svcaccounts-1819 deletion completed in 9.222068088s

• [SLOW TEST:16.713 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:22:49.321: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-6633
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar  2 09:22:54.058: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Mar  2 09:22:56.078: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718737773, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718737773, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718737773, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718737773, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7794d7ccd5\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar  2 09:22:59.309: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a mutating webhook configuration
STEP: Updating a mutating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that should not be mutated
STEP: Patching a mutating webhook configuration's rules to include the create operation
STEP: Creating a configMap that should be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:23:01.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6633" for this suite.
Mar  2 09:23:11.359: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:23:11.737: INFO: namespace webhook-6633 deletion completed in 10.441417506s
STEP: Destroying namespace "webhook-6633-markers" for this suite.
Mar  2 09:23:17.811: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:23:18.127: INFO: namespace webhook-6633-markers deletion completed in 6.38942197s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:28.910 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:23:18.232: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-6416
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Mar  2 09:23:18.806: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:18.806: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:18.806: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:18.813: INFO: Number of nodes with available pods: 0
Mar  2 09:23:18.813: INFO: Node worker1 is running more than one daemon pod
Mar  2 09:23:19.823: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:19.823: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:19.823: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:20.031: INFO: Number of nodes with available pods: 0
Mar  2 09:23:20.031: INFO: Node worker1 is running more than one daemon pod
Mar  2 09:23:20.931: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:20.931: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:20.931: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:20.938: INFO: Number of nodes with available pods: 0
Mar  2 09:23:20.938: INFO: Node worker1 is running more than one daemon pod
Mar  2 09:23:21.823: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:21.823: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:21.823: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:21.829: INFO: Number of nodes with available pods: 1
Mar  2 09:23:21.829: INFO: Node worker2 is running more than one daemon pod
Mar  2 09:23:22.822: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:22.822: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:22.822: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:23.202: INFO: Number of nodes with available pods: 1
Mar  2 09:23:23.202: INFO: Node worker2 is running more than one daemon pod
Mar  2 09:23:23.823: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:23.824: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:23.824: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:23.832: INFO: Number of nodes with available pods: 1
Mar  2 09:23:23.832: INFO: Node worker2 is running more than one daemon pod
Mar  2 09:23:24.823: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:24.823: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:24.823: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:24.831: INFO: Number of nodes with available pods: 2
Mar  2 09:23:24.831: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Mar  2 09:23:24.959: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:24.959: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:24.959: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:25.032: INFO: Number of nodes with available pods: 1
Mar  2 09:23:25.033: INFO: Node worker2 is running more than one daemon pod
Mar  2 09:23:26.045: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:26.045: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:26.045: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:26.053: INFO: Number of nodes with available pods: 1
Mar  2 09:23:26.053: INFO: Node worker2 is running more than one daemon pod
Mar  2 09:23:27.043: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:27.044: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:27.044: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:27.052: INFO: Number of nodes with available pods: 1
Mar  2 09:23:27.052: INFO: Node worker2 is running more than one daemon pod
Mar  2 09:23:28.042: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:28.042: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:28.042: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:28.052: INFO: Number of nodes with available pods: 1
Mar  2 09:23:28.052: INFO: Node worker2 is running more than one daemon pod
Mar  2 09:23:29.044: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:29.044: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:29.044: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:29.051: INFO: Number of nodes with available pods: 1
Mar  2 09:23:29.051: INFO: Node worker2 is running more than one daemon pod
Mar  2 09:23:30.045: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:30.045: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:30.045: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:30.052: INFO: Number of nodes with available pods: 1
Mar  2 09:23:30.052: INFO: Node worker2 is running more than one daemon pod
Mar  2 09:23:31.043: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:31.043: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:31.043: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:31.554: INFO: Number of nodes with available pods: 1
Mar  2 09:23:31.555: INFO: Node worker2 is running more than one daemon pod
Mar  2 09:23:32.044: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:32.044: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:32.044: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:32.051: INFO: Number of nodes with available pods: 1
Mar  2 09:23:32.051: INFO: Node worker2 is running more than one daemon pod
Mar  2 09:23:33.044: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:33.044: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:33.044: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:33.060: INFO: Number of nodes with available pods: 1
Mar  2 09:23:33.060: INFO: Node worker2 is running more than one daemon pod
Mar  2 09:23:34.042: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:34.042: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:34.042: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:34.050: INFO: Number of nodes with available pods: 1
Mar  2 09:23:34.050: INFO: Node worker2 is running more than one daemon pod
Mar  2 09:23:35.043: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:35.043: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:35.043: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:35.054: INFO: Number of nodes with available pods: 1
Mar  2 09:23:35.054: INFO: Node worker2 is running more than one daemon pod
Mar  2 09:23:36.044: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:36.044: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:36.044: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:36.050: INFO: Number of nodes with available pods: 1
Mar  2 09:23:36.050: INFO: Node worker2 is running more than one daemon pod
Mar  2 09:23:37.042: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:37.043: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:37.043: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:37.189: INFO: Number of nodes with available pods: 1
Mar  2 09:23:37.189: INFO: Node worker2 is running more than one daemon pod
Mar  2 09:23:38.044: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:38.044: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:38.044: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:38.052: INFO: Number of nodes with available pods: 1
Mar  2 09:23:38.052: INFO: Node worker2 is running more than one daemon pod
Mar  2 09:23:39.042: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:39.043: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:39.043: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:39.050: INFO: Number of nodes with available pods: 1
Mar  2 09:23:39.050: INFO: Node worker2 is running more than one daemon pod
Mar  2 09:23:40.042: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:40.042: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:40.042: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:40.051: INFO: Number of nodes with available pods: 1
Mar  2 09:23:40.051: INFO: Node worker2 is running more than one daemon pod
Mar  2 09:23:41.313: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:41.313: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:41.313: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:41.345: INFO: Number of nodes with available pods: 1
Mar  2 09:23:41.345: INFO: Node worker2 is running more than one daemon pod
Mar  2 09:23:42.047: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:42.048: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:42.048: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:42.059: INFO: Number of nodes with available pods: 1
Mar  2 09:23:42.059: INFO: Node worker2 is running more than one daemon pod
Mar  2 09:23:43.041: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:43.042: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:43.042: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:43.061: INFO: Number of nodes with available pods: 1
Mar  2 09:23:43.061: INFO: Node worker2 is running more than one daemon pod
Mar  2 09:23:44.071: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:44.071: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:44.071: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:44.081: INFO: Number of nodes with available pods: 1
Mar  2 09:23:44.081: INFO: Node worker2 is running more than one daemon pod
Mar  2 09:23:45.050: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:45.050: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:45.050: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:45.079: INFO: Number of nodes with available pods: 1
Mar  2 09:23:45.079: INFO: Node worker2 is running more than one daemon pod
Mar  2 09:23:46.090: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:46.090: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:46.090: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:46.187: INFO: Number of nodes with available pods: 1
Mar  2 09:23:46.187: INFO: Node worker2 is running more than one daemon pod
Mar  2 09:23:47.044: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:47.044: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:47.044: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:23:47.052: INFO: Number of nodes with available pods: 2
Mar  2 09:23:47.052: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6416, will wait for the garbage collector to delete the pods
Mar  2 09:23:47.168: INFO: Deleting DaemonSet.extensions daemon-set took: 48.320006ms
Mar  2 09:23:47.869: INFO: Terminating DaemonSet.extensions daemon-set pods took: 700.407469ms
Mar  2 09:24:01.202: INFO: Number of nodes with available pods: 0
Mar  2 09:24:01.202: INFO: Number of running nodes: 0, number of available pods: 0
Mar  2 09:24:01.212: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-6416/daemonsets","resourceVersion":"80648"},"items":null}

Mar  2 09:24:01.311: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-6416/pods","resourceVersion":"80648"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:24:01.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6416" for this suite.
Mar  2 09:24:11.421: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:24:11.604: INFO: namespace daemonsets-6416 deletion completed in 10.262300289s

• [SLOW TEST:53.372 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:24:11.604: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2461
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating api versions
Mar  2 09:24:12.182: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 api-versions'
Mar  2 09:24:12.481: INFO: stderr: ""
Mar  2 09:24:12.481: INFO: stdout: "admissionregistration.k8s.io/v1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\nbatch/v2alpha1\ncertificates.k8s.io/v1beta1\ncontour.heptio.com/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nprojectcontour.io/v1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:24:12.482: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2461" for this suite.
Mar  2 09:24:20.531: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:24:20.711: INFO: namespace kubectl-2461 deletion completed in 8.217852857s

• [SLOW TEST:9.107 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl api-versions
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:738
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:24:20.713: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5464
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-1943e7f6-d2ea-42d7-a3f0-f77c7cbe05c5
STEP: Creating configMap with name cm-test-opt-upd-4896ce10-610b-4d7c-8d92-ed1e4ca7a0d9
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-1943e7f6-d2ea-42d7-a3f0-f77c7cbe05c5
STEP: Updating configmap cm-test-opt-upd-4896ce10-610b-4d7c-8d92-ed1e4ca7a0d9
STEP: Creating configMap with name cm-test-opt-create-1458ff89-8e25-4d9b-9419-c06d1a38a2db
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:24:29.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5464" for this suite.
Mar  2 09:24:59.628: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:25:00.354: INFO: namespace projected-5464 deletion completed in 30.804577029s

• [SLOW TEST:39.642 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:25:00.355: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6398
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Mar  2 09:25:00.989: INFO: Waiting up to 5m0s for pod "downwardapi-volume-40688b34-3f9a-4531-be3e-4ae420a0d0b4" in namespace "projected-6398" to be "success or failure"
Mar  2 09:25:01.025: INFO: Pod "downwardapi-volume-40688b34-3f9a-4531-be3e-4ae420a0d0b4": Phase="Pending", Reason="", readiness=false. Elapsed: 35.963085ms
Mar  2 09:25:03.032: INFO: Pod "downwardapi-volume-40688b34-3f9a-4531-be3e-4ae420a0d0b4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.043333522s
Mar  2 09:25:05.041: INFO: Pod "downwardapi-volume-40688b34-3f9a-4531-be3e-4ae420a0d0b4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.051982012s
STEP: Saw pod success
Mar  2 09:25:05.041: INFO: Pod "downwardapi-volume-40688b34-3f9a-4531-be3e-4ae420a0d0b4" satisfied condition "success or failure"
Mar  2 09:25:05.049: INFO: Trying to get logs from node worker1 pod downwardapi-volume-40688b34-3f9a-4531-be3e-4ae420a0d0b4 container client-container: <nil>
STEP: delete the pod
Mar  2 09:25:05.196: INFO: Waiting for pod downwardapi-volume-40688b34-3f9a-4531-be3e-4ae420a0d0b4 to disappear
Mar  2 09:25:05.203: INFO: Pod downwardapi-volume-40688b34-3f9a-4531-be3e-4ae420a0d0b4 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:25:05.203: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6398" for this suite.
Mar  2 09:25:13.273: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:25:13.608: INFO: namespace projected-6398 deletion completed in 8.394489485s

• [SLOW TEST:13.253 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] ResourceQuota 
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:25:13.608: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-883
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota
STEP: Getting a ResourceQuota
STEP: Updating a ResourceQuota
STEP: Verifying a ResourceQuota was modified
STEP: Deleting a ResourceQuota
STEP: Verifying the deleted ResourceQuota
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:25:14.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-883" for this suite.
Mar  2 09:25:22.945: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:25:23.334: INFO: namespace resourcequota-883 deletion completed in 8.531060217s

• [SLOW TEST:9.726 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with privileged 
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:25:23.335: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-5579
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  2 09:25:23.780: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-5698e3a7-181f-45af-bbe8-3ad09ba5e052" in namespace "security-context-test-5579" to be "success or failure"
Mar  2 09:25:24.268: INFO: Pod "busybox-privileged-false-5698e3a7-181f-45af-bbe8-3ad09ba5e052": Phase="Pending", Reason="", readiness=false. Elapsed: 488.407741ms
Mar  2 09:25:26.276: INFO: Pod "busybox-privileged-false-5698e3a7-181f-45af-bbe8-3ad09ba5e052": Phase="Pending", Reason="", readiness=false. Elapsed: 2.496624091s
Mar  2 09:25:28.283: INFO: Pod "busybox-privileged-false-5698e3a7-181f-45af-bbe8-3ad09ba5e052": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.502892627s
Mar  2 09:25:28.283: INFO: Pod "busybox-privileged-false-5698e3a7-181f-45af-bbe8-3ad09ba5e052" satisfied condition "success or failure"
Mar  2 09:25:28.332: INFO: Got logs for pod "busybox-privileged-false-5698e3a7-181f-45af-bbe8-3ad09ba5e052": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:25:28.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-5579" for this suite.
Mar  2 09:25:36.394: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:25:36.917: INFO: namespace security-context-test-5579 deletion completed in 8.574525175s

• [SLOW TEST:13.582 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a pod with privileged
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:226
    should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:25:36.917: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename crd-webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-webhook-468
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Mar  2 09:25:39.606: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718737939, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718737939, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718737939, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718737938, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-5bb99b877f\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  2 09:25:41.666: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718737939, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718737939, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718737939, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718737938, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-5bb99b877f\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar  2 09:25:44.675: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  2 09:25:44.683: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Creating a v1 custom resource
STEP: v2 custom resource should be converted
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:25:51.925: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-468" for this suite.
Mar  2 09:25:59.995: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:26:00.426: INFO: namespace crd-webhook-468 deletion completed in 8.492528681s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:23.586 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:26:00.504: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2048
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Mar  2 09:26:01.114: INFO: Waiting up to 5m0s for pod "pod-9a033cc5-5c67-4767-8382-288d26039923" in namespace "emptydir-2048" to be "success or failure"
Mar  2 09:26:01.129: INFO: Pod "pod-9a033cc5-5c67-4767-8382-288d26039923": Phase="Pending", Reason="", readiness=false. Elapsed: 14.910683ms
Mar  2 09:26:03.136: INFO: Pod "pod-9a033cc5-5c67-4767-8382-288d26039923": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021877004s
Mar  2 09:26:05.145: INFO: Pod "pod-9a033cc5-5c67-4767-8382-288d26039923": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030854499s
STEP: Saw pod success
Mar  2 09:26:05.145: INFO: Pod "pod-9a033cc5-5c67-4767-8382-288d26039923" satisfied condition "success or failure"
Mar  2 09:26:05.152: INFO: Trying to get logs from node worker1 pod pod-9a033cc5-5c67-4767-8382-288d26039923 container test-container: <nil>
STEP: delete the pod
Mar  2 09:26:05.415: INFO: Waiting for pod pod-9a033cc5-5c67-4767-8382-288d26039923 to disappear
Mar  2 09:26:05.423: INFO: Pod pod-9a033cc5-5c67-4767-8382-288d26039923 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:26:05.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2048" for this suite.
Mar  2 09:26:13.535: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:26:13.712: INFO: namespace emptydir-2048 deletion completed in 8.279934136s

• [SLOW TEST:13.208 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:26:13.713: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5404
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Mar  2 09:26:14.231: INFO: Waiting up to 5m0s for pod "downwardapi-volume-dd7dbe8b-26b0-4ce2-9eeb-e61eb3924634" in namespace "projected-5404" to be "success or failure"
Mar  2 09:26:14.285: INFO: Pod "downwardapi-volume-dd7dbe8b-26b0-4ce2-9eeb-e61eb3924634": Phase="Pending", Reason="", readiness=false. Elapsed: 54.365185ms
Mar  2 09:26:16.293: INFO: Pod "downwardapi-volume-dd7dbe8b-26b0-4ce2-9eeb-e61eb3924634": Phase="Pending", Reason="", readiness=false. Elapsed: 2.061857315s
Mar  2 09:26:18.733: INFO: Pod "downwardapi-volume-dd7dbe8b-26b0-4ce2-9eeb-e61eb3924634": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.501844813s
STEP: Saw pod success
Mar  2 09:26:18.733: INFO: Pod "downwardapi-volume-dd7dbe8b-26b0-4ce2-9eeb-e61eb3924634" satisfied condition "success or failure"
Mar  2 09:26:18.740: INFO: Trying to get logs from node worker1 pod downwardapi-volume-dd7dbe8b-26b0-4ce2-9eeb-e61eb3924634 container client-container: <nil>
STEP: delete the pod
Mar  2 09:26:19.076: INFO: Waiting for pod downwardapi-volume-dd7dbe8b-26b0-4ce2-9eeb-e61eb3924634 to disappear
Mar  2 09:26:19.092: INFO: Pod downwardapi-volume-dd7dbe8b-26b0-4ce2-9eeb-e61eb3924634 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:26:19.092: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5404" for this suite.
Mar  2 09:26:27.237: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:26:27.709: INFO: namespace projected-5404 deletion completed in 8.532432055s

• [SLOW TEST:13.996 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:26:27.710: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-5760
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Mar  2 09:26:32.513: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-956629573 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Mar  2 09:26:37.724: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:26:37.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5760" for this suite.
Mar  2 09:26:46.582: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:26:46.911: INFO: namespace pods-5760 deletion completed in 9.1144347s

• [SLOW TEST:19.201 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should be submitted and removed [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:26:46.911: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-9647
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-b084f7dc-7255-494e-8ed5-19c276e201bc in namespace container-probe-9647
Mar  2 09:26:51.565: INFO: Started pod liveness-b084f7dc-7255-494e-8ed5-19c276e201bc in namespace container-probe-9647
STEP: checking the pod's current state and verifying that restartCount is present
Mar  2 09:26:51.572: INFO: Initial restart count of pod liveness-b084f7dc-7255-494e-8ed5-19c276e201bc is 0
Mar  2 09:27:15.003: INFO: Restart count of pod container-probe-9647/liveness-b084f7dc-7255-494e-8ed5-19c276e201bc is now 1 (23.431607304s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:27:15.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9647" for this suite.
Mar  2 09:27:21.599: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:27:21.788: INFO: namespace container-probe-9647 deletion completed in 6.239330565s

• [SLOW TEST:34.876 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:27:21.788: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5883
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secret-namespace-9719
STEP: Creating secret with name secret-test-63e0ad10-d9c5-4707-b5dd-0888f7ca2b87
STEP: Creating a pod to test consume secrets
Mar  2 09:27:22.525: INFO: Waiting up to 5m0s for pod "pod-secrets-dbb2edae-776f-4ab3-97c7-587c292161f8" in namespace "secrets-5883" to be "success or failure"
Mar  2 09:27:22.547: INFO: Pod "pod-secrets-dbb2edae-776f-4ab3-97c7-587c292161f8": Phase="Pending", Reason="", readiness=false. Elapsed: 22.222629ms
Mar  2 09:27:24.555: INFO: Pod "pod-secrets-dbb2edae-776f-4ab3-97c7-587c292161f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030223235s
Mar  2 09:27:26.563: INFO: Pod "pod-secrets-dbb2edae-776f-4ab3-97c7-587c292161f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037906614s
STEP: Saw pod success
Mar  2 09:27:26.563: INFO: Pod "pod-secrets-dbb2edae-776f-4ab3-97c7-587c292161f8" satisfied condition "success or failure"
Mar  2 09:27:26.568: INFO: Trying to get logs from node worker1 pod pod-secrets-dbb2edae-776f-4ab3-97c7-587c292161f8 container secret-volume-test: <nil>
STEP: delete the pod
Mar  2 09:27:26.649: INFO: Waiting for pod pod-secrets-dbb2edae-776f-4ab3-97c7-587c292161f8 to disappear
Mar  2 09:27:26.655: INFO: Pod pod-secrets-dbb2edae-776f-4ab3-97c7-587c292161f8 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:27:26.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5883" for this suite.
Mar  2 09:27:32.745: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:27:32.979: INFO: namespace secrets-5883 deletion completed in 6.31485252s
STEP: Destroying namespace "secret-namespace-9719" for this suite.
Mar  2 09:27:39.017: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:27:39.201: INFO: namespace secret-namespace-9719 deletion completed in 6.221604382s

• [SLOW TEST:17.413 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:27:39.202: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-5688
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service nodeport-test with type=NodePort in namespace services-5688
STEP: creating replication controller nodeport-test in namespace services-5688
I0302 09:27:40.053489      24 runners.go:184] Created replication controller with name: nodeport-test, namespace: services-5688, replica count: 2
I0302 09:27:43.104221      24 runners.go:184] nodeport-test Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Mar  2 09:27:46.104: INFO: Creating new exec pod
I0302 09:27:46.104634      24 runners.go:184] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Mar  2 09:27:51.164: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 exec --namespace=services-5688 execpodjxw97 -- /bin/sh -x -c nc -zv -t -w 2 nodeport-test 80'
Mar  2 09:27:51.637: INFO: stderr: "+ nc -zv -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Mar  2 09:27:51.637: INFO: stdout: ""
Mar  2 09:27:51.638: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 exec --namespace=services-5688 execpodjxw97 -- /bin/sh -x -c nc -zv -t -w 2 10.106.3.33 80'
Mar  2 09:27:52.153: INFO: stderr: "+ nc -zv -t -w 2 10.106.3.33 80\nConnection to 10.106.3.33 80 port [tcp/http] succeeded!\n"
Mar  2 09:27:52.154: INFO: stdout: ""
Mar  2 09:27:52.154: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 exec --namespace=services-5688 execpodjxw97 -- /bin/sh -x -c nc -zv -t -w 2 172.20.8.5 30260'
Mar  2 09:27:52.593: INFO: stderr: "+ nc -zv -t -w 2 172.20.8.5 30260\nConnection to 172.20.8.5 30260 port [tcp/30260] succeeded!\n"
Mar  2 09:27:52.593: INFO: stdout: ""
Mar  2 09:27:52.593: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 exec --namespace=services-5688 execpodjxw97 -- /bin/sh -x -c nc -zv -t -w 2 172.20.8.6 30260'
Mar  2 09:27:53.047: INFO: stderr: "+ nc -zv -t -w 2 172.20.8.6 30260\nConnection to 172.20.8.6 30260 port [tcp/30260] succeeded!\n"
Mar  2 09:27:53.047: INFO: stdout: ""
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:27:53.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5688" for this suite.
Mar  2 09:28:01.302: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:28:01.485: INFO: namespace services-5688 deletion completed in 8.354421006s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:22.284 seconds]
[sig-network] Services
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:28:01.486: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4186
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Mar  2 09:28:01.884: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6bbeb11d-ed21-466f-9baf-9dbb1b48865c" in namespace "downward-api-4186" to be "success or failure"
Mar  2 09:28:01.940: INFO: Pod "downwardapi-volume-6bbeb11d-ed21-466f-9baf-9dbb1b48865c": Phase="Pending", Reason="", readiness=false. Elapsed: 55.241621ms
Mar  2 09:28:03.971: INFO: Pod "downwardapi-volume-6bbeb11d-ed21-466f-9baf-9dbb1b48865c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.086520385s
Mar  2 09:28:05.980: INFO: Pod "downwardapi-volume-6bbeb11d-ed21-466f-9baf-9dbb1b48865c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.095478964s
STEP: Saw pod success
Mar  2 09:28:05.980: INFO: Pod "downwardapi-volume-6bbeb11d-ed21-466f-9baf-9dbb1b48865c" satisfied condition "success or failure"
Mar  2 09:28:05.987: INFO: Trying to get logs from node worker1 pod downwardapi-volume-6bbeb11d-ed21-466f-9baf-9dbb1b48865c container client-container: <nil>
STEP: delete the pod
Mar  2 09:28:06.086: INFO: Waiting for pod downwardapi-volume-6bbeb11d-ed21-466f-9baf-9dbb1b48865c to disappear
Mar  2 09:28:06.094: INFO: Pod downwardapi-volume-6bbeb11d-ed21-466f-9baf-9dbb1b48865c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:28:06.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4186" for this suite.
Mar  2 09:28:12.133: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:28:12.535: INFO: namespace downward-api-4186 deletion completed in 6.432300268s

• [SLOW TEST:11.049 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:28:12.535: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-9838
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  2 09:28:13.015: INFO: Create a RollingUpdate DaemonSet
Mar  2 09:28:13.050: INFO: Check that daemon pods launch on every node of the cluster
Mar  2 09:28:13.061: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:28:13.061: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:28:13.061: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:28:13.086: INFO: Number of nodes with available pods: 0
Mar  2 09:28:13.086: INFO: Node worker1 is running more than one daemon pod
Mar  2 09:28:14.096: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:28:14.096: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:28:14.096: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:28:14.101: INFO: Number of nodes with available pods: 0
Mar  2 09:28:14.101: INFO: Node worker1 is running more than one daemon pod
Mar  2 09:28:15.108: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:28:15.108: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:28:15.108: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:28:15.117: INFO: Number of nodes with available pods: 0
Mar  2 09:28:15.117: INFO: Node worker1 is running more than one daemon pod
Mar  2 09:28:16.126: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:28:16.126: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:28:16.126: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:28:16.133: INFO: Number of nodes with available pods: 1
Mar  2 09:28:16.133: INFO: Node worker2 is running more than one daemon pod
Mar  2 09:28:17.095: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:28:17.095: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:28:17.095: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:28:17.102: INFO: Number of nodes with available pods: 2
Mar  2 09:28:17.102: INFO: Number of running nodes: 2, number of available pods: 2
Mar  2 09:28:17.102: INFO: Update the DaemonSet to trigger a rollout
Mar  2 09:28:17.157: INFO: Updating DaemonSet daemon-set
Mar  2 09:28:23.234: INFO: Roll back the DaemonSet before rollout is complete
Mar  2 09:28:23.277: INFO: Updating DaemonSet daemon-set
Mar  2 09:28:23.277: INFO: Make sure DaemonSet rollback is complete
Mar  2 09:28:23.284: INFO: Wrong image for pod: daemon-set-pkrjg. Expected: 172.20.8.7/library/httpd:2.4.38-alpine, got: foo:non-existent.
Mar  2 09:28:23.284: INFO: Pod daemon-set-pkrjg is not available
Mar  2 09:28:23.368: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:28:23.368: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:28:23.368: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:28:24.377: INFO: Wrong image for pod: daemon-set-pkrjg. Expected: 172.20.8.7/library/httpd:2.4.38-alpine, got: foo:non-existent.
Mar  2 09:28:24.377: INFO: Pod daemon-set-pkrjg is not available
Mar  2 09:28:24.387: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:28:24.387: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:28:24.387: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:28:25.377: INFO: Wrong image for pod: daemon-set-pkrjg. Expected: 172.20.8.7/library/httpd:2.4.38-alpine, got: foo:non-existent.
Mar  2 09:28:25.377: INFO: Pod daemon-set-pkrjg is not available
Mar  2 09:28:25.387: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:28:25.387: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:28:25.387: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:28:26.376: INFO: Wrong image for pod: daemon-set-pkrjg. Expected: 172.20.8.7/library/httpd:2.4.38-alpine, got: foo:non-existent.
Mar  2 09:28:26.376: INFO: Pod daemon-set-pkrjg is not available
Mar  2 09:28:26.386: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:28:26.386: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:28:26.386: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:28:27.399: INFO: Wrong image for pod: daemon-set-pkrjg. Expected: 172.20.8.7/library/httpd:2.4.38-alpine, got: foo:non-existent.
Mar  2 09:28:27.399: INFO: Pod daemon-set-pkrjg is not available
Mar  2 09:28:27.408: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:28:27.408: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:28:27.408: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:28:28.378: INFO: Wrong image for pod: daemon-set-pkrjg. Expected: 172.20.8.7/library/httpd:2.4.38-alpine, got: foo:non-existent.
Mar  2 09:28:28.378: INFO: Pod daemon-set-pkrjg is not available
Mar  2 09:28:28.387: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:28:28.387: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:28:28.388: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:28:29.377: INFO: Wrong image for pod: daemon-set-pkrjg. Expected: 172.20.8.7/library/httpd:2.4.38-alpine, got: foo:non-existent.
Mar  2 09:28:29.377: INFO: Pod daemon-set-pkrjg is not available
Mar  2 09:28:29.387: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:28:29.387: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:28:29.387: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:28:30.379: INFO: Wrong image for pod: daemon-set-pkrjg. Expected: 172.20.8.7/library/httpd:2.4.38-alpine, got: foo:non-existent.
Mar  2 09:28:30.379: INFO: Pod daemon-set-pkrjg is not available
Mar  2 09:28:30.389: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:28:30.389: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:28:30.389: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:28:31.377: INFO: Wrong image for pod: daemon-set-pkrjg. Expected: 172.20.8.7/library/httpd:2.4.38-alpine, got: foo:non-existent.
Mar  2 09:28:31.377: INFO: Pod daemon-set-pkrjg is not available
Mar  2 09:28:31.388: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:28:31.388: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:28:31.388: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:28:32.376: INFO: Wrong image for pod: daemon-set-pkrjg. Expected: 172.20.8.7/library/httpd:2.4.38-alpine, got: foo:non-existent.
Mar  2 09:28:32.376: INFO: Pod daemon-set-pkrjg is not available
Mar  2 09:28:32.386: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:28:32.386: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:28:32.386: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:28:33.377: INFO: Pod daemon-set-fp4b2 is not available
Mar  2 09:28:33.386: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:28:33.386: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 09:28:33.386: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9838, will wait for the garbage collector to delete the pods
Mar  2 09:28:33.576: INFO: Deleting DaemonSet.extensions daemon-set took: 119.987516ms
Mar  2 09:28:34.176: INFO: Terminating DaemonSet.extensions daemon-set pods took: 600.423981ms
Mar  2 09:28:37.783: INFO: Number of nodes with available pods: 0
Mar  2 09:28:37.783: INFO: Number of running nodes: 0, number of available pods: 0
Mar  2 09:28:37.789: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9838/daemonsets","resourceVersion":"81723"},"items":null}

Mar  2 09:28:37.796: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9838/pods","resourceVersion":"81723"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:28:37.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9838" for this suite.
Mar  2 09:28:45.878: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:28:46.128: INFO: namespace daemonsets-9838 deletion completed in 8.303301224s

• [SLOW TEST:33.593 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:28:46.128: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-2007
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-3413
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-9571
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:28:54.311: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-2007" for this suite.
Mar  2 09:29:00.376: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:29:00.554: INFO: namespace namespaces-2007 deletion completed in 6.233908232s
STEP: Destroying namespace "nsdeletetest-3413" for this suite.
Mar  2 09:29:00.561: INFO: Namespace nsdeletetest-3413 was already deleted
STEP: Destroying namespace "nsdeletetest-9571" for this suite.
Mar  2 09:29:06.643: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:29:06.878: INFO: namespace nsdeletetest-9571 deletion completed in 6.317461531s

• [SLOW TEST:20.750 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:29:06.879: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-6538
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Mar  2 09:29:07.305: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar  2 09:29:07.334: INFO: Waiting for terminating namespaces to be deleted...
Mar  2 09:29:07.340: INFO: 
Logging pods the kubelet thinks is on node worker1 before test
Mar  2 09:29:07.356: INFO: envoy-hwmt2 from projectcontour started at 2020-03-02 02:43:15 +0000 UTC (1 container statuses recorded)
Mar  2 09:29:07.356: INFO: 	Container envoy ready: false, restart count 0
Mar  2 09:29:07.356: INFO: kube-flannel-ds-amd64-hmpfw from kube-system started at 2020-03-02 03:03:50 +0000 UTC (1 container statuses recorded)
Mar  2 09:29:07.356: INFO: 	Container kube-flannel ready: true, restart count 0
Mar  2 09:29:07.356: INFO: kube-proxy-bnv2b from kube-system started at 2020-03-02 03:03:07 +0000 UTC (1 container statuses recorded)
Mar  2 09:29:07.356: INFO: 	Container kube-proxy ready: true, restart count 0
Mar  2 09:29:07.356: INFO: sonobuoy from sonobuoy started at 2020-03-02 09:09:31 +0000 UTC (1 container statuses recorded)
Mar  2 09:29:07.356: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Mar  2 09:29:07.356: INFO: sonobuoy-e2e-job-6f4cd8785f284b6e from sonobuoy started at 2020-03-02 09:09:33 +0000 UTC (2 container statuses recorded)
Mar  2 09:29:07.356: INFO: 	Container e2e ready: true, restart count 0
Mar  2 09:29:07.356: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar  2 09:29:07.356: INFO: sonobuoy-systemd-logs-daemon-set-003190d3042d4113-rtkgw from sonobuoy started at 2020-03-02 09:09:34 +0000 UTC (2 container statuses recorded)
Mar  2 09:29:07.356: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar  2 09:29:07.356: INFO: 	Container systemd-logs ready: true, restart count 0
Mar  2 09:29:07.356: INFO: 
Logging pods the kubelet thinks is on node worker2 before test
Mar  2 09:29:07.404: INFO: contour-7594d96455-vcdf6 from projectcontour started at 2020-03-02 02:40:59 +0000 UTC (1 container statuses recorded)
Mar  2 09:29:07.404: INFO: 	Container contour ready: false, restart count 0
Mar  2 09:29:07.404: INFO: contour-certgen-bh5fh from projectcontour started at 2020-03-02 02:40:59 +0000 UTC (1 container statuses recorded)
Mar  2 09:29:07.404: INFO: 	Container contour ready: false, restart count 0
Mar  2 09:29:07.404: INFO: kuard-85c85bcf66-qv4qm from default started at 2020-03-02 02:41:50 +0000 UTC (1 container statuses recorded)
Mar  2 09:29:07.405: INFO: 	Container kuard ready: true, restart count 0
Mar  2 09:29:07.405: INFO: sonobuoy-systemd-logs-daemon-set-003190d3042d4113-4dn5h from sonobuoy started at 2020-03-02 09:09:34 +0000 UTC (2 container statuses recorded)
Mar  2 09:29:07.405: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar  2 09:29:07.405: INFO: 	Container systemd-logs ready: true, restart count 0
Mar  2 09:29:07.405: INFO: kube-proxy-77czp from kube-system started at 2020-03-02 03:03:11 +0000 UTC (1 container statuses recorded)
Mar  2 09:29:07.405: INFO: 	Container kube-proxy ready: true, restart count 0
Mar  2 09:29:07.405: INFO: kuard-85c85bcf66-6dv5z from default started at 2020-03-02 02:41:51 +0000 UTC (1 container statuses recorded)
Mar  2 09:29:07.405: INFO: 	Container kuard ready: true, restart count 0
Mar  2 09:29:07.405: INFO: contour-7594d96455-sm4qm from projectcontour started at 2020-03-02 02:40:59 +0000 UTC (1 container statuses recorded)
Mar  2 09:29:07.405: INFO: 	Container contour ready: false, restart count 0
Mar  2 09:29:07.405: INFO: kube-flannel-ds-amd64-6l2th from kube-system started at 2020-03-02 03:04:01 +0000 UTC (1 container statuses recorded)
Mar  2 09:29:07.405: INFO: 	Container kube-flannel ready: true, restart count 0
Mar  2 09:29:07.405: INFO: metrics-server-557c6b848b-k8ssl from kube-system started at 2020-03-02 02:41:51 +0000 UTC (1 container statuses recorded)
Mar  2 09:29:07.405: INFO: 	Container metrics-server ready: true, restart count 0
Mar  2 09:29:07.405: INFO: envoy-l4k6z from projectcontour started at 2020-03-02 02:40:59 +0000 UTC (1 container statuses recorded)
Mar  2 09:29:07.405: INFO: 	Container envoy ready: false, restart count 0
Mar  2 09:29:07.405: INFO: kuard-85c85bcf66-lf9xs from default started at 2020-03-02 02:41:49 +0000 UTC (1 container statuses recorded)
Mar  2 09:29:07.405: INFO: 	Container kuard ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-14e92950-b9ba-469d-8096-0f565777abcb 95
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 127.0.0.1 on the node which pod4 resides and expect not scheduled
STEP: removing the label kubernetes.io/e2e-14e92950-b9ba-469d-8096-0f565777abcb off the node worker1
STEP: verifying the node doesn't have the label kubernetes.io/e2e-14e92950-b9ba-469d-8096-0f565777abcb
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:34:15.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-6538" for this suite.
Mar  2 09:34:36.122: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:34:36.319: INFO: namespace sched-pred-6538 deletion completed in 20.279814851s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:329.440 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context when creating containers with AllowPrivilegeEscalation 
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:34:36.320: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-4928
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  2 09:34:36.695: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-e1347d78-68cc-4c68-be12-e34dab1e5427" in namespace "security-context-test-4928" to be "success or failure"
Mar  2 09:34:36.709: INFO: Pod "alpine-nnp-false-e1347d78-68cc-4c68-be12-e34dab1e5427": Phase="Pending", Reason="", readiness=false. Elapsed: 14.062284ms
Mar  2 09:34:38.716: INFO: Pod "alpine-nnp-false-e1347d78-68cc-4c68-be12-e34dab1e5427": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020814582s
Mar  2 09:34:40.723: INFO: Pod "alpine-nnp-false-e1347d78-68cc-4c68-be12-e34dab1e5427": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02845284s
Mar  2 09:34:40.723: INFO: Pod "alpine-nnp-false-e1347d78-68cc-4c68-be12-e34dab1e5427" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:34:40.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-4928" for this suite.
Mar  2 09:34:49.064: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:34:49.390: INFO: namespace security-context-test-4928 deletion completed in 8.594357747s

• [SLOW TEST:13.070 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when creating containers with AllowPrivilegeEscalation
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:277
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:34:49.391: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-8813
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:34:53.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-8813" for this suite.
Mar  2 09:35:43.893: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:35:44.059: INFO: namespace kubelet-test-8813 deletion completed in 50.227891281s

• [SLOW TEST:54.668 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command in a pod
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:35:44.059: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-9965
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:35:48.873: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-9965" for this suite.
Mar  2 09:35:57.045: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:35:57.358: INFO: namespace emptydir-wrapper-9965 deletion completed in 8.398210212s

• [SLOW TEST:13.299 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not conflict [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:35:57.359: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-9722
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring job reaches completions
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:36:07.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-9722" for this suite.
Mar  2 09:36:15.991: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:36:16.213: INFO: namespace job-9722 deletion completed in 8.286172798s

• [SLOW TEST:18.854 seconds]
[sig-apps] Job
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:36:16.213: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-7142
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  2 09:36:16.611: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Mar  2 09:36:26.660: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 --namespace=crd-publish-openapi-7142 create -f -'
Mar  2 09:36:29.426: INFO: stderr: ""
Mar  2 09:36:29.426: INFO: stdout: "e2e-test-crd-publish-openapi-4967-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Mar  2 09:36:29.426: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 --namespace=crd-publish-openapi-7142 delete e2e-test-crd-publish-openapi-4967-crds test-cr'
Mar  2 09:36:29.702: INFO: stderr: ""
Mar  2 09:36:29.702: INFO: stdout: "e2e-test-crd-publish-openapi-4967-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Mar  2 09:36:29.702: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 --namespace=crd-publish-openapi-7142 apply -f -'
Mar  2 09:36:30.555: INFO: stderr: ""
Mar  2 09:36:30.555: INFO: stdout: "e2e-test-crd-publish-openapi-4967-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Mar  2 09:36:30.555: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 --namespace=crd-publish-openapi-7142 delete e2e-test-crd-publish-openapi-4967-crds test-cr'
Mar  2 09:36:30.844: INFO: stderr: ""
Mar  2 09:36:30.844: INFO: stdout: "e2e-test-crd-publish-openapi-4967-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema
Mar  2 09:36:30.845: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 explain e2e-test-crd-publish-openapi-4967-crds'
Mar  2 09:36:31.934: INFO: stderr: ""
Mar  2 09:36:31.934: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-4967-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:36:36.902: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7142" for this suite.
Mar  2 09:36:42.994: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:36:43.336: INFO: namespace crd-publish-openapi-7142 deletion completed in 6.423584835s

• [SLOW TEST:27.122 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:36:43.336: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-9858
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service endpoint-test2 in namespace services-9858
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9858 to expose endpoints map[]
Mar  2 09:36:43.911: INFO: successfully validated that service endpoint-test2 in namespace services-9858 exposes endpoints map[] (115.287553ms elapsed)
STEP: Creating pod pod1 in namespace services-9858
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9858 to expose endpoints map[pod1:[80]]
Mar  2 09:36:47.290: INFO: successfully validated that service endpoint-test2 in namespace services-9858 exposes endpoints map[pod1:[80]] (3.174085179s elapsed)
STEP: Creating pod pod2 in namespace services-9858
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9858 to expose endpoints map[pod1:[80] pod2:[80]]
Mar  2 09:36:51.675: INFO: Unexpected endpoints: found map[967ca975-75ca-48ce-baab-0d34671ef70f:[80]], expected map[pod1:[80] pod2:[80]] (4.367324834s elapsed, will retry)
Mar  2 09:36:52.693: INFO: successfully validated that service endpoint-test2 in namespace services-9858 exposes endpoints map[pod1:[80] pod2:[80]] (5.384852911s elapsed)
STEP: Deleting pod pod1 in namespace services-9858
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9858 to expose endpoints map[pod2:[80]]
Mar  2 09:36:53.959: INFO: successfully validated that service endpoint-test2 in namespace services-9858 exposes endpoints map[pod2:[80]] (1.209705399s elapsed)
STEP: Deleting pod pod2 in namespace services-9858
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9858 to expose endpoints map[]
Mar  2 09:36:55.003: INFO: successfully validated that service endpoint-test2 in namespace services-9858 exposes endpoints map[] (1.012821664s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:36:55.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9858" for this suite.
Mar  2 09:37:03.318: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:37:03.502: INFO: namespace services-9858 deletion completed in 8.239456767s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:20.166 seconds]
[sig-network] Services
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:37:03.503: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-2938
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override all
Mar  2 09:37:03.845: INFO: Waiting up to 5m0s for pod "client-containers-aa616974-7cef-4e17-b41d-77497db9d4d6" in namespace "containers-2938" to be "success or failure"
Mar  2 09:37:03.852: INFO: Pod "client-containers-aa616974-7cef-4e17-b41d-77497db9d4d6": Phase="Pending", Reason="", readiness=false. Elapsed: 6.448994ms
Mar  2 09:37:05.860: INFO: Pod "client-containers-aa616974-7cef-4e17-b41d-77497db9d4d6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014779088s
Mar  2 09:37:07.867: INFO: Pod "client-containers-aa616974-7cef-4e17-b41d-77497db9d4d6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021978369s
STEP: Saw pod success
Mar  2 09:37:07.867: INFO: Pod "client-containers-aa616974-7cef-4e17-b41d-77497db9d4d6" satisfied condition "success or failure"
Mar  2 09:37:07.872: INFO: Trying to get logs from node worker1 pod client-containers-aa616974-7cef-4e17-b41d-77497db9d4d6 container test-container: <nil>
STEP: delete the pod
Mar  2 09:37:08.011: INFO: Waiting for pod client-containers-aa616974-7cef-4e17-b41d-77497db9d4d6 to disappear
Mar  2 09:37:08.025: INFO: Pod client-containers-aa616974-7cef-4e17-b41d-77497db9d4d6 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:37:08.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-2938" for this suite.
Mar  2 09:37:16.115: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:37:16.293: INFO: namespace containers-2938 deletion completed in 8.259448455s

• [SLOW TEST:12.791 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:37:16.294: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-2222
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-2222
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar  2 09:37:16.738: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar  2 09:37:43.262: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.4.181:8080/dial?request=hostName&protocol=http&host=10.244.4.180&port=8080&tries=1'] Namespace:pod-network-test-2222 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  2 09:37:43.262: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
Mar  2 09:37:43.534: INFO: Waiting for endpoints: map[]
Mar  2 09:37:43.544: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.4.181:8080/dial?request=hostName&protocol=http&host=10.244.3.139&port=8080&tries=1'] Namespace:pod-network-test-2222 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  2 09:37:43.544: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
Mar  2 09:37:43.816: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:37:43.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-2222" for this suite.
Mar  2 09:37:57.913: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:37:58.183: INFO: namespace pod-network-test-2222 deletion completed in 14.356731815s

• [SLOW TEST:41.889 seconds]
[sig-network] Networking
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:37:58.184: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-219
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-3769c59e-8bec-4d71-b312-9089b5d71047
STEP: Creating a pod to test consume secrets
Mar  2 09:37:58.665: INFO: Waiting up to 5m0s for pod "pod-secrets-22b90cf7-6365-4399-9a63-d9869096898e" in namespace "secrets-219" to be "success or failure"
Mar  2 09:37:58.671: INFO: Pod "pod-secrets-22b90cf7-6365-4399-9a63-d9869096898e": Phase="Pending", Reason="", readiness=false. Elapsed: 5.719403ms
Mar  2 09:38:00.705: INFO: Pod "pod-secrets-22b90cf7-6365-4399-9a63-d9869096898e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040495808s
Mar  2 09:38:02.730: INFO: Pod "pod-secrets-22b90cf7-6365-4399-9a63-d9869096898e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.064898838s
STEP: Saw pod success
Mar  2 09:38:02.730: INFO: Pod "pod-secrets-22b90cf7-6365-4399-9a63-d9869096898e" satisfied condition "success or failure"
Mar  2 09:38:02.736: INFO: Trying to get logs from node worker1 pod pod-secrets-22b90cf7-6365-4399-9a63-d9869096898e container secret-volume-test: <nil>
STEP: delete the pod
Mar  2 09:38:02.923: INFO: Waiting for pod pod-secrets-22b90cf7-6365-4399-9a63-d9869096898e to disappear
Mar  2 09:38:02.929: INFO: Pod pod-secrets-22b90cf7-6365-4399-9a63-d9869096898e no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:38:02.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-219" for this suite.
Mar  2 09:38:11.119: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:38:11.403: INFO: namespace secrets-219 deletion completed in 8.403621467s

• [SLOW TEST:13.219 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:38:11.403: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-9645
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-52bba965-f5b6-488d-9877-d1e6c39bc7e7
STEP: Creating a pod to test consume secrets
Mar  2 09:38:11.891: INFO: Waiting up to 5m0s for pod "pod-secrets-4801884d-8b06-48ca-b245-b94d0f5449ae" in namespace "secrets-9645" to be "success or failure"
Mar  2 09:38:11.906: INFO: Pod "pod-secrets-4801884d-8b06-48ca-b245-b94d0f5449ae": Phase="Pending", Reason="", readiness=false. Elapsed: 14.940773ms
Mar  2 09:38:13.913: INFO: Pod "pod-secrets-4801884d-8b06-48ca-b245-b94d0f5449ae": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022475918s
Mar  2 09:38:15.921: INFO: Pod "pod-secrets-4801884d-8b06-48ca-b245-b94d0f5449ae": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030541768s
STEP: Saw pod success
Mar  2 09:38:15.922: INFO: Pod "pod-secrets-4801884d-8b06-48ca-b245-b94d0f5449ae" satisfied condition "success or failure"
Mar  2 09:38:15.927: INFO: Trying to get logs from node worker1 pod pod-secrets-4801884d-8b06-48ca-b245-b94d0f5449ae container secret-volume-test: <nil>
STEP: delete the pod
Mar  2 09:38:16.010: INFO: Waiting for pod pod-secrets-4801884d-8b06-48ca-b245-b94d0f5449ae to disappear
Mar  2 09:38:16.034: INFO: Pod pod-secrets-4801884d-8b06-48ca-b245-b94d0f5449ae no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:38:16.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9645" for this suite.
Mar  2 09:38:24.131: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:38:24.486: INFO: namespace secrets-9645 deletion completed in 8.43371392s

• [SLOW TEST:13.083 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:38:24.487: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9293
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-b7afb3df-c8a2-4a21-9885-4bbc94a864e2
STEP: Creating a pod to test consume configMaps
Mar  2 09:38:25.145: INFO: Waiting up to 5m0s for pod "pod-configmaps-857530f1-1c97-45d4-9597-0bd2ff2788ed" in namespace "configmap-9293" to be "success or failure"
Mar  2 09:38:25.181: INFO: Pod "pod-configmaps-857530f1-1c97-45d4-9597-0bd2ff2788ed": Phase="Pending", Reason="", readiness=false. Elapsed: 36.123585ms
Mar  2 09:38:27.251: INFO: Pod "pod-configmaps-857530f1-1c97-45d4-9597-0bd2ff2788ed": Phase="Pending", Reason="", readiness=false. Elapsed: 2.106586889s
Mar  2 09:38:29.258: INFO: Pod "pod-configmaps-857530f1-1c97-45d4-9597-0bd2ff2788ed": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.113150399s
STEP: Saw pod success
Mar  2 09:38:29.258: INFO: Pod "pod-configmaps-857530f1-1c97-45d4-9597-0bd2ff2788ed" satisfied condition "success or failure"
Mar  2 09:38:29.263: INFO: Trying to get logs from node worker1 pod pod-configmaps-857530f1-1c97-45d4-9597-0bd2ff2788ed container configmap-volume-test: <nil>
STEP: delete the pod
Mar  2 09:38:29.343: INFO: Waiting for pod pod-configmaps-857530f1-1c97-45d4-9597-0bd2ff2788ed to disappear
Mar  2 09:38:29.370: INFO: Pod pod-configmaps-857530f1-1c97-45d4-9597-0bd2ff2788ed no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:38:29.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9293" for this suite.
Mar  2 09:38:37.439: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:38:37.724: INFO: namespace configmap-9293 deletion completed in 8.344681071s

• [SLOW TEST:13.237 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:38:37.725: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-16
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Mar  2 09:38:38.203: INFO: Waiting up to 5m0s for pod "pod-6ed5b7a1-9f26-4e26-a45d-21b60e9d6b58" in namespace "emptydir-16" to be "success or failure"
Mar  2 09:38:38.411: INFO: Pod "pod-6ed5b7a1-9f26-4e26-a45d-21b60e9d6b58": Phase="Pending", Reason="", readiness=false. Elapsed: 207.815569ms
Mar  2 09:38:40.418: INFO: Pod "pod-6ed5b7a1-9f26-4e26-a45d-21b60e9d6b58": Phase="Pending", Reason="", readiness=false. Elapsed: 2.215001967s
Mar  2 09:38:42.426: INFO: Pod "pod-6ed5b7a1-9f26-4e26-a45d-21b60e9d6b58": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.223010957s
STEP: Saw pod success
Mar  2 09:38:42.426: INFO: Pod "pod-6ed5b7a1-9f26-4e26-a45d-21b60e9d6b58" satisfied condition "success or failure"
Mar  2 09:38:42.434: INFO: Trying to get logs from node worker1 pod pod-6ed5b7a1-9f26-4e26-a45d-21b60e9d6b58 container test-container: <nil>
STEP: delete the pod
Mar  2 09:38:42.702: INFO: Waiting for pod pod-6ed5b7a1-9f26-4e26-a45d-21b60e9d6b58 to disappear
Mar  2 09:38:42.731: INFO: Pod pod-6ed5b7a1-9f26-4e26-a45d-21b60e9d6b58 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:38:42.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-16" for this suite.
Mar  2 09:38:50.881: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:38:51.060: INFO: namespace emptydir-16 deletion completed in 8.289228772s

• [SLOW TEST:13.335 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:38:51.061: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-4670
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4670.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-4670.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4670.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-4670.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar  2 09:38:55.573: INFO: DNS probes using dns-test-fd927cd4-a66d-4ab4-a203-0f27adb6a1c1 succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4670.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-4670.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4670.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-4670.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar  2 09:39:00.358: INFO: File wheezy_udp@dns-test-service-3.dns-4670.svc.cluster.local from pod  dns-4670/dns-test-559383ef-d8ec-4443-bd81-e395d6c98164 contains 'foo.example.com.
' instead of 'bar.example.com.'
Mar  2 09:39:00.368: INFO: File jessie_udp@dns-test-service-3.dns-4670.svc.cluster.local from pod  dns-4670/dns-test-559383ef-d8ec-4443-bd81-e395d6c98164 contains 'foo.example.com.
' instead of 'bar.example.com.'
Mar  2 09:39:00.368: INFO: Lookups using dns-4670/dns-test-559383ef-d8ec-4443-bd81-e395d6c98164 failed for: [wheezy_udp@dns-test-service-3.dns-4670.svc.cluster.local jessie_udp@dns-test-service-3.dns-4670.svc.cluster.local]

Mar  2 09:39:05.377: INFO: File wheezy_udp@dns-test-service-3.dns-4670.svc.cluster.local from pod  dns-4670/dns-test-559383ef-d8ec-4443-bd81-e395d6c98164 contains 'foo.example.com.
' instead of 'bar.example.com.'
Mar  2 09:39:05.384: INFO: File jessie_udp@dns-test-service-3.dns-4670.svc.cluster.local from pod  dns-4670/dns-test-559383ef-d8ec-4443-bd81-e395d6c98164 contains 'foo.example.com.
' instead of 'bar.example.com.'
Mar  2 09:39:05.384: INFO: Lookups using dns-4670/dns-test-559383ef-d8ec-4443-bd81-e395d6c98164 failed for: [wheezy_udp@dns-test-service-3.dns-4670.svc.cluster.local jessie_udp@dns-test-service-3.dns-4670.svc.cluster.local]

Mar  2 09:39:10.412: INFO: File wheezy_udp@dns-test-service-3.dns-4670.svc.cluster.local from pod  dns-4670/dns-test-559383ef-d8ec-4443-bd81-e395d6c98164 contains 'foo.example.com.
' instead of 'bar.example.com.'
Mar  2 09:39:10.419: INFO: File jessie_udp@dns-test-service-3.dns-4670.svc.cluster.local from pod  dns-4670/dns-test-559383ef-d8ec-4443-bd81-e395d6c98164 contains 'foo.example.com.
' instead of 'bar.example.com.'
Mar  2 09:39:10.419: INFO: Lookups using dns-4670/dns-test-559383ef-d8ec-4443-bd81-e395d6c98164 failed for: [wheezy_udp@dns-test-service-3.dns-4670.svc.cluster.local jessie_udp@dns-test-service-3.dns-4670.svc.cluster.local]

Mar  2 09:39:15.377: INFO: File wheezy_udp@dns-test-service-3.dns-4670.svc.cluster.local from pod  dns-4670/dns-test-559383ef-d8ec-4443-bd81-e395d6c98164 contains 'foo.example.com.
' instead of 'bar.example.com.'
Mar  2 09:39:15.386: INFO: File jessie_udp@dns-test-service-3.dns-4670.svc.cluster.local from pod  dns-4670/dns-test-559383ef-d8ec-4443-bd81-e395d6c98164 contains 'foo.example.com.
' instead of 'bar.example.com.'
Mar  2 09:39:15.386: INFO: Lookups using dns-4670/dns-test-559383ef-d8ec-4443-bd81-e395d6c98164 failed for: [wheezy_udp@dns-test-service-3.dns-4670.svc.cluster.local jessie_udp@dns-test-service-3.dns-4670.svc.cluster.local]

Mar  2 09:39:20.377: INFO: File wheezy_udp@dns-test-service-3.dns-4670.svc.cluster.local from pod  dns-4670/dns-test-559383ef-d8ec-4443-bd81-e395d6c98164 contains 'foo.example.com.
' instead of 'bar.example.com.'
Mar  2 09:39:20.385: INFO: File jessie_udp@dns-test-service-3.dns-4670.svc.cluster.local from pod  dns-4670/dns-test-559383ef-d8ec-4443-bd81-e395d6c98164 contains 'foo.example.com.
' instead of 'bar.example.com.'
Mar  2 09:39:20.385: INFO: Lookups using dns-4670/dns-test-559383ef-d8ec-4443-bd81-e395d6c98164 failed for: [wheezy_udp@dns-test-service-3.dns-4670.svc.cluster.local jessie_udp@dns-test-service-3.dns-4670.svc.cluster.local]

Mar  2 09:39:25.383: INFO: DNS probes using dns-test-559383ef-d8ec-4443-bd81-e395d6c98164 succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4670.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-4670.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-4670.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-4670.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar  2 09:39:32.030: INFO: DNS probes using dns-test-2fb6a4e1-94e5-4997-8483-2d5905d3fc20 succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:39:32.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4670" for this suite.
Mar  2 09:39:42.626: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:39:42.877: INFO: namespace dns-4670 deletion completed in 10.446693985s

• [SLOW TEST:51.816 seconds]
[sig-network] DNS
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:39:42.877: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7383
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Mar  2 09:39:43.345: INFO: Waiting up to 5m0s for pod "downwardapi-volume-be8eb77b-13c9-45a5-9c3d-227fead7001e" in namespace "downward-api-7383" to be "success or failure"
Mar  2 09:39:43.419: INFO: Pod "downwardapi-volume-be8eb77b-13c9-45a5-9c3d-227fead7001e": Phase="Pending", Reason="", readiness=false. Elapsed: 73.746988ms
Mar  2 09:39:45.428: INFO: Pod "downwardapi-volume-be8eb77b-13c9-45a5-9c3d-227fead7001e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.082275069s
Mar  2 09:39:47.435: INFO: Pod "downwardapi-volume-be8eb77b-13c9-45a5-9c3d-227fead7001e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.089790533s
STEP: Saw pod success
Mar  2 09:39:47.435: INFO: Pod "downwardapi-volume-be8eb77b-13c9-45a5-9c3d-227fead7001e" satisfied condition "success or failure"
Mar  2 09:39:47.442: INFO: Trying to get logs from node worker1 pod downwardapi-volume-be8eb77b-13c9-45a5-9c3d-227fead7001e container client-container: <nil>
STEP: delete the pod
Mar  2 09:39:47.520: INFO: Waiting for pod downwardapi-volume-be8eb77b-13c9-45a5-9c3d-227fead7001e to disappear
Mar  2 09:39:47.589: INFO: Pod downwardapi-volume-be8eb77b-13c9-45a5-9c3d-227fead7001e no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:39:47.589: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7383" for this suite.
Mar  2 09:39:55.728: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:39:55.923: INFO: namespace downward-api-7383 deletion completed in 8.294354818s

• [SLOW TEST:13.046 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:39:55.924: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5819
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Mar  2 09:40:01.070: INFO: Successfully updated pod "labelsupdate038f1cc6-eb89-492d-8ea7-eab30be3353e"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:40:03.140: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5819" for this suite.
Mar  2 09:40:15.228: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:40:15.516: INFO: namespace projected-5819 deletion completed in 12.365394182s

• [SLOW TEST:19.592 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:40:15.517: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-5919
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-5919
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar  2 09:40:15.869: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar  2 09:40:42.618: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.4.191:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5919 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  2 09:40:42.618: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
Mar  2 09:40:42.866: INFO: Found all expected endpoints: [netserver-0]
Mar  2 09:40:42.875: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.3.140:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5919 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  2 09:40:42.875: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
Mar  2 09:40:43.132: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:40:43.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5919" for this suite.
Mar  2 09:40:57.220: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:40:57.483: INFO: namespace pod-network-test-5919 deletion completed in 14.34002825s

• [SLOW TEST:41.965 seconds]
[sig-network] Networking
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:40:57.484: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-8687
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Mar  2 09:41:02.457: INFO: Successfully updated pod "pod-update-2be3db11-a2d8-4658-b49d-8429dd142917"
STEP: verifying the updated pod is in kubernetes
Mar  2 09:41:02.474: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:41:02.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8687" for this suite.
Mar  2 09:41:32.561: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:41:32.803: INFO: namespace pods-8687 deletion completed in 30.319595313s

• [SLOW TEST:35.319 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:41:32.803: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-9181
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Mar  2 09:41:43.903: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:41:43.903: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W0302 09:41:43.903476      24 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-9181" for this suite.
Mar  2 09:41:58.086: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:41:58.260: INFO: namespace gc-9181 deletion completed in 14.347058856s

• [SLOW TEST:25.457 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:41:58.260: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7350
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-33fe6012-cdb4-4931-b607-7e28574bc4bf
STEP: Creating a pod to test consume configMaps
Mar  2 09:41:59.215: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b3312257-f0ce-4a6f-9c94-d5926367b422" in namespace "projected-7350" to be "success or failure"
Mar  2 09:42:00.229: INFO: Pod "pod-projected-configmaps-b3312257-f0ce-4a6f-9c94-d5926367b422": Phase="Pending", Reason="", readiness=false. Elapsed: 1.01381999s
Mar  2 09:42:02.237: INFO: Pod "pod-projected-configmaps-b3312257-f0ce-4a6f-9c94-d5926367b422": Phase="Pending", Reason="", readiness=false. Elapsed: 3.022529189s
Mar  2 09:42:04.243: INFO: Pod "pod-projected-configmaps-b3312257-f0ce-4a6f-9c94-d5926367b422": Phase="Succeeded", Reason="", readiness=false. Elapsed: 5.028689593s
STEP: Saw pod success
Mar  2 09:42:04.243: INFO: Pod "pod-projected-configmaps-b3312257-f0ce-4a6f-9c94-d5926367b422" satisfied condition "success or failure"
Mar  2 09:42:04.257: INFO: Trying to get logs from node worker1 pod pod-projected-configmaps-b3312257-f0ce-4a6f-9c94-d5926367b422 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar  2 09:42:04.625: INFO: Waiting for pod pod-projected-configmaps-b3312257-f0ce-4a6f-9c94-d5926367b422 to disappear
Mar  2 09:42:04.750: INFO: Pod pod-projected-configmaps-b3312257-f0ce-4a6f-9c94-d5926367b422 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:42:04.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7350" for this suite.
Mar  2 09:42:14.889: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:42:15.067: INFO: namespace projected-7350 deletion completed in 10.3065753s

• [SLOW TEST:16.806 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:42:15.067: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-4435
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Mar  2 09:42:21.712: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:42:22.902: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-4435" for this suite.
Mar  2 09:42:53.370: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:42:53.542: INFO: namespace replicaset-4435 deletion completed in 30.63143137s

• [SLOW TEST:38.476 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:42:53.543: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-303
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Mar  2 09:42:53.853: INFO: Waiting up to 5m0s for pod "downwardapi-volume-16b2eb0e-6a46-47e9-b870-724efd9713b9" in namespace "projected-303" to be "success or failure"
Mar  2 09:42:53.860: INFO: Pod "downwardapi-volume-16b2eb0e-6a46-47e9-b870-724efd9713b9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.934732ms
Mar  2 09:42:55.869: INFO: Pod "downwardapi-volume-16b2eb0e-6a46-47e9-b870-724efd9713b9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015423639s
Mar  2 09:42:57.876: INFO: Pod "downwardapi-volume-16b2eb0e-6a46-47e9-b870-724efd9713b9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022941551s
STEP: Saw pod success
Mar  2 09:42:57.876: INFO: Pod "downwardapi-volume-16b2eb0e-6a46-47e9-b870-724efd9713b9" satisfied condition "success or failure"
Mar  2 09:42:57.882: INFO: Trying to get logs from node worker1 pod downwardapi-volume-16b2eb0e-6a46-47e9-b870-724efd9713b9 container client-container: <nil>
STEP: delete the pod
Mar  2 09:42:57.993: INFO: Waiting for pod downwardapi-volume-16b2eb0e-6a46-47e9-b870-724efd9713b9 to disappear
Mar  2 09:42:58.003: INFO: Pod downwardapi-volume-16b2eb0e-6a46-47e9-b870-724efd9713b9 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:42:58.003: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-303" for this suite.
Mar  2 09:43:06.093: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:43:06.336: INFO: namespace projected-303 deletion completed in 8.30895037s

• [SLOW TEST:12.793 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:43:06.336: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-7266
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Mar  2 09:43:14.911: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  2 09:43:14.918: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  2 09:43:16.919: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  2 09:43:16.928: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  2 09:43:18.919: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  2 09:43:18.927: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  2 09:43:20.919: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  2 09:43:20.928: INFO: Pod pod-with-prestop-exec-hook still exists
Mar  2 09:43:22.919: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Mar  2 09:43:22.925: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:43:22.941: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-7266" for this suite.
Mar  2 09:43:34.989: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:43:35.174: INFO: namespace container-lifecycle-hook-7266 deletion completed in 12.222637818s

• [SLOW TEST:28.838 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:43:35.174: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-9364
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Mar  2 09:43:35.639: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar  2 09:43:35.678: INFO: Waiting for terminating namespaces to be deleted...
Mar  2 09:43:35.685: INFO: 
Logging pods the kubelet thinks is on node worker1 before test
Mar  2 09:43:35.698: INFO: kube-flannel-ds-amd64-hmpfw from kube-system started at 2020-03-02 03:03:50 +0000 UTC (1 container statuses recorded)
Mar  2 09:43:35.698: INFO: 	Container kube-flannel ready: true, restart count 0
Mar  2 09:43:35.698: INFO: kube-proxy-bnv2b from kube-system started at 2020-03-02 03:03:07 +0000 UTC (1 container statuses recorded)
Mar  2 09:43:35.698: INFO: 	Container kube-proxy ready: true, restart count 0
Mar  2 09:43:35.698: INFO: sonobuoy from sonobuoy started at 2020-03-02 09:09:31 +0000 UTC (1 container statuses recorded)
Mar  2 09:43:35.698: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Mar  2 09:43:35.698: INFO: sonobuoy-e2e-job-6f4cd8785f284b6e from sonobuoy started at 2020-03-02 09:09:33 +0000 UTC (2 container statuses recorded)
Mar  2 09:43:35.698: INFO: 	Container e2e ready: true, restart count 0
Mar  2 09:43:35.698: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar  2 09:43:35.698: INFO: sonobuoy-systemd-logs-daemon-set-003190d3042d4113-rtkgw from sonobuoy started at 2020-03-02 09:09:34 +0000 UTC (2 container statuses recorded)
Mar  2 09:43:35.698: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar  2 09:43:35.698: INFO: 	Container systemd-logs ready: true, restart count 0
Mar  2 09:43:35.698: INFO: envoy-hwmt2 from projectcontour started at 2020-03-02 02:43:15 +0000 UTC (1 container statuses recorded)
Mar  2 09:43:35.698: INFO: 	Container envoy ready: false, restart count 0
Mar  2 09:43:35.698: INFO: 
Logging pods the kubelet thinks is on node worker2 before test
Mar  2 09:43:35.737: INFO: kuard-85c85bcf66-6dv5z from default started at 2020-03-02 02:41:51 +0000 UTC (1 container statuses recorded)
Mar  2 09:43:35.737: INFO: 	Container kuard ready: true, restart count 0
Mar  2 09:43:35.737: INFO: kube-proxy-77czp from kube-system started at 2020-03-02 03:03:11 +0000 UTC (1 container statuses recorded)
Mar  2 09:43:35.737: INFO: 	Container kube-proxy ready: true, restart count 0
Mar  2 09:43:35.737: INFO: kube-flannel-ds-amd64-6l2th from kube-system started at 2020-03-02 03:04:01 +0000 UTC (1 container statuses recorded)
Mar  2 09:43:35.737: INFO: 	Container kube-flannel ready: true, restart count 0
Mar  2 09:43:35.737: INFO: contour-7594d96455-sm4qm from projectcontour started at 2020-03-02 02:40:59 +0000 UTC (1 container statuses recorded)
Mar  2 09:43:35.737: INFO: 	Container contour ready: false, restart count 0
Mar  2 09:43:35.737: INFO: metrics-server-557c6b848b-k8ssl from kube-system started at 2020-03-02 02:41:51 +0000 UTC (1 container statuses recorded)
Mar  2 09:43:35.737: INFO: 	Container metrics-server ready: true, restart count 0
Mar  2 09:43:35.737: INFO: envoy-l4k6z from projectcontour started at 2020-03-02 02:40:59 +0000 UTC (1 container statuses recorded)
Mar  2 09:43:35.737: INFO: 	Container envoy ready: false, restart count 0
Mar  2 09:43:35.737: INFO: kuard-85c85bcf66-lf9xs from default started at 2020-03-02 02:41:49 +0000 UTC (1 container statuses recorded)
Mar  2 09:43:35.737: INFO: 	Container kuard ready: true, restart count 0
Mar  2 09:43:35.737: INFO: contour-7594d96455-vcdf6 from projectcontour started at 2020-03-02 02:40:59 +0000 UTC (1 container statuses recorded)
Mar  2 09:43:35.737: INFO: 	Container contour ready: false, restart count 0
Mar  2 09:43:35.737: INFO: kuard-85c85bcf66-qv4qm from default started at 2020-03-02 02:41:50 +0000 UTC (1 container statuses recorded)
Mar  2 09:43:35.737: INFO: 	Container kuard ready: true, restart count 0
Mar  2 09:43:35.737: INFO: sonobuoy-systemd-logs-daemon-set-003190d3042d4113-4dn5h from sonobuoy started at 2020-03-02 09:09:34 +0000 UTC (2 container statuses recorded)
Mar  2 09:43:35.737: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar  2 09:43:35.737: INFO: 	Container systemd-logs ready: true, restart count 0
Mar  2 09:43:35.737: INFO: contour-certgen-bh5fh from projectcontour started at 2020-03-02 02:40:59 +0000 UTC (1 container statuses recorded)
Mar  2 09:43:35.737: INFO: 	Container contour ready: false, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: verifying the node has the label node worker1
STEP: verifying the node has the label node worker2
Mar  2 09:43:36.027: INFO: Pod kuard-85c85bcf66-6dv5z requesting resource cpu=0m on Node worker2
Mar  2 09:43:36.027: INFO: Pod kuard-85c85bcf66-lf9xs requesting resource cpu=0m on Node worker2
Mar  2 09:43:36.027: INFO: Pod kuard-85c85bcf66-qv4qm requesting resource cpu=0m on Node worker2
Mar  2 09:43:36.027: INFO: Pod kube-flannel-ds-amd64-6l2th requesting resource cpu=100m on Node worker2
Mar  2 09:43:36.027: INFO: Pod kube-flannel-ds-amd64-hmpfw requesting resource cpu=100m on Node worker1
Mar  2 09:43:36.027: INFO: Pod kube-proxy-77czp requesting resource cpu=0m on Node worker2
Mar  2 09:43:36.027: INFO: Pod kube-proxy-bnv2b requesting resource cpu=0m on Node worker1
Mar  2 09:43:36.027: INFO: Pod metrics-server-557c6b848b-k8ssl requesting resource cpu=0m on Node worker2
Mar  2 09:43:36.027: INFO: Pod contour-7594d96455-sm4qm requesting resource cpu=0m on Node worker2
Mar  2 09:43:36.027: INFO: Pod contour-7594d96455-vcdf6 requesting resource cpu=0m on Node worker2
Mar  2 09:43:36.027: INFO: Pod contour-certgen-bh5fh requesting resource cpu=0m on Node worker2
Mar  2 09:43:36.027: INFO: Pod envoy-hwmt2 requesting resource cpu=0m on Node worker1
Mar  2 09:43:36.027: INFO: Pod envoy-l4k6z requesting resource cpu=0m on Node worker2
Mar  2 09:43:36.027: INFO: Pod sonobuoy requesting resource cpu=0m on Node worker1
Mar  2 09:43:36.027: INFO: Pod sonobuoy-e2e-job-6f4cd8785f284b6e requesting resource cpu=0m on Node worker1
Mar  2 09:43:36.027: INFO: Pod sonobuoy-systemd-logs-daemon-set-003190d3042d4113-4dn5h requesting resource cpu=0m on Node worker2
Mar  2 09:43:36.027: INFO: Pod sonobuoy-systemd-logs-daemon-set-003190d3042d4113-rtkgw requesting resource cpu=0m on Node worker1
STEP: Starting Pods to consume most of the cluster CPU.
Mar  2 09:43:36.027: INFO: Creating a pod which consumes cpu=5530m on Node worker1
Mar  2 09:43:36.061: INFO: Creating a pod which consumes cpu=5530m on Node worker2
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3999b46a-9c73-46bd-9cfb-7d8864a75710.15f873752b4a4704], Reason = [Scheduled], Message = [Successfully assigned sched-pred-9364/filler-pod-3999b46a-9c73-46bd-9cfb-7d8864a75710 to worker1]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3999b46a-9c73-46bd-9cfb-7d8864a75710.15f873757dd16d53], Reason = [Pulled], Message = [Container image "172.20.8.7/library/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3999b46a-9c73-46bd-9cfb-7d8864a75710.15f8737585466a94], Reason = [Created], Message = [Created container filler-pod-3999b46a-9c73-46bd-9cfb-7d8864a75710]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3999b46a-9c73-46bd-9cfb-7d8864a75710.15f873759b391576], Reason = [Started], Message = [Started container filler-pod-3999b46a-9c73-46bd-9cfb-7d8864a75710]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-bf77551d-0bf4-45b7-b007-982cee6f4cb5.15f8737530cfe886], Reason = [Scheduled], Message = [Successfully assigned sched-pred-9364/filler-pod-bf77551d-0bf4-45b7-b007-982cee6f4cb5 to worker2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-bf77551d-0bf4-45b7-b007-982cee6f4cb5.15f87375a80a8f76], Reason = [Pulled], Message = [Container image "172.20.8.7/library/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-bf77551d-0bf4-45b7-b007-982cee6f4cb5.15f87375b8b98bb4], Reason = [Created], Message = [Created container filler-pod-bf77551d-0bf4-45b7-b007-982cee6f4cb5]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-bf77551d-0bf4-45b7-b007-982cee6f4cb5.15f87375ddd24d3d], Reason = [Started], Message = [Started container filler-pod-bf77551d-0bf4-45b7-b007-982cee6f4cb5]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15f873762965a5f4], Reason = [FailedScheduling], Message = [0/5 nodes are available: 2 Insufficient cpu, 3 node(s) had taints that the pod didn't tolerate.]
STEP: removing the label node off the node worker1
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node worker2
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:43:41.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-9364" for this suite.
Mar  2 09:43:49.678: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:43:49.900: INFO: namespace sched-pred-9364 deletion completed in 8.256842203s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:14.726 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:43:49.901: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9695
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-883791b2-0682-4500-ac3e-99e756ffe51c
STEP: Creating secret with name s-test-opt-upd-35d97d6e-44a6-40df-9a2f-dc9adbf6124e
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-883791b2-0682-4500-ac3e-99e756ffe51c
STEP: Updating secret s-test-opt-upd-35d97d6e-44a6-40df-9a2f-dc9adbf6124e
STEP: Creating secret with name s-test-opt-create-ef8af942-48c6-4237-b574-d723a7892675
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:45:05.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9695" for this suite.
Mar  2 09:45:19.906: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:45:20.084: INFO: namespace projected-9695 deletion completed in 14.213546257s

• [SLOW TEST:90.183 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:45:20.084: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5413
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Mar  2 09:45:20.474: INFO: Waiting up to 5m0s for pod "downwardapi-volume-843d090d-ca68-41b8-95fe-b70d73b906e2" in namespace "projected-5413" to be "success or failure"
Mar  2 09:45:20.481: INFO: Pod "downwardapi-volume-843d090d-ca68-41b8-95fe-b70d73b906e2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.791852ms
Mar  2 09:45:22.490: INFO: Pod "downwardapi-volume-843d090d-ca68-41b8-95fe-b70d73b906e2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015306443s
Mar  2 09:45:24.498: INFO: Pod "downwardapi-volume-843d090d-ca68-41b8-95fe-b70d73b906e2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023699933s
STEP: Saw pod success
Mar  2 09:45:24.498: INFO: Pod "downwardapi-volume-843d090d-ca68-41b8-95fe-b70d73b906e2" satisfied condition "success or failure"
Mar  2 09:45:24.504: INFO: Trying to get logs from node worker1 pod downwardapi-volume-843d090d-ca68-41b8-95fe-b70d73b906e2 container client-container: <nil>
STEP: delete the pod
Mar  2 09:45:24.643: INFO: Waiting for pod downwardapi-volume-843d090d-ca68-41b8-95fe-b70d73b906e2 to disappear
Mar  2 09:45:24.679: INFO: Pod downwardapi-volume-843d090d-ca68-41b8-95fe-b70d73b906e2 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:45:24.679: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5413" for this suite.
Mar  2 09:45:32.729: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:45:32.997: INFO: namespace projected-5413 deletion completed in 8.309180919s

• [SLOW TEST:12.913 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:45:32.997: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-587
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Mar  2 09:45:33.458: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ac69a3ad-d0f5-4290-9253-ed24eea1511c" in namespace "projected-587" to be "success or failure"
Mar  2 09:45:33.464: INFO: Pod "downwardapi-volume-ac69a3ad-d0f5-4290-9253-ed24eea1511c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.049854ms
Mar  2 09:45:35.473: INFO: Pod "downwardapi-volume-ac69a3ad-d0f5-4290-9253-ed24eea1511c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015168147s
Mar  2 09:45:37.482: INFO: Pod "downwardapi-volume-ac69a3ad-d0f5-4290-9253-ed24eea1511c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023288884s
STEP: Saw pod success
Mar  2 09:45:37.482: INFO: Pod "downwardapi-volume-ac69a3ad-d0f5-4290-9253-ed24eea1511c" satisfied condition "success or failure"
Mar  2 09:45:37.509: INFO: Trying to get logs from node worker1 pod downwardapi-volume-ac69a3ad-d0f5-4290-9253-ed24eea1511c container client-container: <nil>
STEP: delete the pod
Mar  2 09:45:37.605: INFO: Waiting for pod downwardapi-volume-ac69a3ad-d0f5-4290-9253-ed24eea1511c to disappear
Mar  2 09:45:37.643: INFO: Pod downwardapi-volume-ac69a3ad-d0f5-4290-9253-ed24eea1511c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:45:37.643: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-587" for this suite.
Mar  2 09:45:43.812: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:45:44.055: INFO: namespace projected-587 deletion completed in 6.326655866s

• [SLOW TEST:11.058 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:45:44.056: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-3573
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a best-effort pod
STEP: Ensuring resource quota with best effort scope captures the pod usage
STEP: Ensuring resource quota with not best effort ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a not best-effort pod
STEP: Ensuring resource quota with not best effort scope captures the pod usage
STEP: Ensuring resource quota with best effort scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:46:00.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3573" for this suite.
Mar  2 09:46:09.108: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:46:09.288: INFO: namespace resourcequota-3573 deletion completed in 8.295292434s

• [SLOW TEST:25.232 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:46:09.289: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-5691
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Mar  2 09:46:09.601: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar  2 09:46:09.691: INFO: Waiting for terminating namespaces to be deleted...
Mar  2 09:46:09.698: INFO: 
Logging pods the kubelet thinks is on node worker1 before test
Mar  2 09:46:09.711: INFO: kube-flannel-ds-amd64-hmpfw from kube-system started at 2020-03-02 03:03:50 +0000 UTC (1 container statuses recorded)
Mar  2 09:46:09.711: INFO: 	Container kube-flannel ready: true, restart count 0
Mar  2 09:46:09.711: INFO: kube-proxy-bnv2b from kube-system started at 2020-03-02 03:03:07 +0000 UTC (1 container statuses recorded)
Mar  2 09:46:09.711: INFO: 	Container kube-proxy ready: true, restart count 0
Mar  2 09:46:09.711: INFO: sonobuoy from sonobuoy started at 2020-03-02 09:09:31 +0000 UTC (1 container statuses recorded)
Mar  2 09:46:09.711: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Mar  2 09:46:09.711: INFO: sonobuoy-e2e-job-6f4cd8785f284b6e from sonobuoy started at 2020-03-02 09:09:33 +0000 UTC (2 container statuses recorded)
Mar  2 09:46:09.711: INFO: 	Container e2e ready: true, restart count 0
Mar  2 09:46:09.711: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar  2 09:46:09.711: INFO: sonobuoy-systemd-logs-daemon-set-003190d3042d4113-rtkgw from sonobuoy started at 2020-03-02 09:09:34 +0000 UTC (2 container statuses recorded)
Mar  2 09:46:09.711: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar  2 09:46:09.711: INFO: 	Container systemd-logs ready: true, restart count 0
Mar  2 09:46:09.711: INFO: envoy-hwmt2 from projectcontour started at 2020-03-02 02:43:15 +0000 UTC (1 container statuses recorded)
Mar  2 09:46:09.711: INFO: 	Container envoy ready: false, restart count 0
Mar  2 09:46:09.711: INFO: 
Logging pods the kubelet thinks is on node worker2 before test
Mar  2 09:46:09.746: INFO: contour-certgen-bh5fh from projectcontour started at 2020-03-02 02:40:59 +0000 UTC (1 container statuses recorded)
Mar  2 09:46:09.746: INFO: 	Container contour ready: false, restart count 0
Mar  2 09:46:09.746: INFO: kuard-85c85bcf66-qv4qm from default started at 2020-03-02 02:41:50 +0000 UTC (1 container statuses recorded)
Mar  2 09:46:09.746: INFO: 	Container kuard ready: true, restart count 0
Mar  2 09:46:09.746: INFO: sonobuoy-systemd-logs-daemon-set-003190d3042d4113-4dn5h from sonobuoy started at 2020-03-02 09:09:34 +0000 UTC (2 container statuses recorded)
Mar  2 09:46:09.746: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar  2 09:46:09.746: INFO: 	Container systemd-logs ready: true, restart count 0
Mar  2 09:46:09.746: INFO: kube-proxy-77czp from kube-system started at 2020-03-02 03:03:11 +0000 UTC (1 container statuses recorded)
Mar  2 09:46:09.746: INFO: 	Container kube-proxy ready: true, restart count 0
Mar  2 09:46:09.746: INFO: kuard-85c85bcf66-6dv5z from default started at 2020-03-02 02:41:51 +0000 UTC (1 container statuses recorded)
Mar  2 09:46:09.746: INFO: 	Container kuard ready: true, restart count 0
Mar  2 09:46:09.746: INFO: contour-7594d96455-sm4qm from projectcontour started at 2020-03-02 02:40:59 +0000 UTC (1 container statuses recorded)
Mar  2 09:46:09.746: INFO: 	Container contour ready: false, restart count 0
Mar  2 09:46:09.746: INFO: kube-flannel-ds-amd64-6l2th from kube-system started at 2020-03-02 03:04:01 +0000 UTC (1 container statuses recorded)
Mar  2 09:46:09.746: INFO: 	Container kube-flannel ready: true, restart count 0
Mar  2 09:46:09.746: INFO: metrics-server-557c6b848b-k8ssl from kube-system started at 2020-03-02 02:41:51 +0000 UTC (1 container statuses recorded)
Mar  2 09:46:09.746: INFO: 	Container metrics-server ready: true, restart count 0
Mar  2 09:46:09.746: INFO: envoy-l4k6z from projectcontour started at 2020-03-02 02:40:59 +0000 UTC (1 container statuses recorded)
Mar  2 09:46:09.746: INFO: 	Container envoy ready: false, restart count 0
Mar  2 09:46:09.746: INFO: kuard-85c85bcf66-lf9xs from default started at 2020-03-02 02:41:49 +0000 UTC (1 container statuses recorded)
Mar  2 09:46:09.746: INFO: 	Container kuard ready: true, restart count 0
Mar  2 09:46:09.746: INFO: contour-7594d96455-vcdf6 from projectcontour started at 2020-03-02 02:40:59 +0000 UTC (1 container statuses recorded)
Mar  2 09:46:09.746: INFO: 	Container contour ready: false, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15f87398f5ff5443], Reason = [FailedScheduling], Message = [0/5 nodes are available: 5 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:46:10.838: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-5691" for this suite.
Mar  2 09:46:18.907: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:46:19.194: INFO: namespace sched-pred-5691 deletion completed in 8.346014637s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:9.905 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:46:19.195: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7320
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating secret secrets-7320/secret-test-a6b53553-23ef-4466-8e62-c8f7bdf03da2
STEP: Creating a pod to test consume secrets
Mar  2 09:46:19.633: INFO: Waiting up to 5m0s for pod "pod-configmaps-e77339cb-9441-49c3-8eea-021242403a63" in namespace "secrets-7320" to be "success or failure"
Mar  2 09:46:19.674: INFO: Pod "pod-configmaps-e77339cb-9441-49c3-8eea-021242403a63": Phase="Pending", Reason="", readiness=false. Elapsed: 40.537965ms
Mar  2 09:46:21.683: INFO: Pod "pod-configmaps-e77339cb-9441-49c3-8eea-021242403a63": Phase="Pending", Reason="", readiness=false. Elapsed: 2.049598148s
Mar  2 09:46:23.691: INFO: Pod "pod-configmaps-e77339cb-9441-49c3-8eea-021242403a63": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.05717004s
STEP: Saw pod success
Mar  2 09:46:23.691: INFO: Pod "pod-configmaps-e77339cb-9441-49c3-8eea-021242403a63" satisfied condition "success or failure"
Mar  2 09:46:23.697: INFO: Trying to get logs from node worker1 pod pod-configmaps-e77339cb-9441-49c3-8eea-021242403a63 container env-test: <nil>
STEP: delete the pod
Mar  2 09:46:23.768: INFO: Waiting for pod pod-configmaps-e77339cb-9441-49c3-8eea-021242403a63 to disappear
Mar  2 09:46:23.786: INFO: Pod pod-configmaps-e77339cb-9441-49c3-8eea-021242403a63 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:46:23.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7320" for this suite.
Mar  2 09:46:31.846: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:46:32.165: INFO: namespace secrets-7320 deletion completed in 8.36767398s

• [SLOW TEST:12.970 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:46:32.165: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9339
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Mar  2 09:46:36.709: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 exec pod-sharedvolume-b9dd41f6-7e9e-4a56-98c3-9837a05a1c15 -c busybox-main-container --namespace=emptydir-9339 -- cat /usr/share/volumeshare/shareddata.txt'
Mar  2 09:46:38.750: INFO: stderr: ""
Mar  2 09:46:38.750: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:46:38.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9339" for this suite.
Mar  2 09:46:46.870: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:46:47.087: INFO: namespace emptydir-9339 deletion completed in 8.323700815s

• [SLOW TEST:14.922 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:46:47.088: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-5623
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Mar  2 09:47:18.598: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:47:18.598: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W0302 09:47:18.598743      24 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-5623" for this suite.
Mar  2 09:47:26.645: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:47:26.820: INFO: namespace gc-5623 deletion completed in 8.210748779s

• [SLOW TEST:39.732 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:47:26.821: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-6605
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Mar  2 09:47:27.230: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:47:32.092: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6605" for this suite.
Mar  2 09:47:44.221: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:47:44.546: INFO: namespace init-container-6605 deletion completed in 12.441394511s

• [SLOW TEST:17.726 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:47:44.547: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in prestop-3100
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:173
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating server pod server in namespace prestop-3100
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-3100
STEP: Deleting pre-stop pod
Mar  2 09:47:58.660: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:47:58.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-3100" for this suite.
Mar  2 09:48:44.778: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:48:44.959: INFO: namespace prestop-3100 deletion completed in 46.254781448s

• [SLOW TEST:60.412 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:48:44.959: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-1883
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-1883
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-1883
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-1883
Mar  2 09:48:45.357: INFO: Found 0 stateful pods, waiting for 1
Mar  2 09:48:55.365: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Mar  2 09:48:55.372: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 exec --namespace=statefulset-1883 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Mar  2 09:48:55.827: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Mar  2 09:48:55.827: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Mar  2 09:48:55.827: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Mar  2 09:48:55.836: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Mar  2 09:49:05.846: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar  2 09:49:05.846: INFO: Waiting for statefulset status.replicas updated to 0
Mar  2 09:49:05.949: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.99999892s
Mar  2 09:49:06.957: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.992777378s
Mar  2 09:49:07.966: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.984672963s
Mar  2 09:49:08.975: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.976272459s
Mar  2 09:49:09.983: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.967277373s
Mar  2 09:49:10.991: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.95943795s
Mar  2 09:49:11.999: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.950902682s
Mar  2 09:49:13.007: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.942718464s
Mar  2 09:49:14.015: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.934896832s
Mar  2 09:49:15.023: INFO: Verifying statefulset ss doesn't scale past 1 for another 926.693698ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-1883
Mar  2 09:49:16.032: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 exec --namespace=statefulset-1883 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar  2 09:49:16.466: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Mar  2 09:49:16.466: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Mar  2 09:49:16.467: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Mar  2 09:49:16.475: INFO: Found 1 stateful pods, waiting for 3
Mar  2 09:49:26.483: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Mar  2 09:49:26.483: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Mar  2 09:49:26.483: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Mar  2 09:49:26.494: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 exec --namespace=statefulset-1883 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Mar  2 09:49:26.823: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Mar  2 09:49:26.823: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Mar  2 09:49:26.823: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Mar  2 09:49:26.823: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 exec --namespace=statefulset-1883 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Mar  2 09:49:27.318: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Mar  2 09:49:27.318: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Mar  2 09:49:27.318: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Mar  2 09:49:27.318: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 exec --namespace=statefulset-1883 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Mar  2 09:49:27.694: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Mar  2 09:49:27.694: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Mar  2 09:49:27.694: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Mar  2 09:49:27.694: INFO: Waiting for statefulset status.replicas updated to 0
Mar  2 09:49:27.700: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Mar  2 09:49:37.713: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar  2 09:49:37.713: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Mar  2 09:49:37.713: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Mar  2 09:49:37.743: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999063s
Mar  2 09:49:38.764: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.99497547s
Mar  2 09:49:39.806: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.973954752s
Mar  2 09:49:40.813: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.932619641s
Mar  2 09:49:41.820: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.925618243s
Mar  2 09:49:42.828: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.918227343s
Mar  2 09:49:43.834: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.910525795s
Mar  2 09:49:44.840: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.904033715s
Mar  2 09:49:45.848: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.898501713s
Mar  2 09:49:46.855: INFO: Verifying statefulset ss doesn't scale past 3 for another 890.500289ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-1883
Mar  2 09:49:47.864: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 exec --namespace=statefulset-1883 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar  2 09:49:48.178: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Mar  2 09:49:48.178: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Mar  2 09:49:48.178: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Mar  2 09:49:48.178: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 exec --namespace=statefulset-1883 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar  2 09:49:48.614: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Mar  2 09:49:48.614: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Mar  2 09:49:48.614: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Mar  2 09:49:48.615: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 exec --namespace=statefulset-1883 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar  2 09:49:48.977: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Mar  2 09:49:48.977: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Mar  2 09:49:48.977: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Mar  2 09:49:48.977: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Mar  2 09:50:19.003: INFO: Deleting all statefulset in ns statefulset-1883
Mar  2 09:50:19.009: INFO: Scaling statefulset ss to 0
Mar  2 09:50:19.044: INFO: Waiting for statefulset status.replicas updated to 0
Mar  2 09:50:19.049: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:50:19.116: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1883" for this suite.
Mar  2 09:50:27.309: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:50:27.538: INFO: namespace statefulset-1883 deletion completed in 8.415652979s

• [SLOW TEST:102.580 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a container with runAsUser 
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:50:27.539: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-6337
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  2 09:50:27.848: INFO: Waiting up to 5m0s for pod "busybox-user-65534-1fe4b3fe-187a-493b-9b93-bb6b8680b001" in namespace "security-context-test-6337" to be "success or failure"
Mar  2 09:50:27.853: INFO: Pod "busybox-user-65534-1fe4b3fe-187a-493b-9b93-bb6b8680b001": Phase="Pending", Reason="", readiness=false. Elapsed: 4.930758ms
Mar  2 09:50:29.859: INFO: Pod "busybox-user-65534-1fe4b3fe-187a-493b-9b93-bb6b8680b001": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010866132s
Mar  2 09:50:31.865: INFO: Pod "busybox-user-65534-1fe4b3fe-187a-493b-9b93-bb6b8680b001": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016689475s
Mar  2 09:50:31.865: INFO: Pod "busybox-user-65534-1fe4b3fe-187a-493b-9b93-bb6b8680b001" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:50:31.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-6337" for this suite.
Mar  2 09:50:39.954: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:50:40.119: INFO: namespace security-context-test-6337 deletion completed in 8.246843783s

• [SLOW TEST:12.580 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a container with runAsUser
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:44
    should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:50:40.119: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-2643
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Mar  2 09:50:45.094: INFO: Successfully updated pod "pod-update-activedeadlineseconds-e75a7603-e401-40d9-8bc9-123530243cb2"
Mar  2 09:50:45.094: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-e75a7603-e401-40d9-8bc9-123530243cb2" in namespace "pods-2643" to be "terminated due to deadline exceeded"
Mar  2 09:50:45.113: INFO: Pod "pod-update-activedeadlineseconds-e75a7603-e401-40d9-8bc9-123530243cb2": Phase="Running", Reason="", readiness=true. Elapsed: 18.641162ms
Mar  2 09:50:47.118: INFO: Pod "pod-update-activedeadlineseconds-e75a7603-e401-40d9-8bc9-123530243cb2": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.024049472s
Mar  2 09:50:47.119: INFO: Pod "pod-update-activedeadlineseconds-e75a7603-e401-40d9-8bc9-123530243cb2" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:50:47.119: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2643" for this suite.
Mar  2 09:50:55.235: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:50:55.366: INFO: namespace pods-2643 deletion completed in 8.239051188s

• [SLOW TEST:15.247 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:50:55.367: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-7062
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-7062
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Mar  2 09:50:55.860: INFO: Found 0 stateful pods, waiting for 3
Mar  2 09:51:05.869: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar  2 09:51:05.869: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar  2 09:51:05.869: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=false
Mar  2 09:51:15.868: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar  2 09:51:15.868: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar  2 09:51:15.868: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Mar  2 09:51:15.884: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 exec --namespace=statefulset-7062 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Mar  2 09:51:16.582: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Mar  2 09:51:16.582: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Mar  2 09:51:16.582: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from 172.20.8.7/library/httpd:2.4.38-alpine to 172.20.8.7/library/httpd:2.4.39-alpine
Mar  2 09:51:16.854: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Mar  2 09:51:26.886: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 exec --namespace=statefulset-7062 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar  2 09:51:27.276: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Mar  2 09:51:27.276: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Mar  2 09:51:27.276: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Mar  2 09:51:47.309: INFO: Waiting for StatefulSet statefulset-7062/ss2 to complete update
STEP: Rolling back to a previous revision
Mar  2 09:51:57.334: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 exec --namespace=statefulset-7062 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Mar  2 09:51:57.761: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Mar  2 09:51:57.761: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Mar  2 09:51:57.761: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Mar  2 09:52:07.823: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Mar  2 09:52:17.903: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 exec --namespace=statefulset-7062 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar  2 09:52:18.280: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Mar  2 09:52:18.280: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Mar  2 09:52:18.280: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Mar  2 09:52:38.326: INFO: Waiting for StatefulSet statefulset-7062/ss2 to complete update
Mar  2 09:52:38.326: INFO: Waiting for Pod statefulset-7062/ss2-0 to have revision ss2-5f4b4c7df9 update revision ss2-95cdf5d68
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Mar  2 09:52:48.337: INFO: Deleting all statefulset in ns statefulset-7062
Mar  2 09:52:48.342: INFO: Scaling statefulset ss2 to 0
Mar  2 09:53:08.435: INFO: Waiting for statefulset status.replicas updated to 0
Mar  2 09:53:08.440: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:53:08.504: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7062" for this suite.
Mar  2 09:53:20.614: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:53:20.772: INFO: namespace statefulset-7062 deletion completed in 12.260964145s

• [SLOW TEST:145.405 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:53:20.773: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-1161
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar  2 09:53:22.537: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Mar  2 09:53:24.579: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718739602, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718739602, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718739602, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718739602, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7794d7ccd5\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar  2 09:53:27.808: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod that should be denied by the webhook
STEP: create a pod that causes the webhook to hang
STEP: create a configmap that should be denied by the webhook
STEP: create a configmap that should be admitted by the webhook
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: create a namespace that bypass the webhook
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:53:38.338: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1161" for this suite.
Mar  2 09:53:46.436: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:53:46.575: INFO: namespace webhook-1161 deletion completed in 8.228639204s
STEP: Destroying namespace "webhook-1161-markers" for this suite.
Mar  2 09:53:52.607: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:53:52.717: INFO: namespace webhook-1161-markers deletion completed in 6.14167265s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:31.998 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:53:52.771: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-2710
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:53:53.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2710" for this suite.
Mar  2 09:54:21.358: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:54:21.487: INFO: namespace pods-2710 deletion completed in 28.251885869s

• [SLOW TEST:28.716 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should honor timeout [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:54:21.487: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3943
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar  2 09:54:23.778: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Mar  2 09:54:25.795: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718739663, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718739663, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718739664, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718739663, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7794d7ccd5\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar  2 09:54:28.930: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting timeout (1s) shorter than webhook latency (5s)
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s)
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is longer than webhook latency
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is empty (defaulted to 10s in v1)
STEP: Registering slow webhook via the AdmissionRegistration API
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:54:41.802: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3943" for this suite.
Mar  2 09:54:49.896: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:54:50.019: INFO: namespace webhook-3943 deletion completed in 8.208335847s
STEP: Destroying namespace "webhook-3943-markers" for this suite.
Mar  2 09:54:56.080: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:54:56.202: INFO: namespace webhook-3943-markers deletion completed in 6.18269553s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:34.783 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:54:56.270: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-3649
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicationController
STEP: Ensuring resource quota status captures replication controller creation
STEP: Deleting a ReplicationController
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:55:07.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3649" for this suite.
Mar  2 09:55:15.928: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:55:16.167: INFO: namespace resourcequota-3649 deletion completed in 8.305845283s

• [SLOW TEST:19.897 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:55:16.168: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-8864
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  2 09:55:16.718: INFO: (0) /api/v1/nodes/worker1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 121.139348ms)
Mar  2 09:55:16.726: INFO: (1) /api/v1/nodes/worker1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.120549ms)
Mar  2 09:55:16.734: INFO: (2) /api/v1/nodes/worker1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.634794ms)
Mar  2 09:55:16.742: INFO: (3) /api/v1/nodes/worker1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.982973ms)
Mar  2 09:55:16.749: INFO: (4) /api/v1/nodes/worker1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.41207ms)
Mar  2 09:55:16.756: INFO: (5) /api/v1/nodes/worker1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.615925ms)
Mar  2 09:55:16.764: INFO: (6) /api/v1/nodes/worker1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.627777ms)
Mar  2 09:55:16.770: INFO: (7) /api/v1/nodes/worker1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.966454ms)
Mar  2 09:55:16.777: INFO: (8) /api/v1/nodes/worker1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.566487ms)
Mar  2 09:55:16.784: INFO: (9) /api/v1/nodes/worker1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.981555ms)
Mar  2 09:55:16.791: INFO: (10) /api/v1/nodes/worker1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.716051ms)
Mar  2 09:55:16.797: INFO: (11) /api/v1/nodes/worker1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.62217ms)
Mar  2 09:55:16.805: INFO: (12) /api/v1/nodes/worker1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.392564ms)
Mar  2 09:55:16.811: INFO: (13) /api/v1/nodes/worker1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.810313ms)
Mar  2 09:55:16.817: INFO: (14) /api/v1/nodes/worker1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.301632ms)
Mar  2 09:55:16.824: INFO: (15) /api/v1/nodes/worker1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.894772ms)
Mar  2 09:55:16.831: INFO: (16) /api/v1/nodes/worker1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.930069ms)
Mar  2 09:55:16.839: INFO: (17) /api/v1/nodes/worker1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.882321ms)
Mar  2 09:55:16.846: INFO: (18) /api/v1/nodes/worker1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.090154ms)
Mar  2 09:55:16.852: INFO: (19) /api/v1/nodes/worker1:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.218222ms)
[AfterEach] version v1
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:55:16.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-8864" for this suite.
Mar  2 09:55:22.893: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:55:23.023: INFO: namespace proxy-8864 deletion completed in 6.163615317s

• [SLOW TEST:6.855 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:55:23.024: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-859
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-0ca093a6-f455-4232-abee-4e941eed809e
STEP: Creating a pod to test consume secrets
Mar  2 09:55:23.759: INFO: Waiting up to 5m0s for pod "pod-secrets-982a210a-aa17-4e5a-9131-f60b9d9b63f7" in namespace "secrets-859" to be "success or failure"
Mar  2 09:55:23.765: INFO: Pod "pod-secrets-982a210a-aa17-4e5a-9131-f60b9d9b63f7": Phase="Pending", Reason="", readiness=false. Elapsed: 5.510692ms
Mar  2 09:55:25.811: INFO: Pod "pod-secrets-982a210a-aa17-4e5a-9131-f60b9d9b63f7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.052131315s
Mar  2 09:55:27.817: INFO: Pod "pod-secrets-982a210a-aa17-4e5a-9131-f60b9d9b63f7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.05835321s
STEP: Saw pod success
Mar  2 09:55:27.818: INFO: Pod "pod-secrets-982a210a-aa17-4e5a-9131-f60b9d9b63f7" satisfied condition "success or failure"
Mar  2 09:55:27.822: INFO: Trying to get logs from node worker1 pod pod-secrets-982a210a-aa17-4e5a-9131-f60b9d9b63f7 container secret-volume-test: <nil>
STEP: delete the pod
Mar  2 09:55:27.969: INFO: Waiting for pod pod-secrets-982a210a-aa17-4e5a-9131-f60b9d9b63f7 to disappear
Mar  2 09:55:27.973: INFO: Pod pod-secrets-982a210a-aa17-4e5a-9131-f60b9d9b63f7 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:55:27.974: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-859" for this suite.
Mar  2 09:55:34.038: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:55:34.166: INFO: namespace secrets-859 deletion completed in 6.187440078s

• [SLOW TEST:11.143 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:55:34.167: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-kubelet-etc-hosts-1204
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Mar  2 09:55:42.841: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1204 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  2 09:55:42.841: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
Mar  2 09:55:43.039: INFO: Exec stderr: ""
Mar  2 09:55:43.039: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1204 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  2 09:55:43.039: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
Mar  2 09:55:43.262: INFO: Exec stderr: ""
Mar  2 09:55:43.262: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1204 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  2 09:55:43.262: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
Mar  2 09:55:43.466: INFO: Exec stderr: ""
Mar  2 09:55:43.466: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1204 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  2 09:55:43.466: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
Mar  2 09:55:43.633: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Mar  2 09:55:43.633: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1204 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  2 09:55:43.633: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
Mar  2 09:55:43.839: INFO: Exec stderr: ""
Mar  2 09:55:43.839: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1204 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  2 09:55:43.839: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
Mar  2 09:55:44.020: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Mar  2 09:55:44.020: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1204 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  2 09:55:44.020: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
Mar  2 09:55:44.192: INFO: Exec stderr: ""
Mar  2 09:55:44.192: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1204 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  2 09:55:44.192: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
Mar  2 09:55:44.395: INFO: Exec stderr: ""
Mar  2 09:55:44.395: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1204 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  2 09:55:44.395: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
Mar  2 09:55:44.579: INFO: Exec stderr: ""
Mar  2 09:55:44.579: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1204 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  2 09:55:44.579: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
Mar  2 09:55:44.748: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:55:44.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-1204" for this suite.
Mar  2 09:56:30.826: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:56:30.963: INFO: namespace e2e-kubelet-etc-hosts-1204 deletion completed in 46.177127839s

• [SLOW TEST:56.796 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:56:30.963: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-4487
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  2 09:56:31.307: INFO: Creating deployment "webserver-deployment"
Mar  2 09:56:31.348: INFO: Waiting for observed generation 1
Mar  2 09:56:33.360: INFO: Waiting for all required pods to come up
Mar  2 09:56:33.368: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running
Mar  2 09:56:37.383: INFO: Waiting for deployment "webserver-deployment" to complete
Mar  2 09:56:37.392: INFO: Updating deployment "webserver-deployment" with a non-existent image
Mar  2 09:56:37.448: INFO: Updating deployment webserver-deployment
Mar  2 09:56:37.448: INFO: Waiting for observed generation 2
Mar  2 09:56:39.457: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Mar  2 09:56:39.463: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Mar  2 09:56:39.469: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Mar  2 09:56:39.484: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Mar  2 09:56:39.484: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Mar  2 09:56:39.488: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Mar  2 09:56:39.503: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Mar  2 09:56:39.503: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Mar  2 09:56:39.558: INFO: Updating deployment webserver-deployment
Mar  2 09:56:39.558: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Mar  2 09:56:39.772: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Mar  2 09:56:39.842: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Mar  2 09:56:39.856: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-4487 /apis/apps/v1/namespaces/deployment-4487/deployments/webserver-deployment 655441bb-540a-4025-b283-a9292795fba9 87678 3 2020-03-02 09:56:31 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003688c88 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-c7997dcc8" is progressing.,LastUpdateTime:2020-03-02 09:56:38 +0000 UTC,LastTransitionTime:2020-03-02 09:56:31 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2020-03-02 09:56:39 +0000 UTC,LastTransitionTime:2020-03-02 09:56:39 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Mar  2 09:56:40.016: INFO: New ReplicaSet "webserver-deployment-c7997dcc8" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-c7997dcc8  deployment-4487 /apis/apps/v1/namespaces/deployment-4487/replicasets/webserver-deployment-c7997dcc8 881bccdb-3764-473a-9ba2-fe23730debe3 87674 3 2020-03-02 09:56:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 655441bb-540a-4025-b283-a9292795fba9 0xc003689197 0xc003689198}] []  []},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: c7997dcc8,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003689208 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Mar  2 09:56:40.016: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Mar  2 09:56:40.016: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-68df7476b  deployment-4487 /apis/apps/v1/namespaces/deployment-4487/replicasets/webserver-deployment-68df7476b dff7f3c0-7b15-4163-b55f-3869e848cff9 87671 3 2020-03-02 09:56:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:68df7476b] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 655441bb-540a-4025-b283-a9292795fba9 0xc0036890d7 0xc0036890d8}] []  []},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 68df7476b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:68df7476b] map[] [] []  []} {[] [] [{httpd 172.20.8.7/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003689138 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Mar  2 09:56:40.084: INFO: Pod "webserver-deployment-68df7476b-44gxx" is available:
&Pod{ObjectMeta:{webserver-deployment-68df7476b-44gxx webserver-deployment-68df7476b- deployment-4487 /api/v1/namespaces/deployment-4487/pods/webserver-deployment-68df7476b-44gxx 23b5723b-26c9-4f6a-8521-9399427350ec 87595 0 2020-03-02 09:56:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:68df7476b] map[] [{apps/v1 ReplicaSet webserver-deployment-68df7476b dff7f3c0-7b15-4163-b55f-3869e848cff9 0xc0036896e7 0xc0036896e8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-hbg7h,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-hbg7h,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:172.20.8.7/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-hbg7h,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 09:56:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 09:56:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 09:56:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 09:56:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.8.5,PodIP:10.244.4.232,StartTime:2020-03-02 09:56:31 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-03-02 09:56:33 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:172.20.8.7/library/httpd:2.4.38-alpine,ImageID:docker-pullable://172.20.8.7/library/httpd@sha256:6feb0ea7b0967367da66e8d58ba813fde32bdb92f63bfc21a9e170d211539db4,ContainerID:docker://2073a71fe766056f79e86d4a77d4241983b8f6c0b2d66d53997dd5ae4aded951,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.4.232,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  2 09:56:40.085: INFO: Pod "webserver-deployment-68df7476b-4wgfl" is available:
&Pod{ObjectMeta:{webserver-deployment-68df7476b-4wgfl webserver-deployment-68df7476b- deployment-4487 /api/v1/namespaces/deployment-4487/pods/webserver-deployment-68df7476b-4wgfl 2c787e5f-820d-404a-a99b-8d71312fb92c 87567 0 2020-03-02 09:56:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:68df7476b] map[] [{apps/v1 ReplicaSet webserver-deployment-68df7476b dff7f3c0-7b15-4163-b55f-3869e848cff9 0xc003689860 0xc003689861}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-hbg7h,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-hbg7h,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:172.20.8.7/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-hbg7h,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 09:56:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 09:56:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 09:56:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 09:56:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.8.6,PodIP:10.244.3.152,StartTime:2020-03-02 09:56:31 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-03-02 09:56:34 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:172.20.8.7/library/httpd:2.4.38-alpine,ImageID:docker-pullable://172.20.8.7/library/httpd@sha256:6feb0ea7b0967367da66e8d58ba813fde32bdb92f63bfc21a9e170d211539db4,ContainerID:docker://4cb02a07152adeb22594dfa120334299a83ae8b27348a97796d1378eccbc664f,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.3.152,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  2 09:56:40.085: INFO: Pod "webserver-deployment-68df7476b-5v7qd" is not available:
&Pod{ObjectMeta:{webserver-deployment-68df7476b-5v7qd webserver-deployment-68df7476b- deployment-4487 /api/v1/namespaces/deployment-4487/pods/webserver-deployment-68df7476b-5v7qd a55998e1-5145-40ca-80b0-5fce82f1735d 87679 0 2020-03-02 09:56:39 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:68df7476b] map[] [{apps/v1 ReplicaSet webserver-deployment-68df7476b dff7f3c0-7b15-4163-b55f-3869e848cff9 0xc0036899d0 0xc0036899d1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-hbg7h,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-hbg7h,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:172.20.8.7/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-hbg7h,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 09:56:39 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  2 09:56:40.085: INFO: Pod "webserver-deployment-68df7476b-b976k" is available:
&Pod{ObjectMeta:{webserver-deployment-68df7476b-b976k webserver-deployment-68df7476b- deployment-4487 /api/v1/namespaces/deployment-4487/pods/webserver-deployment-68df7476b-b976k eeebddf3-8394-46f8-aa06-346a1fb07ecf 87580 0 2020-03-02 09:56:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:68df7476b] map[] [{apps/v1 ReplicaSet webserver-deployment-68df7476b dff7f3c0-7b15-4163-b55f-3869e848cff9 0xc003689ae0 0xc003689ae1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-hbg7h,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-hbg7h,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:172.20.8.7/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-hbg7h,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 09:56:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 09:56:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 09:56:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 09:56:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.8.5,PodIP:10.244.4.234,StartTime:2020-03-02 09:56:32 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-03-02 09:56:34 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:172.20.8.7/library/httpd:2.4.38-alpine,ImageID:docker-pullable://172.20.8.7/library/httpd@sha256:6feb0ea7b0967367da66e8d58ba813fde32bdb92f63bfc21a9e170d211539db4,ContainerID:docker://13ecbe81d99fa6996cca1d44d146b145f8d2adb21f10ff3ce79ac36fdd3efc95,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.4.234,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  2 09:56:40.086: INFO: Pod "webserver-deployment-68df7476b-crxwn" is available:
&Pod{ObjectMeta:{webserver-deployment-68df7476b-crxwn webserver-deployment-68df7476b- deployment-4487 /api/v1/namespaces/deployment-4487/pods/webserver-deployment-68df7476b-crxwn a472844d-76da-4476-919e-ff52c56211b1 87587 0 2020-03-02 09:56:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:68df7476b] map[] [{apps/v1 ReplicaSet webserver-deployment-68df7476b dff7f3c0-7b15-4163-b55f-3869e848cff9 0xc003689c50 0xc003689c51}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-hbg7h,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-hbg7h,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:172.20.8.7/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-hbg7h,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 09:56:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 09:56:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 09:56:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 09:56:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.8.5,PodIP:10.244.4.235,StartTime:2020-03-02 09:56:32 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-03-02 09:56:34 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:172.20.8.7/library/httpd:2.4.38-alpine,ImageID:docker-pullable://172.20.8.7/library/httpd@sha256:6feb0ea7b0967367da66e8d58ba813fde32bdb92f63bfc21a9e170d211539db4,ContainerID:docker://cf7abfeeea872ab8626fb9d1de5adeebad5ce68d6809cf7f2cd71074545cc49f,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.4.235,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  2 09:56:40.086: INFO: Pod "webserver-deployment-68df7476b-fhcf2" is available:
&Pod{ObjectMeta:{webserver-deployment-68df7476b-fhcf2 webserver-deployment-68df7476b- deployment-4487 /api/v1/namespaces/deployment-4487/pods/webserver-deployment-68df7476b-fhcf2 10b82836-4032-4b3d-8e4b-02552c83c7ec 87601 0 2020-03-02 09:56:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:68df7476b] map[] [{apps/v1 ReplicaSet webserver-deployment-68df7476b dff7f3c0-7b15-4163-b55f-3869e848cff9 0xc003689dc0 0xc003689dc1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-hbg7h,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-hbg7h,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:172.20.8.7/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-hbg7h,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 09:56:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 09:56:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 09:56:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 09:56:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.8.6,PodIP:10.244.3.154,StartTime:2020-03-02 09:56:32 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-03-02 09:56:35 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:172.20.8.7/library/httpd:2.4.38-alpine,ImageID:docker-pullable://172.20.8.7/library/httpd@sha256:6feb0ea7b0967367da66e8d58ba813fde32bdb92f63bfc21a9e170d211539db4,ContainerID:docker://b83a8a8e4b47aa466860ce1d500cfbb4025d5dde2cba306b3128a556353f538e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.3.154,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  2 09:56:40.086: INFO: Pod "webserver-deployment-68df7476b-spwfk" is available:
&Pod{ObjectMeta:{webserver-deployment-68df7476b-spwfk webserver-deployment-68df7476b- deployment-4487 /api/v1/namespaces/deployment-4487/pods/webserver-deployment-68df7476b-spwfk 1fb05726-af2e-4cc8-8fb5-30eb8645c8a2 87597 0 2020-03-02 09:56:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:68df7476b] map[] [{apps/v1 ReplicaSet webserver-deployment-68df7476b dff7f3c0-7b15-4163-b55f-3869e848cff9 0xc003689f30 0xc003689f31}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-hbg7h,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-hbg7h,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:172.20.8.7/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-hbg7h,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 09:56:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 09:56:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 09:56:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 09:56:32 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.8.6,PodIP:10.244.3.155,StartTime:2020-03-02 09:56:32 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-03-02 09:56:35 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:172.20.8.7/library/httpd:2.4.38-alpine,ImageID:docker-pullable://172.20.8.7/library/httpd@sha256:6feb0ea7b0967367da66e8d58ba813fde32bdb92f63bfc21a9e170d211539db4,ContainerID:docker://d6b7580775feae66525113cd02549616e0d3b3aa806c83688d89f5a451aa3785,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.3.155,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  2 09:56:40.087: INFO: Pod "webserver-deployment-68df7476b-vjgx9" is available:
&Pod{ObjectMeta:{webserver-deployment-68df7476b-vjgx9 webserver-deployment-68df7476b- deployment-4487 /api/v1/namespaces/deployment-4487/pods/webserver-deployment-68df7476b-vjgx9 0da323ec-51cc-410b-a195-9d4ef76ce93d 87596 0 2020-03-02 09:56:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:68df7476b] map[] [{apps/v1 ReplicaSet webserver-deployment-68df7476b dff7f3c0-7b15-4163-b55f-3869e848cff9 0xc002eaa8d0 0xc002eaa8d1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-hbg7h,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-hbg7h,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:172.20.8.7/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-hbg7h,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 09:56:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 09:56:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 09:56:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 09:56:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.8.6,PodIP:10.244.3.153,StartTime:2020-03-02 09:56:32 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-03-02 09:56:35 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:172.20.8.7/library/httpd:2.4.38-alpine,ImageID:docker-pullable://172.20.8.7/library/httpd@sha256:6feb0ea7b0967367da66e8d58ba813fde32bdb92f63bfc21a9e170d211539db4,ContainerID:docker://ae330168afee4cab016b9ea87fb4118ff154d37295c2e85576261ae5e48015ea,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.3.153,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  2 09:56:40.087: INFO: Pod "webserver-deployment-68df7476b-wcc7p" is available:
&Pod{ObjectMeta:{webserver-deployment-68df7476b-wcc7p webserver-deployment-68df7476b- deployment-4487 /api/v1/namespaces/deployment-4487/pods/webserver-deployment-68df7476b-wcc7p 1829d8a1-4183-4ab4-9914-a0ee88ab2e5a 87576 0 2020-03-02 09:56:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:68df7476b] map[] [{apps/v1 ReplicaSet webserver-deployment-68df7476b dff7f3c0-7b15-4163-b55f-3869e848cff9 0xc002eaaa60 0xc002eaaa61}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-hbg7h,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-hbg7h,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:172.20.8.7/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-hbg7h,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 09:56:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 09:56:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 09:56:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 09:56:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.8.5,PodIP:10.244.4.233,StartTime:2020-03-02 09:56:31 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-03-02 09:56:34 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:172.20.8.7/library/httpd:2.4.38-alpine,ImageID:docker-pullable://172.20.8.7/library/httpd@sha256:6feb0ea7b0967367da66e8d58ba813fde32bdb92f63bfc21a9e170d211539db4,ContainerID:docker://223d30972fd2c77b36b87462561e8c8cfba1af462278d422adf8514ce50fd1f7,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.4.233,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  2 09:56:40.088: INFO: Pod "webserver-deployment-68df7476b-wgqx9" is not available:
&Pod{ObjectMeta:{webserver-deployment-68df7476b-wgqx9 webserver-deployment-68df7476b- deployment-4487 /api/v1/namespaces/deployment-4487/pods/webserver-deployment-68df7476b-wgqx9 83f74a6e-263c-440f-afe2-dc86a842317b 87688 0 2020-03-02 09:56:39 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:68df7476b] map[] [{apps/v1 ReplicaSet webserver-deployment-68df7476b dff7f3c0-7b15-4163-b55f-3869e848cff9 0xc002eaae10 0xc002eaae11}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-hbg7h,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-hbg7h,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:172.20.8.7/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-hbg7h,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 09:56:39 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  2 09:56:40.088: INFO: Pod "webserver-deployment-68df7476b-z7wdf" is not available:
&Pod{ObjectMeta:{webserver-deployment-68df7476b-z7wdf webserver-deployment-68df7476b- deployment-4487 /api/v1/namespaces/deployment-4487/pods/webserver-deployment-68df7476b-z7wdf c1dd039e-cd54-4427-9b58-34c8815dffd7 87684 0 2020-03-02 09:56:39 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:68df7476b] map[] [{apps/v1 ReplicaSet webserver-deployment-68df7476b dff7f3c0-7b15-4163-b55f-3869e848cff9 0xc002eab130 0xc002eab131}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-hbg7h,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-hbg7h,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:172.20.8.7/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-hbg7h,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  2 09:56:40.088: INFO: Pod "webserver-deployment-c7997dcc8-48d67" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-48d67 webserver-deployment-c7997dcc8- deployment-4487 /api/v1/namespaces/deployment-4487/pods/webserver-deployment-c7997dcc8-48d67 8ee0789f-c700-47d1-adcc-6c8998b167e8 87647 0 2020-03-02 09:56:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 881bccdb-3764-473a-9ba2-fe23730debe3 0xc002eab397 0xc002eab398}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-hbg7h,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-hbg7h,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-hbg7h,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 09:56:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 09:56:38 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 09:56:38 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 09:56:37 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.8.5,PodIP:,StartTime:2020-03-02 09:56:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  2 09:56:40.089: INFO: Pod "webserver-deployment-c7997dcc8-dr98x" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-dr98x webserver-deployment-c7997dcc8- deployment-4487 /api/v1/namespaces/deployment-4487/pods/webserver-deployment-c7997dcc8-dr98x 0bc90356-0bae-495d-af8e-766076147ec1 87661 0 2020-03-02 09:56:38 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 881bccdb-3764-473a-9ba2-fe23730debe3 0xc002eab510 0xc002eab511}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-hbg7h,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-hbg7h,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-hbg7h,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 09:56:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 09:56:38 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 09:56:38 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 09:56:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.8.5,PodIP:,StartTime:2020-03-02 09:56:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  2 09:56:40.089: INFO: Pod "webserver-deployment-c7997dcc8-fqxv8" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-fqxv8 webserver-deployment-c7997dcc8- deployment-4487 /api/v1/namespaces/deployment-4487/pods/webserver-deployment-c7997dcc8-fqxv8 de49da55-50ab-4ff9-be52-9adf3c0be2cb 87665 0 2020-03-02 09:56:38 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 881bccdb-3764-473a-9ba2-fe23730debe3 0xc002eab680 0xc002eab681}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-hbg7h,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-hbg7h,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-hbg7h,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 09:56:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 09:56:38 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 09:56:38 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 09:56:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.8.6,PodIP:,StartTime:2020-03-02 09:56:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  2 09:56:40.090: INFO: Pod "webserver-deployment-c7997dcc8-ft7cx" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-ft7cx webserver-deployment-c7997dcc8- deployment-4487 /api/v1/namespaces/deployment-4487/pods/webserver-deployment-c7997dcc8-ft7cx 8fcade5a-ab28-4737-b1c2-f4015a311461 87690 0 2020-03-02 09:56:39 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 881bccdb-3764-473a-9ba2-fe23730debe3 0xc002eab7f0 0xc002eab7f1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-hbg7h,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-hbg7h,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-hbg7h,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 09:56:39 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  2 09:56:40.091: INFO: Pod "webserver-deployment-c7997dcc8-hrggh" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-hrggh webserver-deployment-c7997dcc8- deployment-4487 /api/v1/namespaces/deployment-4487/pods/webserver-deployment-c7997dcc8-hrggh c0107236-489d-4ba6-b195-def2fe59dabb 87637 0 2020-03-02 09:56:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 881bccdb-3764-473a-9ba2-fe23730debe3 0xc002eab910 0xc002eab911}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-hbg7h,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-hbg7h,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-hbg7h,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 09:56:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 09:56:37 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 09:56:37 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 09:56:37 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.8.5,PodIP:,StartTime:2020-03-02 09:56:37 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  2 09:56:40.091: INFO: Pod "webserver-deployment-c7997dcc8-kvwkx" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-kvwkx webserver-deployment-c7997dcc8- deployment-4487 /api/v1/namespaces/deployment-4487/pods/webserver-deployment-c7997dcc8-kvwkx cdb5792c-fb58-488d-bc7b-43e37d752cdc 87689 0 2020-03-02 09:56:39 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 881bccdb-3764-473a-9ba2-fe23730debe3 0xc002eaba80 0xc002eaba81}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-hbg7h,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-hbg7h,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-hbg7h,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 09:56:39 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  2 09:56:40.092: INFO: Pod "webserver-deployment-c7997dcc8-lhkrw" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-lhkrw webserver-deployment-c7997dcc8- deployment-4487 /api/v1/namespaces/deployment-4487/pods/webserver-deployment-c7997dcc8-lhkrw 061321c4-e3ed-42a1-902e-d051c0110329 87639 0 2020-03-02 09:56:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 881bccdb-3764-473a-9ba2-fe23730debe3 0xc002eabba0 0xc002eabba1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-hbg7h,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-hbg7h,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-hbg7h,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 09:56:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 09:56:37 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 09:56:37 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 09:56:37 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.8.6,PodIP:,StartTime:2020-03-02 09:56:37 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  2 09:56:40.093: INFO: Pod "webserver-deployment-c7997dcc8-wfkp8" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-wfkp8 webserver-deployment-c7997dcc8- deployment-4487 /api/v1/namespaces/deployment-4487/pods/webserver-deployment-c7997dcc8-wfkp8 bd780fe1-0ec0-4fb7-b1e8-4bfcf82e81c5 87686 0 2020-03-02 09:56:39 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 881bccdb-3764-473a-9ba2-fe23730debe3 0xc002eabe40 0xc002eabe41}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-hbg7h,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-hbg7h,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-hbg7h,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:56:40.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4487" for this suite.
Mar  2 09:56:52.837: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:56:53.104: INFO: namespace deployment-4487 deletion completed in 12.975057197s

• [SLOW TEST:22.141 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:56:53.105: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-6963
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ConfigMap
STEP: Ensuring resource quota status captures configMap creation
STEP: Deleting a ConfigMap
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:57:10.208: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6963" for this suite.
Mar  2 09:57:16.267: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:57:16.562: INFO: namespace resourcequota-6963 deletion completed in 6.348002457s

• [SLOW TEST:23.458 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:57:16.563: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-8012
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:57:21.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8012" for this suite.
Mar  2 09:57:33.289: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:57:33.421: INFO: namespace containers-8012 deletion completed in 12.206210264s

• [SLOW TEST:16.859 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:57:33.422: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9528
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Mar  2 09:57:34.182: INFO: Waiting up to 5m0s for pod "downwardapi-volume-43e42d2f-44ce-405f-afcd-c9405bed4cba" in namespace "projected-9528" to be "success or failure"
Mar  2 09:57:34.231: INFO: Pod "downwardapi-volume-43e42d2f-44ce-405f-afcd-c9405bed4cba": Phase="Pending", Reason="", readiness=false. Elapsed: 48.518231ms
Mar  2 09:57:36.248: INFO: Pod "downwardapi-volume-43e42d2f-44ce-405f-afcd-c9405bed4cba": Phase="Pending", Reason="", readiness=false. Elapsed: 2.065582125s
Mar  2 09:57:38.254: INFO: Pod "downwardapi-volume-43e42d2f-44ce-405f-afcd-c9405bed4cba": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.072066853s
STEP: Saw pod success
Mar  2 09:57:38.254: INFO: Pod "downwardapi-volume-43e42d2f-44ce-405f-afcd-c9405bed4cba" satisfied condition "success or failure"
Mar  2 09:57:38.259: INFO: Trying to get logs from node worker1 pod downwardapi-volume-43e42d2f-44ce-405f-afcd-c9405bed4cba container client-container: <nil>
STEP: delete the pod
Mar  2 09:57:38.603: INFO: Waiting for pod downwardapi-volume-43e42d2f-44ce-405f-afcd-c9405bed4cba to disappear
Mar  2 09:57:38.619: INFO: Pod downwardapi-volume-43e42d2f-44ce-405f-afcd-c9405bed4cba no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 09:57:38.619: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9528" for this suite.
Mar  2 09:57:44.712: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 09:57:45.086: INFO: namespace projected-9528 deletion completed in 6.459816999s

• [SLOW TEST:11.664 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 09:57:45.086: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-1535
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-954e340e-85e1-49fc-94c6-ffbc99a38a9f in namespace container-probe-1535
Mar  2 09:57:49.636: INFO: Started pod liveness-954e340e-85e1-49fc-94c6-ffbc99a38a9f in namespace container-probe-1535
STEP: checking the pod's current state and verifying that restartCount is present
Mar  2 09:57:49.641: INFO: Initial restart count of pod liveness-954e340e-85e1-49fc-94c6-ffbc99a38a9f is 0
Mar  2 09:58:03.868: INFO: Restart count of pod container-probe-1535/liveness-954e340e-85e1-49fc-94c6-ffbc99a38a9f is now 1 (14.226565701s elapsed)
Mar  2 09:58:24.212: INFO: Restart count of pod container-probe-1535/liveness-954e340e-85e1-49fc-94c6-ffbc99a38a9f is now 2 (34.570583311s elapsed)
Mar  2 09:58:44.303: INFO: Restart count of pod container-probe-1535/liveness-954e340e-85e1-49fc-94c6-ffbc99a38a9f is now 3 (54.662211742s elapsed)
Mar  2 09:59:02.357: INFO: Restart count of pod container-probe-1535/liveness-954e340e-85e1-49fc-94c6-ffbc99a38a9f is now 4 (1m12.715830319s elapsed)
Mar  2 10:00:04.882: INFO: Restart count of pod container-probe-1535/liveness-954e340e-85e1-49fc-94c6-ffbc99a38a9f is now 5 (2m15.240952668s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:00:05.033: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1535" for this suite.
Mar  2 10:00:13.144: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:00:13.442: INFO: namespace container-probe-1535 deletion completed in 8.392161221s

• [SLOW TEST:148.356 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:00:13.442: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-1744
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  2 10:00:14.010: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:00:18.207: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1744" for this suite.
Mar  2 10:01:04.289: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:01:04.511: INFO: namespace pods-1744 deletion completed in 46.295719464s

• [SLOW TEST:51.068 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:01:04.511: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2862
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Mar  2 10:01:05.061: INFO: Waiting up to 5m0s for pod "downwardapi-volume-def18910-2f16-4f7f-8090-c9bc544b1813" in namespace "downward-api-2862" to be "success or failure"
Mar  2 10:01:05.140: INFO: Pod "downwardapi-volume-def18910-2f16-4f7f-8090-c9bc544b1813": Phase="Pending", Reason="", readiness=false. Elapsed: 78.85884ms
Mar  2 10:01:07.146: INFO: Pod "downwardapi-volume-def18910-2f16-4f7f-8090-c9bc544b1813": Phase="Pending", Reason="", readiness=false. Elapsed: 2.084956117s
Mar  2 10:01:09.151: INFO: Pod "downwardapi-volume-def18910-2f16-4f7f-8090-c9bc544b1813": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.090372521s
STEP: Saw pod success
Mar  2 10:01:09.151: INFO: Pod "downwardapi-volume-def18910-2f16-4f7f-8090-c9bc544b1813" satisfied condition "success or failure"
Mar  2 10:01:09.155: INFO: Trying to get logs from node worker1 pod downwardapi-volume-def18910-2f16-4f7f-8090-c9bc544b1813 container client-container: <nil>
STEP: delete the pod
Mar  2 10:01:09.296: INFO: Waiting for pod downwardapi-volume-def18910-2f16-4f7f-8090-c9bc544b1813 to disappear
Mar  2 10:01:09.301: INFO: Pod downwardapi-volume-def18910-2f16-4f7f-8090-c9bc544b1813 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:01:09.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2862" for this suite.
Mar  2 10:01:17.352: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:01:17.485: INFO: namespace downward-api-2862 deletion completed in 8.175813476s

• [SLOW TEST:12.974 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:01:17.486: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-987
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
Mar  2 10:01:19.354: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:01:19.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W0302 10:01:19.354332      24 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-987" for this suite.
Mar  2 10:01:25.422: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:01:25.659: INFO: namespace gc-987 deletion completed in 6.298350567s

• [SLOW TEST:8.174 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:01:25.660: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6758
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl replace
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1704
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image 172.20.8.7/library/httpd:2.4.38-alpine
Mar  2 10:01:26.171: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 run e2e-test-httpd-pod --generator=run-pod/v1 --image=172.20.8.7/library/httpd:2.4.38-alpine --labels=run=e2e-test-httpd-pod --namespace=kubectl-6758'
Mar  2 10:01:27.684: INFO: stderr: ""
Mar  2 10:01:27.685: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running
STEP: verifying the pod e2e-test-httpd-pod was created
Mar  2 10:01:32.735: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 get pod e2e-test-httpd-pod --namespace=kubectl-6758 -o json'
Mar  2 10:01:32.888: INFO: stderr: ""
Mar  2 10:01:32.888: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2020-03-02T10:01:27Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-6758\",\n        \"resourceVersion\": \"88689\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-6758/pods/e2e-test-httpd-pod\",\n        \"uid\": \"bf9f1a6c-6c35-4a27-84ab-8780d0a5c705\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"172.20.8.7/library/httpd:2.4.38-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-65qkt\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"worker1\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-65qkt\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-65qkt\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-03-02T10:01:27Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-03-02T10:01:29Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-03-02T10:01:29Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-03-02T10:01:27Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://27ec909b1a4b5397e8f25bed18e39a0e7afa906918fda02743e5948436bb0711\",\n                \"image\": \"172.20.8.7/library/httpd:2.4.38-alpine\",\n                \"imageID\": \"docker-pullable://172.20.8.7/library/httpd@sha256:6feb0ea7b0967367da66e8d58ba813fde32bdb92f63bfc21a9e170d211539db4\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2020-03-02T10:01:29Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"172.20.8.5\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.244.4.252\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.244.4.252\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2020-03-02T10:01:27Z\"\n    }\n}\n"
STEP: replace the image in the pod
Mar  2 10:01:32.888: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 replace -f - --namespace=kubectl-6758'
Mar  2 10:01:33.375: INFO: stderr: ""
Mar  2 10:01:33.375: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image 172.20.8.7/library/busybox:1.29
[AfterEach] Kubectl replace
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1709
Mar  2 10:01:33.400: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 delete pods e2e-test-httpd-pod --namespace=kubectl-6758'
Mar  2 10:01:42.352: INFO: stderr: ""
Mar  2 10:01:42.352: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:01:42.353: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6758" for this suite.
Mar  2 10:01:50.404: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:01:50.534: INFO: namespace kubectl-6758 deletion completed in 8.173691057s

• [SLOW TEST:24.874 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl replace
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1700
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-cli] Kubectl client Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:01:50.534: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9134
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating all guestbook components
Mar  2 10:01:50.988: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Mar  2 10:01:50.988: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 create -f - --namespace=kubectl-9134'
Mar  2 10:01:51.550: INFO: stderr: ""
Mar  2 10:01:51.550: INFO: stdout: "service/redis-slave created\n"
Mar  2 10:01:51.550: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Mar  2 10:01:51.550: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 create -f - --namespace=kubectl-9134'
Mar  2 10:01:52.364: INFO: stderr: ""
Mar  2 10:01:52.364: INFO: stdout: "service/redis-master created\n"
Mar  2 10:01:52.364: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Mar  2 10:01:52.364: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 create -f - --namespace=kubectl-9134'
Mar  2 10:01:52.936: INFO: stderr: ""
Mar  2 10:01:52.936: INFO: stdout: "service/frontend created\n"
Mar  2 10:01:52.936: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: 172.20.8.7/library/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Mar  2 10:01:52.936: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 create -f - --namespace=kubectl-9134'
Mar  2 10:01:53.471: INFO: stderr: ""
Mar  2 10:01:53.471: INFO: stdout: "deployment.apps/frontend created\n"
Mar  2 10:01:53.471: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: 172.20.8.7/library/redis:5.0.5-alpine
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Mar  2 10:01:53.471: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 create -f - --namespace=kubectl-9134'
Mar  2 10:01:54.159: INFO: stderr: ""
Mar  2 10:01:54.159: INFO: stdout: "deployment.apps/redis-master created\n"
Mar  2 10:01:54.159: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: 172.20.8.7/library/redis:5.0.5-alpine
        # We are only implementing the dns option of:
        # https://github.com/kubernetes/examples/blob/97c7ed0eb6555a4b667d2877f965d392e00abc45/guestbook/redis-slave/run.sh
        command: [ "redis-server", "--slaveof", "redis-master", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Mar  2 10:01:54.159: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 create -f - --namespace=kubectl-9134'
Mar  2 10:01:54.792: INFO: stderr: ""
Mar  2 10:01:54.792: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Mar  2 10:01:54.792: INFO: Waiting for all frontend pods to be Running.
Mar  2 10:01:59.842: INFO: Waiting for frontend to serve content.
Mar  2 10:01:59.869: INFO: Trying to add a new entry to the guestbook.
Mar  2 10:01:59.890: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Mar  2 10:01:59.915: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 delete --grace-period=0 --force -f - --namespace=kubectl-9134'
Mar  2 10:02:00.529: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  2 10:02:00.529: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Mar  2 10:02:00.530: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 delete --grace-period=0 --force -f - --namespace=kubectl-9134'
Mar  2 10:02:00.944: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  2 10:02:00.945: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Mar  2 10:02:00.945: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 delete --grace-period=0 --force -f - --namespace=kubectl-9134'
Mar  2 10:02:01.296: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  2 10:02:01.296: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Mar  2 10:02:01.297: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 delete --grace-period=0 --force -f - --namespace=kubectl-9134'
Mar  2 10:02:01.471: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  2 10:02:01.471: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Mar  2 10:02:01.472: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 delete --grace-period=0 --force -f - --namespace=kubectl-9134'
Mar  2 10:02:01.660: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  2 10:02:01.660: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Mar  2 10:02:01.660: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 delete --grace-period=0 --force -f - --namespace=kubectl-9134'
Mar  2 10:02:01.831: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  2 10:02:01.831: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:02:01.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9134" for this suite.
Mar  2 10:02:15.940: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:02:16.141: INFO: namespace kubectl-9134 deletion completed in 14.303242253s

• [SLOW TEST:25.607 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Guestbook application
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:333
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:02:16.142: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8450
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run job
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1595
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image 172.20.8.7/library/httpd:2.4.38-alpine
Mar  2 10:02:16.530: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 run e2e-test-httpd-job --restart=OnFailure --generator=job/v1 --image=172.20.8.7/library/httpd:2.4.38-alpine --namespace=kubectl-8450'
Mar  2 10:02:16.774: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Mar  2 10:02:16.774: INFO: stdout: "job.batch/e2e-test-httpd-job created\n"
STEP: verifying the job e2e-test-httpd-job was created
[AfterEach] Kubectl run job
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1600
Mar  2 10:02:16.779: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 delete jobs e2e-test-httpd-job --namespace=kubectl-8450'
Mar  2 10:02:17.141: INFO: stderr: ""
Mar  2 10:02:17.141: INFO: stdout: "job.batch \"e2e-test-httpd-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:02:17.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8450" for this suite.
Mar  2 10:02:23.213: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:02:23.448: INFO: namespace kubectl-8450 deletion completed in 6.298885237s

• [SLOW TEST:7.306 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run job
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1591
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:02:23.449: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svc-latency-5807
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating replication controller svc-latency-rc in namespace svc-latency-5807
I0302 10:02:23.999232      24 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-5807, replica count: 1
I0302 10:02:25.050038      24 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0302 10:02:26.050393      24 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0302 10:02:27.050820      24 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Mar  2 10:02:27.323: INFO: Created: latency-svc-wgjkv
Mar  2 10:02:27.328: INFO: Got endpoints: latency-svc-wgjkv [177.159151ms]
Mar  2 10:02:27.431: INFO: Created: latency-svc-rrjqg
Mar  2 10:02:27.514: INFO: Got endpoints: latency-svc-rrjqg [186.013012ms]
Mar  2 10:02:27.539: INFO: Created: latency-svc-744m4
Mar  2 10:02:27.568: INFO: Got endpoints: latency-svc-744m4 [240.127557ms]
Mar  2 10:02:27.794: INFO: Created: latency-svc-pfq76
Mar  2 10:02:27.794: INFO: Got endpoints: latency-svc-pfq76 [465.722773ms]
Mar  2 10:02:27.865: INFO: Created: latency-svc-4vwt6
Mar  2 10:02:27.899: INFO: Got endpoints: latency-svc-4vwt6 [571.103943ms]
Mar  2 10:02:28.061: INFO: Created: latency-svc-h9bc2
Mar  2 10:02:28.091: INFO: Got endpoints: latency-svc-h9bc2 [762.618583ms]
Mar  2 10:02:28.333: INFO: Created: latency-svc-tl7rq
Mar  2 10:02:28.352: INFO: Got endpoints: latency-svc-tl7rq [1.02321815s]
Mar  2 10:02:28.473: INFO: Created: latency-svc-6grv2
Mar  2 10:02:28.473: INFO: Got endpoints: latency-svc-6grv2 [1.144946726s]
Mar  2 10:02:28.628: INFO: Created: latency-svc-csd6z
Mar  2 10:02:28.713: INFO: Got endpoints: latency-svc-csd6z [1.384447577s]
Mar  2 10:02:28.818: INFO: Created: latency-svc-mklw2
Mar  2 10:02:28.894: INFO: Created: latency-svc-lkrwf
Mar  2 10:02:28.906: INFO: Got endpoints: latency-svc-lkrwf [1.576928868s]
Mar  2 10:02:28.988: INFO: Got endpoints: latency-svc-mklw2 [1.659629631s]
Mar  2 10:02:29.133: INFO: Created: latency-svc-vt7wq
Mar  2 10:02:29.166: INFO: Got endpoints: latency-svc-vt7wq [1.836856914s]
Mar  2 10:02:29.325: INFO: Created: latency-svc-rx6h6
Mar  2 10:02:29.427: INFO: Created: latency-svc-gstdb
Mar  2 10:02:29.519: INFO: Got endpoints: latency-svc-rx6h6 [2.190558301s]
Mar  2 10:02:29.524: INFO: Got endpoints: latency-svc-gstdb [2.195687958s]
Mar  2 10:02:29.692: INFO: Created: latency-svc-fbwbd
Mar  2 10:02:29.724: INFO: Got endpoints: latency-svc-fbwbd [2.395314559s]
Mar  2 10:02:29.818: INFO: Created: latency-svc-wz4pf
Mar  2 10:02:29.870: INFO: Got endpoints: latency-svc-wz4pf [2.541633153s]
Mar  2 10:02:29.924: INFO: Created: latency-svc-z6thv
Mar  2 10:02:29.966: INFO: Got endpoints: latency-svc-z6thv [2.452312934s]
Mar  2 10:02:30.073: INFO: Created: latency-svc-zqm2k
Mar  2 10:02:30.206: INFO: Got endpoints: latency-svc-zqm2k [2.637254488s]
Mar  2 10:02:30.346: INFO: Created: latency-svc-crqrc
Mar  2 10:02:30.500: INFO: Got endpoints: latency-svc-crqrc [2.706284255s]
Mar  2 10:02:30.501: INFO: Created: latency-svc-hjp8w
Mar  2 10:02:30.501: INFO: Got endpoints: latency-svc-hjp8w [2.60174329s]
Mar  2 10:02:30.552: INFO: Created: latency-svc-cfkhw
Mar  2 10:02:30.687: INFO: Got endpoints: latency-svc-cfkhw [2.595909435s]
Mar  2 10:02:30.821: INFO: Created: latency-svc-4nd26
Mar  2 10:02:30.838: INFO: Got endpoints: latency-svc-4nd26 [2.36466233s]
Mar  2 10:02:30.840: INFO: Created: latency-svc-jdxhq
Mar  2 10:02:30.840: INFO: Got endpoints: latency-svc-jdxhq [2.488773544s]
Mar  2 10:02:30.943: INFO: Created: latency-svc-mfpmm
Mar  2 10:02:31.085: INFO: Got endpoints: latency-svc-mfpmm [2.371555441s]
Mar  2 10:02:31.143: INFO: Created: latency-svc-4rwhx
Mar  2 10:02:31.207: INFO: Got endpoints: latency-svc-4rwhx [2.218393534s]
Mar  2 10:02:31.313: INFO: Created: latency-svc-498r2
Mar  2 10:02:31.313: INFO: Got endpoints: latency-svc-498r2 [2.407463746s]
Mar  2 10:02:31.418: INFO: Created: latency-svc-7tc84
Mar  2 10:02:31.487: INFO: Got endpoints: latency-svc-7tc84 [2.321590439s]
Mar  2 10:02:31.854: INFO: Created: latency-svc-9jmjq
Mar  2 10:02:31.976: INFO: Got endpoints: latency-svc-9jmjq [2.456384292s]
Mar  2 10:02:32.064: INFO: Created: latency-svc-wklx6
Mar  2 10:02:32.127: INFO: Got endpoints: latency-svc-wklx6 [2.602344399s]
Mar  2 10:02:32.258: INFO: Created: latency-svc-krw4x
Mar  2 10:02:32.293: INFO: Got endpoints: latency-svc-krw4x [2.568965422s]
Mar  2 10:02:32.536: INFO: Created: latency-svc-l8rvf
Mar  2 10:02:32.541: INFO: Created: latency-svc-zmm4k
Mar  2 10:02:32.564: INFO: Got endpoints: latency-svc-l8rvf [2.59697413s]
Mar  2 10:02:32.718: INFO: Got endpoints: latency-svc-zmm4k [2.848084684s]
Mar  2 10:02:32.806: INFO: Created: latency-svc-zbtpl
Mar  2 10:02:32.984: INFO: Got endpoints: latency-svc-zbtpl [2.777893607s]
Mar  2 10:02:33.158: INFO: Created: latency-svc-sjq86
Mar  2 10:02:33.204: INFO: Got endpoints: latency-svc-sjq86 [2.702676857s]
Mar  2 10:02:33.291: INFO: Created: latency-svc-k5wz9
Mar  2 10:02:33.362: INFO: Got endpoints: latency-svc-k5wz9 [2.861562757s]
Mar  2 10:02:33.409: INFO: Created: latency-svc-t9t6b
Mar  2 10:02:33.431: INFO: Got endpoints: latency-svc-t9t6b [2.74377648s]
Mar  2 10:02:33.583: INFO: Created: latency-svc-pslbz
Mar  2 10:02:33.633: INFO: Got endpoints: latency-svc-pslbz [2.794551694s]
Mar  2 10:02:33.678: INFO: Created: latency-svc-df52v
Mar  2 10:02:33.770: INFO: Got endpoints: latency-svc-df52v [2.929285235s]
Mar  2 10:02:33.913: INFO: Created: latency-svc-gmh46
Mar  2 10:02:34.037: INFO: Got endpoints: latency-svc-gmh46 [2.952490962s]
Mar  2 10:02:34.134: INFO: Created: latency-svc-w8bw7
Mar  2 10:02:34.187: INFO: Got endpoints: latency-svc-w8bw7 [2.980179502s]
Mar  2 10:02:34.199: INFO: Created: latency-svc-ttssd
Mar  2 10:02:34.218: INFO: Got endpoints: latency-svc-ttssd [2.90414895s]
Mar  2 10:02:34.407: INFO: Created: latency-svc-kd8q2
Mar  2 10:02:34.466: INFO: Got endpoints: latency-svc-kd8q2 [2.978315972s]
Mar  2 10:02:34.734: INFO: Created: latency-svc-z797j
Mar  2 10:02:34.734: INFO: Got endpoints: latency-svc-z797j [2.757946007s]
Mar  2 10:02:34.746: INFO: Created: latency-svc-2xv72
Mar  2 10:02:34.813: INFO: Got endpoints: latency-svc-2xv72 [2.685708164s]
Mar  2 10:02:34.890: INFO: Created: latency-svc-j44qj
Mar  2 10:02:34.927: INFO: Got endpoints: latency-svc-j44qj [2.633419639s]
Mar  2 10:02:35.147: INFO: Created: latency-svc-crbpz
Mar  2 10:02:35.189: INFO: Got endpoints: latency-svc-crbpz [2.625798795s]
Mar  2 10:02:35.195: INFO: Created: latency-svc-tz2xt
Mar  2 10:02:35.325: INFO: Got endpoints: latency-svc-tz2xt [2.606820205s]
Mar  2 10:02:35.708: INFO: Created: latency-svc-82zhb
Mar  2 10:02:35.708: INFO: Got endpoints: latency-svc-82zhb [2.724645003s]
Mar  2 10:02:35.783: INFO: Created: latency-svc-57swb
Mar  2 10:02:35.803: INFO: Got endpoints: latency-svc-57swb [2.598572663s]
Mar  2 10:02:35.813: INFO: Created: latency-svc-8wvf2
Mar  2 10:02:35.917: INFO: Got endpoints: latency-svc-8wvf2 [2.554851611s]
Mar  2 10:02:35.990: INFO: Created: latency-svc-wjcf2
Mar  2 10:02:36.101: INFO: Got endpoints: latency-svc-wjcf2 [2.670242229s]
Mar  2 10:02:36.237: INFO: Created: latency-svc-jp4js
Mar  2 10:02:36.313: INFO: Got endpoints: latency-svc-jp4js [2.679917481s]
Mar  2 10:02:36.358: INFO: Created: latency-svc-jg9d5
Mar  2 10:02:36.383: INFO: Got endpoints: latency-svc-jg9d5 [2.613529291s]
Mar  2 10:02:36.500: INFO: Created: latency-svc-cjcnq
Mar  2 10:02:36.633: INFO: Got endpoints: latency-svc-cjcnq [2.596086094s]
Mar  2 10:02:36.693: INFO: Created: latency-svc-w4k28
Mar  2 10:02:36.712: INFO: Got endpoints: latency-svc-w4k28 [2.525293967s]
Mar  2 10:02:36.794: INFO: Created: latency-svc-csnj7
Mar  2 10:02:36.855: INFO: Got endpoints: latency-svc-csnj7 [2.637242291s]
Mar  2 10:02:36.939: INFO: Created: latency-svc-jljcc
Mar  2 10:02:36.991: INFO: Got endpoints: latency-svc-jljcc [2.524943426s]
Mar  2 10:02:37.193: INFO: Created: latency-svc-56m8r
Mar  2 10:02:37.211: INFO: Got endpoints: latency-svc-56m8r [2.477092215s]
Mar  2 10:02:37.236: INFO: Created: latency-svc-fr959
Mar  2 10:02:37.256: INFO: Got endpoints: latency-svc-fr959 [2.443734047s]
Mar  2 10:02:37.777: INFO: Created: latency-svc-t2lsx
Mar  2 10:02:37.777: INFO: Got endpoints: latency-svc-t2lsx [2.850286432s]
Mar  2 10:02:37.792: INFO: Created: latency-svc-v8rd9
Mar  2 10:02:37.918: INFO: Got endpoints: latency-svc-v8rd9 [2.728679785s]
Mar  2 10:02:37.944: INFO: Created: latency-svc-bdh22
Mar  2 10:02:37.988: INFO: Got endpoints: latency-svc-bdh22 [2.662914281s]
Mar  2 10:02:38.189: INFO: Created: latency-svc-fq78c
Mar  2 10:02:38.214: INFO: Got endpoints: latency-svc-fq78c [2.505258267s]
Mar  2 10:02:38.312: INFO: Created: latency-svc-zxlv5
Mar  2 10:02:38.413: INFO: Got endpoints: latency-svc-zxlv5 [2.610519285s]
Mar  2 10:02:38.419: INFO: Created: latency-svc-gtpk9
Mar  2 10:02:38.556: INFO: Got endpoints: latency-svc-gtpk9 [2.639386549s]
Mar  2 10:02:38.795: INFO: Created: latency-svc-qpxcq
Mar  2 10:02:38.825: INFO: Got endpoints: latency-svc-qpxcq [2.723580421s]
Mar  2 10:02:39.010: INFO: Created: latency-svc-4fv2d
Mar  2 10:02:39.060: INFO: Got endpoints: latency-svc-4fv2d [2.747407428s]
Mar  2 10:02:39.100: INFO: Created: latency-svc-kzqbr
Mar  2 10:02:39.248: INFO: Got endpoints: latency-svc-kzqbr [2.864100527s]
Mar  2 10:02:39.477: INFO: Created: latency-svc-crvbg
Mar  2 10:02:39.478: INFO: Got endpoints: latency-svc-crvbg [2.844095843s]
Mar  2 10:02:39.731: INFO: Created: latency-svc-nhw8f
Mar  2 10:02:39.731: INFO: Got endpoints: latency-svc-nhw8f [3.018873807s]
Mar  2 10:02:39.883: INFO: Created: latency-svc-t4v7l
Mar  2 10:02:39.926: INFO: Got endpoints: latency-svc-t4v7l [3.070850007s]
Mar  2 10:02:40.177: INFO: Created: latency-svc-xtzq6
Mar  2 10:02:40.184: INFO: Got endpoints: latency-svc-xtzq6 [3.192825953s]
Mar  2 10:02:40.193: INFO: Created: latency-svc-5222w
Mar  2 10:02:40.468: INFO: Got endpoints: latency-svc-5222w [3.256821329s]
Mar  2 10:02:40.581: INFO: Created: latency-svc-dwjb8
Mar  2 10:02:40.592: INFO: Got endpoints: latency-svc-dwjb8 [3.335814128s]
Mar  2 10:02:41.023: INFO: Created: latency-svc-tskz8
Mar  2 10:02:41.048: INFO: Got endpoints: latency-svc-tskz8 [3.271461991s]
Mar  2 10:02:41.051: INFO: Created: latency-svc-mxnrz
Mar  2 10:02:41.162: INFO: Created: latency-svc-n6f66
Mar  2 10:02:41.168: INFO: Got endpoints: latency-svc-mxnrz [3.249293762s]
Mar  2 10:02:41.185: INFO: Got endpoints: latency-svc-n6f66 [3.197169526s]
Mar  2 10:02:41.410: INFO: Created: latency-svc-jr9nq
Mar  2 10:02:41.444: INFO: Got endpoints: latency-svc-jr9nq [3.229903983s]
Mar  2 10:02:41.518: INFO: Created: latency-svc-prkms
Mar  2 10:02:41.605: INFO: Created: latency-svc-pzzj5
Mar  2 10:02:41.668: INFO: Got endpoints: latency-svc-pzzj5 [3.111644373s]
Mar  2 10:02:41.696: INFO: Got endpoints: latency-svc-prkms [3.282673927s]
Mar  2 10:02:42.025: INFO: Created: latency-svc-jlrhc
Mar  2 10:02:42.025: INFO: Got endpoints: latency-svc-jlrhc [3.200138218s]
Mar  2 10:02:42.111: INFO: Created: latency-svc-zxgdq
Mar  2 10:02:42.116: INFO: Got endpoints: latency-svc-zxgdq [3.055812474s]
Mar  2 10:02:42.190: INFO: Created: latency-svc-87ncg
Mar  2 10:02:42.330: INFO: Got endpoints: latency-svc-87ncg [3.082322745s]
Mar  2 10:02:42.479: INFO: Created: latency-svc-n2lcz
Mar  2 10:02:42.541: INFO: Got endpoints: latency-svc-n2lcz [3.063370824s]
Mar  2 10:02:42.560: INFO: Created: latency-svc-dgn6l
Mar  2 10:02:42.776: INFO: Created: latency-svc-vn5k7
Mar  2 10:02:42.800: INFO: Got endpoints: latency-svc-dgn6l [3.068666642s]
Mar  2 10:02:42.888: INFO: Got endpoints: latency-svc-vn5k7 [2.962538997s]
Mar  2 10:02:43.060: INFO: Created: latency-svc-l26p5
Mar  2 10:02:43.067: INFO: Got endpoints: latency-svc-l26p5 [2.883521097s]
Mar  2 10:02:43.270: INFO: Created: latency-svc-jlnpn
Mar  2 10:02:43.527: INFO: Got endpoints: latency-svc-jlnpn [3.059264035s]
Mar  2 10:02:43.565: INFO: Created: latency-svc-fhb45
Mar  2 10:02:43.598: INFO: Got endpoints: latency-svc-fhb45 [3.005797023s]
Mar  2 10:02:43.928: INFO: Created: latency-svc-j4cdj
Mar  2 10:02:43.928: INFO: Got endpoints: latency-svc-j4cdj [2.879422391s]
Mar  2 10:02:43.948: INFO: Created: latency-svc-4cr7r
Mar  2 10:02:44.006: INFO: Got endpoints: latency-svc-4cr7r [2.838490916s]
Mar  2 10:02:44.019: INFO: Created: latency-svc-2fg5m
Mar  2 10:02:44.031: INFO: Got endpoints: latency-svc-2fg5m [2.846406221s]
Mar  2 10:02:44.405: INFO: Created: latency-svc-fvgsn
Mar  2 10:02:44.518: INFO: Got endpoints: latency-svc-fvgsn [3.074718739s]
Mar  2 10:02:44.519: INFO: Created: latency-svc-4kmmc
Mar  2 10:02:44.570: INFO: Got endpoints: latency-svc-4kmmc [2.902117938s]
Mar  2 10:02:44.648: INFO: Created: latency-svc-r9zb8
Mar  2 10:02:44.663: INFO: Got endpoints: latency-svc-r9zb8 [2.967224288s]
Mar  2 10:02:44.890: INFO: Created: latency-svc-6sntf
Mar  2 10:02:44.950: INFO: Got endpoints: latency-svc-6sntf [2.925375252s]
Mar  2 10:02:45.081: INFO: Created: latency-svc-g9tm2
Mar  2 10:02:45.127: INFO: Created: latency-svc-hd726
Mar  2 10:02:45.155: INFO: Got endpoints: latency-svc-hd726 [2.825297344s]
Mar  2 10:02:45.269: INFO: Got endpoints: latency-svc-g9tm2 [3.152641762s]
Mar  2 10:02:45.442: INFO: Created: latency-svc-lxhlg
Mar  2 10:02:45.515: INFO: Got endpoints: latency-svc-lxhlg [2.973773438s]
Mar  2 10:02:45.963: INFO: Created: latency-svc-vfntf
Mar  2 10:02:46.114: INFO: Got endpoints: latency-svc-vfntf [3.31385421s]
Mar  2 10:02:46.115: INFO: Created: latency-svc-4f5kz
Mar  2 10:02:46.130: INFO: Got endpoints: latency-svc-4f5kz [3.24175682s]
Mar  2 10:02:46.599: INFO: Created: latency-svc-tfq5j
Mar  2 10:02:46.722: INFO: Got endpoints: latency-svc-tfq5j [3.654777788s]
Mar  2 10:02:46.739: INFO: Created: latency-svc-r262w
Mar  2 10:02:46.868: INFO: Got endpoints: latency-svc-r262w [3.340950061s]
Mar  2 10:02:46.899: INFO: Created: latency-svc-5mxph
Mar  2 10:02:46.916: INFO: Got endpoints: latency-svc-5mxph [3.318002407s]
Mar  2 10:02:47.236: INFO: Created: latency-svc-844dn
Mar  2 10:02:47.273: INFO: Got endpoints: latency-svc-844dn [3.345257656s]
Mar  2 10:02:47.274: INFO: Created: latency-svc-fbh2x
Mar  2 10:02:47.339: INFO: Got endpoints: latency-svc-fbh2x [3.332374752s]
Mar  2 10:02:47.495: INFO: Created: latency-svc-9bfwk
Mar  2 10:02:47.502: INFO: Got endpoints: latency-svc-9bfwk [3.47021389s]
Mar  2 10:02:47.737: INFO: Created: latency-svc-88fzv
Mar  2 10:02:47.944: INFO: Got endpoints: latency-svc-88fzv [3.425370284s]
Mar  2 10:02:47.978: INFO: Created: latency-svc-j7l8d
Mar  2 10:02:48.047: INFO: Got endpoints: latency-svc-j7l8d [3.476472149s]
Mar  2 10:02:48.114: INFO: Created: latency-svc-vw94j
Mar  2 10:02:48.115: INFO: Got endpoints: latency-svc-vw94j [3.451374334s]
Mar  2 10:02:48.196: INFO: Created: latency-svc-cbbbl
Mar  2 10:02:48.305: INFO: Got endpoints: latency-svc-cbbbl [3.354497494s]
Mar  2 10:02:48.371: INFO: Created: latency-svc-qjtd7
Mar  2 10:02:48.432: INFO: Got endpoints: latency-svc-qjtd7 [3.277096447s]
Mar  2 10:02:48.592: INFO: Created: latency-svc-g7h6w
Mar  2 10:02:48.615: INFO: Got endpoints: latency-svc-g7h6w [3.346310245s]
Mar  2 10:02:48.674: INFO: Created: latency-svc-9q2tg
Mar  2 10:02:48.824: INFO: Got endpoints: latency-svc-9q2tg [3.308729985s]
Mar  2 10:02:48.967: INFO: Created: latency-svc-44mmh
Mar  2 10:02:48.991: INFO: Got endpoints: latency-svc-44mmh [2.877069451s]
Mar  2 10:02:49.108: INFO: Created: latency-svc-mxc6k
Mar  2 10:02:49.132: INFO: Got endpoints: latency-svc-mxc6k [3.001482056s]
Mar  2 10:02:49.211: INFO: Created: latency-svc-rxl7d
Mar  2 10:02:49.474: INFO: Got endpoints: latency-svc-rxl7d [2.751572371s]
Mar  2 10:02:49.603: INFO: Created: latency-svc-q7wbn
Mar  2 10:02:49.704: INFO: Got endpoints: latency-svc-q7wbn [2.835831123s]
Mar  2 10:02:49.776: INFO: Created: latency-svc-r95bp
Mar  2 10:02:49.786: INFO: Got endpoints: latency-svc-r95bp [2.869347907s]
Mar  2 10:02:49.905: INFO: Created: latency-svc-wbfvh
Mar  2 10:02:49.927: INFO: Got endpoints: latency-svc-wbfvh [2.653962946s]
Mar  2 10:02:50.154: INFO: Created: latency-svc-pxl27
Mar  2 10:02:50.214: INFO: Got endpoints: latency-svc-pxl27 [2.87552069s]
Mar  2 10:02:50.354: INFO: Created: latency-svc-8x49l
Mar  2 10:02:50.355: INFO: Got endpoints: latency-svc-8x49l [2.852688431s]
Mar  2 10:02:50.483: INFO: Created: latency-svc-ngwpt
Mar  2 10:02:50.487: INFO: Got endpoints: latency-svc-ngwpt [2.543062216s]
Mar  2 10:02:50.829: INFO: Created: latency-svc-qzvf8
Mar  2 10:02:50.890: INFO: Got endpoints: latency-svc-qzvf8 [2.8428043s]
Mar  2 10:02:51.022: INFO: Created: latency-svc-jgnx9
Mar  2 10:02:51.054: INFO: Got endpoints: latency-svc-jgnx9 [2.939648302s]
Mar  2 10:02:51.116: INFO: Created: latency-svc-kcsc9
Mar  2 10:02:51.278: INFO: Got endpoints: latency-svc-kcsc9 [2.972722786s]
Mar  2 10:02:51.332: INFO: Created: latency-svc-r7gzn
Mar  2 10:02:51.414: INFO: Got endpoints: latency-svc-r7gzn [2.981447495s]
Mar  2 10:02:51.493: INFO: Created: latency-svc-dd9g6
Mar  2 10:02:51.559: INFO: Got endpoints: latency-svc-dd9g6 [2.943157566s]
Mar  2 10:02:51.604: INFO: Created: latency-svc-xtj2m
Mar  2 10:02:51.641: INFO: Got endpoints: latency-svc-xtj2m [2.817566369s]
Mar  2 10:02:51.905: INFO: Created: latency-svc-kprnv
Mar  2 10:02:51.976: INFO: Created: latency-svc-8bl4f
Mar  2 10:02:51.976: INFO: Got endpoints: latency-svc-8bl4f [2.984599521s]
Mar  2 10:02:52.039: INFO: Got endpoints: latency-svc-kprnv [2.906602744s]
Mar  2 10:02:52.190: INFO: Created: latency-svc-kh8g9
Mar  2 10:02:52.211: INFO: Got endpoints: latency-svc-kh8g9 [2.737385736s]
Mar  2 10:02:52.492: INFO: Created: latency-svc-g7hzd
Mar  2 10:02:52.525: INFO: Got endpoints: latency-svc-g7hzd [2.820781729s]
Mar  2 10:02:52.749: INFO: Created: latency-svc-l8vkb
Mar  2 10:02:52.760: INFO: Created: latency-svc-d2t9r
Mar  2 10:02:52.797: INFO: Got endpoints: latency-svc-d2t9r [2.869944491s]
Mar  2 10:02:52.957: INFO: Got endpoints: latency-svc-l8vkb [3.170700369s]
Mar  2 10:02:53.075: INFO: Created: latency-svc-r6jlj
Mar  2 10:02:53.118: INFO: Got endpoints: latency-svc-r6jlj [2.903321707s]
Mar  2 10:02:53.243: INFO: Created: latency-svc-vkll9
Mar  2 10:02:53.292: INFO: Got endpoints: latency-svc-vkll9 [2.937897831s]
Mar  2 10:02:53.420: INFO: Created: latency-svc-ddzkq
Mar  2 10:02:53.475: INFO: Got endpoints: latency-svc-ddzkq [2.987663898s]
Mar  2 10:02:53.516: INFO: Created: latency-svc-k2pc9
Mar  2 10:02:53.543: INFO: Got endpoints: latency-svc-k2pc9 [2.65331059s]
Mar  2 10:02:53.675: INFO: Created: latency-svc-sr4pj
Mar  2 10:02:53.720: INFO: Got endpoints: latency-svc-sr4pj [2.665409648s]
Mar  2 10:02:53.860: INFO: Created: latency-svc-wcgj4
Mar  2 10:02:53.876: INFO: Got endpoints: latency-svc-wcgj4 [2.598588088s]
Mar  2 10:02:54.130: INFO: Created: latency-svc-qqb8z
Mar  2 10:02:54.130: INFO: Got endpoints: latency-svc-qqb8z [2.716174143s]
Mar  2 10:02:54.161: INFO: Created: latency-svc-btk7d
Mar  2 10:02:54.283: INFO: Got endpoints: latency-svc-btk7d [2.724869754s]
Mar  2 10:02:54.406: INFO: Created: latency-svc-nnjsf
Mar  2 10:02:54.421: INFO: Got endpoints: latency-svc-nnjsf [2.780140023s]
Mar  2 10:02:54.655: INFO: Created: latency-svc-mbfcq
Mar  2 10:02:54.716: INFO: Got endpoints: latency-svc-mbfcq [2.740017183s]
Mar  2 10:02:54.785: INFO: Created: latency-svc-zknd7
Mar  2 10:02:54.797: INFO: Got endpoints: latency-svc-zknd7 [2.758015389s]
Mar  2 10:02:54.938: INFO: Created: latency-svc-hdc8p
Mar  2 10:02:55.051: INFO: Got endpoints: latency-svc-hdc8p [2.839079091s]
Mar  2 10:02:55.133: INFO: Created: latency-svc-zblzt
Mar  2 10:02:55.241: INFO: Got endpoints: latency-svc-zblzt [2.716578817s]
Mar  2 10:02:55.256: INFO: Created: latency-svc-9k759
Mar  2 10:02:55.299: INFO: Got endpoints: latency-svc-9k759 [2.501375921s]
Mar  2 10:02:55.383: INFO: Created: latency-svc-624lw
Mar  2 10:02:55.519: INFO: Got endpoints: latency-svc-624lw [2.56193257s]
Mar  2 10:02:55.581: INFO: Created: latency-svc-mjt6z
Mar  2 10:02:55.662: INFO: Got endpoints: latency-svc-mjt6z [2.543951844s]
Mar  2 10:02:55.685: INFO: Created: latency-svc-ft6ld
Mar  2 10:02:55.701: INFO: Got endpoints: latency-svc-ft6ld [2.408340188s]
Mar  2 10:02:55.822: INFO: Created: latency-svc-fqw5h
Mar  2 10:02:55.993: INFO: Got endpoints: latency-svc-fqw5h [2.517895531s]
Mar  2 10:02:56.079: INFO: Created: latency-svc-n5llz
Mar  2 10:02:56.080: INFO: Got endpoints: latency-svc-n5llz [2.536459066s]
Mar  2 10:02:56.133: INFO: Created: latency-svc-k9vjj
Mar  2 10:02:56.142: INFO: Got endpoints: latency-svc-k9vjj [2.421804314s]
Mar  2 10:02:56.236: INFO: Created: latency-svc-gcx4g
Mar  2 10:02:56.475: INFO: Got endpoints: latency-svc-gcx4g [2.598614783s]
Mar  2 10:02:56.563: INFO: Created: latency-svc-sct2q
Mar  2 10:02:56.641: INFO: Got endpoints: latency-svc-sct2q [2.510964002s]
Mar  2 10:02:56.673: INFO: Created: latency-svc-8fgtm
Mar  2 10:02:56.690: INFO: Got endpoints: latency-svc-8fgtm [2.405996593s]
Mar  2 10:02:56.810: INFO: Created: latency-svc-4psp9
Mar  2 10:02:56.958: INFO: Got endpoints: latency-svc-4psp9 [2.536292568s]
Mar  2 10:02:57.183: INFO: Created: latency-svc-85jzq
Mar  2 10:02:57.188: INFO: Created: latency-svc-r6vq9
Mar  2 10:02:57.196: INFO: Got endpoints: latency-svc-85jzq [2.398983415s]
Mar  2 10:02:57.260: INFO: Got endpoints: latency-svc-r6vq9 [2.544105108s]
Mar  2 10:02:57.438: INFO: Created: latency-svc-d8zlx
Mar  2 10:02:57.477: INFO: Got endpoints: latency-svc-d8zlx [2.426479736s]
Mar  2 10:02:57.497: INFO: Created: latency-svc-2sxpl
Mar  2 10:02:57.600: INFO: Created: latency-svc-829tl
Mar  2 10:02:57.616: INFO: Got endpoints: latency-svc-829tl [2.317498629s]
Mar  2 10:02:57.642: INFO: Got endpoints: latency-svc-2sxpl [2.400880375s]
Mar  2 10:02:57.864: INFO: Created: latency-svc-9pt6z
Mar  2 10:02:57.985: INFO: Got endpoints: latency-svc-9pt6z [2.466807759s]
Mar  2 10:02:58.038: INFO: Created: latency-svc-9nkmw
Mar  2 10:02:58.077: INFO: Got endpoints: latency-svc-9nkmw [2.415754794s]
Mar  2 10:02:58.110: INFO: Created: latency-svc-v8xv2
Mar  2 10:02:58.124: INFO: Got endpoints: latency-svc-v8xv2 [2.42314349s]
Mar  2 10:02:58.421: INFO: Created: latency-svc-dmfbj
Mar  2 10:02:58.459: INFO: Got endpoints: latency-svc-dmfbj [2.466291348s]
Mar  2 10:02:58.461: INFO: Created: latency-svc-snqcd
Mar  2 10:02:58.496: INFO: Got endpoints: latency-svc-snqcd [2.416101041s]
Mar  2 10:02:58.569: INFO: Created: latency-svc-v6wsj
Mar  2 10:02:58.589: INFO: Got endpoints: latency-svc-v6wsj [2.447224993s]
Mar  2 10:02:58.831: INFO: Created: latency-svc-gpxbc
Mar  2 10:02:58.869: INFO: Got endpoints: latency-svc-gpxbc [2.39362273s]
Mar  2 10:02:58.954: INFO: Created: latency-svc-6kjmt
Mar  2 10:02:59.042: INFO: Created: latency-svc-f8zzd
Mar  2 10:02:59.042: INFO: Got endpoints: latency-svc-6kjmt [2.400921829s]
Mar  2 10:02:59.076: INFO: Got endpoints: latency-svc-f8zzd [2.386875429s]
Mar  2 10:02:59.279: INFO: Created: latency-svc-mpdp8
Mar  2 10:02:59.298: INFO: Got endpoints: latency-svc-mpdp8 [2.339534696s]
Mar  2 10:02:59.344: INFO: Created: latency-svc-62spg
Mar  2 10:02:59.411: INFO: Got endpoints: latency-svc-62spg [2.215336123s]
Mar  2 10:02:59.489: INFO: Created: latency-svc-4k92l
Mar  2 10:02:59.511: INFO: Got endpoints: latency-svc-4k92l [2.250967002s]
Mar  2 10:02:59.808: INFO: Created: latency-svc-p54zs
Mar  2 10:02:59.901: INFO: Got endpoints: latency-svc-p54zs [2.423976889s]
Mar  2 10:02:59.983: INFO: Created: latency-svc-5ldhk
Mar  2 10:03:00.062: INFO: Got endpoints: latency-svc-5ldhk [2.445799417s]
Mar  2 10:03:00.064: INFO: Created: latency-svc-mm69d
Mar  2 10:03:00.213: INFO: Got endpoints: latency-svc-mm69d [2.570960864s]
Mar  2 10:03:00.346: INFO: Created: latency-svc-rpnj2
Mar  2 10:03:00.358: INFO: Got endpoints: latency-svc-rpnj2 [2.371991457s]
Mar  2 10:03:00.533: INFO: Created: latency-svc-7wxw5
Mar  2 10:03:00.564: INFO: Got endpoints: latency-svc-7wxw5 [2.486505632s]
Mar  2 10:03:00.631: INFO: Created: latency-svc-qdrmd
Mar  2 10:03:00.779: INFO: Got endpoints: latency-svc-qdrmd [2.655071866s]
Mar  2 10:03:00.948: INFO: Created: latency-svc-fpckw
Mar  2 10:03:00.948: INFO: Got endpoints: latency-svc-fpckw [2.489236006s]
Mar  2 10:03:01.066: INFO: Created: latency-svc-rj2v7
Mar  2 10:03:01.124: INFO: Got endpoints: latency-svc-rj2v7 [2.628109837s]
Mar  2 10:03:01.177: INFO: Created: latency-svc-b2ln8
Mar  2 10:03:01.236: INFO: Got endpoints: latency-svc-b2ln8 [2.646614545s]
Mar  2 10:03:01.433: INFO: Created: latency-svc-w5dqf
Mar  2 10:03:01.482: INFO: Got endpoints: latency-svc-w5dqf [2.612936038s]
Mar  2 10:03:01.500: INFO: Created: latency-svc-pmpbq
Mar  2 10:03:01.541: INFO: Created: latency-svc-rbnjd
Mar  2 10:03:01.612: INFO: Got endpoints: latency-svc-rbnjd [2.535589944s]
Mar  2 10:03:01.666: INFO: Got endpoints: latency-svc-pmpbq [2.623825816s]
Mar  2 10:03:01.989: INFO: Created: latency-svc-hj92z
Mar  2 10:03:02.001: INFO: Got endpoints: latency-svc-hj92z [2.70364812s]
Mar  2 10:03:02.071: INFO: Created: latency-svc-pgjc2
Mar  2 10:03:02.152: INFO: Got endpoints: latency-svc-pgjc2 [2.740812151s]
Mar  2 10:03:02.203: INFO: Created: latency-svc-pdnkt
Mar  2 10:03:02.275: INFO: Got endpoints: latency-svc-pdnkt [2.763698582s]
Mar  2 10:03:02.474: INFO: Created: latency-svc-tdbkg
Mar  2 10:03:02.504: INFO: Got endpoints: latency-svc-tdbkg [2.603236926s]
Mar  2 10:03:02.538: INFO: Created: latency-svc-tlgrp
Mar  2 10:03:02.631: INFO: Created: latency-svc-7m2jt
Mar  2 10:03:02.648: INFO: Got endpoints: latency-svc-tlgrp [2.585162264s]
Mar  2 10:03:02.669: INFO: Got endpoints: latency-svc-7m2jt [2.455522884s]
Mar  2 10:03:02.857: INFO: Created: latency-svc-4rpdk
Mar  2 10:03:02.861: INFO: Got endpoints: latency-svc-4rpdk [2.503758791s]
Mar  2 10:03:02.949: INFO: Created: latency-svc-2zhqd
Mar  2 10:03:03.038: INFO: Got endpoints: latency-svc-2zhqd [2.473551864s]
Mar  2 10:03:03.054: INFO: Created: latency-svc-sj2sj
Mar  2 10:03:03.099: INFO: Got endpoints: latency-svc-sj2sj [2.31997908s]
Mar  2 10:03:03.404: INFO: Created: latency-svc-hv5fr
Mar  2 10:03:03.505: INFO: Got endpoints: latency-svc-hv5fr [2.557008229s]
Mar  2 10:03:03.552: INFO: Created: latency-svc-7k6z5
Mar  2 10:03:03.677: INFO: Got endpoints: latency-svc-7k6z5 [2.552980031s]
Mar  2 10:03:03.677: INFO: Created: latency-svc-bb72j
Mar  2 10:03:03.714: INFO: Got endpoints: latency-svc-bb72j [2.478402041s]
Mar  2 10:03:03.967: INFO: Created: latency-svc-2vhtw
Mar  2 10:03:03.980: INFO: Got endpoints: latency-svc-2vhtw [2.497810651s]
Mar  2 10:03:03.980: INFO: Latencies: [186.013012ms 240.127557ms 465.722773ms 571.103943ms 762.618583ms 1.02321815s 1.144946726s 1.384447577s 1.576928868s 1.659629631s 1.836856914s 2.190558301s 2.195687958s 2.215336123s 2.218393534s 2.250967002s 2.317498629s 2.31997908s 2.321590439s 2.339534696s 2.36466233s 2.371555441s 2.371991457s 2.386875429s 2.39362273s 2.395314559s 2.398983415s 2.400880375s 2.400921829s 2.405996593s 2.407463746s 2.408340188s 2.415754794s 2.416101041s 2.421804314s 2.42314349s 2.423976889s 2.426479736s 2.443734047s 2.445799417s 2.447224993s 2.452312934s 2.455522884s 2.456384292s 2.466291348s 2.466807759s 2.473551864s 2.477092215s 2.478402041s 2.486505632s 2.488773544s 2.489236006s 2.497810651s 2.501375921s 2.503758791s 2.505258267s 2.510964002s 2.517895531s 2.524943426s 2.525293967s 2.535589944s 2.536292568s 2.536459066s 2.541633153s 2.543062216s 2.543951844s 2.544105108s 2.552980031s 2.554851611s 2.557008229s 2.56193257s 2.568965422s 2.570960864s 2.585162264s 2.595909435s 2.596086094s 2.59697413s 2.598572663s 2.598588088s 2.598614783s 2.60174329s 2.602344399s 2.603236926s 2.606820205s 2.610519285s 2.612936038s 2.613529291s 2.623825816s 2.625798795s 2.628109837s 2.633419639s 2.637242291s 2.637254488s 2.639386549s 2.646614545s 2.65331059s 2.653962946s 2.655071866s 2.662914281s 2.665409648s 2.670242229s 2.679917481s 2.685708164s 2.702676857s 2.70364812s 2.706284255s 2.716174143s 2.716578817s 2.723580421s 2.724645003s 2.724869754s 2.728679785s 2.737385736s 2.740017183s 2.740812151s 2.74377648s 2.747407428s 2.751572371s 2.757946007s 2.758015389s 2.763698582s 2.777893607s 2.780140023s 2.794551694s 2.817566369s 2.820781729s 2.825297344s 2.835831123s 2.838490916s 2.839079091s 2.8428043s 2.844095843s 2.846406221s 2.848084684s 2.850286432s 2.852688431s 2.861562757s 2.864100527s 2.869347907s 2.869944491s 2.87552069s 2.877069451s 2.879422391s 2.883521097s 2.902117938s 2.903321707s 2.90414895s 2.906602744s 2.925375252s 2.929285235s 2.937897831s 2.939648302s 2.943157566s 2.952490962s 2.962538997s 2.967224288s 2.972722786s 2.973773438s 2.978315972s 2.980179502s 2.981447495s 2.984599521s 2.987663898s 3.001482056s 3.005797023s 3.018873807s 3.055812474s 3.059264035s 3.063370824s 3.068666642s 3.070850007s 3.074718739s 3.082322745s 3.111644373s 3.152641762s 3.170700369s 3.192825953s 3.197169526s 3.200138218s 3.229903983s 3.24175682s 3.249293762s 3.256821329s 3.271461991s 3.277096447s 3.282673927s 3.308729985s 3.31385421s 3.318002407s 3.332374752s 3.335814128s 3.340950061s 3.345257656s 3.346310245s 3.354497494s 3.425370284s 3.451374334s 3.47021389s 3.476472149s 3.654777788s]
Mar  2 10:03:03.980: INFO: 50 %ile: 2.670242229s
Mar  2 10:03:03.980: INFO: 90 %ile: 3.24175682s
Mar  2 10:03:03.980: INFO: 99 %ile: 3.476472149s
Mar  2 10:03:03.980: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:03:03.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-5807" for this suite.
Mar  2 10:04:10.096: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:04:10.407: INFO: namespace svc-latency-5807 deletion completed in 1m6.416869448s

• [SLOW TEST:106.958 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:04:10.407: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-4022
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  2 10:04:10.722: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Mar  2 10:04:20.180: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 --namespace=crd-publish-openapi-4022 create -f -'
Mar  2 10:04:21.933: INFO: stderr: ""
Mar  2 10:04:21.934: INFO: stdout: "e2e-test-crd-publish-openapi-3194-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Mar  2 10:04:21.934: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 --namespace=crd-publish-openapi-4022 delete e2e-test-crd-publish-openapi-3194-crds test-cr'
Mar  2 10:04:22.261: INFO: stderr: ""
Mar  2 10:04:22.261: INFO: stdout: "e2e-test-crd-publish-openapi-3194-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Mar  2 10:04:22.261: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 --namespace=crd-publish-openapi-4022 apply -f -'
Mar  2 10:04:22.909: INFO: stderr: ""
Mar  2 10:04:22.909: INFO: stdout: "e2e-test-crd-publish-openapi-3194-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Mar  2 10:04:22.909: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 --namespace=crd-publish-openapi-4022 delete e2e-test-crd-publish-openapi-3194-crds test-cr'
Mar  2 10:04:23.199: INFO: stderr: ""
Mar  2 10:04:23.199: INFO: stdout: "e2e-test-crd-publish-openapi-3194-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Mar  2 10:04:23.200: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 explain e2e-test-crd-publish-openapi-3194-crds'
Mar  2 10:04:23.611: INFO: stderr: ""
Mar  2 10:04:23.611: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-3194-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<map[string]>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:04:28.240: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4022" for this suite.
Mar  2 10:04:34.285: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:04:34.587: INFO: namespace crd-publish-openapi-4022 deletion completed in 6.339989158s

• [SLOW TEST:24.180 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:04:34.588: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-7949
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-7949, will wait for the garbage collector to delete the pods
Mar  2 10:04:39.145: INFO: Deleting Job.batch foo took: 48.007792ms
Mar  2 10:04:39.745: INFO: Terminating Job.batch foo pods took: 600.458883ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:05:13.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-7949" for this suite.
Mar  2 10:05:21.240: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:05:21.424: INFO: namespace job-7949 deletion completed in 8.240955876s

• [SLOW TEST:46.836 seconds]
[sig-apps] Job
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:05:21.424: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-2572
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service multi-endpoint-test in namespace services-2572
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2572 to expose endpoints map[]
Mar  2 10:05:21.940: INFO: Get endpoints failed (3.959169ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Mar  2 10:05:22.960: INFO: successfully validated that service multi-endpoint-test in namespace services-2572 exposes endpoints map[] (1.024050291s elapsed)
STEP: Creating pod pod1 in namespace services-2572
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2572 to expose endpoints map[pod1:[100]]
Mar  2 10:05:26.147: INFO: successfully validated that service multi-endpoint-test in namespace services-2572 exposes endpoints map[pod1:[100]] (3.136191709s elapsed)
STEP: Creating pod pod2 in namespace services-2572
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2572 to expose endpoints map[pod1:[100] pod2:[101]]
Mar  2 10:05:30.468: INFO: successfully validated that service multi-endpoint-test in namespace services-2572 exposes endpoints map[pod1:[100] pod2:[101]] (4.292449968s elapsed)
STEP: Deleting pod pod1 in namespace services-2572
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2572 to expose endpoints map[pod2:[101]]
Mar  2 10:05:31.558: INFO: successfully validated that service multi-endpoint-test in namespace services-2572 exposes endpoints map[pod2:[101]] (1.06398209s elapsed)
STEP: Deleting pod pod2 in namespace services-2572
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-2572 to expose endpoints map[]
Mar  2 10:05:31.610: INFO: successfully validated that service multi-endpoint-test in namespace services-2572 exposes endpoints map[] (17.871639ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:05:32.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2572" for this suite.
Mar  2 10:05:40.321: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:05:40.445: INFO: namespace services-2572 deletion completed in 8.347923395s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:19.021 seconds]
[sig-network] Services
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:05:40.445: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-5999
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:05:47.173: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-5999" for this suite.
Mar  2 10:05:53.250: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:05:53.572: INFO: namespace watch-5999 deletion completed in 6.391381181s

• [SLOW TEST:13.127 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:05:53.572: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3266
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Mar  2 10:05:54.053: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c5e9d69b-3f92-405b-81f3-a1b7f127641f" in namespace "downward-api-3266" to be "success or failure"
Mar  2 10:05:54.058: INFO: Pod "downwardapi-volume-c5e9d69b-3f92-405b-81f3-a1b7f127641f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.934454ms
Mar  2 10:05:56.067: INFO: Pod "downwardapi-volume-c5e9d69b-3f92-405b-81f3-a1b7f127641f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014653939s
Mar  2 10:05:58.075: INFO: Pod "downwardapi-volume-c5e9d69b-3f92-405b-81f3-a1b7f127641f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022685776s
STEP: Saw pod success
Mar  2 10:05:58.075: INFO: Pod "downwardapi-volume-c5e9d69b-3f92-405b-81f3-a1b7f127641f" satisfied condition "success or failure"
Mar  2 10:05:58.081: INFO: Trying to get logs from node worker1 pod downwardapi-volume-c5e9d69b-3f92-405b-81f3-a1b7f127641f container client-container: <nil>
STEP: delete the pod
Mar  2 10:05:58.184: INFO: Waiting for pod downwardapi-volume-c5e9d69b-3f92-405b-81f3-a1b7f127641f to disappear
Mar  2 10:05:58.190: INFO: Pod downwardapi-volume-c5e9d69b-3f92-405b-81f3-a1b7f127641f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:05:58.190: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3266" for this suite.
Mar  2 10:06:06.279: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:06:06.568: INFO: namespace downward-api-3266 deletion completed in 8.371376377s

• [SLOW TEST:12.996 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:06:06.569: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-6075
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar  2 10:06:07.484: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Mar  2 10:06:09.563: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718740367, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718740367, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718740367, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718740367, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7794d7ccd5\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar  2 10:06:12.762: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a validating webhook configuration
Mar  2 10:06:13.004: INFO: Waiting for webhook configuration to be ready...
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Updating a validating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Patching a validating webhook configuration's rules to include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:06:13.754: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6075" for this suite.
Mar  2 10:06:21.894: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:06:22.031: INFO: namespace webhook-6075 deletion completed in 8.2512252s
STEP: Destroying namespace "webhook-6075-markers" for this suite.
Mar  2 10:06:28.078: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:06:28.264: INFO: namespace webhook-6075-markers deletion completed in 6.232472681s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:21.729 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:06:28.298: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-4241
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:06:35.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4241" for this suite.
Mar  2 10:06:41.894: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:06:42.037: INFO: namespace resourcequota-4241 deletion completed in 6.18921919s

• [SLOW TEST:13.740 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:06:42.038: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8505
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-d18b491a-10fb-484b-914d-5ae903935561
STEP: Creating a pod to test consume configMaps
Mar  2 10:06:42.504: INFO: Waiting up to 5m0s for pod "pod-configmaps-a2b11111-ad92-4995-b68f-7c41aa34b6a1" in namespace "configmap-8505" to be "success or failure"
Mar  2 10:06:42.509: INFO: Pod "pod-configmaps-a2b11111-ad92-4995-b68f-7c41aa34b6a1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.789353ms
Mar  2 10:06:44.513: INFO: Pod "pod-configmaps-a2b11111-ad92-4995-b68f-7c41aa34b6a1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008859064s
Mar  2 10:06:46.518: INFO: Pod "pod-configmaps-a2b11111-ad92-4995-b68f-7c41aa34b6a1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013926696s
STEP: Saw pod success
Mar  2 10:06:46.518: INFO: Pod "pod-configmaps-a2b11111-ad92-4995-b68f-7c41aa34b6a1" satisfied condition "success or failure"
Mar  2 10:06:46.525: INFO: Trying to get logs from node worker1 pod pod-configmaps-a2b11111-ad92-4995-b68f-7c41aa34b6a1 container configmap-volume-test: <nil>
STEP: delete the pod
Mar  2 10:06:46.705: INFO: Waiting for pod pod-configmaps-a2b11111-ad92-4995-b68f-7c41aa34b6a1 to disappear
Mar  2 10:06:46.709: INFO: Pod pod-configmaps-a2b11111-ad92-4995-b68f-7c41aa34b6a1 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:06:46.709: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8505" for this suite.
Mar  2 10:06:54.741: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:06:54.955: INFO: namespace configmap-8505 deletion completed in 8.238072554s

• [SLOW TEST:12.917 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:06:54.955: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-2069
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar  2 10:06:57.049: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Mar  2 10:06:59.216: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718740417, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718740417, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718740417, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718740417, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7794d7ccd5\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar  2 10:07:02.298: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:07:04.337: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2069" for this suite.
Mar  2 10:07:12.651: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:07:12.791: INFO: namespace webhook-2069 deletion completed in 8.444884136s
STEP: Destroying namespace "webhook-2069-markers" for this suite.
Mar  2 10:07:18.827: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:07:18.974: INFO: namespace webhook-2069-markers deletion completed in 6.182958471s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:24.060 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:07:19.016: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-9427
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  2 10:07:24.014: INFO: Waiting up to 5m0s for pod "client-envvars-b497aa30-daaa-498f-83ec-a1be7d3acaf2" in namespace "pods-9427" to be "success or failure"
Mar  2 10:07:24.128: INFO: Pod "client-envvars-b497aa30-daaa-498f-83ec-a1be7d3acaf2": Phase="Pending", Reason="", readiness=false. Elapsed: 113.958126ms
Mar  2 10:07:26.136: INFO: Pod "client-envvars-b497aa30-daaa-498f-83ec-a1be7d3acaf2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.121944766s
Mar  2 10:07:28.142: INFO: Pod "client-envvars-b497aa30-daaa-498f-83ec-a1be7d3acaf2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.12878111s
STEP: Saw pod success
Mar  2 10:07:28.143: INFO: Pod "client-envvars-b497aa30-daaa-498f-83ec-a1be7d3acaf2" satisfied condition "success or failure"
Mar  2 10:07:28.147: INFO: Trying to get logs from node worker1 pod client-envvars-b497aa30-daaa-498f-83ec-a1be7d3acaf2 container env3cont: <nil>
STEP: delete the pod
Mar  2 10:07:28.282: INFO: Waiting for pod client-envvars-b497aa30-daaa-498f-83ec-a1be7d3acaf2 to disappear
Mar  2 10:07:28.338: INFO: Pod client-envvars-b497aa30-daaa-498f-83ec-a1be7d3acaf2 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:07:28.338: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9427" for this suite.
Mar  2 10:07:42.452: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:07:42.619: INFO: namespace pods-9427 deletion completed in 14.273829917s

• [SLOW TEST:23.602 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:07:42.619: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-5058
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-bb34eb0a-b67b-47a3-8186-a3470b990de3 in namespace container-probe-5058
Mar  2 10:07:47.029: INFO: Started pod busybox-bb34eb0a-b67b-47a3-8186-a3470b990de3 in namespace container-probe-5058
STEP: checking the pod's current state and verifying that restartCount is present
Mar  2 10:07:47.087: INFO: Initial restart count of pod busybox-bb34eb0a-b67b-47a3-8186-a3470b990de3 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:11:48.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5058" for this suite.
Mar  2 10:11:57.079: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:11:57.303: INFO: namespace container-probe-5058 deletion completed in 8.352863249s

• [SLOW TEST:254.683 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:11:57.303: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-519
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-projected-all-test-volume-7853decd-8ec3-4026-b415-8466d393cf9f
STEP: Creating secret with name secret-projected-all-test-volume-75aadabf-136c-4c5c-86d3-efd5395ebd66
STEP: Creating a pod to test Check all projections for projected volume plugin
Mar  2 10:11:57.784: INFO: Waiting up to 5m0s for pod "projected-volume-be34f69b-58d4-4b15-92a6-2a8d6f0890e4" in namespace "projected-519" to be "success or failure"
Mar  2 10:11:57.791: INFO: Pod "projected-volume-be34f69b-58d4-4b15-92a6-2a8d6f0890e4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.555519ms
Mar  2 10:11:59.799: INFO: Pod "projected-volume-be34f69b-58d4-4b15-92a6-2a8d6f0890e4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014878454s
Mar  2 10:12:01.806: INFO: Pod "projected-volume-be34f69b-58d4-4b15-92a6-2a8d6f0890e4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021456949s
STEP: Saw pod success
Mar  2 10:12:01.806: INFO: Pod "projected-volume-be34f69b-58d4-4b15-92a6-2a8d6f0890e4" satisfied condition "success or failure"
Mar  2 10:12:01.810: INFO: Trying to get logs from node worker1 pod projected-volume-be34f69b-58d4-4b15-92a6-2a8d6f0890e4 container projected-all-volume-test: <nil>
STEP: delete the pod
Mar  2 10:12:02.039: INFO: Waiting for pod projected-volume-be34f69b-58d4-4b15-92a6-2a8d6f0890e4 to disappear
Mar  2 10:12:02.071: INFO: Pod projected-volume-be34f69b-58d4-4b15-92a6-2a8d6f0890e4 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:12:02.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-519" for this suite.
Mar  2 10:12:10.147: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:12:10.281: INFO: namespace projected-519 deletion completed in 8.198327426s

• [SLOW TEST:12.978 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:32
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:12:10.281: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-1815
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar  2 10:12:12.441: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Mar  2 10:12:14.459: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718740732, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718740732, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718740732, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718740732, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7794d7ccd5\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar  2 10:12:17.597: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API
STEP: create a configmap that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:12:17.814: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1815" for this suite.
Mar  2 10:12:25.889: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:12:26.094: INFO: namespace webhook-1815 deletion completed in 8.272257421s
STEP: Destroying namespace "webhook-1815-markers" for this suite.
Mar  2 10:12:32.148: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:12:32.283: INFO: namespace webhook-1815-markers deletion completed in 6.189210783s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:22.050 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:12:32.331: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1652
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Mar  2 10:12:32.774: INFO: namespace kubectl-1652
Mar  2 10:12:32.774: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 create -f - --namespace=kubectl-1652'
Mar  2 10:12:33.348: INFO: stderr: ""
Mar  2 10:12:33.348: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Mar  2 10:12:34.355: INFO: Selector matched 1 pods for map[app:redis]
Mar  2 10:12:34.355: INFO: Found 0 / 1
Mar  2 10:12:35.370: INFO: Selector matched 1 pods for map[app:redis]
Mar  2 10:12:35.370: INFO: Found 0 / 1
Mar  2 10:12:36.355: INFO: Selector matched 1 pods for map[app:redis]
Mar  2 10:12:36.355: INFO: Found 1 / 1
Mar  2 10:12:36.355: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Mar  2 10:12:36.360: INFO: Selector matched 1 pods for map[app:redis]
Mar  2 10:12:36.360: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Mar  2 10:12:36.360: INFO: wait on redis-master startup in kubectl-1652 
Mar  2 10:12:36.360: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 logs redis-master-ghfmx redis-master --namespace=kubectl-1652'
Mar  2 10:12:36.529: INFO: stderr: ""
Mar  2 10:12:36.529: INFO: stdout: "1:C 02 Mar 2020 10:12:35.248 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\n1:C 02 Mar 2020 10:12:35.248 # Redis version=5.0.5, bits=64, commit=00000000, modified=0, pid=1, just started\n1:C 02 Mar 2020 10:12:35.248 # Warning: no config file specified, using the default config. In order to specify a config file use redis-server /path/to/redis.conf\n1:M 02 Mar 2020 10:12:35.251 * Running mode=standalone, port=6379.\n1:M 02 Mar 2020 10:12:35.251 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 02 Mar 2020 10:12:35.251 # Server initialized\n1:M 02 Mar 2020 10:12:35.251 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 02 Mar 2020 10:12:35.251 * Ready to accept connections\n"
STEP: exposing RC
Mar  2 10:12:36.529: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-1652'
Mar  2 10:12:36.810: INFO: stderr: ""
Mar  2 10:12:36.810: INFO: stdout: "service/rm2 exposed\n"
Mar  2 10:12:36.875: INFO: Service rm2 in namespace kubectl-1652 found.
STEP: exposing service
Mar  2 10:12:38.885: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-1652'
Mar  2 10:12:39.280: INFO: stderr: ""
Mar  2 10:12:39.280: INFO: stdout: "service/rm3 exposed\n"
Mar  2 10:12:39.321: INFO: Service rm3 in namespace kubectl-1652 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:12:41.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1652" for this suite.
Mar  2 10:12:55.452: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:12:55.611: INFO: namespace kubectl-1652 deletion completed in 14.22846484s

• [SLOW TEST:23.280 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl expose
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1105
    should create services for rc  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:12:55.612: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-4464
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Mar  2 10:12:55.999: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar  2 10:12:56.055: INFO: Waiting for terminating namespaces to be deleted...
Mar  2 10:12:56.059: INFO: 
Logging pods the kubelet thinks is on node worker1 before test
Mar  2 10:12:56.068: INFO: kube-proxy-bnv2b from kube-system started at 2020-03-02 03:03:07 +0000 UTC (1 container statuses recorded)
Mar  2 10:12:56.068: INFO: 	Container kube-proxy ready: true, restart count 0
Mar  2 10:12:56.068: INFO: sonobuoy from sonobuoy started at 2020-03-02 09:09:31 +0000 UTC (1 container statuses recorded)
Mar  2 10:12:56.068: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Mar  2 10:12:56.068: INFO: sonobuoy-e2e-job-6f4cd8785f284b6e from sonobuoy started at 2020-03-02 09:09:33 +0000 UTC (2 container statuses recorded)
Mar  2 10:12:56.068: INFO: 	Container e2e ready: true, restart count 0
Mar  2 10:12:56.068: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar  2 10:12:56.068: INFO: kube-flannel-ds-amd64-hmpfw from kube-system started at 2020-03-02 03:03:50 +0000 UTC (1 container statuses recorded)
Mar  2 10:12:56.068: INFO: 	Container kube-flannel ready: true, restart count 0
Mar  2 10:12:56.068: INFO: sonobuoy-systemd-logs-daemon-set-003190d3042d4113-rtkgw from sonobuoy started at 2020-03-02 09:09:34 +0000 UTC (2 container statuses recorded)
Mar  2 10:12:56.068: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Mar  2 10:12:56.068: INFO: 	Container systemd-logs ready: true, restart count 0
Mar  2 10:12:56.068: INFO: envoy-hwmt2 from projectcontour started at 2020-03-02 02:43:15 +0000 UTC (1 container statuses recorded)
Mar  2 10:12:56.068: INFO: 	Container envoy ready: false, restart count 0
Mar  2 10:12:56.068: INFO: 
Logging pods the kubelet thinks is on node worker2 before test
Mar  2 10:12:56.104: INFO: contour-7594d96455-vcdf6 from projectcontour started at 2020-03-02 02:40:59 +0000 UTC (1 container statuses recorded)
Mar  2 10:12:56.104: INFO: 	Container contour ready: false, restart count 0
Mar  2 10:12:56.104: INFO: kuard-85c85bcf66-qv4qm from default started at 2020-03-02 02:41:50 +0000 UTC (1 container statuses recorded)
Mar  2 10:12:56.104: INFO: 	Container kuard ready: true, restart count 0
Mar  2 10:12:56.104: INFO: sonobuoy-systemd-logs-daemon-set-003190d3042d4113-4dn5h from sonobuoy started at 2020-03-02 09:09:34 +0000 UTC (2 container statuses recorded)
Mar  2 10:12:56.105: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Mar  2 10:12:56.105: INFO: 	Container systemd-logs ready: true, restart count 0
Mar  2 10:12:56.105: INFO: contour-certgen-bh5fh from projectcontour started at 2020-03-02 02:40:59 +0000 UTC (1 container statuses recorded)
Mar  2 10:12:56.105: INFO: 	Container contour ready: false, restart count 0
Mar  2 10:12:56.105: INFO: kuard-85c85bcf66-6dv5z from default started at 2020-03-02 02:41:51 +0000 UTC (1 container statuses recorded)
Mar  2 10:12:56.105: INFO: 	Container kuard ready: true, restart count 0
Mar  2 10:12:56.105: INFO: kube-proxy-77czp from kube-system started at 2020-03-02 03:03:11 +0000 UTC (1 container statuses recorded)
Mar  2 10:12:56.105: INFO: 	Container kube-proxy ready: true, restart count 0
Mar  2 10:12:56.105: INFO: kube-flannel-ds-amd64-6l2th from kube-system started at 2020-03-02 03:04:01 +0000 UTC (1 container statuses recorded)
Mar  2 10:12:56.105: INFO: 	Container kube-flannel ready: true, restart count 0
Mar  2 10:12:56.105: INFO: contour-7594d96455-sm4qm from projectcontour started at 2020-03-02 02:40:59 +0000 UTC (1 container statuses recorded)
Mar  2 10:12:56.105: INFO: 	Container contour ready: false, restart count 0
Mar  2 10:12:56.105: INFO: metrics-server-557c6b848b-k8ssl from kube-system started at 2020-03-02 02:41:51 +0000 UTC (1 container statuses recorded)
Mar  2 10:12:56.105: INFO: 	Container metrics-server ready: true, restart count 0
Mar  2 10:12:56.105: INFO: envoy-l4k6z from projectcontour started at 2020-03-02 02:40:59 +0000 UTC (1 container statuses recorded)
Mar  2 10:12:56.105: INFO: 	Container envoy ready: false, restart count 0
Mar  2 10:12:56.105: INFO: kuard-85c85bcf66-lf9xs from default started at 2020-03-02 02:41:49 +0000 UTC (1 container statuses recorded)
Mar  2 10:12:56.105: INFO: 	Container kuard ready: true, restart count 0
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-5db8393a-efc7-4840-ba91-e4109605ab11 90
STEP: Trying to create a pod(pod1) with hostport 54321 and hostIP 127.0.0.1 and expect scheduled
STEP: Trying to create another pod(pod2) with hostport 54321 but hostIP 127.0.0.2 on the node which pod1 resides and expect scheduled
STEP: Trying to create a third pod(pod3) with hostport 54321, hostIP 127.0.0.2 but use UDP protocol on the node which pod2 resides
STEP: removing the label kubernetes.io/e2e-5db8393a-efc7-4840-ba91-e4109605ab11 off the node worker1
STEP: verifying the node doesn't have the label kubernetes.io/e2e-5db8393a-efc7-4840-ba91-e4109605ab11
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:13:12.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4464" for this suite.
Mar  2 10:13:34.972: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:13:35.165: INFO: namespace sched-pred-4464 deletion completed in 22.24517103s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:39.554 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:13:35.166: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-3719
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a long running pod
STEP: Ensuring resource quota with not terminating scope captures the pod usage
STEP: Ensuring resource quota with terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a terminating pod
STEP: Ensuring resource quota with terminating scope captures the pod usage
STEP: Ensuring resource quota with not terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:13:52.359: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3719" for this suite.
Mar  2 10:14:00.446: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:14:00.594: INFO: namespace resourcequota-3719 deletion completed in 8.229200257s

• [SLOW TEST:25.429 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:14:00.594: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7178
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-7c4e957a-0d78-4e54-8c5e-02eafb1f1e36
STEP: Creating configMap with name cm-test-opt-upd-10c4d477-e1f0-4f19-97c8-9c24e04c24c4
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-7c4e957a-0d78-4e54-8c5e-02eafb1f1e36
STEP: Updating configmap cm-test-opt-upd-10c4d477-e1f0-4f19-97c8-9c24e04c24c4
STEP: Creating configMap with name cm-test-opt-create-17d91d0b-413f-483f-835a-0734c43e93da
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:15:26.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7178" for this suite.
Mar  2 10:15:46.104: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:15:46.227: INFO: namespace configmap-7178 deletion completed in 20.169515075s

• [SLOW TEST:105.632 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:15:46.227: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1489
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Mar  2 10:15:46.593: INFO: Waiting up to 5m0s for pod "downward-api-ae565fd8-479b-4355-9e5c-36473d9eae22" in namespace "downward-api-1489" to be "success or failure"
Mar  2 10:15:46.662: INFO: Pod "downward-api-ae565fd8-479b-4355-9e5c-36473d9eae22": Phase="Pending", Reason="", readiness=false. Elapsed: 68.658918ms
Mar  2 10:15:48.667: INFO: Pod "downward-api-ae565fd8-479b-4355-9e5c-36473d9eae22": Phase="Pending", Reason="", readiness=false. Elapsed: 2.074408552s
Mar  2 10:15:50.712: INFO: Pod "downward-api-ae565fd8-479b-4355-9e5c-36473d9eae22": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.118865842s
STEP: Saw pod success
Mar  2 10:15:50.712: INFO: Pod "downward-api-ae565fd8-479b-4355-9e5c-36473d9eae22" satisfied condition "success or failure"
Mar  2 10:15:50.721: INFO: Trying to get logs from node worker1 pod downward-api-ae565fd8-479b-4355-9e5c-36473d9eae22 container dapi-container: <nil>
STEP: delete the pod
Mar  2 10:15:50.802: INFO: Waiting for pod downward-api-ae565fd8-479b-4355-9e5c-36473d9eae22 to disappear
Mar  2 10:15:50.806: INFO: Pod downward-api-ae565fd8-479b-4355-9e5c-36473d9eae22 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:15:50.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1489" for this suite.
Mar  2 10:15:58.880: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:15:59.002: INFO: namespace downward-api-1489 deletion completed in 8.189744509s

• [SLOW TEST:12.776 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:15:59.003: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-9427
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Mar  2 10:16:02.527: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:16:02.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-9427" for this suite.
Mar  2 10:16:10.672: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:16:10.882: INFO: namespace container-runtime-9427 deletion completed in 8.250436086s

• [SLOW TEST:11.880 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:16:10.883: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-4687
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Mar  2 10:16:14.339: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:16:14.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-4687" for this suite.
Mar  2 10:16:20.562: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:16:20.768: INFO: namespace container-runtime-4687 deletion completed in 6.249440092s

• [SLOW TEST:9.885 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:16:20.769: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-4719
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  2 10:16:21.168: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Mar  2 10:16:25.230: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Mar  2 10:16:27.256: INFO: Creating deployment "test-rollover-deployment"
Mar  2 10:16:27.396: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Mar  2 10:16:29.425: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Mar  2 10:16:29.435: INFO: Ensure that both replica sets have 1 created replica
Mar  2 10:16:29.477: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Mar  2 10:16:29.511: INFO: Updating deployment test-rollover-deployment
Mar  2 10:16:29.511: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Mar  2 10:16:31.550: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Mar  2 10:16:31.562: INFO: Make sure deployment "test-rollover-deployment" is complete
Mar  2 10:16:31.574: INFO: all replica sets need to contain the pod-template-hash label
Mar  2 10:16:31.574: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718740987, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718740987, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718740990, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718740987, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6589d75b4d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  2 10:16:33.589: INFO: all replica sets need to contain the pod-template-hash label
Mar  2 10:16:33.589: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718740987, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718740987, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718740992, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718740987, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6589d75b4d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  2 10:16:35.586: INFO: all replica sets need to contain the pod-template-hash label
Mar  2 10:16:35.586: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718740987, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718740987, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718740992, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718740987, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6589d75b4d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  2 10:16:37.587: INFO: all replica sets need to contain the pod-template-hash label
Mar  2 10:16:37.587: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718740987, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718740987, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718740992, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718740987, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6589d75b4d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  2 10:16:39.654: INFO: all replica sets need to contain the pod-template-hash label
Mar  2 10:16:39.654: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718740987, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718740987, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718740992, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718740987, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6589d75b4d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  2 10:16:41.586: INFO: all replica sets need to contain the pod-template-hash label
Mar  2 10:16:41.586: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718740987, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718740987, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718740992, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718740987, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6589d75b4d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  2 10:16:43.586: INFO: 
Mar  2 10:16:43.586: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Mar  2 10:16:43.598: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-4719 /apis/apps/v1/namespaces/deployment-4719/deployments/test-rollover-deployment 542e5adc-4029-464b-b957-205e39b659e2 92953 2 2020-03-02 10:16:27 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] []  []} {[] [] [{redis 172.20.8.7/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc002eab3f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-03-02 10:16:27 +0000 UTC,LastTransitionTime:2020-03-02 10:16:27 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-6589d75b4d" has successfully progressed.,LastUpdateTime:2020-03-02 10:16:42 +0000 UTC,LastTransitionTime:2020-03-02 10:16:27 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Mar  2 10:16:43.603: INFO: New ReplicaSet "test-rollover-deployment-6589d75b4d" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-6589d75b4d  deployment-4719 /apis/apps/v1/namespaces/deployment-4719/replicasets/test-rollover-deployment-6589d75b4d 51440ced-1b23-4ee2-b3d9-dfa09a13a5b5 92942 2 2020-03-02 10:16:29 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6589d75b4d] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 542e5adc-4029-464b-b957-205e39b659e2 0xc002eab8c7 0xc002eab8c8}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6589d75b4d,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6589d75b4d] map[] [] []  []} {[] [] [{redis 172.20.8.7/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc002eab928 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Mar  2 10:16:43.603: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Mar  2 10:16:43.603: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-4719 /apis/apps/v1/namespaces/deployment-4719/replicasets/test-rollover-controller f63a7a1c-9ee8-4834-88f9-55ac9b7d4aec 92952 2 2020-03-02 10:16:21 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 542e5adc-4029-464b-b957-205e39b659e2 0xc002eab7e7 0xc002eab7e8}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] []  []} {[] [] [{httpd 172.20.8.7/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc002eab848 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Mar  2 10:16:43.604: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-f6c94f66c  deployment-4719 /apis/apps/v1/namespaces/deployment-4719/replicasets/test-rollover-deployment-f6c94f66c 7ea520a8-643c-4c7c-82f0-08eb858201ab 92912 2 2020-03-02 10:16:27 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 542e5adc-4029-464b-b957-205e39b659e2 0xc002eab990 0xc002eab991}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: f6c94f66c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[] [] []  []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc002eaba08 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Mar  2 10:16:43.609: INFO: Pod "test-rollover-deployment-6589d75b4d-pbzdh" is available:
&Pod{ObjectMeta:{test-rollover-deployment-6589d75b4d-pbzdh test-rollover-deployment-6589d75b4d- deployment-4719 /api/v1/namespaces/deployment-4719/pods/test-rollover-deployment-6589d75b4d-pbzdh 98d8041d-d5ae-427e-adb6-d4934661f54f 92921 0 2020-03-02 10:16:29 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6589d75b4d] map[] [{apps/v1 ReplicaSet test-rollover-deployment-6589d75b4d 51440ced-1b23-4ee2-b3d9-dfa09a13a5b5 0xc002dd40a7 0xc002dd40a8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-jnfkq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-jnfkq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:172.20.8.7/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-jnfkq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 10:16:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 10:16:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 10:16:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 10:16:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.8.5,PodIP:10.244.4.31,StartTime:2020-03-02 10:16:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-03-02 10:16:31 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:172.20.8.7/library/redis:5.0.5-alpine,ImageID:docker-pullable://172.20.8.7/library/redis@sha256:a606eaca41c3c69c7d2c8a142ec445e71156bae8526ae7970f62b6399e57761c,ContainerID:docker://8be73506d37088d950711656d160f6e68e1e30eee1837243a8beae52413a7b71,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.4.31,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:16:43.609: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4719" for this suite.
Mar  2 10:16:51.653: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:16:51.870: INFO: namespace deployment-4719 deletion completed in 8.251098947s

• [SLOW TEST:31.101 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:16:51.870: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-6791
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test env composition
Mar  2 10:16:52.339: INFO: Waiting up to 5m0s for pod "var-expansion-f1beb755-0c56-4d84-a517-23d454de79f2" in namespace "var-expansion-6791" to be "success or failure"
Mar  2 10:16:52.603: INFO: Pod "var-expansion-f1beb755-0c56-4d84-a517-23d454de79f2": Phase="Pending", Reason="", readiness=false. Elapsed: 263.825774ms
Mar  2 10:16:54.609: INFO: Pod "var-expansion-f1beb755-0c56-4d84-a517-23d454de79f2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.270447496s
Mar  2 10:16:56.618: INFO: Pod "var-expansion-f1beb755-0c56-4d84-a517-23d454de79f2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.279176216s
STEP: Saw pod success
Mar  2 10:16:56.618: INFO: Pod "var-expansion-f1beb755-0c56-4d84-a517-23d454de79f2" satisfied condition "success or failure"
Mar  2 10:16:56.624: INFO: Trying to get logs from node worker1 pod var-expansion-f1beb755-0c56-4d84-a517-23d454de79f2 container dapi-container: <nil>
STEP: delete the pod
Mar  2 10:16:56.732: INFO: Waiting for pod var-expansion-f1beb755-0c56-4d84-a517-23d454de79f2 to disappear
Mar  2 10:16:56.764: INFO: Pod var-expansion-f1beb755-0c56-4d84-a517-23d454de79f2 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:16:56.764: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-6791" for this suite.
Mar  2 10:17:04.832: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:17:04.960: INFO: namespace var-expansion-6791 deletion completed in 8.188903954s

• [SLOW TEST:13.090 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:17:04.960: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-6166
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:18:05.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6166" for this suite.
Mar  2 10:18:35.440: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:18:35.561: INFO: namespace container-probe-6166 deletion completed in 30.161601408s

• [SLOW TEST:90.601 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:18:35.561: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-6833
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Mar  2 10:18:38.121: INFO: Pod name wrapped-volume-race-84cfd591-3fd0-438c-aa8b-9788c1e88bbd: Found 0 pods out of 5
Mar  2 10:18:43.131: INFO: Pod name wrapped-volume-race-84cfd591-3fd0-438c-aa8b-9788c1e88bbd: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-84cfd591-3fd0-438c-aa8b-9788c1e88bbd in namespace emptydir-wrapper-6833, will wait for the garbage collector to delete the pods
Mar  2 10:18:57.463: INFO: Deleting ReplicationController wrapped-volume-race-84cfd591-3fd0-438c-aa8b-9788c1e88bbd took: 40.040816ms
Mar  2 10:18:58.063: INFO: Terminating ReplicationController wrapped-volume-race-84cfd591-3fd0-438c-aa8b-9788c1e88bbd pods took: 600.373797ms
STEP: Creating RC which spawns configmap-volume pods
Mar  2 10:19:33.396: INFO: Pod name wrapped-volume-race-ab04da6c-d483-4543-a20e-4f0b1f2e6568: Found 0 pods out of 5
Mar  2 10:19:38.454: INFO: Pod name wrapped-volume-race-ab04da6c-d483-4543-a20e-4f0b1f2e6568: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-ab04da6c-d483-4543-a20e-4f0b1f2e6568 in namespace emptydir-wrapper-6833, will wait for the garbage collector to delete the pods
Mar  2 10:19:50.668: INFO: Deleting ReplicationController wrapped-volume-race-ab04da6c-d483-4543-a20e-4f0b1f2e6568 took: 94.72659ms
Mar  2 10:19:51.468: INFO: Terminating ReplicationController wrapped-volume-race-ab04da6c-d483-4543-a20e-4f0b1f2e6568 pods took: 800.372334ms
STEP: Creating RC which spawns configmap-volume pods
Mar  2 10:20:33.673: INFO: Pod name wrapped-volume-race-cdabee51-2edf-4a52-b232-07490ff2334b: Found 0 pods out of 5
Mar  2 10:20:38.684: INFO: Pod name wrapped-volume-race-cdabee51-2edf-4a52-b232-07490ff2334b: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-cdabee51-2edf-4a52-b232-07490ff2334b in namespace emptydir-wrapper-6833, will wait for the garbage collector to delete the pods
Mar  2 10:20:51.216: INFO: Deleting ReplicationController wrapped-volume-race-cdabee51-2edf-4a52-b232-07490ff2334b took: 90.586525ms
Mar  2 10:20:52.117: INFO: Terminating ReplicationController wrapped-volume-race-cdabee51-2edf-4a52-b232-07490ff2334b pods took: 900.271506ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:21:36.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-6833" for this suite.
Mar  2 10:21:54.357: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:21:54.757: INFO: namespace emptydir-wrapper-6833 deletion completed in 18.424373533s

• [SLOW TEST:199.196 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:21:54.758: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4534
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl label
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1192
STEP: creating the pod
Mar  2 10:21:55.098: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 create -f - --namespace=kubectl-4534'
Mar  2 10:21:57.184: INFO: stderr: ""
Mar  2 10:21:57.184: INFO: stdout: "pod/pause created\n"
Mar  2 10:21:57.184: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Mar  2 10:21:57.184: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-4534" to be "running and ready"
Mar  2 10:21:57.205: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 21.096219ms
Mar  2 10:21:59.371: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.186602235s
Mar  2 10:22:01.393: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.208461811s
Mar  2 10:22:01.393: INFO: Pod "pause" satisfied condition "running and ready"
Mar  2 10:22:01.393: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: adding the label testing-label with value testing-label-value to a pod
Mar  2 10:22:01.393: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 label pods pause testing-label=testing-label-value --namespace=kubectl-4534'
Mar  2 10:22:01.588: INFO: stderr: ""
Mar  2 10:22:01.588: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Mar  2 10:22:01.588: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 get pod pause -L testing-label --namespace=kubectl-4534'
Mar  2 10:22:01.751: INFO: stderr: ""
Mar  2 10:22:01.751: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Mar  2 10:22:01.751: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 label pods pause testing-label- --namespace=kubectl-4534'
Mar  2 10:22:01.924: INFO: stderr: ""
Mar  2 10:22:01.924: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Mar  2 10:22:01.924: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 get pod pause -L testing-label --namespace=kubectl-4534'
Mar  2 10:22:02.182: INFO: stderr: ""
Mar  2 10:22:02.182: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    \n"
[AfterEach] Kubectl label
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1199
STEP: using delete to clean up resources
Mar  2 10:22:02.183: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 delete --grace-period=0 --force -f - --namespace=kubectl-4534'
Mar  2 10:22:02.489: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  2 10:22:02.489: INFO: stdout: "pod \"pause\" force deleted\n"
Mar  2 10:22:02.489: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 get rc,svc -l name=pause --no-headers --namespace=kubectl-4534'
Mar  2 10:22:02.653: INFO: stderr: "No resources found in kubectl-4534 namespace.\n"
Mar  2 10:22:02.653: INFO: stdout: ""
Mar  2 10:22:02.653: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 get pods -l name=pause --namespace=kubectl-4534 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar  2 10:22:02.789: INFO: stderr: ""
Mar  2 10:22:02.789: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:22:02.789: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4534" for this suite.
Mar  2 10:22:08.829: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:22:08.964: INFO: namespace kubectl-4534 deletion completed in 6.168891184s

• [SLOW TEST:14.206 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl label
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1189
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:22:08.964: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7151
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Mar  2 10:22:09.665: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e852ff07-b456-4d95-894a-ce47d30a9a7f" in namespace "downward-api-7151" to be "success or failure"
Mar  2 10:22:09.710: INFO: Pod "downwardapi-volume-e852ff07-b456-4d95-894a-ce47d30a9a7f": Phase="Pending", Reason="", readiness=false. Elapsed: 44.780403ms
Mar  2 10:22:11.716: INFO: Pod "downwardapi-volume-e852ff07-b456-4d95-894a-ce47d30a9a7f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.05066776s
Mar  2 10:22:13.721: INFO: Pod "downwardapi-volume-e852ff07-b456-4d95-894a-ce47d30a9a7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.056191023s
STEP: Saw pod success
Mar  2 10:22:13.721: INFO: Pod "downwardapi-volume-e852ff07-b456-4d95-894a-ce47d30a9a7f" satisfied condition "success or failure"
Mar  2 10:22:13.728: INFO: Trying to get logs from node worker1 pod downwardapi-volume-e852ff07-b456-4d95-894a-ce47d30a9a7f container client-container: <nil>
STEP: delete the pod
Mar  2 10:22:13.931: INFO: Waiting for pod downwardapi-volume-e852ff07-b456-4d95-894a-ce47d30a9a7f to disappear
Mar  2 10:22:13.937: INFO: Pod downwardapi-volume-e852ff07-b456-4d95-894a-ce47d30a9a7f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:22:13.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7151" for this suite.
Mar  2 10:22:20.027: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:22:20.213: INFO: namespace downward-api-7151 deletion completed in 6.2686346s

• [SLOW TEST:11.249 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:22:20.213: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1853
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Mar  2 10:22:20.613: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b7cae685-e06f-4a1a-9fd2-ef7f3850447e" in namespace "downward-api-1853" to be "success or failure"
Mar  2 10:22:20.649: INFO: Pod "downwardapi-volume-b7cae685-e06f-4a1a-9fd2-ef7f3850447e": Phase="Pending", Reason="", readiness=false. Elapsed: 35.368674ms
Mar  2 10:22:22.655: INFO: Pod "downwardapi-volume-b7cae685-e06f-4a1a-9fd2-ef7f3850447e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041620079s
Mar  2 10:22:24.660: INFO: Pod "downwardapi-volume-b7cae685-e06f-4a1a-9fd2-ef7f3850447e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.047228679s
STEP: Saw pod success
Mar  2 10:22:24.660: INFO: Pod "downwardapi-volume-b7cae685-e06f-4a1a-9fd2-ef7f3850447e" satisfied condition "success or failure"
Mar  2 10:22:24.665: INFO: Trying to get logs from node worker1 pod downwardapi-volume-b7cae685-e06f-4a1a-9fd2-ef7f3850447e container client-container: <nil>
STEP: delete the pod
Mar  2 10:22:24.871: INFO: Waiting for pod downwardapi-volume-b7cae685-e06f-4a1a-9fd2-ef7f3850447e to disappear
Mar  2 10:22:24.909: INFO: Pod downwardapi-volume-b7cae685-e06f-4a1a-9fd2-ef7f3850447e no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:22:24.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1853" for this suite.
Mar  2 10:22:32.953: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:22:33.085: INFO: namespace downward-api-1853 deletion completed in 8.168794538s

• [SLOW TEST:12.871 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:22:33.085: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-2607
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar  2 10:22:34.697: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Mar  2 10:22:36.712: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718741354, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718741354, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718741355, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718741354, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7794d7ccd5\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar  2 10:22:39.918: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that should be mutated
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that should not be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:22:41.941: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2607" for this suite.
Mar  2 10:22:50.042: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:22:50.176: INFO: namespace webhook-2607 deletion completed in 8.22674649s
STEP: Destroying namespace "webhook-2607-markers" for this suite.
Mar  2 10:22:56.283: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:22:56.393: INFO: namespace webhook-2607-markers deletion completed in 6.21728815s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:23.341 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:22:56.427: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5317
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Mar  2 10:22:56.912: INFO: Waiting up to 5m0s for pod "downward-api-bb4a70db-8f6f-47b2-8a9c-ea658fe7e8ac" in namespace "downward-api-5317" to be "success or failure"
Mar  2 10:22:56.916: INFO: Pod "downward-api-bb4a70db-8f6f-47b2-8a9c-ea658fe7e8ac": Phase="Pending", Reason="", readiness=false. Elapsed: 3.470382ms
Mar  2 10:22:58.921: INFO: Pod "downward-api-bb4a70db-8f6f-47b2-8a9c-ea658fe7e8ac": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009250484s
Mar  2 10:23:00.927: INFO: Pod "downward-api-bb4a70db-8f6f-47b2-8a9c-ea658fe7e8ac": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015085187s
STEP: Saw pod success
Mar  2 10:23:00.927: INFO: Pod "downward-api-bb4a70db-8f6f-47b2-8a9c-ea658fe7e8ac" satisfied condition "success or failure"
Mar  2 10:23:00.933: INFO: Trying to get logs from node worker1 pod downward-api-bb4a70db-8f6f-47b2-8a9c-ea658fe7e8ac container dapi-container: <nil>
STEP: delete the pod
Mar  2 10:23:01.074: INFO: Waiting for pod downward-api-bb4a70db-8f6f-47b2-8a9c-ea658fe7e8ac to disappear
Mar  2 10:23:01.078: INFO: Pod downward-api-bb4a70db-8f6f-47b2-8a9c-ea658fe7e8ac no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:23:01.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5317" for this suite.
Mar  2 10:23:07.213: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:23:07.493: INFO: namespace downward-api-5317 deletion completed in 6.354889354s

• [SLOW TEST:11.067 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:23:07.494: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-9160
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar  2 10:23:09.064: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Mar  2 10:23:11.143: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718741389, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718741389, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718741389, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718741389, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7794d7ccd5\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar  2 10:23:14.201: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Creating a dummy validating-webhook-configuration object
STEP: Deleting the validating-webhook-configuration, which should be possible to remove
STEP: Creating a dummy mutating-webhook-configuration object
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:23:14.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9160" for this suite.
Mar  2 10:23:22.803: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:23:22.962: INFO: namespace webhook-9160 deletion completed in 8.289723723s
STEP: Destroying namespace "webhook-9160-markers" for this suite.
Mar  2 10:23:29.019: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:23:29.261: INFO: namespace webhook-9160-markers deletion completed in 6.29839648s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:21.809 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:23:29.304: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-5135
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Service
STEP: Ensuring resource quota status captures service creation
STEP: Deleting a Service
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:23:41.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5135" for this suite.
Mar  2 10:23:47.163: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:23:47.570: INFO: namespace resourcequota-5135 deletion completed in 6.456369689s

• [SLOW TEST:18.266 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:23:47.570: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3059
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with configMap that has name projected-configmap-test-upd-a1fd0e96-c6fe-4af0-ad11-33bdedcebaf1
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-a1fd0e96-c6fe-4af0-ad11-33bdedcebaf1
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:25:11.410: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3059" for this suite.
Mar  2 10:25:25.444: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:25:25.565: INFO: namespace projected-3059 deletion completed in 14.148956892s

• [SLOW TEST:97.995 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:25:25.566: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-351
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service nodeport-service with the type=NodePort in namespace services-351
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-351
STEP: creating replication controller externalsvc in namespace services-351
I0302 10:25:26.543123      24 runners.go:184] Created replication controller with name: externalsvc, namespace: services-351, replica count: 2
I0302 10:25:29.593890      24 runners.go:184] externalsvc Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0302 10:25:32.594119      24 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName
Mar  2 10:25:32.844: INFO: Creating new exec pod
Mar  2 10:25:36.877: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 exec --namespace=services-351 execpodqm8ht -- /bin/sh -x -c nslookup nodeport-service'
Mar  2 10:25:37.216: INFO: stderr: "+ nslookup nodeport-service\n"
Mar  2 10:25:37.216: INFO: stdout: "Server:\t\t10.96.0.10\nAddress:\t10.96.0.10#53\n\nnodeport-service.services-351.svc.cluster.local\tcanonical name = externalsvc.services-351.svc.cluster.local.\nName:\texternalsvc.services-351.svc.cluster.local\nAddress: 10.104.83.34\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-351, will wait for the garbage collector to delete the pods
Mar  2 10:25:37.403: INFO: Deleting ReplicationController externalsvc took: 90.621674ms
Mar  2 10:25:37.804: INFO: Terminating ReplicationController externalsvc pods took: 400.22047ms
Mar  2 10:25:52.450: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:25:52.668: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-351" for this suite.
Mar  2 10:26:00.814: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:26:00.944: INFO: namespace services-351 deletion completed in 8.266442011s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:35.378 seconds]
[sig-network] Services
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:26:00.944: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-9845
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-9845
STEP: changing the ExternalName service to type=NodePort
STEP: creating replication controller externalname-service in namespace services-9845
I0302 10:26:01.687596      24 runners.go:184] Created replication controller with name: externalname-service, namespace: services-9845, replica count: 2
I0302 10:26:04.738106      24 runners.go:184] externalname-service Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Mar  2 10:26:07.738: INFO: Creating new exec pod
I0302 10:26:07.738367      24 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Mar  2 10:26:12.796: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 exec --namespace=services-9845 execpodt25b2 -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Mar  2 10:26:13.288: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Mar  2 10:26:13.288: INFO: stdout: ""
Mar  2 10:26:13.289: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 exec --namespace=services-9845 execpodt25b2 -- /bin/sh -x -c nc -zv -t -w 2 10.111.113.228 80'
Mar  2 10:26:13.667: INFO: stderr: "+ nc -zv -t -w 2 10.111.113.228 80\nConnection to 10.111.113.228 80 port [tcp/http] succeeded!\n"
Mar  2 10:26:13.667: INFO: stdout: ""
Mar  2 10:26:13.668: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 exec --namespace=services-9845 execpodt25b2 -- /bin/sh -x -c nc -zv -t -w 2 172.20.8.5 32477'
Mar  2 10:26:14.005: INFO: stderr: "+ nc -zv -t -w 2 172.20.8.5 32477\nConnection to 172.20.8.5 32477 port [tcp/32477] succeeded!\n"
Mar  2 10:26:14.005: INFO: stdout: ""
Mar  2 10:26:14.005: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 exec --namespace=services-9845 execpodt25b2 -- /bin/sh -x -c nc -zv -t -w 2 172.20.8.6 32477'
Mar  2 10:26:14.338: INFO: stderr: "+ nc -zv -t -w 2 172.20.8.6 32477\nConnection to 172.20.8.6 32477 port [tcp/32477] succeeded!\n"
Mar  2 10:26:14.339: INFO: stdout: ""
Mar  2 10:26:14.339: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:26:14.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9845" for this suite.
Mar  2 10:26:22.683: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:26:22.825: INFO: namespace services-9845 deletion completed in 8.21102057s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:21.881 seconds]
[sig-network] Services
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:26:22.826: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-1397
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1397.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1397.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar  2 10:26:27.722: INFO: DNS probes using dns-1397/dns-test-118c14b4-1904-422b-9aa5-d71098e14eec succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:26:27.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1397" for this suite.
Mar  2 10:26:35.960: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:26:36.107: INFO: namespace dns-1397 deletion completed in 8.22515239s

• [SLOW TEST:13.281 seconds]
[sig-network] DNS
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:26:36.107: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4397
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-acf33765-70cb-4119-86dc-2d9ae1e57d73
STEP: Creating a pod to test consume secrets
Mar  2 10:26:36.526: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-780d8256-4d25-40b1-9008-8ed13bc5804c" in namespace "projected-4397" to be "success or failure"
Mar  2 10:26:36.530: INFO: Pod "pod-projected-secrets-780d8256-4d25-40b1-9008-8ed13bc5804c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.457807ms
Mar  2 10:26:38.534: INFO: Pod "pod-projected-secrets-780d8256-4d25-40b1-9008-8ed13bc5804c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007864761s
Mar  2 10:26:40.540: INFO: Pod "pod-projected-secrets-780d8256-4d25-40b1-9008-8ed13bc5804c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013638153s
STEP: Saw pod success
Mar  2 10:26:40.540: INFO: Pod "pod-projected-secrets-780d8256-4d25-40b1-9008-8ed13bc5804c" satisfied condition "success or failure"
Mar  2 10:26:40.545: INFO: Trying to get logs from node worker1 pod pod-projected-secrets-780d8256-4d25-40b1-9008-8ed13bc5804c container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar  2 10:26:40.629: INFO: Waiting for pod pod-projected-secrets-780d8256-4d25-40b1-9008-8ed13bc5804c to disappear
Mar  2 10:26:40.639: INFO: Pod pod-projected-secrets-780d8256-4d25-40b1-9008-8ed13bc5804c no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:26:40.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4397" for this suite.
Mar  2 10:26:46.696: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:26:46.810: INFO: namespace projected-4397 deletion completed in 6.164785552s

• [SLOW TEST:10.703 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:26:46.810: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3880
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Mar  2 10:26:47.390: INFO: Waiting up to 5m0s for pod "pod-7d04ecb5-d701-407f-8208-fd9fab6d0af9" in namespace "emptydir-3880" to be "success or failure"
Mar  2 10:26:47.411: INFO: Pod "pod-7d04ecb5-d701-407f-8208-fd9fab6d0af9": Phase="Pending", Reason="", readiness=false. Elapsed: 21.025017ms
Mar  2 10:26:49.417: INFO: Pod "pod-7d04ecb5-d701-407f-8208-fd9fab6d0af9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026557757s
Mar  2 10:26:51.424: INFO: Pod "pod-7d04ecb5-d701-407f-8208-fd9fab6d0af9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033476831s
STEP: Saw pod success
Mar  2 10:26:51.424: INFO: Pod "pod-7d04ecb5-d701-407f-8208-fd9fab6d0af9" satisfied condition "success or failure"
Mar  2 10:26:51.427: INFO: Trying to get logs from node worker1 pod pod-7d04ecb5-d701-407f-8208-fd9fab6d0af9 container test-container: <nil>
STEP: delete the pod
Mar  2 10:26:51.501: INFO: Waiting for pod pod-7d04ecb5-d701-407f-8208-fd9fab6d0af9 to disappear
Mar  2 10:26:51.506: INFO: Pod pod-7d04ecb5-d701-407f-8208-fd9fab6d0af9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:26:51.506: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3880" for this suite.
Mar  2 10:26:59.564: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:26:59.806: INFO: namespace emptydir-3880 deletion completed in 8.292218015s

• [SLOW TEST:12.995 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:26:59.806: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7653
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-3832b1a0-92c6-4ba3-a58b-d8428d8bc9ce
STEP: Creating a pod to test consume configMaps
Mar  2 10:27:00.224: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ad22095d-37b5-4f99-a7e6-14d27529ec2a" in namespace "projected-7653" to be "success or failure"
Mar  2 10:27:00.232: INFO: Pod "pod-projected-configmaps-ad22095d-37b5-4f99-a7e6-14d27529ec2a": Phase="Pending", Reason="", readiness=false. Elapsed: 7.951146ms
Mar  2 10:27:02.252: INFO: Pod "pod-projected-configmaps-ad22095d-37b5-4f99-a7e6-14d27529ec2a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028478931s
Mar  2 10:27:04.257: INFO: Pod "pod-projected-configmaps-ad22095d-37b5-4f99-a7e6-14d27529ec2a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032966131s
STEP: Saw pod success
Mar  2 10:27:04.257: INFO: Pod "pod-projected-configmaps-ad22095d-37b5-4f99-a7e6-14d27529ec2a" satisfied condition "success or failure"
Mar  2 10:27:04.262: INFO: Trying to get logs from node worker1 pod pod-projected-configmaps-ad22095d-37b5-4f99-a7e6-14d27529ec2a container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar  2 10:27:04.443: INFO: Waiting for pod pod-projected-configmaps-ad22095d-37b5-4f99-a7e6-14d27529ec2a to disappear
Mar  2 10:27:04.447: INFO: Pod pod-projected-configmaps-ad22095d-37b5-4f99-a7e6-14d27529ec2a no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:27:04.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7653" for this suite.
Mar  2 10:27:12.577: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:27:12.801: INFO: namespace projected-7653 deletion completed in 8.271383601s

• [SLOW TEST:12.996 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:27:12.802: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4854
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name secret-emptykey-test-475cc555-4fcc-46a0-b7dd-8657ed1cf911
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:27:13.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4854" for this suite.
Mar  2 10:27:21.489: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:27:21.605: INFO: namespace secrets-4854 deletion completed in 8.141743519s

• [SLOW TEST:8.804 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:27:21.606: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9967
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-9967/configmap-test-229722fd-e3f8-4f16-a841-b5e4954eeea9
STEP: Creating a pod to test consume configMaps
Mar  2 10:27:22.006: INFO: Waiting up to 5m0s for pod "pod-configmaps-b50c17fd-5dc2-4e57-be77-5da227ed759d" in namespace "configmap-9967" to be "success or failure"
Mar  2 10:27:22.010: INFO: Pod "pod-configmaps-b50c17fd-5dc2-4e57-be77-5da227ed759d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.913851ms
Mar  2 10:27:24.015: INFO: Pod "pod-configmaps-b50c17fd-5dc2-4e57-be77-5da227ed759d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009222311s
Mar  2 10:27:26.019: INFO: Pod "pod-configmaps-b50c17fd-5dc2-4e57-be77-5da227ed759d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013455407s
STEP: Saw pod success
Mar  2 10:27:26.019: INFO: Pod "pod-configmaps-b50c17fd-5dc2-4e57-be77-5da227ed759d" satisfied condition "success or failure"
Mar  2 10:27:26.024: INFO: Trying to get logs from node worker1 pod pod-configmaps-b50c17fd-5dc2-4e57-be77-5da227ed759d container env-test: <nil>
STEP: delete the pod
Mar  2 10:27:26.195: INFO: Waiting for pod pod-configmaps-b50c17fd-5dc2-4e57-be77-5da227ed759d to disappear
Mar  2 10:27:26.200: INFO: Pod pod-configmaps-b50c17fd-5dc2-4e57-be77-5da227ed759d no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:27:26.200: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9967" for this suite.
Mar  2 10:27:32.235: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:27:32.395: INFO: namespace configmap-9967 deletion completed in 6.190076356s

• [SLOW TEST:10.790 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:27:32.396: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1603
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Mar  2 10:27:33.586: INFO: Waiting up to 5m0s for pod "downward-api-ad191f98-c8f3-4627-b379-bdae673e1fd3" in namespace "downward-api-1603" to be "success or failure"
Mar  2 10:27:33.622: INFO: Pod "downward-api-ad191f98-c8f3-4627-b379-bdae673e1fd3": Phase="Pending", Reason="", readiness=false. Elapsed: 36.023113ms
Mar  2 10:27:35.628: INFO: Pod "downward-api-ad191f98-c8f3-4627-b379-bdae673e1fd3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041626851s
Mar  2 10:27:37.633: INFO: Pod "downward-api-ad191f98-c8f3-4627-b379-bdae673e1fd3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.046880254s
STEP: Saw pod success
Mar  2 10:27:37.633: INFO: Pod "downward-api-ad191f98-c8f3-4627-b379-bdae673e1fd3" satisfied condition "success or failure"
Mar  2 10:27:37.638: INFO: Trying to get logs from node worker1 pod downward-api-ad191f98-c8f3-4627-b379-bdae673e1fd3 container dapi-container: <nil>
STEP: delete the pod
Mar  2 10:27:37.729: INFO: Waiting for pod downward-api-ad191f98-c8f3-4627-b379-bdae673e1fd3 to disappear
Mar  2 10:27:37.760: INFO: Pod downward-api-ad191f98-c8f3-4627-b379-bdae673e1fd3 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:27:37.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1603" for this suite.
Mar  2 10:27:43.958: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:27:44.086: INFO: namespace downward-api-1603 deletion completed in 6.3179668s

• [SLOW TEST:11.691 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:27:44.087: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-6828
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-6828
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-6828
STEP: creating replication controller externalsvc in namespace services-6828
I0302 10:27:45.034192      24 runners.go:184] Created replication controller with name: externalsvc, namespace: services-6828, replica count: 2
I0302 10:27:48.084697      24 runners.go:184] externalsvc Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0302 10:27:51.084914      24 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName
Mar  2 10:27:51.165: INFO: Creating new exec pod
Mar  2 10:27:55.225: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 exec --namespace=services-6828 execpodm287d -- /bin/sh -x -c nslookup clusterip-service'
Mar  2 10:27:55.593: INFO: stderr: "+ nslookup clusterip-service\n"
Mar  2 10:27:55.593: INFO: stdout: "Server:\t\t10.96.0.10\nAddress:\t10.96.0.10#53\n\nclusterip-service.services-6828.svc.cluster.local\tcanonical name = externalsvc.services-6828.svc.cluster.local.\nName:\texternalsvc.services-6828.svc.cluster.local\nAddress: 10.108.166.195\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-6828, will wait for the garbage collector to delete the pods
Mar  2 10:27:55.682: INFO: Deleting ReplicationController externalsvc took: 34.480345ms
Mar  2 10:27:56.282: INFO: Terminating ReplicationController externalsvc pods took: 600.321521ms
Mar  2 10:28:11.193: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:28:11.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6828" for this suite.
Mar  2 10:28:19.355: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:28:19.568: INFO: namespace services-6828 deletion completed in 8.259836104s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:35.481 seconds]
[sig-network] Services
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:28:19.568: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-5528
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-5528
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating stateful set ss in namespace statefulset-5528
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-5528
Mar  2 10:28:19.971: INFO: Found 0 stateful pods, waiting for 1
Mar  2 10:28:30.016: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Mar  2 10:28:30.023: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 exec --namespace=statefulset-5528 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Mar  2 10:28:30.365: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Mar  2 10:28:30.365: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Mar  2 10:28:30.365: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Mar  2 10:28:30.371: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Mar  2 10:28:40.378: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar  2 10:28:40.378: INFO: Waiting for statefulset status.replicas updated to 0
Mar  2 10:28:40.476: INFO: POD   NODE     PHASE    GRACE  CONDITIONS
Mar  2 10:28:40.476: INFO: ss-0  worker1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:20 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:20 +0000 UTC  }]
Mar  2 10:28:40.476: INFO: 
Mar  2 10:28:40.476: INFO: StatefulSet ss has not reached scale 3, at 1
Mar  2 10:28:41.528: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.963132041s
Mar  2 10:28:42.536: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.911748205s
Mar  2 10:28:43.545: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.903798805s
Mar  2 10:28:44.551: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.893941806s
Mar  2 10:28:45.560: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.88791298s
Mar  2 10:28:46.568: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.87924962s
Mar  2 10:28:47.574: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.871137372s
Mar  2 10:28:48.582: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.865667293s
Mar  2 10:28:49.590: INFO: Verifying statefulset ss doesn't scale past 3 for another 857.873929ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-5528
Mar  2 10:28:50.596: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 exec --namespace=statefulset-5528 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar  2 10:28:50.973: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Mar  2 10:28:50.973: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Mar  2 10:28:50.973: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Mar  2 10:28:50.973: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 exec --namespace=statefulset-5528 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar  2 10:28:51.424: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Mar  2 10:28:51.424: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Mar  2 10:28:51.424: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Mar  2 10:28:51.424: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 exec --namespace=statefulset-5528 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Mar  2 10:28:51.769: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Mar  2 10:28:51.770: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Mar  2 10:28:51.770: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Mar  2 10:28:51.778: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Mar  2 10:28:51.778: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Mar  2 10:28:51.778: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Mar  2 10:28:51.784: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 exec --namespace=statefulset-5528 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Mar  2 10:28:52.140: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Mar  2 10:28:52.140: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Mar  2 10:28:52.140: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Mar  2 10:28:52.140: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 exec --namespace=statefulset-5528 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Mar  2 10:28:52.566: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Mar  2 10:28:52.566: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Mar  2 10:28:52.567: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Mar  2 10:28:52.567: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 exec --namespace=statefulset-5528 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Mar  2 10:28:52.914: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Mar  2 10:28:52.915: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Mar  2 10:28:52.915: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Mar  2 10:28:52.915: INFO: Waiting for statefulset status.replicas updated to 0
Mar  2 10:28:52.966: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Mar  2 10:29:03.032: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Mar  2 10:29:03.032: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Mar  2 10:29:03.032: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Mar  2 10:29:03.111: INFO: POD   NODE     PHASE    GRACE  CONDITIONS
Mar  2 10:29:03.111: INFO: ss-0  worker1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:20 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:20 +0000 UTC  }]
Mar  2 10:29:03.111: INFO: ss-1  worker2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:52 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:52 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:40 +0000 UTC  }]
Mar  2 10:29:03.111: INFO: ss-2  worker1  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:40 +0000 UTC  }]
Mar  2 10:29:03.111: INFO: 
Mar  2 10:29:03.111: INFO: StatefulSet ss has not reached scale 0, at 3
Mar  2 10:29:04.160: INFO: POD   NODE     PHASE    GRACE  CONDITIONS
Mar  2 10:29:04.160: INFO: ss-0  worker1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:20 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:20 +0000 UTC  }]
Mar  2 10:29:04.160: INFO: ss-1  worker2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:52 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:52 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:40 +0000 UTC  }]
Mar  2 10:29:04.160: INFO: ss-2  worker1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:40 +0000 UTC  }]
Mar  2 10:29:04.160: INFO: 
Mar  2 10:29:04.160: INFO: StatefulSet ss has not reached scale 0, at 3
Mar  2 10:29:05.184: INFO: POD   NODE     PHASE    GRACE  CONDITIONS
Mar  2 10:29:05.184: INFO: ss-0  worker1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:20 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:20 +0000 UTC  }]
Mar  2 10:29:05.184: INFO: ss-1  worker2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:52 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:52 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:40 +0000 UTC  }]
Mar  2 10:29:05.185: INFO: ss-2  worker1  Running  0s     [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:40 +0000 UTC  }]
Mar  2 10:29:05.185: INFO: 
Mar  2 10:29:05.185: INFO: StatefulSet ss has not reached scale 0, at 3
Mar  2 10:29:06.193: INFO: POD   NODE     PHASE    GRACE  CONDITIONS
Mar  2 10:29:06.193: INFO: ss-0  worker1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:20 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:20 +0000 UTC  }]
Mar  2 10:29:06.193: INFO: ss-1  worker2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:52 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:52 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:40 +0000 UTC  }]
Mar  2 10:29:06.193: INFO: 
Mar  2 10:29:06.193: INFO: StatefulSet ss has not reached scale 0, at 2
Mar  2 10:29:07.241: INFO: POD   NODE     PHASE    GRACE  CONDITIONS
Mar  2 10:29:07.241: INFO: ss-0  worker1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:20 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:20 +0000 UTC  }]
Mar  2 10:29:07.241: INFO: ss-1  worker2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:52 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:52 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:40 +0000 UTC  }]
Mar  2 10:29:07.241: INFO: 
Mar  2 10:29:07.241: INFO: StatefulSet ss has not reached scale 0, at 2
Mar  2 10:29:08.247: INFO: POD   NODE     PHASE    GRACE  CONDITIONS
Mar  2 10:29:08.247: INFO: ss-0  worker1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:20 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:20 +0000 UTC  }]
Mar  2 10:29:08.247: INFO: ss-1  worker2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:52 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:52 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:40 +0000 UTC  }]
Mar  2 10:29:08.247: INFO: 
Mar  2 10:29:08.247: INFO: StatefulSet ss has not reached scale 0, at 2
Mar  2 10:29:09.254: INFO: POD   NODE     PHASE    GRACE  CONDITIONS
Mar  2 10:29:09.254: INFO: ss-0  worker1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:20 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:20 +0000 UTC  }]
Mar  2 10:29:09.254: INFO: ss-1  worker2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:52 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:52 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:40 +0000 UTC  }]
Mar  2 10:29:09.254: INFO: 
Mar  2 10:29:09.254: INFO: StatefulSet ss has not reached scale 0, at 2
Mar  2 10:29:10.269: INFO: POD   NODE     PHASE    GRACE  CONDITIONS
Mar  2 10:29:10.269: INFO: ss-0  worker1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:20 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:20 +0000 UTC  }]
Mar  2 10:29:10.269: INFO: ss-1  worker2  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:40 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:52 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:52 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:40 +0000 UTC  }]
Mar  2 10:29:10.269: INFO: 
Mar  2 10:29:10.269: INFO: StatefulSet ss has not reached scale 0, at 2
Mar  2 10:29:11.276: INFO: POD   NODE     PHASE    GRACE  CONDITIONS
Mar  2 10:29:11.276: INFO: ss-0  worker1  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:20 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:20 +0000 UTC  }]
Mar  2 10:29:11.276: INFO: 
Mar  2 10:29:11.276: INFO: StatefulSet ss has not reached scale 0, at 1
Mar  2 10:29:12.315: INFO: POD   NODE     PHASE    GRACE  CONDITIONS
Mar  2 10:29:12.315: INFO: ss-0  worker1  Running  0s     [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:20 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-03-02 10:28:20 +0000 UTC  }]
Mar  2 10:29:12.316: INFO: 
Mar  2 10:29:12.316: INFO: StatefulSet ss has not reached scale 0, at 1
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-5528
Mar  2 10:29:13.325: INFO: Scaling statefulset ss to 0
Mar  2 10:29:13.340: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Mar  2 10:29:13.345: INFO: Deleting all statefulset in ns statefulset-5528
Mar  2 10:29:13.349: INFO: Scaling statefulset ss to 0
Mar  2 10:29:13.362: INFO: Waiting for statefulset status.replicas updated to 0
Mar  2 10:29:13.368: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:29:13.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5528" for this suite.
Mar  2 10:29:21.478: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:29:21.638: INFO: namespace statefulset-5528 deletion completed in 8.193940883s

• [SLOW TEST:62.069 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-cli] Kubectl client Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:29:21.638: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6820
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1540
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image 172.20.8.7/library/httpd:2.4.38-alpine
Mar  2 10:29:22.025: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 run e2e-test-httpd-deployment --image=172.20.8.7/library/httpd:2.4.38-alpine --generator=deployment/apps.v1 --namespace=kubectl-6820'
Mar  2 10:29:22.182: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Mar  2 10:29:22.182: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the deployment e2e-test-httpd-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-httpd-deployment was created
[AfterEach] Kubectl run deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1545
Mar  2 10:29:26.217: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 delete deployment e2e-test-httpd-deployment --namespace=kubectl-6820'
Mar  2 10:29:26.363: INFO: stderr: ""
Mar  2 10:29:26.363: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:29:26.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6820" for this suite.
Mar  2 10:29:34.434: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:29:34.938: INFO: namespace kubectl-6820 deletion completed in 8.558744343s

• [SLOW TEST:13.301 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1536
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:29:34.939: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-558
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-5cecddf3-6ee8-47a5-9523-e75bf953dc5f
STEP: Creating a pod to test consume configMaps
Mar  2 10:29:35.352: INFO: Waiting up to 5m0s for pod "pod-configmaps-ba65f008-20c7-4825-a2dc-9bd0e691b0c0" in namespace "configmap-558" to be "success or failure"
Mar  2 10:29:35.510: INFO: Pod "pod-configmaps-ba65f008-20c7-4825-a2dc-9bd0e691b0c0": Phase="Pending", Reason="", readiness=false. Elapsed: 158.157444ms
Mar  2 10:29:37.517: INFO: Pod "pod-configmaps-ba65f008-20c7-4825-a2dc-9bd0e691b0c0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.16568277s
Mar  2 10:29:39.525: INFO: Pod "pod-configmaps-ba65f008-20c7-4825-a2dc-9bd0e691b0c0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.173223574s
STEP: Saw pod success
Mar  2 10:29:39.525: INFO: Pod "pod-configmaps-ba65f008-20c7-4825-a2dc-9bd0e691b0c0" satisfied condition "success or failure"
Mar  2 10:29:39.531: INFO: Trying to get logs from node worker1 pod pod-configmaps-ba65f008-20c7-4825-a2dc-9bd0e691b0c0 container configmap-volume-test: <nil>
STEP: delete the pod
Mar  2 10:29:39.814: INFO: Waiting for pod pod-configmaps-ba65f008-20c7-4825-a2dc-9bd0e691b0c0 to disappear
Mar  2 10:29:39.826: INFO: Pod pod-configmaps-ba65f008-20c7-4825-a2dc-9bd0e691b0c0 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:29:39.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-558" for this suite.
Mar  2 10:29:47.904: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:29:48.041: INFO: namespace configmap-558 deletion completed in 8.207414955s

• [SLOW TEST:13.102 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:29:48.041: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9098
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Mar  2 10:29:48.362: INFO: Waiting up to 5m0s for pod "downwardapi-volume-03a29ce6-d5bc-42c8-b4d1-b5274e1acd7c" in namespace "projected-9098" to be "success or failure"
Mar  2 10:29:48.423: INFO: Pod "downwardapi-volume-03a29ce6-d5bc-42c8-b4d1-b5274e1acd7c": Phase="Pending", Reason="", readiness=false. Elapsed: 61.33738ms
Mar  2 10:29:50.431: INFO: Pod "downwardapi-volume-03a29ce6-d5bc-42c8-b4d1-b5274e1acd7c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.068824084s
Mar  2 10:29:52.437: INFO: Pod "downwardapi-volume-03a29ce6-d5bc-42c8-b4d1-b5274e1acd7c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.075154148s
STEP: Saw pod success
Mar  2 10:29:52.437: INFO: Pod "downwardapi-volume-03a29ce6-d5bc-42c8-b4d1-b5274e1acd7c" satisfied condition "success or failure"
Mar  2 10:29:52.442: INFO: Trying to get logs from node worker1 pod downwardapi-volume-03a29ce6-d5bc-42c8-b4d1-b5274e1acd7c container client-container: <nil>
STEP: delete the pod
Mar  2 10:29:52.557: INFO: Waiting for pod downwardapi-volume-03a29ce6-d5bc-42c8-b4d1-b5274e1acd7c to disappear
Mar  2 10:29:52.562: INFO: Pod downwardapi-volume-03a29ce6-d5bc-42c8-b4d1-b5274e1acd7c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:29:52.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9098" for this suite.
Mar  2 10:30:00.631: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:30:00.773: INFO: namespace projected-9098 deletion completed in 8.180614446s

• [SLOW TEST:12.731 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:30:00.773: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6006
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-11052643-ba76-4f29-970e-29f260d6f695
STEP: Creating a pod to test consume secrets
Mar  2 10:30:01.353: INFO: Waiting up to 5m0s for pod "pod-secrets-3949e990-c18a-4544-9249-49ac50c85f5a" in namespace "secrets-6006" to be "success or failure"
Mar  2 10:30:01.356: INFO: Pod "pod-secrets-3949e990-c18a-4544-9249-49ac50c85f5a": Phase="Pending", Reason="", readiness=false. Elapsed: 3.009891ms
Mar  2 10:30:03.360: INFO: Pod "pod-secrets-3949e990-c18a-4544-9249-49ac50c85f5a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007455167s
Mar  2 10:30:05.364: INFO: Pod "pod-secrets-3949e990-c18a-4544-9249-49ac50c85f5a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011645886s
STEP: Saw pod success
Mar  2 10:30:05.364: INFO: Pod "pod-secrets-3949e990-c18a-4544-9249-49ac50c85f5a" satisfied condition "success or failure"
Mar  2 10:30:05.369: INFO: Trying to get logs from node worker1 pod pod-secrets-3949e990-c18a-4544-9249-49ac50c85f5a container secret-volume-test: <nil>
STEP: delete the pod
Mar  2 10:30:05.562: INFO: Waiting for pod pod-secrets-3949e990-c18a-4544-9249-49ac50c85f5a to disappear
Mar  2 10:30:05.566: INFO: Pod pod-secrets-3949e990-c18a-4544-9249-49ac50c85f5a no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:30:05.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6006" for this suite.
Mar  2 10:30:13.615: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:30:13.832: INFO: namespace secrets-6006 deletion completed in 8.260021227s

• [SLOW TEST:13.059 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:30:13.833: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in hostpath-602
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test hostPath mode
Mar  2 10:30:14.367: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-602" to be "success or failure"
Mar  2 10:30:14.378: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 11.470395ms
Mar  2 10:30:16.565: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.198177909s
Mar  2 10:30:18.606: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.239797652s
STEP: Saw pod success
Mar  2 10:30:18.607: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Mar  2 10:30:18.672: INFO: Trying to get logs from node worker1 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Mar  2 10:30:18.862: INFO: Waiting for pod pod-host-path-test to disappear
Mar  2 10:30:18.867: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:30:18.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-602" for this suite.
Mar  2 10:30:26.966: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:30:27.186: INFO: namespace hostpath-602 deletion completed in 8.312274696s

• [SLOW TEST:13.353 seconds]
[sig-storage] HostPath
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:30:27.187: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7266
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Mar  2 10:30:27.690: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 create -f - --namespace=kubectl-7266'
Mar  2 10:30:28.311: INFO: stderr: ""
Mar  2 10:30:28.312: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar  2 10:30:28.312: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7266'
Mar  2 10:30:28.521: INFO: stderr: ""
Mar  2 10:30:28.521: INFO: stdout: "update-demo-nautilus-cktjb update-demo-nautilus-ml97h "
Mar  2 10:30:28.521: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 get pods update-demo-nautilus-cktjb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7266'
Mar  2 10:30:28.709: INFO: stderr: ""
Mar  2 10:30:28.709: INFO: stdout: ""
Mar  2 10:30:28.709: INFO: update-demo-nautilus-cktjb is created but not running
Mar  2 10:30:33.709: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7266'
Mar  2 10:30:33.873: INFO: stderr: ""
Mar  2 10:30:33.873: INFO: stdout: "update-demo-nautilus-cktjb update-demo-nautilus-ml97h "
Mar  2 10:30:33.873: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 get pods update-demo-nautilus-cktjb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7266'
Mar  2 10:30:34.030: INFO: stderr: ""
Mar  2 10:30:34.030: INFO: stdout: "true"
Mar  2 10:30:34.030: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 get pods update-demo-nautilus-cktjb -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7266'
Mar  2 10:30:34.241: INFO: stderr: ""
Mar  2 10:30:34.241: INFO: stdout: "172.20.8.7/library/nautilus:1.0"
Mar  2 10:30:34.241: INFO: validating pod update-demo-nautilus-cktjb
Mar  2 10:30:34.280: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  2 10:30:34.280: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  2 10:30:34.280: INFO: update-demo-nautilus-cktjb is verified up and running
Mar  2 10:30:34.280: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 get pods update-demo-nautilus-ml97h -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7266'
Mar  2 10:30:34.402: INFO: stderr: ""
Mar  2 10:30:34.402: INFO: stdout: "true"
Mar  2 10:30:34.402: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 get pods update-demo-nautilus-ml97h -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7266'
Mar  2 10:30:34.536: INFO: stderr: ""
Mar  2 10:30:34.536: INFO: stdout: "172.20.8.7/library/nautilus:1.0"
Mar  2 10:30:34.536: INFO: validating pod update-demo-nautilus-ml97h
Mar  2 10:30:34.543: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  2 10:30:34.543: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  2 10:30:34.543: INFO: update-demo-nautilus-ml97h is verified up and running
STEP: using delete to clean up resources
Mar  2 10:30:34.543: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 delete --grace-period=0 --force -f - --namespace=kubectl-7266'
Mar  2 10:30:34.705: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  2 10:30:34.706: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Mar  2 10:30:34.706: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-7266'
Mar  2 10:30:34.853: INFO: stderr: "No resources found in kubectl-7266 namespace.\n"
Mar  2 10:30:34.853: INFO: stdout: ""
Mar  2 10:30:34.854: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 get pods -l name=update-demo --namespace=kubectl-7266 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar  2 10:30:35.034: INFO: stderr: ""
Mar  2 10:30:35.034: INFO: stdout: "update-demo-nautilus-cktjb\nupdate-demo-nautilus-ml97h\n"
Mar  2 10:30:35.534: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-7266'
Mar  2 10:30:35.701: INFO: stderr: "No resources found in kubectl-7266 namespace.\n"
Mar  2 10:30:35.701: INFO: stdout: ""
Mar  2 10:30:35.701: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 get pods -l name=update-demo --namespace=kubectl-7266 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar  2 10:30:35.838: INFO: stderr: ""
Mar  2 10:30:35.838: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:30:35.838: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7266" for this suite.
Mar  2 10:30:47.886: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:30:48.016: INFO: namespace kubectl-7266 deletion completed in 12.170515167s

• [SLOW TEST:20.829 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:30:48.017: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-7736
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Pod that fits quota
STEP: Ensuring ResourceQuota status captures the pod usage
STEP: Not allowing a pod to be created that exceeds remaining quota
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources)
STEP: Ensuring a pod cannot update its resource requirements
STEP: Ensuring attempts to update pod resource requirements did not change quota usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:31:01.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7736" for this suite.
Mar  2 10:31:08.036: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:31:08.357: INFO: namespace resourcequota-7736 deletion completed in 6.3639579s

• [SLOW TEST:20.340 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:31:08.358: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-5506
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  2 10:31:08.934: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Mar  2 10:31:13.940: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Mar  2 10:31:13.940: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Mar  2 10:31:14.103: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-5506 /apis/apps/v1/namespaces/deployment-5506/deployments/test-cleanup-deployment 9574828c-065e-4982-b5ca-42f9bdd667ad 96731 1 2020-03-02 10:31:13 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []} {[] [] [{redis 172.20.8.7/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004891e18 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

Mar  2 10:31:14.120: INFO: New ReplicaSet "test-cleanup-deployment-658687d769" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:{test-cleanup-deployment-658687d769  deployment-5506 /apis/apps/v1/namespaces/deployment-5506/replicasets/test-cleanup-deployment-658687d769 374116f5-9203-4c4a-85f0-387f3e828d56 96734 1 2020-03-02 10:31:14 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:658687d769] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment 9574828c-065e-4982-b5ca-42f9bdd667ad 0xc00295b5a7 0xc00295b5a8}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 658687d769,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:658687d769] map[] [] []  []} {[] [] [{redis 172.20.8.7/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00295b608 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Mar  2 10:31:14.120: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Mar  2 10:31:14.121: INFO: &ReplicaSet{ObjectMeta:{test-cleanup-controller  deployment-5506 /apis/apps/v1/namespaces/deployment-5506/replicasets/test-cleanup-controller 194ff60d-7424-43ee-9767-4249c1f46e39 96732 1 2020-03-02 10:31:08 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 Deployment test-cleanup-deployment 9574828c-065e-4982-b5ca-42f9bdd667ad 0xc00295b4d7 0xc00295b4d8}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [] []  []} {[] [] [{httpd 172.20.8.7/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc00295b538 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Mar  2 10:31:14.246: INFO: Pod "test-cleanup-controller-kmchj" is available:
&Pod{ObjectMeta:{test-cleanup-controller-kmchj test-cleanup-controller- deployment-5506 /api/v1/namespaces/deployment-5506/pods/test-cleanup-controller-kmchj 5b64d893-4344-46e8-961c-f20d29165124 96724 0 2020-03-02 10:31:08 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 ReplicaSet test-cleanup-controller 194ff60d-7424-43ee-9767-4249c1f46e39 0xc0034c7f07 0xc0034c7f08}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-kcp5j,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-kcp5j,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:172.20.8.7/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-kcp5j,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 10:31:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 10:31:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 10:31:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 10:31:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.8.5,PodIP:10.244.4.76,StartTime:2020-03-02 10:31:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-03-02 10:31:10 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:172.20.8.7/library/httpd:2.4.38-alpine,ImageID:docker-pullable://172.20.8.7/library/httpd@sha256:6feb0ea7b0967367da66e8d58ba813fde32bdb92f63bfc21a9e170d211539db4,ContainerID:docker://9ec03da09cb2b1b3467eb8b178ec541cd51ffee3d3c6f8cea8873784f5c98110,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.4.76,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Mar  2 10:31:14.247: INFO: Pod "test-cleanup-deployment-658687d769-4n74v" is not available:
&Pod{ObjectMeta:{test-cleanup-deployment-658687d769-4n74v test-cleanup-deployment-658687d769- deployment-5506 /api/v1/namespaces/deployment-5506/pods/test-cleanup-deployment-658687d769-4n74v 9b6e24ca-3d9f-4f01-a627-70715296b724 96735 0 2020-03-02 10:31:14 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:658687d769] map[] [{apps/v1 ReplicaSet test-cleanup-deployment-658687d769 374116f5-9203-4c4a-85f0-387f3e828d56 0xc0021aa4d7 0xc0021aa4d8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-kcp5j,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-kcp5j,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:172.20.8.7/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-kcp5j,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:31:14.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5506" for this suite.
Mar  2 10:31:22.380: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:31:22.517: INFO: namespace deployment-5506 deletion completed in 8.263565247s

• [SLOW TEST:14.159 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:31:22.517: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-8098
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicaSet
STEP: Ensuring resource quota status captures replicaset creation
STEP: Deleting a ReplicaSet
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:31:34.291: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8098" for this suite.
Mar  2 10:31:40.388: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:31:40.612: INFO: namespace resourcequota-8098 deletion completed in 6.313643547s

• [SLOW TEST:18.094 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:31:40.612: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-8735
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  2 10:31:41.232: INFO: Creating deployment "test-recreate-deployment"
Mar  2 10:31:41.266: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Mar  2 10:31:41.275: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
Mar  2 10:31:43.364: INFO: Waiting deployment "test-recreate-deployment" to complete
Mar  2 10:31:43.388: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718741901, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718741901, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718741901, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718741901, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-8ffcb657f\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  2 10:31:45.395: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Mar  2 10:31:45.421: INFO: Updating deployment test-recreate-deployment
Mar  2 10:31:45.421: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Mar  2 10:31:46.454: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-8735 /apis/apps/v1/namespaces/deployment-8735/deployments/test-recreate-deployment 70171b04-68f4-4f82-84bb-26c2cdc0579a 96905 2 2020-03-02 10:31:41 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] []  []} {[] [] [{httpd 172.20.8.7/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00334f6b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2020-03-02 10:31:46 +0000 UTC,LastTransitionTime:2020-03-02 10:31:46 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-75f6b9b45d" is progressing.,LastUpdateTime:2020-03-02 10:31:46 +0000 UTC,LastTransitionTime:2020-03-02 10:31:41 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Mar  2 10:31:46.462: INFO: New ReplicaSet "test-recreate-deployment-75f6b9b45d" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-75f6b9b45d  deployment-8735 /apis/apps/v1/namespaces/deployment-8735/replicasets/test-recreate-deployment-75f6b9b45d f27e3547-6e8d-445e-a80b-8326b4378a0d 96900 1 2020-03-02 10:31:46 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:75f6b9b45d] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 70171b04-68f4-4f82-84bb-26c2cdc0579a 0xc00334feb7 0xc00334feb8}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 75f6b9b45d,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:75f6b9b45d] map[] [] []  []} {[] [] [{httpd 172.20.8.7/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00334ff28 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Mar  2 10:31:46.463: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Mar  2 10:31:46.463: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-8ffcb657f  deployment-8735 /apis/apps/v1/namespaces/deployment-8735/replicasets/test-recreate-deployment-8ffcb657f 501d4b3f-3486-4e1d-8a9a-ec486bf13ae1 96892 2 2020-03-02 10:31:41 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:8ffcb657f] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 70171b04-68f4-4f82-84bb-26c2cdc0579a 0xc00334ff90 0xc00334ff91}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 8ffcb657f,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:8ffcb657f] map[] [] []  []} {[] [] [{redis 172.20.8.7/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00334fff8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Mar  2 10:31:46.470: INFO: Pod "test-recreate-deployment-75f6b9b45d-7762g" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-75f6b9b45d-7762g test-recreate-deployment-75f6b9b45d- deployment-8735 /api/v1/namespaces/deployment-8735/pods/test-recreate-deployment-75f6b9b45d-7762g 2ec8c353-9adb-4074-9434-42dcfe4f294b 96904 0 2020-03-02 10:31:46 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:75f6b9b45d] map[] [{apps/v1 ReplicaSet test-recreate-deployment-75f6b9b45d f27e3547-6e8d-445e-a80b-8326b4378a0d 0xc00380e477 0xc00380e478}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-lx8vh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-lx8vh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:172.20.8.7/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-lx8vh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 10:31:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 10:31:46 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 10:31:46 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 10:31:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.8.5,PodIP:,StartTime:2020-03-02 10:31:46 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:172.20.8.7/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:31:46.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8735" for this suite.
Mar  2 10:31:54.557: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:31:54.776: INFO: namespace deployment-8735 deletion completed in 8.299553781s

• [SLOW TEST:14.164 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:31:54.777: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6777
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-6b41b600-aa28-4c4f-96f0-1e483f5bc577
STEP: Creating a pod to test consume configMaps
Mar  2 10:31:55.353: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ac32e75b-6b8f-4b52-af61-cffa38088b33" in namespace "projected-6777" to be "success or failure"
Mar  2 10:31:55.483: INFO: Pod "pod-projected-configmaps-ac32e75b-6b8f-4b52-af61-cffa38088b33": Phase="Pending", Reason="", readiness=false. Elapsed: 130.887049ms
Mar  2 10:31:57.489: INFO: Pod "pod-projected-configmaps-ac32e75b-6b8f-4b52-af61-cffa38088b33": Phase="Pending", Reason="", readiness=false. Elapsed: 2.136592133s
Mar  2 10:31:59.496: INFO: Pod "pod-projected-configmaps-ac32e75b-6b8f-4b52-af61-cffa38088b33": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.143320625s
STEP: Saw pod success
Mar  2 10:31:59.496: INFO: Pod "pod-projected-configmaps-ac32e75b-6b8f-4b52-af61-cffa38088b33" satisfied condition "success or failure"
Mar  2 10:31:59.501: INFO: Trying to get logs from node worker1 pod pod-projected-configmaps-ac32e75b-6b8f-4b52-af61-cffa38088b33 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar  2 10:31:59.831: INFO: Waiting for pod pod-projected-configmaps-ac32e75b-6b8f-4b52-af61-cffa38088b33 to disappear
Mar  2 10:31:59.850: INFO: Pod pod-projected-configmaps-ac32e75b-6b8f-4b52-af61-cffa38088b33 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:31:59.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6777" for this suite.
Mar  2 10:32:05.981: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:32:06.176: INFO: namespace projected-6777 deletion completed in 6.289677252s

• [SLOW TEST:11.399 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:32:06.176: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-3550
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's command
Mar  2 10:32:06.618: INFO: Waiting up to 5m0s for pod "var-expansion-a4d2fb74-a625-4094-ab54-5a29484c38cd" in namespace "var-expansion-3550" to be "success or failure"
Mar  2 10:32:06.622: INFO: Pod "var-expansion-a4d2fb74-a625-4094-ab54-5a29484c38cd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.410346ms
Mar  2 10:32:08.628: INFO: Pod "var-expansion-a4d2fb74-a625-4094-ab54-5a29484c38cd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01002852s
Mar  2 10:32:10.633: INFO: Pod "var-expansion-a4d2fb74-a625-4094-ab54-5a29484c38cd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015767475s
STEP: Saw pod success
Mar  2 10:32:10.633: INFO: Pod "var-expansion-a4d2fb74-a625-4094-ab54-5a29484c38cd" satisfied condition "success or failure"
Mar  2 10:32:10.640: INFO: Trying to get logs from node worker1 pod var-expansion-a4d2fb74-a625-4094-ab54-5a29484c38cd container dapi-container: <nil>
STEP: delete the pod
Mar  2 10:32:11.018: INFO: Waiting for pod var-expansion-a4d2fb74-a625-4094-ab54-5a29484c38cd to disappear
Mar  2 10:32:11.024: INFO: Pod var-expansion-a4d2fb74-a625-4094-ab54-5a29484c38cd no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:32:11.024: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-3550" for this suite.
Mar  2 10:32:19.078: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:32:19.466: INFO: namespace var-expansion-3550 deletion completed in 8.434861116s

• [SLOW TEST:13.290 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:32:19.466: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-2738
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Mar  2 10:32:19.965: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2738 /api/v1/namespaces/watch-2738/configmaps/e2e-watch-test-configmap-a 38034d58-1fb7-4be8-a5fe-30a14f495764 97056 0 2020-03-02 10:32:19 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar  2 10:32:19.965: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2738 /api/v1/namespaces/watch-2738/configmaps/e2e-watch-test-configmap-a 38034d58-1fb7-4be8-a5fe-30a14f495764 97056 0 2020-03-02 10:32:19 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Mar  2 10:32:30.071: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2738 /api/v1/namespaces/watch-2738/configmaps/e2e-watch-test-configmap-a 38034d58-1fb7-4be8-a5fe-30a14f495764 97077 0 2020-03-02 10:32:19 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Mar  2 10:32:30.071: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2738 /api/v1/namespaces/watch-2738/configmaps/e2e-watch-test-configmap-a 38034d58-1fb7-4be8-a5fe-30a14f495764 97077 0 2020-03-02 10:32:19 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Mar  2 10:32:40.114: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2738 /api/v1/namespaces/watch-2738/configmaps/e2e-watch-test-configmap-a 38034d58-1fb7-4be8-a5fe-30a14f495764 97095 0 2020-03-02 10:32:19 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar  2 10:32:40.114: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2738 /api/v1/namespaces/watch-2738/configmaps/e2e-watch-test-configmap-a 38034d58-1fb7-4be8-a5fe-30a14f495764 97095 0 2020-03-02 10:32:19 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Mar  2 10:32:50.151: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2738 /api/v1/namespaces/watch-2738/configmaps/e2e-watch-test-configmap-a 38034d58-1fb7-4be8-a5fe-30a14f495764 97114 0 2020-03-02 10:32:19 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar  2 10:32:50.152: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2738 /api/v1/namespaces/watch-2738/configmaps/e2e-watch-test-configmap-a 38034d58-1fb7-4be8-a5fe-30a14f495764 97114 0 2020-03-02 10:32:19 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Mar  2 10:33:00.186: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-2738 /api/v1/namespaces/watch-2738/configmaps/e2e-watch-test-configmap-b 535fbbd4-226b-4d26-a439-f99decc14d1b 97133 0 2020-03-02 10:33:00 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar  2 10:33:00.186: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-2738 /api/v1/namespaces/watch-2738/configmaps/e2e-watch-test-configmap-b 535fbbd4-226b-4d26-a439-f99decc14d1b 97133 0 2020-03-02 10:33:00 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Mar  2 10:33:10.230: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-2738 /api/v1/namespaces/watch-2738/configmaps/e2e-watch-test-configmap-b 535fbbd4-226b-4d26-a439-f99decc14d1b 97152 0 2020-03-02 10:33:00 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar  2 10:33:10.230: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-2738 /api/v1/namespaces/watch-2738/configmaps/e2e-watch-test-configmap-b 535fbbd4-226b-4d26-a439-f99decc14d1b 97152 0 2020-03-02 10:33:00 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:33:20.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2738" for this suite.
Mar  2 10:33:26.292: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:33:26.439: INFO: namespace watch-2738 deletion completed in 6.199453644s

• [SLOW TEST:66.973 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:33:26.440: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-9775
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9775.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-9775.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9775.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9775.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-9775.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-9775.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-9775.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-9775.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9775.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9775.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-9775.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9775.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-9775.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-9775.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-9775.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-9775.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-9775.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9775.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar  2 10:33:31.029: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-9775.svc.cluster.local from pod dns-9775/dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89: the server could not find the requested resource (get pods dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89)
Mar  2 10:33:31.035: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9775.svc.cluster.local from pod dns-9775/dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89: the server could not find the requested resource (get pods dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89)
Mar  2 10:33:31.040: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-9775.svc.cluster.local from pod dns-9775/dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89: the server could not find the requested resource (get pods dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89)
Mar  2 10:33:31.044: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-9775.svc.cluster.local from pod dns-9775/dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89: the server could not find the requested resource (get pods dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89)
Mar  2 10:33:31.168: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-9775.svc.cluster.local from pod dns-9775/dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89: the server could not find the requested resource (get pods dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89)
Mar  2 10:33:31.172: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-9775.svc.cluster.local from pod dns-9775/dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89: the server could not find the requested resource (get pods dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89)
Mar  2 10:33:31.177: INFO: Unable to read jessie_udp@dns-test-service-2.dns-9775.svc.cluster.local from pod dns-9775/dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89: the server could not find the requested resource (get pods dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89)
Mar  2 10:33:31.183: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-9775.svc.cluster.local from pod dns-9775/dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89: the server could not find the requested resource (get pods dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89)
Mar  2 10:33:31.195: INFO: Lookups using dns-9775/dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-9775.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9775.svc.cluster.local wheezy_udp@dns-test-service-2.dns-9775.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-9775.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-9775.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-9775.svc.cluster.local jessie_udp@dns-test-service-2.dns-9775.svc.cluster.local jessie_tcp@dns-test-service-2.dns-9775.svc.cluster.local]

Mar  2 10:33:36.201: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-9775.svc.cluster.local from pod dns-9775/dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89: the server could not find the requested resource (get pods dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89)
Mar  2 10:33:36.207: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9775.svc.cluster.local from pod dns-9775/dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89: the server could not find the requested resource (get pods dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89)
Mar  2 10:33:36.213: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-9775.svc.cluster.local from pod dns-9775/dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89: the server could not find the requested resource (get pods dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89)
Mar  2 10:33:36.218: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-9775.svc.cluster.local from pod dns-9775/dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89: the server could not find the requested resource (get pods dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89)
Mar  2 10:33:36.235: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-9775.svc.cluster.local from pod dns-9775/dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89: the server could not find the requested resource (get pods dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89)
Mar  2 10:33:36.241: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-9775.svc.cluster.local from pod dns-9775/dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89: the server could not find the requested resource (get pods dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89)
Mar  2 10:33:36.287: INFO: Unable to read jessie_udp@dns-test-service-2.dns-9775.svc.cluster.local from pod dns-9775/dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89: the server could not find the requested resource (get pods dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89)
Mar  2 10:33:36.292: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-9775.svc.cluster.local from pod dns-9775/dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89: the server could not find the requested resource (get pods dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89)
Mar  2 10:33:36.303: INFO: Lookups using dns-9775/dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-9775.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9775.svc.cluster.local wheezy_udp@dns-test-service-2.dns-9775.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-9775.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-9775.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-9775.svc.cluster.local jessie_udp@dns-test-service-2.dns-9775.svc.cluster.local jessie_tcp@dns-test-service-2.dns-9775.svc.cluster.local]

Mar  2 10:33:41.254: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-9775.svc.cluster.local from pod dns-9775/dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89: the server could not find the requested resource (get pods dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89)
Mar  2 10:33:41.265: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9775.svc.cluster.local from pod dns-9775/dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89: the server could not find the requested resource (get pods dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89)
Mar  2 10:33:41.272: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-9775.svc.cluster.local from pod dns-9775/dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89: the server could not find the requested resource (get pods dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89)
Mar  2 10:33:41.278: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-9775.svc.cluster.local from pod dns-9775/dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89: the server could not find the requested resource (get pods dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89)
Mar  2 10:33:41.295: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-9775.svc.cluster.local from pod dns-9775/dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89: the server could not find the requested resource (get pods dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89)
Mar  2 10:33:41.301: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-9775.svc.cluster.local from pod dns-9775/dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89: the server could not find the requested resource (get pods dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89)
Mar  2 10:33:41.308: INFO: Unable to read jessie_udp@dns-test-service-2.dns-9775.svc.cluster.local from pod dns-9775/dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89: the server could not find the requested resource (get pods dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89)
Mar  2 10:33:41.314: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-9775.svc.cluster.local from pod dns-9775/dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89: the server could not find the requested resource (get pods dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89)
Mar  2 10:33:41.329: INFO: Lookups using dns-9775/dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-9775.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9775.svc.cluster.local wheezy_udp@dns-test-service-2.dns-9775.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-9775.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-9775.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-9775.svc.cluster.local jessie_udp@dns-test-service-2.dns-9775.svc.cluster.local jessie_tcp@dns-test-service-2.dns-9775.svc.cluster.local]

Mar  2 10:33:46.203: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-9775.svc.cluster.local from pod dns-9775/dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89: the server could not find the requested resource (get pods dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89)
Mar  2 10:33:46.212: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9775.svc.cluster.local from pod dns-9775/dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89: the server could not find the requested resource (get pods dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89)
Mar  2 10:33:46.219: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-9775.svc.cluster.local from pod dns-9775/dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89: the server could not find the requested resource (get pods dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89)
Mar  2 10:33:46.225: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-9775.svc.cluster.local from pod dns-9775/dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89: the server could not find the requested resource (get pods dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89)
Mar  2 10:33:46.242: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-9775.svc.cluster.local from pod dns-9775/dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89: the server could not find the requested resource (get pods dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89)
Mar  2 10:33:46.249: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-9775.svc.cluster.local from pod dns-9775/dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89: the server could not find the requested resource (get pods dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89)
Mar  2 10:33:46.254: INFO: Unable to read jessie_udp@dns-test-service-2.dns-9775.svc.cluster.local from pod dns-9775/dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89: the server could not find the requested resource (get pods dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89)
Mar  2 10:33:46.261: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-9775.svc.cluster.local from pod dns-9775/dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89: the server could not find the requested resource (get pods dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89)
Mar  2 10:33:46.272: INFO: Lookups using dns-9775/dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-9775.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9775.svc.cluster.local wheezy_udp@dns-test-service-2.dns-9775.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-9775.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-9775.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-9775.svc.cluster.local jessie_udp@dns-test-service-2.dns-9775.svc.cluster.local jessie_tcp@dns-test-service-2.dns-9775.svc.cluster.local]

Mar  2 10:33:51.202: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-9775.svc.cluster.local from pod dns-9775/dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89: the server could not find the requested resource (get pods dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89)
Mar  2 10:33:51.208: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9775.svc.cluster.local from pod dns-9775/dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89: the server could not find the requested resource (get pods dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89)
Mar  2 10:33:51.213: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-9775.svc.cluster.local from pod dns-9775/dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89: the server could not find the requested resource (get pods dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89)
Mar  2 10:33:51.218: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-9775.svc.cluster.local from pod dns-9775/dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89: the server could not find the requested resource (get pods dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89)
Mar  2 10:33:51.233: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-9775.svc.cluster.local from pod dns-9775/dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89: the server could not find the requested resource (get pods dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89)
Mar  2 10:33:51.237: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-9775.svc.cluster.local from pod dns-9775/dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89: the server could not find the requested resource (get pods dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89)
Mar  2 10:33:51.241: INFO: Unable to read jessie_udp@dns-test-service-2.dns-9775.svc.cluster.local from pod dns-9775/dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89: the server could not find the requested resource (get pods dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89)
Mar  2 10:33:51.246: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-9775.svc.cluster.local from pod dns-9775/dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89: the server could not find the requested resource (get pods dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89)
Mar  2 10:33:51.256: INFO: Lookups using dns-9775/dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-9775.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9775.svc.cluster.local wheezy_udp@dns-test-service-2.dns-9775.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-9775.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-9775.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-9775.svc.cluster.local jessie_udp@dns-test-service-2.dns-9775.svc.cluster.local jessie_tcp@dns-test-service-2.dns-9775.svc.cluster.local]

Mar  2 10:33:56.272: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-9775.svc.cluster.local from pod dns-9775/dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89: the server could not find the requested resource (get pods dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89)
Mar  2 10:33:56.278: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9775.svc.cluster.local from pod dns-9775/dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89: the server could not find the requested resource (get pods dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89)
Mar  2 10:33:56.285: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-9775.svc.cluster.local from pod dns-9775/dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89: the server could not find the requested resource (get pods dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89)
Mar  2 10:33:56.290: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-9775.svc.cluster.local from pod dns-9775/dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89: the server could not find the requested resource (get pods dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89)
Mar  2 10:33:56.304: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-9775.svc.cluster.local from pod dns-9775/dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89: the server could not find the requested resource (get pods dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89)
Mar  2 10:33:56.309: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-9775.svc.cluster.local from pod dns-9775/dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89: the server could not find the requested resource (get pods dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89)
Mar  2 10:33:56.313: INFO: Unable to read jessie_udp@dns-test-service-2.dns-9775.svc.cluster.local from pod dns-9775/dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89: the server could not find the requested resource (get pods dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89)
Mar  2 10:33:56.319: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-9775.svc.cluster.local from pod dns-9775/dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89: the server could not find the requested resource (get pods dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89)
Mar  2 10:33:56.329: INFO: Lookups using dns-9775/dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-9775.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9775.svc.cluster.local wheezy_udp@dns-test-service-2.dns-9775.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-9775.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-9775.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-9775.svc.cluster.local jessie_udp@dns-test-service-2.dns-9775.svc.cluster.local jessie_tcp@dns-test-service-2.dns-9775.svc.cluster.local]

Mar  2 10:34:01.318: INFO: DNS probes using dns-9775/dns-test-9d64daf9-a02a-4312-9460-aadfb59d4b89 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:34:01.812: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9775" for this suite.
Mar  2 10:34:11.994: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:34:12.321: INFO: namespace dns-9775 deletion completed in 10.500958823s

• [SLOW TEST:45.881 seconds]
[sig-network] DNS
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:34:12.322: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-6944
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Mar  2 10:34:12.965: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:34:12.966: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:34:12.966: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:34:12.974: INFO: Number of nodes with available pods: 0
Mar  2 10:34:12.974: INFO: Node worker1 is running more than one daemon pod
Mar  2 10:34:14.051: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:34:14.051: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:34:14.051: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:34:14.057: INFO: Number of nodes with available pods: 0
Mar  2 10:34:14.057: INFO: Node worker1 is running more than one daemon pod
Mar  2 10:34:14.986: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:34:14.986: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:34:14.986: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:34:15.001: INFO: Number of nodes with available pods: 0
Mar  2 10:34:15.001: INFO: Node worker1 is running more than one daemon pod
Mar  2 10:34:15.980: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:34:15.981: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:34:15.981: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:34:15.998: INFO: Number of nodes with available pods: 1
Mar  2 10:34:15.998: INFO: Node worker2 is running more than one daemon pod
Mar  2 10:34:16.982: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:34:16.982: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:34:16.982: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:34:16.988: INFO: Number of nodes with available pods: 2
Mar  2 10:34:16.988: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Mar  2 10:34:17.065: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:34:17.065: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:34:17.066: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:34:17.078: INFO: Number of nodes with available pods: 2
Mar  2 10:34:17.078: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6944, will wait for the garbage collector to delete the pods
Mar  2 10:34:18.226: INFO: Deleting DaemonSet.extensions daemon-set took: 22.826842ms
Mar  2 10:34:18.926: INFO: Terminating DaemonSet.extensions daemon-set pods took: 700.306575ms
Mar  2 10:34:32.471: INFO: Number of nodes with available pods: 0
Mar  2 10:34:32.471: INFO: Number of running nodes: 0, number of available pods: 0
Mar  2 10:34:32.474: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-6944/daemonsets","resourceVersion":"97425"},"items":null}

Mar  2 10:34:32.478: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-6944/pods","resourceVersion":"97425"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:34:32.493: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6944" for this suite.
Mar  2 10:34:40.624: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:34:40.827: INFO: namespace daemonsets-6944 deletion completed in 8.329466342s

• [SLOW TEST:28.505 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:34:40.827: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-7318
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-5164
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-4013
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:34:58.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-7318" for this suite.
Mar  2 10:35:04.099: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:35:04.221: INFO: namespace namespaces-7318 deletion completed in 6.154408498s
STEP: Destroying namespace "nsdeletetest-5164" for this suite.
Mar  2 10:35:04.224: INFO: Namespace nsdeletetest-5164 was already deleted
STEP: Destroying namespace "nsdeletetest-4013" for this suite.
Mar  2 10:35:10.339: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:35:10.479: INFO: namespace nsdeletetest-4013 deletion completed in 6.254703669s

• [SLOW TEST:29.652 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:35:10.479: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8899
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-16f6b9ea-b377-4e30-88ac-0d2bcce5776f
STEP: Creating a pod to test consume configMaps
Mar  2 10:35:10.948: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c2c49c26-d135-4732-8d4b-952a35a4db52" in namespace "projected-8899" to be "success or failure"
Mar  2 10:35:10.953: INFO: Pod "pod-projected-configmaps-c2c49c26-d135-4732-8d4b-952a35a4db52": Phase="Pending", Reason="", readiness=false. Elapsed: 4.637917ms
Mar  2 10:35:12.959: INFO: Pod "pod-projected-configmaps-c2c49c26-d135-4732-8d4b-952a35a4db52": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010665797s
Mar  2 10:35:14.965: INFO: Pod "pod-projected-configmaps-c2c49c26-d135-4732-8d4b-952a35a4db52": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016551562s
STEP: Saw pod success
Mar  2 10:35:14.965: INFO: Pod "pod-projected-configmaps-c2c49c26-d135-4732-8d4b-952a35a4db52" satisfied condition "success or failure"
Mar  2 10:35:14.969: INFO: Trying to get logs from node worker1 pod pod-projected-configmaps-c2c49c26-d135-4732-8d4b-952a35a4db52 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar  2 10:35:15.091: INFO: Waiting for pod pod-projected-configmaps-c2c49c26-d135-4732-8d4b-952a35a4db52 to disappear
Mar  2 10:35:15.095: INFO: Pod pod-projected-configmaps-c2c49c26-d135-4732-8d4b-952a35a4db52 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:35:15.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8899" for this suite.
Mar  2 10:35:23.183: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:35:23.355: INFO: namespace projected-8899 deletion completed in 8.252640129s

• [SLOW TEST:12.876 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:35:23.356: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9506
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Mar  2 10:35:23.722: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 create -f - --namespace=kubectl-9506'
Mar  2 10:35:25.613: INFO: stderr: ""
Mar  2 10:35:25.613: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar  2 10:35:25.613: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9506'
Mar  2 10:35:25.958: INFO: stderr: ""
Mar  2 10:35:25.958: INFO: stdout: "update-demo-nautilus-2vdlr "
STEP: Replicas for name=update-demo: expected=2 actual=1
Mar  2 10:35:30.958: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9506'
Mar  2 10:35:31.122: INFO: stderr: ""
Mar  2 10:35:31.122: INFO: stdout: "update-demo-nautilus-2vdlr update-demo-nautilus-db5hg "
Mar  2 10:35:31.122: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 get pods update-demo-nautilus-2vdlr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9506'
Mar  2 10:35:31.275: INFO: stderr: ""
Mar  2 10:35:31.275: INFO: stdout: "true"
Mar  2 10:35:31.275: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 get pods update-demo-nautilus-2vdlr -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9506'
Mar  2 10:35:31.421: INFO: stderr: ""
Mar  2 10:35:31.421: INFO: stdout: "172.20.8.7/library/nautilus:1.0"
Mar  2 10:35:31.421: INFO: validating pod update-demo-nautilus-2vdlr
Mar  2 10:35:31.429: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  2 10:35:31.429: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  2 10:35:31.429: INFO: update-demo-nautilus-2vdlr is verified up and running
Mar  2 10:35:31.429: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 get pods update-demo-nautilus-db5hg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9506'
Mar  2 10:35:31.550: INFO: stderr: ""
Mar  2 10:35:31.550: INFO: stdout: "true"
Mar  2 10:35:31.550: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 get pods update-demo-nautilus-db5hg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9506'
Mar  2 10:35:31.703: INFO: stderr: ""
Mar  2 10:35:31.703: INFO: stdout: "172.20.8.7/library/nautilus:1.0"
Mar  2 10:35:31.703: INFO: validating pod update-demo-nautilus-db5hg
Mar  2 10:35:31.712: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  2 10:35:31.712: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  2 10:35:31.712: INFO: update-demo-nautilus-db5hg is verified up and running
STEP: scaling down the replication controller
Mar  2 10:35:31.714: INFO: scanned /root for discovery docs: <nil>
Mar  2 10:35:31.714: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-9506'
Mar  2 10:35:33.029: INFO: stderr: ""
Mar  2 10:35:33.029: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar  2 10:35:33.029: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9506'
Mar  2 10:35:33.174: INFO: stderr: ""
Mar  2 10:35:33.174: INFO: stdout: "update-demo-nautilus-2vdlr update-demo-nautilus-db5hg "
STEP: Replicas for name=update-demo: expected=1 actual=2
Mar  2 10:35:38.175: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9506'
Mar  2 10:35:38.329: INFO: stderr: ""
Mar  2 10:35:38.329: INFO: stdout: "update-demo-nautilus-2vdlr "
Mar  2 10:35:38.329: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 get pods update-demo-nautilus-2vdlr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9506'
Mar  2 10:35:38.467: INFO: stderr: ""
Mar  2 10:35:38.467: INFO: stdout: "true"
Mar  2 10:35:38.467: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 get pods update-demo-nautilus-2vdlr -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9506'
Mar  2 10:35:38.597: INFO: stderr: ""
Mar  2 10:35:38.597: INFO: stdout: "172.20.8.7/library/nautilus:1.0"
Mar  2 10:35:38.597: INFO: validating pod update-demo-nautilus-2vdlr
Mar  2 10:35:38.603: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  2 10:35:38.603: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  2 10:35:38.603: INFO: update-demo-nautilus-2vdlr is verified up and running
STEP: scaling up the replication controller
Mar  2 10:35:38.605: INFO: scanned /root for discovery docs: <nil>
Mar  2 10:35:38.605: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-9506'
Mar  2 10:35:39.823: INFO: stderr: ""
Mar  2 10:35:39.823: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar  2 10:35:39.823: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9506'
Mar  2 10:35:40.079: INFO: stderr: ""
Mar  2 10:35:40.079: INFO: stdout: "update-demo-nautilus-2vdlr update-demo-nautilus-jsnpd "
Mar  2 10:35:40.079: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 get pods update-demo-nautilus-2vdlr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9506'
Mar  2 10:35:40.235: INFO: stderr: ""
Mar  2 10:35:40.235: INFO: stdout: "true"
Mar  2 10:35:40.235: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 get pods update-demo-nautilus-2vdlr -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9506'
Mar  2 10:35:40.365: INFO: stderr: ""
Mar  2 10:35:40.365: INFO: stdout: "172.20.8.7/library/nautilus:1.0"
Mar  2 10:35:40.365: INFO: validating pod update-demo-nautilus-2vdlr
Mar  2 10:35:40.371: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  2 10:35:40.371: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  2 10:35:40.371: INFO: update-demo-nautilus-2vdlr is verified up and running
Mar  2 10:35:40.371: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 get pods update-demo-nautilus-jsnpd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9506'
Mar  2 10:35:40.537: INFO: stderr: ""
Mar  2 10:35:40.537: INFO: stdout: ""
Mar  2 10:35:40.537: INFO: update-demo-nautilus-jsnpd is created but not running
Mar  2 10:35:45.537: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9506'
Mar  2 10:35:45.687: INFO: stderr: ""
Mar  2 10:35:45.688: INFO: stdout: "update-demo-nautilus-2vdlr update-demo-nautilus-jsnpd "
Mar  2 10:35:45.688: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 get pods update-demo-nautilus-2vdlr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9506'
Mar  2 10:35:45.862: INFO: stderr: ""
Mar  2 10:35:45.862: INFO: stdout: "true"
Mar  2 10:35:45.862: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 get pods update-demo-nautilus-2vdlr -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9506'
Mar  2 10:35:46.033: INFO: stderr: ""
Mar  2 10:35:46.033: INFO: stdout: "172.20.8.7/library/nautilus:1.0"
Mar  2 10:35:46.034: INFO: validating pod update-demo-nautilus-2vdlr
Mar  2 10:35:46.040: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  2 10:35:46.040: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  2 10:35:46.040: INFO: update-demo-nautilus-2vdlr is verified up and running
Mar  2 10:35:46.040: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 get pods update-demo-nautilus-jsnpd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9506'
Mar  2 10:35:46.159: INFO: stderr: ""
Mar  2 10:35:46.159: INFO: stdout: "true"
Mar  2 10:35:46.159: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 get pods update-demo-nautilus-jsnpd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9506'
Mar  2 10:35:46.285: INFO: stderr: ""
Mar  2 10:35:46.285: INFO: stdout: "172.20.8.7/library/nautilus:1.0"
Mar  2 10:35:46.285: INFO: validating pod update-demo-nautilus-jsnpd
Mar  2 10:35:46.292: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  2 10:35:46.293: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  2 10:35:46.293: INFO: update-demo-nautilus-jsnpd is verified up and running
STEP: using delete to clean up resources
Mar  2 10:35:46.293: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 delete --grace-period=0 --force -f - --namespace=kubectl-9506'
Mar  2 10:35:46.478: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Mar  2 10:35:46.478: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Mar  2 10:35:46.478: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-9506'
Mar  2 10:35:46.623: INFO: stderr: "No resources found in kubectl-9506 namespace.\n"
Mar  2 10:35:46.623: INFO: stdout: ""
Mar  2 10:35:46.623: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 get pods -l name=update-demo --namespace=kubectl-9506 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar  2 10:35:46.765: INFO: stderr: ""
Mar  2 10:35:46.765: INFO: stdout: "update-demo-nautilus-2vdlr\nupdate-demo-nautilus-jsnpd\n"
Mar  2 10:35:47.267: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-9506'
Mar  2 10:35:47.396: INFO: stderr: "No resources found in kubectl-9506 namespace.\n"
Mar  2 10:35:47.396: INFO: stdout: ""
Mar  2 10:35:47.396: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 get pods -l name=update-demo --namespace=kubectl-9506 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Mar  2 10:35:47.513: INFO: stderr: ""
Mar  2 10:35:47.513: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:35:47.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9506" for this suite.
Mar  2 10:35:55.645: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:35:55.905: INFO: namespace kubectl-9506 deletion completed in 8.373014518s

• [SLOW TEST:32.549 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:35:55.905: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-3400
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  2 10:35:56.454: INFO: Creating ReplicaSet my-hostname-basic-692593d4-9590-4224-acc4-34a3391355ca
Mar  2 10:35:56.477: INFO: Pod name my-hostname-basic-692593d4-9590-4224-acc4-34a3391355ca: Found 0 pods out of 1
Mar  2 10:36:01.483: INFO: Pod name my-hostname-basic-692593d4-9590-4224-acc4-34a3391355ca: Found 1 pods out of 1
Mar  2 10:36:01.483: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-692593d4-9590-4224-acc4-34a3391355ca" is running
Mar  2 10:36:01.487: INFO: Pod "my-hostname-basic-692593d4-9590-4224-acc4-34a3391355ca-zdvgj" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-03-02 10:35:56 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-03-02 10:35:58 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-03-02 10:35:58 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-03-02 10:35:56 +0000 UTC Reason: Message:}])
Mar  2 10:36:01.487: INFO: Trying to dial the pod
Mar  2 10:36:06.592: INFO: Controller my-hostname-basic-692593d4-9590-4224-acc4-34a3391355ca: Got expected result from replica 1 [my-hostname-basic-692593d4-9590-4224-acc4-34a3391355ca-zdvgj]: "my-hostname-basic-692593d4-9590-4224-acc4-34a3391355ca-zdvgj", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:36:06.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-3400" for this suite.
Mar  2 10:36:14.648: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:36:14.790: INFO: namespace replicaset-3400 deletion completed in 8.189541422s

• [SLOW TEST:18.885 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:36:14.790: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8024
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Mar  2 10:36:15.302: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e59a414e-f563-4538-84e5-3261a15f95da" in namespace "projected-8024" to be "success or failure"
Mar  2 10:36:15.309: INFO: Pod "downwardapi-volume-e59a414e-f563-4538-84e5-3261a15f95da": Phase="Pending", Reason="", readiness=false. Elapsed: 6.982409ms
Mar  2 10:36:17.386: INFO: Pod "downwardapi-volume-e59a414e-f563-4538-84e5-3261a15f95da": Phase="Pending", Reason="", readiness=false. Elapsed: 2.084463194s
Mar  2 10:36:19.405: INFO: Pod "downwardapi-volume-e59a414e-f563-4538-84e5-3261a15f95da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.103482313s
STEP: Saw pod success
Mar  2 10:36:19.406: INFO: Pod "downwardapi-volume-e59a414e-f563-4538-84e5-3261a15f95da" satisfied condition "success or failure"
Mar  2 10:36:19.411: INFO: Trying to get logs from node worker1 pod downwardapi-volume-e59a414e-f563-4538-84e5-3261a15f95da container client-container: <nil>
STEP: delete the pod
Mar  2 10:36:19.556: INFO: Waiting for pod downwardapi-volume-e59a414e-f563-4538-84e5-3261a15f95da to disappear
Mar  2 10:36:19.577: INFO: Pod downwardapi-volume-e59a414e-f563-4538-84e5-3261a15f95da no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:36:19.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8024" for this suite.
Mar  2 10:36:25.732: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:36:26.036: INFO: namespace projected-8024 deletion completed in 6.346505239s

• [SLOW TEST:11.245 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:36:26.036: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-6307
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Mar  2 10:36:29.722: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:36:29.875: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-6307" for this suite.
Mar  2 10:36:37.946: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:36:38.073: INFO: namespace container-runtime-6307 deletion completed in 8.191690332s

• [SLOW TEST:12.038 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:36:38.074: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1985
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Mar  2 10:36:38.456: INFO: Waiting up to 5m0s for pod "pod-775bef10-e33d-4d54-96f8-5447165e75a9" in namespace "emptydir-1985" to be "success or failure"
Mar  2 10:36:38.461: INFO: Pod "pod-775bef10-e33d-4d54-96f8-5447165e75a9": Phase="Pending", Reason="", readiness=false. Elapsed: 3.978054ms
Mar  2 10:36:40.468: INFO: Pod "pod-775bef10-e33d-4d54-96f8-5447165e75a9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011290292s
Mar  2 10:36:42.473: INFO: Pod "pod-775bef10-e33d-4d54-96f8-5447165e75a9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016814062s
STEP: Saw pod success
Mar  2 10:36:42.473: INFO: Pod "pod-775bef10-e33d-4d54-96f8-5447165e75a9" satisfied condition "success or failure"
Mar  2 10:36:42.477: INFO: Trying to get logs from node worker1 pod pod-775bef10-e33d-4d54-96f8-5447165e75a9 container test-container: <nil>
STEP: delete the pod
Mar  2 10:36:42.608: INFO: Waiting for pod pod-775bef10-e33d-4d54-96f8-5447165e75a9 to disappear
Mar  2 10:36:42.613: INFO: Pod pod-775bef10-e33d-4d54-96f8-5447165e75a9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:36:42.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1985" for this suite.
Mar  2 10:36:48.779: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:36:48.900: INFO: namespace emptydir-1985 deletion completed in 6.279973024s

• [SLOW TEST:10.827 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:36:48.901: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-1233
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar  2 10:36:50.460: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:0, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:0, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718742210, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718742210, loc:(*time.Location)(0x788c6e0)}}, Reason:"NewReplicaSetCreated", Message:"Created new replica set \"sample-webhook-deployment-7794d7ccd5\""}}, CollisionCount:(*int32)(nil)}
Mar  2 10:36:52.465: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718742210, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718742210, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718742210, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718742210, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7794d7ccd5\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar  2 10:36:55.567: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  2 10:36:55.573: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Registering the custom resource webhook via the AdmissionRegistration API
Mar  2 10:37:01.853: INFO: Waiting for webhook configuration to be ready...
STEP: Creating a custom resource that should be denied by the webhook
STEP: Creating a custom resource whose deletion would be denied by the webhook
STEP: Updating the custom resource with disallowed data should be denied
STEP: Deleting the custom resource should be denied
STEP: Remove the offending key and value from the custom resource data
STEP: Deleting the updated custom resource should be successful
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:37:02.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1233" for this suite.
Mar  2 10:37:11.181: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:37:11.314: INFO: namespace webhook-1233 deletion completed in 8.224388811s
STEP: Destroying namespace "webhook-1233-markers" for this suite.
Mar  2 10:37:17.351: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:37:17.585: INFO: namespace webhook-1233-markers deletion completed in 6.271377259s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:28.742 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:37:17.643: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-508
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Mar  2 10:37:18.099: INFO: Waiting up to 5m0s for pod "pod-f276610c-de0d-43a1-ad74-f353ab7071e9" in namespace "emptydir-508" to be "success or failure"
Mar  2 10:37:18.185: INFO: Pod "pod-f276610c-de0d-43a1-ad74-f353ab7071e9": Phase="Pending", Reason="", readiness=false. Elapsed: 86.282085ms
Mar  2 10:37:20.191: INFO: Pod "pod-f276610c-de0d-43a1-ad74-f353ab7071e9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.091859906s
Mar  2 10:37:22.196: INFO: Pod "pod-f276610c-de0d-43a1-ad74-f353ab7071e9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.097473357s
STEP: Saw pod success
Mar  2 10:37:22.196: INFO: Pod "pod-f276610c-de0d-43a1-ad74-f353ab7071e9" satisfied condition "success or failure"
Mar  2 10:37:22.200: INFO: Trying to get logs from node worker1 pod pod-f276610c-de0d-43a1-ad74-f353ab7071e9 container test-container: <nil>
STEP: delete the pod
Mar  2 10:37:22.401: INFO: Waiting for pod pod-f276610c-de0d-43a1-ad74-f353ab7071e9 to disappear
Mar  2 10:37:22.411: INFO: Pod pod-f276610c-de0d-43a1-ad74-f353ab7071e9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:37:22.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-508" for this suite.
Mar  2 10:37:30.492: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:37:30.860: INFO: namespace emptydir-508 deletion completed in 8.445294809s

• [SLOW TEST:13.217 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:37:30.861: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-6063
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Mar  2 10:37:31.271: INFO: PodSpec: initContainers in spec.initContainers
Mar  2 10:38:13.288: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-8d4d61fe-f833-45fa-8be3-d7e1a5c4d75b", GenerateName:"", Namespace:"init-container-6063", SelfLink:"/api/v1/namespaces/init-container-6063/pods/pod-init-8d4d61fe-f833-45fa-8be3-d7e1a5c4d75b", UID:"813cf31a-a694-4352-9b1a-67467c6c00f8", ResourceVersion:"98284", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63718742251, loc:(*time.Location)(0x788c6e0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"271193939"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-9gkxh", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0036c8540), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"172.20.8.7/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-9gkxh", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"172.20.8.7/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-9gkxh", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"172.20.8.7/library/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-9gkxh", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc003c70298), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"worker1", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0037421e0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc003c70320)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc003c70340)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc003c70348), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc003c7034c), PreemptionPolicy:(*v1.PreemptionPolicy)(nil), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718742251, loc:(*time.Location)(0x788c6e0)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718742251, loc:(*time.Location)(0x788c6e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718742251, loc:(*time.Location)(0x788c6e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718742251, loc:(*time.Location)(0x788c6e0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.20.8.5", PodIP:"10.244.4.93", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.244.4.93"}}, StartTime:(*v1.Time)(0xc003b9e5e0), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002885960)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0028859d0)}, Ready:false, RestartCount:3, Image:"172.20.8.7/library/busybox:1.29", ImageID:"docker-pullable://172.20.8.7/library/busybox@sha256:e004c2cc521c95383aebb1fb5893719aa7a8eae2e7a71f316a4410784edb00a9", ContainerID:"docker://315d8f5a5eb1c92515802b05ca69568cb53d0da5dfd4604d7dea961b218ff067", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc003b9e620), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"172.20.8.7/library/busybox:1.29", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc003b9e600), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"172.20.8.7/library/pause:3.1", ImageID:"", ContainerID:"", Started:(*bool)(0xc003c703cf)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:38:13.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6063" for this suite.
Mar  2 10:38:41.445: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:38:41.579: INFO: namespace init-container-6063 deletion completed in 28.261670868s

• [SLOW TEST:70.718 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:38:41.579: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-196
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar  2 10:38:44.047: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718742323, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718742323, loc:(*time.Location)(0x788c6e0)}}, Reason:"NewReplicaSetCreated", Message:"Created new replica set \"sample-webhook-deployment-7794d7ccd5\""}, v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718742323, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718742323, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}}, CollisionCount:(*int32)(nil)}
Mar  2 10:38:46.052: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718742323, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718742323, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718742324, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718742323, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7794d7ccd5\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar  2 10:38:49.670: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating pod webhook via the AdmissionRegistration API
Mar  2 10:38:49.800: INFO: Waiting for webhook configuration to be ready...
STEP: create a pod that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:38:50.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-196" for this suite.
Mar  2 10:39:04.160: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:39:04.383: INFO: namespace webhook-196 deletion completed in 14.361499622s
STEP: Destroying namespace "webhook-196-markers" for this suite.
Mar  2 10:39:10.530: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:39:10.788: INFO: namespace webhook-196-markers deletion completed in 6.405248557s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:29.336 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:39:10.915: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3802
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Mar  2 10:39:11.364: INFO: Waiting up to 5m0s for pod "downwardapi-volume-42fc88e3-bd58-4636-b871-9bd8357c9baa" in namespace "downward-api-3802" to be "success or failure"
Mar  2 10:39:11.408: INFO: Pod "downwardapi-volume-42fc88e3-bd58-4636-b871-9bd8357c9baa": Phase="Pending", Reason="", readiness=false. Elapsed: 43.362783ms
Mar  2 10:39:13.415: INFO: Pod "downwardapi-volume-42fc88e3-bd58-4636-b871-9bd8357c9baa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.050877916s
Mar  2 10:39:15.422: INFO: Pod "downwardapi-volume-42fc88e3-bd58-4636-b871-9bd8357c9baa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.057773555s
STEP: Saw pod success
Mar  2 10:39:15.422: INFO: Pod "downwardapi-volume-42fc88e3-bd58-4636-b871-9bd8357c9baa" satisfied condition "success or failure"
Mar  2 10:39:15.429: INFO: Trying to get logs from node worker1 pod downwardapi-volume-42fc88e3-bd58-4636-b871-9bd8357c9baa container client-container: <nil>
STEP: delete the pod
Mar  2 10:39:15.536: INFO: Waiting for pod downwardapi-volume-42fc88e3-bd58-4636-b871-9bd8357c9baa to disappear
Mar  2 10:39:15.564: INFO: Pod downwardapi-volume-42fc88e3-bd58-4636-b871-9bd8357c9baa no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:39:15.564: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3802" for this suite.
Mar  2 10:39:23.667: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:39:23.818: INFO: namespace downward-api-3802 deletion completed in 8.232725632s

• [SLOW TEST:12.903 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:39:23.818: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9276
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Mar  2 10:39:24.249: INFO: Waiting up to 5m0s for pod "pod-a652c1e8-5ef4-4355-aa0a-e77939bb461a" in namespace "emptydir-9276" to be "success or failure"
Mar  2 10:39:24.278: INFO: Pod "pod-a652c1e8-5ef4-4355-aa0a-e77939bb461a": Phase="Pending", Reason="", readiness=false. Elapsed: 28.593342ms
Mar  2 10:39:26.283: INFO: Pod "pod-a652c1e8-5ef4-4355-aa0a-e77939bb461a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0333407s
Mar  2 10:39:28.289: INFO: Pod "pod-a652c1e8-5ef4-4355-aa0a-e77939bb461a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.039236366s
STEP: Saw pod success
Mar  2 10:39:28.289: INFO: Pod "pod-a652c1e8-5ef4-4355-aa0a-e77939bb461a" satisfied condition "success or failure"
Mar  2 10:39:28.295: INFO: Trying to get logs from node worker1 pod pod-a652c1e8-5ef4-4355-aa0a-e77939bb461a container test-container: <nil>
STEP: delete the pod
Mar  2 10:39:28.453: INFO: Waiting for pod pod-a652c1e8-5ef4-4355-aa0a-e77939bb461a to disappear
Mar  2 10:39:28.460: INFO: Pod pod-a652c1e8-5ef4-4355-aa0a-e77939bb461a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:39:28.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9276" for this suite.
Mar  2 10:39:34.517: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:39:34.644: INFO: namespace emptydir-9276 deletion completed in 6.177008965s

• [SLOW TEST:10.826 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:39:34.645: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9993
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-3916927f-f159-441f-8276-ff0509cf1fa0
STEP: Creating a pod to test consume configMaps
Mar  2 10:39:35.099: INFO: Waiting up to 5m0s for pod "pod-configmaps-2e15e612-3f8a-480a-8a5d-8f0cb54d1978" in namespace "configmap-9993" to be "success or failure"
Mar  2 10:39:35.104: INFO: Pod "pod-configmaps-2e15e612-3f8a-480a-8a5d-8f0cb54d1978": Phase="Pending", Reason="", readiness=false. Elapsed: 5.03084ms
Mar  2 10:39:37.109: INFO: Pod "pod-configmaps-2e15e612-3f8a-480a-8a5d-8f0cb54d1978": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01044895s
Mar  2 10:39:39.120: INFO: Pod "pod-configmaps-2e15e612-3f8a-480a-8a5d-8f0cb54d1978": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021378934s
STEP: Saw pod success
Mar  2 10:39:39.120: INFO: Pod "pod-configmaps-2e15e612-3f8a-480a-8a5d-8f0cb54d1978" satisfied condition "success or failure"
Mar  2 10:39:39.125: INFO: Trying to get logs from node worker1 pod pod-configmaps-2e15e612-3f8a-480a-8a5d-8f0cb54d1978 container configmap-volume-test: <nil>
STEP: delete the pod
Mar  2 10:39:39.280: INFO: Waiting for pod pod-configmaps-2e15e612-3f8a-480a-8a5d-8f0cb54d1978 to disappear
Mar  2 10:39:39.285: INFO: Pod pod-configmaps-2e15e612-3f8a-480a-8a5d-8f0cb54d1978 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:39:39.286: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9993" for this suite.
Mar  2 10:39:45.366: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:39:45.633: INFO: namespace configmap-9993 deletion completed in 6.340965217s

• [SLOW TEST:10.988 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:39:45.633: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9332
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on node default medium
Mar  2 10:39:46.003: INFO: Waiting up to 5m0s for pod "pod-98b94224-9b12-4dfc-afa0-c44f175b06c3" in namespace "emptydir-9332" to be "success or failure"
Mar  2 10:39:46.008: INFO: Pod "pod-98b94224-9b12-4dfc-afa0-c44f175b06c3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.54534ms
Mar  2 10:39:48.014: INFO: Pod "pod-98b94224-9b12-4dfc-afa0-c44f175b06c3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011203008s
Mar  2 10:39:50.021: INFO: Pod "pod-98b94224-9b12-4dfc-afa0-c44f175b06c3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017937902s
STEP: Saw pod success
Mar  2 10:39:50.021: INFO: Pod "pod-98b94224-9b12-4dfc-afa0-c44f175b06c3" satisfied condition "success or failure"
Mar  2 10:39:50.026: INFO: Trying to get logs from node worker1 pod pod-98b94224-9b12-4dfc-afa0-c44f175b06c3 container test-container: <nil>
STEP: delete the pod
Mar  2 10:39:50.089: INFO: Waiting for pod pod-98b94224-9b12-4dfc-afa0-c44f175b06c3 to disappear
Mar  2 10:39:50.099: INFO: Pod pod-98b94224-9b12-4dfc-afa0-c44f175b06c3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:39:50.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9332" for this suite.
Mar  2 10:39:56.192: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:39:56.326: INFO: namespace emptydir-9332 deletion completed in 6.218736739s

• [SLOW TEST:10.693 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:39:56.326: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-3856
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:40:00.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3856" for this suite.
Mar  2 10:40:08.880: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:40:09.027: INFO: namespace kubelet-test-3856 deletion completed in 8.199320338s

• [SLOW TEST:12.701 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:40:09.027: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6344
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-26213c03-253c-4e28-be73-a46663f80e9f
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-26213c03-253c-4e28-be73-a46663f80e9f
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:41:42.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6344" for this suite.
Mar  2 10:41:54.624: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:41:54.763: INFO: namespace configmap-6344 deletion completed in 12.226777548s

• [SLOW TEST:105.736 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:41:54.763: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9574
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  2 10:41:55.133: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 create -f - --namespace=kubectl-9574'
Mar  2 10:41:55.592: INFO: stderr: ""
Mar  2 10:41:55.592: INFO: stdout: "replicationcontroller/redis-master created\n"
Mar  2 10:41:55.592: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 create -f - --namespace=kubectl-9574'
Mar  2 10:41:56.154: INFO: stderr: ""
Mar  2 10:41:56.154: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Mar  2 10:41:57.161: INFO: Selector matched 1 pods for map[app:redis]
Mar  2 10:41:57.161: INFO: Found 0 / 1
Mar  2 10:41:58.162: INFO: Selector matched 1 pods for map[app:redis]
Mar  2 10:41:58.162: INFO: Found 1 / 1
Mar  2 10:41:58.162: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Mar  2 10:41:58.168: INFO: Selector matched 1 pods for map[app:redis]
Mar  2 10:41:58.168: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Mar  2 10:41:58.168: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 describe pod redis-master-zzf74 --namespace=kubectl-9574'
Mar  2 10:41:58.441: INFO: stderr: ""
Mar  2 10:41:58.441: INFO: stdout: "Name:         redis-master-zzf74\nNamespace:    kubectl-9574\nPriority:     0\nNode:         worker1/172.20.8.5\nStart Time:   Mon, 02 Mar 2020 10:41:55 +0000\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nStatus:       Running\nIP:           10.244.4.102\nIPs:\n  IP:           10.244.4.102\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://5d4b158cfb4f37ab307844d1fdc376748106dbc0d35d9a282e2df87bfc1a7ecf\n    Image:          172.20.8.7/library/redis:5.0.5-alpine\n    Image ID:       docker-pullable://172.20.8.7/library/redis@sha256:a606eaca41c3c69c7d2c8a142ec445e71156bae8526ae7970f62b6399e57761c\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Mon, 02 Mar 2020 10:41:57 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-6ldrs (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-6ldrs:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-6ldrs\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  3s    default-scheduler  Successfully assigned kubectl-9574/redis-master-zzf74 to worker1\n  Normal  Pulled     1s    kubelet, worker1   Container image \"172.20.8.7/library/redis:5.0.5-alpine\" already present on machine\n  Normal  Created    1s    kubelet, worker1   Created container redis-master\n  Normal  Started    1s    kubelet, worker1   Started container redis-master\n"
Mar  2 10:41:58.442: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 describe rc redis-master --namespace=kubectl-9574'
Mar  2 10:41:58.621: INFO: stderr: ""
Mar  2 10:41:58.621: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-9574\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        172.20.8.7/library/redis:5.0.5-alpine\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-zzf74\n"
Mar  2 10:41:58.621: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 describe service redis-master --namespace=kubectl-9574'
Mar  2 10:41:58.774: INFO: stderr: ""
Mar  2 10:41:58.774: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-9574\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.96.72.250\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.244.4.102:6379\nSession Affinity:  None\nEvents:            <none>\n"
Mar  2 10:41:58.781: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 describe node master1'
Mar  2 10:41:58.960: INFO: stderr: ""
Mar  2 10:41:58.960: INFO: stdout: "Name:               master1\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=master1\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/master=\nAnnotations:        flannel.alpha.coreos.com/backend-data: {\"VtepMAC\":\"c6:78:c6:87:1f:02\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 172.20.8.2\n                    kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Mon, 02 Mar 2020 02:19:04 +0000\nTaints:             node-role.kubernetes.io/master:NoSchedule\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Mon, 02 Mar 2020 10:41:20 +0000   Mon, 02 Mar 2020 02:19:04 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Mon, 02 Mar 2020 10:41:20 +0000   Mon, 02 Mar 2020 02:19:04 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Mon, 02 Mar 2020 10:41:20 +0000   Mon, 02 Mar 2020 02:19:04 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Mon, 02 Mar 2020 10:41:20 +0000   Mon, 02 Mar 2020 02:30:17 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  172.20.8.2\n  Hostname:    master1\nCapacity:\n cpu:                8\n ephemeral-storage:  51175Mi\n hugepages-2Mi:      0\n memory:             3878044Ki\n pods:               110\nAllocatable:\n cpu:                8\n ephemeral-storage:  48294789041\n hugepages-2Mi:      0\n memory:             3775644Ki\n pods:               110\nSystem Info:\n Machine ID:                 c1e2a7e37ea041feb133fd939fc56629\n System UUID:                564D17FA-35A3-5FA5-545D-CA0C20E0EA19\n Boot ID:                    f1256a26-35d7-43ec-8c05-9c43609f046c\n Kernel Version:             3.10.0-693.el7.x86_64\n OS Image:                   CentOS Linux 7 (Core)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.9.9\n Kubelet Version:            v1.16.7\n Kube-Proxy Version:         v1.16.7\nPodCIDR:                     10.244.2.0/24\nPodCIDRs:                    10.244.2.0/24\nNon-terminated Pods:         (7 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                coredns-74b6fc5854-grsnn                                   100m (1%)     0 (0%)      70Mi (1%)        170Mi (4%)     8h\n  kube-system                kube-apiserver-master1                                     250m (3%)     0 (0%)      0 (0%)           0 (0%)         8h\n  kube-system                kube-controller-manager-master1                            200m (2%)     0 (0%)      0 (0%)           0 (0%)         8h\n  kube-system                kube-flannel-ds-amd64-v5hqg                                100m (1%)     100m (1%)   50Mi (1%)        50Mi (1%)      7h38m\n  kube-system                kube-proxy-5tfvn                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         7h38m\n  kube-system                kube-scheduler-master1                                     100m (1%)     0 (0%)      0 (0%)           0 (0%)         8h\n  sonobuoy                   sonobuoy-systemd-logs-daemon-set-003190d3042d4113-sd488    0 (0%)        0 (0%)      0 (0%)           0 (0%)         92m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                750m (9%)   100m (1%)\n  memory             120Mi (3%)  220Mi (5%)\n  ephemeral-storage  0 (0%)      0 (0%)\nEvents:              <none>\n"
Mar  2 10:41:58.961: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 describe namespace kubectl-9574'
Mar  2 10:41:59.125: INFO: stderr: ""
Mar  2 10:41:59.125: INFO: stdout: "Name:         kubectl-9574\nLabels:       e2e-framework=kubectl\n              e2e-run=a8c81237-777b-4b10-b1f0-cd6cebfe6741\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:41:59.125: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9574" for this suite.
Mar  2 10:42:11.178: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:42:11.427: INFO: namespace kubectl-9574 deletion completed in 12.294838499s

• [SLOW TEST:16.664 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl describe
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1000
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:42:11.427: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-915
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:42:16.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-915" for this suite.
Mar  2 10:42:46.962: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:42:47.375: INFO: namespace replication-controller-915 deletion completed in 30.460027117s

• [SLOW TEST:35.948 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:42:47.375: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-8954
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation
Mar  2 10:42:47.801: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
Mar  2 10:42:58.334: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:43:20.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8954" for this suite.
Mar  2 10:43:27.027: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:43:27.165: INFO: namespace crd-publish-openapi-8954 deletion completed in 6.175732089s

• [SLOW TEST:39.790 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:43:27.165: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9241
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Mar  2 10:43:32.240: INFO: Successfully updated pod "annotationupdate188d2a09-d8d0-4191-91f5-b2348a406a7c"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:43:34.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9241" for this suite.
Mar  2 10:44:02.333: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:44:02.548: INFO: namespace downward-api-9241 deletion completed in 28.269740933s

• [SLOW TEST:35.383 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:44:02.549: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-8836
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-8836.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-8836.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8836.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-8836.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-8836.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8836.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Mar  2 10:44:07.123: INFO: DNS probes using dns-8836/dns-test-1d65fb5e-19bd-40ca-b092-1f800998e258 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:44:07.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8836" for this suite.
Mar  2 10:44:15.683: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:44:15.863: INFO: namespace dns-8836 deletion completed in 8.300717268s

• [SLOW TEST:13.313 seconds]
[sig-network] DNS
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:44:15.863: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1364
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run default
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1403
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image 172.20.8.7/library/httpd:2.4.38-alpine
Mar  2 10:44:16.394: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 run e2e-test-httpd-deployment --image=172.20.8.7/library/httpd:2.4.38-alpine --namespace=kubectl-1364'
Mar  2 10:44:16.606: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Mar  2 10:44:16.606: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the pod controlled by e2e-test-httpd-deployment gets created
[AfterEach] Kubectl run default
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1409
Mar  2 10:44:18.641: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 delete deployment e2e-test-httpd-deployment --namespace=kubectl-1364'
Mar  2 10:44:18.865: INFO: stderr: ""
Mar  2 10:44:18.865: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:44:18.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1364" for this suite.
Mar  2 10:44:46.934: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:44:47.073: INFO: namespace kubectl-1364 deletion completed in 28.198787979s

• [SLOW TEST:31.210 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run default
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1397
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:44:47.073: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-5386
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-5386
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar  2 10:44:47.498: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar  2 10:45:11.888: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.4.108:8080/dial?request=hostName&protocol=udp&host=10.244.3.178&port=8081&tries=1'] Namespace:pod-network-test-5386 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  2 10:45:11.888: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
Mar  2 10:45:12.069: INFO: Waiting for endpoints: map[]
Mar  2 10:45:12.074: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.4.108:8080/dial?request=hostName&protocol=udp&host=10.244.4.107&port=8081&tries=1'] Namespace:pod-network-test-5386 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  2 10:45:12.074: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
Mar  2 10:45:12.267: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:45:12.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5386" for this suite.
Mar  2 10:45:26.481: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:45:26.605: INFO: namespace pod-network-test-5386 deletion completed in 14.319367357s

• [SLOW TEST:39.532 seconds]
[sig-network] Networking
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:45:26.605: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-5621
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
Mar  2 10:45:27.660: INFO: created pod pod-service-account-defaultsa
Mar  2 10:45:27.660: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Mar  2 10:45:27.678: INFO: created pod pod-service-account-mountsa
Mar  2 10:45:27.678: INFO: pod pod-service-account-mountsa service account token volume mount: true
Mar  2 10:45:27.743: INFO: created pod pod-service-account-nomountsa
Mar  2 10:45:27.743: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Mar  2 10:45:27.787: INFO: created pod pod-service-account-defaultsa-mountspec
Mar  2 10:45:27.787: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Mar  2 10:45:27.811: INFO: created pod pod-service-account-mountsa-mountspec
Mar  2 10:45:27.811: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Mar  2 10:45:27.952: INFO: created pod pod-service-account-nomountsa-mountspec
Mar  2 10:45:27.952: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Mar  2 10:45:27.994: INFO: created pod pod-service-account-defaultsa-nomountspec
Mar  2 10:45:27.994: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Mar  2 10:45:28.182: INFO: created pod pod-service-account-mountsa-nomountspec
Mar  2 10:45:28.182: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Mar  2 10:45:28.437: INFO: created pod pod-service-account-nomountsa-nomountspec
Mar  2 10:45:28.437: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:45:28.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-5621" for this suite.
Mar  2 10:45:36.699: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:45:36.820: INFO: namespace svcaccounts-5621 deletion completed in 8.323136899s

• [SLOW TEST:10.215 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:45:36.820: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-9617
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-9617
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-9617
STEP: Creating statefulset with conflicting port in namespace statefulset-9617
STEP: Waiting until pod test-pod will start running in namespace statefulset-9617
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-9617
Mar  2 10:45:41.496: INFO: Observed stateful pod in namespace: statefulset-9617, name: ss-0, uid: 57593fe6-5385-4c0f-86ae-1d08ddbca9a6, status phase: Pending. Waiting for statefulset controller to delete.
Mar  2 10:45:41.599: INFO: Observed stateful pod in namespace: statefulset-9617, name: ss-0, uid: 57593fe6-5385-4c0f-86ae-1d08ddbca9a6, status phase: Failed. Waiting for statefulset controller to delete.
Mar  2 10:45:41.635: INFO: Observed stateful pod in namespace: statefulset-9617, name: ss-0, uid: 57593fe6-5385-4c0f-86ae-1d08ddbca9a6, status phase: Failed. Waiting for statefulset controller to delete.
Mar  2 10:45:41.727: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-9617
STEP: Removing pod with conflicting port in namespace statefulset-9617
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-9617 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Mar  2 10:45:45.987: INFO: Deleting all statefulset in ns statefulset-9617
Mar  2 10:45:45.991: INFO: Scaling statefulset ss to 0
Mar  2 10:45:56.028: INFO: Waiting for statefulset status.replicas updated to 0
Mar  2 10:45:56.032: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:45:56.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9617" for this suite.
Mar  2 10:46:04.117: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:46:04.242: INFO: namespace statefulset-9617 deletion completed in 8.169428658s

• [SLOW TEST:27.422 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:46:04.242: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-2362
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  2 10:46:04.660: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:46:08.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2362" for this suite.
Mar  2 10:46:54.925: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:46:55.054: INFO: namespace pods-2362 deletion completed in 46.18225762s

• [SLOW TEST:50.812 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:46:55.054: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4937
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-c190cea3-75b1-4c54-a9c4-e0f84b8b7334
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:46:59.594: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4937" for this suite.
Mar  2 10:47:13.682: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:47:13.808: INFO: namespace configmap-4937 deletion completed in 14.170327588s

• [SLOW TEST:18.754 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:47:13.808: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6554
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: executing a command with run --rm and attach with stdin
Mar  2 10:47:14.184: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 --namespace=kubectl-6554 run e2e-test-rm-busybox-job --image=172.20.8.7/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Mar  2 10:47:18.694: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Mar  2 10:47:18.694: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:47:20.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6554" for this suite.
Mar  2 10:47:26.919: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:47:27.045: INFO: namespace kubectl-6554 deletion completed in 6.332487519s

• [SLOW TEST:13.237 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run --rm job
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1751
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:47:27.045: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1989
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Mar  2 10:47:27.577: INFO: Waiting up to 5m0s for pod "pod-0dd5b09c-4bb7-4829-b680-19f6c6988376" in namespace "emptydir-1989" to be "success or failure"
Mar  2 10:47:27.590: INFO: Pod "pod-0dd5b09c-4bb7-4829-b680-19f6c6988376": Phase="Pending", Reason="", readiness=false. Elapsed: 12.859521ms
Mar  2 10:47:29.669: INFO: Pod "pod-0dd5b09c-4bb7-4829-b680-19f6c6988376": Phase="Pending", Reason="", readiness=false. Elapsed: 2.092020985s
Mar  2 10:47:31.676: INFO: Pod "pod-0dd5b09c-4bb7-4829-b680-19f6c6988376": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.098510655s
STEP: Saw pod success
Mar  2 10:47:31.676: INFO: Pod "pod-0dd5b09c-4bb7-4829-b680-19f6c6988376" satisfied condition "success or failure"
Mar  2 10:47:31.680: INFO: Trying to get logs from node worker1 pod pod-0dd5b09c-4bb7-4829-b680-19f6c6988376 container test-container: <nil>
STEP: delete the pod
Mar  2 10:47:31.882: INFO: Waiting for pod pod-0dd5b09c-4bb7-4829-b680-19f6c6988376 to disappear
Mar  2 10:47:31.889: INFO: Pod pod-0dd5b09c-4bb7-4829-b680-19f6c6988376 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:47:31.890: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1989" for this suite.
Mar  2 10:47:39.982: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:47:40.143: INFO: namespace emptydir-1989 deletion completed in 8.248200864s

• [SLOW TEST:13.098 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:47:40.144: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-6747
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-6747
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Mar  2 10:47:40.525: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Mar  2 10:48:02.869: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.3.181 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6747 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  2 10:48:02.869: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
Mar  2 10:48:04.075: INFO: Found all expected endpoints: [netserver-0]
Mar  2 10:48:04.091: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.4.124 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6747 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Mar  2 10:48:04.091: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
Mar  2 10:48:05.289: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:48:05.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-6747" for this suite.
Mar  2 10:48:19.354: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:48:19.493: INFO: namespace pod-network-test-6747 deletion completed in 14.19702264s

• [SLOW TEST:39.349 seconds]
[sig-network] Networking
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-cli] Kubectl client Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:48:19.493: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3222
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the initial replication controller
Mar  2 10:48:19.839: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 create -f - --namespace=kubectl-3222'
Mar  2 10:48:20.333: INFO: stderr: ""
Mar  2 10:48:20.333: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar  2 10:48:20.333: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3222'
Mar  2 10:48:20.481: INFO: stderr: ""
Mar  2 10:48:20.481: INFO: stdout: "update-demo-nautilus-ks2wg update-demo-nautilus-scpxq "
Mar  2 10:48:20.481: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 get pods update-demo-nautilus-ks2wg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3222'
Mar  2 10:48:20.627: INFO: stderr: ""
Mar  2 10:48:20.627: INFO: stdout: ""
Mar  2 10:48:20.627: INFO: update-demo-nautilus-ks2wg is created but not running
Mar  2 10:48:25.627: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3222'
Mar  2 10:48:25.762: INFO: stderr: ""
Mar  2 10:48:25.762: INFO: stdout: "update-demo-nautilus-ks2wg update-demo-nautilus-scpxq "
Mar  2 10:48:25.762: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 get pods update-demo-nautilus-ks2wg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3222'
Mar  2 10:48:25.887: INFO: stderr: ""
Mar  2 10:48:25.887: INFO: stdout: "true"
Mar  2 10:48:25.887: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 get pods update-demo-nautilus-ks2wg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3222'
Mar  2 10:48:26.029: INFO: stderr: ""
Mar  2 10:48:26.029: INFO: stdout: "172.20.8.7/library/nautilus:1.0"
Mar  2 10:48:26.029: INFO: validating pod update-demo-nautilus-ks2wg
Mar  2 10:48:26.039: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  2 10:48:26.039: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  2 10:48:26.039: INFO: update-demo-nautilus-ks2wg is verified up and running
Mar  2 10:48:26.039: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 get pods update-demo-nautilus-scpxq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3222'
Mar  2 10:48:26.178: INFO: stderr: ""
Mar  2 10:48:26.178: INFO: stdout: "true"
Mar  2 10:48:26.179: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 get pods update-demo-nautilus-scpxq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3222'
Mar  2 10:48:26.325: INFO: stderr: ""
Mar  2 10:48:26.325: INFO: stdout: "172.20.8.7/library/nautilus:1.0"
Mar  2 10:48:26.325: INFO: validating pod update-demo-nautilus-scpxq
Mar  2 10:48:26.332: INFO: got data: {
  "image": "nautilus.jpg"
}

Mar  2 10:48:26.332: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Mar  2 10:48:26.332: INFO: update-demo-nautilus-scpxq is verified up and running
STEP: rolling-update to new replication controller
Mar  2 10:48:26.334: INFO: scanned /root for discovery docs: <nil>
Mar  2 10:48:26.334: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-3222'
Mar  2 10:48:49.781: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Mar  2 10:48:49.781: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Mar  2 10:48:49.781: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3222'
Mar  2 10:48:49.915: INFO: stderr: ""
Mar  2 10:48:49.915: INFO: stdout: "update-demo-kitten-2wd77 update-demo-kitten-gk9rf "
Mar  2 10:48:49.915: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 get pods update-demo-kitten-2wd77 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3222'
Mar  2 10:48:50.045: INFO: stderr: ""
Mar  2 10:48:50.045: INFO: stdout: "true"
Mar  2 10:48:50.045: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 get pods update-demo-kitten-2wd77 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3222'
Mar  2 10:48:50.193: INFO: stderr: ""
Mar  2 10:48:50.193: INFO: stdout: "172.20.8.7/library/kitten:1.0"
Mar  2 10:48:50.193: INFO: validating pod update-demo-kitten-2wd77
Mar  2 10:48:50.210: INFO: got data: {
  "image": "kitten.jpg"
}

Mar  2 10:48:50.210: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Mar  2 10:48:50.210: INFO: update-demo-kitten-2wd77 is verified up and running
Mar  2 10:48:50.210: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 get pods update-demo-kitten-gk9rf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3222'
Mar  2 10:48:50.342: INFO: stderr: ""
Mar  2 10:48:50.342: INFO: stdout: "true"
Mar  2 10:48:50.342: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 get pods update-demo-kitten-gk9rf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3222'
Mar  2 10:48:50.480: INFO: stderr: ""
Mar  2 10:48:50.480: INFO: stdout: "172.20.8.7/library/kitten:1.0"
Mar  2 10:48:50.480: INFO: validating pod update-demo-kitten-gk9rf
Mar  2 10:48:50.489: INFO: got data: {
  "image": "kitten.jpg"
}

Mar  2 10:48:50.489: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Mar  2 10:48:50.489: INFO: update-demo-kitten-gk9rf is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:48:50.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3222" for this suite.
Mar  2 10:49:20.565: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:49:20.710: INFO: namespace kubectl-3222 deletion completed in 30.213570003s

• [SLOW TEST:61.217 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:49:20.711: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-6749
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Mar  2 10:49:20.999: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:49:24.601: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6749" for this suite.
Mar  2 10:49:30.656: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:49:30.843: INFO: namespace init-container-6749 deletion completed in 6.234108662s

• [SLOW TEST:10.133 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:49:30.844: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2895
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Mar  2 10:49:31.299: INFO: Waiting up to 5m0s for pod "pod-3146c77a-42dc-485d-8f3f-5dd134055a74" in namespace "emptydir-2895" to be "success or failure"
Mar  2 10:49:31.304: INFO: Pod "pod-3146c77a-42dc-485d-8f3f-5dd134055a74": Phase="Pending", Reason="", readiness=false. Elapsed: 4.786067ms
Mar  2 10:49:33.309: INFO: Pod "pod-3146c77a-42dc-485d-8f3f-5dd134055a74": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010283804s
Mar  2 10:49:35.315: INFO: Pod "pod-3146c77a-42dc-485d-8f3f-5dd134055a74": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016198721s
STEP: Saw pod success
Mar  2 10:49:35.315: INFO: Pod "pod-3146c77a-42dc-485d-8f3f-5dd134055a74" satisfied condition "success or failure"
Mar  2 10:49:35.321: INFO: Trying to get logs from node worker1 pod pod-3146c77a-42dc-485d-8f3f-5dd134055a74 container test-container: <nil>
STEP: delete the pod
Mar  2 10:49:35.439: INFO: Waiting for pod pod-3146c77a-42dc-485d-8f3f-5dd134055a74 to disappear
Mar  2 10:49:35.479: INFO: Pod pod-3146c77a-42dc-485d-8f3f-5dd134055a74 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:49:35.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2895" for this suite.
Mar  2 10:49:41.521: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:49:41.697: INFO: namespace emptydir-2895 deletion completed in 6.21182655s

• [SLOW TEST:10.854 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:49:41.698: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-6167
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Mar  2 10:49:42.108: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Mar  2 10:49:42.136: INFO: Waiting for terminating namespaces to be deleted...
Mar  2 10:49:42.141: INFO: 
Logging pods the kubelet thinks is on node worker1 before test
Mar  2 10:49:42.151: INFO: sonobuoy-e2e-job-6f4cd8785f284b6e from sonobuoy started at 2020-03-02 09:09:33 +0000 UTC (2 container statuses recorded)
Mar  2 10:49:42.151: INFO: 	Container e2e ready: true, restart count 0
Mar  2 10:49:42.151: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Mar  2 10:49:42.151: INFO: kube-flannel-ds-amd64-hmpfw from kube-system started at 2020-03-02 03:03:50 +0000 UTC (1 container statuses recorded)
Mar  2 10:49:42.151: INFO: 	Container kube-flannel ready: true, restart count 0
Mar  2 10:49:42.151: INFO: kube-proxy-bnv2b from kube-system started at 2020-03-02 03:03:07 +0000 UTC (1 container statuses recorded)
Mar  2 10:49:42.151: INFO: 	Container kube-proxy ready: true, restart count 0
Mar  2 10:49:42.151: INFO: sonobuoy from sonobuoy started at 2020-03-02 09:09:31 +0000 UTC (1 container statuses recorded)
Mar  2 10:49:42.151: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Mar  2 10:49:42.151: INFO: sonobuoy-systemd-logs-daemon-set-003190d3042d4113-rtkgw from sonobuoy started at 2020-03-02 09:09:34 +0000 UTC (2 container statuses recorded)
Mar  2 10:49:42.151: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Mar  2 10:49:42.151: INFO: 	Container systemd-logs ready: true, restart count 0
Mar  2 10:49:42.151: INFO: envoy-hwmt2 from projectcontour started at 2020-03-02 02:43:15 +0000 UTC (1 container statuses recorded)
Mar  2 10:49:42.151: INFO: 	Container envoy ready: false, restart count 0
Mar  2 10:49:42.151: INFO: 
Logging pods the kubelet thinks is on node worker2 before test
Mar  2 10:49:42.181: INFO: contour-certgen-bh5fh from projectcontour started at 2020-03-02 02:40:59 +0000 UTC (1 container statuses recorded)
Mar  2 10:49:42.181: INFO: 	Container contour ready: false, restart count 0
Mar  2 10:49:42.181: INFO: kuard-85c85bcf66-qv4qm from default started at 2020-03-02 02:41:50 +0000 UTC (1 container statuses recorded)
Mar  2 10:49:42.181: INFO: 	Container kuard ready: true, restart count 0
Mar  2 10:49:42.181: INFO: sonobuoy-systemd-logs-daemon-set-003190d3042d4113-4dn5h from sonobuoy started at 2020-03-02 09:09:34 +0000 UTC (2 container statuses recorded)
Mar  2 10:49:42.181: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Mar  2 10:49:42.181: INFO: 	Container systemd-logs ready: true, restart count 0
Mar  2 10:49:42.181: INFO: kube-proxy-77czp from kube-system started at 2020-03-02 03:03:11 +0000 UTC (1 container statuses recorded)
Mar  2 10:49:42.181: INFO: 	Container kube-proxy ready: true, restart count 0
Mar  2 10:49:42.181: INFO: kuard-85c85bcf66-6dv5z from default started at 2020-03-02 02:41:51 +0000 UTC (1 container statuses recorded)
Mar  2 10:49:42.181: INFO: 	Container kuard ready: true, restart count 0
Mar  2 10:49:42.181: INFO: contour-7594d96455-sm4qm from projectcontour started at 2020-03-02 02:40:59 +0000 UTC (1 container statuses recorded)
Mar  2 10:49:42.181: INFO: 	Container contour ready: false, restart count 0
Mar  2 10:49:42.181: INFO: kube-flannel-ds-amd64-6l2th from kube-system started at 2020-03-02 03:04:01 +0000 UTC (1 container statuses recorded)
Mar  2 10:49:42.181: INFO: 	Container kube-flannel ready: true, restart count 0
Mar  2 10:49:42.181: INFO: metrics-server-557c6b848b-k8ssl from kube-system started at 2020-03-02 02:41:51 +0000 UTC (1 container statuses recorded)
Mar  2 10:49:42.181: INFO: 	Container metrics-server ready: true, restart count 0
Mar  2 10:49:42.181: INFO: envoy-l4k6z from projectcontour started at 2020-03-02 02:40:59 +0000 UTC (1 container statuses recorded)
Mar  2 10:49:42.181: INFO: 	Container envoy ready: false, restart count 0
Mar  2 10:49:42.181: INFO: kuard-85c85bcf66-lf9xs from default started at 2020-03-02 02:41:49 +0000 UTC (1 container statuses recorded)
Mar  2 10:49:42.181: INFO: 	Container kuard ready: true, restart count 0
Mar  2 10:49:42.181: INFO: contour-7594d96455-vcdf6 from projectcontour started at 2020-03-02 02:40:59 +0000 UTC (1 container statuses recorded)
Mar  2 10:49:42.181: INFO: 	Container contour ready: false, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-23ff7cf4-f995-48a0-8fd4-faca4b81940c 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-23ff7cf4-f995-48a0-8fd4-faca4b81940c off the node worker1
STEP: verifying the node doesn't have the label kubernetes.io/e2e-23ff7cf4-f995-48a0-8fd4-faca4b81940c
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:49:50.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-6167" for this suite.
Mar  2 10:50:04.706: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:50:04.994: INFO: namespace sched-pred-6167 deletion completed in 14.312113905s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:23.296 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:50:04.994: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-7974
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation
Mar  2 10:50:05.501: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
Mar  2 10:50:14.960: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:50:38.869: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7974" for this suite.
Mar  2 10:50:44.943: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:50:45.120: INFO: namespace crd-publish-openapi-7974 deletion completed in 6.244378539s

• [SLOW TEST:40.126 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:50:45.121: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9363
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl logs
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1274
STEP: creating an pod
Mar  2 10:50:45.435: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 run logs-generator --generator=run-pod/v1 --image=172.20.8.7/library/agnhost:2.6 --namespace=kubectl-9363 -- logs-generator --log-lines-total 100 --run-duration 20s'
Mar  2 10:50:45.663: INFO: stderr: ""
Mar  2 10:50:45.663: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Waiting for log generator to start.
Mar  2 10:50:45.663: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Mar  2 10:50:45.663: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-9363" to be "running and ready, or succeeded"
Mar  2 10:50:45.705: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 42.231229ms
Mar  2 10:50:47.710: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.047352168s
Mar  2 10:50:49.715: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 4.051933361s
Mar  2 10:50:49.715: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Mar  2 10:50:49.715: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings
Mar  2 10:50:49.715: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 logs logs-generator logs-generator --namespace=kubectl-9363'
Mar  2 10:50:49.912: INFO: stderr: ""
Mar  2 10:50:49.912: INFO: stdout: "I0302 10:50:47.378398       1 logs_generator.go:76] 0 POST /api/v1/namespaces/default/pods/c8q 479\nI0302 10:50:47.578573       1 logs_generator.go:76] 1 POST /api/v1/namespaces/default/pods/rvvp 462\nI0302 10:50:47.778660       1 logs_generator.go:76] 2 GET /api/v1/namespaces/kube-system/pods/dk2n 307\nI0302 10:50:47.978570       1 logs_generator.go:76] 3 GET /api/v1/namespaces/default/pods/tn86 553\nI0302 10:50:48.178656       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/kube-system/pods/8djd 413\nI0302 10:50:48.378583       1 logs_generator.go:76] 5 POST /api/v1/namespaces/default/pods/r6kr 534\nI0302 10:50:48.578667       1 logs_generator.go:76] 6 GET /api/v1/namespaces/default/pods/7xf 425\nI0302 10:50:48.778593       1 logs_generator.go:76] 7 GET /api/v1/namespaces/kube-system/pods/nf4v 392\nI0302 10:50:48.978562       1 logs_generator.go:76] 8 POST /api/v1/namespaces/kube-system/pods/hw9k 380\nI0302 10:50:49.178618       1 logs_generator.go:76] 9 GET /api/v1/namespaces/kube-system/pods/mqbk 294\nI0302 10:50:49.378657       1 logs_generator.go:76] 10 GET /api/v1/namespaces/kube-system/pods/jd2q 222\nI0302 10:50:49.578596       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/kube-system/pods/knh 320\nI0302 10:50:49.778566       1 logs_generator.go:76] 12 GET /api/v1/namespaces/kube-system/pods/69r 226\n"
STEP: limiting log lines
Mar  2 10:50:49.912: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 logs logs-generator logs-generator --namespace=kubectl-9363 --tail=1'
Mar  2 10:50:50.096: INFO: stderr: ""
Mar  2 10:50:50.096: INFO: stdout: "I0302 10:50:49.978551       1 logs_generator.go:76] 13 GET /api/v1/namespaces/default/pods/xrcm 260\n"
STEP: limiting log bytes
Mar  2 10:50:50.096: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 logs logs-generator logs-generator --namespace=kubectl-9363 --limit-bytes=1'
Mar  2 10:50:50.281: INFO: stderr: ""
Mar  2 10:50:50.281: INFO: stdout: "I"
STEP: exposing timestamps
Mar  2 10:50:50.281: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 logs logs-generator logs-generator --namespace=kubectl-9363 --tail=1 --timestamps'
Mar  2 10:50:50.434: INFO: stderr: ""
Mar  2 10:50:50.434: INFO: stdout: "2020-03-02T10:50:50.378967926Z I0302 10:50:50.378577       1 logs_generator.go:76] 15 GET /api/v1/namespaces/kube-system/pods/v9d 523\n"
STEP: restricting to a time range
Mar  2 10:50:52.934: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 logs logs-generator logs-generator --namespace=kubectl-9363 --since=1s'
Mar  2 10:50:53.103: INFO: stderr: ""
Mar  2 10:50:53.104: INFO: stdout: "I0302 10:50:52.178601       1 logs_generator.go:76] 24 GET /api/v1/namespaces/ns/pods/lbd5 262\nI0302 10:50:52.378542       1 logs_generator.go:76] 25 POST /api/v1/namespaces/kube-system/pods/tzlx 369\nI0302 10:50:52.578580       1 logs_generator.go:76] 26 PUT /api/v1/namespaces/default/pods/h9bq 527\nI0302 10:50:52.778607       1 logs_generator.go:76] 27 PUT /api/v1/namespaces/default/pods/dxvf 376\nI0302 10:50:52.978579       1 logs_generator.go:76] 28 POST /api/v1/namespaces/ns/pods/sdgc 262\n"
Mar  2 10:50:53.104: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 logs logs-generator logs-generator --namespace=kubectl-9363 --since=24h'
Mar  2 10:50:53.280: INFO: stderr: ""
Mar  2 10:50:53.280: INFO: stdout: "I0302 10:50:47.378398       1 logs_generator.go:76] 0 POST /api/v1/namespaces/default/pods/c8q 479\nI0302 10:50:47.578573       1 logs_generator.go:76] 1 POST /api/v1/namespaces/default/pods/rvvp 462\nI0302 10:50:47.778660       1 logs_generator.go:76] 2 GET /api/v1/namespaces/kube-system/pods/dk2n 307\nI0302 10:50:47.978570       1 logs_generator.go:76] 3 GET /api/v1/namespaces/default/pods/tn86 553\nI0302 10:50:48.178656       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/kube-system/pods/8djd 413\nI0302 10:50:48.378583       1 logs_generator.go:76] 5 POST /api/v1/namespaces/default/pods/r6kr 534\nI0302 10:50:48.578667       1 logs_generator.go:76] 6 GET /api/v1/namespaces/default/pods/7xf 425\nI0302 10:50:48.778593       1 logs_generator.go:76] 7 GET /api/v1/namespaces/kube-system/pods/nf4v 392\nI0302 10:50:48.978562       1 logs_generator.go:76] 8 POST /api/v1/namespaces/kube-system/pods/hw9k 380\nI0302 10:50:49.178618       1 logs_generator.go:76] 9 GET /api/v1/namespaces/kube-system/pods/mqbk 294\nI0302 10:50:49.378657       1 logs_generator.go:76] 10 GET /api/v1/namespaces/kube-system/pods/jd2q 222\nI0302 10:50:49.578596       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/kube-system/pods/knh 320\nI0302 10:50:49.778566       1 logs_generator.go:76] 12 GET /api/v1/namespaces/kube-system/pods/69r 226\nI0302 10:50:49.978551       1 logs_generator.go:76] 13 GET /api/v1/namespaces/default/pods/xrcm 260\nI0302 10:50:50.178552       1 logs_generator.go:76] 14 GET /api/v1/namespaces/kube-system/pods/9c9 356\nI0302 10:50:50.378577       1 logs_generator.go:76] 15 GET /api/v1/namespaces/kube-system/pods/v9d 523\nI0302 10:50:50.578648       1 logs_generator.go:76] 16 POST /api/v1/namespaces/default/pods/wt8t 231\nI0302 10:50:50.778591       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/kube-system/pods/4fw7 591\nI0302 10:50:50.978552       1 logs_generator.go:76] 18 POST /api/v1/namespaces/ns/pods/v77l 277\nI0302 10:50:51.178582       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/ns/pods/ddm 223\nI0302 10:50:51.378564       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/default/pods/7xsv 447\nI0302 10:50:51.578585       1 logs_generator.go:76] 21 PUT /api/v1/namespaces/ns/pods/f2m 265\nI0302 10:50:51.778651       1 logs_generator.go:76] 22 PUT /api/v1/namespaces/kube-system/pods/2jk8 261\nI0302 10:50:51.978593       1 logs_generator.go:76] 23 POST /api/v1/namespaces/ns/pods/8dl4 494\nI0302 10:50:52.178601       1 logs_generator.go:76] 24 GET /api/v1/namespaces/ns/pods/lbd5 262\nI0302 10:50:52.378542       1 logs_generator.go:76] 25 POST /api/v1/namespaces/kube-system/pods/tzlx 369\nI0302 10:50:52.578580       1 logs_generator.go:76] 26 PUT /api/v1/namespaces/default/pods/h9bq 527\nI0302 10:50:52.778607       1 logs_generator.go:76] 27 PUT /api/v1/namespaces/default/pods/dxvf 376\nI0302 10:50:52.978579       1 logs_generator.go:76] 28 POST /api/v1/namespaces/ns/pods/sdgc 262\nI0302 10:50:53.178567       1 logs_generator.go:76] 29 PUT /api/v1/namespaces/kube-system/pods/9k6 338\n"
[AfterEach] Kubectl logs
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1280
Mar  2 10:50:53.280: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 delete pod logs-generator --namespace=kubectl-9363'
Mar  2 10:51:02.338: INFO: stderr: ""
Mar  2 10:51:02.338: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:51:02.338: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9363" for this suite.
Mar  2 10:51:08.389: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:51:08.631: INFO: namespace kubectl-9363 deletion completed in 6.286726798s

• [SLOW TEST:23.510 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl logs
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1270
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:51:08.632: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3240
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Mar  2 10:51:08.992: INFO: Waiting up to 5m0s for pod "pod-f0a2f665-d7b3-49d4-8b5f-a5cfe89b4c36" in namespace "emptydir-3240" to be "success or failure"
Mar  2 10:51:09.005: INFO: Pod "pod-f0a2f665-d7b3-49d4-8b5f-a5cfe89b4c36": Phase="Pending", Reason="", readiness=false. Elapsed: 13.127611ms
Mar  2 10:51:11.182: INFO: Pod "pod-f0a2f665-d7b3-49d4-8b5f-a5cfe89b4c36": Phase="Pending", Reason="", readiness=false. Elapsed: 2.190317339s
Mar  2 10:51:13.188: INFO: Pod "pod-f0a2f665-d7b3-49d4-8b5f-a5cfe89b4c36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.195905171s
STEP: Saw pod success
Mar  2 10:51:13.188: INFO: Pod "pod-f0a2f665-d7b3-49d4-8b5f-a5cfe89b4c36" satisfied condition "success or failure"
Mar  2 10:51:13.192: INFO: Trying to get logs from node worker1 pod pod-f0a2f665-d7b3-49d4-8b5f-a5cfe89b4c36 container test-container: <nil>
STEP: delete the pod
Mar  2 10:51:13.435: INFO: Waiting for pod pod-f0a2f665-d7b3-49d4-8b5f-a5cfe89b4c36 to disappear
Mar  2 10:51:13.439: INFO: Pod pod-f0a2f665-d7b3-49d4-8b5f-a5cfe89b4c36 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:51:13.439: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3240" for this suite.
Mar  2 10:51:19.484: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:51:19.723: INFO: namespace emptydir-3240 deletion completed in 6.277538857s

• [SLOW TEST:11.091 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:51:19.724: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-2470
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's args
Mar  2 10:51:20.071: INFO: Waiting up to 5m0s for pod "var-expansion-bcfa383c-393c-4d24-b9c6-6fe034d873d3" in namespace "var-expansion-2470" to be "success or failure"
Mar  2 10:51:20.074: INFO: Pod "var-expansion-bcfa383c-393c-4d24-b9c6-6fe034d873d3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.24094ms
Mar  2 10:51:22.079: INFO: Pod "var-expansion-bcfa383c-393c-4d24-b9c6-6fe034d873d3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008005138s
Mar  2 10:51:24.083: INFO: Pod "var-expansion-bcfa383c-393c-4d24-b9c6-6fe034d873d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012169174s
STEP: Saw pod success
Mar  2 10:51:24.083: INFO: Pod "var-expansion-bcfa383c-393c-4d24-b9c6-6fe034d873d3" satisfied condition "success or failure"
Mar  2 10:51:24.088: INFO: Trying to get logs from node worker1 pod var-expansion-bcfa383c-393c-4d24-b9c6-6fe034d873d3 container dapi-container: <nil>
STEP: delete the pod
Mar  2 10:51:24.391: INFO: Waiting for pod var-expansion-bcfa383c-393c-4d24-b9c6-6fe034d873d3 to disappear
Mar  2 10:51:24.405: INFO: Pod var-expansion-bcfa383c-393c-4d24-b9c6-6fe034d873d3 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:51:24.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2470" for this suite.
Mar  2 10:51:30.477: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:51:30.660: INFO: namespace var-expansion-2470 deletion completed in 6.247112892s

• [SLOW TEST:10.936 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:51:30.660: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2316
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Mar  2 10:51:35.691: INFO: Successfully updated pod "annotationupdate0eaab86d-75c5-40a7-beba-da25a0a8e2bd"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:51:37.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2316" for this suite.
Mar  2 10:51:53.771: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:51:53.955: INFO: namespace projected-2316 deletion completed in 16.229357223s

• [SLOW TEST:23.295 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:51:53.955: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8802
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating cluster-info
Mar  2 10:51:54.311: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 cluster-info'
Mar  2 10:51:54.441: INFO: stderr: ""
Mar  2 10:51:54.441: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mMetrics-server\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/https:metrics-server:/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:51:54.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8802" for this suite.
Mar  2 10:52:00.644: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:52:00.798: INFO: namespace kubectl-8802 deletion completed in 6.346881192s

• [SLOW TEST:6.843 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl cluster-info
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:974
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:52:00.799: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-6367
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Mar  2 10:52:09.511: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  2 10:52:09.517: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  2 10:52:11.517: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  2 10:52:11.523: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  2 10:52:13.517: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  2 10:52:13.526: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  2 10:52:15.517: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  2 10:52:15.524: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  2 10:52:17.517: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  2 10:52:17.524: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  2 10:52:19.517: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  2 10:52:19.528: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  2 10:52:21.517: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  2 10:52:21.522: INFO: Pod pod-with-poststart-exec-hook still exists
Mar  2 10:52:23.517: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Mar  2 10:52:23.526: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:52:23.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-6367" for this suite.
Mar  2 10:52:51.575: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:52:51.713: INFO: namespace container-lifecycle-hook-6367 deletion completed in 28.17661307s

• [SLOW TEST:50.914 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:52:51.714: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6334
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Mar  2 10:52:56.644: INFO: Successfully updated pod "labelsupdatead4a1138-72a8-4a98-8f9b-9e47eb52df45"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:52:58.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6334" for this suite.
Mar  2 10:53:10.767: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:53:10.890: INFO: namespace downward-api-6334 deletion completed in 12.190186059s

• [SLOW TEST:19.177 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:53:10.890: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5259
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-d04f1fc8-e0e0-41d0-9df6-454ba38ed180
STEP: Creating a pod to test consume configMaps
Mar  2 10:53:11.294: INFO: Waiting up to 5m0s for pod "pod-configmaps-10648766-27bb-435b-a1c9-e5c5ea5ced74" in namespace "configmap-5259" to be "success or failure"
Mar  2 10:53:11.370: INFO: Pod "pod-configmaps-10648766-27bb-435b-a1c9-e5c5ea5ced74": Phase="Pending", Reason="", readiness=false. Elapsed: 76.030169ms
Mar  2 10:53:13.402: INFO: Pod "pod-configmaps-10648766-27bb-435b-a1c9-e5c5ea5ced74": Phase="Pending", Reason="", readiness=false. Elapsed: 2.107362842s
Mar  2 10:53:15.407: INFO: Pod "pod-configmaps-10648766-27bb-435b-a1c9-e5c5ea5ced74": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.112465308s
STEP: Saw pod success
Mar  2 10:53:15.407: INFO: Pod "pod-configmaps-10648766-27bb-435b-a1c9-e5c5ea5ced74" satisfied condition "success or failure"
Mar  2 10:53:15.412: INFO: Trying to get logs from node worker1 pod pod-configmaps-10648766-27bb-435b-a1c9-e5c5ea5ced74 container configmap-volume-test: <nil>
STEP: delete the pod
Mar  2 10:53:15.481: INFO: Waiting for pod pod-configmaps-10648766-27bb-435b-a1c9-e5c5ea5ced74 to disappear
Mar  2 10:53:15.581: INFO: Pod pod-configmaps-10648766-27bb-435b-a1c9-e5c5ea5ced74 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:53:15.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5259" for this suite.
Mar  2 10:53:23.655: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:53:23.803: INFO: namespace configmap-5259 deletion completed in 8.213949073s

• [SLOW TEST:12.912 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:53:23.803: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-6559
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:53:24.556: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6559" for this suite.
Mar  2 10:53:30.812: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:53:30.919: INFO: namespace kubelet-test-6559 deletion completed in 6.170330093s

• [SLOW TEST:7.116 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:53:30.920: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7025
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-e707dae5-0dbb-4d0f-b0c7-16ec9be7216e
STEP: Creating a pod to test consume configMaps
Mar  2 10:53:31.493: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5e965549-26e8-450f-ab7f-cd08dc4f94e6" in namespace "projected-7025" to be "success or failure"
Mar  2 10:53:31.509: INFO: Pod "pod-projected-configmaps-5e965549-26e8-450f-ab7f-cd08dc4f94e6": Phase="Pending", Reason="", readiness=false. Elapsed: 16.410573ms
Mar  2 10:53:33.515: INFO: Pod "pod-projected-configmaps-5e965549-26e8-450f-ab7f-cd08dc4f94e6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021505846s
Mar  2 10:53:35.522: INFO: Pod "pod-projected-configmaps-5e965549-26e8-450f-ab7f-cd08dc4f94e6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.028613361s
STEP: Saw pod success
Mar  2 10:53:35.522: INFO: Pod "pod-projected-configmaps-5e965549-26e8-450f-ab7f-cd08dc4f94e6" satisfied condition "success or failure"
Mar  2 10:53:35.526: INFO: Trying to get logs from node worker1 pod pod-projected-configmaps-5e965549-26e8-450f-ab7f-cd08dc4f94e6 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar  2 10:53:35.696: INFO: Waiting for pod pod-projected-configmaps-5e965549-26e8-450f-ab7f-cd08dc4f94e6 to disappear
Mar  2 10:53:35.743: INFO: Pod pod-projected-configmaps-5e965549-26e8-450f-ab7f-cd08dc4f94e6 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:53:35.743: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7025" for this suite.
Mar  2 10:53:41.835: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:53:42.062: INFO: namespace projected-7025 deletion completed in 6.312508771s

• [SLOW TEST:11.142 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:53:42.062: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-9035
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  2 10:53:42.459: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Mar  2 10:53:42.501: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:53:42.501: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:53:42.501: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:53:42.505: INFO: Number of nodes with available pods: 0
Mar  2 10:53:42.505: INFO: Node worker1 is running more than one daemon pod
Mar  2 10:53:43.512: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:53:43.513: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:53:43.513: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:53:43.517: INFO: Number of nodes with available pods: 0
Mar  2 10:53:43.517: INFO: Node worker1 is running more than one daemon pod
Mar  2 10:53:44.513: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:53:44.513: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:53:44.513: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:53:44.518: INFO: Number of nodes with available pods: 0
Mar  2 10:53:44.518: INFO: Node worker1 is running more than one daemon pod
Mar  2 10:53:45.556: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:53:45.556: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:53:45.556: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:53:45.562: INFO: Number of nodes with available pods: 1
Mar  2 10:53:45.562: INFO: Node worker2 is running more than one daemon pod
Mar  2 10:53:46.512: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:53:46.512: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:53:46.512: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:53:46.518: INFO: Number of nodes with available pods: 2
Mar  2 10:53:46.518: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Mar  2 10:53:46.675: INFO: Wrong image for pod: daemon-set-6kd2g. Expected: 172.20.8.7/library/redis:5.0.5-alpine, got: 172.20.8.7/library/httpd:2.4.38-alpine.
Mar  2 10:53:46.675: INFO: Wrong image for pod: daemon-set-ggxcn. Expected: 172.20.8.7/library/redis:5.0.5-alpine, got: 172.20.8.7/library/httpd:2.4.38-alpine.
Mar  2 10:53:46.681: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:53:46.681: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:53:46.681: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:53:47.686: INFO: Wrong image for pod: daemon-set-6kd2g. Expected: 172.20.8.7/library/redis:5.0.5-alpine, got: 172.20.8.7/library/httpd:2.4.38-alpine.
Mar  2 10:53:47.686: INFO: Wrong image for pod: daemon-set-ggxcn. Expected: 172.20.8.7/library/redis:5.0.5-alpine, got: 172.20.8.7/library/httpd:2.4.38-alpine.
Mar  2 10:53:47.692: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:53:47.692: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:53:47.692: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:53:48.686: INFO: Wrong image for pod: daemon-set-6kd2g. Expected: 172.20.8.7/library/redis:5.0.5-alpine, got: 172.20.8.7/library/httpd:2.4.38-alpine.
Mar  2 10:53:48.686: INFO: Wrong image for pod: daemon-set-ggxcn. Expected: 172.20.8.7/library/redis:5.0.5-alpine, got: 172.20.8.7/library/httpd:2.4.38-alpine.
Mar  2 10:53:48.686: INFO: Pod daemon-set-ggxcn is not available
Mar  2 10:53:48.693: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:53:48.693: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:53:48.693: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:53:49.808: INFO: Wrong image for pod: daemon-set-6kd2g. Expected: 172.20.8.7/library/redis:5.0.5-alpine, got: 172.20.8.7/library/httpd:2.4.38-alpine.
Mar  2 10:53:49.808: INFO: Pod daemon-set-glccf is not available
Mar  2 10:53:49.814: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:53:49.814: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:53:49.814: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:53:50.687: INFO: Wrong image for pod: daemon-set-6kd2g. Expected: 172.20.8.7/library/redis:5.0.5-alpine, got: 172.20.8.7/library/httpd:2.4.38-alpine.
Mar  2 10:53:50.688: INFO: Pod daemon-set-glccf is not available
Mar  2 10:53:50.704: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:53:50.704: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:53:50.704: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:53:51.686: INFO: Wrong image for pod: daemon-set-6kd2g. Expected: 172.20.8.7/library/redis:5.0.5-alpine, got: 172.20.8.7/library/httpd:2.4.38-alpine.
Mar  2 10:53:51.818: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:53:51.818: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:53:51.818: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:53:52.727: INFO: Wrong image for pod: daemon-set-6kd2g. Expected: 172.20.8.7/library/redis:5.0.5-alpine, got: 172.20.8.7/library/httpd:2.4.38-alpine.
Mar  2 10:53:52.735: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:53:52.735: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:53:52.735: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:53:53.687: INFO: Wrong image for pod: daemon-set-6kd2g. Expected: 172.20.8.7/library/redis:5.0.5-alpine, got: 172.20.8.7/library/httpd:2.4.38-alpine.
Mar  2 10:53:53.692: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:53:53.692: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:53:53.692: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:53:54.686: INFO: Wrong image for pod: daemon-set-6kd2g. Expected: 172.20.8.7/library/redis:5.0.5-alpine, got: 172.20.8.7/library/httpd:2.4.38-alpine.
Mar  2 10:53:54.686: INFO: Pod daemon-set-6kd2g is not available
Mar  2 10:53:54.700: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:53:54.700: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:53:54.700: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:53:55.687: INFO: Pod daemon-set-q6nv4 is not available
Mar  2 10:53:55.703: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:53:55.703: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:53:55.703: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Mar  2 10:53:55.729: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:53:55.729: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:53:55.729: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:53:55.742: INFO: Number of nodes with available pods: 1
Mar  2 10:53:55.742: INFO: Node worker2 is running more than one daemon pod
Mar  2 10:53:56.759: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:53:56.759: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:53:56.759: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:53:56.764: INFO: Number of nodes with available pods: 1
Mar  2 10:53:56.764: INFO: Node worker2 is running more than one daemon pod
Mar  2 10:53:57.748: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:53:57.748: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:53:57.748: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:53:57.761: INFO: Number of nodes with available pods: 1
Mar  2 10:53:57.761: INFO: Node worker2 is running more than one daemon pod
Mar  2 10:53:58.748: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:53:58.748: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:53:58.748: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:53:58.754: INFO: Number of nodes with available pods: 1
Mar  2 10:53:58.754: INFO: Node worker2 is running more than one daemon pod
Mar  2 10:53:59.801: INFO: DaemonSet pods can't tolerate node master1 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:53:59.802: INFO: DaemonSet pods can't tolerate node master2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:53:59.802: INFO: DaemonSet pods can't tolerate node master3 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Mar  2 10:53:59.806: INFO: Number of nodes with available pods: 2
Mar  2 10:53:59.806: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9035, will wait for the garbage collector to delete the pods
Mar  2 10:53:59.903: INFO: Deleting DaemonSet.extensions daemon-set took: 22.471466ms
Mar  2 10:54:00.403: INFO: Terminating DaemonSet.extensions daemon-set pods took: 500.21026ms
Mar  2 10:54:10.907: INFO: Number of nodes with available pods: 0
Mar  2 10:54:10.907: INFO: Number of running nodes: 0, number of available pods: 0
Mar  2 10:54:10.910: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9035/daemonsets","resourceVersion":"101689"},"items":null}

Mar  2 10:54:10.919: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9035/pods","resourceVersion":"101689"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:54:10.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9035" for this suite.
Mar  2 10:54:19.006: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:54:19.172: INFO: namespace daemonsets-9035 deletion completed in 8.2324589s

• [SLOW TEST:37.110 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:54:19.172: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-7177
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-7177
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Mar  2 10:54:19.665: INFO: Found 0 stateful pods, waiting for 3
Mar  2 10:54:29.672: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar  2 10:54:29.672: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar  2 10:54:29.672: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=false
Mar  2 10:54:39.675: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar  2 10:54:39.675: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar  2 10:54:39.675: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from 172.20.8.7/library/httpd:2.4.38-alpine to 172.20.8.7/library/httpd:2.4.39-alpine
Mar  2 10:54:39.756: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Mar  2 10:54:49.849: INFO: Updating stateful set ss2
Mar  2 10:54:49.857: INFO: Waiting for Pod statefulset-7177/ss2-2 to have revision ss2-95cdf5d68 update revision ss2-5f4b4c7df9
Mar  2 10:54:59.867: INFO: Waiting for Pod statefulset-7177/ss2-2 to have revision ss2-95cdf5d68 update revision ss2-5f4b4c7df9
STEP: Restoring Pods to the correct revision when they are deleted
Mar  2 10:55:10.270: INFO: Found 2 stateful pods, waiting for 3
Mar  2 10:55:20.278: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Mar  2 10:55:20.278: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Mar  2 10:55:20.278: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Mar  2 10:55:20.316: INFO: Updating stateful set ss2
Mar  2 10:55:20.366: INFO: Waiting for Pod statefulset-7177/ss2-1 to have revision ss2-95cdf5d68 update revision ss2-5f4b4c7df9
Mar  2 10:55:30.458: INFO: Updating stateful set ss2
Mar  2 10:55:30.524: INFO: Waiting for StatefulSet statefulset-7177/ss2 to complete update
Mar  2 10:55:30.524: INFO: Waiting for Pod statefulset-7177/ss2-0 to have revision ss2-95cdf5d68 update revision ss2-5f4b4c7df9
Mar  2 10:55:40.534: INFO: Waiting for StatefulSet statefulset-7177/ss2 to complete update
Mar  2 10:55:40.534: INFO: Waiting for Pod statefulset-7177/ss2-0 to have revision ss2-95cdf5d68 update revision ss2-5f4b4c7df9
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Mar  2 10:55:50.536: INFO: Deleting all statefulset in ns statefulset-7177
Mar  2 10:55:50.542: INFO: Scaling statefulset ss2 to 0
Mar  2 10:56:10.581: INFO: Waiting for statefulset status.replicas updated to 0
Mar  2 10:56:10.588: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:56:10.618: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7177" for this suite.
Mar  2 10:56:20.652: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:56:20.766: INFO: namespace statefulset-7177 deletion completed in 10.141998565s

• [SLOW TEST:121.594 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:56:20.767: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-7484
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating replication controller my-hostname-basic-870232dd-0bcf-4be9-bca7-a0cc9133bad2
Mar  2 10:56:21.118: INFO: Pod name my-hostname-basic-870232dd-0bcf-4be9-bca7-a0cc9133bad2: Found 0 pods out of 1
Mar  2 10:56:26.124: INFO: Pod name my-hostname-basic-870232dd-0bcf-4be9-bca7-a0cc9133bad2: Found 1 pods out of 1
Mar  2 10:56:26.124: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-870232dd-0bcf-4be9-bca7-a0cc9133bad2" are running
Mar  2 10:56:26.128: INFO: Pod "my-hostname-basic-870232dd-0bcf-4be9-bca7-a0cc9133bad2-ctd9p" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-03-02 10:56:21 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-03-02 10:56:23 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-03-02 10:56:23 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-03-02 10:56:21 +0000 UTC Reason: Message:}])
Mar  2 10:56:26.128: INFO: Trying to dial the pod
Mar  2 10:56:31.145: INFO: Controller my-hostname-basic-870232dd-0bcf-4be9-bca7-a0cc9133bad2: Got expected result from replica 1 [my-hostname-basic-870232dd-0bcf-4be9-bca7-a0cc9133bad2-ctd9p]: "my-hostname-basic-870232dd-0bcf-4be9-bca7-a0cc9133bad2-ctd9p", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:56:31.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-7484" for this suite.
Mar  2 10:56:39.187: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:56:39.364: INFO: namespace replication-controller-7484 deletion completed in 8.213490013s

• [SLOW TEST:18.597 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:56:39.365: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-2351
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:56:43.877: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2351" for this suite.
Mar  2 10:57:29.960: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:57:30.081: INFO: namespace kubelet-test-2351 deletion completed in 46.194976384s

• [SLOW TEST:50.717 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a read only busybox container
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:57:30.082: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-2925
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-2925
[It] should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating statefulset ss in namespace statefulset-2925
Mar  2 10:57:30.817: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
Mar  2 10:57:40.822: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Mar  2 10:57:40.869: INFO: Deleting all statefulset in ns statefulset-2925
Mar  2 10:57:40.897: INFO: Scaling statefulset ss to 0
Mar  2 10:58:00.978: INFO: Waiting for statefulset status.replicas updated to 0
Mar  2 10:58:00.982: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:58:01.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2925" for this suite.
Mar  2 10:58:09.065: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:58:09.255: INFO: namespace statefulset-2925 deletion completed in 8.225151739s

• [SLOW TEST:39.173 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should have a working scale subresource [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:58:09.255: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9805
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-6bdc0447-cb1e-49f8-9514-ede76cce54bf
STEP: Creating a pod to test consume secrets
Mar  2 10:58:09.679: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-4a385a51-1924-410b-85e8-47cfa34c540d" in namespace "projected-9805" to be "success or failure"
Mar  2 10:58:09.682: INFO: Pod "pod-projected-secrets-4a385a51-1924-410b-85e8-47cfa34c540d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.712108ms
Mar  2 10:58:11.688: INFO: Pod "pod-projected-secrets-4a385a51-1924-410b-85e8-47cfa34c540d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009106246s
Mar  2 10:58:13.697: INFO: Pod "pod-projected-secrets-4a385a51-1924-410b-85e8-47cfa34c540d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018386254s
STEP: Saw pod success
Mar  2 10:58:13.697: INFO: Pod "pod-projected-secrets-4a385a51-1924-410b-85e8-47cfa34c540d" satisfied condition "success or failure"
Mar  2 10:58:13.701: INFO: Trying to get logs from node worker1 pod pod-projected-secrets-4a385a51-1924-410b-85e8-47cfa34c540d container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar  2 10:58:13.856: INFO: Waiting for pod pod-projected-secrets-4a385a51-1924-410b-85e8-47cfa34c540d to disappear
Mar  2 10:58:13.901: INFO: Pod pod-projected-secrets-4a385a51-1924-410b-85e8-47cfa34c540d no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:58:13.901: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9805" for this suite.
Mar  2 10:58:22.132: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:58:22.451: INFO: namespace projected-9805 deletion completed in 8.543548302s

• [SLOW TEST:13.196 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:58:22.452: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5577
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Mar  2 10:58:22.768: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4b50f964-c4a6-4dad-8219-f97918d7041c" in namespace "downward-api-5577" to be "success or failure"
Mar  2 10:58:22.773: INFO: Pod "downwardapi-volume-4b50f964-c4a6-4dad-8219-f97918d7041c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.742726ms
Mar  2 10:58:24.779: INFO: Pod "downwardapi-volume-4b50f964-c4a6-4dad-8219-f97918d7041c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011066472s
Mar  2 10:58:26.785: INFO: Pod "downwardapi-volume-4b50f964-c4a6-4dad-8219-f97918d7041c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01697626s
STEP: Saw pod success
Mar  2 10:58:26.785: INFO: Pod "downwardapi-volume-4b50f964-c4a6-4dad-8219-f97918d7041c" satisfied condition "success or failure"
Mar  2 10:58:26.791: INFO: Trying to get logs from node worker1 pod downwardapi-volume-4b50f964-c4a6-4dad-8219-f97918d7041c container client-container: <nil>
STEP: delete the pod
Mar  2 10:58:26.872: INFO: Waiting for pod downwardapi-volume-4b50f964-c4a6-4dad-8219-f97918d7041c to disappear
Mar  2 10:58:26.914: INFO: Pod downwardapi-volume-4b50f964-c4a6-4dad-8219-f97918d7041c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:58:26.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5577" for this suite.
Mar  2 10:58:32.972: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:58:33.195: INFO: namespace downward-api-5577 deletion completed in 6.271584757s

• [SLOW TEST:10.743 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:58:33.195: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-9771
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Mar  2 10:58:36.596: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:58:36.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-9771" for this suite.
Mar  2 10:58:42.799: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:58:42.932: INFO: namespace container-runtime-9771 deletion completed in 6.204513163s

• [SLOW TEST:9.737 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:58:42.933: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5112
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Mar  2 10:58:43.476: INFO: Waiting up to 5m0s for pod "downward-api-728a8cf8-ca3a-442e-8bcc-c92696f660e7" in namespace "downward-api-5112" to be "success or failure"
Mar  2 10:58:43.481: INFO: Pod "downward-api-728a8cf8-ca3a-442e-8bcc-c92696f660e7": Phase="Pending", Reason="", readiness=false. Elapsed: 5.091437ms
Mar  2 10:58:45.509: INFO: Pod "downward-api-728a8cf8-ca3a-442e-8bcc-c92696f660e7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033614232s
Mar  2 10:58:47.516: INFO: Pod "downward-api-728a8cf8-ca3a-442e-8bcc-c92696f660e7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040197375s
STEP: Saw pod success
Mar  2 10:58:47.516: INFO: Pod "downward-api-728a8cf8-ca3a-442e-8bcc-c92696f660e7" satisfied condition "success or failure"
Mar  2 10:58:47.523: INFO: Trying to get logs from node worker1 pod downward-api-728a8cf8-ca3a-442e-8bcc-c92696f660e7 container dapi-container: <nil>
STEP: delete the pod
Mar  2 10:58:47.625: INFO: Waiting for pod downward-api-728a8cf8-ca3a-442e-8bcc-c92696f660e7 to disappear
Mar  2 10:58:47.630: INFO: Pod downward-api-728a8cf8-ca3a-442e-8bcc-c92696f660e7 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:58:47.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5112" for this suite.
Mar  2 10:58:53.729: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:58:54.035: INFO: namespace downward-api-5112 deletion completed in 6.397549275s

• [SLOW TEST:11.102 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:58:54.037: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-2121
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Mar  2 10:59:04.752: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:59:04.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W0302 10:59:04.752560      24 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-2121" for this suite.
Mar  2 10:59:12.807: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:59:12.933: INFO: namespace gc-2121 deletion completed in 8.174900466s

• [SLOW TEST:18.897 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:59:12.934: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-482
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:59:39.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-482" for this suite.
Mar  2 10:59:47.938: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:59:48.074: INFO: namespace container-runtime-482 deletion completed in 8.187613821s

• [SLOW TEST:35.140 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    when starting a container that exits
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:40
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:59:48.074: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4023
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Mar  2 10:59:48.618: INFO: Waiting up to 5m0s for pod "pod-5f632b80-50db-4473-a2bb-a14888aafe1f" in namespace "emptydir-4023" to be "success or failure"
Mar  2 10:59:48.678: INFO: Pod "pod-5f632b80-50db-4473-a2bb-a14888aafe1f": Phase="Pending", Reason="", readiness=false. Elapsed: 59.788131ms
Mar  2 10:59:50.685: INFO: Pod "pod-5f632b80-50db-4473-a2bb-a14888aafe1f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.067118532s
Mar  2 10:59:52.692: INFO: Pod "pod-5f632b80-50db-4473-a2bb-a14888aafe1f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.073884636s
STEP: Saw pod success
Mar  2 10:59:52.692: INFO: Pod "pod-5f632b80-50db-4473-a2bb-a14888aafe1f" satisfied condition "success or failure"
Mar  2 10:59:52.697: INFO: Trying to get logs from node worker1 pod pod-5f632b80-50db-4473-a2bb-a14888aafe1f container test-container: <nil>
STEP: delete the pod
Mar  2 10:59:52.862: INFO: Waiting for pod pod-5f632b80-50db-4473-a2bb-a14888aafe1f to disappear
Mar  2 10:59:52.868: INFO: Pod pod-5f632b80-50db-4473-a2bb-a14888aafe1f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 10:59:52.868: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4023" for this suite.
Mar  2 10:59:58.914: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 10:59:59.090: INFO: namespace emptydir-4023 deletion completed in 6.214822456s

• [SLOW TEST:11.015 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 10:59:59.090: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-4444
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Mar  2 10:59:59.578: INFO: Pod name pod-release: Found 0 pods out of 1
Mar  2 11:00:04.584: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 11:00:05.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-4444" for this suite.
Mar  2 11:00:13.760: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 11:00:13.954: INFO: namespace replication-controller-4444 deletion completed in 8.310358197s

• [SLOW TEST:14.865 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 11:00:13.955: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-5632
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating pod
Mar  2 11:00:18.489: INFO: Pod pod-hostip-225756de-e3e4-4b9c-97f8-3373ae853ec2 has hostIP: 172.20.8.5
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 11:00:18.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5632" for this suite.
Mar  2 11:00:30.553: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 11:00:30.769: INFO: namespace pods-5632 deletion completed in 12.272649176s

• [SLOW TEST:16.815 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 11:00:30.770: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5124
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-c15210d4-e8c5-402f-a7fd-050add291ed0
STEP: Creating a pod to test consume configMaps
Mar  2 11:00:31.195: INFO: Waiting up to 5m0s for pod "pod-configmaps-a8025027-3f07-4070-9980-0ae112d56010" in namespace "configmap-5124" to be "success or failure"
Mar  2 11:00:31.224: INFO: Pod "pod-configmaps-a8025027-3f07-4070-9980-0ae112d56010": Phase="Pending", Reason="", readiness=false. Elapsed: 28.75977ms
Mar  2 11:00:33.261: INFO: Pod "pod-configmaps-a8025027-3f07-4070-9980-0ae112d56010": Phase="Pending", Reason="", readiness=false. Elapsed: 2.065815987s
Mar  2 11:00:35.268: INFO: Pod "pod-configmaps-a8025027-3f07-4070-9980-0ae112d56010": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.072887885s
STEP: Saw pod success
Mar  2 11:00:35.268: INFO: Pod "pod-configmaps-a8025027-3f07-4070-9980-0ae112d56010" satisfied condition "success or failure"
Mar  2 11:00:35.274: INFO: Trying to get logs from node worker1 pod pod-configmaps-a8025027-3f07-4070-9980-0ae112d56010 container configmap-volume-test: <nil>
STEP: delete the pod
Mar  2 11:00:35.380: INFO: Waiting for pod pod-configmaps-a8025027-3f07-4070-9980-0ae112d56010 to disappear
Mar  2 11:00:35.384: INFO: Pod pod-configmaps-a8025027-3f07-4070-9980-0ae112d56010 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 11:00:35.384: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5124" for this suite.
Mar  2 11:00:41.442: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 11:00:41.612: INFO: namespace configmap-5124 deletion completed in 6.219586386s

• [SLOW TEST:10.842 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 11:00:41.612: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename aggregator
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in aggregator-472
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:77
Mar  2 11:00:41.953: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the sample API server.
Mar  2 11:00:43.592: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Mar  2 11:00:45.939: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718743643, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718743643, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718743643, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718743643, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-5c59b48dc4\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  2 11:00:49.431: INFO: Waited 1.400366332s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:68
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 11:00:50.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-472" for this suite.
Mar  2 11:00:58.820: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 11:00:59.164: INFO: namespace aggregator-472 deletion completed in 8.370767703s

• [SLOW TEST:17.552 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 11:00:59.165: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-7319
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  2 11:00:59.572: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Mar  2 11:01:01.732: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 11:01:02.744: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-7319" for this suite.
Mar  2 11:01:10.798: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 11:01:10.929: INFO: namespace replication-controller-7319 deletion completed in 8.177676873s

• [SLOW TEST:11.765 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 11:01:10.930: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename crd-webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-webhook-1272
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Mar  2 11:01:12.682: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Mar  2 11:01:14.709: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718743672, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718743672, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718743672, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718743672, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-5bb99b877f\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar  2 11:01:17.786: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  2 11:01:17.791: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Creating a v1 custom resource
STEP: Create a v2 custom resource
STEP: List CRs in v1
STEP: List CRs in v2
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 11:01:25.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-1272" for this suite.
Mar  2 11:01:33.109: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 11:01:33.479: INFO: namespace crd-webhook-1272 deletion completed in 8.422344565s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:22.585 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 11:01:33.516: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-5334
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod test-webserver-f624eacf-fa43-44c4-8f47-571b7d618a5e in namespace container-probe-5334
Mar  2 11:01:38.112: INFO: Started pod test-webserver-f624eacf-fa43-44c4-8f47-571b7d618a5e in namespace container-probe-5334
STEP: checking the pod's current state and verifying that restartCount is present
Mar  2 11:01:38.119: INFO: Initial restart count of pod test-webserver-f624eacf-fa43-44c4-8f47-571b7d618a5e is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 11:05:39.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5334" for this suite.
Mar  2 11:05:48.045: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 11:05:48.175: INFO: namespace container-probe-5334 deletion completed in 8.183291278s

• [SLOW TEST:254.659 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 11:05:48.175: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-7399
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  2 11:05:48.570: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Mar  2 11:05:58.419: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 --namespace=crd-publish-openapi-7399 create -f -'
Mar  2 11:06:00.847: INFO: stderr: ""
Mar  2 11:06:00.847: INFO: stdout: "e2e-test-crd-publish-openapi-7662-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Mar  2 11:06:00.847: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 --namespace=crd-publish-openapi-7399 delete e2e-test-crd-publish-openapi-7662-crds test-cr'
Mar  2 11:06:01.002: INFO: stderr: ""
Mar  2 11:06:01.002: INFO: stdout: "e2e-test-crd-publish-openapi-7662-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Mar  2 11:06:01.002: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 --namespace=crd-publish-openapi-7399 apply -f -'
Mar  2 11:06:01.575: INFO: stderr: ""
Mar  2 11:06:01.575: INFO: stdout: "e2e-test-crd-publish-openapi-7662-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Mar  2 11:06:01.575: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 --namespace=crd-publish-openapi-7399 delete e2e-test-crd-publish-openapi-7662-crds test-cr'
Mar  2 11:06:01.751: INFO: stderr: ""
Mar  2 11:06:01.751: INFO: stdout: "e2e-test-crd-publish-openapi-7662-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Mar  2 11:06:01.751: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 explain e2e-test-crd-publish-openapi-7662-crds'
Mar  2 11:06:02.284: INFO: stderr: ""
Mar  2 11:06:02.284: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-7662-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 11:06:07.307: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7399" for this suite.
Mar  2 11:06:15.361: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 11:06:15.489: INFO: namespace crd-publish-openapi-7399 deletion completed in 8.172885789s

• [SLOW TEST:27.314 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 11:06:15.489: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3928
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar  2 11:06:17.254: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:0, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:0, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718743977, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718743977, loc:(*time.Location)(0x788c6e0)}}, Reason:"NewReplicaSetCreated", Message:"Created new replica set \"sample-webhook-deployment-7794d7ccd5\""}}, CollisionCount:(*int32)(nil)}
Mar  2 11:06:19.260: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718743977, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718743977, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718743977, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718743977, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7794d7ccd5\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar  2 11:06:22.551: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  2 11:06:22.557: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-1125-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource while v1 is storage version
STEP: Patching Custom Resource Definition to set v2 as storage
STEP: Patching the custom resource while v2 is storage version
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 11:06:29.494: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3928" for this suite.
Mar  2 11:06:37.600: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 11:06:37.736: INFO: namespace webhook-3928 deletion completed in 8.233890412s
STEP: Destroying namespace "webhook-3928-markers" for this suite.
Mar  2 11:06:45.765: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 11:06:46.022: INFO: namespace webhook-3928-markers deletion completed in 8.285928543s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:30.564 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 11:06:46.055: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-8784
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Mar  2 11:06:54.780: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar  2 11:06:54.784: INFO: Pod pod-with-poststart-http-hook still exists
Mar  2 11:06:56.784: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar  2 11:06:56.791: INFO: Pod pod-with-poststart-http-hook still exists
Mar  2 11:06:58.784: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Mar  2 11:06:58.790: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 11:06:58.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8784" for this suite.
Mar  2 11:07:10.837: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 11:07:10.972: INFO: namespace container-lifecycle-hook-8784 deletion completed in 12.174826168s

• [SLOW TEST:24.917 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 11:07:10.972: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-142
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-629b5ade-4812-48d7-827a-81f5444c40e2
STEP: Creating a pod to test consume configMaps
Mar  2 11:07:11.447: INFO: Waiting up to 5m0s for pod "pod-configmaps-87ffebfe-5515-482c-ad6a-9f3a3d375d8f" in namespace "configmap-142" to be "success or failure"
Mar  2 11:07:11.451: INFO: Pod "pod-configmaps-87ffebfe-5515-482c-ad6a-9f3a3d375d8f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.692423ms
Mar  2 11:07:13.484: INFO: Pod "pod-configmaps-87ffebfe-5515-482c-ad6a-9f3a3d375d8f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036855243s
Mar  2 11:07:15.499: INFO: Pod "pod-configmaps-87ffebfe-5515-482c-ad6a-9f3a3d375d8f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.051965005s
STEP: Saw pod success
Mar  2 11:07:15.499: INFO: Pod "pod-configmaps-87ffebfe-5515-482c-ad6a-9f3a3d375d8f" satisfied condition "success or failure"
Mar  2 11:07:15.557: INFO: Trying to get logs from node worker1 pod pod-configmaps-87ffebfe-5515-482c-ad6a-9f3a3d375d8f container configmap-volume-test: <nil>
STEP: delete the pod
Mar  2 11:07:15.642: INFO: Waiting for pod pod-configmaps-87ffebfe-5515-482c-ad6a-9f3a3d375d8f to disappear
Mar  2 11:07:15.647: INFO: Pod pod-configmaps-87ffebfe-5515-482c-ad6a-9f3a3d375d8f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 11:07:15.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-142" for this suite.
Mar  2 11:07:21.841: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 11:07:22.115: INFO: namespace configmap-142 deletion completed in 6.463016481s

• [SLOW TEST:11.144 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with readOnlyRootFilesystem 
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 11:07:22.116: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-3772
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  2 11:07:22.563: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-0e676290-ba2e-407c-bcc4-e38e301be173" in namespace "security-context-test-3772" to be "success or failure"
Mar  2 11:07:22.677: INFO: Pod "busybox-readonly-false-0e676290-ba2e-407c-bcc4-e38e301be173": Phase="Pending", Reason="", readiness=false. Elapsed: 113.273982ms
Mar  2 11:07:24.685: INFO: Pod "busybox-readonly-false-0e676290-ba2e-407c-bcc4-e38e301be173": Phase="Pending", Reason="", readiness=false. Elapsed: 2.12140035s
Mar  2 11:07:26.692: INFO: Pod "busybox-readonly-false-0e676290-ba2e-407c-bcc4-e38e301be173": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.128846774s
Mar  2 11:07:26.692: INFO: Pod "busybox-readonly-false-0e676290-ba2e-407c-bcc4-e38e301be173" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 11:07:26.692: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-3772" for this suite.
Mar  2 11:07:34.756: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 11:07:34.880: INFO: namespace security-context-test-3772 deletion completed in 8.178904389s

• [SLOW TEST:12.764 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a pod with readOnlyRootFilesystem
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:165
    should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 11:07:34.880: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7305
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Mar  2 11:07:35.496: INFO: Waiting up to 5m0s for pod "pod-e654247e-43f4-4ee9-8790-c1fda9e01dc7" in namespace "emptydir-7305" to be "success or failure"
Mar  2 11:07:35.507: INFO: Pod "pod-e654247e-43f4-4ee9-8790-c1fda9e01dc7": Phase="Pending", Reason="", readiness=false. Elapsed: 10.7655ms
Mar  2 11:07:37.514: INFO: Pod "pod-e654247e-43f4-4ee9-8790-c1fda9e01dc7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017820634s
Mar  2 11:07:39.521: INFO: Pod "pod-e654247e-43f4-4ee9-8790-c1fda9e01dc7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024790025s
STEP: Saw pod success
Mar  2 11:07:39.521: INFO: Pod "pod-e654247e-43f4-4ee9-8790-c1fda9e01dc7" satisfied condition "success or failure"
Mar  2 11:07:39.529: INFO: Trying to get logs from node worker1 pod pod-e654247e-43f4-4ee9-8790-c1fda9e01dc7 container test-container: <nil>
STEP: delete the pod
Mar  2 11:07:39.621: INFO: Waiting for pod pod-e654247e-43f4-4ee9-8790-c1fda9e01dc7 to disappear
Mar  2 11:07:39.626: INFO: Pod pod-e654247e-43f4-4ee9-8790-c1fda9e01dc7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 11:07:39.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7305" for this suite.
Mar  2 11:07:47.711: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 11:07:47.853: INFO: namespace emptydir-7305 deletion completed in 8.206777294s

• [SLOW TEST:12.973 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 11:07:47.854: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-6660
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-brwqc in namespace proxy-6660
I0302 11:07:48.291432      24 runners.go:184] Created replication controller with name: proxy-service-brwqc, namespace: proxy-6660, replica count: 1
I0302 11:07:49.342065      24 runners.go:184] proxy-service-brwqc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0302 11:07:50.342288      24 runners.go:184] proxy-service-brwqc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0302 11:07:51.342492      24 runners.go:184] proxy-service-brwqc Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0302 11:07:52.342708      24 runners.go:184] proxy-service-brwqc Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0302 11:07:53.342966      24 runners.go:184] proxy-service-brwqc Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0302 11:07:54.343234      24 runners.go:184] proxy-service-brwqc Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0302 11:07:55.343473      24 runners.go:184] proxy-service-brwqc Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0302 11:07:56.343737      24 runners.go:184] proxy-service-brwqc Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0302 11:07:57.344012      24 runners.go:184] proxy-service-brwqc Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0302 11:07:58.344266      24 runners.go:184] proxy-service-brwqc Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0302 11:07:59.344503      24 runners.go:184] proxy-service-brwqc Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0302 11:08:00.344867      24 runners.go:184] proxy-service-brwqc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Mar  2 11:08:00.354: INFO: setup took 12.182308412s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Mar  2 11:08:00.368: INFO: (0) /api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:160/proxy/: foo (200; 12.911258ms)
Mar  2 11:08:00.368: INFO: (0) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:160/proxy/: foo (200; 12.594354ms)
Mar  2 11:08:00.369: INFO: (0) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:162/proxy/: bar (200; 14.199948ms)
Mar  2 11:08:00.384: INFO: (0) /api/v1/namespaces/proxy-6660/services/proxy-service-brwqc:portname1/proxy/: foo (200; 29.065164ms)
Mar  2 11:08:00.384: INFO: (0) /api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:162/proxy/: bar (200; 29.726218ms)
Mar  2 11:08:00.384: INFO: (0) /api/v1/namespaces/proxy-6660/services/http:proxy-service-brwqc:portname1/proxy/: foo (200; 29.103747ms)
Mar  2 11:08:00.391: INFO: (0) /api/v1/namespaces/proxy-6660/services/http:proxy-service-brwqc:portname2/proxy/: bar (200; 36.033822ms)
Mar  2 11:08:00.391: INFO: (0) /api/v1/namespaces/proxy-6660/services/proxy-service-brwqc:portname2/proxy/: bar (200; 36.410429ms)
Mar  2 11:08:00.392: INFO: (0) /api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:1080/proxy/rewriteme">... (200; 36.488407ms)
Mar  2 11:08:00.392: INFO: (0) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5/proxy/rewriteme">test</a> (200; 37.022448ms)
Mar  2 11:08:00.392: INFO: (0) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:1080/proxy/rewriteme">test<... (200; 37.245108ms)
Mar  2 11:08:00.393: INFO: (0) /api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:443/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:443/proxy/tlsrewritem... (200; 37.283901ms)
Mar  2 11:08:00.394: INFO: (0) /api/v1/namespaces/proxy-6660/services/https:proxy-service-brwqc:tlsportname2/proxy/: tls qux (200; 39.130245ms)
Mar  2 11:08:00.394: INFO: (0) /api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:462/proxy/: tls qux (200; 39.59721ms)
Mar  2 11:08:00.398: INFO: (0) /api/v1/namespaces/proxy-6660/services/https:proxy-service-brwqc:tlsportname1/proxy/: tls baz (200; 43.471715ms)
Mar  2 11:08:00.399: INFO: (0) /api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:460/proxy/: tls baz (200; 43.238528ms)
Mar  2 11:08:00.412: INFO: (1) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:162/proxy/: bar (200; 11.96904ms)
Mar  2 11:08:00.412: INFO: (1) /api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:443/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:443/proxy/tlsrewritem... (200; 13.105899ms)
Mar  2 11:08:00.412: INFO: (1) /api/v1/namespaces/proxy-6660/services/https:proxy-service-brwqc:tlsportname1/proxy/: tls baz (200; 12.736211ms)
Mar  2 11:08:00.412: INFO: (1) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:1080/proxy/rewriteme">test<... (200; 11.817499ms)
Mar  2 11:08:00.412: INFO: (1) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5/proxy/rewriteme">test</a> (200; 12.5176ms)
Mar  2 11:08:00.412: INFO: (1) /api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:462/proxy/: tls qux (200; 12.056463ms)
Mar  2 11:08:00.413: INFO: (1) /api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:460/proxy/: tls baz (200; 12.982959ms)
Mar  2 11:08:00.413: INFO: (1) /api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:1080/proxy/rewriteme">... (200; 13.363513ms)
Mar  2 11:08:00.413: INFO: (1) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:160/proxy/: foo (200; 12.970492ms)
Mar  2 11:08:00.414: INFO: (1) /api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:162/proxy/: bar (200; 13.305605ms)
Mar  2 11:08:00.414: INFO: (1) /api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:160/proxy/: foo (200; 13.787631ms)
Mar  2 11:08:00.415: INFO: (1) /api/v1/namespaces/proxy-6660/services/proxy-service-brwqc:portname1/proxy/: foo (200; 15.475824ms)
Mar  2 11:08:00.415: INFO: (1) /api/v1/namespaces/proxy-6660/services/http:proxy-service-brwqc:portname1/proxy/: foo (200; 15.23093ms)
Mar  2 11:08:00.417: INFO: (1) /api/v1/namespaces/proxy-6660/services/proxy-service-brwqc:portname2/proxy/: bar (200; 17.024224ms)
Mar  2 11:08:00.417: INFO: (1) /api/v1/namespaces/proxy-6660/services/https:proxy-service-brwqc:tlsportname2/proxy/: tls qux (200; 16.98415ms)
Mar  2 11:08:00.418: INFO: (1) /api/v1/namespaces/proxy-6660/services/http:proxy-service-brwqc:portname2/proxy/: bar (200; 18.368837ms)
Mar  2 11:08:00.426: INFO: (2) /api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:160/proxy/: foo (200; 7.453597ms)
Mar  2 11:08:00.427: INFO: (2) /api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:443/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:443/proxy/tlsrewritem... (200; 8.078964ms)
Mar  2 11:08:00.428: INFO: (2) /api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:162/proxy/: bar (200; 8.471082ms)
Mar  2 11:08:00.429: INFO: (2) /api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:460/proxy/: tls baz (200; 9.806208ms)
Mar  2 11:08:00.429: INFO: (2) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5/proxy/rewriteme">test</a> (200; 10.254886ms)
Mar  2 11:08:00.430: INFO: (2) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:1080/proxy/rewriteme">test<... (200; 9.871368ms)
Mar  2 11:08:00.431: INFO: (2) /api/v1/namespaces/proxy-6660/services/https:proxy-service-brwqc:tlsportname1/proxy/: tls baz (200; 12.740795ms)
Mar  2 11:08:00.432: INFO: (2) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:160/proxy/: foo (200; 11.715326ms)
Mar  2 11:08:00.434: INFO: (2) /api/v1/namespaces/proxy-6660/services/proxy-service-brwqc:portname1/proxy/: foo (200; 14.646059ms)
Mar  2 11:08:00.434: INFO: (2) /api/v1/namespaces/proxy-6660/services/proxy-service-brwqc:portname2/proxy/: bar (200; 15.300114ms)
Mar  2 11:08:00.435: INFO: (2) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:162/proxy/: bar (200; 15.204524ms)
Mar  2 11:08:00.436: INFO: (2) /api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:1080/proxy/rewriteme">... (200; 16.264749ms)
Mar  2 11:08:00.436: INFO: (2) /api/v1/namespaces/proxy-6660/services/http:proxy-service-brwqc:portname2/proxy/: bar (200; 16.76852ms)
Mar  2 11:08:00.437: INFO: (2) /api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:462/proxy/: tls qux (200; 17.959692ms)
Mar  2 11:08:00.438: INFO: (2) /api/v1/namespaces/proxy-6660/services/http:proxy-service-brwqc:portname1/proxy/: foo (200; 18.44412ms)
Mar  2 11:08:00.440: INFO: (2) /api/v1/namespaces/proxy-6660/services/https:proxy-service-brwqc:tlsportname2/proxy/: tls qux (200; 20.305907ms)
Mar  2 11:08:00.448: INFO: (3) /api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:443/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:443/proxy/tlsrewritem... (200; 7.71107ms)
Mar  2 11:08:00.449: INFO: (3) /api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:462/proxy/: tls qux (200; 8.296015ms)
Mar  2 11:08:00.450: INFO: (3) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5/proxy/rewriteme">test</a> (200; 8.718393ms)
Mar  2 11:08:00.451: INFO: (3) /api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:160/proxy/: foo (200; 10.199296ms)
Mar  2 11:08:00.452: INFO: (3) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:162/proxy/: bar (200; 10.27514ms)
Mar  2 11:08:00.452: INFO: (3) /api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:162/proxy/: bar (200; 10.040239ms)
Mar  2 11:08:00.452: INFO: (3) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:160/proxy/: foo (200; 10.62492ms)
Mar  2 11:08:00.452: INFO: (3) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:1080/proxy/rewriteme">test<... (200; 10.93377ms)
Mar  2 11:08:00.453: INFO: (3) /api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:1080/proxy/rewriteme">... (200; 11.483702ms)
Mar  2 11:08:00.455: INFO: (3) /api/v1/namespaces/proxy-6660/services/http:proxy-service-brwqc:portname1/proxy/: foo (200; 12.998189ms)
Mar  2 11:08:00.455: INFO: (3) /api/v1/namespaces/proxy-6660/services/proxy-service-brwqc:portname2/proxy/: bar (200; 13.801184ms)
Mar  2 11:08:00.455: INFO: (3) /api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:460/proxy/: tls baz (200; 13.61371ms)
Mar  2 11:08:00.455: INFO: (3) /api/v1/namespaces/proxy-6660/services/https:proxy-service-brwqc:tlsportname1/proxy/: tls baz (200; 14.603102ms)
Mar  2 11:08:00.458: INFO: (3) /api/v1/namespaces/proxy-6660/services/proxy-service-brwqc:portname1/proxy/: foo (200; 16.112452ms)
Mar  2 11:08:00.459: INFO: (3) /api/v1/namespaces/proxy-6660/services/http:proxy-service-brwqc:portname2/proxy/: bar (200; 17.214767ms)
Mar  2 11:08:00.460: INFO: (3) /api/v1/namespaces/proxy-6660/services/https:proxy-service-brwqc:tlsportname2/proxy/: tls qux (200; 17.857399ms)
Mar  2 11:08:00.469: INFO: (4) /api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:460/proxy/: tls baz (200; 8.507316ms)
Mar  2 11:08:00.469: INFO: (4) /api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:162/proxy/: bar (200; 9.357531ms)
Mar  2 11:08:00.471: INFO: (4) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:160/proxy/: foo (200; 10.360093ms)
Mar  2 11:08:00.472: INFO: (4) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:1080/proxy/rewriteme">test<... (200; 10.742464ms)
Mar  2 11:08:00.472: INFO: (4) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5/proxy/rewriteme">test</a> (200; 10.726401ms)
Mar  2 11:08:00.472: INFO: (4) /api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:1080/proxy/rewriteme">... (200; 10.686887ms)
Mar  2 11:08:00.473: INFO: (4) /api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:160/proxy/: foo (200; 11.902393ms)
Mar  2 11:08:00.473: INFO: (4) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:162/proxy/: bar (200; 11.996539ms)
Mar  2 11:08:00.474: INFO: (4) /api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:443/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:443/proxy/tlsrewritem... (200; 13.767324ms)
Mar  2 11:08:00.474: INFO: (4) /api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:462/proxy/: tls qux (200; 12.924085ms)
Mar  2 11:08:00.475: INFO: (4) /api/v1/namespaces/proxy-6660/services/http:proxy-service-brwqc:portname1/proxy/: foo (200; 14.505358ms)
Mar  2 11:08:00.476: INFO: (4) /api/v1/namespaces/proxy-6660/services/proxy-service-brwqc:portname1/proxy/: foo (200; 14.957349ms)
Mar  2 11:08:00.478: INFO: (4) /api/v1/namespaces/proxy-6660/services/http:proxy-service-brwqc:portname2/proxy/: bar (200; 16.92415ms)
Mar  2 11:08:00.478: INFO: (4) /api/v1/namespaces/proxy-6660/services/https:proxy-service-brwqc:tlsportname2/proxy/: tls qux (200; 17.932183ms)
Mar  2 11:08:00.479: INFO: (4) /api/v1/namespaces/proxy-6660/services/proxy-service-brwqc:portname2/proxy/: bar (200; 18.475207ms)
Mar  2 11:08:00.482: INFO: (4) /api/v1/namespaces/proxy-6660/services/https:proxy-service-brwqc:tlsportname1/proxy/: tls baz (200; 21.154213ms)
Mar  2 11:08:00.491: INFO: (5) /api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:162/proxy/: bar (200; 8.260095ms)
Mar  2 11:08:00.492: INFO: (5) /api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:460/proxy/: tls baz (200; 9.328553ms)
Mar  2 11:08:00.493: INFO: (5) /api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:160/proxy/: foo (200; 9.845225ms)
Mar  2 11:08:00.493: INFO: (5) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:162/proxy/: bar (200; 9.202904ms)
Mar  2 11:08:00.493: INFO: (5) /api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:443/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:443/proxy/tlsrewritem... (200; 10.294623ms)
Mar  2 11:08:00.493: INFO: (5) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5/proxy/rewriteme">test</a> (200; 10.207442ms)
Mar  2 11:08:00.495: INFO: (5) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:1080/proxy/rewriteme">test<... (200; 12.002487ms)
Mar  2 11:08:00.495: INFO: (5) /api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:462/proxy/: tls qux (200; 12.506557ms)
Mar  2 11:08:00.495: INFO: (5) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:160/proxy/: foo (200; 11.999849ms)
Mar  2 11:08:00.497: INFO: (5) /api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:1080/proxy/rewriteme">... (200; 14.090831ms)
Mar  2 11:08:00.498: INFO: (5) /api/v1/namespaces/proxy-6660/services/https:proxy-service-brwqc:tlsportname1/proxy/: tls baz (200; 14.516132ms)
Mar  2 11:08:00.499: INFO: (5) /api/v1/namespaces/proxy-6660/services/https:proxy-service-brwqc:tlsportname2/proxy/: tls qux (200; 15.270224ms)
Mar  2 11:08:00.499: INFO: (5) /api/v1/namespaces/proxy-6660/services/http:proxy-service-brwqc:portname1/proxy/: foo (200; 15.589688ms)
Mar  2 11:08:00.499: INFO: (5) /api/v1/namespaces/proxy-6660/services/proxy-service-brwqc:portname1/proxy/: foo (200; 16.193415ms)
Mar  2 11:08:00.500: INFO: (5) /api/v1/namespaces/proxy-6660/services/proxy-service-brwqc:portname2/proxy/: bar (200; 16.484916ms)
Mar  2 11:08:00.501: INFO: (5) /api/v1/namespaces/proxy-6660/services/http:proxy-service-brwqc:portname2/proxy/: bar (200; 18.12542ms)
Mar  2 11:08:00.511: INFO: (6) /api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:160/proxy/: foo (200; 9.947608ms)
Mar  2 11:08:00.511: INFO: (6) /api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:460/proxy/: tls baz (200; 9.01367ms)
Mar  2 11:08:00.512: INFO: (6) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:160/proxy/: foo (200; 9.867971ms)
Mar  2 11:08:00.512: INFO: (6) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:1080/proxy/rewriteme">test<... (200; 9.123253ms)
Mar  2 11:08:00.512: INFO: (6) /api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:462/proxy/: tls qux (200; 8.816706ms)
Mar  2 11:08:00.514: INFO: (6) /api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:1080/proxy/rewriteme">... (200; 10.678106ms)
Mar  2 11:08:00.515: INFO: (6) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:162/proxy/: bar (200; 13.090418ms)
Mar  2 11:08:00.515: INFO: (6) /api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:443/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:443/proxy/tlsrewritem... (200; 12.437114ms)
Mar  2 11:08:00.515: INFO: (6) /api/v1/namespaces/proxy-6660/services/proxy-service-brwqc:portname1/proxy/: foo (200; 12.168277ms)
Mar  2 11:08:00.518: INFO: (6) /api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:162/proxy/: bar (200; 14.948366ms)
Mar  2 11:08:00.519: INFO: (6) /api/v1/namespaces/proxy-6660/services/https:proxy-service-brwqc:tlsportname1/proxy/: tls baz (200; 15.761487ms)
Mar  2 11:08:00.519: INFO: (6) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5/proxy/rewriteme">test</a> (200; 15.899485ms)
Mar  2 11:08:00.519: INFO: (6) /api/v1/namespaces/proxy-6660/services/https:proxy-service-brwqc:tlsportname2/proxy/: tls qux (200; 16.860643ms)
Mar  2 11:08:00.520: INFO: (6) /api/v1/namespaces/proxy-6660/services/http:proxy-service-brwqc:portname2/proxy/: bar (200; 16.923194ms)
Mar  2 11:08:00.520: INFO: (6) /api/v1/namespaces/proxy-6660/services/http:proxy-service-brwqc:portname1/proxy/: foo (200; 17.100001ms)
Mar  2 11:08:00.520: INFO: (6) /api/v1/namespaces/proxy-6660/services/proxy-service-brwqc:portname2/proxy/: bar (200; 17.030704ms)
Mar  2 11:08:00.529: INFO: (7) /api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:160/proxy/: foo (200; 8.873276ms)
Mar  2 11:08:00.531: INFO: (7) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:1080/proxy/rewriteme">test<... (200; 9.511408ms)
Mar  2 11:08:00.531: INFO: (7) /api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:462/proxy/: tls qux (200; 9.873375ms)
Mar  2 11:08:00.533: INFO: (7) /api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:460/proxy/: tls baz (200; 11.97722ms)
Mar  2 11:08:00.534: INFO: (7) /api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:162/proxy/: bar (200; 13.073751ms)
Mar  2 11:08:00.534: INFO: (7) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:162/proxy/: bar (200; 12.924838ms)
Mar  2 11:08:00.534: INFO: (7) /api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:1080/proxy/rewriteme">... (200; 12.897768ms)
Mar  2 11:08:00.534: INFO: (7) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5/proxy/rewriteme">test</a> (200; 12.997628ms)
Mar  2 11:08:00.534: INFO: (7) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:160/proxy/: foo (200; 13.177342ms)
Mar  2 11:08:00.534: INFO: (7) /api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:443/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:443/proxy/tlsrewritem... (200; 13.172405ms)
Mar  2 11:08:00.534: INFO: (7) /api/v1/namespaces/proxy-6660/services/http:proxy-service-brwqc:portname1/proxy/: foo (200; 13.541083ms)
Mar  2 11:08:00.535: INFO: (7) /api/v1/namespaces/proxy-6660/services/proxy-service-brwqc:portname2/proxy/: bar (200; 14.228244ms)
Mar  2 11:08:00.536: INFO: (7) /api/v1/namespaces/proxy-6660/services/https:proxy-service-brwqc:tlsportname1/proxy/: tls baz (200; 14.883586ms)
Mar  2 11:08:00.538: INFO: (7) /api/v1/namespaces/proxy-6660/services/https:proxy-service-brwqc:tlsportname2/proxy/: tls qux (200; 17.181637ms)
Mar  2 11:08:00.538: INFO: (7) /api/v1/namespaces/proxy-6660/services/proxy-service-brwqc:portname1/proxy/: foo (200; 17.137124ms)
Mar  2 11:08:00.539: INFO: (7) /api/v1/namespaces/proxy-6660/services/http:proxy-service-brwqc:portname2/proxy/: bar (200; 18.452644ms)
Mar  2 11:08:00.549: INFO: (8) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:1080/proxy/rewriteme">test<... (200; 9.28296ms)
Mar  2 11:08:00.552: INFO: (8) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:160/proxy/: foo (200; 11.463665ms)
Mar  2 11:08:00.552: INFO: (8) /api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:1080/proxy/rewriteme">... (200; 11.659619ms)
Mar  2 11:08:00.552: INFO: (8) /api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:162/proxy/: bar (200; 12.097983ms)
Mar  2 11:08:00.553: INFO: (8) /api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:460/proxy/: tls baz (200; 12.14366ms)
Mar  2 11:08:00.554: INFO: (8) /api/v1/namespaces/proxy-6660/services/https:proxy-service-brwqc:tlsportname1/proxy/: tls baz (200; 14.047121ms)
Mar  2 11:08:00.554: INFO: (8) /api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:443/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:443/proxy/tlsrewritem... (200; 14.591456ms)
Mar  2 11:08:00.555: INFO: (8) /api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:160/proxy/: foo (200; 14.910453ms)
Mar  2 11:08:00.555: INFO: (8) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:162/proxy/: bar (200; 14.690869ms)
Mar  2 11:08:00.555: INFO: (8) /api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:462/proxy/: tls qux (200; 15.094356ms)
Mar  2 11:08:00.555: INFO: (8) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5/proxy/rewriteme">test</a> (200; 15.074183ms)
Mar  2 11:08:00.556: INFO: (8) /api/v1/namespaces/proxy-6660/services/proxy-service-brwqc:portname2/proxy/: bar (200; 16.263142ms)
Mar  2 11:08:00.557: INFO: (8) /api/v1/namespaces/proxy-6660/services/https:proxy-service-brwqc:tlsportname2/proxy/: tls qux (200; 16.957994ms)
Mar  2 11:08:00.558: INFO: (8) /api/v1/namespaces/proxy-6660/services/http:proxy-service-brwqc:portname2/proxy/: bar (200; 17.391478ms)
Mar  2 11:08:00.558: INFO: (8) /api/v1/namespaces/proxy-6660/services/http:proxy-service-brwqc:portname1/proxy/: foo (200; 17.550865ms)
Mar  2 11:08:00.561: INFO: (8) /api/v1/namespaces/proxy-6660/services/proxy-service-brwqc:portname1/proxy/: foo (200; 20.323254ms)
Mar  2 11:08:00.570: INFO: (9) /api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:1080/proxy/rewriteme">... (200; 8.362055ms)
Mar  2 11:08:00.570: INFO: (9) /api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:160/proxy/: foo (200; 8.310451ms)
Mar  2 11:08:00.570: INFO: (9) /api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:443/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:443/proxy/tlsrewritem... (200; 9.098767ms)
Mar  2 11:08:00.570: INFO: (9) /api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:462/proxy/: tls qux (200; 8.368118ms)
Mar  2 11:08:00.570: INFO: (9) /api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:460/proxy/: tls baz (200; 8.236812ms)
Mar  2 11:08:00.572: INFO: (9) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:162/proxy/: bar (200; 9.943951ms)
Mar  2 11:08:00.573: INFO: (9) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5/proxy/rewriteme">test</a> (200; 10.442326ms)
Mar  2 11:08:00.575: INFO: (9) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:160/proxy/: foo (200; 12.09013ms)
Mar  2 11:08:00.575: INFO: (9) /api/v1/namespaces/proxy-6660/services/https:proxy-service-brwqc:tlsportname2/proxy/: tls qux (200; 12.882782ms)
Mar  2 11:08:00.575: INFO: (9) /api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:162/proxy/: bar (200; 12.938378ms)
Mar  2 11:08:00.576: INFO: (9) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:1080/proxy/rewriteme">test<... (200; 13.436399ms)
Mar  2 11:08:00.579: INFO: (9) /api/v1/namespaces/proxy-6660/services/proxy-service-brwqc:portname2/proxy/: bar (200; 16.871653ms)
Mar  2 11:08:00.580: INFO: (9) /api/v1/namespaces/proxy-6660/services/http:proxy-service-brwqc:portname2/proxy/: bar (200; 17.124514ms)
Mar  2 11:08:00.580: INFO: (9) /api/v1/namespaces/proxy-6660/services/proxy-service-brwqc:portname1/proxy/: foo (200; 17.928736ms)
Mar  2 11:08:00.581: INFO: (9) /api/v1/namespaces/proxy-6660/services/http:proxy-service-brwqc:portname1/proxy/: foo (200; 19.120705ms)
Mar  2 11:08:00.583: INFO: (9) /api/v1/namespaces/proxy-6660/services/https:proxy-service-brwqc:tlsportname1/proxy/: tls baz (200; 20.310771ms)
Mar  2 11:08:00.591: INFO: (10) /api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:160/proxy/: foo (200; 6.855848ms)
Mar  2 11:08:00.591: INFO: (10) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5/proxy/rewriteme">test</a> (200; 7.444166ms)
Mar  2 11:08:00.591: INFO: (10) /api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:162/proxy/: bar (200; 7.867684ms)
Mar  2 11:08:00.592: INFO: (10) /api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:1080/proxy/rewriteme">... (200; 8.147074ms)
Mar  2 11:08:00.592: INFO: (10) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:1080/proxy/rewriteme">test<... (200; 7.179669ms)
Mar  2 11:08:00.593: INFO: (10) /api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:460/proxy/: tls baz (200; 8.941796ms)
Mar  2 11:08:00.595: INFO: (10) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:162/proxy/: bar (200; 10.359356ms)
Mar  2 11:08:00.595: INFO: (10) /api/v1/namespaces/proxy-6660/services/https:proxy-service-brwqc:tlsportname1/proxy/: tls baz (200; 10.450796ms)
Mar  2 11:08:00.596: INFO: (10) /api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:443/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:443/proxy/tlsrewritem... (200; 11.043284ms)
Mar  2 11:08:00.596: INFO: (10) /api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:462/proxy/: tls qux (200; 11.952929ms)
Mar  2 11:08:00.597: INFO: (10) /api/v1/namespaces/proxy-6660/services/https:proxy-service-brwqc:tlsportname2/proxy/: tls qux (200; 12.714951ms)
Mar  2 11:08:00.598: INFO: (10) /api/v1/namespaces/proxy-6660/services/http:proxy-service-brwqc:portname2/proxy/: bar (200; 13.074828ms)
Mar  2 11:08:00.598: INFO: (10) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:160/proxy/: foo (200; 13.650196ms)
Mar  2 11:08:00.600: INFO: (10) /api/v1/namespaces/proxy-6660/services/http:proxy-service-brwqc:portname1/proxy/: foo (200; 15.32438ms)
Mar  2 11:08:00.600: INFO: (10) /api/v1/namespaces/proxy-6660/services/proxy-service-brwqc:portname2/proxy/: bar (200; 15.630241ms)
Mar  2 11:08:00.600: INFO: (10) /api/v1/namespaces/proxy-6660/services/proxy-service-brwqc:portname1/proxy/: foo (200; 15.820904ms)
Mar  2 11:08:00.610: INFO: (11) /api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:443/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:443/proxy/tlsrewritem... (200; 9.39196ms)
Mar  2 11:08:00.611: INFO: (11) /api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:160/proxy/: foo (200; 10.005822ms)
Mar  2 11:08:00.611: INFO: (11) /api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:162/proxy/: bar (200; 9.668198ms)
Mar  2 11:08:00.612: INFO: (11) /api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:1080/proxy/rewriteme">... (200; 10.570903ms)
Mar  2 11:08:00.612: INFO: (11) /api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:460/proxy/: tls baz (200; 11.166391ms)
Mar  2 11:08:00.614: INFO: (11) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:162/proxy/: bar (200; 13.017146ms)
Mar  2 11:08:00.614: INFO: (11) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:160/proxy/: foo (200; 13.682317ms)
Mar  2 11:08:00.615: INFO: (11) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5/proxy/rewriteme">test</a> (200; 13.282583ms)
Mar  2 11:08:00.615: INFO: (11) /api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:462/proxy/: tls qux (200; 13.550593ms)
Mar  2 11:08:00.615: INFO: (11) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:1080/proxy/rewriteme">test<... (200; 14.036661ms)
Mar  2 11:08:00.615: INFO: (11) /api/v1/namespaces/proxy-6660/services/https:proxy-service-brwqc:tlsportname2/proxy/: tls qux (200; 14.709616ms)
Mar  2 11:08:00.615: INFO: (11) /api/v1/namespaces/proxy-6660/services/proxy-service-brwqc:portname1/proxy/: foo (200; 14.388041ms)
Mar  2 11:08:00.615: INFO: (11) /api/v1/namespaces/proxy-6660/services/proxy-service-brwqc:portname2/proxy/: bar (200; 14.388595ms)
Mar  2 11:08:00.616: INFO: (11) /api/v1/namespaces/proxy-6660/services/http:proxy-service-brwqc:portname1/proxy/: foo (200; 14.681662ms)
Mar  2 11:08:00.616: INFO: (11) /api/v1/namespaces/proxy-6660/services/https:proxy-service-brwqc:tlsportname1/proxy/: tls baz (200; 15.161633ms)
Mar  2 11:08:00.617: INFO: (11) /api/v1/namespaces/proxy-6660/services/http:proxy-service-brwqc:portname2/proxy/: bar (200; 16.486046ms)
Mar  2 11:08:00.625: INFO: (12) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:162/proxy/: bar (200; 7.094106ms)
Mar  2 11:08:00.626: INFO: (12) /api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:160/proxy/: foo (200; 8.217318ms)
Mar  2 11:08:00.628: INFO: (12) /api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:1080/proxy/rewriteme">... (200; 9.849478ms)
Mar  2 11:08:00.628: INFO: (12) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:160/proxy/: foo (200; 10.54277ms)
Mar  2 11:08:00.629: INFO: (12) /api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:460/proxy/: tls baz (200; 10.042422ms)
Mar  2 11:08:00.630: INFO: (12) /api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:162/proxy/: bar (200; 11.695146ms)
Mar  2 11:08:00.631: INFO: (12) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:1080/proxy/rewriteme">test<... (200; 11.876723ms)
Mar  2 11:08:00.631: INFO: (12) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5/proxy/rewriteme">test</a> (200; 12.372021ms)
Mar  2 11:08:00.631: INFO: (12) /api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:462/proxy/: tls qux (200; 12.583945ms)
Mar  2 11:08:00.632: INFO: (12) /api/v1/namespaces/proxy-6660/services/https:proxy-service-brwqc:tlsportname2/proxy/: tls qux (200; 13.63181ms)
Mar  2 11:08:00.632: INFO: (12) /api/v1/namespaces/proxy-6660/services/proxy-service-brwqc:portname2/proxy/: bar (200; 13.282646ms)
Mar  2 11:08:00.633: INFO: (12) /api/v1/namespaces/proxy-6660/services/https:proxy-service-brwqc:tlsportname1/proxy/: tls baz (200; 15.028696ms)
Mar  2 11:08:00.634: INFO: (12) /api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:443/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:443/proxy/tlsrewritem... (200; 14.962883ms)
Mar  2 11:08:00.634: INFO: (12) /api/v1/namespaces/proxy-6660/services/http:proxy-service-brwqc:portname2/proxy/: bar (200; 15.015246ms)
Mar  2 11:08:00.635: INFO: (12) /api/v1/namespaces/proxy-6660/services/http:proxy-service-brwqc:portname1/proxy/: foo (200; 15.927335ms)
Mar  2 11:08:00.636: INFO: (12) /api/v1/namespaces/proxy-6660/services/proxy-service-brwqc:portname1/proxy/: foo (200; 17.124148ms)
Mar  2 11:08:00.643: INFO: (13) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:160/proxy/: foo (200; 6.893712ms)
Mar  2 11:08:00.692: INFO: (13) /api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:162/proxy/: bar (200; 54.833427ms)
Mar  2 11:08:00.692: INFO: (13) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:162/proxy/: bar (200; 54.796527ms)
Mar  2 11:08:00.693: INFO: (13) /api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:443/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:443/proxy/tlsrewritem... (200; 56.328413ms)
Mar  2 11:08:00.693: INFO: (13) /api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:462/proxy/: tls qux (200; 56.489634ms)
Mar  2 11:08:00.694: INFO: (13) /api/v1/namespaces/proxy-6660/services/http:proxy-service-brwqc:portname1/proxy/: foo (200; 58.251888ms)
Mar  2 11:08:00.696: INFO: (13) /api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:160/proxy/: foo (200; 60.085754ms)
Mar  2 11:08:00.698: INFO: (13) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5/proxy/rewriteme">test</a> (200; 60.897067ms)
Mar  2 11:08:00.698: INFO: (13) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:1080/proxy/rewriteme">test<... (200; 60.432625ms)
Mar  2 11:08:00.700: INFO: (13) /api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:460/proxy/: tls baz (200; 62.951998ms)
Mar  2 11:08:00.700: INFO: (13) /api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:1080/proxy/rewriteme">... (200; 63.308395ms)
Mar  2 11:08:00.700: INFO: (13) /api/v1/namespaces/proxy-6660/services/https:proxy-service-brwqc:tlsportname2/proxy/: tls qux (200; 63.401335ms)
Mar  2 11:08:00.701: INFO: (13) /api/v1/namespaces/proxy-6660/services/proxy-service-brwqc:portname1/proxy/: foo (200; 64.056404ms)
Mar  2 11:08:00.702: INFO: (13) /api/v1/namespaces/proxy-6660/services/proxy-service-brwqc:portname2/proxy/: bar (200; 64.841035ms)
Mar  2 11:08:00.703: INFO: (13) /api/v1/namespaces/proxy-6660/services/http:proxy-service-brwqc:portname2/proxy/: bar (200; 65.296446ms)
Mar  2 11:08:00.704: INFO: (13) /api/v1/namespaces/proxy-6660/services/https:proxy-service-brwqc:tlsportname1/proxy/: tls baz (200; 67.093147ms)
Mar  2 11:08:00.713: INFO: (14) /api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:1080/proxy/rewriteme">... (200; 8.853432ms)
Mar  2 11:08:00.714: INFO: (14) /api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:460/proxy/: tls baz (200; 9.784431ms)
Mar  2 11:08:00.714: INFO: (14) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:1080/proxy/rewriteme">test<... (200; 10.205192ms)
Mar  2 11:08:00.715: INFO: (14) /api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:160/proxy/: foo (200; 10.759237ms)
Mar  2 11:08:00.716: INFO: (14) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:162/proxy/: bar (200; 11.340418ms)
Mar  2 11:08:00.716: INFO: (14) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:160/proxy/: foo (200; 12.012356ms)
Mar  2 11:08:00.717: INFO: (14) /api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:462/proxy/: tls qux (200; 12.232997ms)
Mar  2 11:08:00.720: INFO: (14) /api/v1/namespaces/proxy-6660/services/https:proxy-service-brwqc:tlsportname2/proxy/: tls qux (200; 15.686141ms)
Mar  2 11:08:00.721: INFO: (14) /api/v1/namespaces/proxy-6660/services/http:proxy-service-brwqc:portname2/proxy/: bar (200; 16.806336ms)
Mar  2 11:08:00.732: INFO: (14) /api/v1/namespaces/proxy-6660/services/http:proxy-service-brwqc:portname1/proxy/: foo (200; 27.803541ms)
Mar  2 11:08:00.732: INFO: (14) /api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:443/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:443/proxy/tlsrewritem... (200; 28.013438ms)
Mar  2 11:08:00.733: INFO: (14) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5/proxy/rewriteme">test</a> (200; 28.984577ms)
Mar  2 11:08:00.733: INFO: (14) /api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:162/proxy/: bar (200; 28.565746ms)
Mar  2 11:08:00.733: INFO: (14) /api/v1/namespaces/proxy-6660/services/https:proxy-service-brwqc:tlsportname1/proxy/: tls baz (200; 28.293049ms)
Mar  2 11:08:00.735: INFO: (14) /api/v1/namespaces/proxy-6660/services/proxy-service-brwqc:portname1/proxy/: foo (200; 31.041997ms)
Mar  2 11:08:00.747: INFO: (14) /api/v1/namespaces/proxy-6660/services/proxy-service-brwqc:portname2/proxy/: bar (200; 42.752814ms)
Mar  2 11:08:00.756: INFO: (15) /api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:162/proxy/: bar (200; 7.999507ms)
Mar  2 11:08:00.759: INFO: (15) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:1080/proxy/rewriteme">test<... (200; 9.997005ms)
Mar  2 11:08:00.760: INFO: (15) /api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:460/proxy/: tls baz (200; 10.76352ms)
Mar  2 11:08:00.762: INFO: (15) /api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:160/proxy/: foo (200; 12.39479ms)
Mar  2 11:08:00.763: INFO: (15) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5/proxy/rewriteme">test</a> (200; 14.359695ms)
Mar  2 11:08:00.763: INFO: (15) /api/v1/namespaces/proxy-6660/services/proxy-service-brwqc:portname1/proxy/: foo (200; 15.730535ms)
Mar  2 11:08:00.763: INFO: (15) /api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:462/proxy/: tls qux (200; 13.57735ms)
Mar  2 11:08:00.763: INFO: (15) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:160/proxy/: foo (200; 13.665466ms)
Mar  2 11:08:00.764: INFO: (15) /api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:443/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:443/proxy/tlsrewritem... (200; 15.64075ms)
Mar  2 11:08:00.765: INFO: (15) /api/v1/namespaces/proxy-6660/services/https:proxy-service-brwqc:tlsportname2/proxy/: tls qux (200; 17.061991ms)
Mar  2 11:08:00.765: INFO: (15) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:162/proxy/: bar (200; 15.106039ms)
Mar  2 11:08:00.765: INFO: (15) /api/v1/namespaces/proxy-6660/services/https:proxy-service-brwqc:tlsportname1/proxy/: tls baz (200; 15.167384ms)
Mar  2 11:08:00.765: INFO: (15) /api/v1/namespaces/proxy-6660/services/http:proxy-service-brwqc:portname2/proxy/: bar (200; 15.4681ms)
Mar  2 11:08:00.765: INFO: (15) /api/v1/namespaces/proxy-6660/services/http:proxy-service-brwqc:portname1/proxy/: foo (200; 16.979144ms)
Mar  2 11:08:00.765: INFO: (15) /api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:1080/proxy/rewriteme">... (200; 16.145125ms)
Mar  2 11:08:00.766: INFO: (15) /api/v1/namespaces/proxy-6660/services/proxy-service-brwqc:portname2/proxy/: bar (200; 15.941001ms)
Mar  2 11:08:00.778: INFO: (16) /api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:160/proxy/: foo (200; 12.563627ms)
Mar  2 11:08:00.779: INFO: (16) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5/proxy/rewriteme">test</a> (200; 12.132227ms)
Mar  2 11:08:00.779: INFO: (16) /api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:443/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:443/proxy/tlsrewritem... (200; 12.423101ms)
Mar  2 11:08:00.779: INFO: (16) /api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:460/proxy/: tls baz (200; 13.597696ms)
Mar  2 11:08:00.780: INFO: (16) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:160/proxy/: foo (200; 13.5157ms)
Mar  2 11:08:00.780: INFO: (16) /api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:462/proxy/: tls qux (200; 13.564643ms)
Mar  2 11:08:00.781: INFO: (16) /api/v1/namespaces/proxy-6660/services/http:proxy-service-brwqc:portname1/proxy/: foo (200; 15.095939ms)
Mar  2 11:08:00.781: INFO: (16) /api/v1/namespaces/proxy-6660/services/proxy-service-brwqc:portname2/proxy/: bar (200; 14.717506ms)
Mar  2 11:08:00.783: INFO: (16) /api/v1/namespaces/proxy-6660/services/http:proxy-service-brwqc:portname2/proxy/: bar (200; 16.211715ms)
Mar  2 11:08:00.786: INFO: (16) /api/v1/namespaces/proxy-6660/services/proxy-service-brwqc:portname1/proxy/: foo (200; 19.998347ms)
Mar  2 11:08:00.786: INFO: (16) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:162/proxy/: bar (200; 20.004753ms)
Mar  2 11:08:00.787: INFO: (16) /api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:1080/proxy/rewriteme">... (200; 21.113459ms)
Mar  2 11:08:00.787: INFO: (16) /api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:162/proxy/: bar (200; 21.18366ms)
Mar  2 11:08:00.787: INFO: (16) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:1080/proxy/rewriteme">test<... (200; 21.505231ms)
Mar  2 11:08:00.790: INFO: (16) /api/v1/namespaces/proxy-6660/services/https:proxy-service-brwqc:tlsportname2/proxy/: tls qux (200; 23.856852ms)
Mar  2 11:08:00.791: INFO: (16) /api/v1/namespaces/proxy-6660/services/https:proxy-service-brwqc:tlsportname1/proxy/: tls baz (200; 24.583064ms)
Mar  2 11:08:00.800: INFO: (17) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:162/proxy/: bar (200; 8.035624ms)
Mar  2 11:08:00.802: INFO: (17) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:1080/proxy/rewriteme">test<... (200; 10.43624ms)
Mar  2 11:08:00.802: INFO: (17) /api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:160/proxy/: foo (200; 10.82466ms)
Mar  2 11:08:00.803: INFO: (17) /api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:462/proxy/: tls qux (200; 11.391012ms)
Mar  2 11:08:00.803: INFO: (17) /api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:443/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:443/proxy/tlsrewritem... (200; 12.275083ms)
Mar  2 11:08:00.805: INFO: (17) /api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:460/proxy/: tls baz (200; 12.625381ms)
Mar  2 11:08:00.805: INFO: (17) /api/v1/namespaces/proxy-6660/services/proxy-service-brwqc:portname1/proxy/: foo (200; 12.659385ms)
Mar  2 11:08:00.805: INFO: (17) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:160/proxy/: foo (200; 12.954979ms)
Mar  2 11:08:00.805: INFO: (17) /api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:162/proxy/: bar (200; 12.656301ms)
Mar  2 11:08:00.805: INFO: (17) /api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:1080/proxy/rewriteme">... (200; 13.137605ms)
Mar  2 11:08:00.807: INFO: (17) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5/proxy/rewriteme">test</a> (200; 15.193567ms)
Mar  2 11:08:00.807: INFO: (17) /api/v1/namespaces/proxy-6660/services/https:proxy-service-brwqc:tlsportname2/proxy/: tls qux (200; 15.022199ms)
Mar  2 11:08:00.808: INFO: (17) /api/v1/namespaces/proxy-6660/services/http:proxy-service-brwqc:portname2/proxy/: bar (200; 15.682844ms)
Mar  2 11:08:00.808: INFO: (17) /api/v1/namespaces/proxy-6660/services/proxy-service-brwqc:portname2/proxy/: bar (200; 15.963565ms)
Mar  2 11:08:00.808: INFO: (17) /api/v1/namespaces/proxy-6660/services/https:proxy-service-brwqc:tlsportname1/proxy/: tls baz (200; 16.297142ms)
Mar  2 11:08:00.808: INFO: (17) /api/v1/namespaces/proxy-6660/services/http:proxy-service-brwqc:portname1/proxy/: foo (200; 16.483ms)
Mar  2 11:08:00.822: INFO: (18) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:162/proxy/: bar (200; 12.696788ms)
Mar  2 11:08:00.822: INFO: (18) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:160/proxy/: foo (200; 12.901839ms)
Mar  2 11:08:00.822: INFO: (18) /api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:162/proxy/: bar (200; 13.653276ms)
Mar  2 11:08:00.822: INFO: (18) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5/proxy/rewriteme">test</a> (200; 13.81205ms)
Mar  2 11:08:00.822: INFO: (18) /api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:462/proxy/: tls qux (200; 13.488107ms)
Mar  2 11:08:00.825: INFO: (18) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:1080/proxy/rewriteme">test<... (200; 16.293182ms)
Mar  2 11:08:00.825: INFO: (18) /api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:460/proxy/: tls baz (200; 15.921538ms)
Mar  2 11:08:00.825: INFO: (18) /api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:160/proxy/: foo (200; 16.398352ms)
Mar  2 11:08:00.825: INFO: (18) /api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:1080/proxy/rewriteme">... (200; 16.534903ms)
Mar  2 11:08:00.825: INFO: (18) /api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:443/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:443/proxy/tlsrewritem... (200; 16.005059ms)
Mar  2 11:08:00.827: INFO: (18) /api/v1/namespaces/proxy-6660/services/http:proxy-service-brwqc:portname1/proxy/: foo (200; 17.087538ms)
Mar  2 11:08:00.827: INFO: (18) /api/v1/namespaces/proxy-6660/services/http:proxy-service-brwqc:portname2/proxy/: bar (200; 17.619582ms)
Mar  2 11:08:00.827: INFO: (18) /api/v1/namespaces/proxy-6660/services/proxy-service-brwqc:portname1/proxy/: foo (200; 17.572809ms)
Mar  2 11:08:00.828: INFO: (18) /api/v1/namespaces/proxy-6660/services/https:proxy-service-brwqc:tlsportname1/proxy/: tls baz (200; 18.873648ms)
Mar  2 11:08:00.830: INFO: (18) /api/v1/namespaces/proxy-6660/services/proxy-service-brwqc:portname2/proxy/: bar (200; 20.642712ms)
Mar  2 11:08:00.830: INFO: (18) /api/v1/namespaces/proxy-6660/services/https:proxy-service-brwqc:tlsportname2/proxy/: tls qux (200; 20.653485ms)
Mar  2 11:08:00.843: INFO: (19) /api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:443/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:443/proxy/tlsrewritem... (200; 11.070381ms)
Mar  2 11:08:00.844: INFO: (19) /api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:1080/proxy/rewriteme">... (200; 11.643986ms)
Mar  2 11:08:00.845: INFO: (19) /api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:162/proxy/: bar (200; 13.572996ms)
Mar  2 11:08:00.845: INFO: (19) /api/v1/namespaces/proxy-6660/pods/http:proxy-service-brwqc-wvnn5:160/proxy/: foo (200; 13.332592ms)
Mar  2 11:08:00.845: INFO: (19) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:162/proxy/: bar (200; 12.761964ms)
Mar  2 11:08:00.846: INFO: (19) /api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:460/proxy/: tls baz (200; 13.286136ms)
Mar  2 11:08:00.846: INFO: (19) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5/proxy/rewriteme">test</a> (200; 13.553093ms)
Mar  2 11:08:00.846: INFO: (19) /api/v1/namespaces/proxy-6660/services/http:proxy-service-brwqc:portname1/proxy/: foo (200; 15.184633ms)
Mar  2 11:08:00.846: INFO: (19) /api/v1/namespaces/proxy-6660/services/https:proxy-service-brwqc:tlsportname1/proxy/: tls baz (200; 13.691573ms)
Mar  2 11:08:00.846: INFO: (19) /api/v1/namespaces/proxy-6660/pods/https:proxy-service-brwqc-wvnn5:462/proxy/: tls qux (200; 13.914451ms)
Mar  2 11:08:00.846: INFO: (19) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:1080/proxy/: <a href="/api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:1080/proxy/rewriteme">test<... (200; 14.047444ms)
Mar  2 11:08:00.846: INFO: (19) /api/v1/namespaces/proxy-6660/services/http:proxy-service-brwqc:portname2/proxy/: bar (200; 15.919388ms)
Mar  2 11:08:00.846: INFO: (19) /api/v1/namespaces/proxy-6660/services/https:proxy-service-brwqc:tlsportname2/proxy/: tls qux (200; 15.29223ms)
Mar  2 11:08:00.846: INFO: (19) /api/v1/namespaces/proxy-6660/pods/proxy-service-brwqc-wvnn5:160/proxy/: foo (200; 13.73282ms)
Mar  2 11:08:00.847: INFO: (19) /api/v1/namespaces/proxy-6660/services/proxy-service-brwqc:portname1/proxy/: foo (200; 14.369468ms)
Mar  2 11:08:00.849: INFO: (19) /api/v1/namespaces/proxy-6660/services/proxy-service-brwqc:portname2/proxy/: bar (200; 16.528023ms)
STEP: deleting ReplicationController proxy-service-brwqc in namespace proxy-6660, will wait for the garbage collector to delete the pods
Mar  2 11:08:00.941: INFO: Deleting ReplicationController proxy-service-brwqc took: 36.48089ms
Mar  2 11:08:01.441: INFO: Terminating ReplicationController proxy-service-brwqc pods took: 500.412055ms
[AfterEach] version v1
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 11:08:12.342: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-6660" for this suite.
Mar  2 11:08:20.527: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 11:08:20.763: INFO: namespace proxy-6660 deletion completed in 8.411949691s

• [SLOW TEST:32.909 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 11:08:20.764: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-5008
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 11:08:21.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5008" for this suite.
Mar  2 11:08:29.540: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 11:08:29.834: INFO: namespace services-5008 deletion completed in 8.32010312s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:9.071 seconds]
[sig-network] Services
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 11:08:29.835: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-2811
STEP: Waiting for a default service account to be provisioned in namespace
[It] listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  2 11:08:30.197: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 11:09:32.139: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-2811" for this suite.
Mar  2 11:09:38.193: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 11:09:38.394: INFO: namespace custom-resource-definition-2811 deletion completed in 6.246183988s

• [SLOW TEST:68.559 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    listing custom resource definition objects works  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 11:09:38.394: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-4386
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation
Mar  2 11:09:38.821: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation
Mar  2 11:10:02.500: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
Mar  2 11:10:11.933: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 11:10:36.933: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4386" for this suite.
Mar  2 11:10:42.969: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 11:10:43.317: INFO: namespace crd-publish-openapi-4386 deletion completed in 6.375351643s

• [SLOW TEST:64.923 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 11:10:43.317: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8747
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-016c6187-b88a-4ff3-beb6-a0216d4daaf8
STEP: Creating a pod to test consume secrets
Mar  2 11:10:43.685: INFO: Waiting up to 5m0s for pod "pod-secrets-0904ae30-efce-4ab7-b1a3-d70e915b8a11" in namespace "secrets-8747" to be "success or failure"
Mar  2 11:10:43.744: INFO: Pod "pod-secrets-0904ae30-efce-4ab7-b1a3-d70e915b8a11": Phase="Pending", Reason="", readiness=false. Elapsed: 58.466111ms
Mar  2 11:10:45.952: INFO: Pod "pod-secrets-0904ae30-efce-4ab7-b1a3-d70e915b8a11": Phase="Pending", Reason="", readiness=false. Elapsed: 2.266730099s
Mar  2 11:10:47.962: INFO: Pod "pod-secrets-0904ae30-efce-4ab7-b1a3-d70e915b8a11": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.277029652s
STEP: Saw pod success
Mar  2 11:10:47.962: INFO: Pod "pod-secrets-0904ae30-efce-4ab7-b1a3-d70e915b8a11" satisfied condition "success or failure"
Mar  2 11:10:47.966: INFO: Trying to get logs from node worker1 pod pod-secrets-0904ae30-efce-4ab7-b1a3-d70e915b8a11 container secret-volume-test: <nil>
STEP: delete the pod
Mar  2 11:10:48.134: INFO: Waiting for pod pod-secrets-0904ae30-efce-4ab7-b1a3-d70e915b8a11 to disappear
Mar  2 11:10:48.577: INFO: Pod pod-secrets-0904ae30-efce-4ab7-b1a3-d70e915b8a11 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 11:10:48.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8747" for this suite.
Mar  2 11:10:56.691: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 11:10:57.031: INFO: namespace secrets-8747 deletion completed in 8.447663172s

• [SLOW TEST:13.714 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 11:10:57.032: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1498
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl rolling-update
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1499
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image 172.20.8.7/library/httpd:2.4.38-alpine
Mar  2 11:10:57.357: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 run e2e-test-httpd-rc --image=172.20.8.7/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-1498'
Mar  2 11:10:57.527: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Mar  2 11:10:57.527: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
Mar  2 11:10:57.539: INFO: Waiting for rc e2e-test-httpd-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Mar  2 11:10:57.566: INFO: Waiting for rc e2e-test-httpd-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Mar  2 11:10:57.756: INFO: scanned /root for discovery docs: <nil>
Mar  2 11:10:57.756: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 rolling-update e2e-test-httpd-rc --update-period=1s --image=172.20.8.7/library/httpd:2.4.38-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-1498'
Mar  2 11:11:14.674: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Mar  2 11:11:14.674: INFO: stdout: "Created e2e-test-httpd-rc-a06d230e663b2de3ece4de335577ceee\nScaling up e2e-test-httpd-rc-a06d230e663b2de3ece4de335577ceee from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-a06d230e663b2de3ece4de335577ceee up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-a06d230e663b2de3ece4de335577ceee to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
Mar  2 11:11:14.674: INFO: stdout: "Created e2e-test-httpd-rc-a06d230e663b2de3ece4de335577ceee\nScaling up e2e-test-httpd-rc-a06d230e663b2de3ece4de335577ceee from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-a06d230e663b2de3ece4de335577ceee up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-a06d230e663b2de3ece4de335577ceee to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-httpd-rc pods to come up.
Mar  2 11:11:14.674: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-httpd-rc --namespace=kubectl-1498'
Mar  2 11:11:14.825: INFO: stderr: ""
Mar  2 11:11:14.825: INFO: stdout: "e2e-test-httpd-rc-a06d230e663b2de3ece4de335577ceee-6jqdh "
Mar  2 11:11:14.825: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 get pods e2e-test-httpd-rc-a06d230e663b2de3ece4de335577ceee-6jqdh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-httpd-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1498'
Mar  2 11:11:14.964: INFO: stderr: ""
Mar  2 11:11:14.964: INFO: stdout: "true"
Mar  2 11:11:14.964: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 get pods e2e-test-httpd-rc-a06d230e663b2de3ece4de335577ceee-6jqdh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-httpd-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1498'
Mar  2 11:11:15.120: INFO: stderr: ""
Mar  2 11:11:15.120: INFO: stdout: "172.20.8.7/library/httpd:2.4.38-alpine"
Mar  2 11:11:15.120: INFO: e2e-test-httpd-rc-a06d230e663b2de3ece4de335577ceee-6jqdh is verified up and running
[AfterEach] Kubectl rolling-update
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1505
Mar  2 11:11:15.120: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 delete rc e2e-test-httpd-rc --namespace=kubectl-1498'
Mar  2 11:11:15.290: INFO: stderr: ""
Mar  2 11:11:15.290: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 11:11:15.290: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1498" for this suite.
Mar  2 11:11:27.427: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 11:11:27.572: INFO: namespace kubectl-1498 deletion completed in 12.242503439s

• [SLOW TEST:30.540 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl rolling-update
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1494
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 11:11:27.572: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-8804
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Mar  2 11:11:28.473: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8804 /api/v1/namespaces/watch-8804/configmaps/e2e-watch-test-watch-closed 78be6147-4d47-4777-9359-0f9188486608 105229 0 2020-03-02 11:11:28 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar  2 11:11:28.473: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8804 /api/v1/namespaces/watch-8804/configmaps/e2e-watch-test-watch-closed 78be6147-4d47-4777-9359-0f9188486608 105230 0 2020-03-02 11:11:28 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Mar  2 11:11:28.710: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8804 /api/v1/namespaces/watch-8804/configmaps/e2e-watch-test-watch-closed 78be6147-4d47-4777-9359-0f9188486608 105231 0 2020-03-02 11:11:28 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar  2 11:11:28.710: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8804 /api/v1/namespaces/watch-8804/configmaps/e2e-watch-test-watch-closed 78be6147-4d47-4777-9359-0f9188486608 105232 0 2020-03-02 11:11:28 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 11:11:28.710: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8804" for this suite.
Mar  2 11:11:36.752: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 11:11:36.862: INFO: namespace watch-8804 deletion completed in 8.144460387s

• [SLOW TEST:9.290 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 11:11:36.863: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-4222
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  2 11:11:37.177: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Mar  2 11:11:37.237: INFO: Pod name sample-pod: Found 0 pods out of 1
Mar  2 11:11:42.243: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Mar  2 11:11:42.243: INFO: Creating deployment "test-rolling-update-deployment"
Mar  2 11:11:42.285: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Mar  2 11:11:42.293: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Mar  2 11:11:44.341: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Mar  2 11:11:44.353: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718744302, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718744302, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718744303, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718744302, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-5cb9fc687f\" is progressing."}}, CollisionCount:(*int32)(nil)}
Mar  2 11:11:46.358: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Mar  2 11:11:46.672: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-4222 /apis/apps/v1/namespaces/deployment-4222/deployments/test-rolling-update-deployment 2632df81-00f2-4f36-b041-a5d7333e270c 105316 1 2020-03-02 11:11:42 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] []  []} {[] [] [{redis 172.20.8.7/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0034c7b28 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-03-02 11:11:42 +0000 UTC,LastTransitionTime:2020-03-02 11:11:42 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-5cb9fc687f" has successfully progressed.,LastUpdateTime:2020-03-02 11:11:46 +0000 UTC,LastTransitionTime:2020-03-02 11:11:42 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Mar  2 11:11:46.676: INFO: New ReplicaSet "test-rolling-update-deployment-5cb9fc687f" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-5cb9fc687f  deployment-4222 /apis/apps/v1/namespaces/deployment-4222/replicasets/test-rolling-update-deployment-5cb9fc687f a47d35ac-a713-45ba-aa76-4370f817684f 105304 1 2020-03-02 11:11:42 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:5cb9fc687f] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 2632df81-00f2-4f36-b041-a5d7333e270c 0xc00495c017 0xc00495c018}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 5cb9fc687f,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:5cb9fc687f] map[] [] []  []} {[] [] [{redis 172.20.8.7/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00495c078 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Mar  2 11:11:46.676: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Mar  2 11:11:46.676: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-4222 /apis/apps/v1/namespaces/deployment-4222/replicasets/test-rolling-update-controller 5812a2f2-7c18-45ea-871b-fff2e87d3059 105314 2 2020-03-02 11:11:37 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 2632df81-00f2-4f36-b041-a5d7333e270c 0xc0034c7f47 0xc0034c7f48}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] []  []} {[] [] [{httpd 172.20.8.7/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0034c7fa8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Mar  2 11:11:46.681: INFO: Pod "test-rolling-update-deployment-5cb9fc687f-k6bk4" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-5cb9fc687f-k6bk4 test-rolling-update-deployment-5cb9fc687f- deployment-4222 /api/v1/namespaces/deployment-4222/pods/test-rolling-update-deployment-5cb9fc687f-k6bk4 de316183-5d84-4df8-a38a-b22507bae2c7 105302 0 2020-03-02 11:11:42 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:5cb9fc687f] map[] [{apps/v1 ReplicaSet test-rolling-update-deployment-5cb9fc687f a47d35ac-a713-45ba-aa76-4370f817684f 0xc005ebfd27 0xc005ebfd28}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qgxns,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qgxns,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:172.20.8.7/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qgxns,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 11:11:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 11:11:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 11:11:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 11:11:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.8.5,PodIP:10.244.4.182,StartTime:2020-03-02 11:11:42 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-03-02 11:11:44 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:172.20.8.7/library/redis:5.0.5-alpine,ImageID:docker-pullable://172.20.8.7/library/redis@sha256:a606eaca41c3c69c7d2c8a142ec445e71156bae8526ae7970f62b6399e57761c,ContainerID:docker://8e5f0a7739be7cbbdafb92522470574e49cd8f7cc622a425d34dfdaf4e6e3b8d,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.4.182,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 11:11:46.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4222" for this suite.
Mar  2 11:11:54.754: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 11:11:55.366: INFO: namespace deployment-4222 deletion completed in 8.679109703s

• [SLOW TEST:18.504 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 11:11:55.367: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6110
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-f201bd5b-b59d-4c46-aa8f-f7d546290be5
STEP: Creating a pod to test consume secrets
Mar  2 11:11:56.154: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-1c941c9a-9817-49e8-8281-cf5f869ea86d" in namespace "projected-6110" to be "success or failure"
Mar  2 11:11:56.260: INFO: Pod "pod-projected-secrets-1c941c9a-9817-49e8-8281-cf5f869ea86d": Phase="Pending", Reason="", readiness=false. Elapsed: 105.526643ms
Mar  2 11:11:58.269: INFO: Pod "pod-projected-secrets-1c941c9a-9817-49e8-8281-cf5f869ea86d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.115005977s
Mar  2 11:12:00.276: INFO: Pod "pod-projected-secrets-1c941c9a-9817-49e8-8281-cf5f869ea86d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.121748814s
STEP: Saw pod success
Mar  2 11:12:00.276: INFO: Pod "pod-projected-secrets-1c941c9a-9817-49e8-8281-cf5f869ea86d" satisfied condition "success or failure"
Mar  2 11:12:00.281: INFO: Trying to get logs from node worker1 pod pod-projected-secrets-1c941c9a-9817-49e8-8281-cf5f869ea86d container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar  2 11:12:00.440: INFO: Waiting for pod pod-projected-secrets-1c941c9a-9817-49e8-8281-cf5f869ea86d to disappear
Mar  2 11:12:00.445: INFO: Pod pod-projected-secrets-1c941c9a-9817-49e8-8281-cf5f869ea86d no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 11:12:00.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6110" for this suite.
Mar  2 11:12:08.521: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 11:12:08.647: INFO: namespace projected-6110 deletion completed in 8.195019467s

• [SLOW TEST:13.280 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 11:12:08.648: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2545
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Starting the proxy
Mar  2 11:12:09.028: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-956629573 proxy --unix-socket=/tmp/kubectl-proxy-unix413125460/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 11:12:09.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2545" for this suite.
Mar  2 11:12:15.245: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 11:12:15.385: INFO: namespace kubectl-2545 deletion completed in 6.223737177s

• [SLOW TEST:6.737 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Proxy server
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1782
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 11:12:15.385: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8050
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Mar  2 11:12:15.734: INFO: Waiting up to 5m0s for pod "downward-api-366b85b5-3b57-49e8-a93a-31cb24118ca5" in namespace "downward-api-8050" to be "success or failure"
Mar  2 11:12:15.738: INFO: Pod "downward-api-366b85b5-3b57-49e8-a93a-31cb24118ca5": Phase="Pending", Reason="", readiness=false. Elapsed: 3.842432ms
Mar  2 11:12:18.121: INFO: Pod "downward-api-366b85b5-3b57-49e8-a93a-31cb24118ca5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.386533795s
Mar  2 11:12:20.128: INFO: Pod "downward-api-366b85b5-3b57-49e8-a93a-31cb24118ca5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.394310734s
STEP: Saw pod success
Mar  2 11:12:20.128: INFO: Pod "downward-api-366b85b5-3b57-49e8-a93a-31cb24118ca5" satisfied condition "success or failure"
Mar  2 11:12:20.136: INFO: Trying to get logs from node worker1 pod downward-api-366b85b5-3b57-49e8-a93a-31cb24118ca5 container dapi-container: <nil>
STEP: delete the pod
Mar  2 11:12:20.389: INFO: Waiting for pod downward-api-366b85b5-3b57-49e8-a93a-31cb24118ca5 to disappear
Mar  2 11:12:20.476: INFO: Pod downward-api-366b85b5-3b57-49e8-a93a-31cb24118ca5 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 11:12:20.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8050" for this suite.
Mar  2 11:12:28.692: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 11:12:28.822: INFO: namespace downward-api-8050 deletion completed in 8.338532915s

• [SLOW TEST:13.436 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 11:12:28.822: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-4532
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar  2 11:12:30.957: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Mar  2 11:12:32.991: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718744351, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718744351, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718744351, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718744350, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7794d7ccd5\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar  2 11:12:36.152: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API
STEP: create a namespace for the webhook
STEP: create a configmap should be unconditionally rejected by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 11:12:36.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4532" for this suite.
Mar  2 11:12:44.969: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 11:12:45.176: INFO: namespace webhook-4532 deletion completed in 8.571894205s
STEP: Destroying namespace "webhook-4532-markers" for this suite.
Mar  2 11:12:51.271: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 11:12:51.405: INFO: namespace webhook-4532-markers deletion completed in 6.228153362s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:22.650 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 11:12:51.472: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-4094
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar  2 11:12:52.727: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Mar  2 11:12:54.954: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718744372, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718744372, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718744372, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718744372, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7794d7ccd5\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar  2 11:12:58.146: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the crd webhook via the AdmissionRegistration API
Mar  2 11:12:58.471: INFO: Waiting for webhook configuration to be ready...
STEP: Creating a custom resource definition that should be denied by the webhook
Mar  2 11:12:58.587: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 11:12:58.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4094" for this suite.
Mar  2 11:13:06.693: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 11:13:08.235: INFO: namespace webhook-4094 deletion completed in 9.597928692s
STEP: Destroying namespace "webhook-4094-markers" for this suite.
Mar  2 11:13:14.362: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 11:13:14.562: INFO: namespace webhook-4094-markers deletion completed in 6.326078021s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:23.121 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 11:13:14.594: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-1158
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 11:13:19.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1158" for this suite.
Mar  2 11:14:05.658: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 11:14:05.773: INFO: namespace kubelet-test-1158 deletion completed in 46.159976293s

• [SLOW TEST:51.179 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-apps] Job 
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 11:14:05.773: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-985
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: Orphaning one of the Job's Pods
Mar  2 11:14:10.986: INFO: Successfully updated pod "adopt-release-7622b"
STEP: Checking that the Job readopts the Pod
Mar  2 11:14:10.987: INFO: Waiting up to 15m0s for pod "adopt-release-7622b" in namespace "job-985" to be "adopted"
Mar  2 11:14:10.993: INFO: Pod "adopt-release-7622b": Phase="Running", Reason="", readiness=true. Elapsed: 6.83479ms
Mar  2 11:14:12.998: INFO: Pod "adopt-release-7622b": Phase="Running", Reason="", readiness=true. Elapsed: 2.011485783s
Mar  2 11:14:12.998: INFO: Pod "adopt-release-7622b" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod
Mar  2 11:14:13.767: INFO: Successfully updated pod "adopt-release-7622b"
STEP: Checking that the Job releases the Pod
Mar  2 11:14:13.767: INFO: Waiting up to 15m0s for pod "adopt-release-7622b" in namespace "job-985" to be "released"
Mar  2 11:14:13.784: INFO: Pod "adopt-release-7622b": Phase="Running", Reason="", readiness=true. Elapsed: 17.567613ms
Mar  2 11:14:13.784: INFO: Pod "adopt-release-7622b" satisfied condition "released"
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 11:14:13.785: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-985" for this suite.
Mar  2 11:15:10.020: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 11:15:10.139: INFO: namespace job-985 deletion completed in 56.275963721s

• [SLOW TEST:64.366 seconds]
[sig-apps] Job
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 11:15:10.139: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-4006
STEP: Waiting for a default service account to be provisioned in namespace
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Mar  2 11:15:10.413: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: mark a version not serverd
STEP: check the unserved version gets removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 11:15:42.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4006" for this suite.
Mar  2 11:15:50.659: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 11:15:50.840: INFO: namespace crd-publish-openapi-4006 deletion completed in 8.240808338s

• [SLOW TEST:40.701 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 11:15:50.840: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-856
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-secret-68pc
STEP: Creating a pod to test atomic-volume-subpath
Mar  2 11:15:51.288: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-68pc" in namespace "subpath-856" to be "success or failure"
Mar  2 11:15:51.291: INFO: Pod "pod-subpath-test-secret-68pc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.940186ms
Mar  2 11:15:53.299: INFO: Pod "pod-subpath-test-secret-68pc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011272503s
Mar  2 11:15:55.304: INFO: Pod "pod-subpath-test-secret-68pc": Phase="Running", Reason="", readiness=true. Elapsed: 4.016185488s
Mar  2 11:15:57.309: INFO: Pod "pod-subpath-test-secret-68pc": Phase="Running", Reason="", readiness=true. Elapsed: 6.021853314s
Mar  2 11:15:59.315: INFO: Pod "pod-subpath-test-secret-68pc": Phase="Running", Reason="", readiness=true. Elapsed: 8.027300642s
Mar  2 11:16:01.319: INFO: Pod "pod-subpath-test-secret-68pc": Phase="Running", Reason="", readiness=true. Elapsed: 10.031415275s
Mar  2 11:16:03.326: INFO: Pod "pod-subpath-test-secret-68pc": Phase="Running", Reason="", readiness=true. Elapsed: 12.038131717s
Mar  2 11:16:05.332: INFO: Pod "pod-subpath-test-secret-68pc": Phase="Running", Reason="", readiness=true. Elapsed: 14.044141277s
Mar  2 11:16:07.573: INFO: Pod "pod-subpath-test-secret-68pc": Phase="Running", Reason="", readiness=true. Elapsed: 16.285260527s
Mar  2 11:16:09.578: INFO: Pod "pod-subpath-test-secret-68pc": Phase="Running", Reason="", readiness=true. Elapsed: 18.290465481s
Mar  2 11:16:11.591: INFO: Pod "pod-subpath-test-secret-68pc": Phase="Running", Reason="", readiness=true. Elapsed: 20.303252205s
Mar  2 11:16:13.599: INFO: Pod "pod-subpath-test-secret-68pc": Phase="Running", Reason="", readiness=true. Elapsed: 22.311496361s
Mar  2 11:16:15.606: INFO: Pod "pod-subpath-test-secret-68pc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.318206913s
STEP: Saw pod success
Mar  2 11:16:15.606: INFO: Pod "pod-subpath-test-secret-68pc" satisfied condition "success or failure"
Mar  2 11:16:15.611: INFO: Trying to get logs from node worker1 pod pod-subpath-test-secret-68pc container test-container-subpath-secret-68pc: <nil>
STEP: delete the pod
Mar  2 11:16:16.180: INFO: Waiting for pod pod-subpath-test-secret-68pc to disappear
Mar  2 11:16:16.185: INFO: Pod pod-subpath-test-secret-68pc no longer exists
STEP: Deleting pod pod-subpath-test-secret-68pc
Mar  2 11:16:16.185: INFO: Deleting pod "pod-subpath-test-secret-68pc" in namespace "subpath-856"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 11:16:16.306: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-856" for this suite.
Mar  2 11:16:24.360: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 11:16:25.865: INFO: namespace subpath-856 deletion completed in 9.534737701s

• [SLOW TEST:35.025 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 11:16:25.865: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-6619
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  2 11:16:26.940: INFO: (0) /api/v1/nodes/worker1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 9.781538ms)
Mar  2 11:16:26.948: INFO: (1) /api/v1/nodes/worker1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.657176ms)
Mar  2 11:16:26.952: INFO: (2) /api/v1/nodes/worker1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 4.815958ms)
Mar  2 11:16:26.959: INFO: (3) /api/v1/nodes/worker1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.966459ms)
Mar  2 11:16:26.965: INFO: (4) /api/v1/nodes/worker1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.630066ms)
Mar  2 11:16:26.970: INFO: (5) /api/v1/nodes/worker1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.190788ms)
Mar  2 11:16:26.976: INFO: (6) /api/v1/nodes/worker1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.925283ms)
Mar  2 11:16:26.983: INFO: (7) /api/v1/nodes/worker1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.651047ms)
Mar  2 11:16:26.989: INFO: (8) /api/v1/nodes/worker1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.915816ms)
Mar  2 11:16:26.996: INFO: (9) /api/v1/nodes/worker1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.855585ms)
Mar  2 11:16:27.002: INFO: (10) /api/v1/nodes/worker1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.755856ms)
Mar  2 11:16:27.007: INFO: (11) /api/v1/nodes/worker1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.561096ms)
Mar  2 11:16:27.014: INFO: (12) /api/v1/nodes/worker1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.709868ms)
Mar  2 11:16:27.021: INFO: (13) /api/v1/nodes/worker1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.424278ms)
Mar  2 11:16:27.026: INFO: (14) /api/v1/nodes/worker1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.237335ms)
Mar  2 11:16:27.032: INFO: (15) /api/v1/nodes/worker1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.149293ms)
Mar  2 11:16:27.038: INFO: (16) /api/v1/nodes/worker1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 5.547272ms)
Mar  2 11:16:27.045: INFO: (17) /api/v1/nodes/worker1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.330603ms)
Mar  2 11:16:27.052: INFO: (18) /api/v1/nodes/worker1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.764748ms)
Mar  2 11:16:27.058: INFO: (19) /api/v1/nodes/worker1/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.12919ms)
[AfterEach] version v1
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 11:16:27.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-6619" for this suite.
Mar  2 11:16:35.123: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 11:16:35.727: INFO: namespace proxy-6619 deletion completed in 8.66252571s

• [SLOW TEST:9.862 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 11:16:35.728: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2237
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run pod
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1668
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image 172.20.8.7/library/httpd:2.4.38-alpine
Mar  2 11:16:36.204: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 run e2e-test-httpd-pod --restart=Never --generator=run-pod/v1 --image=172.20.8.7/library/httpd:2.4.38-alpine --namespace=kubectl-2237'
Mar  2 11:16:38.199: INFO: stderr: ""
Mar  2 11:16:38.199: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created
[AfterEach] Kubectl run pod
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1673
Mar  2 11:16:38.214: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 delete pods e2e-test-httpd-pod --namespace=kubectl-2237'
Mar  2 11:16:40.889: INFO: stderr: ""
Mar  2 11:16:40.889: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 11:16:40.889: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2237" for this suite.
Mar  2 11:16:48.996: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 11:16:49.225: INFO: namespace kubectl-2237 deletion completed in 8.318893339s

• [SLOW TEST:13.497 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run pod
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1664
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 11:16:49.225: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3134
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Mar  2 11:16:49.670: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3b5078b6-781d-4023-8fcb-5e70b6b36520" in namespace "downward-api-3134" to be "success or failure"
Mar  2 11:16:49.869: INFO: Pod "downwardapi-volume-3b5078b6-781d-4023-8fcb-5e70b6b36520": Phase="Pending", Reason="", readiness=false. Elapsed: 199.212437ms
Mar  2 11:16:51.875: INFO: Pod "downwardapi-volume-3b5078b6-781d-4023-8fcb-5e70b6b36520": Phase="Pending", Reason="", readiness=false. Elapsed: 2.20565839s
Mar  2 11:16:53.883: INFO: Pod "downwardapi-volume-3b5078b6-781d-4023-8fcb-5e70b6b36520": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.213240876s
STEP: Saw pod success
Mar  2 11:16:53.883: INFO: Pod "downwardapi-volume-3b5078b6-781d-4023-8fcb-5e70b6b36520" satisfied condition "success or failure"
Mar  2 11:16:53.887: INFO: Trying to get logs from node worker1 pod downwardapi-volume-3b5078b6-781d-4023-8fcb-5e70b6b36520 container client-container: <nil>
STEP: delete the pod
Mar  2 11:16:54.381: INFO: Waiting for pod downwardapi-volume-3b5078b6-781d-4023-8fcb-5e70b6b36520 to disappear
Mar  2 11:16:54.422: INFO: Pod downwardapi-volume-3b5078b6-781d-4023-8fcb-5e70b6b36520 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 11:16:54.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3134" for this suite.
Mar  2 11:17:02.502: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 11:17:02.683: INFO: namespace downward-api-3134 deletion completed in 8.2248494s

• [SLOW TEST:13.458 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 11:17:02.683: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-2785
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-97kq
STEP: Creating a pod to test atomic-volume-subpath
Mar  2 11:17:03.223: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-97kq" in namespace "subpath-2785" to be "success or failure"
Mar  2 11:17:03.228: INFO: Pod "pod-subpath-test-configmap-97kq": Phase="Pending", Reason="", readiness=false. Elapsed: 4.380423ms
Mar  2 11:17:05.265: INFO: Pod "pod-subpath-test-configmap-97kq": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041955148s
Mar  2 11:17:07.277: INFO: Pod "pod-subpath-test-configmap-97kq": Phase="Running", Reason="", readiness=true. Elapsed: 4.053493283s
Mar  2 11:17:09.316: INFO: Pod "pod-subpath-test-configmap-97kq": Phase="Running", Reason="", readiness=true. Elapsed: 6.092251784s
Mar  2 11:17:11.322: INFO: Pod "pod-subpath-test-configmap-97kq": Phase="Running", Reason="", readiness=true. Elapsed: 8.098627325s
Mar  2 11:17:13.341: INFO: Pod "pod-subpath-test-configmap-97kq": Phase="Running", Reason="", readiness=true. Elapsed: 10.117597028s
Mar  2 11:17:15.349: INFO: Pod "pod-subpath-test-configmap-97kq": Phase="Running", Reason="", readiness=true. Elapsed: 12.125375018s
Mar  2 11:17:17.406: INFO: Pod "pod-subpath-test-configmap-97kq": Phase="Running", Reason="", readiness=true. Elapsed: 14.183052801s
Mar  2 11:17:19.452: INFO: Pod "pod-subpath-test-configmap-97kq": Phase="Running", Reason="", readiness=true. Elapsed: 16.22862678s
Mar  2 11:17:21.459: INFO: Pod "pod-subpath-test-configmap-97kq": Phase="Running", Reason="", readiness=true. Elapsed: 18.236081843s
Mar  2 11:17:23.466: INFO: Pod "pod-subpath-test-configmap-97kq": Phase="Running", Reason="", readiness=true. Elapsed: 20.242205936s
Mar  2 11:17:25.763: INFO: Pod "pod-subpath-test-configmap-97kq": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.539727249s
STEP: Saw pod success
Mar  2 11:17:25.763: INFO: Pod "pod-subpath-test-configmap-97kq" satisfied condition "success or failure"
Mar  2 11:17:25.909: INFO: Trying to get logs from node worker1 pod pod-subpath-test-configmap-97kq container test-container-subpath-configmap-97kq: <nil>
STEP: delete the pod
Mar  2 11:17:26.123: INFO: Waiting for pod pod-subpath-test-configmap-97kq to disappear
Mar  2 11:17:26.128: INFO: Pod pod-subpath-test-configmap-97kq no longer exists
STEP: Deleting pod pod-subpath-test-configmap-97kq
Mar  2 11:17:26.128: INFO: Deleting pod "pod-subpath-test-configmap-97kq" in namespace "subpath-2785"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 11:17:26.137: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2785" for this suite.
Mar  2 11:17:34.231: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 11:17:34.610: INFO: namespace subpath-2785 deletion completed in 8.463433952s

• [SLOW TEST:31.927 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 11:17:34.610: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5837
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Mar  2 11:17:35.087: INFO: Waiting up to 5m0s for pod "pod-849cd73c-0d3d-4953-814d-9546427abc86" in namespace "emptydir-5837" to be "success or failure"
Mar  2 11:17:35.090: INFO: Pod "pod-849cd73c-0d3d-4953-814d-9546427abc86": Phase="Pending", Reason="", readiness=false. Elapsed: 3.790476ms
Mar  2 11:17:37.131: INFO: Pod "pod-849cd73c-0d3d-4953-814d-9546427abc86": Phase="Pending", Reason="", readiness=false. Elapsed: 2.044160708s
Mar  2 11:17:39.138: INFO: Pod "pod-849cd73c-0d3d-4953-814d-9546427abc86": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.051832973s
STEP: Saw pod success
Mar  2 11:17:39.139: INFO: Pod "pod-849cd73c-0d3d-4953-814d-9546427abc86" satisfied condition "success or failure"
Mar  2 11:17:39.144: INFO: Trying to get logs from node worker1 pod pod-849cd73c-0d3d-4953-814d-9546427abc86 container test-container: <nil>
STEP: delete the pod
Mar  2 11:17:39.748: INFO: Waiting for pod pod-849cd73c-0d3d-4953-814d-9546427abc86 to disappear
Mar  2 11:17:39.778: INFO: Pod pod-849cd73c-0d3d-4953-814d-9546427abc86 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 11:17:39.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5837" for this suite.
Mar  2 11:17:45.845: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 11:17:46.103: INFO: namespace emptydir-5837 deletion completed in 6.316980306s

• [SLOW TEST:11.492 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 11:17:46.103: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4762
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  2 11:17:46.508: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-956629573 version'
Mar  2 11:17:46.685: INFO: stderr: ""
Mar  2 11:17:46.685: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.7\", GitCommit:\"be3d344ed06bff7a4fc60656200a93c74f31f9a4\", GitTreeState:\"clean\", BuildDate:\"2020-02-11T19:34:02Z\", GoVersion:\"go1.13.6\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.7\", GitCommit:\"be3d344ed06bff7a4fc60656200a93c74f31f9a4\", GitTreeState:\"clean\", BuildDate:\"2020-02-11T19:24:46Z\", GoVersion:\"go1.13.6\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 11:17:46.685: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4762" for this suite.
Mar  2 11:17:54.727: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 11:17:54.906: INFO: namespace kubectl-4762 deletion completed in 8.211992618s

• [SLOW TEST:8.803 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl version
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1380
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 11:17:54.906: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-6543
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Discovering how many secrets are in namespace by default
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Secret
STEP: Ensuring resource quota status captures secret creation
STEP: Deleting a secret
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 11:18:12.492: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6543" for this suite.
Mar  2 11:18:18.559: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 11:18:18.720: INFO: namespace resourcequota-6543 deletion completed in 6.204145245s

• [SLOW TEST:23.814 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 11:18:18.721: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-3455
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-downwardapi-25bt
STEP: Creating a pod to test atomic-volume-subpath
Mar  2 11:18:19.239: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-25bt" in namespace "subpath-3455" to be "success or failure"
Mar  2 11:18:19.274: INFO: Pod "pod-subpath-test-downwardapi-25bt": Phase="Pending", Reason="", readiness=false. Elapsed: 35.037945ms
Mar  2 11:18:21.450: INFO: Pod "pod-subpath-test-downwardapi-25bt": Phase="Pending", Reason="", readiness=false. Elapsed: 2.21093646s
Mar  2 11:18:23.456: INFO: Pod "pod-subpath-test-downwardapi-25bt": Phase="Running", Reason="", readiness=true. Elapsed: 4.216428808s
Mar  2 11:18:25.467: INFO: Pod "pod-subpath-test-downwardapi-25bt": Phase="Running", Reason="", readiness=true. Elapsed: 6.227926902s
Mar  2 11:18:27.472: INFO: Pod "pod-subpath-test-downwardapi-25bt": Phase="Running", Reason="", readiness=true. Elapsed: 8.232620122s
Mar  2 11:18:29.660: INFO: Pod "pod-subpath-test-downwardapi-25bt": Phase="Running", Reason="", readiness=true. Elapsed: 10.421106066s
Mar  2 11:18:31.667: INFO: Pod "pod-subpath-test-downwardapi-25bt": Phase="Running", Reason="", readiness=true. Elapsed: 12.427789706s
Mar  2 11:18:33.672: INFO: Pod "pod-subpath-test-downwardapi-25bt": Phase="Running", Reason="", readiness=true. Elapsed: 14.432861607s
Mar  2 11:18:35.678: INFO: Pod "pod-subpath-test-downwardapi-25bt": Phase="Running", Reason="", readiness=true. Elapsed: 16.439353201s
Mar  2 11:18:37.684: INFO: Pod "pod-subpath-test-downwardapi-25bt": Phase="Running", Reason="", readiness=true. Elapsed: 18.445027912s
Mar  2 11:18:39.710: INFO: Pod "pod-subpath-test-downwardapi-25bt": Phase="Running", Reason="", readiness=true. Elapsed: 20.471246739s
Mar  2 11:18:41.716: INFO: Pod "pod-subpath-test-downwardapi-25bt": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.476988334s
STEP: Saw pod success
Mar  2 11:18:41.716: INFO: Pod "pod-subpath-test-downwardapi-25bt" satisfied condition "success or failure"
Mar  2 11:18:41.780: INFO: Trying to get logs from node worker1 pod pod-subpath-test-downwardapi-25bt container test-container-subpath-downwardapi-25bt: <nil>
STEP: delete the pod
Mar  2 11:18:42.046: INFO: Waiting for pod pod-subpath-test-downwardapi-25bt to disappear
Mar  2 11:18:42.051: INFO: Pod pod-subpath-test-downwardapi-25bt no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-25bt
Mar  2 11:18:42.051: INFO: Deleting pod "pod-subpath-test-downwardapi-25bt" in namespace "subpath-3455"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 11:18:42.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-3455" for this suite.
Mar  2 11:18:50.170: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 11:18:50.373: INFO: namespace subpath-3455 deletion completed in 8.310978514s

• [SLOW TEST:31.653 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 11:18:50.374: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-5361
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override arguments
Mar  2 11:18:51.097: INFO: Waiting up to 5m0s for pod "client-containers-63d62956-6189-4872-b056-fc29da5c554e" in namespace "containers-5361" to be "success or failure"
Mar  2 11:18:51.165: INFO: Pod "client-containers-63d62956-6189-4872-b056-fc29da5c554e": Phase="Pending", Reason="", readiness=false. Elapsed: 67.858744ms
Mar  2 11:18:53.178: INFO: Pod "client-containers-63d62956-6189-4872-b056-fc29da5c554e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.080640998s
Mar  2 11:18:55.185: INFO: Pod "client-containers-63d62956-6189-4872-b056-fc29da5c554e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.087278092s
STEP: Saw pod success
Mar  2 11:18:55.185: INFO: Pod "client-containers-63d62956-6189-4872-b056-fc29da5c554e" satisfied condition "success or failure"
Mar  2 11:18:55.190: INFO: Trying to get logs from node worker1 pod client-containers-63d62956-6189-4872-b056-fc29da5c554e container test-container: <nil>
STEP: delete the pod
Mar  2 11:18:56.326: INFO: Waiting for pod client-containers-63d62956-6189-4872-b056-fc29da5c554e to disappear
Mar  2 11:18:56.343: INFO: Pod client-containers-63d62956-6189-4872-b056-fc29da5c554e no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 11:18:56.344: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-5361" for this suite.
Mar  2 11:19:04.669: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 11:19:05.292: INFO: namespace containers-5361 deletion completed in 8.705909445s

• [SLOW TEST:14.919 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 11:19:05.293: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9776
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-f8c5d414-c26c-46f7-bc51-df619989a38b
STEP: Creating a pod to test consume configMaps
Mar  2 11:19:05.711: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c9999bda-0979-4533-970b-8ce9455c75ba" in namespace "projected-9776" to be "success or failure"
Mar  2 11:19:05.715: INFO: Pod "pod-projected-configmaps-c9999bda-0979-4533-970b-8ce9455c75ba": Phase="Pending", Reason="", readiness=false. Elapsed: 3.494782ms
Mar  2 11:19:07.720: INFO: Pod "pod-projected-configmaps-c9999bda-0979-4533-970b-8ce9455c75ba": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008625979s
Mar  2 11:19:09.743: INFO: Pod "pod-projected-configmaps-c9999bda-0979-4533-970b-8ce9455c75ba": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031978796s
STEP: Saw pod success
Mar  2 11:19:09.743: INFO: Pod "pod-projected-configmaps-c9999bda-0979-4533-970b-8ce9455c75ba" satisfied condition "success or failure"
Mar  2 11:19:09.748: INFO: Trying to get logs from node worker1 pod pod-projected-configmaps-c9999bda-0979-4533-970b-8ce9455c75ba container projected-configmap-volume-test: <nil>
STEP: delete the pod
Mar  2 11:19:09.930: INFO: Waiting for pod pod-projected-configmaps-c9999bda-0979-4533-970b-8ce9455c75ba to disappear
Mar  2 11:19:09.935: INFO: Pod pod-projected-configmaps-c9999bda-0979-4533-970b-8ce9455c75ba no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 11:19:09.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9776" for this suite.
Mar  2 11:19:18.022: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 11:19:18.140: INFO: namespace projected-9776 deletion completed in 8.197149104s

• [SLOW TEST:12.847 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 11:19:18.140: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5400
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-73b19d5c-2876-429b-a526-a5835e1b4ba5
STEP: Creating a pod to test consume secrets
Mar  2 11:19:18.610: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-c6776a4c-768d-4dda-9d7b-4ddc9fca7002" in namespace "projected-5400" to be "success or failure"
Mar  2 11:19:18.628: INFO: Pod "pod-projected-secrets-c6776a4c-768d-4dda-9d7b-4ddc9fca7002": Phase="Pending", Reason="", readiness=false. Elapsed: 17.643342ms
Mar  2 11:19:20.633: INFO: Pod "pod-projected-secrets-c6776a4c-768d-4dda-9d7b-4ddc9fca7002": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022845316s
Mar  2 11:19:22.638: INFO: Pod "pod-projected-secrets-c6776a4c-768d-4dda-9d7b-4ddc9fca7002": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02785977s
STEP: Saw pod success
Mar  2 11:19:22.638: INFO: Pod "pod-projected-secrets-c6776a4c-768d-4dda-9d7b-4ddc9fca7002" satisfied condition "success or failure"
Mar  2 11:19:22.656: INFO: Trying to get logs from node worker1 pod pod-projected-secrets-c6776a4c-768d-4dda-9d7b-4ddc9fca7002 container projected-secret-volume-test: <nil>
STEP: delete the pod
Mar  2 11:19:22.955: INFO: Waiting for pod pod-projected-secrets-c6776a4c-768d-4dda-9d7b-4ddc9fca7002 to disappear
Mar  2 11:19:22.960: INFO: Pod pod-projected-secrets-c6776a4c-768d-4dda-9d7b-4ddc9fca7002 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 11:19:22.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5400" for this suite.
Mar  2 11:19:31.046: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 11:19:31.175: INFO: namespace projected-5400 deletion completed in 8.157144269s

• [SLOW TEST:13.035 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 11:19:31.176: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-9598
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
Mar  2 11:19:38.753: INFO: 3 pods remaining
Mar  2 11:19:38.753: INFO: 1 pods has nil DeletionTimestamp
Mar  2 11:19:38.753: INFO: 
STEP: Gathering metrics
Mar  2 11:19:39.626: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 11:19:39.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W0302 11:19:39.626267      24 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-9598" for this suite.
Mar  2 11:19:51.688: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 11:19:51.824: INFO: namespace gc-9598 deletion completed in 12.187403003s

• [SLOW TEST:20.648 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 11:19:51.824: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-8486
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-projected-pk79
STEP: Creating a pod to test atomic-volume-subpath
Mar  2 11:19:53.172: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-pk79" in namespace "subpath-8486" to be "success or failure"
Mar  2 11:19:53.204: INFO: Pod "pod-subpath-test-projected-pk79": Phase="Pending", Reason="", readiness=false. Elapsed: 31.632273ms
Mar  2 11:19:55.213: INFO: Pod "pod-subpath-test-projected-pk79": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041044683s
Mar  2 11:19:57.220: INFO: Pod "pod-subpath-test-projected-pk79": Phase="Running", Reason="", readiness=true. Elapsed: 4.048006273s
Mar  2 11:19:59.225: INFO: Pod "pod-subpath-test-projected-pk79": Phase="Running", Reason="", readiness=true. Elapsed: 6.052548314s
Mar  2 11:20:01.259: INFO: Pod "pod-subpath-test-projected-pk79": Phase="Running", Reason="", readiness=true. Elapsed: 8.087214495s
Mar  2 11:20:03.265: INFO: Pod "pod-subpath-test-projected-pk79": Phase="Running", Reason="", readiness=true. Elapsed: 10.092824018s
Mar  2 11:20:05.331: INFO: Pod "pod-subpath-test-projected-pk79": Phase="Running", Reason="", readiness=true. Elapsed: 12.158938673s
Mar  2 11:20:07.337: INFO: Pod "pod-subpath-test-projected-pk79": Phase="Running", Reason="", readiness=true. Elapsed: 14.164979596s
Mar  2 11:20:09.343: INFO: Pod "pod-subpath-test-projected-pk79": Phase="Running", Reason="", readiness=true. Elapsed: 16.170396378s
Mar  2 11:20:11.348: INFO: Pod "pod-subpath-test-projected-pk79": Phase="Running", Reason="", readiness=true. Elapsed: 18.175747308s
Mar  2 11:20:13.355: INFO: Pod "pod-subpath-test-projected-pk79": Phase="Running", Reason="", readiness=true. Elapsed: 20.183032773s
Mar  2 11:20:15.361: INFO: Pod "pod-subpath-test-projected-pk79": Phase="Running", Reason="", readiness=true. Elapsed: 22.189142899s
Mar  2 11:20:17.367: INFO: Pod "pod-subpath-test-projected-pk79": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.19482443s
STEP: Saw pod success
Mar  2 11:20:17.367: INFO: Pod "pod-subpath-test-projected-pk79" satisfied condition "success or failure"
Mar  2 11:20:17.681: INFO: Trying to get logs from node worker1 pod pod-subpath-test-projected-pk79 container test-container-subpath-projected-pk79: <nil>
STEP: delete the pod
Mar  2 11:20:18.033: INFO: Waiting for pod pod-subpath-test-projected-pk79 to disappear
Mar  2 11:20:18.053: INFO: Pod pod-subpath-test-projected-pk79 no longer exists
STEP: Deleting pod pod-subpath-test-projected-pk79
Mar  2 11:20:18.053: INFO: Deleting pod "pod-subpath-test-projected-pk79" in namespace "subpath-8486"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 11:20:18.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8486" for this suite.
Mar  2 11:20:26.151: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 11:20:26.301: INFO: namespace subpath-8486 deletion completed in 8.22636882s

• [SLOW TEST:34.477 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 11:20:26.301: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7766
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-7766/configmap-test-a4702d96-7ee0-4036-a2fe-73d36d7e5397
STEP: Creating a pod to test consume configMaps
Mar  2 11:20:26.814: INFO: Waiting up to 5m0s for pod "pod-configmaps-2fa26c54-7f13-4ee1-9220-cbf437cd0130" in namespace "configmap-7766" to be "success or failure"
Mar  2 11:20:26.818: INFO: Pod "pod-configmaps-2fa26c54-7f13-4ee1-9220-cbf437cd0130": Phase="Pending", Reason="", readiness=false. Elapsed: 4.485294ms
Mar  2 11:20:28.854: INFO: Pod "pod-configmaps-2fa26c54-7f13-4ee1-9220-cbf437cd0130": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040484033s
Mar  2 11:20:30.859: INFO: Pod "pod-configmaps-2fa26c54-7f13-4ee1-9220-cbf437cd0130": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.045559954s
STEP: Saw pod success
Mar  2 11:20:30.860: INFO: Pod "pod-configmaps-2fa26c54-7f13-4ee1-9220-cbf437cd0130" satisfied condition "success or failure"
Mar  2 11:20:30.872: INFO: Trying to get logs from node worker1 pod pod-configmaps-2fa26c54-7f13-4ee1-9220-cbf437cd0130 container env-test: <nil>
STEP: delete the pod
Mar  2 11:20:30.950: INFO: Waiting for pod pod-configmaps-2fa26c54-7f13-4ee1-9220-cbf437cd0130 to disappear
Mar  2 11:20:30.955: INFO: Pod pod-configmaps-2fa26c54-7f13-4ee1-9220-cbf437cd0130 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 11:20:30.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7766" for this suite.
Mar  2 11:20:39.029: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 11:20:39.221: INFO: namespace configmap-7766 deletion completed in 8.257046841s

• [SLOW TEST:12.920 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 11:20:39.221: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in events-1325
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Mar  2 11:20:44.284: INFO: &Pod{ObjectMeta:{send-events-2f5d3302-ddd9-41c4-8cff-4880d27e10f6  events-1325 /api/v1/namespaces/events-1325/pods/send-events-2f5d3302-ddd9-41c4-8cff-4880d27e10f6 ee1ed4fa-f364-4448-9397-2a16cf5060db 107253 0 2020-03-02 11:20:39 +0000 UTC <nil> <nil> map[name:foo time:490869141] map[] [] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4b8ml,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4b8ml,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:p,Image:172.20.8.7/library/agnhost:2.6,Command:[],Args:[serve-hostname],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4b8ml,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worker1,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 11:20:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 11:20:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 11:20:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-03-02 11:20:39 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.20.8.5,PodIP:10.244.4.207,StartTime:2020-03-02 11:20:39 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:p,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-03-02 11:20:41 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:172.20.8.7/library/agnhost:2.6,ImageID:docker-pullable://172.20.8.7/library/agnhost@sha256:4273341f784390e3fd568bee1bf86efe6ef4ad4a7a1a75c0dcd01776683d669a,ContainerID:docker://6adde969d711cfe642300c51f13227adf8975c04728036d4d53eceb80823ac38,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.4.207,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

STEP: checking for scheduler event about the pod
Mar  2 11:20:46.290: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Mar  2 11:20:48.296: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 11:20:48.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-1325" for this suite.
Mar  2 11:21:34.681: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 11:21:35.071: INFO: namespace events-1325 deletion completed in 46.736308556s

• [SLOW TEST:55.850 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 11:21:35.072: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-2203
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Mar  2 11:22:15.613: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 11:22:15.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W0302 11:22:15.613520      24 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-2203" for this suite.
Mar  2 11:22:27.685: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 11:22:27.799: INFO: namespace gc-2203 deletion completed in 12.178507263s

• [SLOW TEST:52.727 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 11:22:27.800: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-8292
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  2 11:22:28.513: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Mar  2 11:22:28.642: INFO: Number of nodes with available pods: 0
Mar  2 11:22:28.642: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Mar  2 11:22:29.204: INFO: Number of nodes with available pods: 0
Mar  2 11:22:29.204: INFO: Node worker1 is running more than one daemon pod
Mar  2 11:22:30.228: INFO: Number of nodes with available pods: 0
Mar  2 11:22:30.228: INFO: Node worker1 is running more than one daemon pod
Mar  2 11:22:31.211: INFO: Number of nodes with available pods: 0
Mar  2 11:22:31.211: INFO: Node worker1 is running more than one daemon pod
Mar  2 11:22:32.210: INFO: Number of nodes with available pods: 1
Mar  2 11:22:32.210: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Mar  2 11:22:32.272: INFO: Number of nodes with available pods: 1
Mar  2 11:22:32.272: INFO: Number of running nodes: 0, number of available pods: 1
Mar  2 11:22:33.296: INFO: Number of nodes with available pods: 0
Mar  2 11:22:33.296: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Mar  2 11:22:33.352: INFO: Number of nodes with available pods: 0
Mar  2 11:22:33.352: INFO: Node worker1 is running more than one daemon pod
Mar  2 11:22:34.359: INFO: Number of nodes with available pods: 0
Mar  2 11:22:34.359: INFO: Node worker1 is running more than one daemon pod
Mar  2 11:22:35.359: INFO: Number of nodes with available pods: 0
Mar  2 11:22:35.359: INFO: Node worker1 is running more than one daemon pod
Mar  2 11:22:36.380: INFO: Number of nodes with available pods: 0
Mar  2 11:22:36.380: INFO: Node worker1 is running more than one daemon pod
Mar  2 11:22:37.360: INFO: Number of nodes with available pods: 0
Mar  2 11:22:37.360: INFO: Node worker1 is running more than one daemon pod
Mar  2 11:22:38.356: INFO: Number of nodes with available pods: 0
Mar  2 11:22:38.356: INFO: Node worker1 is running more than one daemon pod
Mar  2 11:22:39.359: INFO: Number of nodes with available pods: 0
Mar  2 11:22:39.359: INFO: Node worker1 is running more than one daemon pod
Mar  2 11:22:40.357: INFO: Number of nodes with available pods: 0
Mar  2 11:22:40.357: INFO: Node worker1 is running more than one daemon pod
Mar  2 11:22:41.377: INFO: Number of nodes with available pods: 0
Mar  2 11:22:41.377: INFO: Node worker1 is running more than one daemon pod
Mar  2 11:22:42.388: INFO: Number of nodes with available pods: 0
Mar  2 11:22:42.388: INFO: Node worker1 is running more than one daemon pod
Mar  2 11:22:43.359: INFO: Number of nodes with available pods: 0
Mar  2 11:22:43.359: INFO: Node worker1 is running more than one daemon pod
Mar  2 11:22:44.357: INFO: Number of nodes with available pods: 0
Mar  2 11:22:44.357: INFO: Node worker1 is running more than one daemon pod
Mar  2 11:22:45.371: INFO: Number of nodes with available pods: 1
Mar  2 11:22:45.371: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8292, will wait for the garbage collector to delete the pods
Mar  2 11:22:45.810: INFO: Deleting DaemonSet.extensions daemon-set took: 376.06973ms
Mar  2 11:22:46.310: INFO: Terminating DaemonSet.extensions daemon-set pods took: 500.199144ms
Mar  2 11:22:48.817: INFO: Number of nodes with available pods: 0
Mar  2 11:22:48.817: INFO: Number of running nodes: 0, number of available pods: 0
Mar  2 11:22:48.822: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-8292/daemonsets","resourceVersion":"107754"},"items":null}

Mar  2 11:22:48.828: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-8292/pods","resourceVersion":"107754"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 11:22:48.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8292" for this suite.
Mar  2 11:22:56.976: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 11:22:57.427: INFO: namespace daemonsets-8292 deletion completed in 8.527965963s

• [SLOW TEST:29.628 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 11:22:57.428: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-739
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Mar  2 11:22:58.818: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Mar  2 11:23:00.868: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718744978, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718744978, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63718744979, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63718744978, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-7794d7ccd5\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Mar  2 11:23:03.922: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Mar  2 11:23:04.045: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-3755-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 11:23:10.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-739" for this suite.
Mar  2 11:23:18.911: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 11:23:19.042: INFO: namespace webhook-739 deletion completed in 8.428422077s
STEP: Destroying namespace "webhook-739-markers" for this suite.
Mar  2 11:23:27.081: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 11:23:27.407: INFO: namespace webhook-739-markers deletion completed in 8.36483866s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:30.030 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 11:23:27.458: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-4014
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-qwm5
STEP: Creating a pod to test atomic-volume-subpath
Mar  2 11:23:27.864: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-qwm5" in namespace "subpath-4014" to be "success or failure"
Mar  2 11:23:27.878: INFO: Pod "pod-subpath-test-configmap-qwm5": Phase="Pending", Reason="", readiness=false. Elapsed: 14.475832ms
Mar  2 11:23:29.883: INFO: Pod "pod-subpath-test-configmap-qwm5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019135608s
Mar  2 11:23:31.889: INFO: Pod "pod-subpath-test-configmap-qwm5": Phase="Running", Reason="", readiness=true. Elapsed: 4.025273709s
Mar  2 11:23:33.896: INFO: Pod "pod-subpath-test-configmap-qwm5": Phase="Running", Reason="", readiness=true. Elapsed: 6.032162319s
Mar  2 11:23:35.902: INFO: Pod "pod-subpath-test-configmap-qwm5": Phase="Running", Reason="", readiness=true. Elapsed: 8.037835211s
Mar  2 11:23:37.906: INFO: Pod "pod-subpath-test-configmap-qwm5": Phase="Running", Reason="", readiness=true. Elapsed: 10.042461191s
Mar  2 11:23:39.912: INFO: Pod "pod-subpath-test-configmap-qwm5": Phase="Running", Reason="", readiness=true. Elapsed: 12.048020751s
Mar  2 11:23:41.917: INFO: Pod "pod-subpath-test-configmap-qwm5": Phase="Running", Reason="", readiness=true. Elapsed: 14.053409767s
Mar  2 11:23:43.922: INFO: Pod "pod-subpath-test-configmap-qwm5": Phase="Running", Reason="", readiness=true. Elapsed: 16.058624853s
Mar  2 11:23:45.936: INFO: Pod "pod-subpath-test-configmap-qwm5": Phase="Running", Reason="", readiness=true. Elapsed: 18.072169563s
Mar  2 11:23:47.941: INFO: Pod "pod-subpath-test-configmap-qwm5": Phase="Running", Reason="", readiness=true. Elapsed: 20.076788992s
Mar  2 11:23:49.947: INFO: Pod "pod-subpath-test-configmap-qwm5": Phase="Running", Reason="", readiness=true. Elapsed: 22.083243616s
Mar  2 11:23:51.954: INFO: Pod "pod-subpath-test-configmap-qwm5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.090112202s
STEP: Saw pod success
Mar  2 11:23:51.954: INFO: Pod "pod-subpath-test-configmap-qwm5" satisfied condition "success or failure"
Mar  2 11:23:51.958: INFO: Trying to get logs from node worker1 pod pod-subpath-test-configmap-qwm5 container test-container-subpath-configmap-qwm5: <nil>
STEP: delete the pod
Mar  2 11:23:52.102: INFO: Waiting for pod pod-subpath-test-configmap-qwm5 to disappear
Mar  2 11:23:52.106: INFO: Pod pod-subpath-test-configmap-qwm5 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-qwm5
Mar  2 11:23:52.106: INFO: Deleting pod "pod-subpath-test-configmap-qwm5" in namespace "subpath-4014"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 11:23:52.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4014" for this suite.
Mar  2 11:24:00.178: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 11:24:00.298: INFO: namespace subpath-4014 deletion completed in 8.169795542s

• [SLOW TEST:32.840 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 11:24:00.299: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-7337
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Mar  2 11:24:00.770: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7337 /api/v1/namespaces/watch-7337/configmaps/e2e-watch-test-label-changed fe57af26-5a64-45ae-9460-e1c8c62a63ea 108025 0 2020-03-02 11:24:00 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Mar  2 11:24:00.770: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7337 /api/v1/namespaces/watch-7337/configmaps/e2e-watch-test-label-changed fe57af26-5a64-45ae-9460-e1c8c62a63ea 108026 0 2020-03-02 11:24:00 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Mar  2 11:24:00.784: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7337 /api/v1/namespaces/watch-7337/configmaps/e2e-watch-test-label-changed fe57af26-5a64-45ae-9460-e1c8c62a63ea 108028 0 2020-03-02 11:24:00 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Mar  2 11:24:11.002: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7337 /api/v1/namespaces/watch-7337/configmaps/e2e-watch-test-label-changed fe57af26-5a64-45ae-9460-e1c8c62a63ea 108049 0 2020-03-02 11:24:00 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Mar  2 11:24:11.002: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7337 /api/v1/namespaces/watch-7337/configmaps/e2e-watch-test-label-changed fe57af26-5a64-45ae-9460-e1c8c62a63ea 108050 0 2020-03-02 11:24:00 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Mar  2 11:24:11.002: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7337 /api/v1/namespaces/watch-7337/configmaps/e2e-watch-test-label-changed fe57af26-5a64-45ae-9460-e1c8c62a63ea 108051 0 2020-03-02 11:24:00 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 11:24:11.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7337" for this suite.
Mar  2 11:24:17.037: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 11:24:17.175: INFO: namespace watch-7337 deletion completed in 6.166091098s

• [SLOW TEST:16.876 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 11:24:17.175: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-1112
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-fa5455e4-be99-4729-8b0a-27fa4f0a9329
STEP: Creating a pod to test consume secrets
Mar  2 11:24:17.863: INFO: Waiting up to 5m0s for pod "pod-secrets-6e02ab98-c165-442e-a213-b15719947c03" in namespace "secrets-1112" to be "success or failure"
Mar  2 11:24:17.867: INFO: Pod "pod-secrets-6e02ab98-c165-442e-a213-b15719947c03": Phase="Pending", Reason="", readiness=false. Elapsed: 3.595017ms
Mar  2 11:24:19.871: INFO: Pod "pod-secrets-6e02ab98-c165-442e-a213-b15719947c03": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008378563s
Mar  2 11:24:21.877: INFO: Pod "pod-secrets-6e02ab98-c165-442e-a213-b15719947c03": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013784769s
STEP: Saw pod success
Mar  2 11:24:21.877: INFO: Pod "pod-secrets-6e02ab98-c165-442e-a213-b15719947c03" satisfied condition "success or failure"
Mar  2 11:24:21.882: INFO: Trying to get logs from node worker1 pod pod-secrets-6e02ab98-c165-442e-a213-b15719947c03 container secret-volume-test: <nil>
STEP: delete the pod
Mar  2 11:24:21.944: INFO: Waiting for pod pod-secrets-6e02ab98-c165-442e-a213-b15719947c03 to disappear
Mar  2 11:24:21.947: INFO: Pod pod-secrets-6e02ab98-c165-442e-a213-b15719947c03 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 11:24:21.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1112" for this suite.
Mar  2 11:24:28.020: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 11:24:28.291: INFO: namespace secrets-1112 deletion completed in 6.313725468s

• [SLOW TEST:11.116 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Mar  2 11:24:28.292: INFO: >>> kubeConfig: /tmp/kubeconfig-956629573
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-3804
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Mar  2 11:24:28.709: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Mar  2 11:24:37.978: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Mar  2 11:24:37.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3804" for this suite.
Mar  2 11:24:44.037: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Mar  2 11:24:44.151: INFO: namespace pods-3804 deletion completed in 6.160797216s

• [SLOW TEST:15.859 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSMar  2 11:24:44.152: INFO: Running AfterSuite actions on all nodes
Mar  2 11:24:44.152: INFO: Running AfterSuite actions on node 1
Mar  2 11:24:44.152: INFO: Skipping dumping logs from cluster

Ran 274 of 4731 Specs in 8104.359 seconds
SUCCESS! -- 274 Passed | 0 Failed | 0 Pending | 4457 Skipped
PASS

Ginkgo ran 1 suite in 2h15m8.029980855s
Test Suite Passed
